2023/05/23 18:18:09 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.2 (default, Feb 28 2021, 17:03:44) [GCC 10.2.1 20210110]
    CUDA available: True
    numpy_random_seed: 1683914965
    GPU 0,1,2,3,4,5,6,7: Tesla V100-SXM2-32GB
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: x86_64-linux-gnu-gcc (Debian 10.2.1-6) 10.2.1 20210110
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1+cu117
    OpenCV: 4.7.0
    MMEngine: 0.7.3

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: None
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 8
------------------------------------------------------------

2023/05/23 18:18:11 - mmengine - INFO - Config:
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),
    dist_cfg=dict(backend='nccl'))
vis_backends = [dict(type='LocalVisBackend')]
visualizer = dict(
    type='SegLocalVisualizer',
    vis_backends=[dict(type='LocalVisBackend')],
    name='visualizer')
log_processor = dict(by_epoch=False)
log_level = 'INFO'
load_from = None
resume = False
tta_model = dict(type='SegTTAModel')
dataset_type = 'COCOStuffDataset'
data_root = '/home/tiger/COCO'
crop_size = (512, 512)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        type='RandomChoiceResize',
        scales=[
            256, 307, 358, 409, 460, 512, 563, 614, 665, 716, 768, 819, 870,
            921, 972, 1024
        ],
        resize_type='ResizeShortestEdge',
        max_size=2048),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs')
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', scale=(2048, 512), keep_ratio=True),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs')
]
img_ratios = [0.5, 0.75, 1.0, 1.25, 1.5, 1.75]
tta_pipeline = [
    dict(type='LoadImageFromFile', backend_args=None),
    dict(
        type='TestTimeAug',
        transforms=[[{
            'type': 'Resize',
            'scale_factor': 0.5,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 0.75,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.0,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.25,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.5,
            'keep_ratio': True
        }, {
            'type': 'Resize',
            'scale_factor': 1.75,
            'keep_ratio': True
        }],
                    [{
                        'type': 'RandomFlip',
                        'prob': 0.0,
                        'direction': 'horizontal'
                    }, {
                        'type': 'RandomFlip',
                        'prob': 1.0,
                        'direction': 'horizontal'
                    }], [{
                        'type': 'LoadAnnotations'
                    }], [{
                        'type': 'PackSegInputs'
                    }]])
]
val_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='COCOStuffDataset',
        data_root='/home/tiger/COCO',
        data_prefix=dict(
            img_path='images/val2017', seg_map_path='annotations/val2017'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', scale=(2048, 512), keep_ratio=True),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs')
        ]))
test_dataloader = dict(
    batch_size=1,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type='COCOStuffDataset',
        data_root='/home/tiger/COCO',
        data_prefix=dict(
            img_path='images/val2017', seg_map_path='annotations/val2017'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', scale=(2048, 512), keep_ratio=True),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs')
        ]))
val_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])
test_evaluator = dict(type='IoUMetric', iou_metrics=['mIoU'])
custom_imports = dict(imports='mmdet.models', allow_failed_imports=False)
data_preprocessor = dict(
    type='SegDataPreProcessor',
    mean=[123.675, 116.28, 103.53],
    std=[58.395, 57.12, 57.375],
    bgr_to_rgb=True,
    pad_val=0,
    seg_pad_val=255,
    size=(512, 512),
    test_cfg=dict(size_divisor=32))
num_classes = 171
model = dict(
    type='EncoderDecoder',
    data_preprocessor=dict(
        type='SegDataPreProcessor',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        bgr_to_rgb=True,
        pad_val=0,
        seg_pad_val=255,
        size=(512, 512),
        test_cfg=dict(size_divisor=32)),
    backbone=dict(
        type='SwinTransformer',
        embed_dims=96,
        depths=[2, 2, 18, 2],
        num_heads=[3, 6, 12, 24],
        window_size=7,
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        drop_rate=0.0,
        attn_drop_rate=0.0,
        drop_path_rate=0.3,
        patch_norm=True,
        out_indices=(0, 1, 2, 3),
        with_cp=False,
        frozen_stages=-1,
        init_cfg=dict(
            type='Pretrained',
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_small_patch4_window7_224_20220317-7ba6d6dd.pth'
        )),
    decode_head=dict(
        type='Mask2FormerHead',
        in_channels=[96, 192, 384, 768],
        strides=[4, 8, 16, 32],
        feat_channels=256,
        out_channels=256,
        num_classes=171,
        num_queries=100,
        num_transformer_feat_level=3,
        align_corners=False,
        pixel_decoder=dict(
            type='mmdet.MSDeformAttnPixelDecoder',
            num_outs=3,
            norm_cfg=dict(type='GN', num_groups=32),
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                num_layers=6,
                layer_cfg=dict(
                    self_attn_cfg=dict(
                        embed_dims=256,
                        num_heads=8,
                        num_levels=3,
                        num_points=4,
                        im2col_step=64,
                        dropout=0.0,
                        batch_first=True,
                        norm_cfg=None,
                        init_cfg=None),
                    ffn_cfg=dict(
                        embed_dims=256,
                        feedforward_channels=1024,
                        num_fcs=2,
                        ffn_drop=0.0,
                        act_cfg=dict(type='ReLU', inplace=True))),
                init_cfg=None),
            positional_encoding=dict(num_feats=128, normalize=True),
            init_cfg=None),
        enforce_decoder_input_project=False,
        positional_encoding=dict(num_feats=128, normalize=True),
        transformer_decoder=dict(
            return_intermediate=True,
            num_layers=9,
            layer_cfg=dict(
                self_attn_cfg=dict(
                    embed_dims=256,
                    num_heads=8,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=True),
                cross_attn_cfg=dict(
                    embed_dims=256,
                    num_heads=8,
                    attn_drop=0.0,
                    proj_drop=0.0,
                    dropout_layer=None,
                    batch_first=True),
                ffn_cfg=dict(
                    embed_dims=256,
                    feedforward_channels=2048,
                    num_fcs=2,
                    act_cfg=dict(type='ReLU', inplace=True),
                    ffn_drop=0.0,
                    dropout_layer=None,
                    add_identity=True)),
            init_cfg=None),
        loss_cls=dict(
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False,
            loss_weight=2.0,
            reduction='mean',
            class_weight=[
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                1.0, 1.0, 1.0, 0.1
            ]),
        loss_mask=dict(
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True,
            reduction='mean',
            loss_weight=5.0),
        loss_dice=dict(
            type='mmdet.DiceLoss',
            use_sigmoid=True,
            activate=True,
            reduction='mean',
            naive_dice=True,
            eps=1.0,
            loss_weight=5.0),
        train_cfg=dict(
            num_points=12544,
            oversample_ratio=3.0,
            importance_sample_ratio=0.75,
            assigner=dict(
                type='mmdet.HungarianAssigner',
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        weight=5.0,
                        use_sigmoid=True),
                    dict(
                        type='mmdet.DiceCost',
                        weight=5.0,
                        pred_act=True,
                        eps=1.0)
                ]),
            sampler=dict(type='mmdet.MaskPseudoSampler'))),
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
embed_multi = dict(lr_mult=1.0, decay_mult=0.0)
optimizer = dict(
    type='AdamW', lr=0.0001, weight_decay=0.05, eps=1e-08, betas=(0.9, 0.999))
optim_wrapper = dict(
    type='OptimWrapper',
    optimizer=dict(
        type='AdamW',
        lr=0.0001,
        weight_decay=0.05,
        eps=1e-08,
        betas=(0.9, 0.999)),
    clip_grad=dict(max_norm=0.01, norm_type=2),
    paramwise_cfg=dict(
        custom_keys=dict({
            'backbone':
            dict(lr_mult=0.1, decay_mult=1.0),
            'query_embed':
            dict(lr_mult=1.0, decay_mult=0.0),
            'query_feat':
            dict(lr_mult=1.0, decay_mult=0.0),
            'level_embed':
            dict(lr_mult=1.0, decay_mult=0.0),
            'backbone.patch_embed.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'absolute_pos_embed':
            dict(lr_mult=0.1, decay_mult=0.0),
            'relative_position_bias_table':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.0.blocks.0.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.0.blocks.1.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.1.blocks.0.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.1.blocks.1.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.0.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.1.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.2.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.3.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.4.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.5.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.3.blocks.0.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.3.blocks.1.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.0.downsample.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.1.downsample.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.downsample.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.6.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.7.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.8.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.9.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.10.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.11.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.12.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.13.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.14.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.15.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.16.norm':
            dict(lr_mult=0.1, decay_mult=0.0),
            'backbone.stages.2.blocks.17.norm':
            dict(lr_mult=0.1, decay_mult=0.0)
        }),
        norm_decay_mult=0.0))
param_scheduler = [
    dict(
        type='PolyLR',
        eta_min=0,
        power=0.9,
        begin=0,
        end=160000,
        by_epoch=False)
]
train_cfg = dict(
    type='IterBasedTrainLoop', max_iters=160000, val_interval=5000)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')
default_hooks = dict(
    timer=dict(type='IterTimerHook'),
    logger=dict(type='LoggerHook', interval=50, log_metric_by_epoch=False),
    param_scheduler=dict(type='ParamSchedulerHook'),
    checkpoint=dict(
        type='CheckpointHook',
        by_epoch=False,
        interval=1000,
        save_best='mIoU',
        max_keep_ckpts=1),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    visualization=dict(type='SegVisualizationHook'))
auto_scale_lr = dict(enable=False, base_batch_size=16)
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_small_patch4_window7_224_20220317-7ba6d6dd.pth'
depths = [2, 2, 18, 2]
backbone_norm_multi = dict(lr_mult=0.1, decay_mult=0.0)
backbone_embed_multi = dict(lr_mult=0.1, decay_mult=0.0)
custom_keys = dict({
    'backbone':
    dict(lr_mult=0.1, decay_mult=1.0),
    'backbone.patch_embed.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'absolute_pos_embed':
    dict(lr_mult=0.1, decay_mult=0.0),
    'relative_position_bias_table':
    dict(lr_mult=0.1, decay_mult=0.0),
    'query_embed':
    dict(lr_mult=1.0, decay_mult=0.0),
    'query_feat':
    dict(lr_mult=1.0, decay_mult=0.0),
    'level_embed':
    dict(lr_mult=1.0, decay_mult=0.0),
    'backbone.stages.0.blocks.0.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.0.blocks.1.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.1.blocks.0.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.1.blocks.1.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.0.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.1.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.2.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.3.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.4.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.5.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.3.blocks.0.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.3.blocks.1.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.0.downsample.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.1.downsample.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.downsample.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.6.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.7.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.8.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.9.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.10.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.11.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.12.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.13.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.14.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.15.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.16.norm':
    dict(lr_mult=0.1, decay_mult=0.0),
    'backbone.stages.2.blocks.17.norm':
    dict(lr_mult=0.1, decay_mult=0.0)
})
data_root_syn = '/home/tiger/COCO_train_6x'
dataset_real_train = dict(
    type='RepeatDataset',
    times=4,
    dataset=dict(
        type='COCOStuffDataset',
        data_root='/home/tiger/COCO',
        data_prefix=dict(
            img_path='images/train2017', seg_map_path='annotations/train2017'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='RandomChoiceResize',
                scales=[
                    256, 307, 358, 409, 460, 512, 563, 614, 665, 716, 768, 819,
                    870, 921, 972, 1024
                ],
                resize_type='ResizeShortestEdge',
                max_size=2048),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs')
        ]))
dataset_syn_train = dict(
    type='RepeatDataset',
    times=1,
    dataset=dict(
        type='COCOStuffDataset',
        data_root='/home/tiger/COCO_train_6x',
        data_prefix=dict(
            img_path='images_resampled',
            seg_map_path='annotations_ignored_1.25_resampled'),
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                type='RandomChoiceResize',
                scales=[
                    256, 307, 358, 409, 460, 512, 563, 614, 665, 716, 768, 819,
                    870, 921, 972, 1024
                ],
                resize_type='ResizeShortestEdge',
                max_size=2048),
            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
            dict(type='RandomFlip', prob=0.5),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs')
        ]))
train_dataloader = dict(
    batch_size=2,
    num_workers=4,
    persistent_workers=True,
    sampler=dict(type='InfiniteSampler', shuffle=True),
    dataset=dict(
        type='ConcatDataset',
        datasets=[
            dict(
                type='RepeatDataset',
                times=4,
                dataset=dict(
                    type='COCOStuffDataset',
                    data_root='/home/tiger/COCO',
                    data_prefix=dict(
                        img_path='images/train2017',
                        seg_map_path='annotations/train2017'),
                    pipeline=[
                        dict(type='LoadImageFromFile'),
                        dict(type='LoadAnnotations'),
                        dict(
                            type='RandomChoiceResize',
                            scales=[
                                256, 307, 358, 409, 460, 512, 563, 614, 665,
                                716, 768, 819, 870, 921, 972, 1024
                            ],
                            resize_type='ResizeShortestEdge',
                            max_size=2048),
                        dict(
                            type='RandomCrop',
                            crop_size=(512, 512),
                            cat_max_ratio=0.75),
                        dict(type='RandomFlip', prob=0.5),
                        dict(type='PhotoMetricDistortion'),
                        dict(type='PackSegInputs')
                    ])),
            dict(
                type='RepeatDataset',
                times=1,
                dataset=dict(
                    type='COCOStuffDataset',
                    data_root='/home/tiger/COCO_train_6x',
                    data_prefix=dict(
                        img_path='images_resampled',
                        seg_map_path='annotations_ignored_1.25_resampled'),
                    pipeline=[
                        dict(type='LoadImageFromFile'),
                        dict(type='LoadAnnotations'),
                        dict(
                            type='RandomChoiceResize',
                            scales=[
                                256, 307, 358, 409, 460, 512, 563, 614, 665,
                                716, 768, 819, 870, 921, 972, 1024
                            ],
                            resize_type='ResizeShortestEdge',
                            max_size=2048),
                        dict(
                            type='RandomCrop',
                            crop_size=(512, 512),
                            cat_max_ratio=0.75),
                        dict(type='RandomFlip', prob=0.5),
                        dict(type='PhotoMetricDistortion'),
                        dict(type='PackSegInputs')
                    ]))
        ]))
work_dir = './work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled'
launcher = 'pytorch'

2023/05/23 18:18:17 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train:
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2023/05/23 18:18:29 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2023/05/23 18:18:30 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Name of parameter - Initialization information

backbone.patch_embed.projection.weight - torch.Size([96, 3, 4, 4]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.projection.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.patch_embed.norm.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.0.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 3]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.weight - torch.Size([288, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.qkv.bias - torch.Size([288]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.weight - torch.Size([96, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.attn.w_msa.proj.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.weight - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.norm2.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.weight - torch.Size([384, 96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.0.0.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.weight - torch.Size([96, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.blocks.1.ffn.layers.1.bias - torch.Size([96]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.norm.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.0.downsample.reduction.weight - torch.Size([192, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.0.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 6]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.attn.w_msa.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.weight - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.norm2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.0.0.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.blocks.1.ffn.layers.1.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.norm.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.1.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.0.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.1.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.2.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.3.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.4.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.5.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.6.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.7.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.8.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.9.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.10.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.11.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.12.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.13.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.14.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.15.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.16.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table - torch.Size([169, 12]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.attn.w_msa.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.weight - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.norm2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.0.0.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.blocks.17.ffn.layers.1.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.weight - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.norm.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.2.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.0.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table - torch.Size([169, 24]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.attn.w_msa.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.weight - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.norm2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.0.0.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.stages.3.blocks.1.ffn.layers.1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformer  

backbone.norm0.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm0.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 768, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 192, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 96, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([172, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([172]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2023/05/23 18:18:49 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2023/05/23 18:18:49 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2023/05/23 18:18:49 - mmengine - INFO - Checkpoints will be saved to /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled.
2023/05/23 18:19:18 - mmengine - INFO - Iter(train) [    50/160000]  lr: 9.9972e-06  eta: 1 day, 1:39:33  time: 0.4122  data_time: 0.0125  memory: 11845  grad_norm: 83.9058  loss: 118.6660  decode.loss_cls: 5.0732  decode.loss_mask: 1.7490  decode.loss_dice: 4.7148  decode.d0.loss_cls: 10.3563  decode.d0.loss_mask: 1.8776  decode.d0.loss_dice: 4.2380  decode.d1.loss_cls: 5.0473  decode.d1.loss_mask: 1.8669  decode.d1.loss_dice: 4.2881  decode.d2.loss_cls: 5.0411  decode.d2.loss_mask: 1.8475  decode.d2.loss_dice: 4.2713  decode.d3.loss_cls: 5.0587  decode.d3.loss_mask: 1.8826  decode.d3.loss_dice: 4.2657  decode.d4.loss_cls: 5.0201  decode.d4.loss_mask: 1.8872  decode.d4.loss_dice: 4.4033  decode.d5.loss_cls: 5.0519  decode.d5.loss_mask: 1.8532  decode.d5.loss_dice: 4.4559  decode.d6.loss_cls: 4.9876  decode.d6.loss_mask: 1.8250  decode.d6.loss_dice: 4.5166  decode.d7.loss_cls: 5.0562  decode.d7.loss_mask: 1.9141  decode.d7.loss_dice: 4.5952  decode.d8.loss_cls: 5.0448  decode.d8.loss_mask: 1.7695  decode.d8.loss_dice: 4.7073
2023/05/23 18:19:39 - mmengine - INFO - Iter(train) [   100/160000]  lr: 9.9944e-06  eta: 22:09:06  time: 0.4146  data_time: 0.0110  memory: 4807  grad_norm: 99.9825  loss: 101.3472  decode.loss_cls: 4.9944  decode.loss_mask: 1.8251  decode.loss_dice: 3.0549  decode.d0.loss_cls: 10.2375  decode.d0.loss_mask: 1.7174  decode.d0.loss_dice: 3.1157  decode.d1.loss_cls: 4.9771  decode.d1.loss_mask: 1.6783  decode.d1.loss_dice: 2.9727  decode.d2.loss_cls: 4.9474  decode.d2.loss_mask: 1.6527  decode.d2.loss_dice: 2.8350  decode.d3.loss_cls: 4.8617  decode.d3.loss_mask: 1.6882  decode.d3.loss_dice: 2.8300  decode.d4.loss_cls: 4.9114  decode.d4.loss_mask: 1.7086  decode.d4.loss_dice: 2.8050  decode.d5.loss_cls: 4.9174  decode.d5.loss_mask: 1.7552  decode.d5.loss_dice: 2.8526  decode.d6.loss_cls: 4.9719  decode.d6.loss_mask: 1.7551  decode.d6.loss_dice: 2.8587  decode.d7.loss_cls: 5.0235  decode.d7.loss_mask: 1.7283  decode.d7.loss_dice: 2.9233  decode.d8.loss_cls: 4.9868  decode.d8.loss_mask: 1.8031  decode.d8.loss_dice: 2.9583
2023/05/23 18:20:00 - mmengine - INFO - Iter(train) [   150/160000]  lr: 9.9916e-06  eta: 20:57:27  time: 0.4167  data_time: 0.0100  memory: 4837  grad_norm: 107.8854  loss: 85.1808  decode.loss_cls: 4.3855  decode.loss_mask: 1.2657  decode.loss_dice: 2.3556  decode.d0.loss_cls: 10.1502  decode.d0.loss_mask: 1.2659  decode.d0.loss_dice: 2.6070  decode.d1.loss_cls: 4.4170  decode.d1.loss_mask: 1.2512  decode.d1.loss_dice: 2.3878  decode.d2.loss_cls: 4.3541  decode.d2.loss_mask: 1.2550  decode.d2.loss_dice: 2.3449  decode.d3.loss_cls: 4.2812  decode.d3.loss_mask: 1.2842  decode.d3.loss_dice: 2.2803  decode.d4.loss_cls: 4.3113  decode.d4.loss_mask: 1.2267  decode.d4.loss_dice: 2.2528  decode.d5.loss_cls: 4.3398  decode.d5.loss_mask: 1.2363  decode.d5.loss_dice: 2.2971  decode.d6.loss_cls: 4.3501  decode.d6.loss_mask: 1.2611  decode.d6.loss_dice: 2.2226  decode.d7.loss_cls: 4.3723  decode.d7.loss_mask: 1.2430  decode.d7.loss_dice: 2.2701  decode.d8.loss_cls: 4.3911  decode.d8.loss_mask: 1.2365  decode.d8.loss_dice: 2.2843
2023/05/23 18:20:20 - mmengine - INFO - Iter(train) [   200/160000]  lr: 9.9888e-06  eta: 20:16:36  time: 0.4127  data_time: 0.0101  memory: 4870  grad_norm: 118.5033  loss: 101.1682  decode.loss_cls: 4.8396  decode.loss_mask: 1.8135  decode.loss_dice: 2.9145  decode.d0.loss_cls: 10.1302  decode.d0.loss_mask: 1.6939  decode.d0.loss_dice: 3.2830  decode.d1.loss_cls: 4.9669  decode.d1.loss_mask: 1.7303  decode.d1.loss_dice: 3.0889  decode.d2.loss_cls: 4.8445  decode.d2.loss_mask: 1.7164  decode.d2.loss_dice: 2.9376  decode.d3.loss_cls: 4.7954  decode.d3.loss_mask: 1.7771  decode.d3.loss_dice: 2.8997  decode.d4.loss_cls: 4.8042  decode.d4.loss_mask: 1.7648  decode.d4.loss_dice: 2.9349  decode.d5.loss_cls: 4.8374  decode.d5.loss_mask: 1.8100  decode.d5.loss_dice: 2.9015  decode.d6.loss_cls: 4.8077  decode.d6.loss_mask: 1.8315  decode.d6.loss_dice: 2.9363  decode.d7.loss_cls: 4.8187  decode.d7.loss_mask: 1.8102  decode.d7.loss_dice: 2.9219  decode.d8.loss_cls: 4.8467  decode.d8.loss_mask: 1.8149  decode.d8.loss_dice: 2.8960
2023/05/23 18:20:42 - mmengine - INFO - Iter(train) [   250/160000]  lr: 9.9860e-06  eta: 20:00:53  time: 0.4346  data_time: 0.0108  memory: 4869  grad_norm: 126.5500  loss: 109.2323  decode.loss_cls: 5.1362  decode.loss_mask: 1.8076  decode.loss_dice: 3.4885  decode.d0.loss_cls: 9.9877  decode.d0.loss_mask: 1.7379  decode.d0.loss_dice: 4.0220  decode.d1.loss_cls: 5.3221  decode.d1.loss_mask: 1.6899  decode.d1.loss_dice: 3.6511  decode.d2.loss_cls: 5.1341  decode.d2.loss_mask: 1.7366  decode.d2.loss_dice: 3.4515  decode.d3.loss_cls: 5.0861  decode.d3.loss_mask: 1.7608  decode.d3.loss_dice: 3.4445  decode.d4.loss_cls: 5.0738  decode.d4.loss_mask: 1.7299  decode.d4.loss_dice: 3.4800  decode.d5.loss_cls: 5.1341  decode.d5.loss_mask: 1.7382  decode.d5.loss_dice: 3.5052  decode.d6.loss_cls: 5.1152  decode.d6.loss_mask: 1.7829  decode.d6.loss_dice: 3.4977  decode.d7.loss_cls: 5.0984  decode.d7.loss_mask: 1.7458  decode.d7.loss_dice: 3.5103  decode.d8.loss_cls: 5.1054  decode.d8.loss_mask: 1.7464  decode.d8.loss_dice: 3.5124
2023/05/23 18:21:03 - mmengine - INFO - Iter(train) [   300/160000]  lr: 9.9832e-06  eta: 19:47:24  time: 0.4400  data_time: 0.0100  memory: 4881  grad_norm: 108.5209  loss: 85.1713  decode.loss_cls: 4.3527  decode.loss_mask: 1.0948  decode.loss_dice: 2.5111  decode.d0.loss_cls: 9.8526  decode.d0.loss_mask: 1.0873  decode.d0.loss_dice: 2.8270  decode.d1.loss_cls: 4.5396  decode.d1.loss_mask: 1.0732  decode.d1.loss_dice: 2.6055  decode.d2.loss_cls: 4.3533  decode.d2.loss_mask: 1.0656  decode.d2.loss_dice: 2.5060  decode.d3.loss_cls: 4.2748  decode.d3.loss_mask: 1.0558  decode.d3.loss_dice: 2.4133  decode.d4.loss_cls: 4.3074  decode.d4.loss_mask: 1.0440  decode.d4.loss_dice: 2.4908  decode.d5.loss_cls: 4.2893  decode.d5.loss_mask: 1.1173  decode.d5.loss_dice: 2.4865  decode.d6.loss_cls: 4.3042  decode.d6.loss_mask: 1.0986  decode.d6.loss_dice: 2.4941  decode.d7.loss_cls: 4.3713  decode.d7.loss_mask: 1.0696  decode.d7.loss_dice: 2.5129  decode.d8.loss_cls: 4.3593  decode.d8.loss_mask: 1.0997  decode.d8.loss_dice: 2.5138
2023/05/23 18:21:24 - mmengine - INFO - Iter(train) [   350/160000]  lr: 9.9804e-06  eta: 19:37:17  time: 0.4135  data_time: 0.0105  memory: 4850  grad_norm: 121.2365  loss: 90.7203  decode.loss_cls: 4.4953  decode.loss_mask: 1.5695  decode.loss_dice: 2.4984  decode.d0.loss_cls: 9.7138  decode.d0.loss_mask: 1.4755  decode.d0.loss_dice: 2.9214  decode.d1.loss_cls: 4.7668  decode.d1.loss_mask: 1.4062  decode.d1.loss_dice: 2.5849  decode.d2.loss_cls: 4.4831  decode.d2.loss_mask: 1.5111  decode.d2.loss_dice: 2.4410  decode.d3.loss_cls: 4.4871  decode.d3.loss_mask: 1.4549  decode.d3.loss_dice: 2.4259  decode.d4.loss_cls: 4.4416  decode.d4.loss_mask: 1.4980  decode.d4.loss_dice: 2.4799  decode.d5.loss_cls: 4.4559  decode.d5.loss_mask: 1.5641  decode.d5.loss_dice: 2.4543  decode.d6.loss_cls: 4.4909  decode.d6.loss_mask: 1.5796  decode.d6.loss_dice: 2.4500  decode.d7.loss_cls: 4.4815  decode.d7.loss_mask: 1.5324  decode.d7.loss_dice: 2.4992  decode.d8.loss_cls: 4.5060  decode.d8.loss_mask: 1.5812  decode.d8.loss_dice: 2.4708
2023/05/23 18:21:45 - mmengine - INFO - Iter(train) [   400/160000]  lr: 9.9776e-06  eta: 19:28:21  time: 0.4377  data_time: 0.0105  memory: 4837  grad_norm: 117.4946  loss: 85.8447  decode.loss_cls: 4.4029  decode.loss_mask: 1.2858  decode.loss_dice: 2.3160  decode.d0.loss_cls: 9.6328  decode.d0.loss_mask: 1.2741  decode.d0.loss_dice: 2.7510  decode.d1.loss_cls: 4.6696  decode.d1.loss_mask: 1.2639  decode.d1.loss_dice: 2.4004  decode.d2.loss_cls: 4.4890  decode.d2.loss_mask: 1.2563  decode.d2.loss_dice: 2.3314  decode.d3.loss_cls: 4.4110  decode.d3.loss_mask: 1.2762  decode.d3.loss_dice: 2.3016  decode.d4.loss_cls: 4.3882  decode.d4.loss_mask: 1.2849  decode.d4.loss_dice: 2.2734  decode.d5.loss_cls: 4.4000  decode.d5.loss_mask: 1.2847  decode.d5.loss_dice: 2.3018  decode.d6.loss_cls: 4.3770  decode.d6.loss_mask: 1.2664  decode.d6.loss_dice: 2.2674  decode.d7.loss_cls: 4.3946  decode.d7.loss_mask: 1.2598  decode.d7.loss_dice: 2.3071  decode.d8.loss_cls: 4.3738  decode.d8.loss_mask: 1.2964  decode.d8.loss_dice: 2.3070
2023/05/23 18:22:06 - mmengine - INFO - Iter(train) [   450/160000]  lr: 9.9747e-06  eta: 19:24:09  time: 0.4105  data_time: 0.0101  memory: 4835  grad_norm: 121.3480  loss: 70.8907  decode.loss_cls: 3.6228  decode.loss_mask: 1.2176  decode.loss_dice: 1.6252  decode.d0.loss_cls: 9.4291  decode.d0.loss_mask: 1.2294  decode.d0.loss_dice: 1.9510  decode.d1.loss_cls: 3.9100  decode.d1.loss_mask: 1.2739  decode.d1.loss_dice: 1.7527  decode.d2.loss_cls: 3.6867  decode.d2.loss_mask: 1.2491  decode.d2.loss_dice: 1.6566  decode.d3.loss_cls: 3.5850  decode.d3.loss_mask: 1.2130  decode.d3.loss_dice: 1.6249  decode.d4.loss_cls: 3.5698  decode.d4.loss_mask: 1.2296  decode.d4.loss_dice: 1.6157  decode.d5.loss_cls: 3.5847  decode.d5.loss_mask: 1.1762  decode.d5.loss_dice: 1.6161  decode.d6.loss_cls: 3.5828  decode.d6.loss_mask: 1.1352  decode.d6.loss_dice: 1.5882  decode.d7.loss_cls: 3.5813  decode.d7.loss_mask: 1.1705  decode.d7.loss_dice: 1.6164  decode.d8.loss_cls: 3.6114  decode.d8.loss_mask: 1.1701  decode.d8.loss_dice: 1.6156
2023/05/23 18:22:27 - mmengine - INFO - Iter(train) [   500/160000]  lr: 9.9719e-06  eta: 19:22:16  time: 0.4621  data_time: 0.0099  memory: 4968  grad_norm: 118.8810  loss: 87.2187  decode.loss_cls: 4.1442  decode.loss_mask: 1.4794  decode.loss_dice: 2.5102  decode.d0.loss_cls: 9.2251  decode.d0.loss_mask: 1.4323  decode.d0.loss_dice: 2.7982  decode.d1.loss_cls: 4.5134  decode.d1.loss_mask: 1.5359  decode.d1.loss_dice: 2.5179  decode.d2.loss_cls: 4.2812  decode.d2.loss_mask: 1.5139  decode.d2.loss_dice: 2.3886  decode.d3.loss_cls: 4.1887  decode.d3.loss_mask: 1.5061  decode.d3.loss_dice: 2.4602  decode.d4.loss_cls: 4.2158  decode.d4.loss_mask: 1.5152  decode.d4.loss_dice: 2.4766  decode.d5.loss_cls: 4.2029  decode.d5.loss_mask: 1.4753  decode.d5.loss_dice: 2.4786  decode.d6.loss_cls: 4.1769  decode.d6.loss_mask: 1.4772  decode.d6.loss_dice: 2.4451  decode.d7.loss_cls: 4.1498  decode.d7.loss_mask: 1.4915  decode.d7.loss_dice: 2.5013  decode.d8.loss_cls: 4.1271  decode.d8.loss_mask: 1.4914  decode.d8.loss_dice: 2.4989
2023/05/23 18:22:50 - mmengine - INFO - Iter(train) [   550/160000]  lr: 9.9691e-06  eta: 19:23:47  time: 0.4075  data_time: 0.0100  memory: 4865  grad_norm: 117.5342  loss: 80.5073  decode.loss_cls: 3.7954  decode.loss_mask: 1.3214  decode.loss_dice: 2.3142  decode.d0.loss_cls: 9.0941  decode.d0.loss_mask: 1.2867  decode.d0.loss_dice: 2.7442  decode.d1.loss_cls: 4.1276  decode.d1.loss_mask: 1.3360  decode.d1.loss_dice: 2.3875  decode.d2.loss_cls: 3.9204  decode.d2.loss_mask: 1.2732  decode.d2.loss_dice: 2.2764  decode.d3.loss_cls: 3.8898  decode.d3.loss_mask: 1.2487  decode.d3.loss_dice: 2.2754  decode.d4.loss_cls: 3.8766  decode.d4.loss_mask: 1.3036  decode.d4.loss_dice: 2.2690  decode.d5.loss_cls: 3.8585  decode.d5.loss_mask: 1.2605  decode.d5.loss_dice: 2.2983  decode.d6.loss_cls: 3.8631  decode.d6.loss_mask: 1.2679  decode.d6.loss_dice: 2.2890  decode.d7.loss_cls: 3.8626  decode.d7.loss_mask: 1.2400  decode.d7.loss_dice: 2.3396  decode.d8.loss_cls: 3.8911  decode.d8.loss_mask: 1.2990  decode.d8.loss_dice: 2.2973
2023/05/23 18:23:10 - mmengine - INFO - Iter(train) [   600/160000]  lr: 9.9663e-06  eta: 19:17:48  time: 0.4254  data_time: 0.0104  memory: 4900  grad_norm: 114.3696  loss: 74.2046  decode.loss_cls: 3.5255  decode.loss_mask: 1.2981  decode.loss_dice: 2.0331  decode.d0.loss_cls: 8.8095  decode.d0.loss_mask: 1.2493  decode.d0.loss_dice: 2.2222  decode.d1.loss_cls: 3.8470  decode.d1.loss_mask: 1.2620  decode.d1.loss_dice: 2.0307  decode.d2.loss_cls: 3.6777  decode.d2.loss_mask: 1.2287  decode.d2.loss_dice: 1.9415  decode.d3.loss_cls: 3.5845  decode.d3.loss_mask: 1.2560  decode.d3.loss_dice: 1.9833  decode.d4.loss_cls: 3.5829  decode.d4.loss_mask: 1.2858  decode.d4.loss_dice: 1.9681  decode.d5.loss_cls: 3.5148  decode.d5.loss_mask: 1.2800  decode.d5.loss_dice: 2.0017  decode.d6.loss_cls: 3.5347  decode.d6.loss_mask: 1.2936  decode.d6.loss_dice: 2.0425  decode.d7.loss_cls: 3.5135  decode.d7.loss_mask: 1.3348  decode.d7.loss_dice: 2.0141  decode.d8.loss_cls: 3.5620  decode.d8.loss_mask: 1.3053  decode.d8.loss_dice: 2.0219
2023/05/23 18:23:32 - mmengine - INFO - Iter(train) [   650/160000]  lr: 9.9635e-06  eta: 19:17:39  time: 0.4659  data_time: 0.0102  memory: 4902  grad_norm: 114.7624  loss: 78.4110  decode.loss_cls: 3.8851  decode.loss_mask: 1.2324  decode.loss_dice: 2.1187  decode.d0.loss_cls: 8.8272  decode.d0.loss_mask: 1.3835  decode.d0.loss_dice: 2.4117  decode.d1.loss_cls: 4.0858  decode.d1.loss_mask: 1.3052  decode.d1.loss_dice: 2.2085  decode.d2.loss_cls: 3.9267  decode.d2.loss_mask: 1.2968  decode.d2.loss_dice: 2.1340  decode.d3.loss_cls: 3.8471  decode.d3.loss_mask: 1.3217  decode.d3.loss_dice: 2.1309  decode.d4.loss_cls: 3.8014  decode.d4.loss_mask: 1.3006  decode.d4.loss_dice: 2.1313  decode.d5.loss_cls: 3.8344  decode.d5.loss_mask: 1.2747  decode.d5.loss_dice: 2.1144  decode.d6.loss_cls: 3.8393  decode.d6.loss_mask: 1.3126  decode.d6.loss_dice: 2.0978  decode.d7.loss_cls: 3.8871  decode.d7.loss_mask: 1.2752  decode.d7.loss_dice: 2.1571  decode.d8.loss_cls: 3.8412  decode.d8.loss_mask: 1.2827  decode.d8.loss_dice: 2.1460
2023/05/23 18:23:53 - mmengine - INFO - Iter(train) [   700/160000]  lr: 9.9607e-06  eta: 19:13:10  time: 0.4051  data_time: 0.0108  memory: 4928  grad_norm: 98.9116  loss: 61.7556  decode.loss_cls: 3.2156  decode.loss_mask: 0.8488  decode.loss_dice: 1.4296  decode.d0.loss_cls: 8.4775  decode.d0.loss_mask: 0.9238  decode.d0.loss_dice: 1.7288  decode.d1.loss_cls: 3.5572  decode.d1.loss_mask: 0.9114  decode.d1.loss_dice: 1.5222  decode.d2.loss_cls: 3.3558  decode.d2.loss_mask: 0.9212  decode.d2.loss_dice: 1.4785  decode.d3.loss_cls: 3.2604  decode.d3.loss_mask: 0.9215  decode.d3.loss_dice: 1.4683  decode.d4.loss_cls: 3.2330  decode.d4.loss_mask: 0.9038  decode.d4.loss_dice: 1.4829  decode.d5.loss_cls: 3.2345  decode.d5.loss_mask: 0.8950  decode.d5.loss_dice: 1.4137  decode.d6.loss_cls: 3.2352  decode.d6.loss_mask: 0.8796  decode.d6.loss_dice: 1.4285  decode.d7.loss_cls: 3.2415  decode.d7.loss_mask: 0.8575  decode.d7.loss_dice: 1.4324  decode.d8.loss_cls: 3.1958  decode.d8.loss_mask: 0.8616  decode.d8.loss_dice: 1.4400
2023/05/23 18:24:14 - mmengine - INFO - Iter(train) [   750/160000]  lr: 9.9579e-06  eta: 19:09:02  time: 0.4114  data_time: 0.0105  memory: 4868  grad_norm: 101.6218  loss: 64.5656  decode.loss_cls: 3.2692  decode.loss_mask: 0.8770  decode.loss_dice: 1.7320  decode.d0.loss_cls: 8.3315  decode.d0.loss_mask: 0.9042  decode.d0.loss_dice: 2.0252  decode.d1.loss_cls: 3.6783  decode.d1.loss_mask: 0.9369  decode.d1.loss_dice: 1.7802  decode.d2.loss_cls: 3.3803  decode.d2.loss_mask: 0.9200  decode.d2.loss_dice: 1.7108  decode.d3.loss_cls: 3.2843  decode.d3.loss_mask: 0.8862  decode.d3.loss_dice: 1.6722  decode.d4.loss_cls: 3.2935  decode.d4.loss_mask: 0.8680  decode.d4.loss_dice: 1.7172  decode.d5.loss_cls: 3.2912  decode.d5.loss_mask: 0.8469  decode.d5.loss_dice: 1.7207  decode.d6.loss_cls: 3.2365  decode.d6.loss_mask: 0.8551  decode.d6.loss_dice: 1.7078  decode.d7.loss_cls: 3.2176  decode.d7.loss_mask: 0.8620  decode.d7.loss_dice: 1.7446  decode.d8.loss_cls: 3.2349  decode.d8.loss_mask: 0.8710  decode.d8.loss_dice: 1.7103
2023/05/23 18:24:34 - mmengine - INFO - Iter(train) [   800/160000]  lr: 9.9550e-06  eta: 19:04:13  time: 0.4066  data_time: 0.0101  memory: 4848  grad_norm: 99.7243  loss: 80.1603  decode.loss_cls: 3.5555  decode.loss_mask: 1.4137  decode.loss_dice: 2.4552  decode.d0.loss_cls: 8.2213  decode.d0.loss_mask: 1.4400  decode.d0.loss_dice: 2.7343  decode.d1.loss_cls: 3.9607  decode.d1.loss_mask: 1.4421  decode.d1.loss_dice: 2.5206  decode.d2.loss_cls: 3.7613  decode.d2.loss_mask: 1.4177  decode.d2.loss_dice: 2.4532  decode.d3.loss_cls: 3.6293  decode.d3.loss_mask: 1.3790  decode.d3.loss_dice: 2.3776  decode.d4.loss_cls: 3.5919  decode.d4.loss_mask: 1.4468  decode.d4.loss_dice: 2.4287  decode.d5.loss_cls: 3.5823  decode.d5.loss_mask: 1.4543  decode.d5.loss_dice: 2.3865  decode.d6.loss_cls: 3.5562  decode.d6.loss_mask: 1.4880  decode.d6.loss_dice: 2.4135  decode.d7.loss_cls: 3.5932  decode.d7.loss_mask: 1.4429  decode.d7.loss_dice: 2.4406  decode.d8.loss_cls: 3.6626  decode.d8.loss_mask: 1.4370  decode.d8.loss_dice: 2.4744
2023/05/23 18:24:56 - mmengine - INFO - Iter(train) [   850/160000]  lr: 9.9522e-06  eta: 19:06:10  time: 0.4679  data_time: 0.0098  memory: 4892  grad_norm: 101.1690  loss: 68.7374  decode.loss_cls: 3.2705  decode.loss_mask: 0.8988  decode.loss_dice: 2.0136  decode.d0.loss_cls: 7.8789  decode.d0.loss_mask: 0.9694  decode.d0.loss_dice: 2.3252  decode.d1.loss_cls: 3.7277  decode.d1.loss_mask: 1.1258  decode.d1.loss_dice: 2.2116  decode.d2.loss_cls: 3.3530  decode.d2.loss_mask: 0.9990  decode.d2.loss_dice: 2.1070  decode.d3.loss_cls: 3.2806  decode.d3.loss_mask: 0.9706  decode.d3.loss_dice: 2.0686  decode.d4.loss_cls: 3.3417  decode.d4.loss_mask: 0.9714  decode.d4.loss_dice: 2.0528  decode.d5.loss_cls: 3.3000  decode.d5.loss_mask: 0.9706  decode.d5.loss_dice: 2.0600  decode.d6.loss_cls: 3.2557  decode.d6.loss_mask: 0.9676  decode.d6.loss_dice: 2.0636  decode.d7.loss_cls: 3.2515  decode.d7.loss_mask: 0.9580  decode.d7.loss_dice: 2.0684  decode.d8.loss_cls: 3.2723  decode.d8.loss_mask: 0.9334  decode.d8.loss_dice: 2.0703
2023/05/23 18:25:18 - mmengine - INFO - Iter(train) [   900/160000]  lr: 9.9494e-06  eta: 19:05:35  time: 0.4101  data_time: 0.0103  memory: 4891  grad_norm: 110.4131  loss: 62.8413  decode.loss_cls: 3.0729  decode.loss_mask: 1.0236  decode.loss_dice: 1.6702  decode.d0.loss_cls: 7.6948  decode.d0.loss_mask: 1.1066  decode.d0.loss_dice: 2.0592  decode.d1.loss_cls: 3.5252  decode.d1.loss_mask: 0.9765  decode.d1.loss_dice: 1.7115  decode.d2.loss_cls: 3.2137  decode.d2.loss_mask: 0.9779  decode.d2.loss_dice: 1.6209  decode.d3.loss_cls: 3.1322  decode.d3.loss_mask: 0.9743  decode.d3.loss_dice: 1.5784  decode.d4.loss_cls: 3.0955  decode.d4.loss_mask: 1.0003  decode.d4.loss_dice: 1.5909  decode.d5.loss_cls: 3.1039  decode.d5.loss_mask: 0.9651  decode.d5.loss_dice: 1.6159  decode.d6.loss_cls: 3.0931  decode.d6.loss_mask: 0.9462  decode.d6.loss_dice: 1.6092  decode.d7.loss_cls: 3.0841  decode.d7.loss_mask: 0.9790  decode.d7.loss_dice: 1.6603  decode.d8.loss_cls: 3.1020  decode.d8.loss_mask: 1.0033  decode.d8.loss_dice: 1.6546
2023/05/23 18:25:41 - mmengine - INFO - Iter(train) [   950/160000]  lr: 9.9466e-06  eta: 19:09:18  time: 0.4706  data_time: 0.0098  memory: 4890  grad_norm: 111.9764  loss: 68.7524  decode.loss_cls: 3.2309  decode.loss_mask: 1.0784  decode.loss_dice: 2.0217  decode.d0.loss_cls: 7.5486  decode.d0.loss_mask: 1.1204  decode.d0.loss_dice: 2.3830  decode.d1.loss_cls: 3.5946  decode.d1.loss_mask: 1.1256  decode.d1.loss_dice: 2.1119  decode.d2.loss_cls: 3.3526  decode.d2.loss_mask: 1.0643  decode.d2.loss_dice: 2.0457  decode.d3.loss_cls: 3.3013  decode.d3.loss_mask: 1.0914  decode.d3.loss_dice: 1.9916  decode.d4.loss_cls: 3.2464  decode.d4.loss_mask: 1.0797  decode.d4.loss_dice: 2.0135  decode.d5.loss_cls: 3.2199  decode.d5.loss_mask: 1.0977  decode.d5.loss_dice: 2.0055  decode.d6.loss_cls: 3.2357  decode.d6.loss_mask: 1.0898  decode.d6.loss_dice: 2.0138  decode.d7.loss_cls: 3.2371  decode.d7.loss_mask: 1.0945  decode.d7.loss_dice: 2.0820  decode.d8.loss_cls: 3.1927  decode.d8.loss_mask: 1.0963  decode.d8.loss_dice: 1.9859
2023/05/23 18:26:03 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 18:26:03 - mmengine - INFO - Iter(train) [  1000/160000]  lr: 9.9438e-06  eta: 19:11:11  time: 0.4581  data_time: 0.0103  memory: 4866  grad_norm: 125.0905  loss: 68.1316  decode.loss_cls: 3.1033  decode.loss_mask: 1.1672  decode.loss_dice: 2.0263  decode.d0.loss_cls: 7.1224  decode.d0.loss_mask: 1.2191  decode.d0.loss_dice: 2.2926  decode.d1.loss_cls: 3.3328  decode.d1.loss_mask: 1.1825  decode.d1.loss_dice: 2.1091  decode.d2.loss_cls: 3.1746  decode.d2.loss_mask: 1.1741  decode.d2.loss_dice: 2.0470  decode.d3.loss_cls: 3.1504  decode.d3.loss_mask: 1.1358  decode.d3.loss_dice: 2.0251  decode.d4.loss_cls: 3.1784  decode.d4.loss_mask: 1.1438  decode.d4.loss_dice: 2.0331  decode.d5.loss_cls: 3.1644  decode.d5.loss_mask: 1.2053  decode.d5.loss_dice: 2.0436  decode.d6.loss_cls: 3.1462  decode.d6.loss_mask: 1.1925  decode.d6.loss_dice: 2.0411  decode.d7.loss_cls: 3.1121  decode.d7.loss_mask: 1.1809  decode.d7.loss_dice: 2.0209  decode.d8.loss_cls: 3.1333  decode.d8.loss_mask: 1.2073  decode.d8.loss_dice: 2.0665
2023/05/23 18:26:03 - mmengine - INFO - Saving checkpoint at 1000 iterations
2023/05/23 18:26:32 - mmengine - INFO - Iter(train) [  1050/160000]  lr: 9.9410e-06  eta: 19:27:25  time: 0.4083  data_time: 0.0103  memory: 4848  grad_norm: 115.4643  loss: 66.1970  decode.loss_cls: 3.1393  decode.loss_mask: 0.8788  decode.loss_dice: 2.0814  decode.d0.loss_cls: 7.1154  decode.d0.loss_mask: 0.9665  decode.d0.loss_dice: 2.4675  decode.d1.loss_cls: 3.5576  decode.d1.loss_mask: 0.9885  decode.d1.loss_dice: 2.1994  decode.d2.loss_cls: 3.2661  decode.d2.loss_mask: 0.9018  decode.d2.loss_dice: 2.0606  decode.d3.loss_cls: 3.1088  decode.d3.loss_mask: 0.9455  decode.d3.loss_dice: 2.0252  decode.d4.loss_cls: 3.1360  decode.d4.loss_mask: 0.9269  decode.d4.loss_dice: 2.0880  decode.d5.loss_cls: 3.0955  decode.d5.loss_mask: 0.9029  decode.d5.loss_dice: 2.0654  decode.d6.loss_cls: 3.0693  decode.d6.loss_mask: 0.9335  decode.d6.loss_dice: 2.0840  decode.d7.loss_cls: 3.1312  decode.d7.loss_mask: 0.8813  decode.d7.loss_dice: 2.0336  decode.d8.loss_cls: 3.1707  decode.d8.loss_mask: 0.8887  decode.d8.loss_dice: 2.0877
2023/05/23 18:26:52 - mmengine - INFO - Iter(train) [  1100/160000]  lr: 9.9382e-06  eta: 19:22:51  time: 0.4057  data_time: 0.0094  memory: 4826  grad_norm: 125.4127  loss: 58.5878  decode.loss_cls: 2.7781  decode.loss_mask: 1.0469  decode.loss_dice: 1.5131  decode.d0.loss_cls: 6.7826  decode.d0.loss_mask: 1.0557  decode.d0.loss_dice: 1.8047  decode.d1.loss_cls: 3.1283  decode.d1.loss_mask: 1.0461  decode.d1.loss_dice: 1.5805  decode.d2.loss_cls: 2.9539  decode.d2.loss_mask: 1.0224  decode.d2.loss_dice: 1.5713  decode.d3.loss_cls: 2.8465  decode.d3.loss_mask: 1.0174  decode.d3.loss_dice: 1.5371  decode.d4.loss_cls: 2.8331  decode.d4.loss_mask: 1.0411  decode.d4.loss_dice: 1.5361  decode.d5.loss_cls: 2.8175  decode.d5.loss_mask: 1.0228  decode.d5.loss_dice: 1.5099  decode.d6.loss_cls: 2.7664  decode.d6.loss_mask: 1.0363  decode.d6.loss_dice: 1.5279  decode.d7.loss_cls: 2.7918  decode.d7.loss_mask: 1.0688  decode.d7.loss_dice: 1.5420  decode.d8.loss_cls: 2.7763  decode.d8.loss_mask: 1.1233  decode.d8.loss_dice: 1.5098
2023/05/23 18:27:13 - mmengine - INFO - Iter(train) [  1150/160000]  lr: 9.9353e-06  eta: 19:19:40  time: 0.4116  data_time: 0.0091  memory: 4848  grad_norm: 101.2672  loss: 59.4200  decode.loss_cls: 2.9090  decode.loss_mask: 0.8705  decode.loss_dice: 1.6947  decode.d0.loss_cls: 6.6577  decode.d0.loss_mask: 0.9340  decode.d0.loss_dice: 1.9704  decode.d1.loss_cls: 3.1810  decode.d1.loss_mask: 0.9020  decode.d1.loss_dice: 1.8419  decode.d2.loss_cls: 2.9763  decode.d2.loss_mask: 0.8965  decode.d2.loss_dice: 1.7205  decode.d3.loss_cls: 2.9661  decode.d3.loss_mask: 0.8797  decode.d3.loss_dice: 1.6231  decode.d4.loss_cls: 2.9448  decode.d4.loss_mask: 0.8618  decode.d4.loss_dice: 1.6805  decode.d5.loss_cls: 2.9099  decode.d5.loss_mask: 0.8664  decode.d5.loss_dice: 1.6652  decode.d6.loss_cls: 2.9169  decode.d6.loss_mask: 0.8865  decode.d6.loss_dice: 1.6882  decode.d7.loss_cls: 2.9368  decode.d7.loss_mask: 0.8827  decode.d7.loss_dice: 1.6620  decode.d8.loss_cls: 2.8886  decode.d8.loss_mask: 0.9195  decode.d8.loss_dice: 1.6865
2023/05/23 18:27:35 - mmengine - INFO - Iter(train) [  1200/160000]  lr: 9.9325e-06  eta: 19:19:33  time: 0.4383  data_time: 0.0096  memory: 4829  grad_norm: 111.3643  loss: 62.7065  decode.loss_cls: 2.8728  decode.loss_mask: 1.2310  decode.loss_dice: 1.7783  decode.d0.loss_cls: 6.4695  decode.d0.loss_mask: 1.2443  decode.d0.loss_dice: 2.1410  decode.d1.loss_cls: 3.1136  decode.d1.loss_mask: 1.2065  decode.d1.loss_dice: 1.8742  decode.d2.loss_cls: 2.9076  decode.d2.loss_mask: 1.1513  decode.d2.loss_dice: 1.8206  decode.d3.loss_cls: 2.8619  decode.d3.loss_mask: 1.1703  decode.d3.loss_dice: 1.7809  decode.d4.loss_cls: 2.8277  decode.d4.loss_mask: 1.1504  decode.d4.loss_dice: 1.7734  decode.d5.loss_cls: 2.8275  decode.d5.loss_mask: 1.1847  decode.d5.loss_dice: 1.8020  decode.d6.loss_cls: 2.8253  decode.d6.loss_mask: 1.2198  decode.d6.loss_dice: 1.8002  decode.d7.loss_cls: 2.8555  decode.d7.loss_mask: 1.1569  decode.d7.loss_dice: 1.7872  decode.d8.loss_cls: 2.8602  decode.d8.loss_mask: 1.2148  decode.d8.loss_dice: 1.7970
2023/05/23 18:27:55 - mmengine - INFO - Iter(train) [  1250/160000]  lr: 9.9297e-06  eta: 19:16:54  time: 0.4083  data_time: 0.0099  memory: 4828  grad_norm: 109.5314  loss: 67.0359  decode.loss_cls: 2.9738  decode.loss_mask: 1.3193  decode.loss_dice: 2.0559  decode.d0.loss_cls: 6.4055  decode.d0.loss_mask: 1.2352  decode.d0.loss_dice: 2.3103  decode.d1.loss_cls: 3.3154  decode.d1.loss_mask: 1.2663  decode.d1.loss_dice: 2.0870  decode.d2.loss_cls: 3.0749  decode.d2.loss_mask: 1.2535  decode.d2.loss_dice: 2.0502  decode.d3.loss_cls: 2.9637  decode.d3.loss_mask: 1.2615  decode.d3.loss_dice: 2.0047  decode.d4.loss_cls: 2.9579  decode.d4.loss_mask: 1.2835  decode.d4.loss_dice: 1.9984  decode.d5.loss_cls: 2.9818  decode.d5.loss_mask: 1.2546  decode.d5.loss_dice: 2.0417  decode.d6.loss_cls: 2.9643  decode.d6.loss_mask: 1.2690  decode.d6.loss_dice: 1.9715  decode.d7.loss_cls: 3.0114  decode.d7.loss_mask: 1.3161  decode.d7.loss_dice: 1.9955  decode.d8.loss_cls: 2.9922  decode.d8.loss_mask: 1.3906  decode.d8.loss_dice: 2.0303
2023/05/23 18:28:17 - mmengine - INFO - Iter(train) [  1300/160000]  lr: 9.9269e-06  eta: 19:15:14  time: 0.4503  data_time: 0.0094  memory: 4889  grad_norm: 125.5745  loss: 63.5882  decode.loss_cls: 2.9795  decode.loss_mask: 1.1343  decode.loss_dice: 1.8071  decode.d0.loss_cls: 6.0580  decode.d0.loss_mask: 1.1280  decode.d0.loss_dice: 2.0709  decode.d1.loss_cls: 3.1648  decode.d1.loss_mask: 1.1900  decode.d1.loss_dice: 1.9272  decode.d2.loss_cls: 3.0534  decode.d2.loss_mask: 1.1881  decode.d2.loss_dice: 1.8324  decode.d3.loss_cls: 3.0334  decode.d3.loss_mask: 1.2166  decode.d3.loss_dice: 1.8612  decode.d4.loss_cls: 3.0073  decode.d4.loss_mask: 1.2035  decode.d4.loss_dice: 1.8598  decode.d5.loss_cls: 3.0123  decode.d5.loss_mask: 1.2069  decode.d5.loss_dice: 1.8266  decode.d6.loss_cls: 2.9721  decode.d6.loss_mask: 1.1990  decode.d6.loss_dice: 1.8101  decode.d7.loss_cls: 2.9713  decode.d7.loss_mask: 1.1375  decode.d7.loss_dice: 1.8016  decode.d8.loss_cls: 2.9665  decode.d8.loss_mask: 1.1389  decode.d8.loss_dice: 1.8297
2023/05/23 18:28:37 - mmengine - INFO - Iter(train) [  1350/160000]  lr: 9.9241e-06  eta: 19:11:59  time: 0.4098  data_time: 0.0093  memory: 4845  grad_norm: 104.2253  loss: 62.3532  decode.loss_cls: 2.8558  decode.loss_mask: 1.1366  decode.loss_dice: 1.8174  decode.d0.loss_cls: 6.0354  decode.d0.loss_mask: 1.2145  decode.d0.loss_dice: 2.1581  decode.d1.loss_cls: 3.2213  decode.d1.loss_mask: 1.1379  decode.d1.loss_dice: 1.8857  decode.d2.loss_cls: 2.9503  decode.d2.loss_mask: 1.1092  decode.d2.loss_dice: 1.8187  decode.d3.loss_cls: 2.8732  decode.d3.loss_mask: 1.1516  decode.d3.loss_dice: 1.8157  decode.d4.loss_cls: 2.8091  decode.d4.loss_mask: 1.1968  decode.d4.loss_dice: 1.8375  decode.d5.loss_cls: 2.8509  decode.d5.loss_mask: 1.1942  decode.d5.loss_dice: 1.8375  decode.d6.loss_cls: 2.8648  decode.d6.loss_mask: 1.1764  decode.d6.loss_dice: 1.8467  decode.d7.loss_cls: 2.7943  decode.d7.loss_mask: 1.1614  decode.d7.loss_dice: 1.8385  decode.d8.loss_cls: 2.8092  decode.d8.loss_mask: 1.1407  decode.d8.loss_dice: 1.8139
2023/05/23 18:28:58 - mmengine - INFO - Iter(train) [  1400/160000]  lr: 9.9213e-06  eta: 19:09:26  time: 0.4127  data_time: 0.0093  memory: 4849  grad_norm: 103.8978  loss: 57.7270  decode.loss_cls: 2.5035  decode.loss_mask: 1.0605  decode.loss_dice: 1.8167  decode.d0.loss_cls: 5.5919  decode.d0.loss_mask: 1.1242  decode.d0.loss_dice: 2.0568  decode.d1.loss_cls: 2.8452  decode.d1.loss_mask: 1.0871  decode.d1.loss_dice: 1.8453  decode.d2.loss_cls: 2.6200  decode.d2.loss_mask: 1.0259  decode.d2.loss_dice: 1.8007  decode.d3.loss_cls: 2.5493  decode.d3.loss_mask: 1.0293  decode.d3.loss_dice: 1.7967  decode.d4.loss_cls: 2.5048  decode.d4.loss_mask: 1.0680  decode.d4.loss_dice: 1.8203  decode.d5.loss_cls: 2.5049  decode.d5.loss_mask: 1.0573  decode.d5.loss_dice: 1.8210  decode.d6.loss_cls: 2.5112  decode.d6.loss_mask: 1.0698  decode.d6.loss_dice: 1.8297  decode.d7.loss_cls: 2.5137  decode.d7.loss_mask: 1.0362  decode.d7.loss_dice: 1.8366  decode.d8.loss_cls: 2.4874  decode.d8.loss_mask: 1.0796  decode.d8.loss_dice: 1.8335
2023/05/23 18:29:19 - mmengine - INFO - Iter(train) [  1450/160000]  lr: 9.9185e-06  eta: 19:07:44  time: 0.4123  data_time: 0.0093  memory: 4890  grad_norm: 106.5624  loss: 71.8961  decode.loss_cls: 3.1781  decode.loss_mask: 1.3517  decode.loss_dice: 2.4047  decode.d0.loss_cls: 5.9273  decode.d0.loss_mask: 1.2320  decode.d0.loss_dice: 2.6310  decode.d1.loss_cls: 3.4139  decode.d1.loss_mask: 1.2809  decode.d1.loss_dice: 2.3257  decode.d2.loss_cls: 3.2456  decode.d2.loss_mask: 1.3147  decode.d2.loss_dice: 2.3044  decode.d3.loss_cls: 3.2069  decode.d3.loss_mask: 1.2688  decode.d3.loss_dice: 2.3394  decode.d4.loss_cls: 3.2239  decode.d4.loss_mask: 1.3071  decode.d4.loss_dice: 2.3619  decode.d5.loss_cls: 3.1859  decode.d5.loss_mask: 1.3070  decode.d5.loss_dice: 2.3730  decode.d6.loss_cls: 3.1607  decode.d6.loss_mask: 1.3238  decode.d6.loss_dice: 2.3905  decode.d7.loss_cls: 3.2151  decode.d7.loss_mask: 1.3194  decode.d7.loss_dice: 2.3860  decode.d8.loss_cls: 3.2575  decode.d8.loss_mask: 1.2654  decode.d8.loss_dice: 2.3935
2023/05/23 18:29:40 - mmengine - INFO - Iter(train) [  1500/160000]  lr: 9.9156e-06  eta: 19:06:49  time: 0.4239  data_time: 0.0098  memory: 4796  grad_norm: 99.5242  loss: 56.9502  decode.loss_cls: 2.5434  decode.loss_mask: 0.9266  decode.loss_dice: 1.8673  decode.d0.loss_cls: 5.4061  decode.d0.loss_mask: 0.9320  decode.d0.loss_dice: 2.1343  decode.d1.loss_cls: 2.8669  decode.d1.loss_mask: 0.9335  decode.d1.loss_dice: 1.8416  decode.d2.loss_cls: 2.6990  decode.d2.loss_mask: 0.9229  decode.d2.loss_dice: 1.8494  decode.d3.loss_cls: 2.6650  decode.d3.loss_mask: 0.9140  decode.d3.loss_dice: 1.8142  decode.d4.loss_cls: 2.6535  decode.d4.loss_mask: 0.9173  decode.d4.loss_dice: 1.8428  decode.d5.loss_cls: 2.5950  decode.d5.loss_mask: 0.9429  decode.d5.loss_dice: 1.8606  decode.d6.loss_cls: 2.5604  decode.d6.loss_mask: 0.9188  decode.d6.loss_dice: 1.8735  decode.d7.loss_cls: 2.5198  decode.d7.loss_mask: 0.8999  decode.d7.loss_dice: 1.8291  decode.d8.loss_cls: 2.4358  decode.d8.loss_mask: 0.9504  decode.d8.loss_dice: 1.8344
2023/05/23 18:30:01 - mmengine - INFO - Iter(train) [  1550/160000]  lr: 9.9128e-06  eta: 19:05:22  time: 0.4180  data_time: 0.0095  memory: 4941  grad_norm: 140.8106  loss: 61.9830  decode.loss_cls: 2.9641  decode.loss_mask: 1.0897  decode.loss_dice: 1.8610  decode.d0.loss_cls: 5.5582  decode.d0.loss_mask: 1.1446  decode.d0.loss_dice: 2.2064  decode.d1.loss_cls: 3.2158  decode.d1.loss_mask: 1.1105  decode.d1.loss_dice: 1.9431  decode.d2.loss_cls: 2.9617  decode.d2.loss_mask: 1.0791  decode.d2.loss_dice: 1.8454  decode.d3.loss_cls: 2.8686  decode.d3.loss_mask: 1.0770  decode.d3.loss_dice: 1.8294  decode.d4.loss_cls: 2.9082  decode.d4.loss_mask: 1.0642  decode.d4.loss_dice: 1.8419  decode.d5.loss_cls: 2.8962  decode.d5.loss_mask: 1.0634  decode.d5.loss_dice: 1.8574  decode.d6.loss_cls: 2.8959  decode.d6.loss_mask: 1.1142  decode.d6.loss_dice: 1.8360  decode.d7.loss_cls: 2.9313  decode.d7.loss_mask: 1.0840  decode.d7.loss_dice: 1.8413  decode.d8.loss_cls: 2.9299  decode.d8.loss_mask: 1.0761  decode.d8.loss_dice: 1.8885
2023/05/23 18:30:22 - mmengine - INFO - Iter(train) [  1600/160000]  lr: 9.9100e-06  eta: 19:03:48  time: 0.4197  data_time: 0.0096  memory: 4816  grad_norm: 98.8224  loss: 51.4748  decode.loss_cls: 2.2563  decode.loss_mask: 0.9024  decode.loss_dice: 1.5606  decode.d0.loss_cls: 4.9542  decode.d0.loss_mask: 0.9280  decode.d0.loss_dice: 1.8742  decode.d1.loss_cls: 2.6650  decode.d1.loss_mask: 0.9153  decode.d1.loss_dice: 1.6544  decode.d2.loss_cls: 2.4501  decode.d2.loss_mask: 0.9217  decode.d2.loss_dice: 1.5738  decode.d3.loss_cls: 2.4083  decode.d3.loss_mask: 0.9070  decode.d3.loss_dice: 1.5482  decode.d4.loss_cls: 2.4087  decode.d4.loss_mask: 0.8675  decode.d4.loss_dice: 1.5593  decode.d5.loss_cls: 2.3400  decode.d5.loss_mask: 0.9141  decode.d5.loss_dice: 1.5594  decode.d6.loss_cls: 2.3065  decode.d6.loss_mask: 0.9176  decode.d6.loss_dice: 1.5434  decode.d7.loss_cls: 2.3214  decode.d7.loss_mask: 0.8803  decode.d7.loss_dice: 1.5562  decode.d8.loss_cls: 2.2840  decode.d8.loss_mask: 0.9242  decode.d8.loss_dice: 1.5728
2023/05/23 18:30:44 - mmengine - INFO - Iter(train) [  1650/160000]  lr: 9.9072e-06  eta: 19:03:29  time: 0.4678  data_time: 0.0098  memory: 4843  grad_norm: 140.3565  loss: 48.8170  decode.loss_cls: 2.1158  decode.loss_mask: 1.0232  decode.loss_dice: 1.3706  decode.d0.loss_cls: 4.8473  decode.d0.loss_mask: 1.0849  decode.d0.loss_dice: 1.5801  decode.d1.loss_cls: 2.4773  decode.d1.loss_mask: 1.0020  decode.d1.loss_dice: 1.4588  decode.d2.loss_cls: 2.2717  decode.d2.loss_mask: 1.0051  decode.d2.loss_dice: 1.4179  decode.d3.loss_cls: 2.2353  decode.d3.loss_mask: 0.9846  decode.d3.loss_dice: 1.4046  decode.d4.loss_cls: 2.1674  decode.d4.loss_mask: 0.9916  decode.d4.loss_dice: 1.4046  decode.d5.loss_cls: 2.1437  decode.d5.loss_mask: 1.0244  decode.d5.loss_dice: 1.3858  decode.d6.loss_cls: 2.1302  decode.d6.loss_mask: 1.0100  decode.d6.loss_dice: 1.2916  decode.d7.loss_cls: 2.1056  decode.d7.loss_mask: 1.0173  decode.d7.loss_dice: 1.3516  decode.d8.loss_cls: 2.0811  decode.d8.loss_mask: 1.0452  decode.d8.loss_dice: 1.3877
2023/05/23 18:31:05 - mmengine - INFO - Iter(train) [  1700/160000]  lr: 9.9044e-06  eta: 19:02:08  time: 0.4091  data_time: 0.0094  memory: 4884  grad_norm: 129.3402  loss: 61.6429  decode.loss_cls: 2.7384  decode.loss_mask: 1.0833  decode.loss_dice: 1.9351  decode.d0.loss_cls: 5.2182  decode.d0.loss_mask: 1.1318  decode.d0.loss_dice: 2.2371  decode.d1.loss_cls: 3.1400  decode.d1.loss_mask: 1.1432  decode.d1.loss_dice: 2.0174  decode.d2.loss_cls: 2.8326  decode.d2.loss_mask: 1.1012  decode.d2.loss_dice: 1.9940  decode.d3.loss_cls: 2.7837  decode.d3.loss_mask: 1.1951  decode.d3.loss_dice: 1.9815  decode.d4.loss_cls: 2.7863  decode.d4.loss_mask: 1.1742  decode.d4.loss_dice: 1.9579  decode.d5.loss_cls: 2.8003  decode.d5.loss_mask: 1.1167  decode.d5.loss_dice: 1.9305  decode.d6.loss_cls: 2.7603  decode.d6.loss_mask: 1.1201  decode.d6.loss_dice: 1.9090  decode.d7.loss_cls: 2.7084  decode.d7.loss_mask: 1.1533  decode.d7.loss_dice: 1.9401  decode.d8.loss_cls: 2.7326  decode.d8.loss_mask: 1.0980  decode.d8.loss_dice: 1.9226
2023/05/23 18:31:25 - mmengine - INFO - Iter(train) [  1750/160000]  lr: 9.9016e-06  eta: 19:00:04  time: 0.4185  data_time: 0.0097  memory: 4859  grad_norm: 104.9927  loss: 46.0695  decode.loss_cls: 2.2282  decode.loss_mask: 0.7633  decode.loss_dice: 1.1807  decode.d0.loss_cls: 4.6054  decode.d0.loss_mask: 0.8430  decode.d0.loss_dice: 1.4114  decode.d1.loss_cls: 2.6225  decode.d1.loss_mask: 0.7846  decode.d1.loss_dice: 1.2932  decode.d2.loss_cls: 2.4873  decode.d2.loss_mask: 0.7425  decode.d2.loss_dice: 1.2582  decode.d3.loss_cls: 2.4254  decode.d3.loss_mask: 0.7599  decode.d3.loss_dice: 1.2159  decode.d4.loss_cls: 2.4401  decode.d4.loss_mask: 0.7379  decode.d4.loss_dice: 1.2254  decode.d5.loss_cls: 2.3610  decode.d5.loss_mask: 0.7678  decode.d5.loss_dice: 1.1992  decode.d6.loss_cls: 2.2721  decode.d6.loss_mask: 0.7687  decode.d6.loss_dice: 1.2646  decode.d7.loss_cls: 2.2389  decode.d7.loss_mask: 0.7598  decode.d7.loss_dice: 1.2001  decode.d8.loss_cls: 2.2389  decode.d8.loss_mask: 0.7552  decode.d8.loss_dice: 1.2184
2023/05/23 18:31:46 - mmengine - INFO - Iter(train) [  1800/160000]  lr: 9.8987e-06  eta: 18:58:34  time: 0.4546  data_time: 0.0099  memory: 4911  grad_norm: 101.5250  loss: 46.2181  decode.loss_cls: 2.3655  decode.loss_mask: 0.7492  decode.loss_dice: 1.1929  decode.d0.loss_cls: 4.6049  decode.d0.loss_mask: 0.7311  decode.d0.loss_dice: 1.3815  decode.d1.loss_cls: 2.6516  decode.d1.loss_mask: 0.7371  decode.d1.loss_dice: 1.2665  decode.d2.loss_cls: 2.5083  decode.d2.loss_mask: 0.6937  decode.d2.loss_dice: 1.2017  decode.d3.loss_cls: 2.4137  decode.d3.loss_mask: 0.7337  decode.d3.loss_dice: 1.2322  decode.d4.loss_cls: 2.3464  decode.d4.loss_mask: 0.7494  decode.d4.loss_dice: 1.2197  decode.d5.loss_cls: 2.3405  decode.d5.loss_mask: 0.7481  decode.d5.loss_dice: 1.2550  decode.d6.loss_cls: 2.3979  decode.d6.loss_mask: 0.7728  decode.d6.loss_dice: 1.2367  decode.d7.loss_cls: 2.3461  decode.d7.loss_mask: 0.7725  decode.d7.loss_dice: 1.2463  decode.d8.loss_cls: 2.3500  decode.d8.loss_mask: 0.7363  decode.d8.loss_dice: 1.2370
2023/05/23 18:32:08 - mmengine - INFO - Iter(train) [  1850/160000]  lr: 9.8959e-06  eta: 18:58:41  time: 0.4077  data_time: 0.0097  memory: 4915  grad_norm: 108.8035  loss: 62.3497  decode.loss_cls: 2.8387  decode.loss_mask: 1.0469  decode.loss_dice: 2.0458  decode.d0.loss_cls: 5.1142  decode.d0.loss_mask: 1.0672  decode.d0.loss_dice: 2.3434  decode.d1.loss_cls: 3.1083  decode.d1.loss_mask: 1.0795  decode.d1.loss_dice: 2.0895  decode.d2.loss_cls: 2.9224  decode.d2.loss_mask: 1.0454  decode.d2.loss_dice: 2.0622  decode.d3.loss_cls: 2.8812  decode.d3.loss_mask: 1.0926  decode.d3.loss_dice: 1.9994  decode.d4.loss_cls: 2.8458  decode.d4.loss_mask: 1.0370  decode.d4.loss_dice: 2.0724  decode.d5.loss_cls: 2.8279  decode.d5.loss_mask: 1.0638  decode.d5.loss_dice: 2.0137  decode.d6.loss_cls: 2.8533  decode.d6.loss_mask: 1.0429  decode.d6.loss_dice: 1.9757  decode.d7.loss_cls: 2.8699  decode.d7.loss_mask: 1.0513  decode.d7.loss_dice: 2.0159  decode.d8.loss_cls: 2.8538  decode.d8.loss_mask: 1.0536  decode.d8.loss_dice: 2.0359
2023/05/23 18:32:31 - mmengine - INFO - Iter(train) [  1900/160000]  lr: 9.8931e-06  eta: 18:59:39  time: 0.4602  data_time: 0.0094  memory: 4878  grad_norm: 205.6569  loss: 56.9162  decode.loss_cls: 2.6647  decode.loss_mask: 0.9658  decode.loss_dice: 1.7746  decode.d0.loss_cls: 4.8365  decode.d0.loss_mask: 1.0272  decode.d0.loss_dice: 2.0288  decode.d1.loss_cls: 2.9251  decode.d1.loss_mask: 0.9858  decode.d1.loss_dice: 1.8509  decode.d2.loss_cls: 2.7248  decode.d2.loss_mask: 0.9426  decode.d2.loss_dice: 1.7619  decode.d3.loss_cls: 2.7201  decode.d3.loss_mask: 0.9242  decode.d3.loss_dice: 1.7633  decode.d4.loss_cls: 2.6418  decode.d4.loss_mask: 0.9332  decode.d4.loss_dice: 1.7517  decode.d5.loss_cls: 2.6615  decode.d5.loss_mask: 0.9384  decode.d5.loss_dice: 1.7538  decode.d6.loss_cls: 2.7276  decode.d6.loss_mask: 0.9839  decode.d6.loss_dice: 1.7450  decode.d7.loss_cls: 2.6651  decode.d7.loss_mask: 0.9934  decode.d7.loss_dice: 1.7884  decode.d8.loss_cls: 2.6157  decode.d8.loss_mask: 1.0045  decode.d8.loss_dice: 1.8159
2023/05/23 18:32:51 - mmengine - INFO - Iter(train) [  1950/160000]  lr: 9.8903e-06  eta: 18:58:08  time: 0.4103  data_time: 0.0100  memory: 4865  grad_norm: 106.5380  loss: 49.8343  decode.loss_cls: 2.1240  decode.loss_mask: 0.8807  decode.loss_dice: 1.6554  decode.d0.loss_cls: 4.3254  decode.d0.loss_mask: 0.8733  decode.d0.loss_dice: 1.8435  decode.d1.loss_cls: 2.4596  decode.d1.loss_mask: 0.9268  decode.d1.loss_dice: 1.6855  decode.d2.loss_cls: 2.2542  decode.d2.loss_mask: 0.8829  decode.d2.loss_dice: 1.6656  decode.d3.loss_cls: 2.2721  decode.d3.loss_mask: 0.8421  decode.d3.loss_dice: 1.5922  decode.d4.loss_cls: 2.2122  decode.d4.loss_mask: 0.8450  decode.d4.loss_dice: 1.6318  decode.d5.loss_cls: 2.2696  decode.d5.loss_mask: 0.8347  decode.d5.loss_dice: 1.6599  decode.d6.loss_cls: 2.2938  decode.d6.loss_mask: 0.8260  decode.d6.loss_dice: 1.6296  decode.d7.loss_cls: 2.1582  decode.d7.loss_mask: 0.8453  decode.d7.loss_dice: 1.6156  decode.d8.loss_cls: 2.2006  decode.d8.loss_mask: 0.8837  decode.d8.loss_dice: 1.6452
2023/05/23 18:33:12 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 18:33:12 - mmengine - INFO - Iter(train) [  2000/160000]  lr: 9.8875e-06  eta: 18:56:48  time: 0.4130  data_time: 0.0097  memory: 4859  grad_norm: 123.5133  loss: 56.4054  decode.loss_cls: 2.4579  decode.loss_mask: 1.0335  decode.loss_dice: 1.8080  decode.d0.loss_cls: 4.6083  decode.d0.loss_mask: 1.0215  decode.d0.loss_dice: 2.0628  decode.d1.loss_cls: 3.0107  decode.d1.loss_mask: 1.0022  decode.d1.loss_dice: 1.8823  decode.d2.loss_cls: 2.7297  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 1.8031  decode.d3.loss_cls: 2.5469  decode.d3.loss_mask: 1.0357  decode.d3.loss_dice: 1.8288  decode.d4.loss_cls: 2.5385  decode.d4.loss_mask: 0.9736  decode.d4.loss_dice: 1.7995  decode.d5.loss_cls: 2.5754  decode.d5.loss_mask: 0.9989  decode.d5.loss_dice: 1.7977  decode.d6.loss_cls: 2.5265  decode.d6.loss_mask: 1.0082  decode.d6.loss_dice: 1.7760  decode.d7.loss_cls: 2.5091  decode.d7.loss_mask: 0.9891  decode.d7.loss_dice: 1.7693  decode.d8.loss_cls: 2.5113  decode.d8.loss_mask: 1.0320  decode.d8.loss_dice: 1.7979
2023/05/23 18:33:12 - mmengine - INFO - Saving checkpoint at 2000 iterations
2023/05/23 18:33:40 - mmengine - INFO - Iter(train) [  2050/160000]  lr: 9.8847e-06  eta: 19:04:58  time: 0.4682  data_time: 0.0099  memory: 4788  grad_norm: 129.1677  loss: 49.1510  decode.loss_cls: 2.3703  decode.loss_mask: 0.8212  decode.loss_dice: 1.4791  decode.d0.loss_cls: 4.4075  decode.d0.loss_mask: 0.8378  decode.d0.loss_dice: 1.7166  decode.d1.loss_cls: 2.7353  decode.d1.loss_mask: 0.8402  decode.d1.loss_dice: 1.5428  decode.d2.loss_cls: 2.5090  decode.d2.loss_mask: 0.7955  decode.d2.loss_dice: 1.4774  decode.d3.loss_cls: 2.4023  decode.d3.loss_mask: 0.7963  decode.d3.loss_dice: 1.4490  decode.d4.loss_cls: 2.3522  decode.d4.loss_mask: 0.7840  decode.d4.loss_dice: 1.4511  decode.d5.loss_cls: 2.3362  decode.d5.loss_mask: 0.7962  decode.d5.loss_dice: 1.4575  decode.d6.loss_cls: 2.2985  decode.d6.loss_mask: 0.7955  decode.d6.loss_dice: 1.4809  decode.d7.loss_cls: 2.3050  decode.d7.loss_mask: 0.7986  decode.d7.loss_dice: 1.4734  decode.d8.loss_cls: 2.2947  decode.d8.loss_mask: 0.8504  decode.d8.loss_dice: 1.4966
2023/05/23 18:34:01 - mmengine - INFO - Iter(train) [  2100/160000]  lr: 9.8819e-06  eta: 19:03:16  time: 0.4034  data_time: 0.0096  memory: 4820  grad_norm: 98.7985  loss: 55.0134  decode.loss_cls: 2.1904  decode.loss_mask: 1.1010  decode.loss_dice: 1.9050  decode.d0.loss_cls: 4.5006  decode.d0.loss_mask: 1.0947  decode.d0.loss_dice: 2.1228  decode.d1.loss_cls: 2.5767  decode.d1.loss_mask: 1.1119  decode.d1.loss_dice: 1.9424  decode.d2.loss_cls: 2.3383  decode.d2.loss_mask: 1.0569  decode.d2.loss_dice: 1.8534  decode.d3.loss_cls: 2.3040  decode.d3.loss_mask: 1.0492  decode.d3.loss_dice: 1.8554  decode.d4.loss_cls: 2.2417  decode.d4.loss_mask: 1.0497  decode.d4.loss_dice: 1.8531  decode.d5.loss_cls: 2.2533  decode.d5.loss_mask: 1.0633  decode.d5.loss_dice: 1.8670  decode.d6.loss_cls: 2.2749  decode.d6.loss_mask: 1.0721  decode.d6.loss_dice: 1.9042  decode.d7.loss_cls: 2.2476  decode.d7.loss_mask: 1.0696  decode.d7.loss_dice: 1.9385  decode.d8.loss_cls: 2.2196  decode.d8.loss_mask: 1.0718  decode.d8.loss_dice: 1.8846
2023/05/23 18:34:22 - mmengine - INFO - Iter(train) [  2150/160000]  lr: 9.8790e-06  eta: 19:02:21  time: 0.4101  data_time: 0.0121  memory: 4836  grad_norm: 97.3004  loss: 52.3629  decode.loss_cls: 2.3590  decode.loss_mask: 0.8254  decode.loss_dice: 1.8448  decode.d0.loss_cls: 4.3703  decode.d0.loss_mask: 0.8251  decode.d0.loss_dice: 1.9610  decode.d1.loss_cls: 2.5556  decode.d1.loss_mask: 0.8287  decode.d1.loss_dice: 1.8211  decode.d2.loss_cls: 2.4576  decode.d2.loss_mask: 0.8215  decode.d2.loss_dice: 1.7952  decode.d3.loss_cls: 2.3973  decode.d3.loss_mask: 0.8263  decode.d3.loss_dice: 1.7865  decode.d4.loss_cls: 2.4111  decode.d4.loss_mask: 0.8106  decode.d4.loss_dice: 1.8145  decode.d5.loss_cls: 2.3735  decode.d5.loss_mask: 0.8307  decode.d5.loss_dice: 1.7735  decode.d6.loss_cls: 2.3660  decode.d6.loss_mask: 0.8181  decode.d6.loss_dice: 1.8004  decode.d7.loss_cls: 2.2958  decode.d7.loss_mask: 0.8230  decode.d7.loss_dice: 1.7979  decode.d8.loss_cls: 2.3278  decode.d8.loss_mask: 0.8129  decode.d8.loss_dice: 1.8319
2023/05/23 18:34:43 - mmengine - INFO - Iter(train) [  2200/160000]  lr: 9.8762e-06  eta: 19:00:42  time: 0.4063  data_time: 0.0097  memory: 4836  grad_norm: 108.4763  loss: 54.7724  decode.loss_cls: 2.4300  decode.loss_mask: 1.0859  decode.loss_dice: 1.6006  decode.d0.loss_cls: 4.8155  decode.d0.loss_mask: 1.0575  decode.d0.loss_dice: 1.8500  decode.d1.loss_cls: 2.8285  decode.d1.loss_mask: 1.0927  decode.d1.loss_dice: 1.7083  decode.d2.loss_cls: 2.5496  decode.d2.loss_mask: 1.2172  decode.d2.loss_dice: 1.6217  decode.d3.loss_cls: 2.4210  decode.d3.loss_mask: 1.1741  decode.d3.loss_dice: 1.6383  decode.d4.loss_cls: 2.3876  decode.d4.loss_mask: 1.1230  decode.d4.loss_dice: 1.6235  decode.d5.loss_cls: 2.3680  decode.d5.loss_mask: 1.1445  decode.d5.loss_dice: 1.6253  decode.d6.loss_cls: 2.3769  decode.d6.loss_mask: 1.1579  decode.d6.loss_dice: 1.6336  decode.d7.loss_cls: 2.4010  decode.d7.loss_mask: 1.1279  decode.d7.loss_dice: 1.6121  decode.d8.loss_cls: 2.3958  decode.d8.loss_mask: 1.0986  decode.d8.loss_dice: 1.6058
2023/05/23 18:35:06 - mmengine - INFO - Iter(train) [  2250/160000]  lr: 9.8734e-06  eta: 19:01:30  time: 0.4748  data_time: 0.0093  memory: 4794  grad_norm: 116.2742  loss: 47.8131  decode.loss_cls: 2.1191  decode.loss_mask: 0.8783  decode.loss_dice: 1.4580  decode.d0.loss_cls: 4.2073  decode.d0.loss_mask: 0.9995  decode.d0.loss_dice: 1.7467  decode.d1.loss_cls: 2.4679  decode.d1.loss_mask: 0.9122  decode.d1.loss_dice: 1.4934  decode.d2.loss_cls: 2.3640  decode.d2.loss_mask: 0.8905  decode.d2.loss_dice: 1.4467  decode.d3.loss_cls: 2.2115  decode.d3.loss_mask: 0.9120  decode.d3.loss_dice: 1.4020  decode.d4.loss_cls: 2.1466  decode.d4.loss_mask: 0.8586  decode.d4.loss_dice: 1.4423  decode.d5.loss_cls: 2.1684  decode.d5.loss_mask: 0.8692  decode.d5.loss_dice: 1.4058  decode.d6.loss_cls: 2.1949  decode.d6.loss_mask: 0.8776  decode.d6.loss_dice: 1.4137  decode.d7.loss_cls: 2.1416  decode.d7.loss_mask: 0.8980  decode.d7.loss_dice: 1.4182  decode.d8.loss_cls: 2.1550  decode.d8.loss_mask: 0.8940  decode.d8.loss_dice: 1.4203
2023/05/23 18:35:29 - mmengine - INFO - Iter(train) [  2300/160000]  lr: 9.8706e-06  eta: 19:02:55  time: 0.4670  data_time: 0.0095  memory: 4867  grad_norm: 131.7498  loss: 45.1791  decode.loss_cls: 2.1502  decode.loss_mask: 0.7112  decode.loss_dice: 1.3554  decode.d0.loss_cls: 4.1032  decode.d0.loss_mask: 0.7525  decode.d0.loss_dice: 1.5287  decode.d1.loss_cls: 2.4504  decode.d1.loss_mask: 0.7648  decode.d1.loss_dice: 1.4091  decode.d2.loss_cls: 2.2446  decode.d2.loss_mask: 0.7552  decode.d2.loss_dice: 1.3937  decode.d3.loss_cls: 2.1927  decode.d3.loss_mask: 0.7178  decode.d3.loss_dice: 1.3428  decode.d4.loss_cls: 2.2054  decode.d4.loss_mask: 0.6814  decode.d4.loss_dice: 1.3249  decode.d5.loss_cls: 2.1981  decode.d5.loss_mask: 0.7157  decode.d5.loss_dice: 1.3456  decode.d6.loss_cls: 2.2465  decode.d6.loss_mask: 0.7074  decode.d6.loss_dice: 1.3408  decode.d7.loss_cls: 2.1434  decode.d7.loss_mask: 0.7646  decode.d7.loss_dice: 1.3527  decode.d8.loss_cls: 2.1854  decode.d8.loss_mask: 0.7307  decode.d8.loss_dice: 1.3639
2023/05/23 18:35:51 - mmengine - INFO - Iter(train) [  2350/160000]  lr: 9.8678e-06  eta: 19:03:12  time: 0.4681  data_time: 0.0091  memory: 4849  grad_norm: 125.0285  loss: 41.4762  decode.loss_cls: 1.8619  decode.loss_mask: 0.8581  decode.loss_dice: 1.1096  decode.d0.loss_cls: 3.8291  decode.d0.loss_mask: 0.8777  decode.d0.loss_dice: 1.3134  decode.d1.loss_cls: 2.2499  decode.d1.loss_mask: 0.8470  decode.d1.loss_dice: 1.1899  decode.d2.loss_cls: 2.0322  decode.d2.loss_mask: 0.8530  decode.d2.loss_dice: 1.1149  decode.d3.loss_cls: 1.9953  decode.d3.loss_mask: 0.8385  decode.d3.loss_dice: 1.0680  decode.d4.loss_cls: 1.9502  decode.d4.loss_mask: 0.8652  decode.d4.loss_dice: 1.0908  decode.d5.loss_cls: 1.8955  decode.d5.loss_mask: 0.8657  decode.d5.loss_dice: 1.1166  decode.d6.loss_cls: 1.8846  decode.d6.loss_mask: 0.8806  decode.d6.loss_dice: 1.1305  decode.d7.loss_cls: 1.9113  decode.d7.loss_mask: 0.8502  decode.d7.loss_dice: 1.1218  decode.d8.loss_cls: 1.8906  decode.d8.loss_mask: 0.8544  decode.d8.loss_dice: 1.1297
2023/05/23 18:36:13 - mmengine - INFO - Iter(train) [  2400/160000]  lr: 9.8650e-06  eta: 19:02:33  time: 0.4093  data_time: 0.0094  memory: 4825  grad_norm: 112.5807  loss: 52.6528  decode.loss_cls: 2.2654  decode.loss_mask: 1.0198  decode.loss_dice: 1.6669  decode.d0.loss_cls: 4.3419  decode.d0.loss_mask: 1.0638  decode.d0.loss_dice: 2.0044  decode.d1.loss_cls: 2.6231  decode.d1.loss_mask: 1.0631  decode.d1.loss_dice: 1.8013  decode.d2.loss_cls: 2.3604  decode.d2.loss_mask: 1.0997  decode.d2.loss_dice: 1.6872  decode.d3.loss_cls: 2.2637  decode.d3.loss_mask: 1.0007  decode.d3.loss_dice: 1.6706  decode.d4.loss_cls: 2.2336  decode.d4.loss_mask: 1.0434  decode.d4.loss_dice: 1.7000  decode.d5.loss_cls: 2.2214  decode.d5.loss_mask: 1.0400  decode.d5.loss_dice: 1.6837  decode.d6.loss_cls: 2.1972  decode.d6.loss_mask: 1.0569  decode.d6.loss_dice: 1.6763  decode.d7.loss_cls: 2.2138  decode.d7.loss_mask: 1.0443  decode.d7.loss_dice: 1.6877  decode.d8.loss_cls: 2.2649  decode.d8.loss_mask: 0.9906  decode.d8.loss_dice: 1.6668
2023/05/23 18:36:33 - mmengine - INFO - Iter(train) [  2450/160000]  lr: 9.8621e-06  eta: 19:00:45  time: 0.4028  data_time: 0.0094  memory: 4816  grad_norm: 264.2378  loss: 51.9849  decode.loss_cls: 2.0750  decode.loss_mask: 1.0985  decode.loss_dice: 1.7512  decode.d0.loss_cls: 4.2395  decode.d0.loss_mask: 1.0647  decode.d0.loss_dice: 1.9276  decode.d1.loss_cls: 2.3814  decode.d1.loss_mask: 1.0259  decode.d1.loss_dice: 1.8363  decode.d2.loss_cls: 2.2233  decode.d2.loss_mask: 1.1044  decode.d2.loss_dice: 1.7430  decode.d3.loss_cls: 2.1329  decode.d3.loss_mask: 1.0778  decode.d3.loss_dice: 1.7391  decode.d4.loss_cls: 2.1337  decode.d4.loss_mask: 1.0596  decode.d4.loss_dice: 1.7656  decode.d5.loss_cls: 2.1255  decode.d5.loss_mask: 1.0452  decode.d5.loss_dice: 1.7882  decode.d6.loss_cls: 2.0988  decode.d6.loss_mask: 1.0237  decode.d6.loss_dice: 1.7510  decode.d7.loss_cls: 2.1639  decode.d7.loss_mask: 0.9907  decode.d7.loss_dice: 1.7375  decode.d8.loss_cls: 2.0837  decode.d8.loss_mask: 1.0591  decode.d8.loss_dice: 1.7383
2023/05/23 18:36:53 - mmengine - INFO - Iter(train) [  2500/160000]  lr: 9.8593e-06  eta: 18:58:46  time: 0.4069  data_time: 0.0093  memory: 4858  grad_norm: 98.7278  loss: 53.2962  decode.loss_cls: 2.3655  decode.loss_mask: 1.1503  decode.loss_dice: 1.5757  decode.d0.loss_cls: 4.3023  decode.d0.loss_mask: 1.1381  decode.d0.loss_dice: 1.8156  decode.d1.loss_cls: 2.5660  decode.d1.loss_mask: 1.1642  decode.d1.loss_dice: 1.6746  decode.d2.loss_cls: 2.3952  decode.d2.loss_mask: 1.0983  decode.d2.loss_dice: 1.5784  decode.d3.loss_cls: 2.3887  decode.d3.loss_mask: 1.0940  decode.d3.loss_dice: 1.5449  decode.d4.loss_cls: 2.4218  decode.d4.loss_mask: 1.0744  decode.d4.loss_dice: 1.5539  decode.d5.loss_cls: 2.3981  decode.d5.loss_mask: 1.1014  decode.d5.loss_dice: 1.6030  decode.d6.loss_cls: 2.3965  decode.d6.loss_mask: 1.0798  decode.d6.loss_dice: 1.5659  decode.d7.loss_cls: 2.4103  decode.d7.loss_mask: 1.1080  decode.d7.loss_dice: 1.6014  decode.d8.loss_cls: 2.3644  decode.d8.loss_mask: 1.1359  decode.d8.loss_dice: 1.6295
2023/05/23 18:37:14 - mmengine - INFO - Iter(train) [  2550/160000]  lr: 9.8565e-06  eta: 18:57:16  time: 0.4026  data_time: 0.0097  memory: 4839  grad_norm: 100.0870  loss: 52.6182  decode.loss_cls: 2.2729  decode.loss_mask: 0.9889  decode.loss_dice: 1.7567  decode.d0.loss_cls: 4.1938  decode.d0.loss_mask: 1.0356  decode.d0.loss_dice: 1.8717  decode.d1.loss_cls: 2.6095  decode.d1.loss_mask: 0.9691  decode.d1.loss_dice: 1.6730  decode.d2.loss_cls: 2.4053  decode.d2.loss_mask: 0.9802  decode.d2.loss_dice: 1.6513  decode.d3.loss_cls: 2.2959  decode.d3.loss_mask: 0.9724  decode.d3.loss_dice: 1.6786  decode.d4.loss_cls: 2.2568  decode.d4.loss_mask: 1.0212  decode.d4.loss_dice: 1.7244  decode.d5.loss_cls: 2.3207  decode.d5.loss_mask: 1.0220  decode.d5.loss_dice: 1.7384  decode.d6.loss_cls: 2.3667  decode.d6.loss_mask: 1.0563  decode.d6.loss_dice: 1.7288  decode.d7.loss_cls: 2.2662  decode.d7.loss_mask: 1.0368  decode.d7.loss_dice: 1.7308  decode.d8.loss_cls: 2.2127  decode.d8.loss_mask: 1.0351  decode.d8.loss_dice: 1.7461
2023/05/23 18:37:35 - mmengine - INFO - Iter(train) [  2600/160000]  lr: 9.8537e-06  eta: 18:56:19  time: 0.4132  data_time: 0.0096  memory: 4856  grad_norm: 102.9910  loss: 54.1358  decode.loss_cls: 2.3882  decode.loss_mask: 0.9792  decode.loss_dice: 1.6899  decode.d0.loss_cls: 4.4063  decode.d0.loss_mask: 1.0175  decode.d0.loss_dice: 2.0107  decode.d1.loss_cls: 2.7777  decode.d1.loss_mask: 1.0447  decode.d1.loss_dice: 1.7989  decode.d2.loss_cls: 2.5627  decode.d2.loss_mask: 1.0259  decode.d2.loss_dice: 1.7868  decode.d3.loss_cls: 2.4902  decode.d3.loss_mask: 0.9644  decode.d3.loss_dice: 1.7113  decode.d4.loss_cls: 2.4428  decode.d4.loss_mask: 0.9653  decode.d4.loss_dice: 1.7353  decode.d5.loss_cls: 2.4279  decode.d5.loss_mask: 0.9454  decode.d5.loss_dice: 1.7402  decode.d6.loss_cls: 2.4691  decode.d6.loss_mask: 0.9308  decode.d6.loss_dice: 1.6937  decode.d7.loss_cls: 2.4206  decode.d7.loss_mask: 0.9241  decode.d7.loss_dice: 1.7012  decode.d8.loss_cls: 2.4112  decode.d8.loss_mask: 0.9729  decode.d8.loss_dice: 1.7010
2023/05/23 18:37:55 - mmengine - INFO - Iter(train) [  2650/160000]  lr: 9.8509e-06  eta: 18:54:37  time: 0.4021  data_time: 0.0095  memory: 4839  grad_norm: 91.1993  loss: 46.6136  decode.loss_cls: 2.0722  decode.loss_mask: 0.9635  decode.loss_dice: 1.3092  decode.d0.loss_cls: 4.1432  decode.d0.loss_mask: 0.9469  decode.d0.loss_dice: 1.5570  decode.d1.loss_cls: 2.3368  decode.d1.loss_mask: 1.0324  decode.d1.loss_dice: 1.4200  decode.d2.loss_cls: 2.2193  decode.d2.loss_mask: 0.9513  decode.d2.loss_dice: 1.3458  decode.d3.loss_cls: 2.1581  decode.d3.loss_mask: 0.9611  decode.d3.loss_dice: 1.3407  decode.d4.loss_cls: 2.1253  decode.d4.loss_mask: 0.9357  decode.d4.loss_dice: 1.3420  decode.d5.loss_cls: 2.0524  decode.d5.loss_mask: 0.9465  decode.d5.loss_dice: 1.3400  decode.d6.loss_cls: 2.0866  decode.d6.loss_mask: 0.9155  decode.d6.loss_dice: 1.3782  decode.d7.loss_cls: 2.0379  decode.d7.loss_mask: 0.9610  decode.d7.loss_dice: 1.3743  decode.d8.loss_cls: 2.0593  decode.d8.loss_mask: 0.9655  decode.d8.loss_dice: 1.3360
2023/05/23 18:38:16 - mmengine - INFO - Iter(train) [  2700/160000]  lr: 9.8481e-06  eta: 18:53:36  time: 0.4165  data_time: 0.0099  memory: 4817  grad_norm: 190.2442  loss: 36.7125  decode.loss_cls: 1.6552  decode.loss_mask: 0.8149  decode.loss_dice: 0.9769  decode.d0.loss_cls: 3.3437  decode.d0.loss_mask: 0.8490  decode.d0.loss_dice: 1.0968  decode.d1.loss_cls: 1.8331  decode.d1.loss_mask: 0.8357  decode.d1.loss_dice: 1.0660  decode.d2.loss_cls: 1.7499  decode.d2.loss_mask: 0.7864  decode.d2.loss_dice: 1.0009  decode.d3.loss_cls: 1.7775  decode.d3.loss_mask: 0.7824  decode.d3.loss_dice: 0.9953  decode.d4.loss_cls: 1.6901  decode.d4.loss_mask: 0.7618  decode.d4.loss_dice: 0.9501  decode.d5.loss_cls: 1.6949  decode.d5.loss_mask: 0.7793  decode.d5.loss_dice: 0.9374  decode.d6.loss_cls: 1.7119  decode.d6.loss_mask: 0.7879  decode.d6.loss_dice: 0.9472  decode.d7.loss_cls: 1.6462  decode.d7.loss_mask: 0.7584  decode.d7.loss_dice: 0.9620  decode.d8.loss_cls: 1.7068  decode.d8.loss_mask: 0.8011  decode.d8.loss_dice: 1.0138
2023/05/23 18:38:38 - mmengine - INFO - Iter(train) [  2750/160000]  lr: 9.8452e-06  eta: 18:53:23  time: 0.4630  data_time: 0.0100  memory: 4891  grad_norm: 102.1947  loss: 49.3047  decode.loss_cls: 2.2133  decode.loss_mask: 0.8595  decode.loss_dice: 1.5482  decode.d0.loss_cls: 4.3003  decode.d0.loss_mask: 0.9295  decode.d0.loss_dice: 1.8523  decode.d1.loss_cls: 2.6101  decode.d1.loss_mask: 0.8600  decode.d1.loss_dice: 1.5967  decode.d2.loss_cls: 2.2519  decode.d2.loss_mask: 0.8690  decode.d2.loss_dice: 1.5702  decode.d3.loss_cls: 2.2175  decode.d3.loss_mask: 0.8643  decode.d3.loss_dice: 1.5478  decode.d4.loss_cls: 2.2184  decode.d4.loss_mask: 0.8778  decode.d4.loss_dice: 1.5321  decode.d5.loss_cls: 2.2514  decode.d5.loss_mask: 0.8700  decode.d5.loss_dice: 1.5181  decode.d6.loss_cls: 2.2512  decode.d6.loss_mask: 0.8841  decode.d6.loss_dice: 1.5056  decode.d7.loss_cls: 2.2378  decode.d7.loss_mask: 0.8906  decode.d7.loss_dice: 1.5399  decode.d8.loss_cls: 2.2405  decode.d8.loss_mask: 0.8630  decode.d8.loss_dice: 1.5340
2023/05/23 18:39:01 - mmengine - INFO - Iter(train) [  2800/160000]  lr: 9.8424e-06  eta: 18:54:17  time: 0.4651  data_time: 0.0093  memory: 4866  grad_norm: 123.5225  loss: 57.8199  decode.loss_cls: 2.4746  decode.loss_mask: 1.0685  decode.loss_dice: 1.9889  decode.d0.loss_cls: 4.5887  decode.d0.loss_mask: 1.0435  decode.d0.loss_dice: 2.2641  decode.d1.loss_cls: 2.6611  decode.d1.loss_mask: 1.0048  decode.d1.loss_dice: 2.1192  decode.d2.loss_cls: 2.5032  decode.d2.loss_mask: 1.0244  decode.d2.loss_dice: 2.0155  decode.d3.loss_cls: 2.5723  decode.d3.loss_mask: 1.0212  decode.d3.loss_dice: 2.0152  decode.d4.loss_cls: 2.4604  decode.d4.loss_mask: 1.0268  decode.d4.loss_dice: 2.0163  decode.d5.loss_cls: 2.4532  decode.d5.loss_mask: 1.0163  decode.d5.loss_dice: 2.0317  decode.d6.loss_cls: 2.4481  decode.d6.loss_mask: 1.0436  decode.d6.loss_dice: 2.0240  decode.d7.loss_cls: 2.4705  decode.d7.loss_mask: 0.9880  decode.d7.loss_dice: 1.9775  decode.d8.loss_cls: 2.4776  decode.d8.loss_mask: 1.0085  decode.d8.loss_dice: 2.0122
2023/05/23 18:39:24 - mmengine - INFO - Iter(train) [  2850/160000]  lr: 9.8396e-06  eta: 18:55:28  time: 0.4730  data_time: 0.0098  memory: 4840  grad_norm: 118.0669  loss: 43.1202  decode.loss_cls: 1.9450  decode.loss_mask: 0.8461  decode.loss_dice: 1.3508  decode.d0.loss_cls: 3.7200  decode.d0.loss_mask: 0.8577  decode.d0.loss_dice: 1.5221  decode.d1.loss_cls: 2.0905  decode.d1.loss_mask: 0.8490  decode.d1.loss_dice: 1.4050  decode.d2.loss_cls: 1.9926  decode.d2.loss_mask: 0.7971  decode.d2.loss_dice: 1.3251  decode.d3.loss_cls: 1.9688  decode.d3.loss_mask: 0.7779  decode.d3.loss_dice: 1.3206  decode.d4.loss_cls: 1.9333  decode.d4.loss_mask: 0.8168  decode.d4.loss_dice: 1.3130  decode.d5.loss_cls: 1.9366  decode.d5.loss_mask: 0.8150  decode.d5.loss_dice: 1.3004  decode.d6.loss_cls: 1.9459  decode.d6.loss_mask: 0.8356  decode.d6.loss_dice: 1.2499  decode.d7.loss_cls: 1.9601  decode.d7.loss_mask: 0.8484  decode.d7.loss_dice: 1.2983  decode.d8.loss_cls: 1.9599  decode.d8.loss_mask: 0.8169  decode.d8.loss_dice: 1.3217
2023/05/23 18:39:46 - mmengine - INFO - Iter(train) [  2900/160000]  lr: 9.8368e-06  eta: 18:55:27  time: 0.4103  data_time: 0.0098  memory: 4877  grad_norm: 114.5478  loss: 56.9681  decode.loss_cls: 2.4149  decode.loss_mask: 1.1124  decode.loss_dice: 2.0341  decode.d0.loss_cls: 4.2366  decode.d0.loss_mask: 1.1267  decode.d0.loss_dice: 2.2986  decode.d1.loss_cls: 2.5257  decode.d1.loss_mask: 1.0497  decode.d1.loss_dice: 2.0941  decode.d2.loss_cls: 2.4130  decode.d2.loss_mask: 1.0524  decode.d2.loss_dice: 2.0006  decode.d3.loss_cls: 2.3906  decode.d3.loss_mask: 1.0675  decode.d3.loss_dice: 2.0057  decode.d4.loss_cls: 2.4393  decode.d4.loss_mask: 1.0691  decode.d4.loss_dice: 2.0285  decode.d5.loss_cls: 2.3766  decode.d5.loss_mask: 1.0665  decode.d5.loss_dice: 2.0347  decode.d6.loss_cls: 2.4069  decode.d6.loss_mask: 1.0062  decode.d6.loss_dice: 2.0040  decode.d7.loss_cls: 2.3421  decode.d7.loss_mask: 1.0545  decode.d7.loss_dice: 1.9514  decode.d8.loss_cls: 2.3219  decode.d8.loss_mask: 1.0616  decode.d8.loss_dice: 1.9824
2023/05/23 18:40:08 - mmengine - INFO - Iter(train) [  2950/160000]  lr: 9.8340e-06  eta: 18:54:34  time: 0.4431  data_time: 0.0095  memory: 4916  grad_norm: 113.7735  loss: 49.6097  decode.loss_cls: 2.1962  decode.loss_mask: 0.8831  decode.loss_dice: 1.6220  decode.d0.loss_cls: 4.3221  decode.d0.loss_mask: 0.9094  decode.d0.loss_dice: 1.8146  decode.d1.loss_cls: 2.4447  decode.d1.loss_mask: 0.8356  decode.d1.loss_dice: 1.6608  decode.d2.loss_cls: 2.2732  decode.d2.loss_mask: 0.8325  decode.d2.loss_dice: 1.6068  decode.d3.loss_cls: 2.3176  decode.d3.loss_mask: 0.8294  decode.d3.loss_dice: 1.5685  decode.d4.loss_cls: 2.2724  decode.d4.loss_mask: 0.8358  decode.d4.loss_dice: 1.6040  decode.d5.loss_cls: 2.1592  decode.d5.loss_mask: 0.8823  decode.d5.loss_dice: 1.6232  decode.d6.loss_cls: 2.1614  decode.d6.loss_mask: 0.9081  decode.d6.loss_dice: 1.6087  decode.d7.loss_cls: 2.3011  decode.d7.loss_mask: 0.8745  decode.d7.loss_dice: 1.5711  decode.d8.loss_cls: 2.2759  decode.d8.loss_mask: 0.8491  decode.d8.loss_dice: 1.5664
2023/05/23 18:40:31 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 18:40:31 - mmengine - INFO - Iter(train) [  3000/160000]  lr: 9.8311e-06  eta: 18:55:22  time: 0.4581  data_time: 0.0099  memory: 4844  grad_norm: 109.7765  loss: 54.7515  decode.loss_cls: 2.2937  decode.loss_mask: 0.9745  decode.loss_dice: 1.9284  decode.d0.loss_cls: 4.6290  decode.d0.loss_mask: 0.9774  decode.d0.loss_dice: 2.1947  decode.d1.loss_cls: 2.5384  decode.d1.loss_mask: 0.9854  decode.d1.loss_dice: 1.9647  decode.d2.loss_cls: 2.3274  decode.d2.loss_mask: 0.9719  decode.d2.loss_dice: 1.9052  decode.d3.loss_cls: 2.2984  decode.d3.loss_mask: 0.9798  decode.d3.loss_dice: 1.8899  decode.d4.loss_cls: 2.3212  decode.d4.loss_mask: 0.9442  decode.d4.loss_dice: 1.8928  decode.d5.loss_cls: 2.3069  decode.d5.loss_mask: 0.9632  decode.d5.loss_dice: 1.8893  decode.d6.loss_cls: 2.2903  decode.d6.loss_mask: 0.9632  decode.d6.loss_dice: 1.8884  decode.d7.loss_cls: 2.2974  decode.d7.loss_mask: 0.9800  decode.d7.loss_dice: 1.9091  decode.d8.loss_cls: 2.2863  decode.d8.loss_mask: 0.9950  decode.d8.loss_dice: 1.9653
2023/05/23 18:40:31 - mmengine - INFO - Saving checkpoint at 3000 iterations
2023/05/23 18:40:57 - mmengine - INFO - Iter(train) [  3050/160000]  lr: 9.8283e-06  eta: 18:59:06  time: 0.4075  data_time: 0.0097  memory: 4818  grad_norm: 101.5432  loss: 50.5492  decode.loss_cls: 2.1536  decode.loss_mask: 0.9517  decode.loss_dice: 1.7122  decode.d0.loss_cls: 4.1829  decode.d0.loss_mask: 1.0075  decode.d0.loss_dice: 1.9719  decode.d1.loss_cls: 2.5298  decode.d1.loss_mask: 0.9945  decode.d1.loss_dice: 1.7117  decode.d2.loss_cls: 2.2688  decode.d2.loss_mask: 0.9823  decode.d2.loss_dice: 1.6775  decode.d3.loss_cls: 2.2452  decode.d3.loss_mask: 0.9311  decode.d3.loss_dice: 1.6192  decode.d4.loss_cls: 2.2019  decode.d4.loss_mask: 0.9149  decode.d4.loss_dice: 1.6954  decode.d5.loss_cls: 2.1456  decode.d5.loss_mask: 0.9376  decode.d5.loss_dice: 1.6642  decode.d6.loss_cls: 2.1608  decode.d6.loss_mask: 0.9118  decode.d6.loss_dice: 1.6191  decode.d7.loss_cls: 2.1028  decode.d7.loss_mask: 0.9183  decode.d7.loss_dice: 1.6647  decode.d8.loss_cls: 2.0990  decode.d8.loss_mask: 0.9317  decode.d8.loss_dice: 1.6417
2023/05/23 18:41:18 - mmengine - INFO - Iter(train) [  3100/160000]  lr: 9.8255e-06  eta: 18:58:14  time: 0.4150  data_time: 0.0116  memory: 4868  grad_norm: 113.1685  loss: 50.0303  decode.loss_cls: 2.2053  decode.loss_mask: 0.8477  decode.loss_dice: 1.6299  decode.d0.loss_cls: 4.3880  decode.d0.loss_mask: 0.9577  decode.d0.loss_dice: 1.9296  decode.d1.loss_cls: 2.5562  decode.d1.loss_mask: 0.9316  decode.d1.loss_dice: 1.7216  decode.d2.loss_cls: 2.3717  decode.d2.loss_mask: 0.9026  decode.d2.loss_dice: 1.6310  decode.d3.loss_cls: 2.2674  decode.d3.loss_mask: 0.8427  decode.d3.loss_dice: 1.6167  decode.d4.loss_cls: 2.2759  decode.d4.loss_mask: 0.8501  decode.d4.loss_dice: 1.6476  decode.d5.loss_cls: 2.1458  decode.d5.loss_mask: 0.8377  decode.d5.loss_dice: 1.6048  decode.d6.loss_cls: 2.1521  decode.d6.loss_mask: 0.8365  decode.d6.loss_dice: 1.5993  decode.d7.loss_cls: 2.1743  decode.d7.loss_mask: 0.8365  decode.d7.loss_dice: 1.6248  decode.d8.loss_cls: 2.2086  decode.d8.loss_mask: 0.8526  decode.d8.loss_dice: 1.5841
2023/05/23 18:41:40 - mmengine - INFO - Iter(train) [  3150/160000]  lr: 9.8227e-06  eta: 18:58:14  time: 0.4281  data_time: 0.0113  memory: 4805  grad_norm: 174.5386  loss: 45.1413  decode.loss_cls: 2.0484  decode.loss_mask: 0.8954  decode.loss_dice: 1.3443  decode.d0.loss_cls: 3.9681  decode.d0.loss_mask: 0.9353  decode.d0.loss_dice: 1.5022  decode.d1.loss_cls: 2.2473  decode.d1.loss_mask: 0.8974  decode.d1.loss_dice: 1.3552  decode.d2.loss_cls: 2.1065  decode.d2.loss_mask: 0.9255  decode.d2.loss_dice: 1.3115  decode.d3.loss_cls: 2.0596  decode.d3.loss_mask: 0.9348  decode.d3.loss_dice: 1.3061  decode.d4.loss_cls: 2.0315  decode.d4.loss_mask: 0.9351  decode.d4.loss_dice: 1.2864  decode.d5.loss_cls: 2.0590  decode.d5.loss_mask: 0.8911  decode.d5.loss_dice: 1.3023  decode.d6.loss_cls: 2.0778  decode.d6.loss_mask: 0.9082  decode.d6.loss_dice: 1.2763  decode.d7.loss_cls: 2.0264  decode.d7.loss_mask: 0.9202  decode.d7.loss_dice: 1.3083  decode.d8.loss_cls: 2.0663  decode.d8.loss_mask: 0.8984  decode.d8.loss_dice: 1.3164
2023/05/23 18:42:02 - mmengine - INFO - Iter(train) [  3200/160000]  lr: 9.8199e-06  eta: 18:57:23  time: 0.4455  data_time: 0.0098  memory: 4916  grad_norm: 170.8867  loss: 50.5092  decode.loss_cls: 2.2164  decode.loss_mask: 0.9107  decode.loss_dice: 1.6328  decode.d0.loss_cls: 4.0620  decode.d0.loss_mask: 0.9470  decode.d0.loss_dice: 1.9067  decode.d1.loss_cls: 2.4472  decode.d1.loss_mask: 0.9574  decode.d1.loss_dice: 1.7849  decode.d2.loss_cls: 2.2729  decode.d2.loss_mask: 0.9263  decode.d2.loss_dice: 1.6740  decode.d3.loss_cls: 2.2447  decode.d3.loss_mask: 0.9096  decode.d3.loss_dice: 1.6367  decode.d4.loss_cls: 2.2343  decode.d4.loss_mask: 0.9012  decode.d4.loss_dice: 1.6587  decode.d5.loss_cls: 2.2042  decode.d5.loss_mask: 0.8792  decode.d5.loss_dice: 1.6348  decode.d6.loss_cls: 2.3043  decode.d6.loss_mask: 0.9141  decode.d6.loss_dice: 1.6535  decode.d7.loss_cls: 2.2154  decode.d7.loss_mask: 0.9153  decode.d7.loss_dice: 1.7103  decode.d8.loss_cls: 2.2169  decode.d8.loss_mask: 0.8706  decode.d8.loss_dice: 1.6670
2023/05/23 18:42:24 - mmengine - INFO - Iter(train) [  3250/160000]  lr: 9.8171e-06  eta: 18:57:08  time: 0.4341  data_time: 0.0096  memory: 4888  grad_norm: 111.5309  loss: 50.0432  decode.loss_cls: 2.0613  decode.loss_mask: 0.9226  decode.loss_dice: 1.8339  decode.d0.loss_cls: 3.9789  decode.d0.loss_mask: 0.8587  decode.d0.loss_dice: 2.0168  decode.d1.loss_cls: 2.0845  decode.d1.loss_mask: 0.9006  decode.d1.loss_dice: 1.8800  decode.d2.loss_cls: 1.9988  decode.d2.loss_mask: 0.9549  decode.d2.loss_dice: 1.8285  decode.d3.loss_cls: 1.9850  decode.d3.loss_mask: 0.9205  decode.d3.loss_dice: 1.8412  decode.d4.loss_cls: 2.0445  decode.d4.loss_mask: 0.9088  decode.d4.loss_dice: 1.8461  decode.d5.loss_cls: 1.9757  decode.d5.loss_mask: 0.9361  decode.d5.loss_dice: 1.8531  decode.d6.loss_cls: 2.0005  decode.d6.loss_mask: 0.9394  decode.d6.loss_dice: 1.8192  decode.d7.loss_cls: 2.0238  decode.d7.loss_mask: 0.9678  decode.d7.loss_dice: 1.8799  decode.d8.loss_cls: 1.9950  decode.d8.loss_mask: 0.9544  decode.d8.loss_dice: 1.8327
2023/05/23 18:42:44 - mmengine - INFO - Iter(train) [  3300/160000]  lr: 9.8142e-06  eta: 18:56:05  time: 0.4210  data_time: 0.0095  memory: 4908  grad_norm: 93.9235  loss: 43.5951  decode.loss_cls: 1.9020  decode.loss_mask: 0.7706  decode.loss_dice: 1.4347  decode.d0.loss_cls: 3.8790  decode.d0.loss_mask: 0.8265  decode.d0.loss_dice: 1.6295  decode.d1.loss_cls: 2.1742  decode.d1.loss_mask: 0.8321  decode.d1.loss_dice: 1.5368  decode.d2.loss_cls: 2.0677  decode.d2.loss_mask: 0.7543  decode.d2.loss_dice: 1.3922  decode.d3.loss_cls: 1.9956  decode.d3.loss_mask: 0.7114  decode.d3.loss_dice: 1.3875  decode.d4.loss_cls: 1.9307  decode.d4.loss_mask: 0.7440  decode.d4.loss_dice: 1.4151  decode.d5.loss_cls: 1.9038  decode.d5.loss_mask: 0.7552  decode.d5.loss_dice: 1.4166  decode.d6.loss_cls: 1.8116  decode.d6.loss_mask: 0.8051  decode.d6.loss_dice: 1.4372  decode.d7.loss_cls: 1.9024  decode.d7.loss_mask: 0.7345  decode.d7.loss_dice: 1.3468  decode.d8.loss_cls: 1.9283  decode.d8.loss_mask: 0.7833  decode.d8.loss_dice: 1.3859
2023/05/23 18:43:05 - mmengine - INFO - Iter(train) [  3350/160000]  lr: 9.8114e-06  eta: 18:54:47  time: 0.4084  data_time: 0.0096  memory: 4865  grad_norm: 119.0253  loss: 45.4549  decode.loss_cls: 1.9776  decode.loss_mask: 0.8850  decode.loss_dice: 1.3790  decode.d0.loss_cls: 3.8087  decode.d0.loss_mask: 0.8973  decode.d0.loss_dice: 1.6235  decode.d1.loss_cls: 2.2344  decode.d1.loss_mask: 0.9137  decode.d1.loss_dice: 1.4667  decode.d2.loss_cls: 2.0299  decode.d2.loss_mask: 0.9647  decode.d2.loss_dice: 1.4371  decode.d3.loss_cls: 1.9689  decode.d3.loss_mask: 0.8911  decode.d3.loss_dice: 1.3994  decode.d4.loss_cls: 2.0154  decode.d4.loss_mask: 0.8868  decode.d4.loss_dice: 1.4121  decode.d5.loss_cls: 1.9911  decode.d5.loss_mask: 0.9083  decode.d5.loss_dice: 1.4377  decode.d6.loss_cls: 1.9579  decode.d6.loss_mask: 0.8830  decode.d6.loss_dice: 1.3725  decode.d7.loss_cls: 2.0684  decode.d7.loss_mask: 0.8774  decode.d7.loss_dice: 1.4016  decode.d8.loss_cls: 2.0456  decode.d8.loss_mask: 0.9085  decode.d8.loss_dice: 1.4115
2023/05/23 18:43:26 - mmengine - INFO - Iter(train) [  3400/160000]  lr: 9.8086e-06  eta: 18:53:38  time: 0.4197  data_time: 0.0095  memory: 4859  grad_norm: 101.5333  loss: 54.2357  decode.loss_cls: 2.4389  decode.loss_mask: 0.9656  decode.loss_dice: 1.7975  decode.d0.loss_cls: 4.3031  decode.d0.loss_mask: 1.0043  decode.d0.loss_dice: 1.9884  decode.d1.loss_cls: 2.5890  decode.d1.loss_mask: 1.0267  decode.d1.loss_dice: 1.9614  decode.d2.loss_cls: 2.4781  decode.d2.loss_mask: 0.9867  decode.d2.loss_dice: 1.8125  decode.d3.loss_cls: 2.4245  decode.d3.loss_mask: 0.9786  decode.d3.loss_dice: 1.7923  decode.d4.loss_cls: 2.4510  decode.d4.loss_mask: 0.9543  decode.d4.loss_dice: 1.7562  decode.d5.loss_cls: 2.4024  decode.d5.loss_mask: 0.9558  decode.d5.loss_dice: 1.7446  decode.d6.loss_cls: 2.3658  decode.d6.loss_mask: 0.9538  decode.d6.loss_dice: 1.8027  decode.d7.loss_cls: 2.4203  decode.d7.loss_mask: 0.9679  decode.d7.loss_dice: 1.7788  decode.d8.loss_cls: 2.3877  decode.d8.loss_mask: 0.9608  decode.d8.loss_dice: 1.7859
2023/05/23 18:43:47 - mmengine - INFO - Iter(train) [  3450/160000]  lr: 9.8058e-06  eta: 18:53:21  time: 0.4085  data_time: 0.0093  memory: 4818  grad_norm: 119.1035  loss: 39.7843  decode.loss_cls: 1.6583  decode.loss_mask: 0.7504  decode.loss_dice: 1.3033  decode.d0.loss_cls: 3.4102  decode.d0.loss_mask: 0.7862  decode.d0.loss_dice: 1.4956  decode.d1.loss_cls: 1.8698  decode.d1.loss_mask: 0.7457  decode.d1.loss_dice: 1.3959  decode.d2.loss_cls: 1.7666  decode.d2.loss_mask: 0.7518  decode.d2.loss_dice: 1.3538  decode.d3.loss_cls: 1.7320  decode.d3.loss_mask: 0.7477  decode.d3.loss_dice: 1.3261  decode.d4.loss_cls: 1.7198  decode.d4.loss_mask: 0.7366  decode.d4.loss_dice: 1.3209  decode.d5.loss_cls: 1.6607  decode.d5.loss_mask: 0.7396  decode.d5.loss_dice: 1.3246  decode.d6.loss_cls: 1.6341  decode.d6.loss_mask: 0.7549  decode.d6.loss_dice: 1.3704  decode.d7.loss_cls: 1.6482  decode.d7.loss_mask: 0.7424  decode.d7.loss_dice: 1.3196  decode.d8.loss_cls: 1.6246  decode.d8.loss_mask: 0.7504  decode.d8.loss_dice: 1.3443
2023/05/23 18:44:09 - mmengine - INFO - Iter(train) [  3500/160000]  lr: 9.8030e-06  eta: 18:52:31  time: 0.4306  data_time: 0.0096  memory: 4847  grad_norm: 93.4292  loss: 55.0592  decode.loss_cls: 2.0331  decode.loss_mask: 1.1219  decode.loss_dice: 1.9901  decode.d0.loss_cls: 4.2662  decode.d0.loss_mask: 1.0910  decode.d0.loss_dice: 2.2681  decode.d1.loss_cls: 2.4227  decode.d1.loss_mask: 1.1693  decode.d1.loss_dice: 2.0944  decode.d2.loss_cls: 2.2197  decode.d2.loss_mask: 1.1344  decode.d2.loss_dice: 1.9783  decode.d3.loss_cls: 2.1788  decode.d3.loss_mask: 1.1046  decode.d3.loss_dice: 2.0092  decode.d4.loss_cls: 2.1045  decode.d4.loss_mask: 1.1948  decode.d4.loss_dice: 1.9755  decode.d5.loss_cls: 2.0683  decode.d5.loss_mask: 1.1654  decode.d5.loss_dice: 1.9862  decode.d6.loss_cls: 2.0863  decode.d6.loss_mask: 1.1649  decode.d6.loss_dice: 1.9818  decode.d7.loss_cls: 2.0504  decode.d7.loss_mask: 1.1150  decode.d7.loss_dice: 1.9650  decode.d8.loss_cls: 2.0278  decode.d8.loss_mask: 1.1363  decode.d8.loss_dice: 1.9551
2023/05/23 18:44:29 - mmengine - INFO - Iter(train) [  3550/160000]  lr: 9.8001e-06  eta: 18:51:14  time: 0.4094  data_time: 0.0095  memory: 4860  grad_norm: 106.0787  loss: 51.3663  decode.loss_cls: 2.0229  decode.loss_mask: 1.1409  decode.loss_dice: 1.7153  decode.d0.loss_cls: 3.8242  decode.d0.loss_mask: 1.1482  decode.d0.loss_dice: 2.0082  decode.d1.loss_cls: 2.2325  decode.d1.loss_mask: 1.1146  decode.d1.loss_dice: 1.8176  decode.d2.loss_cls: 2.1617  decode.d2.loss_mask: 1.0415  decode.d2.loss_dice: 1.6826  decode.d3.loss_cls: 2.1805  decode.d3.loss_mask: 1.0813  decode.d3.loss_dice: 1.6965  decode.d4.loss_cls: 2.1232  decode.d4.loss_mask: 1.1202  decode.d4.loss_dice: 1.7076  decode.d5.loss_cls: 2.0641  decode.d5.loss_mask: 1.1025  decode.d5.loss_dice: 1.7181  decode.d6.loss_cls: 2.1266  decode.d6.loss_mask: 1.0747  decode.d6.loss_dice: 1.6881  decode.d7.loss_cls: 2.0330  decode.d7.loss_mask: 1.1191  decode.d7.loss_dice: 1.6943  decode.d8.loss_cls: 2.0651  decode.d8.loss_mask: 1.1575  decode.d8.loss_dice: 1.7039
2023/05/23 18:44:50 - mmengine - INFO - Iter(train) [  3600/160000]  lr: 9.7973e-06  eta: 18:50:09  time: 0.4169  data_time: 0.0095  memory: 4839  grad_norm: 115.4849  loss: 51.1680  decode.loss_cls: 2.0950  decode.loss_mask: 1.0899  decode.loss_dice: 1.7620  decode.d0.loss_cls: 3.8556  decode.d0.loss_mask: 1.1488  decode.d0.loss_dice: 1.8835  decode.d1.loss_cls: 2.2223  decode.d1.loss_mask: 1.1286  decode.d1.loss_dice: 1.8151  decode.d2.loss_cls: 2.0543  decode.d2.loss_mask: 1.1524  decode.d2.loss_dice: 1.7340  decode.d3.loss_cls: 2.0323  decode.d3.loss_mask: 1.1540  decode.d3.loss_dice: 1.7507  decode.d4.loss_cls: 1.9361  decode.d4.loss_mask: 1.1399  decode.d4.loss_dice: 1.7876  decode.d5.loss_cls: 1.9639  decode.d5.loss_mask: 1.1427  decode.d5.loss_dice: 1.7836  decode.d6.loss_cls: 2.0245  decode.d6.loss_mask: 1.1037  decode.d6.loss_dice: 1.7468  decode.d7.loss_cls: 2.0269  decode.d7.loss_mask: 1.0621  decode.d7.loss_dice: 1.7044  decode.d8.loss_cls: 2.0572  decode.d8.loss_mask: 1.0791  decode.d8.loss_dice: 1.7312
2023/05/23 18:45:10 - mmengine - INFO - Iter(train) [  3650/160000]  lr: 9.7945e-06  eta: 18:48:57  time: 0.4122  data_time: 0.0097  memory: 4826  grad_norm: 115.0578  loss: 59.3492  decode.loss_cls: 2.3319  decode.loss_mask: 1.1405  decode.loss_dice: 2.1465  decode.d0.loss_cls: 4.4562  decode.d0.loss_mask: 1.1487  decode.d0.loss_dice: 2.4382  decode.d1.loss_cls: 2.4919  decode.d1.loss_mask: 1.1645  decode.d1.loss_dice: 2.2668  decode.d2.loss_cls: 2.3692  decode.d2.loss_mask: 1.1865  decode.d2.loss_dice: 2.2405  decode.d3.loss_cls: 2.3943  decode.d3.loss_mask: 1.1872  decode.d3.loss_dice: 2.2034  decode.d4.loss_cls: 2.2719  decode.d4.loss_mask: 1.1910  decode.d4.loss_dice: 2.1823  decode.d5.loss_cls: 2.2286  decode.d5.loss_mask: 1.1816  decode.d5.loss_dice: 2.2023  decode.d6.loss_cls: 2.2927  decode.d6.loss_mask: 1.1814  decode.d6.loss_dice: 2.1826  decode.d7.loss_cls: 2.3208  decode.d7.loss_mask: 1.1617  decode.d7.loss_dice: 2.1414  decode.d8.loss_cls: 2.3108  decode.d8.loss_mask: 1.1804  decode.d8.loss_dice: 2.1534
2023/05/23 18:45:31 - mmengine - INFO - Iter(train) [  3700/160000]  lr: 9.7917e-06  eta: 18:47:41  time: 0.4025  data_time: 0.0094  memory: 4860  grad_norm: 120.3971  loss: 54.1642  decode.loss_cls: 2.0739  decode.loss_mask: 1.1738  decode.loss_dice: 1.8891  decode.d0.loss_cls: 4.2387  decode.d0.loss_mask: 1.1554  decode.d0.loss_dice: 2.1006  decode.d1.loss_cls: 2.3813  decode.d1.loss_mask: 1.2007  decode.d1.loss_dice: 2.0084  decode.d2.loss_cls: 2.1581  decode.d2.loss_mask: 1.1801  decode.d2.loss_dice: 1.8901  decode.d3.loss_cls: 2.1113  decode.d3.loss_mask: 1.1744  decode.d3.loss_dice: 1.8742  decode.d4.loss_cls: 2.1077  decode.d4.loss_mask: 1.1120  decode.d4.loss_dice: 1.8506  decode.d5.loss_cls: 2.1619  decode.d5.loss_mask: 1.1292  decode.d5.loss_dice: 1.8539  decode.d6.loss_cls: 2.1634  decode.d6.loss_mask: 1.1511  decode.d6.loss_dice: 1.8408  decode.d7.loss_cls: 2.1126  decode.d7.loss_mask: 1.1101  decode.d7.loss_dice: 1.8517  decode.d8.loss_cls: 2.0737  decode.d8.loss_mask: 1.1338  decode.d8.loss_dice: 1.9013
2023/05/23 18:45:52 - mmengine - INFO - Iter(train) [  3750/160000]  lr: 9.7889e-06  eta: 18:47:22  time: 0.4164  data_time: 0.0095  memory: 4859  grad_norm: 127.9966  loss: 52.8152  decode.loss_cls: 2.1290  decode.loss_mask: 1.0632  decode.loss_dice: 1.7847  decode.d0.loss_cls: 4.1503  decode.d0.loss_mask: 1.1284  decode.d0.loss_dice: 2.0675  decode.d1.loss_cls: 2.4991  decode.d1.loss_mask: 1.1000  decode.d1.loss_dice: 1.8841  decode.d2.loss_cls: 2.2246  decode.d2.loss_mask: 1.0822  decode.d2.loss_dice: 1.8012  decode.d3.loss_cls: 2.1166  decode.d3.loss_mask: 1.1680  decode.d3.loss_dice: 1.8123  decode.d4.loss_cls: 2.1101  decode.d4.loss_mask: 1.1360  decode.d4.loss_dice: 1.8195  decode.d5.loss_cls: 2.0889  decode.d5.loss_mask: 1.1279  decode.d5.loss_dice: 1.8012  decode.d6.loss_cls: 2.1403  decode.d6.loss_mask: 1.0810  decode.d6.loss_dice: 1.7427  decode.d7.loss_cls: 2.0813  decode.d7.loss_mask: 1.0439  decode.d7.loss_dice: 1.7257  decode.d8.loss_cls: 2.0743  decode.d8.loss_mask: 1.0764  decode.d8.loss_dice: 1.7548
2023/05/23 18:46:13 - mmengine - INFO - Iter(train) [  3800/160000]  lr: 9.7860e-06  eta: 18:46:31  time: 0.4078  data_time: 0.0097  memory: 4817  grad_norm: 110.8037  loss: 46.1468  decode.loss_cls: 2.0753  decode.loss_mask: 0.8587  decode.loss_dice: 1.3751  decode.d0.loss_cls: 3.8464  decode.d0.loss_mask: 0.8580  decode.d0.loss_dice: 1.6479  decode.d1.loss_cls: 2.2769  decode.d1.loss_mask: 0.8931  decode.d1.loss_dice: 1.5781  decode.d2.loss_cls: 2.2066  decode.d2.loss_mask: 0.8710  decode.d2.loss_dice: 1.4528  decode.d3.loss_cls: 2.1805  decode.d3.loss_mask: 0.8563  decode.d3.loss_dice: 1.4124  decode.d4.loss_cls: 2.0822  decode.d4.loss_mask: 0.8394  decode.d4.loss_dice: 1.4001  decode.d5.loss_cls: 2.1242  decode.d5.loss_mask: 0.8436  decode.d5.loss_dice: 1.4203  decode.d6.loss_cls: 2.1595  decode.d6.loss_mask: 0.8417  decode.d6.loss_dice: 1.4051  decode.d7.loss_cls: 2.1293  decode.d7.loss_mask: 0.8241  decode.d7.loss_dice: 1.3630  decode.d8.loss_cls: 2.0844  decode.d8.loss_mask: 0.8211  decode.d8.loss_dice: 1.4197
2023/05/23 18:46:36 - mmengine - INFO - Iter(train) [  3850/160000]  lr: 9.7832e-06  eta: 18:46:38  time: 0.4630  data_time: 0.0095  memory: 4847  grad_norm: 97.7186  loss: 38.8500  decode.loss_cls: 1.6288  decode.loss_mask: 0.6564  decode.loss_dice: 1.3299  decode.d0.loss_cls: 3.4687  decode.d0.loss_mask: 0.7022  decode.d0.loss_dice: 1.4885  decode.d1.loss_cls: 1.9173  decode.d1.loss_mask: 0.6650  decode.d1.loss_dice: 1.3779  decode.d2.loss_cls: 1.6279  decode.d2.loss_mask: 0.6761  decode.d2.loss_dice: 1.3352  decode.d3.loss_cls: 1.6381  decode.d3.loss_mask: 0.6621  decode.d3.loss_dice: 1.2849  decode.d4.loss_cls: 1.6633  decode.d4.loss_mask: 0.6968  decode.d4.loss_dice: 1.3598  decode.d5.loss_cls: 1.6798  decode.d5.loss_mask: 0.6809  decode.d5.loss_dice: 1.3542  decode.d6.loss_cls: 1.6332  decode.d6.loss_mask: 0.6702  decode.d6.loss_dice: 1.3132  decode.d7.loss_cls: 1.6884  decode.d7.loss_mask: 0.6588  decode.d7.loss_dice: 1.3326  decode.d8.loss_cls: 1.6596  decode.d8.loss_mask: 0.6770  decode.d8.loss_dice: 1.3233
2023/05/23 18:46:57 - mmengine - INFO - Iter(train) [  3900/160000]  lr: 9.7804e-06  eta: 18:45:54  time: 0.4044  data_time: 0.0093  memory: 4840  grad_norm: 106.3099  loss: 44.0645  decode.loss_cls: 1.7823  decode.loss_mask: 0.8096  decode.loss_dice: 1.5949  decode.d0.loss_cls: 3.7888  decode.d0.loss_mask: 0.8709  decode.d0.loss_dice: 1.7923  decode.d1.loss_cls: 1.9527  decode.d1.loss_mask: 0.8389  decode.d1.loss_dice: 1.6552  decode.d2.loss_cls: 1.7644  decode.d2.loss_mask: 0.7855  decode.d2.loss_dice: 1.5516  decode.d3.loss_cls: 1.7569  decode.d3.loss_mask: 0.7860  decode.d3.loss_dice: 1.5631  decode.d4.loss_cls: 1.7616  decode.d4.loss_mask: 0.7809  decode.d4.loss_dice: 1.5238  decode.d5.loss_cls: 1.8069  decode.d5.loss_mask: 0.7968  decode.d5.loss_dice: 1.5590  decode.d6.loss_cls: 1.7803  decode.d6.loss_mask: 0.8457  decode.d6.loss_dice: 1.5468  decode.d7.loss_cls: 1.7916  decode.d7.loss_mask: 0.8500  decode.d7.loss_dice: 1.5495  decode.d8.loss_cls: 1.7771  decode.d8.loss_mask: 0.8181  decode.d8.loss_dice: 1.5833
2023/05/23 18:47:17 - mmengine - INFO - Iter(train) [  3950/160000]  lr: 9.7776e-06  eta: 18:44:52  time: 0.4086  data_time: 0.0095  memory: 4812  grad_norm: 116.7694  loss: 40.2269  decode.loss_cls: 1.7212  decode.loss_mask: 0.8930  decode.loss_dice: 1.1575  decode.d0.loss_cls: 3.5376  decode.d0.loss_mask: 0.9233  decode.d0.loss_dice: 1.2567  decode.d1.loss_cls: 1.9393  decode.d1.loss_mask: 0.8766  decode.d1.loss_dice: 1.1716  decode.d2.loss_cls: 1.8365  decode.d2.loss_mask: 0.8551  decode.d2.loss_dice: 1.1449  decode.d3.loss_cls: 1.8212  decode.d3.loss_mask: 0.8543  decode.d3.loss_dice: 1.1192  decode.d4.loss_cls: 1.8432  decode.d4.loss_mask: 0.8640  decode.d4.loss_dice: 1.1417  decode.d5.loss_cls: 1.8106  decode.d5.loss_mask: 0.8657  decode.d5.loss_dice: 1.1467  decode.d6.loss_cls: 1.7529  decode.d6.loss_mask: 0.9075  decode.d6.loss_dice: 1.1793  decode.d7.loss_cls: 1.8196  decode.d7.loss_mask: 0.8666  decode.d7.loss_dice: 1.1725  decode.d8.loss_cls: 1.7401  decode.d8.loss_mask: 0.8357  decode.d8.loss_dice: 1.1729
2023/05/23 18:47:38 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 18:47:38 - mmengine - INFO - Iter(train) [  4000/160000]  lr: 9.7748e-06  eta: 18:43:51  time: 0.4225  data_time: 0.0095  memory: 4818  grad_norm: 98.6304  loss: 44.2997  decode.loss_cls: 1.9040  decode.loss_mask: 0.8800  decode.loss_dice: 1.3615  decode.d0.loss_cls: 3.6634  decode.d0.loss_mask: 0.9787  decode.d0.loss_dice: 1.5967  decode.d1.loss_cls: 2.0478  decode.d1.loss_mask: 0.9457  decode.d1.loss_dice: 1.4844  decode.d2.loss_cls: 2.0360  decode.d2.loss_mask: 0.9095  decode.d2.loss_dice: 1.3967  decode.d3.loss_cls: 2.0186  decode.d3.loss_mask: 0.9005  decode.d3.loss_dice: 1.3682  decode.d4.loss_cls: 1.8902  decode.d4.loss_mask: 0.8842  decode.d4.loss_dice: 1.3812  decode.d5.loss_cls: 1.9237  decode.d5.loss_mask: 0.9000  decode.d5.loss_dice: 1.3715  decode.d6.loss_cls: 1.9219  decode.d6.loss_mask: 0.8907  decode.d6.loss_dice: 1.3345  decode.d7.loss_cls: 1.9527  decode.d7.loss_mask: 0.8629  decode.d7.loss_dice: 1.3593  decode.d8.loss_cls: 1.9288  decode.d8.loss_mask: 0.8595  decode.d8.loss_dice: 1.3469
2023/05/23 18:47:38 - mmengine - INFO - Saving checkpoint at 4000 iterations
2023/05/23 18:48:04 - mmengine - INFO - Iter(train) [  4050/160000]  lr: 9.7720e-06  eta: 18:46:25  time: 0.4143  data_time: 0.0098  memory: 4878  grad_norm: 127.0827  loss: 51.6435  decode.loss_cls: 2.2353  decode.loss_mask: 0.9325  decode.loss_dice: 1.6878  decode.d0.loss_cls: 4.4276  decode.d0.loss_mask: 0.9839  decode.d0.loss_dice: 1.9714  decode.d1.loss_cls: 2.3564  decode.d1.loss_mask: 1.0048  decode.d1.loss_dice: 1.8459  decode.d2.loss_cls: 2.2223  decode.d2.loss_mask: 0.9712  decode.d2.loss_dice: 1.7788  decode.d3.loss_cls: 2.1638  decode.d3.loss_mask: 0.9645  decode.d3.loss_dice: 1.7770  decode.d4.loss_cls: 2.1541  decode.d4.loss_mask: 0.9676  decode.d4.loss_dice: 1.7487  decode.d5.loss_cls: 2.2033  decode.d5.loss_mask: 0.9432  decode.d5.loss_dice: 1.7354  decode.d6.loss_cls: 2.2428  decode.d6.loss_mask: 0.9395  decode.d6.loss_dice: 1.7169  decode.d7.loss_cls: 2.2035  decode.d7.loss_mask: 0.9453  decode.d7.loss_dice: 1.6714  decode.d8.loss_cls: 2.2245  decode.d8.loss_mask: 0.9348  decode.d8.loss_dice: 1.6894
2023/05/23 18:48:25 - mmengine - INFO - Iter(train) [  4100/160000]  lr: 9.7691e-06  eta: 18:45:37  time: 0.4314  data_time: 0.0103  memory: 4868  grad_norm: 122.8550  loss: 51.4928  decode.loss_cls: 2.3315  decode.loss_mask: 0.9504  decode.loss_dice: 1.6986  decode.d0.loss_cls: 4.0892  decode.d0.loss_mask: 0.9426  decode.d0.loss_dice: 1.9178  decode.d1.loss_cls: 2.4963  decode.d1.loss_mask: 0.9097  decode.d1.loss_dice: 1.6897  decode.d2.loss_cls: 2.3852  decode.d2.loss_mask: 0.8878  decode.d2.loss_dice: 1.6824  decode.d3.loss_cls: 2.3104  decode.d3.loss_mask: 0.9387  decode.d3.loss_dice: 1.7183  decode.d4.loss_cls: 2.3088  decode.d4.loss_mask: 0.9060  decode.d4.loss_dice: 1.7193  decode.d5.loss_cls: 2.3432  decode.d5.loss_mask: 0.9010  decode.d5.loss_dice: 1.7019  decode.d6.loss_cls: 2.2967  decode.d6.loss_mask: 0.8889  decode.d6.loss_dice: 1.7380  decode.d7.loss_cls: 2.2655  decode.d7.loss_mask: 0.9209  decode.d7.loss_dice: 1.6841  decode.d8.loss_cls: 2.2591  decode.d8.loss_mask: 0.9183  decode.d8.loss_dice: 1.6922
2023/05/23 18:48:46 - mmengine - INFO - Iter(train) [  4150/160000]  lr: 9.7663e-06  eta: 18:44:36  time: 0.4063  data_time: 0.0094  memory: 4839  grad_norm: 104.2112  loss: 53.6927  decode.loss_cls: 2.3361  decode.loss_mask: 0.9947  decode.loss_dice: 1.8454  decode.d0.loss_cls: 4.2717  decode.d0.loss_mask: 1.0471  decode.d0.loss_dice: 2.0998  decode.d1.loss_cls: 2.4938  decode.d1.loss_mask: 1.0360  decode.d1.loss_dice: 1.9208  decode.d2.loss_cls: 2.3865  decode.d2.loss_mask: 0.9281  decode.d2.loss_dice: 1.8524  decode.d3.loss_cls: 2.2862  decode.d3.loss_mask: 0.9676  decode.d3.loss_dice: 1.8271  decode.d4.loss_cls: 2.2380  decode.d4.loss_mask: 1.0087  decode.d4.loss_dice: 1.8450  decode.d5.loss_cls: 2.2889  decode.d5.loss_mask: 0.9884  decode.d5.loss_dice: 1.8016  decode.d6.loss_cls: 2.3509  decode.d6.loss_mask: 0.9522  decode.d6.loss_dice: 1.7840  decode.d7.loss_cls: 2.2942  decode.d7.loss_mask: 0.9880  decode.d7.loss_dice: 1.7918  decode.d8.loss_cls: 2.2953  decode.d8.loss_mask: 0.9877  decode.d8.loss_dice: 1.7847
2023/05/23 18:49:07 - mmengine - INFO - Iter(train) [  4200/160000]  lr: 9.7635e-06  eta: 18:44:05  time: 0.4440  data_time: 0.0099  memory: 4861  grad_norm: 104.7758  loss: 54.4898  decode.loss_cls: 1.9886  decode.loss_mask: 1.0429  decode.loss_dice: 2.1298  decode.d0.loss_cls: 4.2467  decode.d0.loss_mask: 1.0277  decode.d0.loss_dice: 2.3065  decode.d1.loss_cls: 2.4246  decode.d1.loss_mask: 1.0092  decode.d1.loss_dice: 2.2022  decode.d2.loss_cls: 2.0282  decode.d2.loss_mask: 1.0462  decode.d2.loss_dice: 2.1369  decode.d3.loss_cls: 1.9900  decode.d3.loss_mask: 1.0479  decode.d3.loss_dice: 2.1405  decode.d4.loss_cls: 2.0203  decode.d4.loss_mask: 1.0101  decode.d4.loss_dice: 2.1265  decode.d5.loss_cls: 1.9842  decode.d5.loss_mask: 1.0692  decode.d5.loss_dice: 2.1551  decode.d6.loss_cls: 2.0154  decode.d6.loss_mask: 1.0300  decode.d6.loss_dice: 2.1047  decode.d7.loss_cls: 1.9709  decode.d7.loss_mask: 0.9960  decode.d7.loss_dice: 2.0819  decode.d8.loss_cls: 1.9950  decode.d8.loss_mask: 1.0444  decode.d8.loss_dice: 2.1181
2023/05/23 18:49:29 - mmengine - INFO - Iter(train) [  4250/160000]  lr: 9.7607e-06  eta: 18:43:47  time: 0.4091  data_time: 0.0094  memory: 4865  grad_norm: 126.4888  loss: 41.7416  decode.loss_cls: 1.6434  decode.loss_mask: 0.6836  decode.loss_dice: 1.6120  decode.d0.loss_cls: 3.6223  decode.d0.loss_mask: 0.7723  decode.d0.loss_dice: 1.8068  decode.d1.loss_cls: 1.7930  decode.d1.loss_mask: 0.7427  decode.d1.loss_dice: 1.6573  decode.d2.loss_cls: 1.6582  decode.d2.loss_mask: 0.7165  decode.d2.loss_dice: 1.6119  decode.d3.loss_cls: 1.5904  decode.d3.loss_mask: 0.6940  decode.d3.loss_dice: 1.6280  decode.d4.loss_cls: 1.5828  decode.d4.loss_mask: 0.7078  decode.d4.loss_dice: 1.6215  decode.d5.loss_cls: 1.5476  decode.d5.loss_mask: 0.7103  decode.d5.loss_dice: 1.6323  decode.d6.loss_cls: 1.6698  decode.d6.loss_mask: 0.6727  decode.d6.loss_dice: 1.5574  decode.d7.loss_cls: 1.5676  decode.d7.loss_mask: 0.7138  decode.d7.loss_dice: 1.5951  decode.d8.loss_cls: 1.5727  decode.d8.loss_mask: 0.7394  decode.d8.loss_dice: 1.6185
2023/05/23 18:49:50 - mmengine - INFO - Iter(train) [  4300/160000]  lr: 9.7579e-06  eta: 18:42:56  time: 0.4099  data_time: 0.0095  memory: 4830  grad_norm: 123.3491  loss: 51.9523  decode.loss_cls: 1.9935  decode.loss_mask: 1.1103  decode.loss_dice: 1.8779  decode.d0.loss_cls: 3.9406  decode.d0.loss_mask: 1.1343  decode.d0.loss_dice: 2.0328  decode.d1.loss_cls: 2.3007  decode.d1.loss_mask: 1.1274  decode.d1.loss_dice: 1.9634  decode.d2.loss_cls: 2.0332  decode.d2.loss_mask: 1.0819  decode.d2.loss_dice: 1.8883  decode.d3.loss_cls: 2.0048  decode.d3.loss_mask: 1.0838  decode.d3.loss_dice: 1.8253  decode.d4.loss_cls: 1.9974  decode.d4.loss_mask: 1.0763  decode.d4.loss_dice: 1.8550  decode.d5.loss_cls: 1.9501  decode.d5.loss_mask: 1.0709  decode.d5.loss_dice: 1.8211  decode.d6.loss_cls: 1.9656  decode.d6.loss_mask: 1.0678  decode.d6.loss_dice: 1.8401  decode.d7.loss_cls: 2.0150  decode.d7.loss_mask: 1.0638  decode.d7.loss_dice: 1.9112  decode.d8.loss_cls: 1.9850  decode.d8.loss_mask: 1.0805  decode.d8.loss_dice: 1.8544
2023/05/23 18:50:12 - mmengine - INFO - Iter(train) [  4350/160000]  lr: 9.7550e-06  eta: 18:43:01  time: 0.4007  data_time: 0.0093  memory: 4860  grad_norm: 99.0578  loss: 50.5947  decode.loss_cls: 2.1314  decode.loss_mask: 1.1213  decode.loss_dice: 1.5912  decode.d0.loss_cls: 3.7871  decode.d0.loss_mask: 1.0915  decode.d0.loss_dice: 1.7765  decode.d1.loss_cls: 2.3833  decode.d1.loss_mask: 1.0558  decode.d1.loss_dice: 1.7295  decode.d2.loss_cls: 2.2640  decode.d2.loss_mask: 1.0673  decode.d2.loss_dice: 1.6476  decode.d3.loss_cls: 2.2601  decode.d3.loss_mask: 1.0879  decode.d3.loss_dice: 1.5888  decode.d4.loss_cls: 2.2012  decode.d4.loss_mask: 1.0760  decode.d4.loss_dice: 1.5528  decode.d5.loss_cls: 2.1251  decode.d5.loss_mask: 1.0895  decode.d5.loss_dice: 1.5866  decode.d6.loss_cls: 2.1098  decode.d6.loss_mask: 1.1363  decode.d6.loss_dice: 1.6218  decode.d7.loss_cls: 2.1267  decode.d7.loss_mask: 1.0896  decode.d7.loss_dice: 1.5696  decode.d8.loss_cls: 2.0360  decode.d8.loss_mask: 1.1112  decode.d8.loss_dice: 1.5790
2023/05/23 18:50:32 - mmengine - INFO - Iter(train) [  4400/160000]  lr: 9.7522e-06  eta: 18:41:55  time: 0.4043  data_time: 0.0095  memory: 4849  grad_norm: 98.2634  loss: 43.2340  decode.loss_cls: 1.9434  decode.loss_mask: 0.6910  decode.loss_dice: 1.4164  decode.d0.loss_cls: 3.6768  decode.d0.loss_mask: 0.8063  decode.d0.loss_dice: 1.6618  decode.d1.loss_cls: 2.0675  decode.d1.loss_mask: 0.7334  decode.d1.loss_dice: 1.5418  decode.d2.loss_cls: 1.9730  decode.d2.loss_mask: 0.7161  decode.d2.loss_dice: 1.4597  decode.d3.loss_cls: 1.9968  decode.d3.loss_mask: 0.7013  decode.d3.loss_dice: 1.4549  decode.d4.loss_cls: 2.0022  decode.d4.loss_mask: 0.7081  decode.d4.loss_dice: 1.4033  decode.d5.loss_cls: 1.9949  decode.d5.loss_mask: 0.7206  decode.d5.loss_dice: 1.4002  decode.d6.loss_cls: 1.9186  decode.d6.loss_mask: 0.7287  decode.d6.loss_dice: 1.4104  decode.d7.loss_cls: 1.9169  decode.d7.loss_mask: 0.7036  decode.d7.loss_dice: 1.4440  decode.d8.loss_cls: 1.9274  decode.d8.loss_mask: 0.6932  decode.d8.loss_dice: 1.4217
2023/05/23 18:50:54 - mmengine - INFO - Iter(train) [  4450/160000]  lr: 9.7494e-06  eta: 18:41:36  time: 0.4199  data_time: 0.0098  memory: 4877  grad_norm: 94.7315  loss: 49.2908  decode.loss_cls: 1.8410  decode.loss_mask: 1.0513  decode.loss_dice: 1.7486  decode.d0.loss_cls: 3.8699  decode.d0.loss_mask: 1.0977  decode.d0.loss_dice: 1.9920  decode.d1.loss_cls: 2.1400  decode.d1.loss_mask: 1.0400  decode.d1.loss_dice: 1.8175  decode.d2.loss_cls: 1.9718  decode.d2.loss_mask: 0.9799  decode.d2.loss_dice: 1.7784  decode.d3.loss_cls: 1.9282  decode.d3.loss_mask: 1.0116  decode.d3.loss_dice: 1.7647  decode.d4.loss_cls: 1.8266  decode.d4.loss_mask: 1.0801  decode.d4.loss_dice: 1.7989  decode.d5.loss_cls: 1.8434  decode.d5.loss_mask: 1.0443  decode.d5.loss_dice: 1.7999  decode.d6.loss_cls: 1.8625  decode.d6.loss_mask: 1.0477  decode.d6.loss_dice: 1.7824  decode.d7.loss_cls: 1.8177  decode.d7.loss_mask: 1.0097  decode.d7.loss_dice: 1.7689  decode.d8.loss_cls: 1.8329  decode.d8.loss_mask: 0.9827  decode.d8.loss_dice: 1.7603
2023/05/23 18:51:15 - mmengine - INFO - Iter(train) [  4500/160000]  lr: 9.7466e-06  eta: 18:40:36  time: 0.4046  data_time: 0.0093  memory: 4867  grad_norm: 96.1241  loss: 49.9859  decode.loss_cls: 1.7396  decode.loss_mask: 0.8933  decode.loss_dice: 2.0399  decode.d0.loss_cls: 3.7476  decode.d0.loss_mask: 0.9320  decode.d0.loss_dice: 2.2596  decode.d1.loss_cls: 1.8821  decode.d1.loss_mask: 0.9802  decode.d1.loss_dice: 2.0852  decode.d2.loss_cls: 1.8612  decode.d2.loss_mask: 0.9662  decode.d2.loss_dice: 2.0676  decode.d3.loss_cls: 1.8853  decode.d3.loss_mask: 0.9202  decode.d3.loss_dice: 2.0381  decode.d4.loss_cls: 1.7880  decode.d4.loss_mask: 0.9347  decode.d4.loss_dice: 2.0983  decode.d5.loss_cls: 1.7682  decode.d5.loss_mask: 0.9265  decode.d5.loss_dice: 2.0489  decode.d6.loss_cls: 1.7782  decode.d6.loss_mask: 0.9115  decode.d6.loss_dice: 2.0273  decode.d7.loss_cls: 1.7771  decode.d7.loss_mask: 0.8847  decode.d7.loss_dice: 2.0352  decode.d8.loss_cls: 1.8132  decode.d8.loss_mask: 0.8918  decode.d8.loss_dice: 2.0040
2023/05/23 18:51:35 - mmengine - INFO - Iter(train) [  4550/160000]  lr: 9.7437e-06  eta: 18:39:47  time: 0.4228  data_time: 0.0095  memory: 4829  grad_norm: 99.9566  loss: 60.9739  decode.loss_cls: 2.4281  decode.loss_mask: 1.2379  decode.loss_dice: 2.1790  decode.d0.loss_cls: 4.5608  decode.d0.loss_mask: 1.3919  decode.d0.loss_dice: 2.4816  decode.d1.loss_cls: 2.5317  decode.d1.loss_mask: 1.2579  decode.d1.loss_dice: 2.2692  decode.d2.loss_cls: 2.4075  decode.d2.loss_mask: 1.2189  decode.d2.loss_dice: 2.1358  decode.d3.loss_cls: 2.4018  decode.d3.loss_mask: 1.2185  decode.d3.loss_dice: 2.2129  decode.d4.loss_cls: 2.3817  decode.d4.loss_mask: 1.1956  decode.d4.loss_dice: 2.2057  decode.d5.loss_cls: 2.3562  decode.d5.loss_mask: 1.2121  decode.d5.loss_dice: 2.2111  decode.d6.loss_cls: 2.4259  decode.d6.loss_mask: 1.2433  decode.d6.loss_dice: 2.2023  decode.d7.loss_cls: 2.4244  decode.d7.loss_mask: 1.2128  decode.d7.loss_dice: 2.1868  decode.d8.loss_cls: 2.3596  decode.d8.loss_mask: 1.2381  decode.d8.loss_dice: 2.1846
2023/05/23 18:51:56 - mmengine - INFO - Iter(train) [  4600/160000]  lr: 9.7409e-06  eta: 18:38:49  time: 0.4128  data_time: 0.0093  memory: 4908  grad_norm: 146.3057  loss: 54.9570  decode.loss_cls: 2.1438  decode.loss_mask: 1.1518  decode.loss_dice: 1.9693  decode.d0.loss_cls: 4.1922  decode.d0.loss_mask: 1.1046  decode.d0.loss_dice: 2.2109  decode.d1.loss_cls: 2.3899  decode.d1.loss_mask: 1.1224  decode.d1.loss_dice: 2.0327  decode.d2.loss_cls: 2.2787  decode.d2.loss_mask: 1.1047  decode.d2.loss_dice: 1.9721  decode.d3.loss_cls: 2.1807  decode.d3.loss_mask: 1.1149  decode.d3.loss_dice: 1.9451  decode.d4.loss_cls: 2.1574  decode.d4.loss_mask: 1.1003  decode.d4.loss_dice: 1.9669  decode.d5.loss_cls: 2.1733  decode.d5.loss_mask: 1.1218  decode.d5.loss_dice: 1.9755  decode.d6.loss_cls: 2.1228  decode.d6.loss_mask: 1.1042  decode.d6.loss_dice: 1.9430  decode.d7.loss_cls: 2.1345  decode.d7.loss_mask: 1.1319  decode.d7.loss_dice: 1.9121  decode.d8.loss_cls: 2.1333  decode.d8.loss_mask: 1.1198  decode.d8.loss_dice: 1.9462
2023/05/23 18:52:17 - mmengine - INFO - Iter(train) [  4650/160000]  lr: 9.7381e-06  eta: 18:38:18  time: 0.4442  data_time: 0.0092  memory: 4844  grad_norm: 125.3559  loss: 45.6257  decode.loss_cls: 2.0674  decode.loss_mask: 0.8728  decode.loss_dice: 1.3861  decode.d0.loss_cls: 3.9048  decode.d0.loss_mask: 0.9315  decode.d0.loss_dice: 1.6787  decode.d1.loss_cls: 2.1585  decode.d1.loss_mask: 0.9177  decode.d1.loss_dice: 1.5143  decode.d2.loss_cls: 2.0398  decode.d2.loss_mask: 0.8925  decode.d2.loss_dice: 1.4593  decode.d3.loss_cls: 2.0198  decode.d3.loss_mask: 0.8865  decode.d3.loss_dice: 1.4359  decode.d4.loss_cls: 2.0497  decode.d4.loss_mask: 0.8784  decode.d4.loss_dice: 1.4107  decode.d5.loss_cls: 2.0157  decode.d5.loss_mask: 0.8709  decode.d5.loss_dice: 1.3880  decode.d6.loss_cls: 1.9128  decode.d6.loss_mask: 0.9277  decode.d6.loss_dice: 1.3760  decode.d7.loss_cls: 2.0057  decode.d7.loss_mask: 0.9231  decode.d7.loss_dice: 1.4125  decode.d8.loss_cls: 2.0392  decode.d8.loss_mask: 0.8734  decode.d8.loss_dice: 1.3763
2023/05/23 18:52:38 - mmengine - INFO - Iter(train) [  4700/160000]  lr: 9.7353e-06  eta: 18:37:42  time: 0.4100  data_time: 0.0095  memory: 4879  grad_norm: 125.4747  loss: 51.2898  decode.loss_cls: 2.0742  decode.loss_mask: 1.0920  decode.loss_dice: 1.7325  decode.d0.loss_cls: 3.8778  decode.d0.loss_mask: 1.1913  decode.d0.loss_dice: 2.0307  decode.d1.loss_cls: 2.1415  decode.d1.loss_mask: 1.1241  decode.d1.loss_dice: 1.8986  decode.d2.loss_cls: 1.9877  decode.d2.loss_mask: 1.1077  decode.d2.loss_dice: 1.8199  decode.d3.loss_cls: 2.0416  decode.d3.loss_mask: 1.0934  decode.d3.loss_dice: 1.7543  decode.d4.loss_cls: 1.9861  decode.d4.loss_mask: 1.0732  decode.d4.loss_dice: 1.7731  decode.d5.loss_cls: 2.0082  decode.d5.loss_mask: 1.0937  decode.d5.loss_dice: 1.7686  decode.d6.loss_cls: 2.0662  decode.d6.loss_mask: 1.0598  decode.d6.loss_dice: 1.7742  decode.d7.loss_cls: 2.0052  decode.d7.loss_mask: 1.0637  decode.d7.loss_dice: 1.7720  decode.d8.loss_cls: 2.0688  decode.d8.loss_mask: 1.0445  decode.d8.loss_dice: 1.7654
2023/05/23 18:52:59 - mmengine - INFO - Iter(train) [  4750/160000]  lr: 9.7325e-06  eta: 18:36:37  time: 0.4115  data_time: 0.0095  memory: 4909  grad_norm: 112.9536  loss: 48.6036  decode.loss_cls: 2.0068  decode.loss_mask: 1.0392  decode.loss_dice: 1.5111  decode.d0.loss_cls: 3.7427  decode.d0.loss_mask: 1.1103  decode.d0.loss_dice: 1.8023  decode.d1.loss_cls: 2.1542  decode.d1.loss_mask: 1.0578  decode.d1.loss_dice: 1.6536  decode.d2.loss_cls: 2.0357  decode.d2.loss_mask: 1.0689  decode.d2.loss_dice: 1.5855  decode.d3.loss_cls: 2.0420  decode.d3.loss_mask: 1.0175  decode.d3.loss_dice: 1.5179  decode.d4.loss_cls: 2.0764  decode.d4.loss_mask: 1.0829  decode.d4.loss_dice: 1.5727  decode.d5.loss_cls: 2.0786  decode.d5.loss_mask: 1.0561  decode.d5.loss_dice: 1.5485  decode.d6.loss_cls: 2.0076  decode.d6.loss_mask: 1.0564  decode.d6.loss_dice: 1.5423  decode.d7.loss_cls: 2.0352  decode.d7.loss_mask: 1.0691  decode.d7.loss_dice: 1.5647  decode.d8.loss_cls: 1.9585  decode.d8.loss_mask: 1.0699  decode.d8.loss_dice: 1.5391
2023/05/23 18:53:19 - mmengine - INFO - Iter(train) [  4800/160000]  lr: 9.7296e-06  eta: 18:35:39  time: 0.4156  data_time: 0.0101  memory: 4830  grad_norm: 113.2240  loss: 51.8795  decode.loss_cls: 2.0860  decode.loss_mask: 1.1007  decode.loss_dice: 1.6853  decode.d0.loss_cls: 3.9676  decode.d0.loss_mask: 1.1296  decode.d0.loss_dice: 1.9769  decode.d1.loss_cls: 2.1814  decode.d1.loss_mask: 1.1401  decode.d1.loss_dice: 1.9067  decode.d2.loss_cls: 2.2041  decode.d2.loss_mask: 1.1146  decode.d2.loss_dice: 1.7668  decode.d3.loss_cls: 2.1967  decode.d3.loss_mask: 1.1005  decode.d3.loss_dice: 1.7144  decode.d4.loss_cls: 2.1475  decode.d4.loss_mask: 1.1285  decode.d4.loss_dice: 1.7421  decode.d5.loss_cls: 2.1364  decode.d5.loss_mask: 1.0837  decode.d5.loss_dice: 1.7190  decode.d6.loss_cls: 2.0868  decode.d6.loss_mask: 1.0652  decode.d6.loss_dice: 1.6610  decode.d7.loss_cls: 2.1574  decode.d7.loss_mask: 1.0827  decode.d7.loss_dice: 1.7170  decode.d8.loss_cls: 2.1420  decode.d8.loss_mask: 1.0435  decode.d8.loss_dice: 1.6954
2023/05/23 18:53:40 - mmengine - INFO - Iter(train) [  4850/160000]  lr: 9.7268e-06  eta: 18:35:03  time: 0.4070  data_time: 0.0096  memory: 4838  grad_norm: 116.5475  loss: 47.5413  decode.loss_cls: 2.0143  decode.loss_mask: 1.1040  decode.loss_dice: 1.3376  decode.d0.loss_cls: 4.1431  decode.d0.loss_mask: 1.0691  decode.d0.loss_dice: 1.5883  decode.d1.loss_cls: 2.2765  decode.d1.loss_mask: 1.0728  decode.d1.loss_dice: 1.4112  decode.d2.loss_cls: 2.0892  decode.d2.loss_mask: 1.1002  decode.d2.loss_dice: 1.3756  decode.d3.loss_cls: 2.0577  decode.d3.loss_mask: 1.1065  decode.d3.loss_dice: 1.3653  decode.d4.loss_cls: 2.0398  decode.d4.loss_mask: 1.1163  decode.d4.loss_dice: 1.3834  decode.d5.loss_cls: 2.0744  decode.d5.loss_mask: 1.0788  decode.d5.loss_dice: 1.3564  decode.d6.loss_cls: 1.9833  decode.d6.loss_mask: 1.1286  decode.d6.loss_dice: 1.3653  decode.d7.loss_cls: 1.9893  decode.d7.loss_mask: 1.1117  decode.d7.loss_dice: 1.3712  decode.d8.loss_cls: 2.0089  decode.d8.loss_mask: 1.0848  decode.d8.loss_dice: 1.3376
2023/05/23 18:54:01 - mmengine - INFO - Iter(train) [  4900/160000]  lr: 9.7240e-06  eta: 18:34:12  time: 0.4154  data_time: 0.0098  memory: 4935  grad_norm: 89.6814  loss: 53.8690  decode.loss_cls: 2.2156  decode.loss_mask: 0.8742  decode.loss_dice: 1.8830  decode.d0.loss_cls: 4.5271  decode.d0.loss_mask: 0.9537  decode.d0.loss_dice: 2.3753  decode.d1.loss_cls: 2.5114  decode.d1.loss_mask: 0.9406  decode.d1.loss_dice: 2.0643  decode.d2.loss_cls: 2.3516  decode.d2.loss_mask: 0.9060  decode.d2.loss_dice: 1.9691  decode.d3.loss_cls: 2.2475  decode.d3.loss_mask: 0.9121  decode.d3.loss_dice: 1.8996  decode.d4.loss_cls: 2.2703  decode.d4.loss_mask: 0.9238  decode.d4.loss_dice: 1.9388  decode.d5.loss_cls: 2.2366  decode.d5.loss_mask: 0.9026  decode.d5.loss_dice: 1.9382  decode.d6.loss_cls: 2.2147  decode.d6.loss_mask: 0.8973  decode.d6.loss_dice: 1.8796  decode.d7.loss_cls: 2.2188  decode.d7.loss_mask: 0.9051  decode.d7.loss_dice: 1.9190  decode.d8.loss_cls: 2.1879  decode.d8.loss_mask: 0.8851  decode.d8.loss_dice: 1.9203
2023/05/23 18:54:22 - mmengine - INFO - Iter(train) [  4950/160000]  lr: 9.7212e-06  eta: 18:33:28  time: 0.4197  data_time: 0.0095  memory: 4839  grad_norm: 122.9838  loss: 42.9435  decode.loss_cls: 1.7044  decode.loss_mask: 0.9072  decode.loss_dice: 1.4242  decode.d0.loss_cls: 3.7030  decode.d0.loss_mask: 0.9559  decode.d0.loss_dice: 1.6262  decode.d1.loss_cls: 1.8750  decode.d1.loss_mask: 0.9285  decode.d1.loss_dice: 1.4957  decode.d2.loss_cls: 1.8280  decode.d2.loss_mask: 0.8328  decode.d2.loss_dice: 1.4230  decode.d3.loss_cls: 1.7980  decode.d3.loss_mask: 0.8216  decode.d3.loss_dice: 1.3972  decode.d4.loss_cls: 1.7559  decode.d4.loss_mask: 0.8464  decode.d4.loss_dice: 1.3834  decode.d5.loss_cls: 1.7664  decode.d5.loss_mask: 0.8363  decode.d5.loss_dice: 1.3870  decode.d6.loss_cls: 1.7815  decode.d6.loss_mask: 0.9045  decode.d6.loss_dice: 1.4496  decode.d7.loss_cls: 1.7635  decode.d7.loss_mask: 0.8923  decode.d7.loss_dice: 1.4314  decode.d8.loss_cls: 1.7201  decode.d8.loss_mask: 0.8817  decode.d8.loss_dice: 1.4225
2023/05/23 18:54:43 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 18:54:43 - mmengine - INFO - Iter(train) [  5000/160000]  lr: 9.7184e-06  eta: 18:33:01  time: 0.4092  data_time: 0.0092  memory: 4794  grad_norm: 108.9812  loss: 45.6712  decode.loss_cls: 2.0644  decode.loss_mask: 0.7972  decode.loss_dice: 1.4497  decode.d0.loss_cls: 4.0269  decode.d0.loss_mask: 0.7966  decode.d0.loss_dice: 1.7925  decode.d1.loss_cls: 2.2299  decode.d1.loss_mask: 0.7910  decode.d1.loss_dice: 1.6213  decode.d2.loss_cls: 2.1153  decode.d2.loss_mask: 0.7823  decode.d2.loss_dice: 1.5309  decode.d3.loss_cls: 2.0728  decode.d3.loss_mask: 0.7323  decode.d3.loss_dice: 1.5110  decode.d4.loss_cls: 2.0651  decode.d4.loss_mask: 0.7438  decode.d4.loss_dice: 1.4752  decode.d5.loss_cls: 2.1040  decode.d5.loss_mask: 0.7308  decode.d5.loss_dice: 1.4813  decode.d6.loss_cls: 2.0080  decode.d6.loss_mask: 0.7282  decode.d6.loss_dice: 1.4607  decode.d7.loss_cls: 2.0686  decode.d7.loss_mask: 0.7471  decode.d7.loss_dice: 1.4356  decode.d8.loss_cls: 2.0677  decode.d8.loss_mask: 0.7979  decode.d8.loss_dice: 1.4430
2023/05/23 18:54:43 - mmengine - INFO - Saving checkpoint at 5000 iterations
2023/05/23 18:55:04 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:02:54  time: 0.2802  data_time: 0.0021  memory: 13891  
2023/05/23 18:55:13 - mmengine - INFO - Iter(val) [100/625]    eta: 0:02:07  time: 0.0958  data_time: 0.0019  memory: 13899  
2023/05/23 18:55:20 - mmengine - INFO - Iter(val) [150/625]    eta: 0:01:37  time: 0.0798  data_time: 0.0020  memory: 13861  
2023/05/23 18:55:26 - mmengine - INFO - Iter(val) [200/625]    eta: 0:01:17  time: 0.0808  data_time: 0.0019  memory: 13883  
2023/05/23 18:55:32 - mmengine - INFO - Iter(val) [250/625]    eta: 0:01:03  time: 0.0818  data_time: 0.0021  memory: 13930  
2023/05/23 18:55:36 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:50  time: 0.1310  data_time: 0.0018  memory: 13861  
2023/05/23 18:55:40 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:40  time: 0.0802  data_time: 0.0018  memory: 2161  
2023/05/23 18:55:45 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:31  time: 0.0813  data_time: 0.0019  memory: 13880  
2023/05/23 18:55:50 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:23  time: 0.0936  data_time: 0.0024  memory: 13935  
2023/05/23 18:55:56 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:16  time: 0.0798  data_time: 0.0019  memory: 13914  
2023/05/23 18:56:01 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:09  time: 0.0787  data_time: 0.0019  memory: 13899  
2023/05/23 18:56:05 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:03  time: 0.0813  data_time: 0.0018  memory: 13913  
2023/05/23 18:56:11 - mmengine - INFO - per class results:
2023/05/23 18:56:11 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      |  83.2 | 90.95 |
|     bicycle      | 30.12 | 34.72 |
|       car        | 52.54 | 64.48 |
|    motorcycle    | 67.47 | 89.85 |
|     airplane     | 69.79 | 85.28 |
|       bus        | 61.98 | 91.14 |
|      train       | 64.76 | 70.81 |
|      truck       | 34.05 | 45.02 |
|       boat       | 47.78 | 63.46 |
|  traffic light   | 52.33 | 65.89 |
|   fire hydrant   | 59.95 | 77.69 |
|    stop sign     | 66.76 | 78.07 |
|  parking meter   | 67.32 | 70.45 |
|      bench       | 39.05 | 59.12 |
|       bird       | 74.32 | 84.32 |
|       cat        | 83.15 | 92.35 |
|       dog        | 65.78 | 88.22 |
|      horse       | 69.25 |  86.2 |
|      sheep       | 63.96 | 69.09 |
|       cow        | 57.89 |  68.3 |
|     elephant     | 85.22 | 91.64 |
|       bear       | 73.16 |  74.2 |
|      zebra       | 88.26 | 92.55 |
|     giraffe      | 81.31 | 89.23 |
|     backpack     |  9.08 | 13.49 |
|     umbrella     | 68.32 | 81.08 |
|     handbag      | 17.09 | 35.61 |
|       tie        |  0.91 |  0.98 |
|     suitcase     | 49.59 | 65.99 |
|     frisbee      | 53.95 | 75.32 |
|       skis       | 22.66 | 38.12 |
|    snowboard     | 17.12 | 37.29 |
|   sports ball    | 38.58 | 46.41 |
|       kite       |  38.4 | 45.84 |
|   baseball bat   | 33.32 | 43.67 |
|  baseball glove  | 44.46 | 54.98 |
|    skateboard    | 40.84 | 61.25 |
|    surfboard     | 61.54 | 81.13 |
|  tennis racket   | 60.14 | 81.54 |
|      bottle      | 37.19 | 59.18 |
|    wine glass    | 41.82 | 53.72 |
|       cup        | 41.43 | 62.17 |
|       fork       | 21.99 | 31.13 |
|      knife       |  7.92 | 12.67 |
|      spoon       |  1.64 |  1.77 |
|       bowl       | 30.58 | 40.03 |
|      banana      | 61.55 |  80.5 |
|      apple       | 30.44 | 38.59 |
|     sandwich     | 23.23 | 32.56 |
|      orange      | 62.17 | 71.95 |
|     broccoli     | 51.65 | 81.19 |
|      carrot      | 39.87 | 49.49 |
|     hot dog      |  37.0 | 39.65 |
|      pizza       | 54.67 | 63.56 |
|      donut       | 37.92 | 41.35 |
|       cake       | 21.24 | 22.73 |
|      chair       | 29.46 | 41.93 |
|      couch       | 38.04 | 58.47 |
|   potted plant   | 23.14 |  58.9 |
|       bed        |  46.3 | 78.72 |
|   dining table   | 33.46 | 81.68 |
|      toilet      | 65.05 | 89.15 |
|        tv        | 54.82 |  68.1 |
|      laptop      |  52.9 |  90.8 |
|      mouse       |  48.9 | 63.46 |
|      remote      | 21.41 | 30.25 |
|     keyboard     | 43.49 | 47.57 |
|    cell phone    | 51.88 | 75.41 |
|    microwave     | 12.93 | 14.49 |
|       oven       | 31.84 | 72.31 |
|     toaster      |  0.0  |  0.0  |
|       sink       | 45.35 | 61.52 |
|   refrigerator   |  51.2 | 67.58 |
|       book       | 32.22 | 44.75 |
|      clock       | 71.06 | 86.54 |
|       vase       | 42.91 | 79.75 |
|     scissors     | 18.28 | 20.53 |
|    teddy bear    |  68.5 | 80.18 |
|    hair drier    |  0.0  |  0.0  |
|    toothbrush    |  0.0  |  0.0  |
|      banner      | 22.51 | 50.08 |
|     blanket      |  0.0  |  0.0  |
|      branch      |  9.54 | 14.83 |
|      bridge      | 19.21 | 24.41 |
|  building-other  | 48.71 | 68.29 |
|       bush       | 23.69 |  30.4 |
|     cabinet      | 46.63 |  64.9 |
|       cage       |  3.15 |  3.42 |
|    cardboard     |  9.21 | 10.12 |
|      carpet      | 41.17 | 71.64 |
|  ceiling-other   | 52.56 | 69.52 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 10.66 | 14.57 |
|      clouds      | 44.01 | 55.93 |
|     counter      | 16.39 | 28.58 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 50.73 | 71.98 |
|    desk-stuff    | 36.53 |  59.8 |
|       dirt       | 38.59 | 71.41 |
|    door-stuff    |  23.6 | 46.67 |
|      fence       | 31.21 | 69.84 |
|   floor-marble   |  0.0  |  0.0  |
|   floor-other    | 16.39 | 24.93 |
|   floor-stone    |  0.0  |  0.0  |
|    floor-tile    | 48.26 | 55.93 |
|    floor-wood    | 52.09 | 71.89 |
|      flower      | 11.04 | 11.62 |
|       fog        |  0.0  |  0.0  |
|    food-other    |  23.3 | 35.57 |
|      fruit       | 10.64 | 12.39 |
| furniture-other  |  5.93 |  6.9  |
|      grass       | 66.57 | 83.79 |
|      gravel      | 15.29 | 23.55 |
|   ground-other   |  2.69 |  3.1  |
|       hill       | 13.09 | 17.66 |
|      house       | 11.93 | 12.82 |
|      leaves      |  6.57 |  7.12 |
|      light       | 26.54 | 47.63 |
|       mat        |  0.0  |  0.0  |
|      metal       | 23.09 | 39.67 |
|   mirror-stuff   |  17.6 |  25.1 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 48.37 |  61.9 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  0.0  |  0.0  |
|       net        | 38.49 | 52.06 |
|      paper       |  22.7 | 34.95 |
|     pavement     | 43.21 | 63.09 |
|      pillow      |  0.0  |  0.0  |
|   plant-other    | 13.61 | 22.72 |
|     plastic      |  6.04 |  6.88 |
|     platform     |  6.85 |  8.75 |
|   playingfield   | 63.02 | 78.41 |
|     railing      |  0.0  |  0.0  |
|     railroad     | 46.89 | 70.28 |
|      river       | 39.47 | 53.15 |
|       road       | 53.69 |  73.6 |
|       rock       | 42.68 | 70.21 |
|       roof       | 10.01 | 11.61 |
|       rug        | 10.33 | 12.23 |
|      salad       |  0.0  |  0.0  |
|       sand       | 52.97 |  66.8 |
|       sea        | 82.56 | 91.52 |
|      shelf       | 21.93 |  29.3 |
|    sky-other     | 68.49 | 86.87 |
|    skyscraper    | 17.22 | 19.55 |
|       snow       | 85.31 | 91.44 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      |  3.76 |  3.77 |
|      stone       |  0.0  |  0.0  |
|      straw       | 15.71 | 24.86 |
| structural-other |  0.0  |  0.0  |
|      table       | 10.88 |  13.7 |
|       tent       |  3.27 |  3.52 |
|  textile-other   |  5.59 |  7.46 |
|      towel       | 16.18 | 21.48 |
|       tree       | 70.49 | 86.89 |
|    vegetable     | 18.34 | 25.68 |
|    wall-brick    | 39.36 | 58.31 |
|  wall-concrete   | 27.08 | 30.83 |
|    wall-other    |  13.4 | 52.26 |
|    wall-panel    |  0.4  |  0.41 |
|    wall-stone    | 20.32 | 24.43 |
|    wall-tile     | 56.02 |  69.7 |
|    wall-wood     | 25.13 | 30.14 |
|   water-other    | 12.87 | 17.71 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 35.85 | 43.12 |
|   window-other   | 35.52 | 53.54 |
|       wood       | 15.54 | 21.13 |
+------------------+-------+-------+
2023/05/23 18:56:11 - mmengine - INFO - Iter(val) [625/625]    aAcc: 62.3700  mIoU: 33.1000  mAcc: 44.3300  data_time: 0.0024  time: 0.1280
2023/05/23 18:56:14 - mmengine - INFO - The best checkpoint with 33.1000 mIoU at 5000 iter is saved to best_mIoU_iter_5000.pth.
2023/05/23 18:56:38 - mmengine - INFO - Iter(train) [  5050/160000]  lr: 9.7155e-06  eta: 18:36:10  time: 0.4637  data_time: 0.0094  memory: 4836  grad_norm: 110.1273  loss: 47.1415  decode.loss_cls: 1.8631  decode.loss_mask: 1.0506  decode.loss_dice: 1.4895  decode.d0.loss_cls: 3.8284  decode.d0.loss_mask: 1.1109  decode.d0.loss_dice: 1.7033  decode.d1.loss_cls: 2.0323  decode.d1.loss_mask: 1.1491  decode.d1.loss_dice: 1.5729  decode.d2.loss_cls: 1.9412  decode.d2.loss_mask: 1.0524  decode.d2.loss_dice: 1.5044  decode.d3.loss_cls: 1.8001  decode.d3.loss_mask: 1.0903  decode.d3.loss_dice: 1.5212  decode.d4.loss_cls: 1.8333  decode.d4.loss_mask: 1.0865  decode.d4.loss_dice: 1.5328  decode.d5.loss_cls: 1.8582  decode.d5.loss_mask: 1.0862  decode.d5.loss_dice: 1.5491  decode.d6.loss_cls: 1.9088  decode.d6.loss_mask: 1.0516  decode.d6.loss_dice: 1.5032  decode.d7.loss_cls: 1.9863  decode.d7.loss_mask: 1.0544  decode.d7.loss_dice: 1.5212  decode.d8.loss_cls: 1.9005  decode.d8.loss_mask: 1.0424  decode.d8.loss_dice: 1.5174
2023/05/23 18:56:59 - mmengine - INFO - Iter(train) [  5100/160000]  lr: 9.7127e-06  eta: 18:35:42  time: 0.4078  data_time: 0.0095  memory: 4818  grad_norm: 130.4301  loss: 60.1454  decode.loss_cls: 2.3813  decode.loss_mask: 1.0890  decode.loss_dice: 2.3210  decode.d0.loss_cls: 4.5710  decode.d0.loss_mask: 1.0332  decode.d0.loss_dice: 2.5753  decode.d1.loss_cls: 2.5237  decode.d1.loss_mask: 1.0488  decode.d1.loss_dice: 2.4021  decode.d2.loss_cls: 2.4353  decode.d2.loss_mask: 1.0077  decode.d2.loss_dice: 2.3647  decode.d3.loss_cls: 2.3314  decode.d3.loss_mask: 1.0248  decode.d3.loss_dice: 2.3805  decode.d4.loss_cls: 2.4202  decode.d4.loss_mask: 1.0800  decode.d4.loss_dice: 2.3310  decode.d5.loss_cls: 2.4262  decode.d5.loss_mask: 1.0399  decode.d5.loss_dice: 2.3231  decode.d6.loss_cls: 2.2658  decode.d6.loss_mask: 1.0357  decode.d6.loss_dice: 2.3334  decode.d7.loss_cls: 2.3114  decode.d7.loss_mask: 1.0223  decode.d7.loss_dice: 2.3435  decode.d8.loss_cls: 2.3934  decode.d8.loss_mask: 1.0246  decode.d8.loss_dice: 2.3049
2023/05/23 18:57:20 - mmengine - INFO - Iter(train) [  5150/160000]  lr: 9.7099e-06  eta: 18:35:08  time: 0.4060  data_time: 0.0093  memory: 4912  grad_norm: 144.1428  loss: 37.4759  decode.loss_cls: 1.7593  decode.loss_mask: 0.6922  decode.loss_dice: 0.9767  decode.d0.loss_cls: 3.6083  decode.d0.loss_mask: 0.7609  decode.d0.loss_dice: 1.2385  decode.d1.loss_cls: 1.9164  decode.d1.loss_mask: 0.7215  decode.d1.loss_dice: 1.1077  decode.d2.loss_cls: 1.8033  decode.d2.loss_mask: 0.7684  decode.d2.loss_dice: 1.0773  decode.d3.loss_cls: 1.7892  decode.d3.loss_mask: 0.7511  decode.d3.loss_dice: 1.0319  decode.d4.loss_cls: 1.7701  decode.d4.loss_mask: 0.7305  decode.d4.loss_dice: 1.0176  decode.d5.loss_cls: 1.7380  decode.d5.loss_mask: 0.7311  decode.d5.loss_dice: 1.0535  decode.d6.loss_cls: 1.7938  decode.d6.loss_mask: 0.7042  decode.d6.loss_dice: 1.0171  decode.d7.loss_cls: 1.7918  decode.d7.loss_mask: 0.6897  decode.d7.loss_dice: 1.0025  decode.d8.loss_cls: 1.7492  decode.d8.loss_mask: 0.6782  decode.d8.loss_dice: 1.0058
2023/05/23 18:57:41 - mmengine - INFO - Iter(train) [  5200/160000]  lr: 9.7071e-06  eta: 18:34:13  time: 0.4052  data_time: 0.0092  memory: 4865  grad_norm: 125.1234  loss: 54.0788  decode.loss_cls: 2.0259  decode.loss_mask: 1.0698  decode.loss_dice: 2.0087  decode.d0.loss_cls: 4.1626  decode.d0.loss_mask: 1.1536  decode.d0.loss_dice: 2.2594  decode.d1.loss_cls: 2.0876  decode.d1.loss_mask: 1.1815  decode.d1.loss_dice: 2.0383  decode.d2.loss_cls: 1.9495  decode.d2.loss_mask: 1.1511  decode.d2.loss_dice: 1.9751  decode.d3.loss_cls: 1.9651  decode.d3.loss_mask: 1.1934  decode.d3.loss_dice: 2.0653  decode.d4.loss_cls: 1.9518  decode.d4.loss_mask: 1.1682  decode.d4.loss_dice: 2.0534  decode.d5.loss_cls: 1.9460  decode.d5.loss_mask: 1.1835  decode.d5.loss_dice: 2.0399  decode.d6.loss_cls: 1.9690  decode.d6.loss_mask: 1.1487  decode.d6.loss_dice: 1.9860  decode.d7.loss_cls: 1.9364  decode.d7.loss_mask: 1.1640  decode.d7.loss_dice: 2.0313  decode.d8.loss_cls: 1.9762  decode.d8.loss_mask: 1.1741  decode.d8.loss_dice: 2.0633
2023/05/23 18:58:02 - mmengine - INFO - Iter(train) [  5250/160000]  lr: 9.7043e-06  eta: 18:33:29  time: 0.4241  data_time: 0.0093  memory: 4855  grad_norm: 122.5774  loss: 48.8571  decode.loss_cls: 1.5825  decode.loss_mask: 1.2228  decode.loss_dice: 1.8793  decode.d0.loss_cls: 3.3718  decode.d0.loss_mask: 1.1540  decode.d0.loss_dice: 2.0289  decode.d1.loss_cls: 1.7563  decode.d1.loss_mask: 1.1430  decode.d1.loss_dice: 1.9451  decode.d2.loss_cls: 1.7175  decode.d2.loss_mask: 1.1413  decode.d2.loss_dice: 1.9024  decode.d3.loss_cls: 1.7267  decode.d3.loss_mask: 1.1349  decode.d3.loss_dice: 1.8264  decode.d4.loss_cls: 1.6594  decode.d4.loss_mask: 1.1773  decode.d4.loss_dice: 1.8632  decode.d5.loss_cls: 1.6427  decode.d5.loss_mask: 1.1752  decode.d5.loss_dice: 1.8536  decode.d6.loss_cls: 1.6262  decode.d6.loss_mask: 1.1568  decode.d6.loss_dice: 1.8620  decode.d7.loss_cls: 1.5981  decode.d7.loss_mask: 1.1624  decode.d7.loss_dice: 1.8826  decode.d8.loss_cls: 1.6318  decode.d8.loss_mask: 1.1726  decode.d8.loss_dice: 1.8602
2023/05/23 18:58:22 - mmengine - INFO - Iter(train) [  5300/160000]  lr: 9.7014e-06  eta: 18:32:41  time: 0.4185  data_time: 0.0096  memory: 4874  grad_norm: 112.0081  loss: 44.2816  decode.loss_cls: 1.8837  decode.loss_mask: 0.8247  decode.loss_dice: 1.4546  decode.d0.loss_cls: 3.7120  decode.d0.loss_mask: 0.7972  decode.d0.loss_dice: 1.6312  decode.d1.loss_cls: 1.9583  decode.d1.loss_mask: 0.8635  decode.d1.loss_dice: 1.5130  decode.d2.loss_cls: 1.9251  decode.d2.loss_mask: 0.8874  decode.d2.loss_dice: 1.4982  decode.d3.loss_cls: 1.8476  decode.d3.loss_mask: 0.9247  decode.d3.loss_dice: 1.5035  decode.d4.loss_cls: 1.9688  decode.d4.loss_mask: 0.8429  decode.d4.loss_dice: 1.4377  decode.d5.loss_cls: 1.9847  decode.d5.loss_mask: 0.8167  decode.d5.loss_dice: 1.4650  decode.d6.loss_cls: 1.8687  decode.d6.loss_mask: 0.8823  decode.d6.loss_dice: 1.4271  decode.d7.loss_cls: 1.9167  decode.d7.loss_mask: 0.8358  decode.d7.loss_dice: 1.4374  decode.d8.loss_cls: 1.9057  decode.d8.loss_mask: 0.8169  decode.d8.loss_dice: 1.4506
2023/05/23 18:58:43 - mmengine - INFO - Iter(train) [  5350/160000]  lr: 9.6986e-06  eta: 18:32:03  time: 0.4084  data_time: 0.0093  memory: 4837  grad_norm: 133.5569  loss: 57.1865  decode.loss_cls: 2.2302  decode.loss_mask: 1.1965  decode.loss_dice: 1.9956  decode.d0.loss_cls: 4.2370  decode.d0.loss_mask: 1.1993  decode.d0.loss_dice: 2.2516  decode.d1.loss_cls: 2.4226  decode.d1.loss_mask: 1.1756  decode.d1.loss_dice: 2.0910  decode.d2.loss_cls: 2.3223  decode.d2.loss_mask: 1.2112  decode.d2.loss_dice: 2.0378  decode.d3.loss_cls: 2.3160  decode.d3.loss_mask: 1.1868  decode.d3.loss_dice: 1.9790  decode.d4.loss_cls: 2.1991  decode.d4.loss_mask: 1.2459  decode.d4.loss_dice: 2.0491  decode.d5.loss_cls: 2.2481  decode.d5.loss_mask: 1.2295  decode.d5.loss_dice: 2.0024  decode.d6.loss_cls: 2.2331  decode.d6.loss_mask: 1.2376  decode.d6.loss_dice: 2.0049  decode.d7.loss_cls: 2.2182  decode.d7.loss_mask: 1.2247  decode.d7.loss_dice: 1.9688  decode.d8.loss_cls: 2.2709  decode.d8.loss_mask: 1.1964  decode.d8.loss_dice: 2.0054
2023/05/23 18:59:04 - mmengine - INFO - Iter(train) [  5400/160000]  lr: 9.6958e-06  eta: 18:31:11  time: 0.4060  data_time: 0.0098  memory: 4921  grad_norm: 108.1049  loss: 48.0761  decode.loss_cls: 2.0647  decode.loss_mask: 0.9388  decode.loss_dice: 1.4558  decode.d0.loss_cls: 4.0133  decode.d0.loss_mask: 1.0122  decode.d0.loss_dice: 1.8458  decode.d1.loss_cls: 2.2152  decode.d1.loss_mask: 1.0210  decode.d1.loss_dice: 1.6608  decode.d2.loss_cls: 2.0813  decode.d2.loss_mask: 1.0235  decode.d2.loss_dice: 1.5706  decode.d3.loss_cls: 2.1976  decode.d3.loss_mask: 0.9406  decode.d3.loss_dice: 1.4649  decode.d4.loss_cls: 2.2146  decode.d4.loss_mask: 0.9058  decode.d4.loss_dice: 1.4770  decode.d5.loss_cls: 2.0612  decode.d5.loss_mask: 0.9272  decode.d5.loss_dice: 1.4988  decode.d6.loss_cls: 2.0400  decode.d6.loss_mask: 0.9666  decode.d6.loss_dice: 1.4897  decode.d7.loss_cls: 2.0164  decode.d7.loss_mask: 0.9654  decode.d7.loss_dice: 1.5029  decode.d8.loss_cls: 2.0876  decode.d8.loss_mask: 0.9337  decode.d8.loss_dice: 1.4832
2023/05/23 18:59:24 - mmengine - INFO - Iter(train) [  5450/160000]  lr: 9.6930e-06  eta: 18:30:22  time: 0.4064  data_time: 0.0094  memory: 4911  grad_norm: 101.4415  loss: 46.1181  decode.loss_cls: 1.9577  decode.loss_mask: 0.8985  decode.loss_dice: 1.5737  decode.d0.loss_cls: 3.7158  decode.d0.loss_mask: 0.9413  decode.d0.loss_dice: 1.7306  decode.d1.loss_cls: 2.0664  decode.d1.loss_mask: 0.9544  decode.d1.loss_dice: 1.6526  decode.d2.loss_cls: 1.9707  decode.d2.loss_mask: 0.9110  decode.d2.loss_dice: 1.6124  decode.d3.loss_cls: 2.0264  decode.d3.loss_mask: 0.8965  decode.d3.loss_dice: 1.5345  decode.d4.loss_cls: 1.9721  decode.d4.loss_mask: 0.8870  decode.d4.loss_dice: 1.5665  decode.d5.loss_cls: 1.8924  decode.d5.loss_mask: 0.8918  decode.d5.loss_dice: 1.5370  decode.d6.loss_cls: 1.8816  decode.d6.loss_mask: 0.8741  decode.d6.loss_dice: 1.5232  decode.d7.loss_cls: 1.8881  decode.d7.loss_mask: 0.9075  decode.d7.loss_dice: 1.5234  decode.d8.loss_cls: 1.9595  decode.d8.loss_mask: 0.8605  decode.d8.loss_dice: 1.5111
2023/05/23 18:59:45 - mmengine - INFO - Iter(train) [  5500/160000]  lr: 9.6901e-06  eta: 18:29:44  time: 0.4108  data_time: 0.0092  memory: 4848  grad_norm: 112.5834  loss: 43.2876  decode.loss_cls: 1.7206  decode.loss_mask: 0.8767  decode.loss_dice: 1.5546  decode.d0.loss_cls: 3.5075  decode.d0.loss_mask: 0.8695  decode.d0.loss_dice: 1.7223  decode.d1.loss_cls: 1.8850  decode.d1.loss_mask: 0.8212  decode.d1.loss_dice: 1.5504  decode.d2.loss_cls: 1.8171  decode.d2.loss_mask: 0.8226  decode.d2.loss_dice: 1.5155  decode.d3.loss_cls: 1.7972  decode.d3.loss_mask: 0.7997  decode.d3.loss_dice: 1.5291  decode.d4.loss_cls: 1.7911  decode.d4.loss_mask: 0.7996  decode.d4.loss_dice: 1.5170  decode.d5.loss_cls: 1.7318  decode.d5.loss_mask: 0.8122  decode.d5.loss_dice: 1.5264  decode.d6.loss_cls: 1.7280  decode.d6.loss_mask: 0.8264  decode.d6.loss_dice: 1.5734  decode.d7.loss_cls: 1.7579  decode.d7.loss_mask: 0.8287  decode.d7.loss_dice: 1.5574  decode.d8.loss_cls: 1.6704  decode.d8.loss_mask: 0.8267  decode.d8.loss_dice: 1.5518
2023/05/23 19:00:07 - mmengine - INFO - Iter(train) [  5550/160000]  lr: 9.6873e-06  eta: 18:29:12  time: 0.4259  data_time: 0.0092  memory: 4918  grad_norm: 94.0114  loss: 52.0352  decode.loss_cls: 2.0644  decode.loss_mask: 1.0462  decode.loss_dice: 1.8405  decode.d0.loss_cls: 3.8707  decode.d0.loss_mask: 1.0153  decode.d0.loss_dice: 2.0756  decode.d1.loss_cls: 2.2368  decode.d1.loss_mask: 1.0264  decode.d1.loss_dice: 1.9682  decode.d2.loss_cls: 2.1625  decode.d2.loss_mask: 1.0499  decode.d2.loss_dice: 1.8511  decode.d3.loss_cls: 2.0654  decode.d3.loss_mask: 1.0476  decode.d3.loss_dice: 1.8509  decode.d4.loss_cls: 2.0262  decode.d4.loss_mask: 1.0493  decode.d4.loss_dice: 1.8651  decode.d5.loss_cls: 2.0654  decode.d5.loss_mask: 1.0702  decode.d5.loss_dice: 1.8511  decode.d6.loss_cls: 2.0654  decode.d6.loss_mask: 1.0479  decode.d6.loss_dice: 1.8609  decode.d7.loss_cls: 2.1089  decode.d7.loss_mask: 1.0271  decode.d7.loss_dice: 1.8544  decode.d8.loss_cls: 2.1230  decode.d8.loss_mask: 1.0153  decode.d8.loss_dice: 1.8337
2023/05/23 19:00:28 - mmengine - INFO - Iter(train) [  5600/160000]  lr: 9.6845e-06  eta: 18:29:02  time: 0.4569  data_time: 0.0092  memory: 4837  grad_norm: 106.1711  loss: 46.1917  decode.loss_cls: 1.9233  decode.loss_mask: 0.7899  decode.loss_dice: 1.6240  decode.d0.loss_cls: 3.8395  decode.d0.loss_mask: 0.8611  decode.d0.loss_dice: 1.9135  decode.d1.loss_cls: 2.0722  decode.d1.loss_mask: 0.8573  decode.d1.loss_dice: 1.7478  decode.d2.loss_cls: 1.8045  decode.d2.loss_mask: 0.8237  decode.d2.loss_dice: 1.6975  decode.d3.loss_cls: 1.8601  decode.d3.loss_mask: 0.8345  decode.d3.loss_dice: 1.6983  decode.d4.loss_cls: 1.9208  decode.d4.loss_mask: 0.8192  decode.d4.loss_dice: 1.7085  decode.d5.loss_cls: 1.8965  decode.d5.loss_mask: 0.8148  decode.d5.loss_dice: 1.7090  decode.d6.loss_cls: 1.8420  decode.d6.loss_mask: 0.7866  decode.d6.loss_dice: 1.6821  decode.d7.loss_cls: 1.8222  decode.d7.loss_mask: 0.8303  decode.d7.loss_dice: 1.7077  decode.d8.loss_cls: 1.8241  decode.d8.loss_mask: 0.7880  decode.d8.loss_dice: 1.6928
2023/05/23 19:00:49 - mmengine - INFO - Iter(train) [  5650/160000]  lr: 9.6817e-06  eta: 18:28:15  time: 0.4380  data_time: 0.0099  memory: 4857  grad_norm: 95.8230  loss: 39.5095  decode.loss_cls: 1.6178  decode.loss_mask: 0.6767  decode.loss_dice: 1.3809  decode.d0.loss_cls: 3.5995  decode.d0.loss_mask: 0.7161  decode.d0.loss_dice: 1.6027  decode.d1.loss_cls: 1.8352  decode.d1.loss_mask: 0.6645  decode.d1.loss_dice: 1.4120  decode.d2.loss_cls: 1.6635  decode.d2.loss_mask: 0.6887  decode.d2.loss_dice: 1.4526  decode.d3.loss_cls: 1.5867  decode.d3.loss_mask: 0.7024  decode.d3.loss_dice: 1.3799  decode.d4.loss_cls: 1.6527  decode.d4.loss_mask: 0.6735  decode.d4.loss_dice: 1.4122  decode.d5.loss_cls: 1.6954  decode.d5.loss_mask: 0.6565  decode.d5.loss_dice: 1.3745  decode.d6.loss_cls: 1.5728  decode.d6.loss_mask: 0.6773  decode.d6.loss_dice: 1.3760  decode.d7.loss_cls: 1.6502  decode.d7.loss_mask: 0.6681  decode.d7.loss_dice: 1.3852  decode.d8.loss_cls: 1.6694  decode.d8.loss_mask: 0.6538  decode.d8.loss_dice: 1.4126
2023/05/23 19:01:10 - mmengine - INFO - Iter(train) [  5700/160000]  lr: 9.6789e-06  eta: 18:27:30  time: 0.4078  data_time: 0.0094  memory: 4859  grad_norm: 95.9998  loss: 56.1471  decode.loss_cls: 2.1943  decode.loss_mask: 0.9822  decode.loss_dice: 1.9800  decode.d0.loss_cls: 4.3687  decode.d0.loss_mask: 1.0978  decode.d0.loss_dice: 2.3429  decode.d1.loss_cls: 2.5935  decode.d1.loss_mask: 1.0487  decode.d1.loss_dice: 2.1927  decode.d2.loss_cls: 2.3794  decode.d2.loss_mask: 1.0597  decode.d2.loss_dice: 2.1343  decode.d3.loss_cls: 2.3306  decode.d3.loss_mask: 1.0441  decode.d3.loss_dice: 2.0581  decode.d4.loss_cls: 2.2752  decode.d4.loss_mask: 1.0341  decode.d4.loss_dice: 2.0566  decode.d5.loss_cls: 2.1970  decode.d5.loss_mask: 1.0117  decode.d5.loss_dice: 2.0168  decode.d6.loss_cls: 2.2727  decode.d6.loss_mask: 1.0394  decode.d6.loss_dice: 2.0041  decode.d7.loss_cls: 2.2518  decode.d7.loss_mask: 1.0129  decode.d7.loss_dice: 2.0063  decode.d8.loss_cls: 2.1593  decode.d8.loss_mask: 1.0041  decode.d8.loss_dice: 1.9983
2023/05/23 19:01:32 - mmengine - INFO - Iter(train) [  5750/160000]  lr: 9.6760e-06  eta: 18:27:34  time: 0.4658  data_time: 0.0102  memory: 4836  grad_norm: 98.5362  loss: 51.0036  decode.loss_cls: 2.1199  decode.loss_mask: 1.1398  decode.loss_dice: 1.6337  decode.d0.loss_cls: 4.0531  decode.d0.loss_mask: 1.1670  decode.d0.loss_dice: 1.8398  decode.d1.loss_cls: 2.3547  decode.d1.loss_mask: 1.1853  decode.d1.loss_dice: 1.7203  decode.d2.loss_cls: 2.1490  decode.d2.loss_mask: 1.1104  decode.d2.loss_dice: 1.6623  decode.d3.loss_cls: 2.1040  decode.d3.loss_mask: 1.0833  decode.d3.loss_dice: 1.5601  decode.d4.loss_cls: 2.0547  decode.d4.loss_mask: 1.1084  decode.d4.loss_dice: 1.6224  decode.d5.loss_cls: 2.1048  decode.d5.loss_mask: 1.1425  decode.d5.loss_dice: 1.6447  decode.d6.loss_cls: 2.0987  decode.d6.loss_mask: 1.1031  decode.d6.loss_dice: 1.5982  decode.d7.loss_cls: 2.0607  decode.d7.loss_mask: 1.1284  decode.d7.loss_dice: 1.6279  decode.d8.loss_cls: 2.0152  decode.d8.loss_mask: 1.1580  decode.d8.loss_dice: 1.6532
2023/05/23 19:01:54 - mmengine - INFO - Iter(train) [  5800/160000]  lr: 9.6732e-06  eta: 18:27:19  time: 0.4114  data_time: 0.0095  memory: 4876  grad_norm: 94.6324  loss: 45.0196  decode.loss_cls: 1.6923  decode.loss_mask: 0.9211  decode.loss_dice: 1.5823  decode.d0.loss_cls: 3.7858  decode.d0.loss_mask: 0.9090  decode.d0.loss_dice: 1.8157  decode.d1.loss_cls: 2.0018  decode.d1.loss_mask: 0.9185  decode.d1.loss_dice: 1.6892  decode.d2.loss_cls: 1.8355  decode.d2.loss_mask: 0.9317  decode.d2.loss_dice: 1.5891  decode.d3.loss_cls: 1.8006  decode.d3.loss_mask: 0.9452  decode.d3.loss_dice: 1.6304  decode.d4.loss_cls: 1.7603  decode.d4.loss_mask: 0.9524  decode.d4.loss_dice: 1.5999  decode.d5.loss_cls: 1.7122  decode.d5.loss_mask: 0.9454  decode.d5.loss_dice: 1.5690  decode.d6.loss_cls: 1.6771  decode.d6.loss_mask: 0.9445  decode.d6.loss_dice: 1.5936  decode.d7.loss_cls: 1.6879  decode.d7.loss_mask: 0.8820  decode.d7.loss_dice: 1.5428  decode.d8.loss_cls: 1.6276  decode.d8.loss_mask: 0.9039  decode.d8.loss_dice: 1.5727
2023/05/23 19:02:15 - mmengine - INFO - Iter(train) [  5850/160000]  lr: 9.6704e-06  eta: 18:26:43  time: 0.4386  data_time: 0.0096  memory: 4809  grad_norm: 103.9846  loss: 34.7608  decode.loss_cls: 1.3537  decode.loss_mask: 0.8486  decode.loss_dice: 1.0017  decode.d0.loss_cls: 3.2687  decode.d0.loss_mask: 0.8349  decode.d0.loss_dice: 1.1816  decode.d1.loss_cls: 1.5469  decode.d1.loss_mask: 0.8775  decode.d1.loss_dice: 1.0434  decode.d2.loss_cls: 1.3962  decode.d2.loss_mask: 0.9004  decode.d2.loss_dice: 1.0456  decode.d3.loss_cls: 1.3732  decode.d3.loss_mask: 0.8771  decode.d3.loss_dice: 1.0137  decode.d4.loss_cls: 1.3980  decode.d4.loss_mask: 0.8196  decode.d4.loss_dice: 1.0275  decode.d5.loss_cls: 1.3791  decode.d5.loss_mask: 0.8485  decode.d5.loss_dice: 1.0451  decode.d6.loss_cls: 1.3269  decode.d6.loss_mask: 0.8507  decode.d6.loss_dice: 1.0095  decode.d7.loss_cls: 1.3492  decode.d7.loss_mask: 0.8273  decode.d7.loss_dice: 1.0209  decode.d8.loss_cls: 1.4355  decode.d8.loss_mask: 0.8261  decode.d8.loss_dice: 1.0339
2023/05/23 19:02:37 - mmengine - INFO - Iter(train) [  5900/160000]  lr: 9.6676e-06  eta: 18:26:26  time: 0.4068  data_time: 0.0094  memory: 4896  grad_norm: 193.6108  loss: 48.6263  decode.loss_cls: 1.8017  decode.loss_mask: 0.9698  decode.loss_dice: 1.6974  decode.d0.loss_cls: 3.8826  decode.d0.loss_mask: 1.0309  decode.d0.loss_dice: 1.9795  decode.d1.loss_cls: 2.1679  decode.d1.loss_mask: 1.0406  decode.d1.loss_dice: 1.9055  decode.d2.loss_cls: 1.9521  decode.d2.loss_mask: 0.9899  decode.d2.loss_dice: 1.8143  decode.d3.loss_cls: 1.8591  decode.d3.loss_mask: 0.9703  decode.d3.loss_dice: 1.7193  decode.d4.loss_cls: 1.8607  decode.d4.loss_mask: 0.9727  decode.d4.loss_dice: 1.7040  decode.d5.loss_cls: 1.8325  decode.d5.loss_mask: 0.9792  decode.d5.loss_dice: 1.7509  decode.d6.loss_cls: 1.8511  decode.d6.loss_mask: 0.9914  decode.d6.loss_dice: 1.7390  decode.d7.loss_cls: 1.8808  decode.d7.loss_mask: 1.0000  decode.d7.loss_dice: 1.7124  decode.d8.loss_cls: 1.8306  decode.d8.loss_mask: 0.9861  decode.d8.loss_dice: 1.7539
2023/05/23 19:02:58 - mmengine - INFO - Iter(train) [  5950/160000]  lr: 9.6647e-06  eta: 18:25:54  time: 0.4035  data_time: 0.0092  memory: 4845  grad_norm: 94.5628  loss: 47.7895  decode.loss_cls: 2.0535  decode.loss_mask: 0.9091  decode.loss_dice: 1.6122  decode.d0.loss_cls: 3.9503  decode.d0.loss_mask: 0.9446  decode.d0.loss_dice: 1.8045  decode.d1.loss_cls: 2.2365  decode.d1.loss_mask: 0.9937  decode.d1.loss_dice: 1.6943  decode.d2.loss_cls: 2.0695  decode.d2.loss_mask: 0.9027  decode.d2.loss_dice: 1.6315  decode.d3.loss_cls: 2.0372  decode.d3.loss_mask: 0.9141  decode.d3.loss_dice: 1.6385  decode.d4.loss_cls: 1.9226  decode.d4.loss_mask: 0.9011  decode.d4.loss_dice: 1.6311  decode.d5.loss_cls: 1.9664  decode.d5.loss_mask: 0.9119  decode.d5.loss_dice: 1.5947  decode.d6.loss_cls: 1.9761  decode.d6.loss_mask: 0.9077  decode.d6.loss_dice: 1.5896  decode.d7.loss_cls: 1.9935  decode.d7.loss_mask: 0.8893  decode.d7.loss_dice: 1.6109  decode.d8.loss_cls: 2.0322  decode.d8.loss_mask: 0.8924  decode.d8.loss_dice: 1.5778
2023/05/23 19:03:18 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 19:03:18 - mmengine - INFO - Iter(train) [  6000/160000]  lr: 9.6619e-06  eta: 18:25:03  time: 0.4005  data_time: 0.0094  memory: 4867  grad_norm: 110.3784  loss: 41.7029  decode.loss_cls: 1.6151  decode.loss_mask: 1.0289  decode.loss_dice: 1.3748  decode.d0.loss_cls: 3.1809  decode.d0.loss_mask: 1.0533  decode.d0.loss_dice: 1.4793  decode.d1.loss_cls: 1.7639  decode.d1.loss_mask: 0.9859  decode.d1.loss_dice: 1.3681  decode.d2.loss_cls: 1.6036  decode.d2.loss_mask: 1.0067  decode.d2.loss_dice: 1.3413  decode.d3.loss_cls: 1.6214  decode.d3.loss_mask: 1.0308  decode.d3.loss_dice: 1.3225  decode.d4.loss_cls: 1.5931  decode.d4.loss_mask: 1.0187  decode.d4.loss_dice: 1.3337  decode.d5.loss_cls: 1.5817  decode.d5.loss_mask: 1.0125  decode.d5.loss_dice: 1.3291  decode.d6.loss_cls: 1.6645  decode.d6.loss_mask: 1.0576  decode.d6.loss_dice: 1.3479  decode.d7.loss_cls: 1.5785  decode.d7.loss_mask: 1.0475  decode.d7.loss_dice: 1.3600  decode.d8.loss_cls: 1.6318  decode.d8.loss_mask: 1.0249  decode.d8.loss_dice: 1.3447
2023/05/23 19:03:18 - mmengine - INFO - Saving checkpoint at 6000 iterations
2023/05/23 19:03:44 - mmengine - INFO - Iter(train) [  6050/160000]  lr: 9.6591e-06  eta: 18:26:24  time: 0.4060  data_time: 0.0092  memory: 4856  grad_norm: 98.9554  loss: 48.5519  decode.loss_cls: 2.1735  decode.loss_mask: 0.9565  decode.loss_dice: 1.5464  decode.d0.loss_cls: 3.8504  decode.d0.loss_mask: 0.9673  decode.d0.loss_dice: 1.7771  decode.d1.loss_cls: 2.1963  decode.d1.loss_mask: 0.9900  decode.d1.loss_dice: 1.6342  decode.d2.loss_cls: 2.1165  decode.d2.loss_mask: 0.9995  decode.d2.loss_dice: 1.5723  decode.d3.loss_cls: 2.0436  decode.d3.loss_mask: 0.9904  decode.d3.loss_dice: 1.5904  decode.d4.loss_cls: 2.0558  decode.d4.loss_mask: 0.9612  decode.d4.loss_dice: 1.5890  decode.d5.loss_cls: 2.1360  decode.d5.loss_mask: 0.9287  decode.d5.loss_dice: 1.5465  decode.d6.loss_cls: 2.1310  decode.d6.loss_mask: 0.9386  decode.d6.loss_dice: 1.5664  decode.d7.loss_cls: 2.1341  decode.d7.loss_mask: 0.9485  decode.d7.loss_dice: 1.5698  decode.d8.loss_cls: 2.1391  decode.d8.loss_mask: 0.9566  decode.d8.loss_dice: 1.5463
2023/05/23 19:04:04 - mmengine - INFO - Iter(train) [  6100/160000]  lr: 9.6563e-06  eta: 18:25:38  time: 0.4102  data_time: 0.0094  memory: 4854  grad_norm: 119.5143  loss: 36.2530  decode.loss_cls: 1.3433  decode.loss_mask: 0.6991  decode.loss_dice: 1.2579  decode.d0.loss_cls: 3.4291  decode.d0.loss_mask: 0.7934  decode.d0.loss_dice: 1.4620  decode.d1.loss_cls: 1.4768  decode.d1.loss_mask: 0.8073  decode.d1.loss_dice: 1.4001  decode.d2.loss_cls: 1.4248  decode.d2.loss_mask: 0.7424  decode.d2.loss_dice: 1.3222  decode.d3.loss_cls: 1.3819  decode.d3.loss_mask: 0.7352  decode.d3.loss_dice: 1.2806  decode.d4.loss_cls: 1.3675  decode.d4.loss_mask: 0.7214  decode.d4.loss_dice: 1.2943  decode.d5.loss_cls: 1.3540  decode.d5.loss_mask: 0.7090  decode.d5.loss_dice: 1.2793  decode.d6.loss_cls: 1.3666  decode.d6.loss_mask: 0.7136  decode.d6.loss_dice: 1.2392  decode.d7.loss_cls: 1.3420  decode.d7.loss_mask: 0.7337  decode.d7.loss_dice: 1.2736  decode.d8.loss_cls: 1.3351  decode.d8.loss_mask: 0.7203  decode.d8.loss_dice: 1.2470
2023/05/23 19:04:26 - mmengine - INFO - Iter(train) [  6150/160000]  lr: 9.6534e-06  eta: 18:25:14  time: 0.4054  data_time: 0.0092  memory: 4838  grad_norm: 115.8799  loss: 54.1891  decode.loss_cls: 2.1445  decode.loss_mask: 0.9734  decode.loss_dice: 2.0245  decode.d0.loss_cls: 4.2630  decode.d0.loss_mask: 0.9651  decode.d0.loss_dice: 2.2503  decode.d1.loss_cls: 2.3699  decode.d1.loss_mask: 1.0040  decode.d1.loss_dice: 2.1542  decode.d2.loss_cls: 2.2377  decode.d2.loss_mask: 0.9702  decode.d2.loss_dice: 2.0098  decode.d3.loss_cls: 2.1664  decode.d3.loss_mask: 0.9401  decode.d3.loss_dice: 1.9455  decode.d4.loss_cls: 2.1802  decode.d4.loss_mask: 0.9523  decode.d4.loss_dice: 2.0178  decode.d5.loss_cls: 2.2147  decode.d5.loss_mask: 0.9448  decode.d5.loss_dice: 2.0129  decode.d6.loss_cls: 2.1755  decode.d6.loss_mask: 1.0012  decode.d6.loss_dice: 1.9566  decode.d7.loss_cls: 2.1664  decode.d7.loss_mask: 0.9815  decode.d7.loss_dice: 1.9970  decode.d8.loss_cls: 2.1594  decode.d8.loss_mask: 0.9894  decode.d8.loss_dice: 2.0209
2023/05/23 19:04:47 - mmengine - INFO - Iter(train) [  6200/160000]  lr: 9.6506e-06  eta: 18:24:31  time: 0.4187  data_time: 0.0102  memory: 4787  grad_norm: 111.5381  loss: 50.6812  decode.loss_cls: 1.9190  decode.loss_mask: 0.9903  decode.loss_dice: 1.8346  decode.d0.loss_cls: 3.8277  decode.d0.loss_mask: 1.0254  decode.d0.loss_dice: 2.0698  decode.d1.loss_cls: 2.1155  decode.d1.loss_mask: 1.0733  decode.d1.loss_dice: 1.9741  decode.d2.loss_cls: 1.9078  decode.d2.loss_mask: 1.0504  decode.d2.loss_dice: 1.9341  decode.d3.loss_cls: 1.8899  decode.d3.loss_mask: 1.0395  decode.d3.loss_dice: 1.8682  decode.d4.loss_cls: 1.9938  decode.d4.loss_mask: 1.0328  decode.d4.loss_dice: 1.8585  decode.d5.loss_cls: 1.9784  decode.d5.loss_mask: 1.0024  decode.d5.loss_dice: 1.8787  decode.d6.loss_cls: 1.9602  decode.d6.loss_mask: 1.0249  decode.d6.loss_dice: 1.8475  decode.d7.loss_cls: 1.9741  decode.d7.loss_mask: 0.9970  decode.d7.loss_dice: 1.8096  decode.d8.loss_cls: 1.9441  decode.d8.loss_mask: 1.0063  decode.d8.loss_dice: 1.8531
2023/05/23 19:05:08 - mmengine - INFO - Iter(train) [  6250/160000]  lr: 9.6478e-06  eta: 18:24:13  time: 0.4102  data_time: 0.0098  memory: 4844  grad_norm: 111.5869  loss: 28.8256  decode.loss_cls: 0.9551  decode.loss_mask: 0.7685  decode.loss_dice: 0.9006  decode.d0.loss_cls: 2.8284  decode.d0.loss_mask: 0.7880  decode.d0.loss_dice: 1.0498  decode.d1.loss_cls: 1.2169  decode.d1.loss_mask: 0.7763  decode.d1.loss_dice: 0.9999  decode.d2.loss_cls: 0.9955  decode.d2.loss_mask: 0.7592  decode.d2.loss_dice: 0.9606  decode.d3.loss_cls: 0.9423  decode.d3.loss_mask: 0.7458  decode.d3.loss_dice: 0.9188  decode.d4.loss_cls: 0.9921  decode.d4.loss_mask: 0.7215  decode.d4.loss_dice: 0.9095  decode.d5.loss_cls: 0.9751  decode.d5.loss_mask: 0.7346  decode.d5.loss_dice: 0.9032  decode.d6.loss_cls: 0.9958  decode.d6.loss_mask: 0.7699  decode.d6.loss_dice: 0.9161  decode.d7.loss_cls: 0.9715  decode.d7.loss_mask: 0.7586  decode.d7.loss_dice: 0.9017  decode.d8.loss_cls: 0.9565  decode.d8.loss_mask: 0.7814  decode.d8.loss_dice: 0.9324
2023/05/23 19:05:29 - mmengine - INFO - Iter(train) [  6300/160000]  lr: 9.6450e-06  eta: 18:23:28  time: 0.4062  data_time: 0.0094  memory: 4918  grad_norm: 111.6774  loss: 36.9905  decode.loss_cls: 1.5270  decode.loss_mask: 0.7801  decode.loss_dice: 1.1040  decode.d0.loss_cls: 3.4359  decode.d0.loss_mask: 0.8392  decode.d0.loss_dice: 1.2633  decode.d1.loss_cls: 1.6127  decode.d1.loss_mask: 0.8397  decode.d1.loss_dice: 1.2064  decode.d2.loss_cls: 1.5880  decode.d2.loss_mask: 0.8019  decode.d2.loss_dice: 1.1429  decode.d3.loss_cls: 1.5413  decode.d3.loss_mask: 0.8132  decode.d3.loss_dice: 1.1539  decode.d4.loss_cls: 1.4446  decode.d4.loss_mask: 0.8323  decode.d4.loss_dice: 1.1748  decode.d5.loss_cls: 1.5074  decode.d5.loss_mask: 0.8539  decode.d5.loss_dice: 1.1397  decode.d6.loss_cls: 1.4976  decode.d6.loss_mask: 0.8264  decode.d6.loss_dice: 1.1231  decode.d7.loss_cls: 1.5268  decode.d7.loss_mask: 0.8228  decode.d7.loss_dice: 1.1188  decode.d8.loss_cls: 1.5563  decode.d8.loss_mask: 0.7840  decode.d8.loss_dice: 1.1324
2023/05/23 19:05:49 - mmengine - INFO - Iter(train) [  6350/160000]  lr: 9.6421e-06  eta: 18:22:39  time: 0.4064  data_time: 0.0093  memory: 4899  grad_norm: 101.9605  loss: 42.9233  decode.loss_cls: 1.7379  decode.loss_mask: 0.8792  decode.loss_dice: 1.4706  decode.d0.loss_cls: 3.6445  decode.d0.loss_mask: 0.9384  decode.d0.loss_dice: 1.6731  decode.d1.loss_cls: 1.8338  decode.d1.loss_mask: 0.8918  decode.d1.loss_dice: 1.5297  decode.d2.loss_cls: 1.7001  decode.d2.loss_mask: 0.9108  decode.d2.loss_dice: 1.5024  decode.d3.loss_cls: 1.7126  decode.d3.loss_mask: 0.8605  decode.d3.loss_dice: 1.4498  decode.d4.loss_cls: 1.6826  decode.d4.loss_mask: 0.8763  decode.d4.loss_dice: 1.4885  decode.d5.loss_cls: 1.7062  decode.d5.loss_mask: 0.8545  decode.d5.loss_dice: 1.4559  decode.d6.loss_cls: 1.6892  decode.d6.loss_mask: 0.8610  decode.d6.loss_dice: 1.4517  decode.d7.loss_cls: 1.6997  decode.d7.loss_mask: 0.8851  decode.d7.loss_dice: 1.4616  decode.d8.loss_cls: 1.7155  decode.d8.loss_mask: 0.8808  decode.d8.loss_dice: 1.4796
2023/05/23 19:06:10 - mmengine - INFO - Iter(train) [  6400/160000]  lr: 9.6393e-06  eta: 18:21:59  time: 0.4128  data_time: 0.0095  memory: 4878  grad_norm: 143.0480  loss: 44.7071  decode.loss_cls: 1.7411  decode.loss_mask: 0.8557  decode.loss_dice: 1.5918  decode.d0.loss_cls: 3.7564  decode.d0.loss_mask: 0.9339  decode.d0.loss_dice: 1.8401  decode.d1.loss_cls: 1.9145  decode.d1.loss_mask: 0.9499  decode.d1.loss_dice: 1.7101  decode.d2.loss_cls: 1.8733  decode.d2.loss_mask: 0.8781  decode.d2.loss_dice: 1.6574  decode.d3.loss_cls: 1.7677  decode.d3.loss_mask: 0.8384  decode.d3.loss_dice: 1.5830  decode.d4.loss_cls: 1.7781  decode.d4.loss_mask: 0.8395  decode.d4.loss_dice: 1.5422  decode.d5.loss_cls: 1.8004  decode.d5.loss_mask: 0.8442  decode.d5.loss_dice: 1.5852  decode.d6.loss_cls: 1.7614  decode.d6.loss_mask: 0.8466  decode.d6.loss_dice: 1.5705  decode.d7.loss_cls: 1.7514  decode.d7.loss_mask: 0.8457  decode.d7.loss_dice: 1.5611  decode.d8.loss_cls: 1.6916  decode.d8.loss_mask: 0.8307  decode.d8.loss_dice: 1.5672
2023/05/23 19:06:32 - mmengine - INFO - Iter(train) [  6450/160000]  lr: 9.6365e-06  eta: 18:21:48  time: 0.4183  data_time: 0.0095  memory: 4820  grad_norm: 132.4999  loss: 42.1957  decode.loss_cls: 1.8130  decode.loss_mask: 0.9063  decode.loss_dice: 1.2182  decode.d0.loss_cls: 3.5691  decode.d0.loss_mask: 1.0227  decode.d0.loss_dice: 1.4324  decode.d1.loss_cls: 1.9129  decode.d1.loss_mask: 0.9749  decode.d1.loss_dice: 1.3052  decode.d2.loss_cls: 1.8597  decode.d2.loss_mask: 0.9659  decode.d2.loss_dice: 1.2719  decode.d3.loss_cls: 1.8621  decode.d3.loss_mask: 0.9372  decode.d3.loss_dice: 1.2575  decode.d4.loss_cls: 1.8445  decode.d4.loss_mask: 0.9586  decode.d4.loss_dice: 1.2407  decode.d5.loss_cls: 1.9075  decode.d5.loss_mask: 0.9334  decode.d5.loss_dice: 1.2491  decode.d6.loss_cls: 1.8130  decode.d6.loss_mask: 0.9484  decode.d6.loss_dice: 1.2154  decode.d7.loss_cls: 1.7646  decode.d7.loss_mask: 0.8925  decode.d7.loss_dice: 1.2066  decode.d8.loss_cls: 1.7805  decode.d8.loss_mask: 0.9034  decode.d8.loss_dice: 1.2285
2023/05/23 19:06:53 - mmengine - INFO - Iter(train) [  6500/160000]  lr: 9.6337e-06  eta: 18:21:22  time: 0.4647  data_time: 0.0101  memory: 4868  grad_norm: 108.5420  loss: 38.7428  decode.loss_cls: 1.6228  decode.loss_mask: 0.9018  decode.loss_dice: 1.1805  decode.d0.loss_cls: 3.6012  decode.d0.loss_mask: 0.9542  decode.d0.loss_dice: 1.3082  decode.d1.loss_cls: 1.6864  decode.d1.loss_mask: 0.9435  decode.d1.loss_dice: 1.2667  decode.d2.loss_cls: 1.6319  decode.d2.loss_mask: 0.8599  decode.d2.loss_dice: 1.1954  decode.d3.loss_cls: 1.5680  decode.d3.loss_mask: 0.8547  decode.d3.loss_dice: 1.1990  decode.d4.loss_cls: 1.5752  decode.d4.loss_mask: 0.8501  decode.d4.loss_dice: 1.1289  decode.d5.loss_cls: 1.5519  decode.d5.loss_mask: 0.8545  decode.d5.loss_dice: 1.1509  decode.d6.loss_cls: 1.6447  decode.d6.loss_mask: 0.8487  decode.d6.loss_dice: 1.1382  decode.d7.loss_cls: 1.5919  decode.d7.loss_mask: 0.8710  decode.d7.loss_dice: 1.1419  decode.d8.loss_cls: 1.5681  decode.d8.loss_mask: 0.8666  decode.d8.loss_dice: 1.1862
2023/05/23 19:07:14 - mmengine - INFO - Iter(train) [  6550/160000]  lr: 9.6309e-06  eta: 18:20:36  time: 0.4102  data_time: 0.0097  memory: 4828  grad_norm: 104.0782  loss: 45.6323  decode.loss_cls: 1.9002  decode.loss_mask: 0.9574  decode.loss_dice: 1.3395  decode.d0.loss_cls: 3.9256  decode.d0.loss_mask: 1.0154  decode.d0.loss_dice: 1.5776  decode.d1.loss_cls: 2.2252  decode.d1.loss_mask: 1.0239  decode.d1.loss_dice: 1.4462  decode.d2.loss_cls: 2.1655  decode.d2.loss_mask: 1.0060  decode.d2.loss_dice: 1.3846  decode.d3.loss_cls: 2.0339  decode.d3.loss_mask: 0.9315  decode.d3.loss_dice: 1.3585  decode.d4.loss_cls: 1.9727  decode.d4.loss_mask: 0.9286  decode.d4.loss_dice: 1.3404  decode.d5.loss_cls: 2.0349  decode.d5.loss_mask: 0.9562  decode.d5.loss_dice: 1.3648  decode.d6.loss_cls: 1.9061  decode.d6.loss_mask: 0.9756  decode.d6.loss_dice: 1.3641  decode.d7.loss_cls: 1.9024  decode.d7.loss_mask: 0.9890  decode.d7.loss_dice: 1.3578  decode.d8.loss_cls: 1.8698  decode.d8.loss_mask: 1.0155  decode.d8.loss_dice: 1.3636
2023/05/23 19:07:34 - mmengine - INFO - Iter(train) [  6600/160000]  lr: 9.6280e-06  eta: 18:19:49  time: 0.4149  data_time: 0.0097  memory: 5072  grad_norm: 119.3619  loss: 57.2094  decode.loss_cls: 2.1170  decode.loss_mask: 0.9784  decode.loss_dice: 2.2291  decode.d0.loss_cls: 4.3385  decode.d0.loss_mask: 1.2715  decode.d0.loss_dice: 2.5855  decode.d1.loss_cls: 2.5045  decode.d1.loss_mask: 1.1551  decode.d1.loss_dice: 2.3679  decode.d2.loss_cls: 2.2727  decode.d2.loss_mask: 0.9925  decode.d2.loss_dice: 2.2280  decode.d3.loss_cls: 2.0939  decode.d3.loss_mask: 1.0242  decode.d3.loss_dice: 2.2319  decode.d4.loss_cls: 2.1400  decode.d4.loss_mask: 1.0366  decode.d4.loss_dice: 2.2281  decode.d5.loss_cls: 2.1144  decode.d5.loss_mask: 1.0312  decode.d5.loss_dice: 2.2123  decode.d6.loss_cls: 2.1121  decode.d6.loss_mask: 1.0109  decode.d6.loss_dice: 2.2090  decode.d7.loss_cls: 2.1507  decode.d7.loss_mask: 1.0206  decode.d7.loss_dice: 2.2115  decode.d8.loss_cls: 2.1133  decode.d8.loss_mask: 1.0315  decode.d8.loss_dice: 2.1963
2023/05/23 19:07:55 - mmengine - INFO - Iter(train) [  6650/160000]  lr: 9.6252e-06  eta: 18:19:16  time: 0.4296  data_time: 0.0095  memory: 4886  grad_norm: 112.7115  loss: 44.6832  decode.loss_cls: 1.7658  decode.loss_mask: 0.9553  decode.loss_dice: 1.5261  decode.d0.loss_cls: 3.6929  decode.d0.loss_mask: 0.9787  decode.d0.loss_dice: 1.6659  decode.d1.loss_cls: 1.8895  decode.d1.loss_mask: 0.9875  decode.d1.loss_dice: 1.5996  decode.d2.loss_cls: 1.8126  decode.d2.loss_mask: 0.9398  decode.d2.loss_dice: 1.5238  decode.d3.loss_cls: 1.8288  decode.d3.loss_mask: 0.9458  decode.d3.loss_dice: 1.5376  decode.d4.loss_cls: 1.7616  decode.d4.loss_mask: 0.9278  decode.d4.loss_dice: 1.5228  decode.d5.loss_cls: 1.7502  decode.d5.loss_mask: 0.9152  decode.d5.loss_dice: 1.5298  decode.d6.loss_cls: 1.7588  decode.d6.loss_mask: 0.9313  decode.d6.loss_dice: 1.5053  decode.d7.loss_cls: 1.6997  decode.d7.loss_mask: 0.9539  decode.d7.loss_dice: 1.5449  decode.d8.loss_cls: 1.7029  decode.d8.loss_mask: 0.9738  decode.d8.loss_dice: 1.5554
2023/05/23 19:08:16 - mmengine - INFO - Iter(train) [  6700/160000]  lr: 9.6224e-06  eta: 18:18:40  time: 0.4166  data_time: 0.0094  memory: 4900  grad_norm: 112.1958  loss: 50.8558  decode.loss_cls: 2.0202  decode.loss_mask: 1.0891  decode.loss_dice: 1.6889  decode.d0.loss_cls: 4.0260  decode.d0.loss_mask: 1.0902  decode.d0.loss_dice: 1.8895  decode.d1.loss_cls: 2.1739  decode.d1.loss_mask: 1.0580  decode.d1.loss_dice: 1.8037  decode.d2.loss_cls: 2.1157  decode.d2.loss_mask: 1.0656  decode.d2.loss_dice: 1.7249  decode.d3.loss_cls: 2.1208  decode.d3.loss_mask: 1.1176  decode.d3.loss_dice: 1.6926  decode.d4.loss_cls: 2.1107  decode.d4.loss_mask: 1.0894  decode.d4.loss_dice: 1.7084  decode.d5.loss_cls: 2.1025  decode.d5.loss_mask: 1.1072  decode.d5.loss_dice: 1.7303  decode.d6.loss_cls: 1.9925  decode.d6.loss_mask: 1.0752  decode.d6.loss_dice: 1.6517  decode.d7.loss_cls: 2.0372  decode.d7.loss_mask: 1.0611  decode.d7.loss_dice: 1.6621  decode.d8.loss_cls: 2.0612  decode.d8.loss_mask: 1.0812  decode.d8.loss_dice: 1.7085
2023/05/23 19:08:37 - mmengine - INFO - Iter(train) [  6750/160000]  lr: 9.6196e-06  eta: 18:18:03  time: 0.4079  data_time: 0.0092  memory: 4835  grad_norm: 103.0843  loss: 47.1079  decode.loss_cls: 2.0370  decode.loss_mask: 0.7661  decode.loss_dice: 1.5864  decode.d0.loss_cls: 3.9291  decode.d0.loss_mask: 0.8784  decode.d0.loss_dice: 1.8938  decode.d1.loss_cls: 2.1469  decode.d1.loss_mask: 0.8156  decode.d1.loss_dice: 1.7593  decode.d2.loss_cls: 2.1248  decode.d2.loss_mask: 0.8199  decode.d2.loss_dice: 1.7030  decode.d3.loss_cls: 2.0722  decode.d3.loss_mask: 0.7710  decode.d3.loss_dice: 1.6493  decode.d4.loss_cls: 2.0460  decode.d4.loss_mask: 0.7535  decode.d4.loss_dice: 1.6191  decode.d5.loss_cls: 2.0804  decode.d5.loss_mask: 0.7413  decode.d5.loss_dice: 1.5672  decode.d6.loss_cls: 2.1145  decode.d6.loss_mask: 0.7649  decode.d6.loss_dice: 1.5737  decode.d7.loss_cls: 2.0725  decode.d7.loss_mask: 0.7576  decode.d7.loss_dice: 1.5752  decode.d8.loss_cls: 2.0887  decode.d8.loss_mask: 0.7874  decode.d8.loss_dice: 1.6131
2023/05/23 19:08:57 - mmengine - INFO - Iter(train) [  6800/160000]  lr: 9.6167e-06  eta: 18:17:18  time: 0.4095  data_time: 0.0096  memory: 4859  grad_norm: 102.2108  loss: 46.8204  decode.loss_cls: 1.7799  decode.loss_mask: 1.0716  decode.loss_dice: 1.5890  decode.d0.loss_cls: 3.6575  decode.d0.loss_mask: 1.1863  decode.d0.loss_dice: 1.8052  decode.d1.loss_cls: 1.9720  decode.d1.loss_mask: 1.2023  decode.d1.loss_dice: 1.7070  decode.d2.loss_cls: 1.7765  decode.d2.loss_mask: 1.1144  decode.d2.loss_dice: 1.6189  decode.d3.loss_cls: 1.8036  decode.d3.loss_mask: 1.0843  decode.d3.loss_dice: 1.5831  decode.d4.loss_cls: 1.7324  decode.d4.loss_mask: 1.0645  decode.d4.loss_dice: 1.5681  decode.d5.loss_cls: 1.7789  decode.d5.loss_mask: 1.0319  decode.d5.loss_dice: 1.5507  decode.d6.loss_cls: 1.7340  decode.d6.loss_mask: 1.0740  decode.d6.loss_dice: 1.5492  decode.d7.loss_cls: 1.7741  decode.d7.loss_mask: 1.0624  decode.d7.loss_dice: 1.5642  decode.d8.loss_cls: 1.7550  decode.d8.loss_mask: 1.0464  decode.d8.loss_dice: 1.5829
2023/05/23 19:09:18 - mmengine - INFO - Iter(train) [  6850/160000]  lr: 9.6139e-06  eta: 18:16:38  time: 0.4176  data_time: 0.0098  memory: 4885  grad_norm: 121.2990  loss: 41.9215  decode.loss_cls: 1.6860  decode.loss_mask: 0.7773  decode.loss_dice: 1.5097  decode.d0.loss_cls: 3.5597  decode.d0.loss_mask: 0.8064  decode.d0.loss_dice: 1.7273  decode.d1.loss_cls: 1.8229  decode.d1.loss_mask: 0.8456  decode.d1.loss_dice: 1.6670  decode.d2.loss_cls: 1.6996  decode.d2.loss_mask: 0.7686  decode.d2.loss_dice: 1.5426  decode.d3.loss_cls: 1.7454  decode.d3.loss_mask: 0.7400  decode.d3.loss_dice: 1.4887  decode.d4.loss_cls: 1.6701  decode.d4.loss_mask: 0.7848  decode.d4.loss_dice: 1.4750  decode.d5.loss_cls: 1.6218  decode.d5.loss_mask: 0.7564  decode.d5.loss_dice: 1.4653  decode.d6.loss_cls: 1.6445  decode.d6.loss_mask: 0.7604  decode.d6.loss_dice: 1.4620  decode.d7.loss_cls: 1.6644  decode.d7.loss_mask: 0.7791  decode.d7.loss_dice: 1.4603  decode.d8.loss_cls: 1.7002  decode.d8.loss_mask: 0.7839  decode.d8.loss_dice: 1.5063
2023/05/23 19:09:39 - mmengine - INFO - Iter(train) [  6900/160000]  lr: 9.6111e-06  eta: 18:15:58  time: 0.4164  data_time: 0.0095  memory: 4845  grad_norm: 143.5569  loss: 53.3629  decode.loss_cls: 2.0931  decode.loss_mask: 0.9898  decode.loss_dice: 1.9366  decode.d0.loss_cls: 4.0603  decode.d0.loss_mask: 1.0797  decode.d0.loss_dice: 2.2772  decode.d1.loss_cls: 2.3658  decode.d1.loss_mask: 1.0141  decode.d1.loss_dice: 2.1275  decode.d2.loss_cls: 2.0811  decode.d2.loss_mask: 1.0274  decode.d2.loss_dice: 2.0505  decode.d3.loss_cls: 2.1515  decode.d3.loss_mask: 0.9873  decode.d3.loss_dice: 1.9842  decode.d4.loss_cls: 2.1052  decode.d4.loss_mask: 0.9777  decode.d4.loss_dice: 1.9611  decode.d5.loss_cls: 2.0276  decode.d5.loss_mask: 1.0020  decode.d5.loss_dice: 1.9356  decode.d6.loss_cls: 2.0458  decode.d6.loss_mask: 1.0242  decode.d6.loss_dice: 2.0022  decode.d7.loss_cls: 2.0901  decode.d7.loss_mask: 0.9807  decode.d7.loss_dice: 1.9684  decode.d8.loss_cls: 2.0899  decode.d8.loss_mask: 0.9937  decode.d8.loss_dice: 1.9325
2023/05/23 19:09:59 - mmengine - INFO - Iter(train) [  6950/160000]  lr: 9.6083e-06  eta: 18:15:22  time: 0.4089  data_time: 0.0096  memory: 4845  grad_norm: 108.0972  loss: 55.9448  decode.loss_cls: 2.1735  decode.loss_mask: 1.2639  decode.loss_dice: 1.8297  decode.d0.loss_cls: 4.0502  decode.d0.loss_mask: 1.4219  decode.d0.loss_dice: 2.1702  decode.d1.loss_cls: 2.4024  decode.d1.loss_mask: 1.3232  decode.d1.loss_dice: 1.9653  decode.d2.loss_cls: 2.2843  decode.d2.loss_mask: 1.3102  decode.d2.loss_dice: 1.9111  decode.d3.loss_cls: 2.1823  decode.d3.loss_mask: 1.2622  decode.d3.loss_dice: 1.8879  decode.d4.loss_cls: 2.1860  decode.d4.loss_mask: 1.2762  decode.d4.loss_dice: 1.8792  decode.d5.loss_cls: 2.1870  decode.d5.loss_mask: 1.2645  decode.d5.loss_dice: 1.8922  decode.d6.loss_cls: 2.1689  decode.d6.loss_mask: 1.2556  decode.d6.loss_dice: 1.8432  decode.d7.loss_cls: 2.1812  decode.d7.loss_mask: 1.2608  decode.d7.loss_dice: 1.8481  decode.d8.loss_cls: 2.1882  decode.d8.loss_mask: 1.2712  decode.d8.loss_dice: 1.8043
2023/05/23 19:10:20 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 19:10:20 - mmengine - INFO - Iter(train) [  7000/160000]  lr: 9.6054e-06  eta: 18:14:47  time: 0.4121  data_time: 0.0096  memory: 4899  grad_norm: 107.1722  loss: 43.9468  decode.loss_cls: 1.8335  decode.loss_mask: 0.9434  decode.loss_dice: 1.3808  decode.d0.loss_cls: 3.7620  decode.d0.loss_mask: 0.9859  decode.d0.loss_dice: 1.5273  decode.d1.loss_cls: 2.0690  decode.d1.loss_mask: 0.9611  decode.d1.loss_dice: 1.4771  decode.d2.loss_cls: 1.9341  decode.d2.loss_mask: 0.9234  decode.d2.loss_dice: 1.3650  decode.d3.loss_cls: 1.8097  decode.d3.loss_mask: 0.9116  decode.d3.loss_dice: 1.3816  decode.d4.loss_cls: 1.8667  decode.d4.loss_mask: 0.8933  decode.d4.loss_dice: 1.3942  decode.d5.loss_cls: 1.8794  decode.d5.loss_mask: 0.9294  decode.d5.loss_dice: 1.3725  decode.d6.loss_cls: 1.8955  decode.d6.loss_mask: 0.8995  decode.d6.loss_dice: 1.3502  decode.d7.loss_cls: 1.8416  decode.d7.loss_mask: 0.9349  decode.d7.loss_dice: 1.3487  decode.d8.loss_cls: 1.7823  decode.d8.loss_mask: 0.9411  decode.d8.loss_dice: 1.3518
2023/05/23 19:10:20 - mmengine - INFO - Saving checkpoint at 7000 iterations
2023/05/23 19:10:47 - mmengine - INFO - Iter(train) [  7050/160000]  lr: 9.6026e-06  eta: 18:16:09  time: 0.4213  data_time: 0.0098  memory: 4866  grad_norm: 102.2204  loss: 40.6181  decode.loss_cls: 1.7146  decode.loss_mask: 0.7512  decode.loss_dice: 1.4560  decode.d0.loss_cls: 3.3520  decode.d0.loss_mask: 0.7615  decode.d0.loss_dice: 1.5584  decode.d1.loss_cls: 1.6981  decode.d1.loss_mask: 0.7709  decode.d1.loss_dice: 1.5340  decode.d2.loss_cls: 1.6450  decode.d2.loss_mask: 0.7576  decode.d2.loss_dice: 1.4961  decode.d3.loss_cls: 1.6708  decode.d3.loss_mask: 0.7844  decode.d3.loss_dice: 1.4444  decode.d4.loss_cls: 1.6228  decode.d4.loss_mask: 0.7384  decode.d4.loss_dice: 1.4610  decode.d5.loss_cls: 1.6191  decode.d5.loss_mask: 0.7363  decode.d5.loss_dice: 1.5039  decode.d6.loss_cls: 1.6173  decode.d6.loss_mask: 0.7536  decode.d6.loss_dice: 1.4677  decode.d7.loss_cls: 1.6412  decode.d7.loss_mask: 0.7405  decode.d7.loss_dice: 1.4428  decode.d8.loss_cls: 1.7068  decode.d8.loss_mask: 0.7168  decode.d8.loss_dice: 1.4549
2023/05/23 19:11:07 - mmengine - INFO - Iter(train) [  7100/160000]  lr: 9.5998e-06  eta: 18:15:32  time: 0.4086  data_time: 0.0094  memory: 4808  grad_norm: 105.9373  loss: 48.4893  decode.loss_cls: 1.8011  decode.loss_mask: 1.0596  decode.loss_dice: 1.6339  decode.d0.loss_cls: 3.7421  decode.d0.loss_mask: 1.0385  decode.d0.loss_dice: 1.8164  decode.d1.loss_cls: 2.0243  decode.d1.loss_mask: 1.1097  decode.d1.loss_dice: 1.7697  decode.d2.loss_cls: 1.9745  decode.d2.loss_mask: 1.1062  decode.d2.loss_dice: 1.6716  decode.d3.loss_cls: 1.8805  decode.d3.loss_mask: 1.1271  decode.d3.loss_dice: 1.6795  decode.d4.loss_cls: 1.8492  decode.d4.loss_mask: 1.1353  decode.d4.loss_dice: 1.6651  decode.d5.loss_cls: 1.8686  decode.d5.loss_mask: 1.1232  decode.d5.loss_dice: 1.6374  decode.d6.loss_cls: 1.7515  decode.d6.loss_mask: 1.1178  decode.d6.loss_dice: 1.6559  decode.d7.loss_cls: 1.8702  decode.d7.loss_mask: 1.1344  decode.d7.loss_dice: 1.6894  decode.d8.loss_cls: 1.8222  decode.d8.loss_mask: 1.0818  decode.d8.loss_dice: 1.6527
2023/05/23 19:11:28 - mmengine - INFO - Iter(train) [  7150/160000]  lr: 9.5970e-06  eta: 18:14:51  time: 0.4325  data_time: 0.0099  memory: 4943  grad_norm: 119.3574  loss: 43.4155  decode.loss_cls: 1.7352  decode.loss_mask: 1.0082  decode.loss_dice: 1.3682  decode.d0.loss_cls: 3.3656  decode.d0.loss_mask: 0.9522  decode.d0.loss_dice: 1.5129  decode.d1.loss_cls: 1.8162  decode.d1.loss_mask: 1.0298  decode.d1.loss_dice: 1.5153  decode.d2.loss_cls: 1.7285  decode.d2.loss_mask: 1.0093  decode.d2.loss_dice: 1.4346  decode.d3.loss_cls: 1.8328  decode.d3.loss_mask: 0.9655  decode.d3.loss_dice: 1.3889  decode.d4.loss_cls: 1.8121  decode.d4.loss_mask: 0.9940  decode.d4.loss_dice: 1.4059  decode.d5.loss_cls: 1.7558  decode.d5.loss_mask: 1.0068  decode.d5.loss_dice: 1.3911  decode.d6.loss_cls: 1.8077  decode.d6.loss_mask: 0.9737  decode.d6.loss_dice: 1.3708  decode.d7.loss_cls: 1.7480  decode.d7.loss_mask: 1.0238  decode.d7.loss_dice: 1.3681  decode.d8.loss_cls: 1.7399  decode.d8.loss_mask: 0.9978  decode.d8.loss_dice: 1.3566
2023/05/23 19:11:49 - mmengine - INFO - Iter(train) [  7200/160000]  lr: 9.5941e-06  eta: 18:14:13  time: 0.4082  data_time: 0.0094  memory: 4917  grad_norm: 84.8029  loss: 44.1640  decode.loss_cls: 1.6479  decode.loss_mask: 0.9044  decode.loss_dice: 1.6472  decode.d0.loss_cls: 3.5768  decode.d0.loss_mask: 0.9523  decode.d0.loss_dice: 1.7593  decode.d1.loss_cls: 1.7203  decode.d1.loss_mask: 0.9538  decode.d1.loss_dice: 1.6737  decode.d2.loss_cls: 1.6363  decode.d2.loss_mask: 0.8782  decode.d2.loss_dice: 1.6397  decode.d3.loss_cls: 1.6739  decode.d3.loss_mask: 0.8839  decode.d3.loss_dice: 1.6268  decode.d4.loss_cls: 1.7547  decode.d4.loss_mask: 0.8722  decode.d4.loss_dice: 1.6406  decode.d5.loss_cls: 1.6524  decode.d5.loss_mask: 0.8843  decode.d5.loss_dice: 1.6479  decode.d6.loss_cls: 1.6891  decode.d6.loss_mask: 0.8843  decode.d6.loss_dice: 1.6091  decode.d7.loss_cls: 1.6440  decode.d7.loss_mask: 0.8898  decode.d7.loss_dice: 1.5933  decode.d8.loss_cls: 1.7212  decode.d8.loss_mask: 0.8919  decode.d8.loss_dice: 1.6148
2023/05/23 19:12:10 - mmengine - INFO - Iter(train) [  7250/160000]  lr: 9.5913e-06  eta: 18:13:50  time: 0.4194  data_time: 0.0095  memory: 4857  grad_norm: 92.5513  loss: 36.3761  decode.loss_cls: 1.4280  decode.loss_mask: 0.7038  decode.loss_dice: 1.2738  decode.d0.loss_cls: 3.0955  decode.d0.loss_mask: 0.7195  decode.d0.loss_dice: 1.4982  decode.d1.loss_cls: 1.6546  decode.d1.loss_mask: 0.7395  decode.d1.loss_dice: 1.3707  decode.d2.loss_cls: 1.4275  decode.d2.loss_mask: 0.7291  decode.d2.loss_dice: 1.2642  decode.d3.loss_cls: 1.4016  decode.d3.loss_mask: 0.7160  decode.d3.loss_dice: 1.2788  decode.d4.loss_cls: 1.4602  decode.d4.loss_mask: 0.7135  decode.d4.loss_dice: 1.2794  decode.d5.loss_cls: 1.4111  decode.d5.loss_mask: 0.7553  decode.d5.loss_dice: 1.2781  decode.d6.loss_cls: 1.3645  decode.d6.loss_mask: 0.7692  decode.d6.loss_dice: 1.2793  decode.d7.loss_cls: 1.4052  decode.d7.loss_mask: 0.7374  decode.d7.loss_dice: 1.2657  decode.d8.loss_cls: 1.3919  decode.d8.loss_mask: 0.6988  decode.d8.loss_dice: 1.2658
2023/05/23 19:12:31 - mmengine - INFO - Iter(train) [  7300/160000]  lr: 9.5885e-06  eta: 18:13:13  time: 0.4237  data_time: 0.0096  memory: 4829  grad_norm: 108.9836  loss: 47.7393  decode.loss_cls: 2.0219  decode.loss_mask: 0.9167  decode.loss_dice: 1.6372  decode.d0.loss_cls: 3.7846  decode.d0.loss_mask: 0.9483  decode.d0.loss_dice: 1.8054  decode.d1.loss_cls: 2.0164  decode.d1.loss_mask: 0.9237  decode.d1.loss_dice: 1.7091  decode.d2.loss_cls: 2.0807  decode.d2.loss_mask: 0.9243  decode.d2.loss_dice: 1.6712  decode.d3.loss_cls: 2.0384  decode.d3.loss_mask: 0.9358  decode.d3.loss_dice: 1.6370  decode.d4.loss_cls: 1.9831  decode.d4.loss_mask: 0.9268  decode.d4.loss_dice: 1.6202  decode.d5.loss_cls: 2.0315  decode.d5.loss_mask: 0.8936  decode.d5.loss_dice: 1.6173  decode.d6.loss_cls: 1.9970  decode.d6.loss_mask: 0.8705  decode.d6.loss_dice: 1.6322  decode.d7.loss_cls: 2.0574  decode.d7.loss_mask: 0.9217  decode.d7.loss_dice: 1.6171  decode.d8.loss_cls: 1.9970  decode.d8.loss_mask: 0.9137  decode.d8.loss_dice: 1.6094
2023/05/23 19:12:52 - mmengine - INFO - Iter(train) [  7350/160000]  lr: 9.5857e-06  eta: 18:12:42  time: 0.4112  data_time: 0.0093  memory: 4845  grad_norm: 103.9871  loss: 47.2074  decode.loss_cls: 1.7987  decode.loss_mask: 0.8811  decode.loss_dice: 1.7812  decode.d0.loss_cls: 3.7553  decode.d0.loss_mask: 0.8729  decode.d0.loss_dice: 1.9481  decode.d1.loss_cls: 1.9826  decode.d1.loss_mask: 0.9139  decode.d1.loss_dice: 1.8807  decode.d2.loss_cls: 1.8085  decode.d2.loss_mask: 0.8516  decode.d2.loss_dice: 1.7809  decode.d3.loss_cls: 1.7594  decode.d3.loss_mask: 0.8906  decode.d3.loss_dice: 1.8166  decode.d4.loss_cls: 1.7942  decode.d4.loss_mask: 0.8813  decode.d4.loss_dice: 1.8327  decode.d5.loss_cls: 1.7899  decode.d5.loss_mask: 0.8591  decode.d5.loss_dice: 1.7998  decode.d6.loss_cls: 1.7806  decode.d6.loss_mask: 0.8889  decode.d6.loss_dice: 1.7894  decode.d7.loss_cls: 1.7867  decode.d7.loss_mask: 0.9040  decode.d7.loss_dice: 1.8229  decode.d8.loss_cls: 1.8107  decode.d8.loss_mask: 0.9183  decode.d8.loss_dice: 1.8268
2023/05/23 19:13:12 - mmengine - INFO - Iter(train) [  7400/160000]  lr: 9.5828e-06  eta: 18:12:00  time: 0.4000  data_time: 0.0094  memory: 4908  grad_norm: 114.8582  loss: 46.8722  decode.loss_cls: 1.8449  decode.loss_mask: 0.9097  decode.loss_dice: 1.5422  decode.d0.loss_cls: 4.0627  decode.d0.loss_mask: 1.0563  decode.d0.loss_dice: 1.9256  decode.d1.loss_cls: 2.0939  decode.d1.loss_mask: 0.9892  decode.d1.loss_dice: 1.7104  decode.d2.loss_cls: 1.9663  decode.d2.loss_mask: 0.9471  decode.d2.loss_dice: 1.6560  decode.d3.loss_cls: 1.8808  decode.d3.loss_mask: 0.9137  decode.d3.loss_dice: 1.5862  decode.d4.loss_cls: 1.8378  decode.d4.loss_mask: 0.9266  decode.d4.loss_dice: 1.6053  decode.d5.loss_cls: 1.8821  decode.d5.loss_mask: 0.9012  decode.d5.loss_dice: 1.5907  decode.d6.loss_cls: 1.8232  decode.d6.loss_mask: 0.9165  decode.d6.loss_dice: 1.5737  decode.d7.loss_cls: 1.9009  decode.d7.loss_mask: 0.9210  decode.d7.loss_dice: 1.5754  decode.d8.loss_cls: 1.8619  decode.d8.loss_mask: 0.8865  decode.d8.loss_dice: 1.5845
2023/05/23 19:13:33 - mmengine - INFO - Iter(train) [  7450/160000]  lr: 9.5800e-06  eta: 18:11:26  time: 0.4128  data_time: 0.0098  memory: 4865  grad_norm: 113.6427  loss: 43.9304  decode.loss_cls: 1.5937  decode.loss_mask: 0.9750  decode.loss_dice: 1.5375  decode.d0.loss_cls: 3.5740  decode.d0.loss_mask: 1.0298  decode.d0.loss_dice: 1.6508  decode.d1.loss_cls: 1.8201  decode.d1.loss_mask: 1.0267  decode.d1.loss_dice: 1.6045  decode.d2.loss_cls: 1.7293  decode.d2.loss_mask: 1.0472  decode.d2.loss_dice: 1.5579  decode.d3.loss_cls: 1.5865  decode.d3.loss_mask: 1.0394  decode.d3.loss_dice: 1.5327  decode.d4.loss_cls: 1.6657  decode.d4.loss_mask: 0.9926  decode.d4.loss_dice: 1.5207  decode.d5.loss_cls: 1.6519  decode.d5.loss_mask: 0.9799  decode.d5.loss_dice: 1.5322  decode.d6.loss_cls: 1.6494  decode.d6.loss_mask: 0.9520  decode.d6.loss_dice: 1.5035  decode.d7.loss_cls: 1.5964  decode.d7.loss_mask: 0.9741  decode.d7.loss_dice: 1.5463  decode.d8.loss_cls: 1.5580  decode.d8.loss_mask: 0.9793  decode.d8.loss_dice: 1.5234
2023/05/23 19:13:54 - mmengine - INFO - Iter(train) [  7500/160000]  lr: 9.5772e-06  eta: 18:10:42  time: 0.4227  data_time: 0.0096  memory: 4845  grad_norm: 105.3983  loss: 41.8717  decode.loss_cls: 1.6112  decode.loss_mask: 1.0090  decode.loss_dice: 1.2581  decode.d0.loss_cls: 3.5831  decode.d0.loss_mask: 1.0049  decode.d0.loss_dice: 1.5426  decode.d1.loss_cls: 1.8398  decode.d1.loss_mask: 1.0124  decode.d1.loss_dice: 1.3651  decode.d2.loss_cls: 1.6261  decode.d2.loss_mask: 1.0225  decode.d2.loss_dice: 1.3547  decode.d3.loss_cls: 1.6731  decode.d3.loss_mask: 0.9905  decode.d3.loss_dice: 1.3082  decode.d4.loss_cls: 1.5939  decode.d4.loss_mask: 1.0266  decode.d4.loss_dice: 1.2905  decode.d5.loss_cls: 1.5936  decode.d5.loss_mask: 1.0057  decode.d5.loss_dice: 1.2796  decode.d6.loss_cls: 1.6576  decode.d6.loss_mask: 1.0204  decode.d6.loss_dice: 1.2476  decode.d7.loss_cls: 1.6473  decode.d7.loss_mask: 1.0191  decode.d7.loss_dice: 1.3079  decode.d8.loss_cls: 1.6796  decode.d8.loss_mask: 0.9949  decode.d8.loss_dice: 1.3060
2023/05/23 19:14:17 - mmengine - INFO - Iter(train) [  7550/160000]  lr: 9.5743e-06  eta: 18:11:02  time: 0.4665  data_time: 0.0092  memory: 4883  grad_norm: 94.7516  loss: 48.7749  decode.loss_cls: 1.8149  decode.loss_mask: 1.0214  decode.loss_dice: 1.7790  decode.d0.loss_cls: 3.8066  decode.d0.loss_mask: 1.0458  decode.d0.loss_dice: 1.9136  decode.d1.loss_cls: 1.9857  decode.d1.loss_mask: 1.0688  decode.d1.loss_dice: 1.8586  decode.d2.loss_cls: 1.8768  decode.d2.loss_mask: 1.0468  decode.d2.loss_dice: 1.7508  decode.d3.loss_cls: 1.8935  decode.d3.loss_mask: 1.0311  decode.d3.loss_dice: 1.7543  decode.d4.loss_cls: 1.8349  decode.d4.loss_mask: 1.0341  decode.d4.loss_dice: 1.7440  decode.d5.loss_cls: 1.8819  decode.d5.loss_mask: 0.9995  decode.d5.loss_dice: 1.7467  decode.d6.loss_cls: 1.8959  decode.d6.loss_mask: 1.0148  decode.d6.loss_dice: 1.7445  decode.d7.loss_cls: 1.8346  decode.d7.loss_mask: 1.0151  decode.d7.loss_dice: 1.7446  decode.d8.loss_cls: 1.8612  decode.d8.loss_mask: 1.0213  decode.d8.loss_dice: 1.7541
2023/05/23 19:14:39 - mmengine - INFO - Iter(train) [  7600/160000]  lr: 9.5715e-06  eta: 18:10:45  time: 0.3995  data_time: 0.0092  memory: 4856  grad_norm: 97.2764  loss: 47.9695  decode.loss_cls: 1.9978  decode.loss_mask: 0.9010  decode.loss_dice: 1.5770  decode.d0.loss_cls: 4.0378  decode.d0.loss_mask: 0.9502  decode.d0.loss_dice: 1.7268  decode.d1.loss_cls: 2.2743  decode.d1.loss_mask: 0.9262  decode.d1.loss_dice: 1.6598  decode.d2.loss_cls: 2.0500  decode.d2.loss_mask: 0.9172  decode.d2.loss_dice: 1.5988  decode.d3.loss_cls: 2.0398  decode.d3.loss_mask: 0.9308  decode.d3.loss_dice: 1.6098  decode.d4.loss_cls: 2.0549  decode.d4.loss_mask: 0.9311  decode.d4.loss_dice: 1.5931  decode.d5.loss_cls: 2.0810  decode.d5.loss_mask: 0.9149  decode.d5.loss_dice: 1.5735  decode.d6.loss_cls: 2.0921  decode.d6.loss_mask: 0.8930  decode.d6.loss_dice: 1.5557  decode.d7.loss_cls: 2.0720  decode.d7.loss_mask: 0.9063  decode.d7.loss_dice: 1.5760  decode.d8.loss_cls: 2.0257  decode.d8.loss_mask: 0.9066  decode.d8.loss_dice: 1.5960
2023/05/23 19:14:59 - mmengine - INFO - Iter(train) [  7650/160000]  lr: 9.5687e-06  eta: 18:10:07  time: 0.4118  data_time: 0.0100  memory: 4802  grad_norm: 108.1184  loss: 38.6138  decode.loss_cls: 1.6829  decode.loss_mask: 0.7332  decode.loss_dice: 1.2492  decode.d0.loss_cls: 3.3690  decode.d0.loss_mask: 0.7775  decode.d0.loss_dice: 1.3930  decode.d1.loss_cls: 1.7403  decode.d1.loss_mask: 0.7502  decode.d1.loss_dice: 1.3350  decode.d2.loss_cls: 1.5780  decode.d2.loss_mask: 0.7784  decode.d2.loss_dice: 1.2627  decode.d3.loss_cls: 1.6187  decode.d3.loss_mask: 0.7789  decode.d3.loss_dice: 1.2668  decode.d4.loss_cls: 1.6455  decode.d4.loss_mask: 0.7918  decode.d4.loss_dice: 1.2357  decode.d5.loss_cls: 1.6086  decode.d5.loss_mask: 0.7879  decode.d5.loss_dice: 1.2705  decode.d6.loss_cls: 1.5823  decode.d6.loss_mask: 0.7819  decode.d6.loss_dice: 1.2805  decode.d7.loss_cls: 1.6142  decode.d7.loss_mask: 0.7725  decode.d7.loss_dice: 1.2574  decode.d8.loss_cls: 1.6341  decode.d8.loss_mask: 0.7730  decode.d8.loss_dice: 1.2641
2023/05/23 19:15:20 - mmengine - INFO - Iter(train) [  7700/160000]  lr: 9.5659e-06  eta: 18:09:25  time: 0.4093  data_time: 0.0100  memory: 4814  grad_norm: 98.2709  loss: 52.7205  decode.loss_cls: 2.1051  decode.loss_mask: 0.9031  decode.loss_dice: 2.0262  decode.d0.loss_cls: 3.8962  decode.d0.loss_mask: 0.9322  decode.d0.loss_dice: 2.1618  decode.d1.loss_cls: 2.3269  decode.d1.loss_mask: 0.8998  decode.d1.loss_dice: 2.0209  decode.d2.loss_cls: 2.1844  decode.d2.loss_mask: 0.8882  decode.d2.loss_dice: 2.0190  decode.d3.loss_cls: 2.1374  decode.d3.loss_mask: 0.9208  decode.d3.loss_dice: 1.9972  decode.d4.loss_cls: 2.1788  decode.d4.loss_mask: 0.9228  decode.d4.loss_dice: 1.9703  decode.d5.loss_cls: 2.1099  decode.d5.loss_mask: 0.9317  decode.d5.loss_dice: 1.9885  decode.d6.loss_cls: 2.0999  decode.d6.loss_mask: 0.9398  decode.d6.loss_dice: 1.9971  decode.d7.loss_cls: 2.2047  decode.d7.loss_mask: 0.9155  decode.d7.loss_dice: 1.9905  decode.d8.loss_cls: 2.1166  decode.d8.loss_mask: 0.9310  decode.d8.loss_dice: 2.0042
2023/05/23 19:15:40 - mmengine - INFO - Iter(train) [  7750/160000]  lr: 9.5630e-06  eta: 18:08:44  time: 0.4068  data_time: 0.0099  memory: 4875  grad_norm: 101.1055  loss: 36.6432  decode.loss_cls: 1.3236  decode.loss_mask: 0.7360  decode.loss_dice: 1.2652  decode.d0.loss_cls: 3.5974  decode.d0.loss_mask: 0.8389  decode.d0.loss_dice: 1.4939  decode.d1.loss_cls: 1.6843  decode.d1.loss_mask: 0.7778  decode.d1.loss_dice: 1.3423  decode.d2.loss_cls: 1.4518  decode.d2.loss_mask: 0.7490  decode.d2.loss_dice: 1.2738  decode.d3.loss_cls: 1.4107  decode.d3.loss_mask: 0.7334  decode.d3.loss_dice: 1.2233  decode.d4.loss_cls: 1.4166  decode.d4.loss_mask: 0.7477  decode.d4.loss_dice: 1.2347  decode.d5.loss_cls: 1.3657  decode.d5.loss_mask: 0.7412  decode.d5.loss_dice: 1.2295  decode.d6.loss_cls: 1.3706  decode.d6.loss_mask: 0.7401  decode.d6.loss_dice: 1.2376  decode.d7.loss_cls: 1.3455  decode.d7.loss_mask: 0.7238  decode.d7.loss_dice: 1.2533  decode.d8.loss_cls: 1.3434  decode.d8.loss_mask: 0.7358  decode.d8.loss_dice: 1.2562
2023/05/23 19:16:01 - mmengine - INFO - Iter(train) [  7800/160000]  lr: 9.5602e-06  eta: 18:08:03  time: 0.4163  data_time: 0.0094  memory: 4835  grad_norm: 104.2477  loss: 42.5164  decode.loss_cls: 1.6752  decode.loss_mask: 0.7065  decode.loss_dice: 1.6022  decode.d0.loss_cls: 3.4469  decode.d0.loss_mask: 0.7427  decode.d0.loss_dice: 1.7764  decode.d1.loss_cls: 1.7670  decode.d1.loss_mask: 0.7416  decode.d1.loss_dice: 1.7017  decode.d2.loss_cls: 1.7214  decode.d2.loss_mask: 0.7687  decode.d2.loss_dice: 1.6965  decode.d3.loss_cls: 1.6838  decode.d3.loss_mask: 0.7276  decode.d3.loss_dice: 1.5866  decode.d4.loss_cls: 1.7298  decode.d4.loss_mask: 0.7124  decode.d4.loss_dice: 1.5897  decode.d5.loss_cls: 1.6711  decode.d5.loss_mask: 0.7076  decode.d5.loss_dice: 1.6031  decode.d6.loss_cls: 1.6654  decode.d6.loss_mask: 0.7414  decode.d6.loss_dice: 1.6349  decode.d7.loss_cls: 1.7001  decode.d7.loss_mask: 0.7209  decode.d7.loss_dice: 1.6346  decode.d8.loss_cls: 1.7373  decode.d8.loss_mask: 0.7052  decode.d8.loss_dice: 1.6180
2023/05/23 19:16:21 - mmengine - INFO - Iter(train) [  7850/160000]  lr: 9.5574e-06  eta: 18:07:26  time: 0.4142  data_time: 0.0099  memory: 4866  grad_norm: 91.1340  loss: 47.6977  decode.loss_cls: 1.9517  decode.loss_mask: 0.9776  decode.loss_dice: 1.5976  decode.d0.loss_cls: 3.8069  decode.d0.loss_mask: 1.0030  decode.d0.loss_dice: 1.7925  decode.d1.loss_cls: 2.0719  decode.d1.loss_mask: 1.0287  decode.d1.loss_dice: 1.7163  decode.d2.loss_cls: 2.0284  decode.d2.loss_mask: 0.9533  decode.d2.loss_dice: 1.6501  decode.d3.loss_cls: 2.0140  decode.d3.loss_mask: 0.9137  decode.d3.loss_dice: 1.6027  decode.d4.loss_cls: 2.0003  decode.d4.loss_mask: 0.9284  decode.d4.loss_dice: 1.5899  decode.d5.loss_cls: 1.9928  decode.d5.loss_mask: 0.9545  decode.d5.loss_dice: 1.6213  decode.d6.loss_cls: 1.9741  decode.d6.loss_mask: 0.9386  decode.d6.loss_dice: 1.5598  decode.d7.loss_cls: 1.9723  decode.d7.loss_mask: 0.9760  decode.d7.loss_dice: 1.6017  decode.d8.loss_cls: 1.9757  decode.d8.loss_mask: 0.9349  decode.d8.loss_dice: 1.5690
2023/05/23 19:16:42 - mmengine - INFO - Iter(train) [  7900/160000]  lr: 9.5546e-06  eta: 18:06:46  time: 0.4066  data_time: 0.0093  memory: 4879  grad_norm: 99.4720  loss: 46.4176  decode.loss_cls: 1.7151  decode.loss_mask: 1.0125  decode.loss_dice: 1.6342  decode.d0.loss_cls: 3.5924  decode.d0.loss_mask: 1.0130  decode.d0.loss_dice: 1.8428  decode.d1.loss_cls: 1.9778  decode.d1.loss_mask: 1.0037  decode.d1.loss_dice: 1.7047  decode.d2.loss_cls: 1.8161  decode.d2.loss_mask: 0.9803  decode.d2.loss_dice: 1.6888  decode.d3.loss_cls: 1.7239  decode.d3.loss_mask: 0.9868  decode.d3.loss_dice: 1.6759  decode.d4.loss_cls: 1.6956  decode.d4.loss_mask: 1.0102  decode.d4.loss_dice: 1.6886  decode.d5.loss_cls: 1.6365  decode.d5.loss_mask: 1.0655  decode.d5.loss_dice: 1.6968  decode.d6.loss_cls: 1.6946  decode.d6.loss_mask: 1.0595  decode.d6.loss_dice: 1.6729  decode.d7.loss_cls: 1.7108  decode.d7.loss_mask: 1.0503  decode.d7.loss_dice: 1.7049  decode.d8.loss_cls: 1.7248  decode.d8.loss_mask: 0.9848  decode.d8.loss_dice: 1.6538
2023/05/23 19:17:03 - mmengine - INFO - Iter(train) [  7950/160000]  lr: 9.5517e-06  eta: 18:06:09  time: 0.4092  data_time: 0.0097  memory: 4844  grad_norm: 92.8595  loss: 39.3776  decode.loss_cls: 1.6849  decode.loss_mask: 0.7272  decode.loss_dice: 1.3301  decode.d0.loss_cls: 3.4615  decode.d0.loss_mask: 0.8197  decode.d0.loss_dice: 1.4753  decode.d1.loss_cls: 1.7158  decode.d1.loss_mask: 0.8373  decode.d1.loss_dice: 1.4050  decode.d2.loss_cls: 1.6995  decode.d2.loss_mask: 0.7637  decode.d2.loss_dice: 1.3428  decode.d3.loss_cls: 1.6394  decode.d3.loss_mask: 0.7147  decode.d3.loss_dice: 1.3043  decode.d4.loss_cls: 1.6099  decode.d4.loss_mask: 0.7190  decode.d4.loss_dice: 1.3215  decode.d5.loss_cls: 1.6250  decode.d5.loss_mask: 0.7351  decode.d5.loss_dice: 1.3321  decode.d6.loss_cls: 1.6620  decode.d6.loss_mask: 0.7223  decode.d6.loss_dice: 1.3105  decode.d7.loss_cls: 1.6266  decode.d7.loss_mask: 0.7586  decode.d7.loss_dice: 1.2936  decode.d8.loss_cls: 1.6695  decode.d8.loss_mask: 0.7404  decode.d8.loss_dice: 1.3303
2023/05/23 19:17:23 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 19:17:23 - mmengine - INFO - Iter(train) [  8000/160000]  lr: 9.5489e-06  eta: 18:05:30  time: 0.4024  data_time: 0.0094  memory: 4868  grad_norm: 117.1758  loss: 51.4639  decode.loss_cls: 1.8320  decode.loss_mask: 1.1288  decode.loss_dice: 2.0115  decode.d0.loss_cls: 3.7878  decode.d0.loss_mask: 1.1658  decode.d0.loss_dice: 2.2057  decode.d1.loss_cls: 1.9777  decode.d1.loss_mask: 1.1492  decode.d1.loss_dice: 2.1396  decode.d2.loss_cls: 1.8985  decode.d2.loss_mask: 1.1051  decode.d2.loss_dice: 2.0745  decode.d3.loss_cls: 1.7755  decode.d3.loss_mask: 1.1356  decode.d3.loss_dice: 1.9331  decode.d4.loss_cls: 1.7309  decode.d4.loss_mask: 1.1361  decode.d4.loss_dice: 1.9517  decode.d5.loss_cls: 1.6641  decode.d5.loss_mask: 1.1448  decode.d5.loss_dice: 2.0084  decode.d6.loss_cls: 1.7020  decode.d6.loss_mask: 1.1438  decode.d6.loss_dice: 1.9761  decode.d7.loss_cls: 1.6607  decode.d7.loss_mask: 1.1337  decode.d7.loss_dice: 2.0041  decode.d8.loss_cls: 1.7375  decode.d8.loss_mask: 1.1261  decode.d8.loss_dice: 2.0236
2023/05/23 19:17:23 - mmengine - INFO - Saving checkpoint at 8000 iterations
2023/05/23 19:17:49 - mmengine - INFO - Iter(train) [  8050/160000]  lr: 9.5461e-06  eta: 18:06:30  time: 0.4071  data_time: 0.0096  memory: 4849  grad_norm: 114.4183  loss: 47.2022  decode.loss_cls: 1.8343  decode.loss_mask: 0.9427  decode.loss_dice: 1.6403  decode.d0.loss_cls: 3.9317  decode.d0.loss_mask: 0.9995  decode.d0.loss_dice: 1.9550  decode.d1.loss_cls: 1.9578  decode.d1.loss_mask: 1.0017  decode.d1.loss_dice: 1.7524  decode.d2.loss_cls: 1.8642  decode.d2.loss_mask: 0.9430  decode.d2.loss_dice: 1.7102  decode.d3.loss_cls: 1.8302  decode.d3.loss_mask: 0.8904  decode.d3.loss_dice: 1.6732  decode.d4.loss_cls: 1.8405  decode.d4.loss_mask: 0.9259  decode.d4.loss_dice: 1.6922  decode.d5.loss_cls: 1.8786  decode.d5.loss_mask: 0.9164  decode.d5.loss_dice: 1.6800  decode.d6.loss_cls: 1.8406  decode.d6.loss_mask: 0.9129  decode.d6.loss_dice: 1.6497  decode.d7.loss_cls: 1.9050  decode.d7.loss_mask: 0.9173  decode.d7.loss_dice: 1.6491  decode.d8.loss_cls: 1.8699  decode.d8.loss_mask: 0.9460  decode.d8.loss_dice: 1.6515
2023/05/23 19:18:09 - mmengine - INFO - Iter(train) [  8100/160000]  lr: 9.5433e-06  eta: 18:05:49  time: 0.4028  data_time: 0.0090  memory: 4890  grad_norm: 122.8417  loss: 48.5866  decode.loss_cls: 2.0012  decode.loss_mask: 0.8170  decode.loss_dice: 1.7137  decode.d0.loss_cls: 3.9360  decode.d0.loss_mask: 0.9522  decode.d0.loss_dice: 1.9967  decode.d1.loss_cls: 2.2590  decode.d1.loss_mask: 0.8468  decode.d1.loss_dice: 1.7923  decode.d2.loss_cls: 2.1017  decode.d2.loss_mask: 0.8722  decode.d2.loss_dice: 1.7317  decode.d3.loss_cls: 2.0384  decode.d3.loss_mask: 0.8559  decode.d3.loss_dice: 1.7525  decode.d4.loss_cls: 2.0213  decode.d4.loss_mask: 0.8686  decode.d4.loss_dice: 1.7470  decode.d5.loss_cls: 1.9910  decode.d5.loss_mask: 0.8751  decode.d5.loss_dice: 1.7389  decode.d6.loss_cls: 1.9989  decode.d6.loss_mask: 0.8355  decode.d6.loss_dice: 1.7014  decode.d7.loss_cls: 1.9923  decode.d7.loss_mask: 0.8354  decode.d7.loss_dice: 1.7315  decode.d8.loss_cls: 2.0285  decode.d8.loss_mask: 0.8517  decode.d8.loss_dice: 1.7021
2023/05/23 19:18:30 - mmengine - INFO - Iter(train) [  8150/160000]  lr: 9.5404e-06  eta: 18:05:08  time: 0.3996  data_time: 0.0097  memory: 4822  grad_norm: 139.0418  loss: 42.1648  decode.loss_cls: 1.6787  decode.loss_mask: 0.6963  decode.loss_dice: 1.5305  decode.d0.loss_cls: 3.4946  decode.d0.loss_mask: 0.7222  decode.d0.loss_dice: 1.7434  decode.d1.loss_cls: 1.7823  decode.d1.loss_mask: 0.7204  decode.d1.loss_dice: 1.6322  decode.d2.loss_cls: 1.6489  decode.d2.loss_mask: 0.7203  decode.d2.loss_dice: 1.6649  decode.d3.loss_cls: 1.6709  decode.d3.loss_mask: 0.7197  decode.d3.loss_dice: 1.6133  decode.d4.loss_cls: 1.6937  decode.d4.loss_mask: 0.7086  decode.d4.loss_dice: 1.6036  decode.d5.loss_cls: 1.7532  decode.d5.loss_mask: 0.7141  decode.d5.loss_dice: 1.6341  decode.d6.loss_cls: 1.7833  decode.d6.loss_mask: 0.6816  decode.d6.loss_dice: 1.5950  decode.d7.loss_cls: 1.7782  decode.d7.loss_mask: 0.6745  decode.d7.loss_dice: 1.5397  decode.d8.loss_cls: 1.7344  decode.d8.loss_mask: 0.6625  decode.d8.loss_dice: 1.5697
2023/05/23 19:18:50 - mmengine - INFO - Iter(train) [  8200/160000]  lr: 9.5376e-06  eta: 18:04:31  time: 0.4117  data_time: 0.0094  memory: 4812  grad_norm: 98.0471  loss: 45.3689  decode.loss_cls: 1.4748  decode.loss_mask: 1.1975  decode.loss_dice: 1.6390  decode.d0.loss_cls: 3.4842  decode.d0.loss_mask: 1.1331  decode.d0.loss_dice: 1.8320  decode.d1.loss_cls: 1.5027  decode.d1.loss_mask: 1.1827  decode.d1.loss_dice: 1.7181  decode.d2.loss_cls: 1.5478  decode.d2.loss_mask: 1.1391  decode.d2.loss_dice: 1.6645  decode.d3.loss_cls: 1.5026  decode.d3.loss_mask: 1.1492  decode.d3.loss_dice: 1.6621  decode.d4.loss_cls: 1.5261  decode.d4.loss_mask: 1.1472  decode.d4.loss_dice: 1.6828  decode.d5.loss_cls: 1.5267  decode.d5.loss_mask: 1.1731  decode.d5.loss_dice: 1.6957  decode.d6.loss_cls: 1.4881  decode.d6.loss_mask: 1.1445  decode.d6.loss_dice: 1.6592  decode.d7.loss_cls: 1.4655  decode.d7.loss_mask: 1.1334  decode.d7.loss_dice: 1.6548  decode.d8.loss_cls: 1.4178  decode.d8.loss_mask: 1.1875  decode.d8.loss_dice: 1.6373
2023/05/23 19:19:12 - mmengine - INFO - Iter(train) [  8250/160000]  lr: 9.5348e-06  eta: 18:04:15  time: 0.4124  data_time: 0.0093  memory: 4855  grad_norm: 108.3776  loss: 35.2452  decode.loss_cls: 1.2845  decode.loss_mask: 0.7163  decode.loss_dice: 1.2861  decode.d0.loss_cls: 3.2562  decode.d0.loss_mask: 0.7140  decode.d0.loss_dice: 1.4006  decode.d1.loss_cls: 1.4616  decode.d1.loss_mask: 0.6769  decode.d1.loss_dice: 1.3272  decode.d2.loss_cls: 1.3128  decode.d2.loss_mask: 0.6748  decode.d2.loss_dice: 1.3365  decode.d3.loss_cls: 1.2910  decode.d3.loss_mask: 0.7111  decode.d3.loss_dice: 1.3046  decode.d4.loss_cls: 1.2808  decode.d4.loss_mask: 0.7024  decode.d4.loss_dice: 1.2992  decode.d5.loss_cls: 1.3334  decode.d5.loss_mask: 0.6815  decode.d5.loss_dice: 1.3186  decode.d6.loss_cls: 1.3257  decode.d6.loss_mask: 0.6681  decode.d6.loss_dice: 1.2918  decode.d7.loss_cls: 1.3082  decode.d7.loss_mask: 0.7279  decode.d7.loss_dice: 1.2989  decode.d8.loss_cls: 1.2576  decode.d8.loss_mask: 0.7115  decode.d8.loss_dice: 1.2855
2023/05/23 19:19:32 - mmengine - INFO - Iter(train) [  8300/160000]  lr: 9.5319e-06  eta: 18:03:36  time: 0.4090  data_time: 0.0095  memory: 4867  grad_norm: 119.4555  loss: 41.4172  decode.loss_cls: 1.5836  decode.loss_mask: 0.8910  decode.loss_dice: 1.3891  decode.d0.loss_cls: 3.4765  decode.d0.loss_mask: 1.0110  decode.d0.loss_dice: 1.6042  decode.d1.loss_cls: 1.6526  decode.d1.loss_mask: 0.9450  decode.d1.loss_dice: 1.5366  decode.d2.loss_cls: 1.6359  decode.d2.loss_mask: 0.8978  decode.d2.loss_dice: 1.4850  decode.d3.loss_cls: 1.5914  decode.d3.loss_mask: 0.8992  decode.d3.loss_dice: 1.4674  decode.d4.loss_cls: 1.5885  decode.d4.loss_mask: 0.9078  decode.d4.loss_dice: 1.4096  decode.d5.loss_cls: 1.5813  decode.d5.loss_mask: 0.9385  decode.d5.loss_dice: 1.4290  decode.d6.loss_cls: 1.5538  decode.d6.loss_mask: 0.8707  decode.d6.loss_dice: 1.3667  decode.d7.loss_cls: 1.5013  decode.d7.loss_mask: 0.8935  decode.d7.loss_dice: 1.4304  decode.d8.loss_cls: 1.5880  decode.d8.loss_mask: 0.8821  decode.d8.loss_dice: 1.4095
2023/05/23 19:19:52 - mmengine - INFO - Iter(train) [  8350/160000]  lr: 9.5291e-06  eta: 18:02:51  time: 0.4021  data_time: 0.0093  memory: 4860  grad_norm: 135.8703  loss: 48.2833  decode.loss_cls: 1.8404  decode.loss_mask: 1.0012  decode.loss_dice: 1.7547  decode.d0.loss_cls: 4.0975  decode.d0.loss_mask: 0.9614  decode.d0.loss_dice: 1.9434  decode.d1.loss_cls: 1.9395  decode.d1.loss_mask: 1.0193  decode.d1.loss_dice: 1.8271  decode.d2.loss_cls: 1.8620  decode.d2.loss_mask: 1.0192  decode.d2.loss_dice: 1.7992  decode.d3.loss_cls: 1.8744  decode.d3.loss_mask: 0.9821  decode.d3.loss_dice: 1.6923  decode.d4.loss_cls: 1.8338  decode.d4.loss_mask: 0.9970  decode.d4.loss_dice: 1.7324  decode.d5.loss_cls: 1.8203  decode.d5.loss_mask: 0.9696  decode.d5.loss_dice: 1.7250  decode.d6.loss_cls: 1.7890  decode.d6.loss_mask: 0.9720  decode.d6.loss_dice: 1.7116  decode.d7.loss_cls: 1.8169  decode.d7.loss_mask: 0.9527  decode.d7.loss_dice: 1.7682  decode.d8.loss_cls: 1.8233  decode.d8.loss_mask: 0.9784  decode.d8.loss_dice: 1.7795
2023/05/23 19:20:13 - mmengine - INFO - Iter(train) [  8400/160000]  lr: 9.5263e-06  eta: 18:02:11  time: 0.4085  data_time: 0.0095  memory: 4885  grad_norm: 111.6674  loss: 46.5488  decode.loss_cls: 1.7952  decode.loss_mask: 0.9680  decode.loss_dice: 1.6519  decode.d0.loss_cls: 3.6493  decode.d0.loss_mask: 0.9446  decode.d0.loss_dice: 1.8048  decode.d1.loss_cls: 1.9661  decode.d1.loss_mask: 0.9986  decode.d1.loss_dice: 1.7921  decode.d2.loss_cls: 1.8246  decode.d2.loss_mask: 0.9618  decode.d2.loss_dice: 1.6619  decode.d3.loss_cls: 1.8074  decode.d3.loss_mask: 1.0122  decode.d3.loss_dice: 1.6826  decode.d4.loss_cls: 1.8066  decode.d4.loss_mask: 0.9783  decode.d4.loss_dice: 1.6563  decode.d5.loss_cls: 1.7800  decode.d5.loss_mask: 0.9939  decode.d5.loss_dice: 1.6552  decode.d6.loss_cls: 1.7794  decode.d6.loss_mask: 0.9787  decode.d6.loss_dice: 1.6623  decode.d7.loss_cls: 1.7333  decode.d7.loss_mask: 0.9651  decode.d7.loss_dice: 1.6260  decode.d8.loss_cls: 1.7654  decode.d8.loss_mask: 0.9925  decode.d8.loss_dice: 1.6548
2023/05/23 19:20:34 - mmengine - INFO - Iter(train) [  8450/160000]  lr: 9.5235e-06  eta: 18:01:53  time: 0.4655  data_time: 0.0102  memory: 4845  grad_norm: 110.8394  loss: 47.3021  decode.loss_cls: 1.4593  decode.loss_mask: 1.1534  decode.loss_dice: 1.8499  decode.d0.loss_cls: 3.4960  decode.d0.loss_mask: 1.2681  decode.d0.loss_dice: 2.0793  decode.d1.loss_cls: 1.5084  decode.d1.loss_mask: 1.2426  decode.d1.loss_dice: 2.0129  decode.d2.loss_cls: 1.3843  decode.d2.loss_mask: 1.2146  decode.d2.loss_dice: 1.9019  decode.d3.loss_cls: 1.4262  decode.d3.loss_mask: 1.1643  decode.d3.loss_dice: 1.8240  decode.d4.loss_cls: 1.4023  decode.d4.loss_mask: 1.1928  decode.d4.loss_dice: 1.8535  decode.d5.loss_cls: 1.4804  decode.d5.loss_mask: 1.1628  decode.d5.loss_dice: 1.8534  decode.d6.loss_cls: 1.4297  decode.d6.loss_mask: 1.1678  decode.d6.loss_dice: 1.8071  decode.d7.loss_cls: 1.4128  decode.d7.loss_mask: 1.1799  decode.d7.loss_dice: 1.8379  decode.d8.loss_cls: 1.5161  decode.d8.loss_mask: 1.1632  decode.d8.loss_dice: 1.8573
2023/05/23 19:20:57 - mmengine - INFO - Iter(train) [  8500/160000]  lr: 9.5206e-06  eta: 18:01:47  time: 0.4162  data_time: 0.0093  memory: 4823  grad_norm: 116.4093  loss: 44.5864  decode.loss_cls: 1.8165  decode.loss_mask: 1.0728  decode.loss_dice: 1.3412  decode.d0.loss_cls: 3.2370  decode.d0.loss_mask: 1.1484  decode.d0.loss_dice: 1.5094  decode.d1.loss_cls: 1.9509  decode.d1.loss_mask: 1.0954  decode.d1.loss_dice: 1.5292  decode.d2.loss_cls: 1.8553  decode.d2.loss_mask: 1.1221  decode.d2.loss_dice: 1.3820  decode.d3.loss_cls: 1.8144  decode.d3.loss_mask: 1.0845  decode.d3.loss_dice: 1.3752  decode.d4.loss_cls: 1.8491  decode.d4.loss_mask: 1.0839  decode.d4.loss_dice: 1.3775  decode.d5.loss_cls: 1.7956  decode.d5.loss_mask: 1.0575  decode.d5.loss_dice: 1.4024  decode.d6.loss_cls: 1.7716  decode.d6.loss_mask: 1.0822  decode.d6.loss_dice: 1.3310  decode.d7.loss_cls: 1.8003  decode.d7.loss_mask: 1.0971  decode.d7.loss_dice: 1.3670  decode.d8.loss_cls: 1.8072  decode.d8.loss_mask: 1.0618  decode.d8.loss_dice: 1.3677
2023/05/23 19:21:18 - mmengine - INFO - Iter(train) [  8550/160000]  lr: 9.5178e-06  eta: 18:01:23  time: 0.4656  data_time: 0.0094  memory: 4930  grad_norm: 91.5939  loss: 51.7532  decode.loss_cls: 2.0157  decode.loss_mask: 0.8901  decode.loss_dice: 1.9516  decode.d0.loss_cls: 3.9916  decode.d0.loss_mask: 0.9964  decode.d0.loss_dice: 2.2626  decode.d1.loss_cls: 2.3674  decode.d1.loss_mask: 0.9705  decode.d1.loss_dice: 2.1187  decode.d2.loss_cls: 2.1631  decode.d2.loss_mask: 0.9238  decode.d2.loss_dice: 1.9962  decode.d3.loss_cls: 1.9646  decode.d3.loss_mask: 0.9958  decode.d3.loss_dice: 1.9743  decode.d4.loss_cls: 1.9467  decode.d4.loss_mask: 0.9164  decode.d4.loss_dice: 1.9761  decode.d5.loss_cls: 2.0092  decode.d5.loss_mask: 0.8837  decode.d5.loss_dice: 1.9473  decode.d6.loss_cls: 2.0209  decode.d6.loss_mask: 0.9074  decode.d6.loss_dice: 1.9275  decode.d7.loss_cls: 2.0216  decode.d7.loss_mask: 0.8715  decode.d7.loss_dice: 1.9244  decode.d8.loss_cls: 1.9801  decode.d8.loss_mask: 0.9060  decode.d8.loss_dice: 1.9324
2023/05/23 19:21:40 - mmengine - INFO - Iter(train) [  8600/160000]  lr: 9.5150e-06  eta: 18:01:11  time: 0.4030  data_time: 0.0092  memory: 4829  grad_norm: 102.6689  loss: 38.6010  decode.loss_cls: 1.5820  decode.loss_mask: 0.7336  decode.loss_dice: 1.2596  decode.d0.loss_cls: 3.4159  decode.d0.loss_mask: 0.8065  decode.d0.loss_dice: 1.3968  decode.d1.loss_cls: 1.7344  decode.d1.loss_mask: 0.7686  decode.d1.loss_dice: 1.3355  decode.d2.loss_cls: 1.5836  decode.d2.loss_mask: 0.7955  decode.d2.loss_dice: 1.2798  decode.d3.loss_cls: 1.6603  decode.d3.loss_mask: 0.7494  decode.d3.loss_dice: 1.2719  decode.d4.loss_cls: 1.6543  decode.d4.loss_mask: 0.7481  decode.d4.loss_dice: 1.2839  decode.d5.loss_cls: 1.5877  decode.d5.loss_mask: 0.7593  decode.d5.loss_dice: 1.2782  decode.d6.loss_cls: 1.5661  decode.d6.loss_mask: 0.7691  decode.d6.loss_dice: 1.2814  decode.d7.loss_cls: 1.5547  decode.d7.loss_mask: 0.7670  decode.d7.loss_dice: 1.3025  decode.d8.loss_cls: 1.6379  decode.d8.loss_mask: 0.7547  decode.d8.loss_dice: 1.2828
2023/05/23 19:22:01 - mmengine - INFO - Iter(train) [  8650/160000]  lr: 9.5121e-06  eta: 18:00:34  time: 0.4129  data_time: 0.0093  memory: 4839  grad_norm: 93.5208  loss: 39.9370  decode.loss_cls: 1.4653  decode.loss_mask: 0.8508  decode.loss_dice: 1.4101  decode.d0.loss_cls: 3.4746  decode.d0.loss_mask: 0.9491  decode.d0.loss_dice: 1.6245  decode.d1.loss_cls: 1.5912  decode.d1.loss_mask: 0.8686  decode.d1.loss_dice: 1.4441  decode.d2.loss_cls: 1.5614  decode.d2.loss_mask: 0.8457  decode.d2.loss_dice: 1.4379  decode.d3.loss_cls: 1.4989  decode.d3.loss_mask: 0.8369  decode.d3.loss_dice: 1.3915  decode.d4.loss_cls: 1.4790  decode.d4.loss_mask: 0.8481  decode.d4.loss_dice: 1.3975  decode.d5.loss_cls: 1.5003  decode.d5.loss_mask: 0.8575  decode.d5.loss_dice: 1.4160  decode.d6.loss_cls: 1.4575  decode.d6.loss_mask: 0.8417  decode.d6.loss_dice: 1.4309  decode.d7.loss_cls: 1.4609  decode.d7.loss_mask: 0.8486  decode.d7.loss_dice: 1.4128  decode.d8.loss_cls: 1.4165  decode.d8.loss_mask: 0.8586  decode.d8.loss_dice: 1.4604
2023/05/23 19:22:22 - mmengine - INFO - Iter(train) [  8700/160000]  lr: 9.5093e-06  eta: 18:00:07  time: 0.4082  data_time: 0.0100  memory: 4844  grad_norm: 97.8742  loss: 42.2253  decode.loss_cls: 1.5506  decode.loss_mask: 0.7986  decode.loss_dice: 1.5789  decode.d0.loss_cls: 3.4041  decode.d0.loss_mask: 0.8045  decode.d0.loss_dice: 1.7805  decode.d1.loss_cls: 1.8365  decode.d1.loss_mask: 0.7918  decode.d1.loss_dice: 1.7329  decode.d2.loss_cls: 1.7064  decode.d2.loss_mask: 0.7662  decode.d2.loss_dice: 1.6899  decode.d3.loss_cls: 1.6893  decode.d3.loss_mask: 0.7610  decode.d3.loss_dice: 1.6192  decode.d4.loss_cls: 1.6277  decode.d4.loss_mask: 0.7380  decode.d4.loss_dice: 1.6029  decode.d5.loss_cls: 1.6184  decode.d5.loss_mask: 0.7504  decode.d5.loss_dice: 1.5859  decode.d6.loss_cls: 1.5586  decode.d6.loss_mask: 0.7870  decode.d6.loss_dice: 1.5888  decode.d7.loss_cls: 1.5596  decode.d7.loss_mask: 0.7717  decode.d7.loss_dice: 1.5989  decode.d8.loss_cls: 1.5622  decode.d8.loss_mask: 0.7866  decode.d8.loss_dice: 1.5783
2023/05/23 19:22:44 - mmengine - INFO - Iter(train) [  8750/160000]  lr: 9.5065e-06  eta: 17:59:53  time: 0.4439  data_time: 0.0092  memory: 4836  grad_norm: 95.0369  loss: 41.1440  decode.loss_cls: 1.5773  decode.loss_mask: 0.7652  decode.loss_dice: 1.5278  decode.d0.loss_cls: 3.3163  decode.d0.loss_mask: 0.7981  decode.d0.loss_dice: 1.6891  decode.d1.loss_cls: 1.6911  decode.d1.loss_mask: 0.8152  decode.d1.loss_dice: 1.6200  decode.d2.loss_cls: 1.5257  decode.d2.loss_mask: 0.7871  decode.d2.loss_dice: 1.5997  decode.d3.loss_cls: 1.5496  decode.d3.loss_mask: 0.7885  decode.d3.loss_dice: 1.5738  decode.d4.loss_cls: 1.6297  decode.d4.loss_mask: 0.7601  decode.d4.loss_dice: 1.5317  decode.d5.loss_cls: 1.5982  decode.d5.loss_mask: 0.7729  decode.d5.loss_dice: 1.5866  decode.d6.loss_cls: 1.5565  decode.d6.loss_mask: 0.7430  decode.d6.loss_dice: 1.5586  decode.d7.loss_cls: 1.5975  decode.d7.loss_mask: 0.7564  decode.d7.loss_dice: 1.5596  decode.d8.loss_cls: 1.5526  decode.d8.loss_mask: 0.7589  decode.d8.loss_dice: 1.5572
2023/05/23 19:23:04 - mmengine - INFO - Iter(train) [  8800/160000]  lr: 9.5037e-06  eta: 17:59:18  time: 0.4176  data_time: 0.0095  memory: 4846  grad_norm: 97.9752  loss: 34.3294  decode.loss_cls: 1.3081  decode.loss_mask: 0.7453  decode.loss_dice: 1.1405  decode.d0.loss_cls: 3.1144  decode.d0.loss_mask: 0.8418  decode.d0.loss_dice: 1.2509  decode.d1.loss_cls: 1.4207  decode.d1.loss_mask: 0.8320  decode.d1.loss_dice: 1.2978  decode.d2.loss_cls: 1.3157  decode.d2.loss_mask: 0.7898  decode.d2.loss_dice: 1.1631  decode.d3.loss_cls: 1.3060  decode.d3.loss_mask: 0.7788  decode.d3.loss_dice: 1.1578  decode.d4.loss_cls: 1.2412  decode.d4.loss_mask: 0.7727  decode.d4.loss_dice: 1.1461  decode.d5.loss_cls: 1.2919  decode.d5.loss_mask: 0.7415  decode.d5.loss_dice: 1.1501  decode.d6.loss_cls: 1.2196  decode.d6.loss_mask: 0.7647  decode.d6.loss_dice: 1.1756  decode.d7.loss_cls: 1.2917  decode.d7.loss_mask: 0.7423  decode.d7.loss_dice: 1.1292  decode.d8.loss_cls: 1.3154  decode.d8.loss_mask: 0.7335  decode.d8.loss_dice: 1.1512
2023/05/23 19:23:27 - mmengine - INFO - Iter(train) [  8850/160000]  lr: 9.5008e-06  eta: 17:59:29  time: 0.4658  data_time: 0.0099  memory: 4877  grad_norm: 99.2775  loss: 46.1807  decode.loss_cls: 1.9386  decode.loss_mask: 0.7946  decode.loss_dice: 1.6149  decode.d0.loss_cls: 3.7298  decode.d0.loss_mask: 0.8508  decode.d0.loss_dice: 1.8705  decode.d1.loss_cls: 2.1120  decode.d1.loss_mask: 0.7936  decode.d1.loss_dice: 1.7710  decode.d2.loss_cls: 2.0836  decode.d2.loss_mask: 0.7788  decode.d2.loss_dice: 1.6088  decode.d3.loss_cls: 2.1073  decode.d3.loss_mask: 0.7762  decode.d3.loss_dice: 1.5931  decode.d4.loss_cls: 2.0199  decode.d4.loss_mask: 0.8090  decode.d4.loss_dice: 1.5888  decode.d5.loss_cls: 2.0190  decode.d5.loss_mask: 0.7758  decode.d5.loss_dice: 1.5820  decode.d6.loss_cls: 1.9468  decode.d6.loss_mask: 0.7945  decode.d6.loss_dice: 1.5601  decode.d7.loss_cls: 1.9350  decode.d7.loss_mask: 0.8161  decode.d7.loss_dice: 1.6026  decode.d8.loss_cls: 1.9010  decode.d8.loss_mask: 0.8178  decode.d8.loss_dice: 1.5884
2023/05/23 19:23:50 - mmengine - INFO - Iter(train) [  8900/160000]  lr: 9.4980e-06  eta: 17:59:20  time: 0.4417  data_time: 0.0096  memory: 4821  grad_norm: 106.7681  loss: 30.2884  decode.loss_cls: 1.2152  decode.loss_mask: 0.6125  decode.loss_dice: 0.8857  decode.d0.loss_cls: 3.0732  decode.d0.loss_mask: 0.6763  decode.d0.loss_dice: 0.9804  decode.d1.loss_cls: 1.4467  decode.d1.loss_mask: 0.5951  decode.d1.loss_dice: 0.9607  decode.d2.loss_cls: 1.3215  decode.d2.loss_mask: 0.6001  decode.d2.loss_dice: 0.9271  decode.d3.loss_cls: 1.2750  decode.d3.loss_mask: 0.6467  decode.d3.loss_dice: 0.9163  decode.d4.loss_cls: 1.3082  decode.d4.loss_mask: 0.6675  decode.d4.loss_dice: 0.9203  decode.d5.loss_cls: 1.2939  decode.d5.loss_mask: 0.6408  decode.d5.loss_dice: 0.9008  decode.d6.loss_cls: 1.3406  decode.d6.loss_mask: 0.6475  decode.d6.loss_dice: 0.8866  decode.d7.loss_cls: 1.2668  decode.d7.loss_mask: 0.6176  decode.d7.loss_dice: 0.9326  decode.d8.loss_cls: 1.2520  decode.d8.loss_mask: 0.5814  decode.d8.loss_dice: 0.8991
2023/05/23 19:24:10 - mmengine - INFO - Iter(train) [  8950/160000]  lr: 9.4952e-06  eta: 17:58:45  time: 0.4143  data_time: 0.0097  memory: 4901  grad_norm: 108.3235  loss: 41.8909  decode.loss_cls: 1.6051  decode.loss_mask: 0.8793  decode.loss_dice: 1.3852  decode.d0.loss_cls: 3.6310  decode.d0.loss_mask: 0.9235  decode.d0.loss_dice: 1.5439  decode.d1.loss_cls: 1.7603  decode.d1.loss_mask: 0.9692  decode.d1.loss_dice: 1.4995  decode.d2.loss_cls: 1.6587  decode.d2.loss_mask: 0.9588  decode.d2.loss_dice: 1.4278  decode.d3.loss_cls: 1.6998  decode.d3.loss_mask: 0.8877  decode.d3.loss_dice: 1.3835  decode.d4.loss_cls: 1.6366  decode.d4.loss_mask: 0.9122  decode.d4.loss_dice: 1.3953  decode.d5.loss_cls: 1.6031  decode.d5.loss_mask: 0.9034  decode.d5.loss_dice: 1.3979  decode.d6.loss_cls: 1.7168  decode.d6.loss_mask: 0.8876  decode.d6.loss_dice: 1.4045  decode.d7.loss_cls: 1.6422  decode.d7.loss_mask: 0.9188  decode.d7.loss_dice: 1.3703  decode.d8.loss_cls: 1.6331  decode.d8.loss_mask: 0.8849  decode.d8.loss_dice: 1.3710
2023/05/23 19:24:31 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 19:24:31 - mmengine - INFO - Iter(train) [  9000/160000]  lr: 9.4923e-06  eta: 17:58:06  time: 0.4066  data_time: 0.0098  memory: 4844  grad_norm: 104.4263  loss: 33.5800  decode.loss_cls: 1.3164  decode.loss_mask: 0.6722  decode.loss_dice: 1.1146  decode.d0.loss_cls: 3.1000  decode.d0.loss_mask: 0.6915  decode.d0.loss_dice: 1.2703  decode.d1.loss_cls: 1.5239  decode.d1.loss_mask: 0.7173  decode.d1.loss_dice: 1.1965  decode.d2.loss_cls: 1.3758  decode.d2.loss_mask: 0.6958  decode.d2.loss_dice: 1.1722  decode.d3.loss_cls: 1.3184  decode.d3.loss_mask: 0.6883  decode.d3.loss_dice: 1.1234  decode.d4.loss_cls: 1.2989  decode.d4.loss_mask: 0.7128  decode.d4.loss_dice: 1.1527  decode.d5.loss_cls: 1.2716  decode.d5.loss_mask: 0.6973  decode.d5.loss_dice: 1.1408  decode.d6.loss_cls: 1.3064  decode.d6.loss_mask: 0.6973  decode.d6.loss_dice: 1.1108  decode.d7.loss_cls: 1.3105  decode.d7.loss_mask: 0.6864  decode.d7.loss_dice: 1.1112  decode.d8.loss_cls: 1.3191  decode.d8.loss_mask: 0.6702  decode.d8.loss_dice: 1.1175
2023/05/23 19:24:31 - mmengine - INFO - Saving checkpoint at 9000 iterations
2023/05/23 19:24:57 - mmengine - INFO - Iter(train) [  9050/160000]  lr: 9.4895e-06  eta: 17:59:09  time: 0.4130  data_time: 0.0096  memory: 4821  grad_norm: 96.7742  loss: 42.4277  decode.loss_cls: 1.3847  decode.loss_mask: 0.9500  decode.loss_dice: 1.6110  decode.d0.loss_cls: 3.3112  decode.d0.loss_mask: 0.9807  decode.d0.loss_dice: 1.8141  decode.d1.loss_cls: 1.5705  decode.d1.loss_mask: 1.0171  decode.d1.loss_dice: 1.7069  decode.d2.loss_cls: 1.4551  decode.d2.loss_mask: 0.9998  decode.d2.loss_dice: 1.6355  decode.d3.loss_cls: 1.4996  decode.d3.loss_mask: 0.9218  decode.d3.loss_dice: 1.6143  decode.d4.loss_cls: 1.4471  decode.d4.loss_mask: 0.9213  decode.d4.loss_dice: 1.6110  decode.d5.loss_cls: 1.4254  decode.d5.loss_mask: 0.9398  decode.d5.loss_dice: 1.6058  decode.d6.loss_cls: 1.4711  decode.d6.loss_mask: 0.9594  decode.d6.loss_dice: 1.6006  decode.d7.loss_cls: 1.3931  decode.d7.loss_mask: 0.9761  decode.d7.loss_dice: 1.6095  decode.d8.loss_cls: 1.4040  decode.d8.loss_mask: 0.9733  decode.d8.loss_dice: 1.6180
2023/05/23 19:25:18 - mmengine - INFO - Iter(train) [  9100/160000]  lr: 9.4867e-06  eta: 17:58:44  time: 0.4090  data_time: 0.0095  memory: 4872  grad_norm: 98.1792  loss: 42.3254  decode.loss_cls: 1.5974  decode.loss_mask: 1.0044  decode.loss_dice: 1.3798  decode.d0.loss_cls: 3.4379  decode.d0.loss_mask: 1.0426  decode.d0.loss_dice: 1.6632  decode.d1.loss_cls: 1.7117  decode.d1.loss_mask: 1.0211  decode.d1.loss_dice: 1.5713  decode.d2.loss_cls: 1.6300  decode.d2.loss_mask: 0.9948  decode.d2.loss_dice: 1.5378  decode.d3.loss_cls: 1.6657  decode.d3.loss_mask: 0.9498  decode.d3.loss_dice: 1.4105  decode.d4.loss_cls: 1.5523  decode.d4.loss_mask: 0.9798  decode.d4.loss_dice: 1.4114  decode.d5.loss_cls: 1.6563  decode.d5.loss_mask: 0.9458  decode.d5.loss_dice: 1.3728  decode.d6.loss_cls: 1.6012  decode.d6.loss_mask: 0.9329  decode.d6.loss_dice: 1.3612  decode.d7.loss_cls: 1.6024  decode.d7.loss_mask: 0.9162  decode.d7.loss_dice: 1.3761  decode.d8.loss_cls: 1.6491  decode.d8.loss_mask: 0.9391  decode.d8.loss_dice: 1.4109
2023/05/23 19:25:39 - mmengine - INFO - Iter(train) [  9150/160000]  lr: 9.4839e-06  eta: 17:58:08  time: 0.4107  data_time: 0.0097  memory: 4867  grad_norm: 97.1726  loss: 40.8174  decode.loss_cls: 1.6363  decode.loss_mask: 0.8427  decode.loss_dice: 1.3476  decode.d0.loss_cls: 3.4839  decode.d0.loss_mask: 0.8649  decode.d0.loss_dice: 1.5672  decode.d1.loss_cls: 1.6987  decode.d1.loss_mask: 0.8724  decode.d1.loss_dice: 1.4805  decode.d2.loss_cls: 1.5298  decode.d2.loss_mask: 0.8867  decode.d2.loss_dice: 1.4443  decode.d3.loss_cls: 1.6715  decode.d3.loss_mask: 0.8541  decode.d3.loss_dice: 1.4053  decode.d4.loss_cls: 1.6163  decode.d4.loss_mask: 0.8514  decode.d4.loss_dice: 1.4048  decode.d5.loss_cls: 1.5364  decode.d5.loss_mask: 0.8683  decode.d5.loss_dice: 1.3917  decode.d6.loss_cls: 1.5537  decode.d6.loss_mask: 0.8788  decode.d6.loss_dice: 1.3585  decode.d7.loss_cls: 1.5632  decode.d7.loss_mask: 0.8864  decode.d7.loss_dice: 1.4287  decode.d8.loss_cls: 1.6305  decode.d8.loss_mask: 0.8415  decode.d8.loss_dice: 1.4215
2023/05/23 19:25:59 - mmengine - INFO - Iter(train) [  9200/160000]  lr: 9.4810e-06  eta: 17:57:28  time: 0.4006  data_time: 0.0093  memory: 4836  grad_norm: 105.8326  loss: 48.0165  decode.loss_cls: 2.0912  decode.loss_mask: 0.8917  decode.loss_dice: 1.5954  decode.d0.loss_cls: 4.0659  decode.d0.loss_mask: 0.9444  decode.d0.loss_dice: 1.7737  decode.d1.loss_cls: 2.2330  decode.d1.loss_mask: 0.8986  decode.d1.loss_dice: 1.6478  decode.d2.loss_cls: 2.0619  decode.d2.loss_mask: 0.8748  decode.d2.loss_dice: 1.5894  decode.d3.loss_cls: 2.1130  decode.d3.loss_mask: 0.9060  decode.d3.loss_dice: 1.5333  decode.d4.loss_cls: 2.0677  decode.d4.loss_mask: 0.9189  decode.d4.loss_dice: 1.5948  decode.d5.loss_cls: 2.0806  decode.d5.loss_mask: 0.8792  decode.d5.loss_dice: 1.5542  decode.d6.loss_cls: 2.0772  decode.d6.loss_mask: 0.8723  decode.d6.loss_dice: 1.5851  decode.d7.loss_cls: 2.0673  decode.d7.loss_mask: 0.9124  decode.d7.loss_dice: 1.6148  decode.d8.loss_cls: 2.0990  decode.d8.loss_mask: 0.8970  decode.d8.loss_dice: 1.5760
2023/05/23 19:26:20 - mmengine - INFO - Iter(train) [  9250/160000]  lr: 9.4782e-06  eta: 17:56:56  time: 0.4187  data_time: 0.0094  memory: 4918  grad_norm: 91.5497  loss: 34.1040  decode.loss_cls: 1.3817  decode.loss_mask: 0.7093  decode.loss_dice: 1.0517  decode.d0.loss_cls: 2.9948  decode.d0.loss_mask: 0.7745  decode.d0.loss_dice: 1.2265  decode.d1.loss_cls: 1.4596  decode.d1.loss_mask: 0.7221  decode.d1.loss_dice: 1.1505  decode.d2.loss_cls: 1.3776  decode.d2.loss_mask: 0.7036  decode.d2.loss_dice: 1.1466  decode.d3.loss_cls: 1.4776  decode.d3.loss_mask: 0.7027  decode.d3.loss_dice: 1.1025  decode.d4.loss_cls: 1.4083  decode.d4.loss_mask: 0.7028  decode.d4.loss_dice: 1.0946  decode.d5.loss_cls: 1.4164  decode.d5.loss_mask: 0.7247  decode.d5.loss_dice: 1.1048  decode.d6.loss_cls: 1.4034  decode.d6.loss_mask: 0.7321  decode.d6.loss_dice: 1.0972  decode.d7.loss_cls: 1.3528  decode.d7.loss_mask: 0.7510  decode.d7.loss_dice: 1.1195  decode.d8.loss_cls: 1.3999  decode.d8.loss_mask: 0.7231  decode.d8.loss_dice: 1.0922
2023/05/23 19:26:41 - mmengine - INFO - Iter(train) [  9300/160000]  lr: 9.4754e-06  eta: 17:56:23  time: 0.4215  data_time: 0.0103  memory: 4840  grad_norm: 104.7817  loss: 49.6637  decode.loss_cls: 1.8140  decode.loss_mask: 1.0491  decode.loss_dice: 1.8322  decode.d0.loss_cls: 3.7485  decode.d0.loss_mask: 1.0948  decode.d0.loss_dice: 2.0234  decode.d1.loss_cls: 2.0135  decode.d1.loss_mask: 1.0784  decode.d1.loss_dice: 1.9074  decode.d2.loss_cls: 1.8740  decode.d2.loss_mask: 1.0476  decode.d2.loss_dice: 1.8688  decode.d3.loss_cls: 1.8721  decode.d3.loss_mask: 1.0600  decode.d3.loss_dice: 1.8437  decode.d4.loss_cls: 1.8070  decode.d4.loss_mask: 1.0748  decode.d4.loss_dice: 1.8380  decode.d5.loss_cls: 1.8005  decode.d5.loss_mask: 1.0812  decode.d5.loss_dice: 1.8034  decode.d6.loss_cls: 1.8724  decode.d6.loss_mask: 1.0753  decode.d6.loss_dice: 1.7433  decode.d7.loss_cls: 1.8734  decode.d7.loss_mask: 1.0875  decode.d7.loss_dice: 1.7933  decode.d8.loss_cls: 1.8020  decode.d8.loss_mask: 1.0645  decode.d8.loss_dice: 1.8197
2023/05/23 19:27:01 - mmengine - INFO - Iter(train) [  9350/160000]  lr: 9.4725e-06  eta: 17:55:51  time: 0.4132  data_time: 0.0094  memory: 4863  grad_norm: 114.2967  loss: 48.5923  decode.loss_cls: 1.7165  decode.loss_mask: 1.0907  decode.loss_dice: 1.7757  decode.d0.loss_cls: 3.7904  decode.d0.loss_mask: 1.1078  decode.d0.loss_dice: 2.0424  decode.d1.loss_cls: 1.9515  decode.d1.loss_mask: 1.1049  decode.d1.loss_dice: 1.9634  decode.d2.loss_cls: 1.9021  decode.d2.loss_mask: 1.0106  decode.d2.loss_dice: 1.7911  decode.d3.loss_cls: 1.8030  decode.d3.loss_mask: 1.0234  decode.d3.loss_dice: 1.7544  decode.d4.loss_cls: 1.7799  decode.d4.loss_mask: 1.0342  decode.d4.loss_dice: 1.7085  decode.d5.loss_cls: 1.7910  decode.d5.loss_mask: 1.0285  decode.d5.loss_dice: 1.7591  decode.d6.loss_cls: 1.7704  decode.d6.loss_mask: 1.0401  decode.d6.loss_dice: 1.7669  decode.d7.loss_cls: 1.7688  decode.d7.loss_mask: 1.0401  decode.d7.loss_dice: 1.7511  decode.d8.loss_cls: 1.7462  decode.d8.loss_mask: 1.0493  decode.d8.loss_dice: 1.7301
2023/05/23 19:27:22 - mmengine - INFO - Iter(train) [  9400/160000]  lr: 9.4697e-06  eta: 17:55:19  time: 0.4097  data_time: 0.0093  memory: 4856  grad_norm: 101.5377  loss: 49.0555  decode.loss_cls: 1.8972  decode.loss_mask: 1.0332  decode.loss_dice: 1.6669  decode.d0.loss_cls: 3.9559  decode.d0.loss_mask: 1.1323  decode.d0.loss_dice: 1.9600  decode.d1.loss_cls: 2.2055  decode.d1.loss_mask: 1.0790  decode.d1.loss_dice: 1.8453  decode.d2.loss_cls: 1.9341  decode.d2.loss_mask: 1.0318  decode.d2.loss_dice: 1.7908  decode.d3.loss_cls: 1.9319  decode.d3.loss_mask: 0.9903  decode.d3.loss_dice: 1.6518  decode.d4.loss_cls: 1.9000  decode.d4.loss_mask: 0.9917  decode.d4.loss_dice: 1.6641  decode.d5.loss_cls: 1.9247  decode.d5.loss_mask: 0.9683  decode.d5.loss_dice: 1.6413  decode.d6.loss_cls: 1.9241  decode.d6.loss_mask: 1.0194  decode.d6.loss_dice: 1.6821  decode.d7.loss_cls: 1.8970  decode.d7.loss_mask: 1.0332  decode.d7.loss_dice: 1.7010  decode.d8.loss_cls: 1.9044  decode.d8.loss_mask: 1.0180  decode.d8.loss_dice: 1.6799
2023/05/23 19:27:43 - mmengine - INFO - Iter(train) [  9450/160000]  lr: 9.4669e-06  eta: 17:54:44  time: 0.4115  data_time: 0.0099  memory: 4872  grad_norm: 87.8905  loss: 42.5681  decode.loss_cls: 1.6918  decode.loss_mask: 0.8646  decode.loss_dice: 1.4244  decode.d0.loss_cls: 3.7685  decode.d0.loss_mask: 0.9393  decode.d0.loss_dice: 1.5682  decode.d1.loss_cls: 1.8123  decode.d1.loss_mask: 0.9643  decode.d1.loss_dice: 1.5651  decode.d2.loss_cls: 1.7059  decode.d2.loss_mask: 0.9363  decode.d2.loss_dice: 1.4828  decode.d3.loss_cls: 1.6944  decode.d3.loss_mask: 0.9265  decode.d3.loss_dice: 1.4465  decode.d4.loss_cls: 1.7221  decode.d4.loss_mask: 0.8834  decode.d4.loss_dice: 1.3994  decode.d5.loss_cls: 1.7632  decode.d5.loss_mask: 0.8646  decode.d5.loss_dice: 1.4296  decode.d6.loss_cls: 1.6693  decode.d6.loss_mask: 0.8651  decode.d6.loss_dice: 1.3626  decode.d7.loss_cls: 1.6849  decode.d7.loss_mask: 0.8527  decode.d7.loss_dice: 1.3486  decode.d8.loss_cls: 1.7006  decode.d8.loss_mask: 0.8679  decode.d8.loss_dice: 1.3633
2023/05/23 19:28:03 - mmengine - INFO - Iter(train) [  9500/160000]  lr: 9.4641e-06  eta: 17:54:11  time: 0.4143  data_time: 0.0095  memory: 4845  grad_norm: 88.7099  loss: 48.6208  decode.loss_cls: 1.6506  decode.loss_mask: 1.1229  decode.loss_dice: 1.8606  decode.d0.loss_cls: 3.5440  decode.d0.loss_mask: 1.1475  decode.d0.loss_dice: 2.0466  decode.d1.loss_cls: 1.7612  decode.d1.loss_mask: 1.1217  decode.d1.loss_dice: 1.9747  decode.d2.loss_cls: 1.6330  decode.d2.loss_mask: 1.1244  decode.d2.loss_dice: 1.9014  decode.d3.loss_cls: 1.6909  decode.d3.loss_mask: 1.0444  decode.d3.loss_dice: 1.8274  decode.d4.loss_cls: 1.7222  decode.d4.loss_mask: 1.0635  decode.d4.loss_dice: 1.8355  decode.d5.loss_cls: 1.6919  decode.d5.loss_mask: 1.0854  decode.d5.loss_dice: 1.8559  decode.d6.loss_cls: 1.7067  decode.d6.loss_mask: 1.1137  decode.d6.loss_dice: 1.8423  decode.d7.loss_cls: 1.6674  decode.d7.loss_mask: 1.1203  decode.d7.loss_dice: 1.8639  decode.d8.loss_cls: 1.7008  decode.d8.loss_mask: 1.0815  decode.d8.loss_dice: 1.8181
2023/05/23 19:28:24 - mmengine - INFO - Iter(train) [  9550/160000]  lr: 9.4612e-06  eta: 17:53:35  time: 0.4181  data_time: 0.0095  memory: 4858  grad_norm: 93.2163  loss: 47.7657  decode.loss_cls: 1.9665  decode.loss_mask: 0.9042  decode.loss_dice: 1.6187  decode.d0.loss_cls: 4.1283  decode.d0.loss_mask: 0.9046  decode.d0.loss_dice: 1.8688  decode.d1.loss_cls: 2.0789  decode.d1.loss_mask: 0.8925  decode.d1.loss_dice: 1.7926  decode.d2.loss_cls: 1.9381  decode.d2.loss_mask: 0.8702  decode.d2.loss_dice: 1.7037  decode.d3.loss_cls: 2.0023  decode.d3.loss_mask: 0.8609  decode.d3.loss_dice: 1.6214  decode.d4.loss_cls: 1.9700  decode.d4.loss_mask: 0.8930  decode.d4.loss_dice: 1.6548  decode.d5.loss_cls: 1.9895  decode.d5.loss_mask: 0.8971  decode.d5.loss_dice: 1.6665  decode.d6.loss_cls: 2.0085  decode.d6.loss_mask: 0.9022  decode.d6.loss_dice: 1.6165  decode.d7.loss_cls: 1.9949  decode.d7.loss_mask: 0.9212  decode.d7.loss_dice: 1.6169  decode.d8.loss_cls: 2.0002  decode.d8.loss_mask: 0.8670  decode.d8.loss_dice: 1.6162
2023/05/23 19:28:44 - mmengine - INFO - Iter(train) [  9600/160000]  lr: 9.4584e-06  eta: 17:53:00  time: 0.4100  data_time: 0.0092  memory: 4859  grad_norm: 126.1500  loss: 38.0613  decode.loss_cls: 1.4107  decode.loss_mask: 0.7431  decode.loss_dice: 1.3533  decode.d0.loss_cls: 3.3211  decode.d0.loss_mask: 0.7830  decode.d0.loss_dice: 1.5391  decode.d1.loss_cls: 1.7061  decode.d1.loss_mask: 0.7515  decode.d1.loss_dice: 1.4450  decode.d2.loss_cls: 1.6074  decode.d2.loss_mask: 0.7333  decode.d2.loss_dice: 1.4023  decode.d3.loss_cls: 1.5124  decode.d3.loss_mask: 0.7634  decode.d3.loss_dice: 1.3553  decode.d4.loss_cls: 1.5002  decode.d4.loss_mask: 0.7506  decode.d4.loss_dice: 1.3366  decode.d5.loss_cls: 1.5158  decode.d5.loss_mask: 0.7354  decode.d5.loss_dice: 1.3433  decode.d6.loss_cls: 1.4173  decode.d6.loss_mask: 0.7351  decode.d6.loss_dice: 1.3209  decode.d7.loss_cls: 1.4169  decode.d7.loss_mask: 0.7214  decode.d7.loss_dice: 1.3387  decode.d8.loss_cls: 1.4063  decode.d8.loss_mask: 0.7418  decode.d8.loss_dice: 1.3540
2023/05/23 19:29:05 - mmengine - INFO - Iter(train) [  9650/160000]  lr: 9.4556e-06  eta: 17:52:23  time: 0.4108  data_time: 0.0094  memory: 4845  grad_norm: 124.7173  loss: 37.2485  decode.loss_cls: 1.5629  decode.loss_mask: 0.7532  decode.loss_dice: 1.1396  decode.d0.loss_cls: 3.0571  decode.d0.loss_mask: 0.7476  decode.d0.loss_dice: 1.2947  decode.d1.loss_cls: 1.7306  decode.d1.loss_mask: 0.7658  decode.d1.loss_dice: 1.1937  decode.d2.loss_cls: 1.6855  decode.d2.loss_mask: 0.7667  decode.d2.loss_dice: 1.1420  decode.d3.loss_cls: 1.6814  decode.d3.loss_mask: 0.7457  decode.d3.loss_dice: 1.1058  decode.d4.loss_cls: 1.6522  decode.d4.loss_mask: 0.7559  decode.d4.loss_dice: 1.1756  decode.d5.loss_cls: 1.6589  decode.d5.loss_mask: 0.7667  decode.d5.loss_dice: 1.1339  decode.d6.loss_cls: 1.7083  decode.d6.loss_mask: 0.7610  decode.d6.loss_dice: 1.1456  decode.d7.loss_cls: 1.7066  decode.d7.loss_mask: 0.7431  decode.d7.loss_dice: 1.1461  decode.d8.loss_cls: 1.6159  decode.d8.loss_mask: 0.7466  decode.d8.loss_dice: 1.1598
2023/05/23 19:29:25 - mmengine - INFO - Iter(train) [  9700/160000]  lr: 9.4527e-06  eta: 17:51:48  time: 0.4257  data_time: 0.0095  memory: 4874  grad_norm: 110.6689  loss: 49.6133  decode.loss_cls: 1.8920  decode.loss_mask: 1.0036  decode.loss_dice: 1.8139  decode.d0.loss_cls: 3.7466  decode.d0.loss_mask: 1.0577  decode.d0.loss_dice: 1.9518  decode.d1.loss_cls: 2.0745  decode.d1.loss_mask: 1.0414  decode.d1.loss_dice: 1.8527  decode.d2.loss_cls: 2.0570  decode.d2.loss_mask: 1.0031  decode.d2.loss_dice: 1.8362  decode.d3.loss_cls: 1.9362  decode.d3.loss_mask: 0.9923  decode.d3.loss_dice: 1.7911  decode.d4.loss_cls: 1.8673  decode.d4.loss_mask: 1.0198  decode.d4.loss_dice: 1.8344  decode.d5.loss_cls: 1.8561  decode.d5.loss_mask: 1.0395  decode.d5.loss_dice: 1.8261  decode.d6.loss_cls: 1.9040  decode.d6.loss_mask: 1.0125  decode.d6.loss_dice: 1.8159  decode.d7.loss_cls: 1.8785  decode.d7.loss_mask: 1.0339  decode.d7.loss_dice: 1.8020  decode.d8.loss_cls: 1.8445  decode.d8.loss_mask: 1.0200  decode.d8.loss_dice: 1.8088
2023/05/23 19:29:47 - mmengine - INFO - Iter(train) [  9750/160000]  lr: 9.4499e-06  eta: 17:51:29  time: 0.4063  data_time: 0.0094  memory: 4992  grad_norm: 109.0962  loss: 37.4220  decode.loss_cls: 1.3678  decode.loss_mask: 0.8152  decode.loss_dice: 1.3291  decode.d0.loss_cls: 3.2288  decode.d0.loss_mask: 0.7655  decode.d0.loss_dice: 1.4186  decode.d1.loss_cls: 1.5782  decode.d1.loss_mask: 0.8144  decode.d1.loss_dice: 1.3836  decode.d2.loss_cls: 1.4971  decode.d2.loss_mask: 0.7699  decode.d2.loss_dice: 1.3907  decode.d3.loss_cls: 1.3300  decode.d3.loss_mask: 0.8180  decode.d3.loss_dice: 1.3388  decode.d4.loss_cls: 1.4017  decode.d4.loss_mask: 0.8028  decode.d4.loss_dice: 1.2943  decode.d5.loss_cls: 1.3995  decode.d5.loss_mask: 0.8115  decode.d5.loss_dice: 1.3433  decode.d6.loss_cls: 1.3902  decode.d6.loss_mask: 0.8000  decode.d6.loss_dice: 1.3248  decode.d7.loss_cls: 1.4148  decode.d7.loss_mask: 0.8170  decode.d7.loss_dice: 1.3226  decode.d8.loss_cls: 1.3558  decode.d8.loss_mask: 0.7958  decode.d8.loss_dice: 1.3023
2023/05/23 19:30:08 - mmengine - INFO - Iter(train) [  9800/160000]  lr: 9.4471e-06  eta: 17:50:56  time: 0.4187  data_time: 0.0099  memory: 4888  grad_norm: 116.5206  loss: 50.8108  decode.loss_cls: 1.8839  decode.loss_mask: 1.1374  decode.loss_dice: 1.8187  decode.d0.loss_cls: 3.6343  decode.d0.loss_mask: 1.1353  decode.d0.loss_dice: 2.0867  decode.d1.loss_cls: 1.9630  decode.d1.loss_mask: 1.0852  decode.d1.loss_dice: 1.9726  decode.d2.loss_cls: 1.9031  decode.d2.loss_mask: 1.0462  decode.d2.loss_dice: 1.9083  decode.d3.loss_cls: 1.9338  decode.d3.loss_mask: 1.0969  decode.d3.loss_dice: 1.8612  decode.d4.loss_cls: 1.9059  decode.d4.loss_mask: 1.1064  decode.d4.loss_dice: 1.8774  decode.d5.loss_cls: 1.9125  decode.d5.loss_mask: 1.1079  decode.d5.loss_dice: 1.8828  decode.d6.loss_cls: 1.8858  decode.d6.loss_mask: 1.1072  decode.d6.loss_dice: 1.8644  decode.d7.loss_cls: 1.8761  decode.d7.loss_mask: 1.1252  decode.d7.loss_dice: 1.8396  decode.d8.loss_cls: 1.9121  decode.d8.loss_mask: 1.1408  decode.d8.loss_dice: 1.8004
2023/05/23 19:30:30 - mmengine - INFO - Iter(train) [  9850/160000]  lr: 9.4442e-06  eta: 17:50:50  time: 0.4287  data_time: 0.0103  memory: 4849  grad_norm: 96.6531  loss: 51.7314  decode.loss_cls: 1.9631  decode.loss_mask: 1.0285  decode.loss_dice: 1.8381  decode.d0.loss_cls: 3.9472  decode.d0.loss_mask: 1.1226  decode.d0.loss_dice: 2.1016  decode.d1.loss_cls: 2.2489  decode.d1.loss_mask: 1.1014  decode.d1.loss_dice: 1.9202  decode.d2.loss_cls: 2.0581  decode.d2.loss_mask: 1.0774  decode.d2.loss_dice: 1.9169  decode.d3.loss_cls: 2.0724  decode.d3.loss_mask: 1.0362  decode.d3.loss_dice: 1.8699  decode.d4.loss_cls: 2.0252  decode.d4.loss_mask: 1.0420  decode.d4.loss_dice: 1.8915  decode.d5.loss_cls: 1.9987  decode.d5.loss_mask: 1.0424  decode.d5.loss_dice: 1.8647  decode.d6.loss_cls: 2.0012  decode.d6.loss_mask: 1.0076  decode.d6.loss_dice: 1.8378  decode.d7.loss_cls: 1.9530  decode.d7.loss_mask: 1.0514  decode.d7.loss_dice: 1.8612  decode.d8.loss_cls: 1.9775  decode.d8.loss_mask: 1.0483  decode.d8.loss_dice: 1.8265
2023/05/23 19:30:51 - mmengine - INFO - Iter(train) [  9900/160000]  lr: 9.4414e-06  eta: 17:50:26  time: 0.4008  data_time: 0.0096  memory: 4866  grad_norm: 101.8354  loss: 41.7174  decode.loss_cls: 1.6804  decode.loss_mask: 0.8106  decode.loss_dice: 1.3612  decode.d0.loss_cls: 3.5380  decode.d0.loss_mask: 0.9832  decode.d0.loss_dice: 1.6735  decode.d1.loss_cls: 1.7644  decode.d1.loss_mask: 0.9620  decode.d1.loss_dice: 1.4905  decode.d2.loss_cls: 1.7021  decode.d2.loss_mask: 0.8745  decode.d2.loss_dice: 1.4628  decode.d3.loss_cls: 1.6408  decode.d3.loss_mask: 0.8629  decode.d3.loss_dice: 1.3785  decode.d4.loss_cls: 1.6557  decode.d4.loss_mask: 0.8740  decode.d4.loss_dice: 1.3876  decode.d5.loss_cls: 1.6198  decode.d5.loss_mask: 0.8848  decode.d5.loss_dice: 1.4166  decode.d6.loss_cls: 1.6361  decode.d6.loss_mask: 0.8856  decode.d6.loss_dice: 1.3566  decode.d7.loss_cls: 1.6793  decode.d7.loss_mask: 0.8737  decode.d7.loss_dice: 1.3700  decode.d8.loss_cls: 1.6814  decode.d8.loss_mask: 0.8427  decode.d8.loss_dice: 1.3680
2023/05/23 19:31:12 - mmengine - INFO - Iter(train) [  9950/160000]  lr: 9.4386e-06  eta: 17:49:51  time: 0.4058  data_time: 0.0100  memory: 4827  grad_norm: 88.5841  loss: 49.4747  decode.loss_cls: 1.8133  decode.loss_mask: 0.9542  decode.loss_dice: 1.9178  decode.d0.loss_cls: 3.7214  decode.d0.loss_mask: 1.0216  decode.d0.loss_dice: 2.2179  decode.d1.loss_cls: 1.9146  decode.d1.loss_mask: 1.0145  decode.d1.loss_dice: 2.0544  decode.d2.loss_cls: 1.8240  decode.d2.loss_mask: 0.9790  decode.d2.loss_dice: 1.9454  decode.d3.loss_cls: 1.8806  decode.d3.loss_mask: 0.9681  decode.d3.loss_dice: 1.8893  decode.d4.loss_cls: 1.8573  decode.d4.loss_mask: 0.9675  decode.d4.loss_dice: 1.9282  decode.d5.loss_cls: 1.8029  decode.d5.loss_mask: 0.9501  decode.d5.loss_dice: 1.8900  decode.d6.loss_cls: 1.8240  decode.d6.loss_mask: 0.9468  decode.d6.loss_dice: 1.8878  decode.d7.loss_cls: 1.7859  decode.d7.loss_mask: 0.9392  decode.d7.loss_dice: 1.8895  decode.d8.loss_cls: 1.7888  decode.d8.loss_mask: 0.9789  decode.d8.loss_dice: 1.9218
2023/05/23 19:31:32 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 19:31:32 - mmengine - INFO - Iter(train) [ 10000/160000]  lr: 9.4358e-06  eta: 17:49:18  time: 0.4118  data_time: 0.0102  memory: 4851  grad_norm: 192.9002  loss: 35.6467  decode.loss_cls: 1.3095  decode.loss_mask: 0.7660  decode.loss_dice: 1.1926  decode.d0.loss_cls: 3.0298  decode.d0.loss_mask: 0.7977  decode.d0.loss_dice: 1.3478  decode.d1.loss_cls: 1.5177  decode.d1.loss_mask: 0.7947  decode.d1.loss_dice: 1.2437  decode.d2.loss_cls: 1.4055  decode.d2.loss_mask: 0.7724  decode.d2.loss_dice: 1.2480  decode.d3.loss_cls: 1.3344  decode.d3.loss_mask: 0.8194  decode.d3.loss_dice: 1.2726  decode.d4.loss_cls: 1.3251  decode.d4.loss_mask: 0.8345  decode.d4.loss_dice: 1.2330  decode.d5.loss_cls: 1.3295  decode.d5.loss_mask: 0.7873  decode.d5.loss_dice: 1.2443  decode.d6.loss_cls: 1.3296  decode.d6.loss_mask: 0.8042  decode.d6.loss_dice: 1.2333  decode.d7.loss_cls: 1.3153  decode.d7.loss_mask: 0.7907  decode.d7.loss_dice: 1.2419  decode.d8.loss_cls: 1.3029  decode.d8.loss_mask: 0.7838  decode.d8.loss_dice: 1.2394
2023/05/23 19:31:32 - mmengine - INFO - Saving checkpoint at 10000 iterations
2023/05/23 19:31:42 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:48  time: 0.0788  data_time: 0.0019  memory: 2167  
2023/05/23 19:31:46 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0812  data_time: 0.0020  memory: 2216  
2023/05/23 19:31:50 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:39  time: 0.0804  data_time: 0.0019  memory: 2167  
2023/05/23 19:31:54 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0793  data_time: 0.0019  memory: 2104  
2023/05/23 19:31:59 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0839  data_time: 0.0025  memory: 2831  
2023/05/23 19:32:03 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0806  data_time: 0.0019  memory: 2167  
2023/05/23 19:32:07 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0813  data_time: 0.0018  memory: 2167  
2023/05/23 19:32:14 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:20  time: 0.0814  data_time: 0.0020  memory: 2167  
2023/05/23 19:32:18 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.1018  data_time: 0.0021  memory: 2944  
2023/05/23 19:32:22 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:11  time: 0.0792  data_time: 0.0022  memory: 2356  
2023/05/23 19:32:26 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0786  data_time: 0.0019  memory: 2217  
2023/05/23 19:32:30 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0844  data_time: 0.0018  memory: 2328  
2023/05/23 19:32:34 - mmengine - INFO - per class results:
2023/05/23 19:32:34 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 83.79 | 92.34 |
|     bicycle      | 53.85 | 67.17 |
|       car        | 53.22 | 65.46 |
|    motorcycle    |  76.3 | 87.16 |
|     airplane     | 71.96 | 88.57 |
|       bus        | 75.61 | 88.02 |
|      train       | 74.29 |  87.3 |
|      truck       | 48.27 | 67.89 |
|       boat       | 48.26 | 70.08 |
|  traffic light   | 54.09 | 85.03 |
|   fire hydrant   | 64.81 | 93.18 |
|    stop sign     | 65.65 | 94.69 |
|  parking meter   |  74.7 | 78.21 |
|      bench       | 39.25 | 66.85 |
|       bird       | 76.52 | 88.04 |
|       cat        | 85.55 | 94.84 |
|       dog        | 72.86 | 81.05 |
|      horse       | 78.38 | 85.09 |
|      sheep       | 83.97 | 93.12 |
|       cow        | 75.75 | 86.58 |
|     elephant     | 87.23 | 90.81 |
|       bear       | 89.12 | 93.27 |
|      zebra       |  88.4 | 90.29 |
|     giraffe      | 82.08 | 90.77 |
|     backpack     | 21.32 | 33.77 |
|     umbrella     | 71.13 | 83.98 |
|     handbag      | 18.34 | 33.73 |
|       tie        |  10.0 | 22.68 |
|     suitcase     | 63.35 | 77.99 |
|     frisbee      | 51.95 | 81.36 |
|       skis       | 26.92 | 38.89 |
|    snowboard     | 27.57 | 48.17 |
|   sports ball    | 43.96 | 56.56 |
|       kite       | 44.82 | 49.28 |
|   baseball bat   | 40.38 | 51.09 |
|  baseball glove  | 53.35 | 67.53 |
|    skateboard    | 44.54 |  53.6 |
|    surfboard     | 65.45 | 85.59 |
|  tennis racket   | 67.67 | 88.14 |
|      bottle      | 42.87 | 60.53 |
|    wine glass    | 49.52 | 72.22 |
|       cup        | 40.27 | 70.86 |
|       fork       | 26.59 | 52.62 |
|      knife       | 12.41 | 28.64 |
|      spoon       |  9.44 | 11.87 |
|       bowl       | 36.54 | 49.25 |
|      banana      | 64.01 | 83.69 |
|      apple       | 36.36 |  55.0 |
|     sandwich     | 38.99 |  53.3 |
|      orange      | 66.72 |  82.1 |
|     broccoli     | 49.04 | 61.95 |
|      carrot      | 45.32 | 61.16 |
|     hot dog      | 44.15 | 50.87 |
|      pizza       | 64.29 |  76.4 |
|      donut       | 48.25 | 53.85 |
|       cake       | 47.26 | 82.01 |
|      chair       | 31.87 | 45.38 |
|      couch       | 45.03 | 76.83 |
|   potted plant   | 24.32 | 36.68 |
|       bed        | 56.35 | 76.87 |
|   dining table   | 40.14 | 72.52 |
|      toilet      | 71.78 | 85.55 |
|        tv        | 59.12 | 72.65 |
|      laptop      |  64.8 | 89.43 |
|      mouse       | 60.83 | 77.46 |
|      remote      | 44.72 | 71.95 |
|     keyboard     |  57.6 | 63.93 |
|    cell phone    | 56.96 | 72.37 |
|    microwave     | 52.36 | 71.14 |
|       oven       | 47.45 | 66.41 |
|     toaster      |  0.0  |  0.0  |
|       sink       |  54.4 | 71.38 |
|   refrigerator   |  59.3 | 73.51 |
|       book       | 33.88 | 42.95 |
|      clock       | 70.58 | 82.89 |
|       vase       | 50.49 | 69.92 |
|     scissors     | 62.52 | 72.17 |
|    teddy bear    |  73.3 | 87.83 |
|    hair drier    |  0.0  |  0.0  |
|    toothbrush    | 10.25 | 15.49 |
|      banner      | 19.48 | 65.46 |
|     blanket      |  0.0  |  0.0  |
|      branch      | 17.94 | 21.57 |
|      bridge      |  29.4 |  41.9 |
|  building-other  | 45.43 | 58.94 |
|       bush       | 24.58 | 32.67 |
|     cabinet      | 48.71 | 64.39 |
|       cage       | 18.25 | 27.12 |
|    cardboard     | 28.17 | 36.57 |
|      carpet      | 44.49 | 72.18 |
|  ceiling-other   | 58.78 | 77.21 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 10.92 |  13.7 |
|      clouds      | 40.51 | 49.05 |
|     counter      | 22.08 | 36.01 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 52.44 | 70.79 |
|    desk-stuff    | 35.52 | 43.84 |
|       dirt       | 38.84 | 69.11 |
|    door-stuff    | 28.09 | 41.16 |
|      fence       | 29.82 | 51.65 |
|   floor-marble   |  0.0  |  0.0  |
|   floor-other    | 12.65 | 15.38 |
|   floor-stone    |  0.01 |  0.01 |
|    floor-tile    | 52.28 | 66.69 |
|    floor-wood    | 55.99 | 62.21 |
|      flower      | 39.67 |  68.2 |
|       fog        |  0.01 |  0.01 |
|    food-other    | 26.93 | 52.61 |
|      fruit       | 27.64 | 39.82 |
| furniture-other  |  9.3  | 11.69 |
|      grass       | 68.49 |  82.6 |
|      gravel      | 17.57 | 21.36 |
|   ground-other   |  5.36 |  8.14 |
|       hill       |  9.82 | 11.78 |
|      house       | 16.37 | 17.75 |
|      leaves      | 23.73 | 36.91 |
|      light       | 30.41 | 47.54 |
|       mat        |  0.0  |  0.0  |
|      metal       | 25.63 | 42.93 |
|   mirror-stuff   | 25.94 | 43.35 |
|       moss       |  0.0  |  0.0  |
|     mountain     |  49.7 | 65.16 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  8.35 |  9.24 |
|       net        | 35.33 | 63.96 |
|      paper       |  29.1 | 49.44 |
|     pavement     | 45.85 | 72.24 |
|      pillow      |  0.09 |  0.09 |
|   plant-other    |  16.4 | 31.71 |
|     plastic      | 12.08 | 16.25 |
|     platform     | 23.13 | 44.74 |
|   playingfield   | 63.21 | 78.25 |
|     railing      |  0.03 |  0.04 |
|     railroad     | 54.25 | 73.74 |
|      river       |  9.79 | 10.48 |
|       road       | 55.09 | 65.15 |
|       rock       | 41.46 | 67.04 |
|       roof       | 17.29 | 26.18 |
|       rug        | 21.52 | 28.63 |
|      salad       |  0.0  |  0.0  |
|       sand       | 57.11 | 64.74 |
|       sea        | 83.62 | 89.31 |
|      shelf       | 29.56 | 42.98 |
|    sky-other     | 68.46 | 90.53 |
|    skyscraper    | 30.07 | 55.02 |
|       snow       | 86.03 | 91.75 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 10.48 | 14.82 |
|      stone       |  1.26 |  1.57 |
|      straw       | 21.93 | 26.53 |
| structural-other |  0.0  |  0.0  |
|      table       | 18.67 | 26.82 |
|       tent       |  4.75 |  5.94 |
|  textile-other   |  9.16 | 18.09 |
|      towel       | 27.02 | 32.76 |
|       tree       |  71.8 | 83.67 |
|    vegetable     | 17.67 | 24.94 |
|    wall-brick    | 37.68 | 54.35 |
|  wall-concrete   | 51.98 | 85.28 |
|    wall-other    |  8.07 |  9.91 |
|    wall-panel    |  5.95 |  6.47 |
|    wall-stone    | 27.77 | 30.36 |
|    wall-tile     | 57.03 | 72.19 |
|    wall-wood     | 32.18 | 45.58 |
|   water-other    | 25.66 |  68.9 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 40.09 | 49.13 |
|   window-other   | 36.54 | 64.81 |
|       wood       | 19.39 | 30.36 |
+------------------+-------+-------+
2023/05/23 19:32:34 - mmengine - INFO - Iter(val) [625/625]    aAcc: 66.4000  mIoU: 38.6500  mAcc: 51.4100  data_time: 0.0020  time: 0.0872
2023/05/23 19:32:34 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_5000.pth is removed
2023/05/23 19:32:37 - mmengine - INFO - The best checkpoint with 38.6500 mIoU at 10000 iter is saved to best_mIoU_iter_10000.pth.
2023/05/23 19:32:58 - mmengine - INFO - Iter(train) [ 10050/160000]  lr: 9.4329e-06  eta: 17:49:55  time: 0.4146  data_time: 0.0094  memory: 4871  grad_norm: 137.7557  loss: 39.9578  decode.loss_cls: 1.5280  decode.loss_mask: 0.9002  decode.loss_dice: 1.2617  decode.d0.loss_cls: 3.5457  decode.d0.loss_mask: 0.9779  decode.d0.loss_dice: 1.5322  decode.d1.loss_cls: 1.7269  decode.d1.loss_mask: 0.9625  decode.d1.loss_dice: 1.4513  decode.d2.loss_cls: 1.5074  decode.d2.loss_mask: 0.9356  decode.d2.loss_dice: 1.3511  decode.d3.loss_cls: 1.4174  decode.d3.loss_mask: 0.9603  decode.d3.loss_dice: 1.3212  decode.d4.loss_cls: 1.5395  decode.d4.loss_mask: 0.9205  decode.d4.loss_dice: 1.3279  decode.d5.loss_cls: 1.5305  decode.d5.loss_mask: 0.9150  decode.d5.loss_dice: 1.3054  decode.d6.loss_cls: 1.5187  decode.d6.loss_mask: 0.9299  decode.d6.loss_dice: 1.2823  decode.d7.loss_cls: 1.4771  decode.d7.loss_mask: 0.9020  decode.d7.loss_dice: 1.2744  decode.d8.loss_cls: 1.4764  decode.d8.loss_mask: 0.9283  decode.d8.loss_dice: 1.2504
2023/05/23 19:33:18 - mmengine - INFO - Iter(train) [ 10100/160000]  lr: 9.4301e-06  eta: 17:49:21  time: 0.4075  data_time: 0.0100  memory: 4864  grad_norm: 107.1377  loss: 51.0734  decode.loss_cls: 1.9191  decode.loss_mask: 1.0293  decode.loss_dice: 1.8258  decode.d0.loss_cls: 4.3205  decode.d0.loss_mask: 1.0728  decode.d0.loss_dice: 2.0512  decode.d1.loss_cls: 2.0508  decode.d1.loss_mask: 1.0723  decode.d1.loss_dice: 1.9180  decode.d2.loss_cls: 1.9600  decode.d2.loss_mask: 1.0265  decode.d2.loss_dice: 1.9211  decode.d3.loss_cls: 2.0371  decode.d3.loss_mask: 1.0191  decode.d3.loss_dice: 1.8465  decode.d4.loss_cls: 1.9930  decode.d4.loss_mask: 1.0020  decode.d4.loss_dice: 1.8457  decode.d5.loss_cls: 1.9694  decode.d5.loss_mask: 1.0204  decode.d5.loss_dice: 1.8366  decode.d6.loss_cls: 1.9914  decode.d6.loss_mask: 1.0127  decode.d6.loss_dice: 1.8315  decode.d7.loss_cls: 1.9993  decode.d7.loss_mask: 0.9890  decode.d7.loss_dice: 1.8204  decode.d8.loss_cls: 1.9231  decode.d8.loss_mask: 1.0106  decode.d8.loss_dice: 1.7581
2023/05/23 19:33:40 - mmengine - INFO - Iter(train) [ 10150/160000]  lr: 9.4273e-06  eta: 17:48:57  time: 0.4086  data_time: 0.0093  memory: 4829  grad_norm: 94.2769  loss: 41.5037  decode.loss_cls: 1.4744  decode.loss_mask: 0.7409  decode.loss_dice: 1.6763  decode.d0.loss_cls: 3.4183  decode.d0.loss_mask: 0.7880  decode.d0.loss_dice: 1.8516  decode.d1.loss_cls: 1.8166  decode.d1.loss_mask: 0.7708  decode.d1.loss_dice: 1.7082  decode.d2.loss_cls: 1.5850  decode.d2.loss_mask: 0.7554  decode.d2.loss_dice: 1.6836  decode.d3.loss_cls: 1.5190  decode.d3.loss_mask: 0.7362  decode.d3.loss_dice: 1.6731  decode.d4.loss_cls: 1.4815  decode.d4.loss_mask: 0.7344  decode.d4.loss_dice: 1.6924  decode.d5.loss_cls: 1.4739  decode.d5.loss_mask: 0.7314  decode.d5.loss_dice: 1.6969  decode.d6.loss_cls: 1.4440  decode.d6.loss_mask: 0.7365  decode.d6.loss_dice: 1.6894  decode.d7.loss_cls: 1.4153  decode.d7.loss_mask: 0.7354  decode.d7.loss_dice: 1.6759  decode.d8.loss_cls: 1.4093  decode.d8.loss_mask: 0.7370  decode.d8.loss_dice: 1.6529
2023/05/23 19:34:01 - mmengine - INFO - Iter(train) [ 10200/160000]  lr: 9.4244e-06  eta: 17:48:34  time: 0.4652  data_time: 0.0094  memory: 4846  grad_norm: 118.8900  loss: 41.3912  decode.loss_cls: 1.6149  decode.loss_mask: 0.7871  decode.loss_dice: 1.4907  decode.d0.loss_cls: 3.7995  decode.d0.loss_mask: 0.8667  decode.d0.loss_dice: 1.6855  decode.d1.loss_cls: 1.7358  decode.d1.loss_mask: 0.8614  decode.d1.loss_dice: 1.5984  decode.d2.loss_cls: 1.6699  decode.d2.loss_mask: 0.7844  decode.d2.loss_dice: 1.4567  decode.d3.loss_cls: 1.5509  decode.d3.loss_mask: 0.7693  decode.d3.loss_dice: 1.4148  decode.d4.loss_cls: 1.6049  decode.d4.loss_mask: 0.7422  decode.d4.loss_dice: 1.4336  decode.d5.loss_cls: 1.6331  decode.d5.loss_mask: 0.7831  decode.d5.loss_dice: 1.4819  decode.d6.loss_cls: 1.6598  decode.d6.loss_mask: 0.7710  decode.d6.loss_dice: 1.4579  decode.d7.loss_cls: 1.5993  decode.d7.loss_mask: 0.7775  decode.d7.loss_dice: 1.4418  decode.d8.loss_cls: 1.6852  decode.d8.loss_mask: 0.7894  decode.d8.loss_dice: 1.4446
2023/05/23 19:34:22 - mmengine - INFO - Iter(train) [ 10250/160000]  lr: 9.4216e-06  eta: 17:48:03  time: 0.4207  data_time: 0.0095  memory: 4906  grad_norm: 120.5706  loss: 42.9028  decode.loss_cls: 1.5798  decode.loss_mask: 0.8497  decode.loss_dice: 1.6041  decode.d0.loss_cls: 3.6818  decode.d0.loss_mask: 1.0067  decode.d0.loss_dice: 1.8525  decode.d1.loss_cls: 1.6739  decode.d1.loss_mask: 0.9075  decode.d1.loss_dice: 1.6556  decode.d2.loss_cls: 1.5049  decode.d2.loss_mask: 0.8579  decode.d2.loss_dice: 1.6162  decode.d3.loss_cls: 1.5502  decode.d3.loss_mask: 0.8303  decode.d3.loss_dice: 1.6118  decode.d4.loss_cls: 1.5753  decode.d4.loss_mask: 0.8473  decode.d4.loss_dice: 1.6246  decode.d5.loss_cls: 1.5385  decode.d5.loss_mask: 0.8583  decode.d5.loss_dice: 1.6078  decode.d6.loss_cls: 1.5734  decode.d6.loss_mask: 0.8476  decode.d6.loss_dice: 1.6062  decode.d7.loss_cls: 1.5145  decode.d7.loss_mask: 0.8550  decode.d7.loss_dice: 1.6153  decode.d8.loss_cls: 1.6046  decode.d8.loss_mask: 0.8404  decode.d8.loss_dice: 1.6110
2023/05/23 19:34:44 - mmengine - INFO - Iter(train) [ 10300/160000]  lr: 9.4188e-06  eta: 17:48:03  time: 0.4653  data_time: 0.0091  memory: 4808  grad_norm: 103.1570  loss: 40.2268  decode.loss_cls: 1.6011  decode.loss_mask: 0.7874  decode.loss_dice: 1.3819  decode.d0.loss_cls: 3.2696  decode.d0.loss_mask: 0.8356  decode.d0.loss_dice: 1.5873  decode.d1.loss_cls: 1.8140  decode.d1.loss_mask: 0.8310  decode.d1.loss_dice: 1.4672  decode.d2.loss_cls: 1.7094  decode.d2.loss_mask: 0.7983  decode.d2.loss_dice: 1.3786  decode.d3.loss_cls: 1.7051  decode.d3.loss_mask: 0.7382  decode.d3.loss_dice: 1.3813  decode.d4.loss_cls: 1.6631  decode.d4.loss_mask: 0.7495  decode.d4.loss_dice: 1.4165  decode.d5.loss_cls: 1.7206  decode.d5.loss_mask: 0.7424  decode.d5.loss_dice: 1.3637  decode.d6.loss_cls: 1.6657  decode.d6.loss_mask: 0.7329  decode.d6.loss_dice: 1.3493  decode.d7.loss_cls: 1.7002  decode.d7.loss_mask: 0.7152  decode.d7.loss_dice: 1.3570  decode.d8.loss_cls: 1.6445  decode.d8.loss_mask: 0.7200  decode.d8.loss_dice: 1.4004
2023/05/23 19:35:06 - mmengine - INFO - Iter(train) [ 10350/160000]  lr: 9.4159e-06  eta: 17:47:47  time: 0.4026  data_time: 0.0091  memory: 4866  grad_norm: 114.6690  loss: 40.2358  decode.loss_cls: 1.6308  decode.loss_mask: 0.7426  decode.loss_dice: 1.3501  decode.d0.loss_cls: 3.6386  decode.d0.loss_mask: 0.8322  decode.d0.loss_dice: 1.6056  decode.d1.loss_cls: 1.7213  decode.d1.loss_mask: 0.8033  decode.d1.loss_dice: 1.4593  decode.d2.loss_cls: 1.7029  decode.d2.loss_mask: 0.7572  decode.d2.loss_dice: 1.3730  decode.d3.loss_cls: 1.5891  decode.d3.loss_mask: 0.7685  decode.d3.loss_dice: 1.4300  decode.d4.loss_cls: 1.6056  decode.d4.loss_mask: 0.8021  decode.d4.loss_dice: 1.4193  decode.d5.loss_cls: 1.5466  decode.d5.loss_mask: 0.7839  decode.d5.loss_dice: 1.3831  decode.d6.loss_cls: 1.5943  decode.d6.loss_mask: 0.7928  decode.d6.loss_dice: 1.4106  decode.d7.loss_cls: 1.6040  decode.d7.loss_mask: 0.7660  decode.d7.loss_dice: 1.3697  decode.d8.loss_cls: 1.5896  decode.d8.loss_mask: 0.7764  decode.d8.loss_dice: 1.3874
2023/05/23 19:35:27 - mmengine - INFO - Iter(train) [ 10400/160000]  lr: 9.4131e-06  eta: 17:47:11  time: 0.4059  data_time: 0.0095  memory: 4871  grad_norm: 110.4232  loss: 40.1602  decode.loss_cls: 1.5351  decode.loss_mask: 0.8287  decode.loss_dice: 1.4844  decode.d0.loss_cls: 3.2047  decode.d0.loss_mask: 0.8752  decode.d0.loss_dice: 1.7168  decode.d1.loss_cls: 1.5330  decode.d1.loss_mask: 0.8799  decode.d1.loss_dice: 1.6250  decode.d2.loss_cls: 1.4965  decode.d2.loss_mask: 0.8474  decode.d2.loss_dice: 1.5453  decode.d3.loss_cls: 1.4832  decode.d3.loss_mask: 0.8186  decode.d3.loss_dice: 1.5022  decode.d4.loss_cls: 1.4518  decode.d4.loss_mask: 0.8226  decode.d4.loss_dice: 1.5043  decode.d5.loss_cls: 1.4287  decode.d5.loss_mask: 0.8075  decode.d5.loss_dice: 1.5191  decode.d6.loss_cls: 1.4201  decode.d6.loss_mask: 0.8196  decode.d6.loss_dice: 1.4829  decode.d7.loss_cls: 1.4239  decode.d7.loss_mask: 0.8220  decode.d7.loss_dice: 1.5152  decode.d8.loss_cls: 1.4145  decode.d8.loss_mask: 0.8245  decode.d8.loss_dice: 1.5272
2023/05/23 19:35:47 - mmengine - INFO - Iter(train) [ 10450/160000]  lr: 9.4103e-06  eta: 17:46:39  time: 0.4078  data_time: 0.0096  memory: 4812  grad_norm: 110.5628  loss: 36.5162  decode.loss_cls: 1.4536  decode.loss_mask: 0.8241  decode.loss_dice: 1.1471  decode.d0.loss_cls: 3.4052  decode.d0.loss_mask: 0.7756  decode.d0.loss_dice: 1.2645  decode.d1.loss_cls: 1.5682  decode.d1.loss_mask: 0.8435  decode.d1.loss_dice: 1.2179  decode.d2.loss_cls: 1.5690  decode.d2.loss_mask: 0.7934  decode.d2.loss_dice: 1.1872  decode.d3.loss_cls: 1.4370  decode.d3.loss_mask: 0.7910  decode.d3.loss_dice: 1.1524  decode.d4.loss_cls: 1.4215  decode.d4.loss_mask: 0.8155  decode.d4.loss_dice: 1.1462  decode.d5.loss_cls: 1.5007  decode.d5.loss_mask: 0.7953  decode.d5.loss_dice: 1.1424  decode.d6.loss_cls: 1.4637  decode.d6.loss_mask: 0.8007  decode.d6.loss_dice: 1.1404  decode.d7.loss_cls: 1.4805  decode.d7.loss_mask: 0.7983  decode.d7.loss_dice: 1.1648  decode.d8.loss_cls: 1.4541  decode.d8.loss_mask: 0.7887  decode.d8.loss_dice: 1.1736
2023/05/23 19:36:08 - mmengine - INFO - Iter(train) [ 10500/160000]  lr: 9.4074e-06  eta: 17:46:04  time: 0.4132  data_time: 0.0092  memory: 4841  grad_norm: 99.7945  loss: 39.5471  decode.loss_cls: 1.6029  decode.loss_mask: 0.6848  decode.loss_dice: 1.4257  decode.d0.loss_cls: 3.5235  decode.d0.loss_mask: 0.7262  decode.d0.loss_dice: 1.5943  decode.d1.loss_cls: 1.7129  decode.d1.loss_mask: 0.7464  decode.d1.loss_dice: 1.5267  decode.d2.loss_cls: 1.5977  decode.d2.loss_mask: 0.7182  decode.d2.loss_dice: 1.5094  decode.d3.loss_cls: 1.5773  decode.d3.loss_mask: 0.7047  decode.d3.loss_dice: 1.4188  decode.d4.loss_cls: 1.5924  decode.d4.loss_mask: 0.7026  decode.d4.loss_dice: 1.4145  decode.d5.loss_cls: 1.5514  decode.d5.loss_mask: 0.6964  decode.d5.loss_dice: 1.3937  decode.d6.loss_cls: 1.6348  decode.d6.loss_mask: 0.6862  decode.d6.loss_dice: 1.3837  decode.d7.loss_cls: 1.6365  decode.d7.loss_mask: 0.6833  decode.d7.loss_dice: 1.4073  decode.d8.loss_cls: 1.5703  decode.d8.loss_mask: 0.6812  decode.d8.loss_dice: 1.4432
2023/05/23 19:36:29 - mmengine - INFO - Iter(train) [ 10550/160000]  lr: 9.4046e-06  eta: 17:45:35  time: 0.4233  data_time: 0.0093  memory: 4847  grad_norm: 90.3697  loss: 43.1564  decode.loss_cls: 1.5421  decode.loss_mask: 0.9397  decode.loss_dice: 1.5472  decode.d0.loss_cls: 3.6984  decode.d0.loss_mask: 0.9599  decode.d0.loss_dice: 1.6791  decode.d1.loss_cls: 1.7030  decode.d1.loss_mask: 0.9305  decode.d1.loss_dice: 1.6238  decode.d2.loss_cls: 1.5588  decode.d2.loss_mask: 0.9355  decode.d2.loss_dice: 1.5535  decode.d3.loss_cls: 1.5536  decode.d3.loss_mask: 0.9305  decode.d3.loss_dice: 1.5750  decode.d4.loss_cls: 1.6626  decode.d4.loss_mask: 0.9468  decode.d4.loss_dice: 1.5346  decode.d5.loss_cls: 1.5640  decode.d5.loss_mask: 0.9634  decode.d5.loss_dice: 1.5764  decode.d6.loss_cls: 1.5311  decode.d6.loss_mask: 0.9476  decode.d6.loss_dice: 1.5598  decode.d7.loss_cls: 1.6295  decode.d7.loss_mask: 0.9252  decode.d7.loss_dice: 1.5422  decode.d8.loss_cls: 1.5876  decode.d8.loss_mask: 0.9274  decode.d8.loss_dice: 1.5275
2023/05/23 19:36:49 - mmengine - INFO - Iter(train) [ 10600/160000]  lr: 9.4018e-06  eta: 17:45:04  time: 0.4091  data_time: 0.0094  memory: 4906  grad_norm: 100.0655  loss: 35.0911  decode.loss_cls: 1.3383  decode.loss_mask: 0.8290  decode.loss_dice: 1.0576  decode.d0.loss_cls: 3.3812  decode.d0.loss_mask: 0.8935  decode.d0.loss_dice: 1.2755  decode.d1.loss_cls: 1.4598  decode.d1.loss_mask: 0.8812  decode.d1.loss_dice: 1.1640  decode.d2.loss_cls: 1.4202  decode.d2.loss_mask: 0.8783  decode.d2.loss_dice: 1.0655  decode.d3.loss_cls: 1.3471  decode.d3.loss_mask: 0.8669  decode.d3.loss_dice: 1.0718  decode.d4.loss_cls: 1.3364  decode.d4.loss_mask: 0.8581  decode.d4.loss_dice: 1.0462  decode.d5.loss_cls: 1.3406  decode.d5.loss_mask: 0.8614  decode.d5.loss_dice: 1.0842  decode.d6.loss_cls: 1.3887  decode.d6.loss_mask: 0.8042  decode.d6.loss_dice: 1.0357  decode.d7.loss_cls: 1.3315  decode.d7.loss_mask: 0.8140  decode.d7.loss_dice: 1.0499  decode.d8.loss_cls: 1.3530  decode.d8.loss_mask: 0.8059  decode.d8.loss_dice: 1.0512
2023/05/23 19:37:11 - mmengine - INFO - Iter(train) [ 10650/160000]  lr: 9.3989e-06  eta: 17:44:44  time: 0.4100  data_time: 0.0094  memory: 4800  grad_norm: 122.5086  loss: 36.7669  decode.loss_cls: 1.3872  decode.loss_mask: 0.8917  decode.loss_dice: 1.1544  decode.d0.loss_cls: 3.3024  decode.d0.loss_mask: 0.9273  decode.d0.loss_dice: 1.2836  decode.d1.loss_cls: 1.5434  decode.d1.loss_mask: 0.9221  decode.d1.loss_dice: 1.2018  decode.d2.loss_cls: 1.4100  decode.d2.loss_mask: 0.9051  decode.d2.loss_dice: 1.1834  decode.d3.loss_cls: 1.4587  decode.d3.loss_mask: 0.8930  decode.d3.loss_dice: 1.1357  decode.d4.loss_cls: 1.4396  decode.d4.loss_mask: 0.8797  decode.d4.loss_dice: 1.1086  decode.d5.loss_cls: 1.4299  decode.d5.loss_mask: 0.9134  decode.d5.loss_dice: 1.1346  decode.d6.loss_cls: 1.3514  decode.d6.loss_mask: 0.9220  decode.d6.loss_dice: 1.1409  decode.d7.loss_cls: 1.3807  decode.d7.loss_mask: 0.8820  decode.d7.loss_dice: 1.1398  decode.d8.loss_cls: 1.3503  decode.d8.loss_mask: 0.9117  decode.d8.loss_dice: 1.1826
2023/05/23 19:37:32 - mmengine - INFO - Iter(train) [ 10700/160000]  lr: 9.3961e-06  eta: 17:44:16  time: 0.4043  data_time: 0.0094  memory: 4877  grad_norm: 89.6960  loss: 45.2289  decode.loss_cls: 1.5874  decode.loss_mask: 0.8477  decode.loss_dice: 1.7565  decode.d0.loss_cls: 3.4421  decode.d0.loss_mask: 0.9083  decode.d0.loss_dice: 1.9762  decode.d1.loss_cls: 1.7703  decode.d1.loss_mask: 0.9048  decode.d1.loss_dice: 1.9131  decode.d2.loss_cls: 1.6040  decode.d2.loss_mask: 0.9007  decode.d2.loss_dice: 1.8217  decode.d3.loss_cls: 1.6382  decode.d3.loss_mask: 0.8883  decode.d3.loss_dice: 1.7816  decode.d4.loss_cls: 1.6309  decode.d4.loss_mask: 0.9191  decode.d4.loss_dice: 1.7489  decode.d5.loss_cls: 1.5891  decode.d5.loss_mask: 0.9200  decode.d5.loss_dice: 1.7947  decode.d6.loss_cls: 1.5560  decode.d6.loss_mask: 0.9253  decode.d6.loss_dice: 1.7826  decode.d7.loss_cls: 1.5981  decode.d7.loss_mask: 0.9178  decode.d7.loss_dice: 1.8255  decode.d8.loss_cls: 1.5951  decode.d8.loss_mask: 0.8854  decode.d8.loss_dice: 1.7993
2023/05/23 19:37:52 - mmengine - INFO - Iter(train) [ 10750/160000]  lr: 9.3933e-06  eta: 17:43:38  time: 0.4042  data_time: 0.0096  memory: 4883  grad_norm: 100.7042  loss: 36.5416  decode.loss_cls: 1.4704  decode.loss_mask: 0.6922  decode.loss_dice: 1.2975  decode.d0.loss_cls: 3.2828  decode.d0.loss_mask: 0.7507  decode.d0.loss_dice: 1.3906  decode.d1.loss_cls: 1.5382  decode.d1.loss_mask: 0.7268  decode.d1.loss_dice: 1.3576  decode.d2.loss_cls: 1.4628  decode.d2.loss_mask: 0.6884  decode.d2.loss_dice: 1.2961  decode.d3.loss_cls: 1.4011  decode.d3.loss_mask: 0.7253  decode.d3.loss_dice: 1.2827  decode.d4.loss_cls: 1.4381  decode.d4.loss_mask: 0.6889  decode.d4.loss_dice: 1.2699  decode.d5.loss_cls: 1.4027  decode.d5.loss_mask: 0.7187  decode.d5.loss_dice: 1.2772  decode.d6.loss_cls: 1.4189  decode.d6.loss_mask: 0.7285  decode.d6.loss_dice: 1.2813  decode.d7.loss_cls: 1.5099  decode.d7.loss_mask: 0.6790  decode.d7.loss_dice: 1.2680  decode.d8.loss_cls: 1.4734  decode.d8.loss_mask: 0.7263  decode.d8.loss_dice: 1.2975
2023/05/23 19:38:12 - mmengine - INFO - Iter(train) [ 10800/160000]  lr: 9.3904e-06  eta: 17:43:04  time: 0.4085  data_time: 0.0102  memory: 4842  grad_norm: 124.3280  loss: 53.6136  decode.loss_cls: 2.2172  decode.loss_mask: 1.0277  decode.loss_dice: 1.8447  decode.d0.loss_cls: 4.0567  decode.d0.loss_mask: 1.1893  decode.d0.loss_dice: 2.1858  decode.d1.loss_cls: 2.2654  decode.d1.loss_mask: 1.1451  decode.d1.loss_dice: 2.0528  decode.d2.loss_cls: 2.1773  decode.d2.loss_mask: 1.1171  decode.d2.loss_dice: 1.9341  decode.d3.loss_cls: 2.2087  decode.d3.loss_mask: 1.0576  decode.d3.loss_dice: 1.9104  decode.d4.loss_cls: 2.1458  decode.d4.loss_mask: 1.0523  decode.d4.loss_dice: 1.8880  decode.d5.loss_cls: 2.0850  decode.d5.loss_mask: 1.0342  decode.d5.loss_dice: 1.8858  decode.d6.loss_cls: 2.1845  decode.d6.loss_mask: 1.0356  decode.d6.loss_dice: 1.8405  decode.d7.loss_cls: 2.1734  decode.d7.loss_mask: 1.0235  decode.d7.loss_dice: 1.8483  decode.d8.loss_cls: 2.1661  decode.d8.loss_mask: 0.9986  decode.d8.loss_dice: 1.8621
2023/05/23 19:38:33 - mmengine - INFO - Iter(train) [ 10850/160000]  lr: 9.3876e-06  eta: 17:42:33  time: 0.4104  data_time: 0.0096  memory: 4844  grad_norm: 98.1896  loss: 52.4672  decode.loss_cls: 2.0145  decode.loss_mask: 1.0604  decode.loss_dice: 1.9456  decode.d0.loss_cls: 4.0635  decode.d0.loss_mask: 1.0060  decode.d0.loss_dice: 2.1558  decode.d1.loss_cls: 2.2159  decode.d1.loss_mask: 0.9963  decode.d1.loss_dice: 2.0063  decode.d2.loss_cls: 2.1016  decode.d2.loss_mask: 0.9856  decode.d2.loss_dice: 1.9144  decode.d3.loss_cls: 2.0932  decode.d3.loss_mask: 0.9747  decode.d3.loss_dice: 1.8385  decode.d4.loss_cls: 2.1285  decode.d4.loss_mask: 1.0094  decode.d4.loss_dice: 1.8512  decode.d5.loss_cls: 2.0322  decode.d5.loss_mask: 1.0929  decode.d5.loss_dice: 1.8954  decode.d6.loss_cls: 2.0277  decode.d6.loss_mask: 1.0609  decode.d6.loss_dice: 1.9196  decode.d7.loss_cls: 2.0716  decode.d7.loss_mask: 1.0533  decode.d7.loss_dice: 1.9697  decode.d8.loss_cls: 2.0010  decode.d8.loss_mask: 1.0461  decode.d8.loss_dice: 1.9352
2023/05/23 19:38:53 - mmengine - INFO - Iter(train) [ 10900/160000]  lr: 9.3848e-06  eta: 17:41:59  time: 0.4052  data_time: 0.0093  memory: 4829  grad_norm: 108.5110  loss: 51.3555  decode.loss_cls: 2.0454  decode.loss_mask: 1.0818  decode.loss_dice: 1.7061  decode.d0.loss_cls: 3.9290  decode.d0.loss_mask: 1.1943  decode.d0.loss_dice: 1.9105  decode.d1.loss_cls: 2.2509  decode.d1.loss_mask: 1.1379  decode.d1.loss_dice: 1.8456  decode.d2.loss_cls: 2.1311  decode.d2.loss_mask: 1.1156  decode.d2.loss_dice: 1.7758  decode.d3.loss_cls: 2.0389  decode.d3.loss_mask: 1.0710  decode.d3.loss_dice: 1.6837  decode.d4.loss_cls: 2.1390  decode.d4.loss_mask: 1.0823  decode.d4.loss_dice: 1.7233  decode.d5.loss_cls: 2.0635  decode.d5.loss_mask: 1.0937  decode.d5.loss_dice: 1.7362  decode.d6.loss_cls: 2.1142  decode.d6.loss_mask: 1.0732  decode.d6.loss_dice: 1.6604  decode.d7.loss_cls: 2.1090  decode.d7.loss_mask: 1.0907  decode.d7.loss_dice: 1.6890  decode.d8.loss_cls: 2.0773  decode.d8.loss_mask: 1.0807  decode.d8.loss_dice: 1.7055
2023/05/23 19:39:14 - mmengine - INFO - Iter(train) [ 10950/160000]  lr: 9.3820e-06  eta: 17:41:27  time: 0.4184  data_time: 0.0095  memory: 4829  grad_norm: 97.4384  loss: 45.0307  decode.loss_cls: 1.5550  decode.loss_mask: 0.9396  decode.loss_dice: 1.6383  decode.d0.loss_cls: 3.6600  decode.d0.loss_mask: 1.0491  decode.d0.loss_dice: 1.9201  decode.d1.loss_cls: 1.8146  decode.d1.loss_mask: 0.9721  decode.d1.loss_dice: 1.7977  decode.d2.loss_cls: 1.7477  decode.d2.loss_mask: 0.9253  decode.d2.loss_dice: 1.7015  decode.d3.loss_cls: 1.6442  decode.d3.loss_mask: 0.9297  decode.d3.loss_dice: 1.6526  decode.d4.loss_cls: 1.6396  decode.d4.loss_mask: 0.9229  decode.d4.loss_dice: 1.6585  decode.d5.loss_cls: 1.5874  decode.d5.loss_mask: 0.9509  decode.d5.loss_dice: 1.7115  decode.d6.loss_cls: 1.6125  decode.d6.loss_mask: 0.9487  decode.d6.loss_dice: 1.6624  decode.d7.loss_cls: 1.6292  decode.d7.loss_mask: 0.9587  decode.d7.loss_dice: 1.6468  decode.d8.loss_cls: 1.5742  decode.d8.loss_mask: 0.9421  decode.d8.loss_dice: 1.6375
2023/05/23 19:39:34 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 19:39:34 - mmengine - INFO - Iter(train) [ 11000/160000]  lr: 9.3791e-06  eta: 17:40:52  time: 0.4073  data_time: 0.0096  memory: 4827  grad_norm: 150.8033  loss: 40.8249  decode.loss_cls: 1.3995  decode.loss_mask: 0.8953  decode.loss_dice: 1.4493  decode.d0.loss_cls: 3.3977  decode.d0.loss_mask: 0.9593  decode.d0.loss_dice: 1.7129  decode.d1.loss_cls: 1.7237  decode.d1.loss_mask: 0.9297  decode.d1.loss_dice: 1.5812  decode.d2.loss_cls: 1.5065  decode.d2.loss_mask: 0.8326  decode.d2.loss_dice: 1.4992  decode.d3.loss_cls: 1.5353  decode.d3.loss_mask: 0.8402  decode.d3.loss_dice: 1.4529  decode.d4.loss_cls: 1.5364  decode.d4.loss_mask: 0.8406  decode.d4.loss_dice: 1.4978  decode.d5.loss_cls: 1.4757  decode.d5.loss_mask: 0.8540  decode.d5.loss_dice: 1.4970  decode.d6.loss_cls: 1.4161  decode.d6.loss_mask: 0.8643  decode.d6.loss_dice: 1.4956  decode.d7.loss_cls: 1.4024  decode.d7.loss_mask: 0.9060  decode.d7.loss_dice: 1.5349  decode.d8.loss_cls: 1.4196  decode.d8.loss_mask: 0.8671  decode.d8.loss_dice: 1.5020
2023/05/23 19:39:34 - mmengine - INFO - Saving checkpoint at 11000 iterations
2023/05/23 19:40:01 - mmengine - INFO - Iter(train) [ 11050/160000]  lr: 9.3763e-06  eta: 17:41:39  time: 0.4202  data_time: 0.0095  memory: 4853  grad_norm: 130.0874  loss: 41.7849  decode.loss_cls: 1.5188  decode.loss_mask: 0.7680  decode.loss_dice: 1.5955  decode.d0.loss_cls: 3.6806  decode.d0.loss_mask: 0.8067  decode.d0.loss_dice: 1.7181  decode.d1.loss_cls: 1.7312  decode.d1.loss_mask: 0.8360  decode.d1.loss_dice: 1.6734  decode.d2.loss_cls: 1.6361  decode.d2.loss_mask: 0.7895  decode.d2.loss_dice: 1.6481  decode.d3.loss_cls: 1.5774  decode.d3.loss_mask: 0.8110  decode.d3.loss_dice: 1.6374  decode.d4.loss_cls: 1.5701  decode.d4.loss_mask: 0.7716  decode.d4.loss_dice: 1.6118  decode.d5.loss_cls: 1.5077  decode.d5.loss_mask: 0.7744  decode.d5.loss_dice: 1.5877  decode.d6.loss_cls: 1.4842  decode.d6.loss_mask: 0.8149  decode.d6.loss_dice: 1.5658  decode.d7.loss_cls: 1.4711  decode.d7.loss_mask: 0.7769  decode.d7.loss_dice: 1.5398  decode.d8.loss_cls: 1.4848  decode.d8.loss_mask: 0.7909  decode.d8.loss_dice: 1.6052
2023/05/23 19:40:22 - mmengine - INFO - Iter(train) [ 11100/160000]  lr: 9.3735e-06  eta: 17:41:09  time: 0.4130  data_time: 0.0094  memory: 4837  grad_norm: 118.3367  loss: 39.9321  decode.loss_cls: 1.6362  decode.loss_mask: 0.8209  decode.loss_dice: 1.2552  decode.d0.loss_cls: 3.6089  decode.d0.loss_mask: 0.9212  decode.d0.loss_dice: 1.4671  decode.d1.loss_cls: 1.7790  decode.d1.loss_mask: 0.9141  decode.d1.loss_dice: 1.3447  decode.d2.loss_cls: 1.7486  decode.d2.loss_mask: 0.8036  decode.d2.loss_dice: 1.2858  decode.d3.loss_cls: 1.6975  decode.d3.loss_mask: 0.8105  decode.d3.loss_dice: 1.2257  decode.d4.loss_cls: 1.6925  decode.d4.loss_mask: 0.8189  decode.d4.loss_dice: 1.2609  decode.d5.loss_cls: 1.6908  decode.d5.loss_mask: 0.8125  decode.d5.loss_dice: 1.2771  decode.d6.loss_cls: 1.6245  decode.d6.loss_mask: 0.8003  decode.d6.loss_dice: 1.2578  decode.d7.loss_cls: 1.6184  decode.d7.loss_mask: 0.7927  decode.d7.loss_dice: 1.2482  decode.d8.loss_cls: 1.6392  decode.d8.loss_mask: 0.8218  decode.d8.loss_dice: 1.2576
2023/05/23 19:40:42 - mmengine - INFO - Iter(train) [ 11150/160000]  lr: 9.3706e-06  eta: 17:40:40  time: 0.4154  data_time: 0.0098  memory: 4823  grad_norm: 101.8381  loss: 35.7471  decode.loss_cls: 1.3887  decode.loss_mask: 0.6818  decode.loss_dice: 1.2594  decode.d0.loss_cls: 3.2234  decode.d0.loss_mask: 0.7242  decode.d0.loss_dice: 1.4588  decode.d1.loss_cls: 1.4961  decode.d1.loss_mask: 0.7529  decode.d1.loss_dice: 1.3686  decode.d2.loss_cls: 1.4082  decode.d2.loss_mask: 0.7257  decode.d2.loss_dice: 1.3500  decode.d3.loss_cls: 1.3837  decode.d3.loss_mask: 0.7418  decode.d3.loss_dice: 1.2776  decode.d4.loss_cls: 1.3445  decode.d4.loss_mask: 0.6864  decode.d4.loss_dice: 1.2902  decode.d5.loss_cls: 1.3362  decode.d5.loss_mask: 0.6708  decode.d5.loss_dice: 1.2667  decode.d6.loss_cls: 1.4001  decode.d6.loss_mask: 0.6532  decode.d6.loss_dice: 1.2440  decode.d7.loss_cls: 1.3172  decode.d7.loss_mask: 0.6699  decode.d7.loss_dice: 1.2823  decode.d8.loss_cls: 1.4237  decode.d8.loss_mask: 0.6540  decode.d8.loss_dice: 1.2670
2023/05/23 19:41:04 - mmengine - INFO - Iter(train) [ 11200/160000]  lr: 9.3678e-06  eta: 17:40:18  time: 0.4403  data_time: 0.0093  memory: 4782  grad_norm: 93.0886  loss: 40.0010  decode.loss_cls: 1.5897  decode.loss_mask: 0.6904  decode.loss_dice: 1.4725  decode.d0.loss_cls: 3.4482  decode.d0.loss_mask: 0.7070  decode.d0.loss_dice: 1.5356  decode.d1.loss_cls: 1.7533  decode.d1.loss_mask: 0.6963  decode.d1.loss_dice: 1.5139  decode.d2.loss_cls: 1.7002  decode.d2.loss_mask: 0.6979  decode.d2.loss_dice: 1.4442  decode.d3.loss_cls: 1.6983  decode.d3.loss_mask: 0.6823  decode.d3.loss_dice: 1.4369  decode.d4.loss_cls: 1.6494  decode.d4.loss_mask: 0.7172  decode.d4.loss_dice: 1.4774  decode.d5.loss_cls: 1.6578  decode.d5.loss_mask: 0.7109  decode.d5.loss_dice: 1.4613  decode.d6.loss_cls: 1.6771  decode.d6.loss_mask: 0.6908  decode.d6.loss_dice: 1.4340  decode.d7.loss_cls: 1.6201  decode.d7.loss_mask: 0.6991  decode.d7.loss_dice: 1.4502  decode.d8.loss_cls: 1.5472  decode.d8.loss_mask: 0.6968  decode.d8.loss_dice: 1.4453
2023/05/23 19:41:27 - mmengine - INFO - Iter(train) [ 11250/160000]  lr: 9.3650e-06  eta: 17:40:17  time: 0.4739  data_time: 0.0097  memory: 4844  grad_norm: 104.8149  loss: 45.6385  decode.loss_cls: 1.7406  decode.loss_mask: 0.8313  decode.loss_dice: 1.6502  decode.d0.loss_cls: 3.8310  decode.d0.loss_mask: 0.8855  decode.d0.loss_dice: 1.9383  decode.d1.loss_cls: 2.0240  decode.d1.loss_mask: 0.8843  decode.d1.loss_dice: 1.8542  decode.d2.loss_cls: 1.9020  decode.d2.loss_mask: 0.8886  decode.d2.loss_dice: 1.8048  decode.d3.loss_cls: 1.7362  decode.d3.loss_mask: 0.8623  decode.d3.loss_dice: 1.7109  decode.d4.loss_cls: 1.7318  decode.d4.loss_mask: 0.8327  decode.d4.loss_dice: 1.6718  decode.d5.loss_cls: 1.7182  decode.d5.loss_mask: 0.8255  decode.d5.loss_dice: 1.6615  decode.d6.loss_cls: 1.7133  decode.d6.loss_mask: 0.8261  decode.d6.loss_dice: 1.6918  decode.d7.loss_cls: 1.7331  decode.d7.loss_mask: 0.8247  decode.d7.loss_dice: 1.6373  decode.d8.loss_cls: 1.7182  decode.d8.loss_mask: 0.8239  decode.d8.loss_dice: 1.6846
2023/05/23 19:41:48 - mmengine - INFO - Iter(train) [ 11300/160000]  lr: 9.3621e-06  eta: 17:39:49  time: 0.4047  data_time: 0.0095  memory: 4848  grad_norm: 188.5452  loss: 38.0402  decode.loss_cls: 1.5297  decode.loss_mask: 0.7918  decode.loss_dice: 1.2518  decode.d0.loss_cls: 3.2063  decode.d0.loss_mask: 0.7788  decode.d0.loss_dice: 1.3840  decode.d1.loss_cls: 1.7359  decode.d1.loss_mask: 0.8130  decode.d1.loss_dice: 1.3067  decode.d2.loss_cls: 1.6266  decode.d2.loss_mask: 0.8087  decode.d2.loss_dice: 1.2525  decode.d3.loss_cls: 1.6141  decode.d3.loss_mask: 0.7707  decode.d3.loss_dice: 1.2250  decode.d4.loss_cls: 1.6854  decode.d4.loss_mask: 0.7727  decode.d4.loss_dice: 1.2071  decode.d5.loss_cls: 1.5321  decode.d5.loss_mask: 0.8012  decode.d5.loss_dice: 1.2396  decode.d6.loss_cls: 1.5958  decode.d6.loss_mask: 0.7832  decode.d6.loss_dice: 1.2243  decode.d7.loss_cls: 1.5618  decode.d7.loss_mask: 0.7605  decode.d7.loss_dice: 1.2274  decode.d8.loss_cls: 1.5740  decode.d8.loss_mask: 0.7605  decode.d8.loss_dice: 1.2190
2023/05/23 19:42:08 - mmengine - INFO - Iter(train) [ 11350/160000]  lr: 9.3593e-06  eta: 17:39:22  time: 0.4141  data_time: 0.0101  memory: 4818  grad_norm: 104.6765  loss: 45.7232  decode.loss_cls: 1.4189  decode.loss_mask: 1.0615  decode.loss_dice: 1.8216  decode.d0.loss_cls: 3.6953  decode.d0.loss_mask: 1.0720  decode.d0.loss_dice: 2.0011  decode.d1.loss_cls: 1.6144  decode.d1.loss_mask: 1.0834  decode.d1.loss_dice: 1.8486  decode.d2.loss_cls: 1.5055  decode.d2.loss_mask: 1.0465  decode.d2.loss_dice: 1.8746  decode.d3.loss_cls: 1.5211  decode.d3.loss_mask: 0.9989  decode.d3.loss_dice: 1.7294  decode.d4.loss_cls: 1.5516  decode.d4.loss_mask: 0.9934  decode.d4.loss_dice: 1.7713  decode.d5.loss_cls: 1.5025  decode.d5.loss_mask: 1.0119  decode.d5.loss_dice: 1.7610  decode.d6.loss_cls: 1.4885  decode.d6.loss_mask: 1.0346  decode.d6.loss_dice: 1.7513  decode.d7.loss_cls: 1.4472  decode.d7.loss_mask: 1.0495  decode.d7.loss_dice: 1.7777  decode.d8.loss_cls: 1.4603  decode.d8.loss_mask: 1.0373  decode.d8.loss_dice: 1.7921
2023/05/23 19:42:29 - mmengine - INFO - Iter(train) [ 11400/160000]  lr: 9.3565e-06  eta: 17:38:51  time: 0.4065  data_time: 0.0097  memory: 4825  grad_norm: 109.4190  loss: 41.9512  decode.loss_cls: 1.4951  decode.loss_mask: 0.8457  decode.loss_dice: 1.5416  decode.d0.loss_cls: 3.4042  decode.d0.loss_mask: 0.9696  decode.d0.loss_dice: 1.8015  decode.d1.loss_cls: 1.6962  decode.d1.loss_mask: 0.8938  decode.d1.loss_dice: 1.6302  decode.d2.loss_cls: 1.6174  decode.d2.loss_mask: 0.8840  decode.d2.loss_dice: 1.5617  decode.d3.loss_cls: 1.5831  decode.d3.loss_mask: 0.8571  decode.d3.loss_dice: 1.5505  decode.d4.loss_cls: 1.5658  decode.d4.loss_mask: 0.8560  decode.d4.loss_dice: 1.5365  decode.d5.loss_cls: 1.5280  decode.d5.loss_mask: 0.8526  decode.d5.loss_dice: 1.5345  decode.d6.loss_cls: 1.5340  decode.d6.loss_mask: 0.8617  decode.d6.loss_dice: 1.5593  decode.d7.loss_cls: 1.5244  decode.d7.loss_mask: 0.8513  decode.d7.loss_dice: 1.5617  decode.d8.loss_cls: 1.4742  decode.d8.loss_mask: 0.8476  decode.d8.loss_dice: 1.5318
2023/05/23 19:42:50 - mmengine - INFO - Iter(train) [ 11450/160000]  lr: 9.3536e-06  eta: 17:38:17  time: 0.4018  data_time: 0.0095  memory: 4858  grad_norm: 97.4015  loss: 47.3842  decode.loss_cls: 1.6604  decode.loss_mask: 0.9161  decode.loss_dice: 1.8185  decode.d0.loss_cls: 4.1278  decode.d0.loss_mask: 1.0285  decode.d0.loss_dice: 2.1832  decode.d1.loss_cls: 1.7206  decode.d1.loss_mask: 0.9498  decode.d1.loss_dice: 1.9841  decode.d2.loss_cls: 1.6941  decode.d2.loss_mask: 0.9328  decode.d2.loss_dice: 1.8944  decode.d3.loss_cls: 1.6550  decode.d3.loss_mask: 0.9080  decode.d3.loss_dice: 1.8457  decode.d4.loss_cls: 1.6499  decode.d4.loss_mask: 0.9638  decode.d4.loss_dice: 1.8891  decode.d5.loss_cls: 1.6167  decode.d5.loss_mask: 0.9369  decode.d5.loss_dice: 1.8703  decode.d6.loss_cls: 1.6079  decode.d6.loss_mask: 0.9336  decode.d6.loss_dice: 1.8991  decode.d7.loss_cls: 1.6225  decode.d7.loss_mask: 0.9004  decode.d7.loss_dice: 1.8248  decode.d8.loss_cls: 1.6028  decode.d8.loss_mask: 0.9199  decode.d8.loss_dice: 1.8278
2023/05/23 19:43:10 - mmengine - INFO - Iter(train) [ 11500/160000]  lr: 9.3508e-06  eta: 17:37:44  time: 0.4068  data_time: 0.0091  memory: 4925  grad_norm: 106.0451  loss: 51.1078  decode.loss_cls: 1.8249  decode.loss_mask: 1.0289  decode.loss_dice: 1.9754  decode.d0.loss_cls: 3.7117  decode.d0.loss_mask: 1.1086  decode.d0.loss_dice: 2.2736  decode.d1.loss_cls: 2.0926  decode.d1.loss_mask: 1.0171  decode.d1.loss_dice: 2.1115  decode.d2.loss_cls: 1.9235  decode.d2.loss_mask: 1.0569  decode.d2.loss_dice: 2.0565  decode.d3.loss_cls: 1.8095  decode.d3.loss_mask: 1.0509  decode.d3.loss_dice: 2.0444  decode.d4.loss_cls: 1.8513  decode.d4.loss_mask: 1.0240  decode.d4.loss_dice: 2.0447  decode.d5.loss_cls: 1.7874  decode.d5.loss_mask: 1.0159  decode.d5.loss_dice: 2.0309  decode.d6.loss_cls: 1.7544  decode.d6.loss_mask: 1.0032  decode.d6.loss_dice: 2.0077  decode.d7.loss_cls: 1.7872  decode.d7.loss_mask: 1.0172  decode.d7.loss_dice: 1.9576  decode.d8.loss_cls: 1.7560  decode.d8.loss_mask: 1.0163  decode.d8.loss_dice: 1.9678
2023/05/23 19:43:31 - mmengine - INFO - Iter(train) [ 11550/160000]  lr: 9.3480e-06  eta: 17:37:24  time: 0.4127  data_time: 0.0097  memory: 4844  grad_norm: 99.1746  loss: 43.5100  decode.loss_cls: 1.5538  decode.loss_mask: 0.9729  decode.loss_dice: 1.5920  decode.d0.loss_cls: 3.6239  decode.d0.loss_mask: 0.9713  decode.d0.loss_dice: 1.7580  decode.d1.loss_cls: 1.7111  decode.d1.loss_mask: 0.9759  decode.d1.loss_dice: 1.6570  decode.d2.loss_cls: 1.5817  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 1.6187  decode.d3.loss_cls: 1.5707  decode.d3.loss_mask: 0.9293  decode.d3.loss_dice: 1.5995  decode.d4.loss_cls: 1.6120  decode.d4.loss_mask: 0.9249  decode.d4.loss_dice: 1.6055  decode.d5.loss_cls: 1.5655  decode.d5.loss_mask: 0.9020  decode.d5.loss_dice: 1.5906  decode.d6.loss_cls: 1.5815  decode.d6.loss_mask: 0.9165  decode.d6.loss_dice: 1.5768  decode.d7.loss_cls: 1.5652  decode.d7.loss_mask: 0.9382  decode.d7.loss_dice: 1.5867  decode.d8.loss_cls: 1.5349  decode.d8.loss_mask: 0.9518  decode.d8.loss_dice: 1.5710
2023/05/23 19:43:52 - mmengine - INFO - Iter(train) [ 11600/160000]  lr: 9.3451e-06  eta: 17:36:54  time: 0.4093  data_time: 0.0095  memory: 4825  grad_norm: 103.3725  loss: 38.8176  decode.loss_cls: 1.4478  decode.loss_mask: 0.8699  decode.loss_dice: 1.2556  decode.d0.loss_cls: 3.5840  decode.d0.loss_mask: 0.9581  decode.d0.loss_dice: 1.5609  decode.d1.loss_cls: 1.5982  decode.d1.loss_mask: 0.9420  decode.d1.loss_dice: 1.4095  decode.d2.loss_cls: 1.4893  decode.d2.loss_mask: 0.8979  decode.d2.loss_dice: 1.3072  decode.d3.loss_cls: 1.4218  decode.d3.loss_mask: 0.9368  decode.d3.loss_dice: 1.2724  decode.d4.loss_cls: 1.4077  decode.d4.loss_mask: 0.9281  decode.d4.loss_dice: 1.2922  decode.d5.loss_cls: 1.3743  decode.d5.loss_mask: 0.9095  decode.d5.loss_dice: 1.2721  decode.d6.loss_cls: 1.4383  decode.d6.loss_mask: 0.8720  decode.d6.loss_dice: 1.2465  decode.d7.loss_cls: 1.4269  decode.d7.loss_mask: 0.8716  decode.d7.loss_dice: 1.2755  decode.d8.loss_cls: 1.4306  decode.d8.loss_mask: 0.8676  decode.d8.loss_dice: 1.2532
2023/05/23 19:44:13 - mmengine - INFO - Iter(train) [ 11650/160000]  lr: 9.3423e-06  eta: 17:36:27  time: 0.4203  data_time: 0.0100  memory: 4846  grad_norm: 90.0296  loss: 40.3957  decode.loss_cls: 1.4600  decode.loss_mask: 0.8871  decode.loss_dice: 1.4786  decode.d0.loss_cls: 3.5892  decode.d0.loss_mask: 0.9396  decode.d0.loss_dice: 1.6309  decode.d1.loss_cls: 1.5873  decode.d1.loss_mask: 0.8722  decode.d1.loss_dice: 1.5372  decode.d2.loss_cls: 1.4501  decode.d2.loss_mask: 0.8738  decode.d2.loss_dice: 1.4358  decode.d3.loss_cls: 1.4953  decode.d3.loss_mask: 0.8394  decode.d3.loss_dice: 1.3723  decode.d4.loss_cls: 1.5733  decode.d4.loss_mask: 0.8696  decode.d4.loss_dice: 1.3969  decode.d5.loss_cls: 1.4939  decode.d5.loss_mask: 0.8634  decode.d5.loss_dice: 1.4139  decode.d6.loss_cls: 1.4654  decode.d6.loss_mask: 0.8695  decode.d6.loss_dice: 1.4225  decode.d7.loss_cls: 1.4880  decode.d7.loss_mask: 0.8878  decode.d7.loss_dice: 1.4279  decode.d8.loss_cls: 1.4649  decode.d8.loss_mask: 0.8750  decode.d8.loss_dice: 1.4351
2023/05/23 19:44:34 - mmengine - INFO - Iter(train) [ 11700/160000]  lr: 9.3395e-06  eta: 17:35:55  time: 0.4062  data_time: 0.0096  memory: 4830  grad_norm: 117.5788  loss: 38.9074  decode.loss_cls: 1.5879  decode.loss_mask: 0.7736  decode.loss_dice: 1.3264  decode.d0.loss_cls: 3.1898  decode.d0.loss_mask: 0.8220  decode.d0.loss_dice: 1.4663  decode.d1.loss_cls: 1.7260  decode.d1.loss_mask: 0.8269  decode.d1.loss_dice: 1.3829  decode.d2.loss_cls: 1.6820  decode.d2.loss_mask: 0.7371  decode.d2.loss_dice: 1.3364  decode.d3.loss_cls: 1.6316  decode.d3.loss_mask: 0.7623  decode.d3.loss_dice: 1.2794  decode.d4.loss_cls: 1.6505  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 1.2758  decode.d5.loss_cls: 1.6078  decode.d5.loss_mask: 0.8510  decode.d5.loss_dice: 1.3045  decode.d6.loss_cls: 1.5487  decode.d6.loss_mask: 0.7865  decode.d6.loss_dice: 1.2699  decode.d7.loss_cls: 1.5435  decode.d7.loss_mask: 0.8165  decode.d7.loss_dice: 1.3255  decode.d8.loss_cls: 1.5250  decode.d8.loss_mask: 0.8144  decode.d8.loss_dice: 1.3106
2023/05/23 19:44:55 - mmengine - INFO - Iter(train) [ 11750/160000]  lr: 9.3366e-06  eta: 17:35:28  time: 0.4405  data_time: 0.0098  memory: 4974  grad_norm: 108.7594  loss: 49.2289  decode.loss_cls: 1.6612  decode.loss_mask: 1.0748  decode.loss_dice: 1.8157  decode.d0.loss_cls: 3.6557  decode.d0.loss_mask: 1.2204  decode.d0.loss_dice: 2.1102  decode.d1.loss_cls: 1.9438  decode.d1.loss_mask: 1.1308  decode.d1.loss_dice: 2.0195  decode.d2.loss_cls: 1.7698  decode.d2.loss_mask: 1.1470  decode.d2.loss_dice: 1.9211  decode.d3.loss_cls: 1.7680  decode.d3.loss_mask: 1.1003  decode.d3.loss_dice: 1.8840  decode.d4.loss_cls: 1.7386  decode.d4.loss_mask: 1.1047  decode.d4.loss_dice: 1.9093  decode.d5.loss_cls: 1.6805  decode.d5.loss_mask: 1.0914  decode.d5.loss_dice: 1.8356  decode.d6.loss_cls: 1.6350  decode.d6.loss_mask: 1.0771  decode.d6.loss_dice: 1.8303  decode.d7.loss_cls: 1.6509  decode.d7.loss_mask: 1.0867  decode.d7.loss_dice: 1.8244  decode.d8.loss_cls: 1.6044  decode.d8.loss_mask: 1.1025  decode.d8.loss_dice: 1.8352
2023/05/23 19:45:15 - mmengine - INFO - Iter(train) [ 11800/160000]  lr: 9.3338e-06  eta: 17:34:55  time: 0.4094  data_time: 0.0097  memory: 4859  grad_norm: 104.2300  loss: 40.8547  decode.loss_cls: 1.5205  decode.loss_mask: 0.8805  decode.loss_dice: 1.4818  decode.d0.loss_cls: 3.3466  decode.d0.loss_mask: 0.8779  decode.d0.loss_dice: 1.7128  decode.d1.loss_cls: 1.6230  decode.d1.loss_mask: 0.8436  decode.d1.loss_dice: 1.5804  decode.d2.loss_cls: 1.4971  decode.d2.loss_mask: 0.8567  decode.d2.loss_dice: 1.5264  decode.d3.loss_cls: 1.5189  decode.d3.loss_mask: 0.8550  decode.d3.loss_dice: 1.4919  decode.d4.loss_cls: 1.5458  decode.d4.loss_mask: 0.8585  decode.d4.loss_dice: 1.4860  decode.d5.loss_cls: 1.5329  decode.d5.loss_mask: 0.8717  decode.d5.loss_dice: 1.4913  decode.d6.loss_cls: 1.5166  decode.d6.loss_mask: 0.8575  decode.d6.loss_dice: 1.4594  decode.d7.loss_cls: 1.4930  decode.d7.loss_mask: 0.8669  decode.d7.loss_dice: 1.4825  decode.d8.loss_cls: 1.4346  decode.d8.loss_mask: 0.8764  decode.d8.loss_dice: 1.4687
2023/05/23 19:45:36 - mmengine - INFO - Iter(train) [ 11850/160000]  lr: 9.3310e-06  eta: 17:34:24  time: 0.4115  data_time: 0.0094  memory: 4907  grad_norm: 100.8067  loss: 36.5822  decode.loss_cls: 1.2584  decode.loss_mask: 0.8794  decode.loss_dice: 1.2240  decode.d0.loss_cls: 3.0836  decode.d0.loss_mask: 0.9174  decode.d0.loss_dice: 1.4255  decode.d1.loss_cls: 1.4903  decode.d1.loss_mask: 0.9484  decode.d1.loss_dice: 1.3163  decode.d2.loss_cls: 1.3910  decode.d2.loss_mask: 0.9212  decode.d2.loss_dice: 1.2692  decode.d3.loss_cls: 1.3668  decode.d3.loss_mask: 0.8690  decode.d3.loss_dice: 1.2446  decode.d4.loss_cls: 1.3192  decode.d4.loss_mask: 0.8559  decode.d4.loss_dice: 1.2422  decode.d5.loss_cls: 1.3519  decode.d5.loss_mask: 0.8626  decode.d5.loss_dice: 1.2113  decode.d6.loss_cls: 1.2959  decode.d6.loss_mask: 0.8380  decode.d6.loss_dice: 1.2221  decode.d7.loss_cls: 1.2895  decode.d7.loss_mask: 0.8579  decode.d7.loss_dice: 1.2266  decode.d8.loss_cls: 1.3241  decode.d8.loss_mask: 0.8516  decode.d8.loss_dice: 1.2285
2023/05/23 19:45:57 - mmengine - INFO - Iter(train) [ 11900/160000]  lr: 9.3281e-06  eta: 17:33:57  time: 0.4158  data_time: 0.0098  memory: 4846  grad_norm: 107.0874  loss: 51.5308  decode.loss_cls: 1.9829  decode.loss_mask: 0.9138  decode.loss_dice: 2.0498  decode.d0.loss_cls: 3.8439  decode.d0.loss_mask: 0.9189  decode.d0.loss_dice: 2.2529  decode.d1.loss_cls: 1.9353  decode.d1.loss_mask: 1.0085  decode.d1.loss_dice: 2.1877  decode.d2.loss_cls: 1.9173  decode.d2.loss_mask: 0.9668  decode.d2.loss_dice: 2.0933  decode.d3.loss_cls: 2.0610  decode.d3.loss_mask: 0.9091  decode.d3.loss_dice: 2.0491  decode.d4.loss_cls: 1.9582  decode.d4.loss_mask: 0.9407  decode.d4.loss_dice: 2.0229  decode.d5.loss_cls: 2.0521  decode.d5.loss_mask: 0.8987  decode.d5.loss_dice: 2.0044  decode.d6.loss_cls: 1.9764  decode.d6.loss_mask: 0.8585  decode.d6.loss_dice: 2.0021  decode.d7.loss_cls: 1.9809  decode.d7.loss_mask: 0.8736  decode.d7.loss_dice: 2.0018  decode.d8.loss_cls: 1.9351  decode.d8.loss_mask: 0.9115  decode.d8.loss_dice: 2.0236
2023/05/23 19:46:17 - mmengine - INFO - Iter(train) [ 11950/160000]  lr: 9.3253e-06  eta: 17:33:28  time: 0.4084  data_time: 0.0097  memory: 4865  grad_norm: 132.4890  loss: 46.4262  decode.loss_cls: 1.5126  decode.loss_mask: 0.9813  decode.loss_dice: 1.8245  decode.d0.loss_cls: 3.5518  decode.d0.loss_mask: 0.9653  decode.d0.loss_dice: 2.0422  decode.d1.loss_cls: 1.6926  decode.d1.loss_mask: 1.0113  decode.d1.loss_dice: 1.9016  decode.d2.loss_cls: 1.6242  decode.d2.loss_mask: 1.1007  decode.d2.loss_dice: 1.8861  decode.d3.loss_cls: 1.4836  decode.d3.loss_mask: 1.0862  decode.d3.loss_dice: 1.8440  decode.d4.loss_cls: 1.5228  decode.d4.loss_mask: 1.0774  decode.d4.loss_dice: 1.9159  decode.d5.loss_cls: 1.5077  decode.d5.loss_mask: 1.0592  decode.d5.loss_dice: 1.8277  decode.d6.loss_cls: 1.4746  decode.d6.loss_mask: 1.0064  decode.d6.loss_dice: 1.8527  decode.d7.loss_cls: 1.4263  decode.d7.loss_mask: 1.0215  decode.d7.loss_dice: 1.8481  decode.d8.loss_cls: 1.4994  decode.d8.loss_mask: 1.0384  decode.d8.loss_dice: 1.8403
2023/05/23 19:46:39 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 19:46:39 - mmengine - INFO - Iter(train) [ 12000/160000]  lr: 9.3224e-06  eta: 17:33:16  time: 0.4640  data_time: 0.0101  memory: 4851  grad_norm: 95.7746  loss: 40.1730  decode.loss_cls: 1.6052  decode.loss_mask: 0.7455  decode.loss_dice: 1.4008  decode.d0.loss_cls: 3.5165  decode.d0.loss_mask: 0.8762  decode.d0.loss_dice: 1.7167  decode.d1.loss_cls: 1.8112  decode.d1.loss_mask: 0.7775  decode.d1.loss_dice: 1.5090  decode.d2.loss_cls: 1.6727  decode.d2.loss_mask: 0.7106  decode.d2.loss_dice: 1.4481  decode.d3.loss_cls: 1.6344  decode.d3.loss_mask: 0.7270  decode.d3.loss_dice: 1.4079  decode.d4.loss_cls: 1.5555  decode.d4.loss_mask: 0.7352  decode.d4.loss_dice: 1.4017  decode.d5.loss_cls: 1.6198  decode.d5.loss_mask: 0.7289  decode.d5.loss_dice: 1.3948  decode.d6.loss_cls: 1.6105  decode.d6.loss_mask: 0.7304  decode.d6.loss_dice: 1.3875  decode.d7.loss_cls: 1.5607  decode.d7.loss_mask: 0.7592  decode.d7.loss_dice: 1.4099  decode.d8.loss_cls: 1.5792  decode.d8.loss_mask: 0.7353  decode.d8.loss_dice: 1.4051
2023/05/23 19:46:39 - mmengine - INFO - Saving checkpoint at 12000 iterations
2023/05/23 19:47:06 - mmengine - INFO - Iter(train) [ 12050/160000]  lr: 9.3196e-06  eta: 17:33:56  time: 0.4088  data_time: 0.0094  memory: 4805  grad_norm: 110.0604  loss: 53.2495  decode.loss_cls: 2.0723  decode.loss_mask: 1.0261  decode.loss_dice: 2.0331  decode.d0.loss_cls: 3.9859  decode.d0.loss_mask: 1.0792  decode.d0.loss_dice: 2.2780  decode.d1.loss_cls: 2.1396  decode.d1.loss_mask: 1.0507  decode.d1.loss_dice: 2.0651  decode.d2.loss_cls: 2.0253  decode.d2.loss_mask: 1.1370  decode.d2.loss_dice: 1.9791  decode.d3.loss_cls: 1.9745  decode.d3.loss_mask: 1.1040  decode.d3.loss_dice: 2.0023  decode.d4.loss_cls: 1.9690  decode.d4.loss_mask: 1.0710  decode.d4.loss_dice: 2.0297  decode.d5.loss_cls: 1.9261  decode.d5.loss_mask: 1.0534  decode.d5.loss_dice: 2.0405  decode.d6.loss_cls: 1.9710  decode.d6.loss_mask: 1.0532  decode.d6.loss_dice: 2.0294  decode.d7.loss_cls: 1.9904  decode.d7.loss_mask: 1.0644  decode.d7.loss_dice: 2.0381  decode.d8.loss_cls: 2.0386  decode.d8.loss_mask: 1.0001  decode.d8.loss_dice: 2.0225
2023/05/23 19:47:26 - mmengine - INFO - Iter(train) [ 12100/160000]  lr: 9.3168e-06  eta: 17:33:24  time: 0.4159  data_time: 0.0099  memory: 4943  grad_norm: 104.8323  loss: 37.0141  decode.loss_cls: 1.4453  decode.loss_mask: 0.7855  decode.loss_dice: 1.1968  decode.d0.loss_cls: 3.2560  decode.d0.loss_mask: 0.7900  decode.d0.loss_dice: 1.3682  decode.d1.loss_cls: 1.7276  decode.d1.loss_mask: 0.7748  decode.d1.loss_dice: 1.2934  decode.d2.loss_cls: 1.5727  decode.d2.loss_mask: 0.7901  decode.d2.loss_dice: 1.2232  decode.d3.loss_cls: 1.4887  decode.d3.loss_mask: 0.7885  decode.d3.loss_dice: 1.2100  decode.d4.loss_cls: 1.4782  decode.d4.loss_mask: 0.8264  decode.d4.loss_dice: 1.1901  decode.d5.loss_cls: 1.5269  decode.d5.loss_mask: 0.7667  decode.d5.loss_dice: 1.1758  decode.d6.loss_cls: 1.4995  decode.d6.loss_mask: 0.7745  decode.d6.loss_dice: 1.1520  decode.d7.loss_cls: 1.5100  decode.d7.loss_mask: 0.7769  decode.d7.loss_dice: 1.1980  decode.d8.loss_cls: 1.4822  decode.d8.loss_mask: 0.7656  decode.d8.loss_dice: 1.1807
2023/05/23 19:47:47 - mmengine - INFO - Iter(train) [ 12150/160000]  lr: 9.3139e-06  eta: 17:32:53  time: 0.4029  data_time: 0.0092  memory: 4848  grad_norm: 104.9170  loss: 40.1511  decode.loss_cls: 1.4862  decode.loss_mask: 0.8471  decode.loss_dice: 1.4379  decode.d0.loss_cls: 3.4416  decode.d0.loss_mask: 0.8618  decode.d0.loss_dice: 1.5622  decode.d1.loss_cls: 1.5871  decode.d1.loss_mask: 0.8650  decode.d1.loss_dice: 1.5323  decode.d2.loss_cls: 1.4661  decode.d2.loss_mask: 0.8571  decode.d2.loss_dice: 1.4858  decode.d3.loss_cls: 1.4131  decode.d3.loss_mask: 0.8815  decode.d3.loss_dice: 1.4427  decode.d4.loss_cls: 1.4228  decode.d4.loss_mask: 0.8932  decode.d4.loss_dice: 1.4822  decode.d5.loss_cls: 1.4797  decode.d5.loss_mask: 0.9057  decode.d5.loss_dice: 1.4663  decode.d6.loss_cls: 1.4380  decode.d6.loss_mask: 0.8756  decode.d6.loss_dice: 1.4438  decode.d7.loss_cls: 1.4707  decode.d7.loss_mask: 0.8744  decode.d7.loss_dice: 1.4506  decode.d8.loss_cls: 1.4402  decode.d8.loss_mask: 0.8734  decode.d8.loss_dice: 1.4671
2023/05/23 19:48:08 - mmengine - INFO - Iter(train) [ 12200/160000]  lr: 9.3111e-06  eta: 17:32:27  time: 0.4087  data_time: 0.0095  memory: 4804  grad_norm: 100.0000  loss: 38.6562  decode.loss_cls: 1.5474  decode.loss_mask: 0.8182  decode.loss_dice: 1.1811  decode.d0.loss_cls: 3.4379  decode.d0.loss_mask: 0.9389  decode.d0.loss_dice: 1.4772  decode.d1.loss_cls: 1.6992  decode.d1.loss_mask: 0.8944  decode.d1.loss_dice: 1.2855  decode.d2.loss_cls: 1.5936  decode.d2.loss_mask: 0.8695  decode.d2.loss_dice: 1.3363  decode.d3.loss_cls: 1.5811  decode.d3.loss_mask: 0.8144  decode.d3.loss_dice: 1.2108  decode.d4.loss_cls: 1.5948  decode.d4.loss_mask: 0.8275  decode.d4.loss_dice: 1.2283  decode.d5.loss_cls: 1.4939  decode.d5.loss_mask: 0.8363  decode.d5.loss_dice: 1.2519  decode.d6.loss_cls: 1.5624  decode.d6.loss_mask: 0.8096  decode.d6.loss_dice: 1.2194  decode.d7.loss_cls: 1.5520  decode.d7.loss_mask: 0.8144  decode.d7.loss_dice: 1.2129  decode.d8.loss_cls: 1.5083  decode.d8.loss_mask: 0.8231  decode.d8.loss_dice: 1.2361
2023/05/23 19:48:29 - mmengine - INFO - Iter(train) [ 12250/160000]  lr: 9.3083e-06  eta: 17:32:02  time: 0.4432  data_time: 0.0097  memory: 4894  grad_norm: 112.0689  loss: 38.6797  decode.loss_cls: 1.3661  decode.loss_mask: 0.8785  decode.loss_dice: 1.3446  decode.d0.loss_cls: 3.4651  decode.d0.loss_mask: 0.8831  decode.d0.loss_dice: 1.5400  decode.d1.loss_cls: 1.5999  decode.d1.loss_mask: 0.9675  decode.d1.loss_dice: 1.4853  decode.d2.loss_cls: 1.3750  decode.d2.loss_mask: 0.9684  decode.d2.loss_dice: 1.3532  decode.d3.loss_cls: 1.3246  decode.d3.loss_mask: 0.9619  decode.d3.loss_dice: 1.3420  decode.d4.loss_cls: 1.3713  decode.d4.loss_mask: 0.8504  decode.d4.loss_dice: 1.3299  decode.d5.loss_cls: 1.3769  decode.d5.loss_mask: 0.8708  decode.d5.loss_dice: 1.3265  decode.d6.loss_cls: 1.3299  decode.d6.loss_mask: 0.8869  decode.d6.loss_dice: 1.3225  decode.d7.loss_cls: 1.3543  decode.d7.loss_mask: 0.8818  decode.d7.loss_dice: 1.3481  decode.d8.loss_cls: 1.3827  decode.d8.loss_mask: 0.8653  decode.d8.loss_dice: 1.3275
2023/05/23 19:48:51 - mmengine - INFO - Iter(train) [ 12300/160000]  lr: 9.3054e-06  eta: 17:31:45  time: 0.4155  data_time: 0.0101  memory: 4833  grad_norm: 103.3077  loss: 46.4150  decode.loss_cls: 1.7221  decode.loss_mask: 1.0511  decode.loss_dice: 1.5227  decode.d0.loss_cls: 3.9243  decode.d0.loss_mask: 1.0826  decode.d0.loss_dice: 1.7364  decode.d1.loss_cls: 1.7431  decode.d1.loss_mask: 1.1634  decode.d1.loss_dice: 1.6583  decode.d2.loss_cls: 1.7935  decode.d2.loss_mask: 1.0807  decode.d2.loss_dice: 1.5875  decode.d3.loss_cls: 1.7386  decode.d3.loss_mask: 1.1145  decode.d3.loss_dice: 1.5531  decode.d4.loss_cls: 1.7336  decode.d4.loss_mask: 1.1100  decode.d4.loss_dice: 1.5613  decode.d5.loss_cls: 1.6378  decode.d5.loss_mask: 1.1191  decode.d5.loss_dice: 1.5902  decode.d6.loss_cls: 1.7164  decode.d6.loss_mask: 1.1012  decode.d6.loss_dice: 1.5107  decode.d7.loss_cls: 1.7755  decode.d7.loss_mask: 1.0860  decode.d7.loss_dice: 1.5633  decode.d8.loss_cls: 1.7861  decode.d8.loss_mask: 1.1068  decode.d8.loss_dice: 1.5453
2023/05/23 19:49:12 - mmengine - INFO - Iter(train) [ 12350/160000]  lr: 9.3026e-06  eta: 17:31:22  time: 0.4347  data_time: 0.0093  memory: 4848  grad_norm: 95.2347  loss: 44.1432  decode.loss_cls: 1.7473  decode.loss_mask: 0.8758  decode.loss_dice: 1.5158  decode.d0.loss_cls: 3.4332  decode.d0.loss_mask: 1.0036  decode.d0.loss_dice: 1.7186  decode.d1.loss_cls: 1.8536  decode.d1.loss_mask: 0.9327  decode.d1.loss_dice: 1.5778  decode.d2.loss_cls: 1.8397  decode.d2.loss_mask: 0.8490  decode.d2.loss_dice: 1.5386  decode.d3.loss_cls: 1.7722  decode.d3.loss_mask: 0.8783  decode.d3.loss_dice: 1.5185  decode.d4.loss_cls: 1.8767  decode.d4.loss_mask: 0.8791  decode.d4.loss_dice: 1.5001  decode.d5.loss_cls: 1.7766  decode.d5.loss_mask: 0.8862  decode.d5.loss_dice: 1.5147  decode.d6.loss_cls: 1.7993  decode.d6.loss_mask: 0.9133  decode.d6.loss_dice: 1.5261  decode.d7.loss_cls: 1.8270  decode.d7.loss_mask: 0.8779  decode.d7.loss_dice: 1.5151  decode.d8.loss_cls: 1.8125  decode.d8.loss_mask: 0.8678  decode.d8.loss_dice: 1.5160
2023/05/23 19:49:34 - mmengine - INFO - Iter(train) [ 12400/160000]  lr: 9.2998e-06  eta: 17:31:14  time: 0.4678  data_time: 0.0101  memory: 4845  grad_norm: 116.0053  loss: 40.0718  decode.loss_cls: 1.6068  decode.loss_mask: 0.7942  decode.loss_dice: 1.3541  decode.d0.loss_cls: 3.2915  decode.d0.loss_mask: 0.8358  decode.d0.loss_dice: 1.5928  decode.d1.loss_cls: 1.7497  decode.d1.loss_mask: 0.8472  decode.d1.loss_dice: 1.4848  decode.d2.loss_cls: 1.5853  decode.d2.loss_mask: 0.8615  decode.d2.loss_dice: 1.4291  decode.d3.loss_cls: 1.6761  decode.d3.loss_mask: 0.8217  decode.d3.loss_dice: 1.3487  decode.d4.loss_cls: 1.6530  decode.d4.loss_mask: 0.7903  decode.d4.loss_dice: 1.3558  decode.d5.loss_cls: 1.5937  decode.d5.loss_mask: 0.8086  decode.d5.loss_dice: 1.3457  decode.d6.loss_cls: 1.6364  decode.d6.loss_mask: 0.7999  decode.d6.loss_dice: 1.3241  decode.d7.loss_cls: 1.5519  decode.d7.loss_mask: 0.8286  decode.d7.loss_dice: 1.3339  decode.d8.loss_cls: 1.6130  decode.d8.loss_mask: 0.7838  decode.d8.loss_dice: 1.3735
2023/05/23 19:49:55 - mmengine - INFO - Iter(train) [ 12450/160000]  lr: 9.2969e-06  eta: 17:30:51  time: 0.4057  data_time: 0.0092  memory: 4824  grad_norm: 144.9183  loss: 31.9909  decode.loss_cls: 1.4142  decode.loss_mask: 0.6999  decode.loss_dice: 0.8588  decode.d0.loss_cls: 2.9705  decode.d0.loss_mask: 0.7479  decode.d0.loss_dice: 0.9956  decode.d1.loss_cls: 1.6674  decode.d1.loss_mask: 0.7314  decode.d1.loss_dice: 0.9809  decode.d2.loss_cls: 1.4756  decode.d2.loss_mask: 0.7043  decode.d2.loss_dice: 0.9152  decode.d3.loss_cls: 1.4328  decode.d3.loss_mask: 0.7043  decode.d3.loss_dice: 0.8661  decode.d4.loss_cls: 1.4156  decode.d4.loss_mask: 0.7071  decode.d4.loss_dice: 0.8582  decode.d5.loss_cls: 1.4126  decode.d5.loss_mask: 0.7003  decode.d5.loss_dice: 0.8792  decode.d6.loss_cls: 1.4088  decode.d6.loss_mask: 0.6838  decode.d6.loss_dice: 0.8512  decode.d7.loss_cls: 1.4110  decode.d7.loss_mask: 0.6654  decode.d7.loss_dice: 0.8563  decode.d8.loss_cls: 1.4236  decode.d8.loss_mask: 0.6840  decode.d8.loss_dice: 0.8686
2023/05/23 19:50:16 - mmengine - INFO - Iter(train) [ 12500/160000]  lr: 9.2941e-06  eta: 17:30:25  time: 0.4468  data_time: 0.0092  memory: 4840  grad_norm: 109.4996  loss: 32.8616  decode.loss_cls: 1.3101  decode.loss_mask: 0.6008  decode.loss_dice: 1.1325  decode.d0.loss_cls: 3.2095  decode.d0.loss_mask: 0.5616  decode.d0.loss_dice: 1.2707  decode.d1.loss_cls: 1.4896  decode.d1.loss_mask: 0.5735  decode.d1.loss_dice: 1.2247  decode.d2.loss_cls: 1.4349  decode.d2.loss_mask: 0.5931  decode.d2.loss_dice: 1.1664  decode.d3.loss_cls: 1.3016  decode.d3.loss_mask: 0.6014  decode.d3.loss_dice: 1.1563  decode.d4.loss_cls: 1.2862  decode.d4.loss_mask: 0.6054  decode.d4.loss_dice: 1.1758  decode.d5.loss_cls: 1.3272  decode.d5.loss_mask: 0.6006  decode.d5.loss_dice: 1.1493  decode.d6.loss_cls: 1.2141  decode.d6.loss_mask: 0.6195  decode.d6.loss_dice: 1.1707  decode.d7.loss_cls: 1.2280  decode.d7.loss_mask: 0.6084  decode.d7.loss_dice: 1.1631  decode.d8.loss_cls: 1.3488  decode.d8.loss_mask: 0.5992  decode.d8.loss_dice: 1.1388
2023/05/23 19:50:37 - mmengine - INFO - Iter(train) [ 12550/160000]  lr: 9.2913e-06  eta: 17:29:58  time: 0.4110  data_time: 0.0093  memory: 4863  grad_norm: 104.8435  loss: 38.9826  decode.loss_cls: 1.6192  decode.loss_mask: 0.8314  decode.loss_dice: 1.1989  decode.d0.loss_cls: 3.2620  decode.d0.loss_mask: 0.8905  decode.d0.loss_dice: 1.4167  decode.d1.loss_cls: 1.6514  decode.d1.loss_mask: 0.8916  decode.d1.loss_dice: 1.3538  decode.d2.loss_cls: 1.6011  decode.d2.loss_mask: 0.8280  decode.d2.loss_dice: 1.2549  decode.d3.loss_cls: 1.6284  decode.d3.loss_mask: 0.8249  decode.d3.loss_dice: 1.2689  decode.d4.loss_cls: 1.6370  decode.d4.loss_mask: 0.8233  decode.d4.loss_dice: 1.2611  decode.d5.loss_cls: 1.5959  decode.d5.loss_mask: 0.8459  decode.d5.loss_dice: 1.2443  decode.d6.loss_cls: 1.5815  decode.d6.loss_mask: 0.8301  decode.d6.loss_dice: 1.2458  decode.d7.loss_cls: 1.6543  decode.d7.loss_mask: 0.8191  decode.d7.loss_dice: 1.2356  decode.d8.loss_cls: 1.6081  decode.d8.loss_mask: 0.8426  decode.d8.loss_dice: 1.2361
2023/05/23 19:50:58 - mmengine - INFO - Iter(train) [ 12600/160000]  lr: 9.2884e-06  eta: 17:29:26  time: 0.4115  data_time: 0.0099  memory: 4844  grad_norm: 116.7010  loss: 44.7123  decode.loss_cls: 1.6607  decode.loss_mask: 1.0011  decode.loss_dice: 1.5602  decode.d0.loss_cls: 3.4983  decode.d0.loss_mask: 1.0382  decode.d0.loss_dice: 1.7104  decode.d1.loss_cls: 1.8219  decode.d1.loss_mask: 1.0455  decode.d1.loss_dice: 1.6625  decode.d2.loss_cls: 1.7599  decode.d2.loss_mask: 0.9826  decode.d2.loss_dice: 1.5951  decode.d3.loss_cls: 1.7194  decode.d3.loss_mask: 0.9492  decode.d3.loss_dice: 1.5310  decode.d4.loss_cls: 1.7363  decode.d4.loss_mask: 0.9748  decode.d4.loss_dice: 1.5347  decode.d5.loss_cls: 1.7110  decode.d5.loss_mask: 0.9537  decode.d5.loss_dice: 1.5098  decode.d6.loss_cls: 1.6583  decode.d6.loss_mask: 0.9919  decode.d6.loss_dice: 1.5511  decode.d7.loss_cls: 1.7403  decode.d7.loss_mask: 0.9858  decode.d7.loss_dice: 1.5462  decode.d8.loss_cls: 1.7229  decode.d8.loss_mask: 1.0046  decode.d8.loss_dice: 1.5550
2023/05/23 19:51:19 - mmengine - INFO - Iter(train) [ 12650/160000]  lr: 9.2856e-06  eta: 17:29:05  time: 0.4707  data_time: 0.0094  memory: 4804  grad_norm: 124.7401  loss: 36.7445  decode.loss_cls: 1.4273  decode.loss_mask: 0.7582  decode.loss_dice: 1.3024  decode.d0.loss_cls: 3.3488  decode.d0.loss_mask: 0.7460  decode.d0.loss_dice: 1.3907  decode.d1.loss_cls: 1.5814  decode.d1.loss_mask: 0.7734  decode.d1.loss_dice: 1.3298  decode.d2.loss_cls: 1.4335  decode.d2.loss_mask: 0.7616  decode.d2.loss_dice: 1.2855  decode.d3.loss_cls: 1.4522  decode.d3.loss_mask: 0.7231  decode.d3.loss_dice: 1.2839  decode.d4.loss_cls: 1.3693  decode.d4.loss_mask: 0.7668  decode.d4.loss_dice: 1.3309  decode.d5.loss_cls: 1.3423  decode.d5.loss_mask: 0.7938  decode.d5.loss_dice: 1.3126  decode.d6.loss_cls: 1.3482  decode.d6.loss_mask: 0.7768  decode.d6.loss_dice: 1.2938  decode.d7.loss_cls: 1.3418  decode.d7.loss_mask: 0.7299  decode.d7.loss_dice: 1.3337  decode.d8.loss_cls: 1.3875  decode.d8.loss_mask: 0.7287  decode.d8.loss_dice: 1.2903
2023/05/23 19:51:40 - mmengine - INFO - Iter(train) [ 12700/160000]  lr: 9.2828e-06  eta: 17:28:38  time: 0.4139  data_time: 0.0095  memory: 4788  grad_norm: 122.3633  loss: 41.2807  decode.loss_cls: 1.5776  decode.loss_mask: 0.9191  decode.loss_dice: 1.3479  decode.d0.loss_cls: 3.5804  decode.d0.loss_mask: 0.9617  decode.d0.loss_dice: 1.5348  decode.d1.loss_cls: 1.6738  decode.d1.loss_mask: 1.0139  decode.d1.loss_dice: 1.4060  decode.d2.loss_cls: 1.6779  decode.d2.loss_mask: 0.9448  decode.d2.loss_dice: 1.3824  decode.d3.loss_cls: 1.6181  decode.d3.loss_mask: 0.9120  decode.d3.loss_dice: 1.3810  decode.d4.loss_cls: 1.6221  decode.d4.loss_mask: 0.9032  decode.d4.loss_dice: 1.3886  decode.d5.loss_cls: 1.5595  decode.d5.loss_mask: 0.9222  decode.d5.loss_dice: 1.3579  decode.d6.loss_cls: 1.5496  decode.d6.loss_mask: 0.9310  decode.d6.loss_dice: 1.3292  decode.d7.loss_cls: 1.5756  decode.d7.loss_mask: 0.9523  decode.d7.loss_dice: 1.3763  decode.d8.loss_cls: 1.5978  decode.d8.loss_mask: 0.9366  decode.d8.loss_dice: 1.3475
2023/05/23 19:52:01 - mmengine - INFO - Iter(train) [ 12750/160000]  lr: 9.2799e-06  eta: 17:28:10  time: 0.4471  data_time: 0.0099  memory: 4860  grad_norm: 133.4924  loss: 47.2549  decode.loss_cls: 1.8039  decode.loss_mask: 0.8218  decode.loss_dice: 1.8194  decode.d0.loss_cls: 3.8185  decode.d0.loss_mask: 0.8880  decode.d0.loss_dice: 2.0819  decode.d1.loss_cls: 1.9354  decode.d1.loss_mask: 0.8648  decode.d1.loss_dice: 1.9904  decode.d2.loss_cls: 1.8480  decode.d2.loss_mask: 0.8398  decode.d2.loss_dice: 1.9630  decode.d3.loss_cls: 1.7508  decode.d3.loss_mask: 0.8514  decode.d3.loss_dice: 1.8571  decode.d4.loss_cls: 1.7658  decode.d4.loss_mask: 0.8584  decode.d4.loss_dice: 1.8738  decode.d5.loss_cls: 1.8010  decode.d5.loss_mask: 0.8309  decode.d5.loss_dice: 1.8299  decode.d6.loss_cls: 1.7300  decode.d6.loss_mask: 0.8373  decode.d6.loss_dice: 1.8171  decode.d7.loss_cls: 1.7401  decode.d7.loss_mask: 0.8109  decode.d7.loss_dice: 1.8283  decode.d8.loss_cls: 1.7123  decode.d8.loss_mask: 0.8340  decode.d8.loss_dice: 1.8510
2023/05/23 19:52:21 - mmengine - INFO - Iter(train) [ 12800/160000]  lr: 9.2771e-06  eta: 17:27:40  time: 0.4155  data_time: 0.0100  memory: 4941  grad_norm: 101.4757  loss: 33.2716  decode.loss_cls: 1.2537  decode.loss_mask: 0.6969  decode.loss_dice: 1.0761  decode.d0.loss_cls: 3.2297  decode.d0.loss_mask: 0.6824  decode.d0.loss_dice: 1.1999  decode.d1.loss_cls: 1.4438  decode.d1.loss_mask: 0.7067  decode.d1.loss_dice: 1.2005  decode.d2.loss_cls: 1.4078  decode.d2.loss_mask: 0.7037  decode.d2.loss_dice: 1.1200  decode.d3.loss_cls: 1.3311  decode.d3.loss_mask: 0.7077  decode.d3.loss_dice: 1.1065  decode.d4.loss_cls: 1.3022  decode.d4.loss_mask: 0.7043  decode.d4.loss_dice: 1.0697  decode.d5.loss_cls: 1.3242  decode.d5.loss_mask: 0.6925  decode.d5.loss_dice: 1.1077  decode.d6.loss_cls: 1.3338  decode.d6.loss_mask: 0.6925  decode.d6.loss_dice: 1.0898  decode.d7.loss_cls: 1.2958  decode.d7.loss_mask: 0.6821  decode.d7.loss_dice: 1.0683  decode.d8.loss_cls: 1.2868  decode.d8.loss_mask: 0.6990  decode.d8.loss_dice: 1.0566
2023/05/23 19:52:42 - mmengine - INFO - Iter(train) [ 12850/160000]  lr: 9.2742e-06  eta: 17:27:11  time: 0.4093  data_time: 0.0094  memory: 4871  grad_norm: 91.7834  loss: 48.0949  decode.loss_cls: 1.7693  decode.loss_mask: 0.9192  decode.loss_dice: 1.7835  decode.d0.loss_cls: 3.8052  decode.d0.loss_mask: 0.8678  decode.d0.loss_dice: 2.0344  decode.d1.loss_cls: 2.0154  decode.d1.loss_mask: 0.9372  decode.d1.loss_dice: 1.9147  decode.d2.loss_cls: 1.8569  decode.d2.loss_mask: 0.9244  decode.d2.loss_dice: 1.9015  decode.d3.loss_cls: 1.8074  decode.d3.loss_mask: 0.9177  decode.d3.loss_dice: 1.8123  decode.d4.loss_cls: 1.8050  decode.d4.loss_mask: 0.9180  decode.d4.loss_dice: 1.8183  decode.d5.loss_cls: 1.7893  decode.d5.loss_mask: 0.9225  decode.d5.loss_dice: 1.8631  decode.d6.loss_cls: 1.8626  decode.d6.loss_mask: 0.9144  decode.d6.loss_dice: 1.8463  decode.d7.loss_cls: 1.8710  decode.d7.loss_mask: 0.9067  decode.d7.loss_dice: 1.7776  decode.d8.loss_cls: 1.7945  decode.d8.loss_mask: 0.9314  decode.d8.loss_dice: 1.8071
2023/05/23 19:53:03 - mmengine - INFO - Iter(train) [ 12900/160000]  lr: 9.2714e-06  eta: 17:26:40  time: 0.4144  data_time: 0.0101  memory: 4858  grad_norm: 113.3050  loss: 40.1820  decode.loss_cls: 1.4915  decode.loss_mask: 0.9789  decode.loss_dice: 1.2165  decode.d0.loss_cls: 3.4403  decode.d0.loss_mask: 1.0389  decode.d0.loss_dice: 1.5225  decode.d1.loss_cls: 1.7486  decode.d1.loss_mask: 0.9818  decode.d1.loss_dice: 1.3440  decode.d2.loss_cls: 1.6036  decode.d2.loss_mask: 0.9571  decode.d2.loss_dice: 1.3199  decode.d3.loss_cls: 1.5453  decode.d3.loss_mask: 0.9795  decode.d3.loss_dice: 1.2888  decode.d4.loss_cls: 1.5115  decode.d4.loss_mask: 1.0034  decode.d4.loss_dice: 1.2814  decode.d5.loss_cls: 1.5329  decode.d5.loss_mask: 1.0155  decode.d5.loss_dice: 1.2846  decode.d6.loss_cls: 1.4182  decode.d6.loss_mask: 1.0053  decode.d6.loss_dice: 1.2575  decode.d7.loss_cls: 1.4650  decode.d7.loss_mask: 1.0022  decode.d7.loss_dice: 1.2392  decode.d8.loss_cls: 1.4922  decode.d8.loss_mask: 0.9860  decode.d8.loss_dice: 1.2301
2023/05/23 19:53:24 - mmengine - INFO - Iter(train) [ 12950/160000]  lr: 9.2686e-06  eta: 17:26:17  time: 0.4135  data_time: 0.0096  memory: 4888  grad_norm: 100.2149  loss: 33.2440  decode.loss_cls: 1.2688  decode.loss_mask: 0.7250  decode.loss_dice: 1.0796  decode.d0.loss_cls: 3.2529  decode.d0.loss_mask: 0.8196  decode.d0.loss_dice: 1.2117  decode.d1.loss_cls: 1.5090  decode.d1.loss_mask: 0.7959  decode.d1.loss_dice: 1.0973  decode.d2.loss_cls: 1.3969  decode.d2.loss_mask: 0.7290  decode.d2.loss_dice: 1.0282  decode.d3.loss_cls: 1.2910  decode.d3.loss_mask: 0.7532  decode.d3.loss_dice: 1.0289  decode.d4.loss_cls: 1.3424  decode.d4.loss_mask: 0.7273  decode.d4.loss_dice: 1.0389  decode.d5.loss_cls: 1.3265  decode.d5.loss_mask: 0.7140  decode.d5.loss_dice: 1.0251  decode.d6.loss_cls: 1.3336  decode.d6.loss_mask: 0.7325  decode.d6.loss_dice: 1.0241  decode.d7.loss_cls: 1.3091  decode.d7.loss_mask: 0.6975  decode.d7.loss_dice: 1.0032  decode.d8.loss_cls: 1.2795  decode.d8.loss_mask: 0.7021  decode.d8.loss_dice: 1.0011
2023/05/23 19:53:44 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 19:53:44 - mmengine - INFO - Iter(train) [ 13000/160000]  lr: 9.2657e-06  eta: 17:25:44  time: 0.4059  data_time: 0.0092  memory: 4884  grad_norm: 133.4529  loss: 40.1830  decode.loss_cls: 1.5549  decode.loss_mask: 0.8978  decode.loss_dice: 1.2751  decode.d0.loss_cls: 3.3779  decode.d0.loss_mask: 0.9889  decode.d0.loss_dice: 1.4625  decode.d1.loss_cls: 1.7176  decode.d1.loss_mask: 0.9317  decode.d1.loss_dice: 1.3992  decode.d2.loss_cls: 1.5877  decode.d2.loss_mask: 0.9153  decode.d2.loss_dice: 1.3583  decode.d3.loss_cls: 1.6374  decode.d3.loss_mask: 0.9101  decode.d3.loss_dice: 1.2558  decode.d4.loss_cls: 1.6352  decode.d4.loss_mask: 0.8950  decode.d4.loss_dice: 1.2565  decode.d5.loss_cls: 1.5408  decode.d5.loss_mask: 0.9085  decode.d5.loss_dice: 1.3026  decode.d6.loss_cls: 1.6257  decode.d6.loss_mask: 0.9302  decode.d6.loss_dice: 1.2860  decode.d7.loss_cls: 1.5638  decode.d7.loss_mask: 0.9198  decode.d7.loss_dice: 1.2828  decode.d8.loss_cls: 1.5471  decode.d8.loss_mask: 0.9291  decode.d8.loss_dice: 1.2899
2023/05/23 19:53:44 - mmengine - INFO - Saving checkpoint at 13000 iterations
2023/05/23 19:54:10 - mmengine - INFO - Iter(train) [ 13050/160000]  lr: 9.2629e-06  eta: 17:26:16  time: 0.4156  data_time: 0.0094  memory: 4832  grad_norm: 94.8137  loss: 46.4027  decode.loss_cls: 1.5926  decode.loss_mask: 0.9554  decode.loss_dice: 1.8014  decode.d0.loss_cls: 3.7974  decode.d0.loss_mask: 0.9916  decode.d0.loss_dice: 2.0694  decode.d1.loss_cls: 1.8609  decode.d1.loss_mask: 0.9861  decode.d1.loss_dice: 1.9247  decode.d2.loss_cls: 1.6075  decode.d2.loss_mask: 0.9866  decode.d2.loss_dice: 1.8696  decode.d3.loss_cls: 1.5481  decode.d3.loss_mask: 0.9779  decode.d3.loss_dice: 1.8261  decode.d4.loss_cls: 1.5747  decode.d4.loss_mask: 0.9459  decode.d4.loss_dice: 1.8108  decode.d5.loss_cls: 1.4900  decode.d5.loss_mask: 0.9600  decode.d5.loss_dice: 1.8179  decode.d6.loss_cls: 1.5846  decode.d6.loss_mask: 0.9404  decode.d6.loss_dice: 1.8088  decode.d7.loss_cls: 1.5715  decode.d7.loss_mask: 0.9363  decode.d7.loss_dice: 1.8185  decode.d8.loss_cls: 1.6263  decode.d8.loss_mask: 0.9439  decode.d8.loss_dice: 1.7775
2023/05/23 19:54:31 - mmengine - INFO - Iter(train) [ 13100/160000]  lr: 9.2601e-06  eta: 17:25:51  time: 0.4264  data_time: 0.0095  memory: 4821  grad_norm: 201.3692  loss: 48.6944  decode.loss_cls: 1.9412  decode.loss_mask: 0.9036  decode.loss_dice: 1.7810  decode.d0.loss_cls: 3.8034  decode.d0.loss_mask: 0.9843  decode.d0.loss_dice: 2.0297  decode.d1.loss_cls: 2.0688  decode.d1.loss_mask: 0.9040  decode.d1.loss_dice: 1.8951  decode.d2.loss_cls: 1.9379  decode.d2.loss_mask: 0.9158  decode.d2.loss_dice: 1.8437  decode.d3.loss_cls: 1.8721  decode.d3.loss_mask: 0.9308  decode.d3.loss_dice: 1.8625  decode.d4.loss_cls: 1.9113  decode.d4.loss_mask: 0.9446  decode.d4.loss_dice: 1.8579  decode.d5.loss_cls: 1.8472  decode.d5.loss_mask: 0.9551  decode.d5.loss_dice: 1.8424  decode.d6.loss_cls: 1.8735  decode.d6.loss_mask: 0.8847  decode.d6.loss_dice: 1.8123  decode.d7.loss_cls: 1.8505  decode.d7.loss_mask: 0.9150  decode.d7.loss_dice: 1.7733  decode.d8.loss_cls: 1.8394  decode.d8.loss_mask: 0.9218  decode.d8.loss_dice: 1.7915
2023/05/23 19:54:52 - mmengine - INFO - Iter(train) [ 13150/160000]  lr: 9.2572e-06  eta: 17:25:24  time: 0.4037  data_time: 0.0099  memory: 4981  grad_norm: 106.1070  loss: 49.2347  decode.loss_cls: 1.7981  decode.loss_mask: 0.9267  decode.loss_dice: 1.8453  decode.d0.loss_cls: 4.0201  decode.d0.loss_mask: 0.9854  decode.d0.loss_dice: 2.0841  decode.d1.loss_cls: 2.0522  decode.d1.loss_mask: 0.9799  decode.d1.loss_dice: 1.9834  decode.d2.loss_cls: 2.0084  decode.d2.loss_mask: 0.9615  decode.d2.loss_dice: 1.8866  decode.d3.loss_cls: 1.8847  decode.d3.loss_mask: 0.9689  decode.d3.loss_dice: 1.7937  decode.d4.loss_cls: 1.8603  decode.d4.loss_mask: 0.9870  decode.d4.loss_dice: 1.8056  decode.d5.loss_cls: 1.7879  decode.d5.loss_mask: 0.9888  decode.d5.loss_dice: 1.8536  decode.d6.loss_cls: 1.8258  decode.d6.loss_mask: 0.9211  decode.d6.loss_dice: 1.7956  decode.d7.loss_cls: 1.8704  decode.d7.loss_mask: 0.9286  decode.d7.loss_dice: 1.8063  decode.d8.loss_cls: 1.8229  decode.d8.loss_mask: 0.9600  decode.d8.loss_dice: 1.8419
2023/05/23 19:55:13 - mmengine - INFO - Iter(train) [ 13200/160000]  lr: 9.2544e-06  eta: 17:24:53  time: 0.4125  data_time: 0.0099  memory: 4853  grad_norm: 115.3999  loss: 41.4073  decode.loss_cls: 1.5185  decode.loss_mask: 0.8338  decode.loss_dice: 1.5634  decode.d0.loss_cls: 3.4528  decode.d0.loss_mask: 0.8678  decode.d0.loss_dice: 1.8220  decode.d1.loss_cls: 1.6343  decode.d1.loss_mask: 0.9296  decode.d1.loss_dice: 1.6255  decode.d2.loss_cls: 1.4514  decode.d2.loss_mask: 0.8732  decode.d2.loss_dice: 1.5560  decode.d3.loss_cls: 1.4703  decode.d3.loss_mask: 0.8599  decode.d3.loss_dice: 1.5268  decode.d4.loss_cls: 1.4763  decode.d4.loss_mask: 0.8542  decode.d4.loss_dice: 1.5171  decode.d5.loss_cls: 1.5114  decode.d5.loss_mask: 0.8269  decode.d5.loss_dice: 1.5407  decode.d6.loss_cls: 1.4640  decode.d6.loss_mask: 0.8318  decode.d6.loss_dice: 1.5545  decode.d7.loss_cls: 1.5254  decode.d7.loss_mask: 0.8352  decode.d7.loss_dice: 1.5639  decode.d8.loss_cls: 1.5061  decode.d8.loss_mask: 0.8391  decode.d8.loss_dice: 1.5755
2023/05/23 19:55:33 - mmengine - INFO - Iter(train) [ 13250/160000]  lr: 9.2516e-06  eta: 17:24:22  time: 0.4120  data_time: 0.0092  memory: 4857  grad_norm: 120.1487  loss: 43.8957  decode.loss_cls: 1.6691  decode.loss_mask: 0.7588  decode.loss_dice: 1.6334  decode.d0.loss_cls: 3.8818  decode.d0.loss_mask: 0.8046  decode.d0.loss_dice: 1.9204  decode.d1.loss_cls: 1.9322  decode.d1.loss_mask: 0.8321  decode.d1.loss_dice: 1.8737  decode.d2.loss_cls: 1.7750  decode.d2.loss_mask: 0.7492  decode.d2.loss_dice: 1.7039  decode.d3.loss_cls: 1.7046  decode.d3.loss_mask: 0.7179  decode.d3.loss_dice: 1.6315  decode.d4.loss_cls: 1.6757  decode.d4.loss_mask: 0.7447  decode.d4.loss_dice: 1.6709  decode.d5.loss_cls: 1.6322  decode.d5.loss_mask: 0.7820  decode.d5.loss_dice: 1.6469  decode.d6.loss_cls: 1.6122  decode.d6.loss_mask: 0.7870  decode.d6.loss_dice: 1.6214  decode.d7.loss_cls: 1.6274  decode.d7.loss_mask: 0.7832  decode.d7.loss_dice: 1.6582  decode.d8.loss_cls: 1.6972  decode.d8.loss_mask: 0.7339  decode.d8.loss_dice: 1.6347
2023/05/23 19:55:54 - mmengine - INFO - Iter(train) [ 13300/160000]  lr: 9.2487e-06  eta: 17:23:52  time: 0.4060  data_time: 0.0097  memory: 4807  grad_norm: 91.4763  loss: 42.2856  decode.loss_cls: 1.4741  decode.loss_mask: 0.9466  decode.loss_dice: 1.5807  decode.d0.loss_cls: 3.2989  decode.d0.loss_mask: 0.9352  decode.d0.loss_dice: 1.7777  decode.d1.loss_cls: 1.6272  decode.d1.loss_mask: 0.9507  decode.d1.loss_dice: 1.6915  decode.d2.loss_cls: 1.5548  decode.d2.loss_mask: 0.8920  decode.d2.loss_dice: 1.6254  decode.d3.loss_cls: 1.5473  decode.d3.loss_mask: 0.9098  decode.d3.loss_dice: 1.5685  decode.d4.loss_cls: 1.5015  decode.d4.loss_mask: 0.9256  decode.d4.loss_dice: 1.6112  decode.d5.loss_cls: 1.5093  decode.d5.loss_mask: 0.9408  decode.d5.loss_dice: 1.5927  decode.d6.loss_cls: 1.4719  decode.d6.loss_mask: 0.9155  decode.d6.loss_dice: 1.5867  decode.d7.loss_cls: 1.3502  decode.d7.loss_mask: 0.9311  decode.d7.loss_dice: 1.5865  decode.d8.loss_cls: 1.4451  decode.d8.loss_mask: 0.9219  decode.d8.loss_dice: 1.6154
2023/05/23 19:56:14 - mmengine - INFO - Iter(train) [ 13350/160000]  lr: 9.2459e-06  eta: 17:23:22  time: 0.4015  data_time: 0.0092  memory: 4824  grad_norm: 99.7424  loss: 43.3846  decode.loss_cls: 1.5240  decode.loss_mask: 0.9855  decode.loss_dice: 1.5334  decode.d0.loss_cls: 3.4942  decode.d0.loss_mask: 0.9931  decode.d0.loss_dice: 1.8117  decode.d1.loss_cls: 1.7157  decode.d1.loss_mask: 0.9711  decode.d1.loss_dice: 1.7085  decode.d2.loss_cls: 1.5688  decode.d2.loss_mask: 0.9934  decode.d2.loss_dice: 1.5925  decode.d3.loss_cls: 1.5554  decode.d3.loss_mask: 0.9935  decode.d3.loss_dice: 1.5796  decode.d4.loss_cls: 1.4892  decode.d4.loss_mask: 0.9904  decode.d4.loss_dice: 1.6264  decode.d5.loss_cls: 1.5436  decode.d5.loss_mask: 0.9409  decode.d5.loss_dice: 1.5801  decode.d6.loss_cls: 1.5829  decode.d6.loss_mask: 0.9288  decode.d6.loss_dice: 1.5221  decode.d7.loss_cls: 1.5856  decode.d7.loss_mask: 0.9497  decode.d7.loss_dice: 1.5473  decode.d8.loss_cls: 1.5762  decode.d8.loss_mask: 0.9586  decode.d8.loss_dice: 1.5426
2023/05/23 19:56:35 - mmengine - INFO - Iter(train) [ 13400/160000]  lr: 9.2430e-06  eta: 17:22:54  time: 0.4414  data_time: 0.0105  memory: 4859  grad_norm: 111.8350  loss: 52.5507  decode.loss_cls: 1.9433  decode.loss_mask: 1.1246  decode.loss_dice: 1.9343  decode.d0.loss_cls: 3.8707  decode.d0.loss_mask: 1.1433  decode.d0.loss_dice: 2.1682  decode.d1.loss_cls: 2.1288  decode.d1.loss_mask: 1.0635  decode.d1.loss_dice: 2.0277  decode.d2.loss_cls: 2.0520  decode.d2.loss_mask: 1.0950  decode.d2.loss_dice: 1.9661  decode.d3.loss_cls: 2.0244  decode.d3.loss_mask: 1.0618  decode.d3.loss_dice: 1.9850  decode.d4.loss_cls: 1.9933  decode.d4.loss_mask: 1.0520  decode.d4.loss_dice: 1.9719  decode.d5.loss_cls: 2.0196  decode.d5.loss_mask: 1.0724  decode.d5.loss_dice: 1.8796  decode.d6.loss_cls: 2.0030  decode.d6.loss_mask: 1.1081  decode.d6.loss_dice: 1.9119  decode.d7.loss_cls: 1.9014  decode.d7.loss_mask: 1.1296  decode.d7.loss_dice: 1.9104  decode.d8.loss_cls: 1.9502  decode.d8.loss_mask: 1.1091  decode.d8.loss_dice: 1.9496
2023/05/23 19:56:56 - mmengine - INFO - Iter(train) [ 13450/160000]  lr: 9.2402e-06  eta: 17:22:33  time: 0.4035  data_time: 0.0093  memory: 4942  grad_norm: 106.8839  loss: 39.5545  decode.loss_cls: 1.4430  decode.loss_mask: 0.8948  decode.loss_dice: 1.3591  decode.d0.loss_cls: 3.3897  decode.d0.loss_mask: 0.8120  decode.d0.loss_dice: 1.5018  decode.d1.loss_cls: 1.5783  decode.d1.loss_mask: 0.8737  decode.d1.loss_dice: 1.4241  decode.d2.loss_cls: 1.5789  decode.d2.loss_mask: 0.8402  decode.d2.loss_dice: 1.4055  decode.d3.loss_cls: 1.5237  decode.d3.loss_mask: 0.8888  decode.d3.loss_dice: 1.4190  decode.d4.loss_cls: 1.4928  decode.d4.loss_mask: 0.8711  decode.d4.loss_dice: 1.3676  decode.d5.loss_cls: 1.5245  decode.d5.loss_mask: 0.9050  decode.d5.loss_dice: 1.3444  decode.d6.loss_cls: 1.4850  decode.d6.loss_mask: 0.8921  decode.d6.loss_dice: 1.3466  decode.d7.loss_cls: 1.4464  decode.d7.loss_mask: 0.8492  decode.d7.loss_dice: 1.3532  decode.d8.loss_cls: 1.4622  decode.d8.loss_mask: 0.9084  decode.d8.loss_dice: 1.3734
2023/05/23 19:57:17 - mmengine - INFO - Iter(train) [ 13500/160000]  lr: 9.2374e-06  eta: 17:22:00  time: 0.4082  data_time: 0.0096  memory: 4845  grad_norm: 112.4670  loss: 45.5871  decode.loss_cls: 1.7578  decode.loss_mask: 1.0033  decode.loss_dice: 1.5040  decode.d0.loss_cls: 3.8115  decode.d0.loss_mask: 1.0220  decode.d0.loss_dice: 1.7539  decode.d1.loss_cls: 2.0779  decode.d1.loss_mask: 0.9602  decode.d1.loss_dice: 1.5805  decode.d2.loss_cls: 1.8936  decode.d2.loss_mask: 0.9315  decode.d2.loss_dice: 1.5226  decode.d3.loss_cls: 1.8874  decode.d3.loss_mask: 0.9731  decode.d3.loss_dice: 1.4939  decode.d4.loss_cls: 1.8645  decode.d4.loss_mask: 0.9786  decode.d4.loss_dice: 1.4969  decode.d5.loss_cls: 1.9031  decode.d5.loss_mask: 0.9650  decode.d5.loss_dice: 1.4651  decode.d6.loss_cls: 1.7956  decode.d6.loss_mask: 0.9968  decode.d6.loss_dice: 1.4612  decode.d7.loss_cls: 1.7690  decode.d7.loss_mask: 0.9834  decode.d7.loss_dice: 1.4727  decode.d8.loss_cls: 1.7867  decode.d8.loss_mask: 0.9829  decode.d8.loss_dice: 1.4923
2023/05/23 19:57:37 - mmengine - INFO - Iter(train) [ 13550/160000]  lr: 9.2345e-06  eta: 17:21:30  time: 0.4043  data_time: 0.0092  memory: 4807  grad_norm: 123.5627  loss: 39.5958  decode.loss_cls: 1.3410  decode.loss_mask: 0.7626  decode.loss_dice: 1.4655  decode.d0.loss_cls: 3.4043  decode.d0.loss_mask: 0.7553  decode.d0.loss_dice: 1.6617  decode.d1.loss_cls: 1.5217  decode.d1.loss_mask: 0.7922  decode.d1.loss_dice: 1.6223  decode.d2.loss_cls: 1.4400  decode.d2.loss_mask: 0.8248  decode.d2.loss_dice: 1.5711  decode.d3.loss_cls: 1.3923  decode.d3.loss_mask: 0.7801  decode.d3.loss_dice: 1.5735  decode.d4.loss_cls: 1.4016  decode.d4.loss_mask: 0.7784  decode.d4.loss_dice: 1.5430  decode.d5.loss_cls: 1.4067  decode.d5.loss_mask: 0.8305  decode.d5.loss_dice: 1.5773  decode.d6.loss_cls: 1.3078  decode.d6.loss_mask: 0.8342  decode.d6.loss_dice: 1.5890  decode.d7.loss_cls: 1.3633  decode.d7.loss_mask: 0.8230  decode.d7.loss_dice: 1.5728  decode.d8.loss_cls: 1.3350  decode.d8.loss_mask: 0.7795  decode.d8.loss_dice: 1.5455
2023/05/23 19:57:58 - mmengine - INFO - Iter(train) [ 13600/160000]  lr: 9.2317e-06  eta: 17:21:00  time: 0.4073  data_time: 0.0104  memory: 4958  grad_norm: 119.4232  loss: 42.2827  decode.loss_cls: 1.5140  decode.loss_mask: 0.9554  decode.loss_dice: 1.4965  decode.d0.loss_cls: 3.5409  decode.d0.loss_mask: 1.0212  decode.d0.loss_dice: 1.7123  decode.d1.loss_cls: 1.6564  decode.d1.loss_mask: 0.9872  decode.d1.loss_dice: 1.5701  decode.d2.loss_cls: 1.5173  decode.d2.loss_mask: 0.9298  decode.d2.loss_dice: 1.5484  decode.d3.loss_cls: 1.4939  decode.d3.loss_mask: 0.9566  decode.d3.loss_dice: 1.4892  decode.d4.loss_cls: 1.5931  decode.d4.loss_mask: 0.9514  decode.d4.loss_dice: 1.4856  decode.d5.loss_cls: 1.5203  decode.d5.loss_mask: 0.9617  decode.d5.loss_dice: 1.4733  decode.d6.loss_cls: 1.4727  decode.d6.loss_mask: 0.9676  decode.d6.loss_dice: 1.5432  decode.d7.loss_cls: 1.5225  decode.d7.loss_mask: 0.9441  decode.d7.loss_dice: 1.4895  decode.d8.loss_cls: 1.5143  decode.d8.loss_mask: 0.9564  decode.d8.loss_dice: 1.4975
2023/05/23 19:58:19 - mmengine - INFO - Iter(train) [ 13650/160000]  lr: 9.2289e-06  eta: 17:20:37  time: 0.4277  data_time: 0.0097  memory: 4919  grad_norm: 84.1195  loss: 53.8759  decode.loss_cls: 1.8770  decode.loss_mask: 1.1020  decode.loss_dice: 2.1345  decode.d0.loss_cls: 3.9955  decode.d0.loss_mask: 1.1364  decode.d0.loss_dice: 2.3797  decode.d1.loss_cls: 2.0626  decode.d1.loss_mask: 1.1748  decode.d1.loss_dice: 2.3252  decode.d2.loss_cls: 2.0455  decode.d2.loss_mask: 1.1037  decode.d2.loss_dice: 2.2205  decode.d3.loss_cls: 1.8667  decode.d3.loss_mask: 1.0556  decode.d3.loss_dice: 2.0883  decode.d4.loss_cls: 1.9440  decode.d4.loss_mask: 1.0619  decode.d4.loss_dice: 2.1479  decode.d5.loss_cls: 1.7966  decode.d5.loss_mask: 1.0867  decode.d5.loss_dice: 2.1047  decode.d6.loss_cls: 1.8990  decode.d6.loss_mask: 1.0517  decode.d6.loss_dice: 2.0927  decode.d7.loss_cls: 1.8605  decode.d7.loss_mask: 1.1068  decode.d7.loss_dice: 2.1132  decode.d8.loss_cls: 1.8808  decode.d8.loss_mask: 1.0790  decode.d8.loss_dice: 2.0826
2023/05/23 19:58:41 - mmengine - INFO - Iter(train) [ 13700/160000]  lr: 9.2260e-06  eta: 17:20:25  time: 0.4440  data_time: 0.0093  memory: 4802  grad_norm: 103.6373  loss: 38.5622  decode.loss_cls: 1.4842  decode.loss_mask: 0.8795  decode.loss_dice: 1.2529  decode.d0.loss_cls: 3.3216  decode.d0.loss_mask: 0.9721  decode.d0.loss_dice: 1.4088  decode.d1.loss_cls: 1.5521  decode.d1.loss_mask: 0.9113  decode.d1.loss_dice: 1.3297  decode.d2.loss_cls: 1.4541  decode.d2.loss_mask: 0.8660  decode.d2.loss_dice: 1.2719  decode.d3.loss_cls: 1.4041  decode.d3.loss_mask: 0.8629  decode.d3.loss_dice: 1.2616  decode.d4.loss_cls: 1.4936  decode.d4.loss_mask: 0.8532  decode.d4.loss_dice: 1.2969  decode.d5.loss_cls: 1.4910  decode.d5.loss_mask: 0.8647  decode.d5.loss_dice: 1.2640  decode.d6.loss_cls: 1.5324  decode.d6.loss_mask: 0.8936  decode.d6.loss_dice: 1.2597  decode.d7.loss_cls: 1.5631  decode.d7.loss_mask: 0.8537  decode.d7.loss_dice: 1.2619  decode.d8.loss_cls: 1.5854  decode.d8.loss_mask: 0.8672  decode.d8.loss_dice: 1.2491
2023/05/23 19:59:01 - mmengine - INFO - Iter(train) [ 13750/160000]  lr: 9.2232e-06  eta: 17:19:54  time: 0.4155  data_time: 0.0097  memory: 4836  grad_norm: 108.9251  loss: 39.7630  decode.loss_cls: 1.4065  decode.loss_mask: 0.8750  decode.loss_dice: 1.4401  decode.d0.loss_cls: 3.3970  decode.d0.loss_mask: 0.8374  decode.d0.loss_dice: 1.6513  decode.d1.loss_cls: 1.5118  decode.d1.loss_mask: 0.8738  decode.d1.loss_dice: 1.5532  decode.d2.loss_cls: 1.4784  decode.d2.loss_mask: 0.8785  decode.d2.loss_dice: 1.4902  decode.d3.loss_cls: 1.4658  decode.d3.loss_mask: 0.8591  decode.d3.loss_dice: 1.4426  decode.d4.loss_cls: 1.4030  decode.d4.loss_mask: 0.8790  decode.d4.loss_dice: 1.4570  decode.d5.loss_cls: 1.4619  decode.d5.loss_mask: 0.8526  decode.d5.loss_dice: 1.4239  decode.d6.loss_cls: 1.4411  decode.d6.loss_mask: 0.8301  decode.d6.loss_dice: 1.4500  decode.d7.loss_cls: 1.3824  decode.d7.loss_mask: 0.8638  decode.d7.loss_dice: 1.4573  decode.d8.loss_cls: 1.3775  decode.d8.loss_mask: 0.8873  decode.d8.loss_dice: 1.4355
2023/05/23 19:59:24 - mmengine - INFO - Iter(train) [ 13800/160000]  lr: 9.2203e-06  eta: 17:19:43  time: 0.4673  data_time: 0.0097  memory: 4856  grad_norm: 92.5712  loss: 43.6818  decode.loss_cls: 1.6576  decode.loss_mask: 0.9942  decode.loss_dice: 1.4471  decode.d0.loss_cls: 3.7185  decode.d0.loss_mask: 1.0635  decode.d0.loss_dice: 1.7218  decode.d1.loss_cls: 1.7367  decode.d1.loss_mask: 1.0701  decode.d1.loss_dice: 1.5903  decode.d2.loss_cls: 1.6312  decode.d2.loss_mask: 1.0602  decode.d2.loss_dice: 1.4587  decode.d3.loss_cls: 1.6408  decode.d3.loss_mask: 1.0725  decode.d3.loss_dice: 1.4656  decode.d4.loss_cls: 1.5818  decode.d4.loss_mask: 1.0403  decode.d4.loss_dice: 1.4661  decode.d5.loss_cls: 1.5876  decode.d5.loss_mask: 1.0404  decode.d5.loss_dice: 1.4381  decode.d6.loss_cls: 1.5906  decode.d6.loss_mask: 1.0524  decode.d6.loss_dice: 1.4417  decode.d7.loss_cls: 1.6559  decode.d7.loss_mask: 1.0084  decode.d7.loss_dice: 1.4196  decode.d8.loss_cls: 1.6390  decode.d8.loss_mask: 1.0093  decode.d8.loss_dice: 1.3816
2023/05/23 19:59:45 - mmengine - INFO - Iter(train) [ 13850/160000]  lr: 9.2175e-06  eta: 17:19:23  time: 0.3985  data_time: 0.0094  memory: 4860  grad_norm: 112.9512  loss: 34.8723  decode.loss_cls: 1.3773  decode.loss_mask: 0.7876  decode.loss_dice: 1.0419  decode.d0.loss_cls: 3.4270  decode.d0.loss_mask: 0.7896  decode.d0.loss_dice: 1.2151  decode.d1.loss_cls: 1.5177  decode.d1.loss_mask: 0.8032  decode.d1.loss_dice: 1.1939  decode.d2.loss_cls: 1.3560  decode.d2.loss_mask: 0.7814  decode.d2.loss_dice: 1.1192  decode.d3.loss_cls: 1.3263  decode.d3.loss_mask: 0.7930  decode.d3.loss_dice: 1.0909  decode.d4.loss_cls: 1.3462  decode.d4.loss_mask: 0.7851  decode.d4.loss_dice: 1.0665  decode.d5.loss_cls: 1.3679  decode.d5.loss_mask: 0.7827  decode.d5.loss_dice: 1.1070  decode.d6.loss_cls: 1.3812  decode.d6.loss_mask: 0.7923  decode.d6.loss_dice: 1.0922  decode.d7.loss_cls: 1.4031  decode.d7.loss_mask: 0.7858  decode.d7.loss_dice: 1.0887  decode.d8.loss_cls: 1.4037  decode.d8.loss_mask: 0.7685  decode.d8.loss_dice: 1.0812
2023/05/23 20:00:06 - mmengine - INFO - Iter(train) [ 13900/160000]  lr: 9.2147e-06  eta: 17:18:53  time: 0.4025  data_time: 0.0095  memory: 4872  grad_norm: 130.0810  loss: 45.8365  decode.loss_cls: 1.6236  decode.loss_mask: 1.0207  decode.loss_dice: 1.5434  decode.d0.loss_cls: 3.4138  decode.d0.loss_mask: 1.2041  decode.d0.loss_dice: 1.7944  decode.d1.loss_cls: 1.8119  decode.d1.loss_mask: 1.1547  decode.d1.loss_dice: 1.7571  decode.d2.loss_cls: 1.7214  decode.d2.loss_mask: 1.1328  decode.d2.loss_dice: 1.6525  decode.d3.loss_cls: 1.6869  decode.d3.loss_mask: 1.0609  decode.d3.loss_dice: 1.6048  decode.d4.loss_cls: 1.6606  decode.d4.loss_mask: 1.0640  decode.d4.loss_dice: 1.5906  decode.d5.loss_cls: 1.6996  decode.d5.loss_mask: 1.0566  decode.d5.loss_dice: 1.6080  decode.d6.loss_cls: 1.6845  decode.d6.loss_mask: 1.0731  decode.d6.loss_dice: 1.5938  decode.d7.loss_cls: 1.6783  decode.d7.loss_mask: 1.0584  decode.d7.loss_dice: 1.6069  decode.d8.loss_cls: 1.6670  decode.d8.loss_mask: 1.0210  decode.d8.loss_dice: 1.5910
2023/05/23 20:00:26 - mmengine - INFO - Iter(train) [ 13950/160000]  lr: 9.2118e-06  eta: 17:18:21  time: 0.4053  data_time: 0.0097  memory: 4874  grad_norm: 104.4593  loss: 41.2452  decode.loss_cls: 1.5311  decode.loss_mask: 0.8060  decode.loss_dice: 1.5643  decode.d0.loss_cls: 3.3949  decode.d0.loss_mask: 0.9257  decode.d0.loss_dice: 1.7246  decode.d1.loss_cls: 1.6995  decode.d1.loss_mask: 0.9025  decode.d1.loss_dice: 1.6709  decode.d2.loss_cls: 1.5578  decode.d2.loss_mask: 0.8324  decode.d2.loss_dice: 1.5554  decode.d3.loss_cls: 1.6234  decode.d3.loss_mask: 0.7958  decode.d3.loss_dice: 1.4588  decode.d4.loss_cls: 1.5374  decode.d4.loss_mask: 0.8185  decode.d4.loss_dice: 1.4944  decode.d5.loss_cls: 1.5225  decode.d5.loss_mask: 0.8031  decode.d5.loss_dice: 1.4793  decode.d6.loss_cls: 1.4492  decode.d6.loss_mask: 0.8034  decode.d6.loss_dice: 1.5408  decode.d7.loss_cls: 1.4949  decode.d7.loss_mask: 0.8153  decode.d7.loss_dice: 1.5744  decode.d8.loss_cls: 1.4922  decode.d8.loss_mask: 0.8139  decode.d8.loss_dice: 1.5627
2023/05/23 20:00:47 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:00:47 - mmengine - INFO - Iter(train) [ 14000/160000]  lr: 9.2090e-06  eta: 17:17:52  time: 0.4087  data_time: 0.0095  memory: 4847  grad_norm: 119.0468  loss: 39.8131  decode.loss_cls: 1.5597  decode.loss_mask: 0.7752  decode.loss_dice: 1.4119  decode.d0.loss_cls: 3.4057  decode.d0.loss_mask: 0.7971  decode.d0.loss_dice: 1.5291  decode.d1.loss_cls: 1.6809  decode.d1.loss_mask: 0.7734  decode.d1.loss_dice: 1.4276  decode.d2.loss_cls: 1.6057  decode.d2.loss_mask: 0.7930  decode.d2.loss_dice: 1.4147  decode.d3.loss_cls: 1.6084  decode.d3.loss_mask: 0.7762  decode.d3.loss_dice: 1.3578  decode.d4.loss_cls: 1.5931  decode.d4.loss_mask: 0.7977  decode.d4.loss_dice: 1.4233  decode.d5.loss_cls: 1.6402  decode.d5.loss_mask: 0.7894  decode.d5.loss_dice: 1.4144  decode.d6.loss_cls: 1.6193  decode.d6.loss_mask: 0.7697  decode.d6.loss_dice: 1.3579  decode.d7.loss_cls: 1.5970  decode.d7.loss_mask: 0.7842  decode.d7.loss_dice: 1.3861  decode.d8.loss_cls: 1.5641  decode.d8.loss_mask: 0.7744  decode.d8.loss_dice: 1.3861
2023/05/23 20:00:47 - mmengine - INFO - Saving checkpoint at 14000 iterations
2023/05/23 20:01:13 - mmengine - INFO - Iter(train) [ 14050/160000]  lr: 9.2062e-06  eta: 17:18:18  time: 0.4069  data_time: 0.0091  memory: 4869  grad_norm: 97.1811  loss: 43.3711  decode.loss_cls: 1.5814  decode.loss_mask: 0.9963  decode.loss_dice: 1.4808  decode.d0.loss_cls: 3.5623  decode.d0.loss_mask: 1.0756  decode.d0.loss_dice: 1.7694  decode.d1.loss_cls: 1.7139  decode.d1.loss_mask: 1.0189  decode.d1.loss_dice: 1.6056  decode.d2.loss_cls: 1.5368  decode.d2.loss_mask: 1.0248  decode.d2.loss_dice: 1.5579  decode.d3.loss_cls: 1.5721  decode.d3.loss_mask: 0.9870  decode.d3.loss_dice: 1.4966  decode.d4.loss_cls: 1.6095  decode.d4.loss_mask: 0.9943  decode.d4.loss_dice: 1.4943  decode.d5.loss_cls: 1.5676  decode.d5.loss_mask: 1.0194  decode.d5.loss_dice: 1.5021  decode.d6.loss_cls: 1.5894  decode.d6.loss_mask: 1.0121  decode.d6.loss_dice: 1.4613  decode.d7.loss_cls: 1.6324  decode.d7.loss_mask: 1.0180  decode.d7.loss_dice: 1.4880  decode.d8.loss_cls: 1.5695  decode.d8.loss_mask: 0.9606  decode.d8.loss_dice: 1.4733
2023/05/23 20:01:33 - mmengine - INFO - Iter(train) [ 14100/160000]  lr: 9.2033e-06  eta: 17:17:48  time: 0.4132  data_time: 0.0096  memory: 4837  grad_norm: 129.5376  loss: 36.4003  decode.loss_cls: 1.3825  decode.loss_mask: 0.8055  decode.loss_dice: 1.2694  decode.d0.loss_cls: 3.0963  decode.d0.loss_mask: 0.7556  decode.d0.loss_dice: 1.3930  decode.d1.loss_cls: 1.5747  decode.d1.loss_mask: 0.7846  decode.d1.loss_dice: 1.2750  decode.d2.loss_cls: 1.4080  decode.d2.loss_mask: 0.7792  decode.d2.loss_dice: 1.2951  decode.d3.loss_cls: 1.4552  decode.d3.loss_mask: 0.7644  decode.d3.loss_dice: 1.2793  decode.d4.loss_cls: 1.4117  decode.d4.loss_mask: 0.7782  decode.d4.loss_dice: 1.2809  decode.d5.loss_cls: 1.3200  decode.d5.loss_mask: 0.7710  decode.d5.loss_dice: 1.2905  decode.d6.loss_cls: 1.3935  decode.d6.loss_mask: 0.7514  decode.d6.loss_dice: 1.2692  decode.d7.loss_cls: 1.3435  decode.d7.loss_mask: 0.7697  decode.d7.loss_dice: 1.2959  decode.d8.loss_cls: 1.3340  decode.d8.loss_mask: 0.7972  decode.d8.loss_dice: 1.2759
2023/05/23 20:01:54 - mmengine - INFO - Iter(train) [ 14150/160000]  lr: 9.2005e-06  eta: 17:17:18  time: 0.4040  data_time: 0.0097  memory: 4888  grad_norm: 91.0133  loss: 44.0710  decode.loss_cls: 1.7014  decode.loss_mask: 1.0192  decode.loss_dice: 1.4533  decode.d0.loss_cls: 3.5557  decode.d0.loss_mask: 1.1527  decode.d0.loss_dice: 1.6549  decode.d1.loss_cls: 1.6809  decode.d1.loss_mask: 1.0236  decode.d1.loss_dice: 1.4937  decode.d2.loss_cls: 1.7558  decode.d2.loss_mask: 0.9810  decode.d2.loss_dice: 1.4283  decode.d3.loss_cls: 1.6628  decode.d3.loss_mask: 1.0448  decode.d3.loss_dice: 1.4966  decode.d4.loss_cls: 1.7147  decode.d4.loss_mask: 1.0870  decode.d4.loss_dice: 1.4770  decode.d5.loss_cls: 1.6869  decode.d5.loss_mask: 1.0468  decode.d5.loss_dice: 1.4527  decode.d6.loss_cls: 1.6925  decode.d6.loss_mask: 1.0532  decode.d6.loss_dice: 1.4578  decode.d7.loss_cls: 1.6318  decode.d7.loss_mask: 1.0532  decode.d7.loss_dice: 1.4707  decode.d8.loss_cls: 1.6534  decode.d8.loss_mask: 1.0131  decode.d8.loss_dice: 1.4754
2023/05/23 20:02:14 - mmengine - INFO - Iter(train) [ 14200/160000]  lr: 9.1976e-06  eta: 17:16:47  time: 0.4140  data_time: 0.0094  memory: 4841  grad_norm: 85.5199  loss: 38.8283  decode.loss_cls: 1.5375  decode.loss_mask: 0.7286  decode.loss_dice: 1.3278  decode.d0.loss_cls: 3.5702  decode.d0.loss_mask: 0.8177  decode.d0.loss_dice: 1.4473  decode.d1.loss_cls: 1.5912  decode.d1.loss_mask: 0.7561  decode.d1.loss_dice: 1.4113  decode.d2.loss_cls: 1.5430  decode.d2.loss_mask: 0.7331  decode.d2.loss_dice: 1.3684  decode.d3.loss_cls: 1.5583  decode.d3.loss_mask: 0.8011  decode.d3.loss_dice: 1.3855  decode.d4.loss_cls: 1.4603  decode.d4.loss_mask: 0.8235  decode.d4.loss_dice: 1.3868  decode.d5.loss_cls: 1.5007  decode.d5.loss_mask: 0.7717  decode.d5.loss_dice: 1.3894  decode.d6.loss_cls: 1.4704  decode.d6.loss_mask: 0.8068  decode.d6.loss_dice: 1.3694  decode.d7.loss_cls: 1.5360  decode.d7.loss_mask: 0.7710  decode.d7.loss_dice: 1.3405  decode.d8.loss_cls: 1.5421  decode.d8.loss_mask: 0.7390  decode.d8.loss_dice: 1.3434
2023/05/23 20:02:37 - mmengine - INFO - Iter(train) [ 14250/160000]  lr: 9.1948e-06  eta: 17:16:46  time: 0.4650  data_time: 0.0091  memory: 4875  grad_norm: 115.2130  loss: 39.7428  decode.loss_cls: 1.5323  decode.loss_mask: 0.6677  decode.loss_dice: 1.5308  decode.d0.loss_cls: 3.3935  decode.d0.loss_mask: 0.7344  decode.d0.loss_dice: 1.7412  decode.d1.loss_cls: 1.6546  decode.d1.loss_mask: 0.7099  decode.d1.loss_dice: 1.6542  decode.d2.loss_cls: 1.4743  decode.d2.loss_mask: 0.7351  decode.d2.loss_dice: 1.5367  decode.d3.loss_cls: 1.4771  decode.d3.loss_mask: 0.7162  decode.d3.loss_dice: 1.5411  decode.d4.loss_cls: 1.5297  decode.d4.loss_mask: 0.6943  decode.d4.loss_dice: 1.5035  decode.d5.loss_cls: 1.5141  decode.d5.loss_mask: 0.6845  decode.d5.loss_dice: 1.5206  decode.d6.loss_cls: 1.5071  decode.d6.loss_mask: 0.6838  decode.d6.loss_dice: 1.5001  decode.d7.loss_cls: 1.5269  decode.d7.loss_mask: 0.7072  decode.d7.loss_dice: 1.5019  decode.d8.loss_cls: 1.5675  decode.d8.loss_mask: 0.6971  decode.d8.loss_dice: 1.5055
2023/05/23 20:03:01 - mmengine - INFO - Iter(train) [ 14300/160000]  lr: 9.1920e-06  eta: 17:16:45  time: 0.4653  data_time: 0.0096  memory: 4923  grad_norm: 97.1069  loss: 35.3126  decode.loss_cls: 1.3020  decode.loss_mask: 0.8301  decode.loss_dice: 1.1065  decode.d0.loss_cls: 3.3895  decode.d0.loss_mask: 0.8544  decode.d0.loss_dice: 1.3615  decode.d1.loss_cls: 1.5263  decode.d1.loss_mask: 0.8485  decode.d1.loss_dice: 1.2124  decode.d2.loss_cls: 1.3731  decode.d2.loss_mask: 0.8084  decode.d2.loss_dice: 1.1920  decode.d3.loss_cls: 1.3669  decode.d3.loss_mask: 0.7871  decode.d3.loss_dice: 1.1082  decode.d4.loss_cls: 1.3250  decode.d4.loss_mask: 0.7894  decode.d4.loss_dice: 1.1264  decode.d5.loss_cls: 1.3354  decode.d5.loss_mask: 0.7855  decode.d5.loss_dice: 1.1207  decode.d6.loss_cls: 1.3461  decode.d6.loss_mask: 0.8298  decode.d6.loss_dice: 1.1135  decode.d7.loss_cls: 1.2622  decode.d7.loss_mask: 0.8284  decode.d7.loss_dice: 1.1451  decode.d8.loss_cls: 1.3239  decode.d8.loss_mask: 0.7912  decode.d8.loss_dice: 1.1230
2023/05/23 20:03:23 - mmengine - INFO - Iter(train) [ 14350/160000]  lr: 9.1891e-06  eta: 17:16:33  time: 0.4098  data_time: 0.0096  memory: 4918  grad_norm: 84.0100  loss: 34.9798  decode.loss_cls: 1.4074  decode.loss_mask: 0.6234  decode.loss_dice: 1.2217  decode.d0.loss_cls: 3.3648  decode.d0.loss_mask: 0.6422  decode.d0.loss_dice: 1.3900  decode.d1.loss_cls: 1.6113  decode.d1.loss_mask: 0.6007  decode.d1.loss_dice: 1.3257  decode.d2.loss_cls: 1.4692  decode.d2.loss_mask: 0.5687  decode.d2.loss_dice: 1.2693  decode.d3.loss_cls: 1.4303  decode.d3.loss_mask: 0.5936  decode.d3.loss_dice: 1.2226  decode.d4.loss_cls: 1.4221  decode.d4.loss_mask: 0.5886  decode.d4.loss_dice: 1.2185  decode.d5.loss_cls: 1.4470  decode.d5.loss_mask: 0.5784  decode.d5.loss_dice: 1.2046  decode.d6.loss_cls: 1.4185  decode.d6.loss_mask: 0.5973  decode.d6.loss_dice: 1.2365  decode.d7.loss_cls: 1.4733  decode.d7.loss_mask: 0.5959  decode.d7.loss_dice: 1.2213  decode.d8.loss_cls: 1.4469  decode.d8.loss_mask: 0.5878  decode.d8.loss_dice: 1.2020
2023/05/23 20:03:44 - mmengine - INFO - Iter(train) [ 14400/160000]  lr: 9.1863e-06  eta: 17:16:05  time: 0.4068  data_time: 0.0090  memory: 4857  grad_norm: 94.9106  loss: 39.6920  decode.loss_cls: 1.4809  decode.loss_mask: 0.8145  decode.loss_dice: 1.4740  decode.d0.loss_cls: 3.4144  decode.d0.loss_mask: 0.8133  decode.d0.loss_dice: 1.5721  decode.d1.loss_cls: 1.6083  decode.d1.loss_mask: 0.8235  decode.d1.loss_dice: 1.5306  decode.d2.loss_cls: 1.5233  decode.d2.loss_mask: 0.8102  decode.d2.loss_dice: 1.4559  decode.d3.loss_cls: 1.5540  decode.d3.loss_mask: 0.7619  decode.d3.loss_dice: 1.4330  decode.d4.loss_cls: 1.5765  decode.d4.loss_mask: 0.7606  decode.d4.loss_dice: 1.4047  decode.d5.loss_cls: 1.5331  decode.d5.loss_mask: 0.7513  decode.d5.loss_dice: 1.3904  decode.d6.loss_cls: 1.5659  decode.d6.loss_mask: 0.7637  decode.d6.loss_dice: 1.4252  decode.d7.loss_cls: 1.5103  decode.d7.loss_mask: 0.7794  decode.d7.loss_dice: 1.4157  decode.d8.loss_cls: 1.5117  decode.d8.loss_mask: 0.8159  decode.d8.loss_dice: 1.4180
2023/05/23 20:04:04 - mmengine - INFO - Iter(train) [ 14450/160000]  lr: 9.1834e-06  eta: 17:15:32  time: 0.4070  data_time: 0.0096  memory: 4835  grad_norm: 91.3696  loss: 44.2636  decode.loss_cls: 1.7544  decode.loss_mask: 0.8107  decode.loss_dice: 1.5838  decode.d0.loss_cls: 3.5777  decode.d0.loss_mask: 0.8491  decode.d0.loss_dice: 1.8525  decode.d1.loss_cls: 1.9561  decode.d1.loss_mask: 0.8033  decode.d1.loss_dice: 1.7632  decode.d2.loss_cls: 1.8204  decode.d2.loss_mask: 0.8101  decode.d2.loss_dice: 1.6848  decode.d3.loss_cls: 1.7888  decode.d3.loss_mask: 0.8107  decode.d3.loss_dice: 1.6065  decode.d4.loss_cls: 1.7454  decode.d4.loss_mask: 0.7972  decode.d4.loss_dice: 1.6064  decode.d5.loss_cls: 1.8131  decode.d5.loss_mask: 0.8018  decode.d5.loss_dice: 1.6123  decode.d6.loss_cls: 1.8073  decode.d6.loss_mask: 0.7675  decode.d6.loss_dice: 1.5658  decode.d7.loss_cls: 1.7336  decode.d7.loss_mask: 0.7865  decode.d7.loss_dice: 1.6118  decode.d8.loss_cls: 1.7110  decode.d8.loss_mask: 0.8144  decode.d8.loss_dice: 1.6171
2023/05/23 20:04:24 - mmengine - INFO - Iter(train) [ 14500/160000]  lr: 9.1806e-06  eta: 17:15:01  time: 0.4090  data_time: 0.0096  memory: 4876  grad_norm: 98.7213  loss: 38.0108  decode.loss_cls: 1.5284  decode.loss_mask: 0.7787  decode.loss_dice: 1.2353  decode.d0.loss_cls: 3.3445  decode.d0.loss_mask: 0.8759  decode.d0.loss_dice: 1.5015  decode.d1.loss_cls: 1.6231  decode.d1.loss_mask: 0.7837  decode.d1.loss_dice: 1.3519  decode.d2.loss_cls: 1.5495  decode.d2.loss_mask: 0.7513  decode.d2.loss_dice: 1.2593  decode.d3.loss_cls: 1.5956  decode.d3.loss_mask: 0.7532  decode.d3.loss_dice: 1.2931  decode.d4.loss_cls: 1.5645  decode.d4.loss_mask: 0.7555  decode.d4.loss_dice: 1.2962  decode.d5.loss_cls: 1.5069  decode.d5.loss_mask: 0.7479  decode.d5.loss_dice: 1.2598  decode.d6.loss_cls: 1.5483  decode.d6.loss_mask: 0.7563  decode.d6.loss_dice: 1.2658  decode.d7.loss_cls: 1.5677  decode.d7.loss_mask: 0.7494  decode.d7.loss_dice: 1.2281  decode.d8.loss_cls: 1.5437  decode.d8.loss_mask: 0.7732  decode.d8.loss_dice: 1.2226
2023/05/23 20:04:45 - mmengine - INFO - Iter(train) [ 14550/160000]  lr: 9.1778e-06  eta: 17:14:32  time: 0.4052  data_time: 0.0098  memory: 4868  grad_norm: 89.8390  loss: 42.3303  decode.loss_cls: 1.7253  decode.loss_mask: 0.8232  decode.loss_dice: 1.4332  decode.d0.loss_cls: 3.3652  decode.d0.loss_mask: 0.9359  decode.d0.loss_dice: 1.7203  decode.d1.loss_cls: 1.7578  decode.d1.loss_mask: 0.8885  decode.d1.loss_dice: 1.5994  decode.d2.loss_cls: 1.8132  decode.d2.loss_mask: 0.8394  decode.d2.loss_dice: 1.4440  decode.d3.loss_cls: 1.6495  decode.d3.loss_mask: 0.8389  decode.d3.loss_dice: 1.4261  decode.d4.loss_cls: 1.7893  decode.d4.loss_mask: 0.8245  decode.d4.loss_dice: 1.4389  decode.d5.loss_cls: 1.8151  decode.d5.loss_mask: 0.8026  decode.d5.loss_dice: 1.4024  decode.d6.loss_cls: 1.7702  decode.d6.loss_mask: 0.8178  decode.d6.loss_dice: 1.4174  decode.d7.loss_cls: 1.7721  decode.d7.loss_mask: 0.8332  decode.d7.loss_dice: 1.4194  decode.d8.loss_cls: 1.7081  decode.d8.loss_mask: 0.8515  decode.d8.loss_dice: 1.4082
2023/05/23 20:05:06 - mmengine - INFO - Iter(train) [ 14600/160000]  lr: 9.1749e-06  eta: 17:14:05  time: 0.4097  data_time: 0.0096  memory: 4781  grad_norm: 114.2985  loss: 44.6658  decode.loss_cls: 1.6720  decode.loss_mask: 0.9291  decode.loss_dice: 1.5710  decode.d0.loss_cls: 3.4718  decode.d0.loss_mask: 0.9793  decode.d0.loss_dice: 1.8272  decode.d1.loss_cls: 1.7271  decode.d1.loss_mask: 0.9511  decode.d1.loss_dice: 1.7018  decode.d2.loss_cls: 1.6995  decode.d2.loss_mask: 0.9453  decode.d2.loss_dice: 1.6485  decode.d3.loss_cls: 1.6804  decode.d3.loss_mask: 0.8910  decode.d3.loss_dice: 1.6165  decode.d4.loss_cls: 1.6506  decode.d4.loss_mask: 0.9245  decode.d4.loss_dice: 1.6336  decode.d5.loss_cls: 1.6168  decode.d5.loss_mask: 0.9859  decode.d5.loss_dice: 1.6994  decode.d6.loss_cls: 1.6693  decode.d6.loss_mask: 0.9249  decode.d6.loss_dice: 1.6504  decode.d7.loss_cls: 1.6887  decode.d7.loss_mask: 0.9488  decode.d7.loss_dice: 1.6498  decode.d8.loss_cls: 1.7503  decode.d8.loss_mask: 0.9499  decode.d8.loss_dice: 1.6116
2023/05/23 20:05:27 - mmengine - INFO - Iter(train) [ 14650/160000]  lr: 9.1721e-06  eta: 17:13:42  time: 0.4544  data_time: 0.0098  memory: 4858  grad_norm: 113.6063  loss: 44.0713  decode.loss_cls: 1.6316  decode.loss_mask: 1.1117  decode.loss_dice: 1.4960  decode.d0.loss_cls: 3.4983  decode.d0.loss_mask: 1.1064  decode.d0.loss_dice: 1.6313  decode.d1.loss_cls: 1.7021  decode.d1.loss_mask: 1.0834  decode.d1.loss_dice: 1.6193  decode.d2.loss_cls: 1.6308  decode.d2.loss_mask: 1.0939  decode.d2.loss_dice: 1.5518  decode.d3.loss_cls: 1.5765  decode.d3.loss_mask: 1.0707  decode.d3.loss_dice: 1.4636  decode.d4.loss_cls: 1.5636  decode.d4.loss_mask: 1.0746  decode.d4.loss_dice: 1.4875  decode.d5.loss_cls: 1.5741  decode.d5.loss_mask: 1.0828  decode.d5.loss_dice: 1.4878  decode.d6.loss_cls: 1.6124  decode.d6.loss_mask: 1.0995  decode.d6.loss_dice: 1.4691  decode.d7.loss_cls: 1.5736  decode.d7.loss_mask: 1.0969  decode.d7.loss_dice: 1.4764  decode.d8.loss_cls: 1.6075  decode.d8.loss_mask: 1.1114  decode.d8.loss_dice: 1.4869
2023/05/23 20:05:50 - mmengine - INFO - Iter(train) [ 14700/160000]  lr: 9.1692e-06  eta: 17:13:40  time: 0.4648  data_time: 0.0096  memory: 4929  grad_norm: 103.0839  loss: 28.2703  decode.loss_cls: 1.1570  decode.loss_mask: 0.5849  decode.loss_dice: 0.8416  decode.d0.loss_cls: 2.8138  decode.d0.loss_mask: 0.6620  decode.d0.loss_dice: 1.0015  decode.d1.loss_cls: 1.3500  decode.d1.loss_mask: 0.6295  decode.d1.loss_dice: 0.9217  decode.d2.loss_cls: 1.2143  decode.d2.loss_mask: 0.6505  decode.d2.loss_dice: 0.9057  decode.d3.loss_cls: 1.1211  decode.d3.loss_mask: 0.6484  decode.d3.loss_dice: 0.9112  decode.d4.loss_cls: 1.1296  decode.d4.loss_mask: 0.6101  decode.d4.loss_dice: 0.8819  decode.d5.loss_cls: 1.1072  decode.d5.loss_mask: 0.6085  decode.d5.loss_dice: 0.8875  decode.d6.loss_cls: 1.1033  decode.d6.loss_mask: 0.5782  decode.d6.loss_dice: 0.8504  decode.d7.loss_cls: 1.0954  decode.d7.loss_mask: 0.5834  decode.d7.loss_dice: 0.8781  decode.d8.loss_cls: 1.1221  decode.d8.loss_mask: 0.5872  decode.d8.loss_dice: 0.8342
2023/05/23 20:06:11 - mmengine - INFO - Iter(train) [ 14750/160000]  lr: 9.1664e-06  eta: 17:13:14  time: 0.4124  data_time: 0.0098  memory: 4829  grad_norm: 121.7862  loss: 39.8863  decode.loss_cls: 1.5163  decode.loss_mask: 0.7820  decode.loss_dice: 1.3762  decode.d0.loss_cls: 3.0154  decode.d0.loss_mask: 0.8461  decode.d0.loss_dice: 1.5846  decode.d1.loss_cls: 1.6685  decode.d1.loss_mask: 0.8679  decode.d1.loss_dice: 1.5275  decode.d2.loss_cls: 1.6382  decode.d2.loss_mask: 0.8056  decode.d2.loss_dice: 1.4419  decode.d3.loss_cls: 1.6450  decode.d3.loss_mask: 0.7989  decode.d3.loss_dice: 1.3945  decode.d4.loss_cls: 1.6168  decode.d4.loss_mask: 0.7873  decode.d4.loss_dice: 1.4012  decode.d5.loss_cls: 1.5586  decode.d5.loss_mask: 0.7674  decode.d5.loss_dice: 1.4260  decode.d6.loss_cls: 1.6075  decode.d6.loss_mask: 0.7952  decode.d6.loss_dice: 1.4193  decode.d7.loss_cls: 1.5693  decode.d7.loss_mask: 0.7980  decode.d7.loss_dice: 1.4253  decode.d8.loss_cls: 1.5913  decode.d8.loss_mask: 0.8029  decode.d8.loss_dice: 1.4115
2023/05/23 20:06:32 - mmengine - INFO - Iter(train) [ 14800/160000]  lr: 9.1636e-06  eta: 17:12:48  time: 0.4204  data_time: 0.0098  memory: 4952  grad_norm: 92.5998  loss: 32.3129  decode.loss_cls: 1.3300  decode.loss_mask: 0.6496  decode.loss_dice: 0.9978  decode.d0.loss_cls: 3.1819  decode.d0.loss_mask: 0.6856  decode.d0.loss_dice: 1.1570  decode.d1.loss_cls: 1.4894  decode.d1.loss_mask: 0.7089  decode.d1.loss_dice: 1.1232  decode.d2.loss_cls: 1.4215  decode.d2.loss_mask: 0.6532  decode.d2.loss_dice: 1.0302  decode.d3.loss_cls: 1.3431  decode.d3.loss_mask: 0.6384  decode.d3.loss_dice: 1.0327  decode.d4.loss_cls: 1.3260  decode.d4.loss_mask: 0.6446  decode.d4.loss_dice: 1.0221  decode.d5.loss_cls: 1.3056  decode.d5.loss_mask: 0.6592  decode.d5.loss_dice: 1.0540  decode.d6.loss_cls: 1.3483  decode.d6.loss_mask: 0.6342  decode.d6.loss_dice: 1.0218  decode.d7.loss_cls: 1.3240  decode.d7.loss_mask: 0.6282  decode.d7.loss_dice: 1.0039  decode.d8.loss_cls: 1.2336  decode.d8.loss_mask: 0.6439  decode.d8.loss_dice: 1.0209
2023/05/23 20:06:54 - mmengine - INFO - Iter(train) [ 14850/160000]  lr: 9.1607e-06  eta: 17:12:39  time: 0.4669  data_time: 0.0094  memory: 4857  grad_norm: 123.6817  loss: 42.3946  decode.loss_cls: 1.4663  decode.loss_mask: 0.7983  decode.loss_dice: 1.6035  decode.d0.loss_cls: 3.6230  decode.d0.loss_mask: 0.9407  decode.d0.loss_dice: 1.8449  decode.d1.loss_cls: 1.6973  decode.d1.loss_mask: 0.8760  decode.d1.loss_dice: 1.7617  decode.d2.loss_cls: 1.5389  decode.d2.loss_mask: 0.8278  decode.d2.loss_dice: 1.6805  decode.d3.loss_cls: 1.5523  decode.d3.loss_mask: 0.8373  decode.d3.loss_dice: 1.6359  decode.d4.loss_cls: 1.5283  decode.d4.loss_mask: 0.8395  decode.d4.loss_dice: 1.6416  decode.d5.loss_cls: 1.5331  decode.d5.loss_mask: 0.8298  decode.d5.loss_dice: 1.6408  decode.d6.loss_cls: 1.4615  decode.d6.loss_mask: 0.8136  decode.d6.loss_dice: 1.6438  decode.d7.loss_cls: 1.4793  decode.d7.loss_mask: 0.8078  decode.d7.loss_dice: 1.6134  decode.d8.loss_cls: 1.4168  decode.d8.loss_mask: 0.8191  decode.d8.loss_dice: 1.6418
2023/05/23 20:07:16 - mmengine - INFO - Iter(train) [ 14900/160000]  lr: 9.1579e-06  eta: 17:12:19  time: 0.4120  data_time: 0.0097  memory: 4889  grad_norm: 101.4614  loss: 44.3321  decode.loss_cls: 1.8327  decode.loss_mask: 0.9535  decode.loss_dice: 1.3511  decode.d0.loss_cls: 3.6219  decode.d0.loss_mask: 1.0526  decode.d0.loss_dice: 1.5793  decode.d1.loss_cls: 1.9364  decode.d1.loss_mask: 1.0552  decode.d1.loss_dice: 1.5562  decode.d2.loss_cls: 1.9030  decode.d2.loss_mask: 0.9899  decode.d2.loss_dice: 1.4093  decode.d3.loss_cls: 1.8131  decode.d3.loss_mask: 0.9875  decode.d3.loss_dice: 1.3926  decode.d4.loss_cls: 1.8500  decode.d4.loss_mask: 0.9841  decode.d4.loss_dice: 1.3852  decode.d5.loss_cls: 1.7979  decode.d5.loss_mask: 0.9614  decode.d5.loss_dice: 1.3834  decode.d6.loss_cls: 1.8159  decode.d6.loss_mask: 0.9967  decode.d6.loss_dice: 1.3856  decode.d7.loss_cls: 1.8251  decode.d7.loss_mask: 0.9776  decode.d7.loss_dice: 1.3780  decode.d8.loss_cls: 1.7914  decode.d8.loss_mask: 0.9707  decode.d8.loss_dice: 1.3947
2023/05/23 20:07:37 - mmengine - INFO - Iter(train) [ 14950/160000]  lr: 9.1550e-06  eta: 17:11:53  time: 0.4209  data_time: 0.0094  memory: 4856  grad_norm: 119.6566  loss: 46.6814  decode.loss_cls: 1.8086  decode.loss_mask: 0.9575  decode.loss_dice: 1.6639  decode.d0.loss_cls: 3.5189  decode.d0.loss_mask: 0.9130  decode.d0.loss_dice: 1.8488  decode.d1.loss_cls: 1.8906  decode.d1.loss_mask: 0.9323  decode.d1.loss_dice: 1.8051  decode.d2.loss_cls: 1.8561  decode.d2.loss_mask: 0.9123  decode.d2.loss_dice: 1.7476  decode.d3.loss_cls: 1.8819  decode.d3.loss_mask: 0.9038  decode.d3.loss_dice: 1.6726  decode.d4.loss_cls: 1.8491  decode.d4.loss_mask: 0.9311  decode.d4.loss_dice: 1.7342  decode.d5.loss_cls: 1.8283  decode.d5.loss_mask: 0.9344  decode.d5.loss_dice: 1.7005  decode.d6.loss_cls: 1.8394  decode.d6.loss_mask: 0.9655  decode.d6.loss_dice: 1.6944  decode.d7.loss_cls: 1.8018  decode.d7.loss_mask: 0.9621  decode.d7.loss_dice: 1.6889  decode.d8.loss_cls: 1.7865  decode.d8.loss_mask: 0.9679  decode.d8.loss_dice: 1.6843
2023/05/23 20:07:57 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:07:57 - mmengine - INFO - Iter(train) [ 15000/160000]  lr: 9.1522e-06  eta: 17:11:25  time: 0.4078  data_time: 0.0097  memory: 4885  grad_norm: 289.0913  loss: 27.0580  decode.loss_cls: 1.1571  decode.loss_mask: 0.5323  decode.loss_dice: 0.7704  decode.d0.loss_cls: 2.9464  decode.d0.loss_mask: 0.6309  decode.d0.loss_dice: 0.8926  decode.d1.loss_cls: 1.3020  decode.d1.loss_mask: 0.5620  decode.d1.loss_dice: 0.8615  decode.d2.loss_cls: 1.1915  decode.d2.loss_mask: 0.5457  decode.d2.loss_dice: 0.7954  decode.d3.loss_cls: 1.1726  decode.d3.loss_mask: 0.5296  decode.d3.loss_dice: 0.7720  decode.d4.loss_cls: 1.1611  decode.d4.loss_mask: 0.5180  decode.d4.loss_dice: 0.7787  decode.d5.loss_cls: 1.2036  decode.d5.loss_mask: 0.5288  decode.d5.loss_dice: 0.7705  decode.d6.loss_cls: 1.2230  decode.d6.loss_mask: 0.5156  decode.d6.loss_dice: 0.7497  decode.d7.loss_cls: 1.2093  decode.d7.loss_mask: 0.5206  decode.d7.loss_dice: 0.7661  decode.d8.loss_cls: 1.2201  decode.d8.loss_mask: 0.5012  decode.d8.loss_dice: 0.7298
2023/05/23 20:07:57 - mmengine - INFO - Saving checkpoint at 15000 iterations
2023/05/23 20:08:09 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:01:14  time: 0.3059  data_time: 0.0023  memory: 2167  
2023/05/23 20:08:13 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:55  time: 0.0784  data_time: 0.0018  memory: 2216  
2023/05/23 20:08:18 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:46  time: 0.0931  data_time: 0.0020  memory: 2167  
2023/05/23 20:08:22 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:39  time: 0.0805  data_time: 0.0021  memory: 2104  
2023/05/23 20:08:26 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:34  time: 0.0823  data_time: 0.0020  memory: 2831  
2023/05/23 20:08:30 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0791  data_time: 0.0018  memory: 2167  
2023/05/23 20:08:34 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0796  data_time: 0.0018  memory: 2167  
2023/05/23 20:08:38 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0918  data_time: 0.0020  memory: 2167  
2023/05/23 20:08:42 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0787  data_time: 0.0018  memory: 2944  
2023/05/23 20:08:46 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0847  data_time: 0.0019  memory: 2356  
2023/05/23 20:08:51 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0874  data_time: 0.0020  memory: 2217  
2023/05/23 20:08:55 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0777  data_time: 0.0018  memory: 2328  
2023/05/23 20:08:59 - mmengine - INFO - per class results:
2023/05/23 20:08:59 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 83.64 | 92.11 |
|     bicycle      | 60.47 |  71.9 |
|       car        | 54.21 | 71.87 |
|    motorcycle    | 78.94 | 90.69 |
|     airplane     | 79.14 | 88.22 |
|       bus        | 78.56 | 89.41 |
|      train       | 78.62 | 88.72 |
|      truck       | 49.66 | 66.99 |
|       boat       | 49.03 |  74.5 |
|  traffic light   | 54.79 | 87.93 |
|   fire hydrant   | 67.44 | 92.79 |
|    stop sign     | 75.64 | 96.49 |
|  parking meter   | 72.11 | 77.67 |
|      bench       | 39.71 | 66.67 |
|       bird       | 75.13 | 87.77 |
|       cat        | 84.57 | 94.45 |
|       dog        | 75.47 | 85.06 |
|      horse       |  78.5 | 86.46 |
|      sheep       | 84.79 | 94.06 |
|       cow        | 77.18 |  86.8 |
|     elephant     | 89.47 | 94.36 |
|       bear       | 90.82 | 95.38 |
|      zebra       | 89.58 | 92.34 |
|     giraffe      | 82.28 | 92.62 |
|     backpack     | 22.25 | 64.87 |
|     umbrella     | 72.37 | 81.64 |
|     handbag      | 17.11 | 40.88 |
|       tie        |  7.76 |  19.6 |
|     suitcase     |  61.7 | 85.04 |
|     frisbee      |  65.4 | 83.36 |
|       skis       |  25.8 | 34.12 |
|    snowboard     |  28.9 | 48.63 |
|   sports ball    | 46.73 | 74.48 |
|       kite       | 42.55 | 56.51 |
|   baseball bat   | 35.71 | 48.81 |
|  baseball glove  | 49.01 | 85.87 |
|    skateboard    | 46.04 | 62.93 |
|    surfboard     | 64.29 | 83.93 |
|  tennis racket   |  76.9 | 86.98 |
|      bottle      | 43.91 | 77.96 |
|    wine glass    | 53.54 | 73.02 |
|       cup        | 46.44 | 76.75 |
|       fork       | 18.44 | 23.32 |
|      knife       | 20.99 | 57.76 |
|      spoon       | 18.82 | 24.17 |
|       bowl       |  40.3 | 51.54 |
|      banana      | 65.57 | 83.67 |
|      apple       | 33.73 | 80.23 |
|     sandwich     | 44.34 | 73.62 |
|      orange      | 58.19 |  62.1 |
|     broccoli     | 50.47 | 72.93 |
|      carrot      | 47.54 | 68.68 |
|     hot dog      | 47.52 |  57.4 |
|      pizza       | 67.06 | 82.53 |
|      donut       | 61.86 |  84.9 |
|       cake       | 53.49 | 68.73 |
|      chair       | 35.12 | 47.09 |
|      couch       | 47.56 | 64.43 |
|   potted plant   | 24.42 | 44.52 |
|       bed        |  56.6 | 71.04 |
|   dining table   |  41.0 |  73.3 |
|      toilet      | 73.43 | 85.51 |
|        tv        | 65.71 | 81.72 |
|      laptop      | 67.56 | 89.29 |
|      mouse       | 60.51 | 80.99 |
|      remote      | 54.91 |  70.0 |
|     keyboard     | 56.56 | 62.34 |
|    cell phone    | 60.31 | 90.79 |
|    microwave     |  57.5 |  87.0 |
|       oven       | 44.23 | 69.15 |
|     toaster      |  0.0  |  0.0  |
|       sink       | 55.09 |  66.9 |
|   refrigerator   | 68.66 | 85.43 |
|       book       | 44.02 | 67.54 |
|      clock       | 66.37 | 81.04 |
|       vase       | 54.06 | 81.52 |
|     scissors     | 65.48 | 85.66 |
|    teddy bear    | 74.51 | 92.22 |
|    hair drier    |  0.0  |  0.0  |
|    toothbrush    | 13.23 | 36.02 |
|      banner      | 26.06 | 60.42 |
|     blanket      |  2.81 |  2.97 |
|      branch      | 18.17 | 22.98 |
|      bridge      | 25.38 | 31.04 |
|  building-other  | 47.93 | 64.82 |
|       bush       | 29.16 | 50.52 |
|     cabinet      | 49.31 | 69.53 |
|       cage       |  22.5 | 44.94 |
|    cardboard     | 31.38 | 35.84 |
|      carpet      |  47.3 |  60.1 |
|  ceiling-other   |  56.1 | 71.72 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 14.42 | 25.14 |
|      clouds      |  48.7 | 68.67 |
|     counter      | 22.93 | 41.51 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 57.59 | 78.25 |
|    desk-stuff    | 36.65 | 53.33 |
|       dirt       | 38.08 | 67.03 |
|    door-stuff    | 28.76 |  41.7 |
|      fence       | 25.85 | 40.36 |
|   floor-marble   |  0.96 |  0.98 |
|   floor-other    | 13.68 |  17.7 |
|   floor-stone    |  5.75 |  7.22 |
|    floor-tile    | 51.23 |  71.4 |
|    floor-wood    | 57.44 | 75.83 |
|      flower      | 37.11 | 64.82 |
|       fog        |  0.02 |  0.03 |
|    food-other    | 28.82 |  41.9 |
|      fruit       | 13.53 | 16.01 |
| furniture-other  | 14.65 | 24.63 |
|      grass       | 67.64 | 86.89 |
|      gravel      | 26.55 | 43.05 |
|   ground-other   |  0.23 |  0.25 |
|       hill       | 14.35 | 18.85 |
|      house       |  21.4 | 25.63 |
|      leaves      | 25.15 | 32.81 |
|      light       | 31.03 | 51.02 |
|       mat        |  0.0  |  0.0  |
|      metal       | 25.69 | 38.66 |
|   mirror-stuff   |  29.9 | 35.24 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 50.14 | 61.55 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  5.96 |  6.39 |
|       net        | 43.09 | 56.05 |
|      paper       | 24.34 |  34.7 |
|     pavement     | 49.06 |  71.8 |
|      pillow      |  2.87 |  4.58 |
|   plant-other    | 16.47 | 26.33 |
|     plastic      | 14.42 | 20.03 |
|     platform     | 24.04 |  38.8 |
|   playingfield   | 63.54 | 77.41 |
|     railing      |  3.04 |  3.31 |
|     railroad     | 52.55 | 62.02 |
|      river       | 44.94 | 75.92 |
|       road       | 59.62 | 73.07 |
|       rock       | 37.47 | 52.06 |
|       roof       | 13.39 | 17.21 |
|       rug        | 31.56 | 57.72 |
|      salad       |  0.0  |  0.0  |
|       sand       | 54.81 | 58.03 |
|       sea        | 83.88 | 91.82 |
|      shelf       | 21.47 | 24.59 |
|    sky-other     | 70.03 | 84.85 |
|    skyscraper    | 23.76 | 36.29 |
|       snow       | 87.12 |  91.4 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 13.53 | 19.19 |
|      stone       |  8.22 | 14.86 |
|      straw       | 23.59 | 29.97 |
| structural-other |  0.0  |  0.0  |
|      table       | 14.43 | 18.76 |
|       tent       |  4.34 |  5.18 |
|  textile-other   |  6.16 |  9.39 |
|      towel       | 24.41 | 44.32 |
|       tree       | 70.88 | 82.27 |
|    vegetable     | 31.16 | 55.09 |
|    wall-brick    |  40.5 | 61.04 |
|  wall-concrete   | 53.92 |  73.0 |
|    wall-other    | 15.99 | 33.69 |
|    wall-panel    |  4.87 |  5.84 |
|    wall-stone    | 25.25 | 28.04 |
|    wall-tile     | 59.22 | 77.69 |
|    wall-wood     | 34.26 | 50.62 |
|   water-other    |  5.26 |  5.65 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 43.06 | 53.81 |
|   window-other   | 39.79 | 57.23 |
|       wood       | 20.58 | 26.68 |
+------------------+-------+-------+
2023/05/23 20:08:59 - mmengine - INFO - Iter(val) [625/625]    aAcc: 67.3800  mIoU: 40.2500  mAcc: 53.9000  data_time: 0.0020  time: 0.0862
2023/05/23 20:08:59 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_10000.pth is removed
2023/05/23 20:09:02 - mmengine - INFO - The best checkpoint with 40.2500 mIoU at 15000 iter is saved to best_mIoU_iter_15000.pth.
2023/05/23 20:09:23 - mmengine - INFO - Iter(train) [ 15050/160000]  lr: 9.1494e-06  eta: 17:11:49  time: 0.4466  data_time: 0.0097  memory: 4867  grad_norm: 88.0303  loss: 43.4408  decode.loss_cls: 1.7580  decode.loss_mask: 0.8150  decode.loss_dice: 1.4861  decode.d0.loss_cls: 3.5069  decode.d0.loss_mask: 0.8618  decode.d0.loss_dice: 1.7019  decode.d1.loss_cls: 1.9353  decode.d1.loss_mask: 0.8715  decode.d1.loss_dice: 1.6001  decode.d2.loss_cls: 1.7971  decode.d2.loss_mask: 0.8653  decode.d2.loss_dice: 1.5855  decode.d3.loss_cls: 1.8027  decode.d3.loss_mask: 0.7961  decode.d3.loss_dice: 1.4930  decode.d4.loss_cls: 1.7509  decode.d4.loss_mask: 0.8588  decode.d4.loss_dice: 1.5398  decode.d5.loss_cls: 1.8154  decode.d5.loss_mask: 0.8121  decode.d5.loss_dice: 1.5280  decode.d6.loss_cls: 1.7924  decode.d6.loss_mask: 0.8291  decode.d6.loss_dice: 1.4556  decode.d7.loss_cls: 1.7832  decode.d7.loss_mask: 0.8127  decode.d7.loss_dice: 1.4641  decode.d8.loss_cls: 1.7555  decode.d8.loss_mask: 0.8549  decode.d8.loss_dice: 1.5117
2023/05/23 20:09:44 - mmengine - INFO - Iter(train) [ 15100/160000]  lr: 9.1465e-06  eta: 17:11:24  time: 0.4084  data_time: 0.0092  memory: 4918  grad_norm: 111.3470  loss: 32.6663  decode.loss_cls: 1.2447  decode.loss_mask: 0.6597  decode.loss_dice: 1.0931  decode.d0.loss_cls: 2.8079  decode.d0.loss_mask: 0.7299  decode.d0.loss_dice: 1.2400  decode.d1.loss_cls: 1.4023  decode.d1.loss_mask: 0.6921  decode.d1.loss_dice: 1.2056  decode.d2.loss_cls: 1.2868  decode.d2.loss_mask: 0.6916  decode.d2.loss_dice: 1.1790  decode.d3.loss_cls: 1.2737  decode.d3.loss_mask: 0.6433  decode.d3.loss_dice: 1.0918  decode.d4.loss_cls: 1.2861  decode.d4.loss_mask: 0.6451  decode.d4.loss_dice: 1.1130  decode.d5.loss_cls: 1.3001  decode.d5.loss_mask: 0.6527  decode.d5.loss_dice: 1.1883  decode.d6.loss_cls: 1.2535  decode.d6.loss_mask: 0.6653  decode.d6.loss_dice: 1.1510  decode.d7.loss_cls: 1.2953  decode.d7.loss_mask: 0.6696  decode.d7.loss_dice: 1.1196  decode.d8.loss_cls: 1.2700  decode.d8.loss_mask: 0.6766  decode.d8.loss_dice: 1.1387
2023/05/23 20:10:04 - mmengine - INFO - Iter(train) [ 15150/160000]  lr: 9.1437e-06  eta: 17:10:54  time: 0.4144  data_time: 0.0096  memory: 4894  grad_norm: 116.3081  loss: 45.5454  decode.loss_cls: 1.6459  decode.loss_mask: 0.9851  decode.loss_dice: 1.6402  decode.d0.loss_cls: 3.5902  decode.d0.loss_mask: 1.0272  decode.d0.loss_dice: 1.8982  decode.d1.loss_cls: 1.8547  decode.d1.loss_mask: 1.0541  decode.d1.loss_dice: 1.7694  decode.d2.loss_cls: 1.7179  decode.d2.loss_mask: 1.0247  decode.d2.loss_dice: 1.6668  decode.d3.loss_cls: 1.6280  decode.d3.loss_mask: 0.9914  decode.d3.loss_dice: 1.6649  decode.d4.loss_cls: 1.5769  decode.d4.loss_mask: 1.0034  decode.d4.loss_dice: 1.6799  decode.d5.loss_cls: 1.6445  decode.d5.loss_mask: 0.9891  decode.d5.loss_dice: 1.6578  decode.d6.loss_cls: 1.6755  decode.d6.loss_mask: 0.9762  decode.d6.loss_dice: 1.6188  decode.d7.loss_cls: 1.6844  decode.d7.loss_mask: 0.9761  decode.d7.loss_dice: 1.6292  decode.d8.loss_cls: 1.6137  decode.d8.loss_mask: 1.0305  decode.d8.loss_dice: 1.6307
2023/05/23 20:10:25 - mmengine - INFO - Iter(train) [ 15200/160000]  lr: 9.1408e-06  eta: 17:10:27  time: 0.4150  data_time: 0.0103  memory: 4856  grad_norm: 108.5905  loss: 32.0757  decode.loss_cls: 1.2082  decode.loss_mask: 0.7202  decode.loss_dice: 0.9752  decode.d0.loss_cls: 3.2788  decode.d0.loss_mask: 0.7509  decode.d0.loss_dice: 1.1428  decode.d1.loss_cls: 1.3817  decode.d1.loss_mask: 0.7668  decode.d1.loss_dice: 1.0890  decode.d2.loss_cls: 1.3545  decode.d2.loss_mask: 0.7104  decode.d2.loss_dice: 1.0475  decode.d3.loss_cls: 1.2690  decode.d3.loss_mask: 0.7137  decode.d3.loss_dice: 1.0012  decode.d4.loss_cls: 1.2520  decode.d4.loss_mask: 0.6913  decode.d4.loss_dice: 1.0042  decode.d5.loss_cls: 1.2432  decode.d5.loss_mask: 0.6857  decode.d5.loss_dice: 0.9775  decode.d6.loss_cls: 1.2661  decode.d6.loss_mask: 0.7066  decode.d6.loss_dice: 0.9841  decode.d7.loss_cls: 1.2130  decode.d7.loss_mask: 0.7261  decode.d7.loss_dice: 0.9990  decode.d8.loss_cls: 1.2024  decode.d8.loss_mask: 0.7263  decode.d8.loss_dice: 0.9884
2023/05/23 20:10:46 - mmengine - INFO - Iter(train) [ 15250/160000]  lr: 9.1380e-06  eta: 17:09:58  time: 0.4028  data_time: 0.0093  memory: 4836  grad_norm: 104.0818  loss: 35.2128  decode.loss_cls: 1.1768  decode.loss_mask: 0.8383  decode.loss_dice: 1.3110  decode.d0.loss_cls: 3.1459  decode.d0.loss_mask: 0.8735  decode.d0.loss_dice: 1.4419  decode.d1.loss_cls: 1.3226  decode.d1.loss_mask: 0.8611  decode.d1.loss_dice: 1.3750  decode.d2.loss_cls: 1.2553  decode.d2.loss_mask: 0.8240  decode.d2.loss_dice: 1.2313  decode.d3.loss_cls: 1.2195  decode.d3.loss_mask: 0.8115  decode.d3.loss_dice: 1.2254  decode.d4.loss_cls: 1.2117  decode.d4.loss_mask: 0.8148  decode.d4.loss_dice: 1.2684  decode.d5.loss_cls: 1.1486  decode.d5.loss_mask: 0.8076  decode.d5.loss_dice: 1.2728  decode.d6.loss_cls: 1.1663  decode.d6.loss_mask: 0.8265  decode.d6.loss_dice: 1.2359  decode.d7.loss_cls: 1.1744  decode.d7.loss_mask: 0.8311  decode.d7.loss_dice: 1.2699  decode.d8.loss_cls: 1.1929  decode.d8.loss_mask: 0.8327  decode.d8.loss_dice: 1.2460
2023/05/23 20:11:06 - mmengine - INFO - Iter(train) [ 15300/160000]  lr: 9.1352e-06  eta: 17:09:30  time: 0.4057  data_time: 0.0094  memory: 4829  grad_norm: 101.1263  loss: 42.1050  decode.loss_cls: 1.4559  decode.loss_mask: 0.8796  decode.loss_dice: 1.5459  decode.d0.loss_cls: 3.4860  decode.d0.loss_mask: 0.9544  decode.d0.loss_dice: 1.7474  decode.d1.loss_cls: 1.5620  decode.d1.loss_mask: 0.9553  decode.d1.loss_dice: 1.6925  decode.d2.loss_cls: 1.4924  decode.d2.loss_mask: 0.9140  decode.d2.loss_dice: 1.6189  decode.d3.loss_cls: 1.4913  decode.d3.loss_mask: 0.8824  decode.d3.loss_dice: 1.5411  decode.d4.loss_cls: 1.4874  decode.d4.loss_mask: 0.8956  decode.d4.loss_dice: 1.5889  decode.d5.loss_cls: 1.4840  decode.d5.loss_mask: 0.9136  decode.d5.loss_dice: 1.5831  decode.d6.loss_cls: 1.4568  decode.d6.loss_mask: 0.9080  decode.d6.loss_dice: 1.5637  decode.d7.loss_cls: 1.5157  decode.d7.loss_mask: 0.9053  decode.d7.loss_dice: 1.6070  decode.d8.loss_cls: 1.5047  decode.d8.loss_mask: 0.9001  decode.d8.loss_dice: 1.5720
2023/05/23 20:11:27 - mmengine - INFO - Iter(train) [ 15350/160000]  lr: 9.1323e-06  eta: 17:09:03  time: 0.4204  data_time: 0.0096  memory: 4845  grad_norm: 138.3033  loss: 38.1362  decode.loss_cls: 1.4049  decode.loss_mask: 0.8186  decode.loss_dice: 1.3534  decode.d0.loss_cls: 3.3552  decode.d0.loss_mask: 0.8824  decode.d0.loss_dice: 1.5505  decode.d1.loss_cls: 1.5631  decode.d1.loss_mask: 0.8452  decode.d1.loss_dice: 1.4294  decode.d2.loss_cls: 1.4493  decode.d2.loss_mask: 0.8235  decode.d2.loss_dice: 1.3649  decode.d3.loss_cls: 1.4376  decode.d3.loss_mask: 0.7797  decode.d3.loss_dice: 1.3362  decode.d4.loss_cls: 1.4529  decode.d4.loss_mask: 0.8236  decode.d4.loss_dice: 1.3398  decode.d5.loss_cls: 1.3689  decode.d5.loss_mask: 0.8205  decode.d5.loss_dice: 1.2866  decode.d6.loss_cls: 1.4241  decode.d6.loss_mask: 0.8253  decode.d6.loss_dice: 1.3195  decode.d7.loss_cls: 1.3855  decode.d7.loss_mask: 0.8015  decode.d7.loss_dice: 1.3360  decode.d8.loss_cls: 1.4073  decode.d8.loss_mask: 0.8139  decode.d8.loss_dice: 1.3368
2023/05/23 20:11:48 - mmengine - INFO - Iter(train) [ 15400/160000]  lr: 9.1295e-06  eta: 17:08:35  time: 0.4212  data_time: 0.0096  memory: 4960  grad_norm: 116.0706  loss: 45.5212  decode.loss_cls: 1.8011  decode.loss_mask: 0.8685  decode.loss_dice: 1.6228  decode.d0.loss_cls: 3.8056  decode.d0.loss_mask: 0.8665  decode.d0.loss_dice: 1.7789  decode.d1.loss_cls: 2.0472  decode.d1.loss_mask: 0.8766  decode.d1.loss_dice: 1.7282  decode.d2.loss_cls: 1.9404  decode.d2.loss_mask: 0.8428  decode.d2.loss_dice: 1.6094  decode.d3.loss_cls: 1.8666  decode.d3.loss_mask: 0.8401  decode.d3.loss_dice: 1.5916  decode.d4.loss_cls: 1.8787  decode.d4.loss_mask: 0.8438  decode.d4.loss_dice: 1.6062  decode.d5.loss_cls: 1.8217  decode.d5.loss_mask: 0.8320  decode.d5.loss_dice: 1.5886  decode.d6.loss_cls: 1.8444  decode.d6.loss_mask: 0.8520  decode.d6.loss_dice: 1.5819  decode.d7.loss_cls: 1.8025  decode.d7.loss_mask: 0.8954  decode.d7.loss_dice: 1.6196  decode.d8.loss_cls: 1.7595  decode.d8.loss_mask: 0.8742  decode.d8.loss_dice: 1.6346
2023/05/23 20:12:09 - mmengine - INFO - Iter(train) [ 15450/160000]  lr: 9.1266e-06  eta: 17:08:09  time: 0.4119  data_time: 0.0093  memory: 4831  grad_norm: 93.9550  loss: 38.0265  decode.loss_cls: 1.3195  decode.loss_mask: 0.9171  decode.loss_dice: 1.2591  decode.d0.loss_cls: 3.2700  decode.d0.loss_mask: 0.9182  decode.d0.loss_dice: 1.4491  decode.d1.loss_cls: 1.4383  decode.d1.loss_mask: 1.0096  decode.d1.loss_dice: 1.3812  decode.d2.loss_cls: 1.4172  decode.d2.loss_mask: 0.9652  decode.d2.loss_dice: 1.3542  decode.d3.loss_cls: 1.4023  decode.d3.loss_mask: 0.9217  decode.d3.loss_dice: 1.2668  decode.d4.loss_cls: 1.3833  decode.d4.loss_mask: 0.9358  decode.d4.loss_dice: 1.2998  decode.d5.loss_cls: 1.3805  decode.d5.loss_mask: 0.9375  decode.d5.loss_dice: 1.2791  decode.d6.loss_cls: 1.3085  decode.d6.loss_mask: 0.9256  decode.d6.loss_dice: 1.2518  decode.d7.loss_cls: 1.3033  decode.d7.loss_mask: 0.9311  decode.d7.loss_dice: 1.2692  decode.d8.loss_cls: 1.3480  decode.d8.loss_mask: 0.9168  decode.d8.loss_dice: 1.2669
2023/05/23 20:12:30 - mmengine - INFO - Iter(train) [ 15500/160000]  lr: 9.1238e-06  eta: 17:07:46  time: 0.4657  data_time: 0.0096  memory: 4856  grad_norm: 133.5441  loss: 40.6132  decode.loss_cls: 1.6445  decode.loss_mask: 0.8894  decode.loss_dice: 1.3151  decode.d0.loss_cls: 3.3105  decode.d0.loss_mask: 0.8638  decode.d0.loss_dice: 1.4411  decode.d1.loss_cls: 1.7132  decode.d1.loss_mask: 0.8891  decode.d1.loss_dice: 1.4163  decode.d2.loss_cls: 1.6210  decode.d2.loss_mask: 0.9273  decode.d2.loss_dice: 1.4083  decode.d3.loss_cls: 1.6491  decode.d3.loss_mask: 0.9611  decode.d3.loss_dice: 1.3627  decode.d4.loss_cls: 1.5842  decode.d4.loss_mask: 0.9199  decode.d4.loss_dice: 1.3408  decode.d5.loss_cls: 1.6129  decode.d5.loss_mask: 0.9179  decode.d5.loss_dice: 1.3329  decode.d6.loss_cls: 1.6475  decode.d6.loss_mask: 0.8901  decode.d6.loss_dice: 1.3424  decode.d7.loss_cls: 1.6040  decode.d7.loss_mask: 0.9045  decode.d7.loss_dice: 1.3169  decode.d8.loss_cls: 1.5962  decode.d8.loss_mask: 0.8652  decode.d8.loss_dice: 1.3251
2023/05/23 20:12:51 - mmengine - INFO - Iter(train) [ 15550/160000]  lr: 9.1210e-06  eta: 17:07:24  time: 0.4035  data_time: 0.0097  memory: 4846  grad_norm: 97.2400  loss: 44.6673  decode.loss_cls: 1.6870  decode.loss_mask: 0.9765  decode.loss_dice: 1.4475  decode.d0.loss_cls: 3.5836  decode.d0.loss_mask: 1.1348  decode.d0.loss_dice: 1.7470  decode.d1.loss_cls: 1.9102  decode.d1.loss_mask: 1.0340  decode.d1.loss_dice: 1.6365  decode.d2.loss_cls: 1.7514  decode.d2.loss_mask: 0.9627  decode.d2.loss_dice: 1.5450  decode.d3.loss_cls: 1.7228  decode.d3.loss_mask: 0.9683  decode.d3.loss_dice: 1.5135  decode.d4.loss_cls: 1.7383  decode.d4.loss_mask: 0.9843  decode.d4.loss_dice: 1.5003  decode.d5.loss_cls: 1.7420  decode.d5.loss_mask: 1.0024  decode.d5.loss_dice: 1.5203  decode.d6.loss_cls: 1.7095  decode.d6.loss_mask: 0.9943  decode.d6.loss_dice: 1.4836  decode.d7.loss_cls: 1.7192  decode.d7.loss_mask: 1.0325  decode.d7.loss_dice: 1.4715  decode.d8.loss_cls: 1.6533  decode.d8.loss_mask: 1.0197  decode.d8.loss_dice: 1.4754
2023/05/23 20:13:12 - mmengine - INFO - Iter(train) [ 15600/160000]  lr: 9.1181e-06  eta: 17:06:57  time: 0.4166  data_time: 0.0092  memory: 4875  grad_norm: 133.4429  loss: 42.7387  decode.loss_cls: 1.4716  decode.loss_mask: 0.9265  decode.loss_dice: 1.6067  decode.d0.loss_cls: 3.5283  decode.d0.loss_mask: 1.0079  decode.d0.loss_dice: 1.7581  decode.d1.loss_cls: 1.5762  decode.d1.loss_mask: 0.9868  decode.d1.loss_dice: 1.7150  decode.d2.loss_cls: 1.4662  decode.d2.loss_mask: 0.9648  decode.d2.loss_dice: 1.6566  decode.d3.loss_cls: 1.5737  decode.d3.loss_mask: 0.9046  decode.d3.loss_dice: 1.5963  decode.d4.loss_cls: 1.5037  decode.d4.loss_mask: 0.9386  decode.d4.loss_dice: 1.5939  decode.d5.loss_cls: 1.5216  decode.d5.loss_mask: 0.9288  decode.d5.loss_dice: 1.6311  decode.d6.loss_cls: 1.4718  decode.d6.loss_mask: 0.8843  decode.d6.loss_dice: 1.5706  decode.d7.loss_cls: 1.4933  decode.d7.loss_mask: 0.9015  decode.d7.loss_dice: 1.5699  decode.d8.loss_cls: 1.5423  decode.d8.loss_mask: 0.8866  decode.d8.loss_dice: 1.5616
2023/05/23 20:13:32 - mmengine - INFO - Iter(train) [ 15650/160000]  lr: 9.1153e-06  eta: 17:06:28  time: 0.4059  data_time: 0.0096  memory: 4866  grad_norm: 131.3339  loss: 37.6079  decode.loss_cls: 1.3874  decode.loss_mask: 0.7237  decode.loss_dice: 1.3667  decode.d0.loss_cls: 3.2412  decode.d0.loss_mask: 0.7409  decode.d0.loss_dice: 1.6097  decode.d1.loss_cls: 1.5983  decode.d1.loss_mask: 0.7049  decode.d1.loss_dice: 1.4548  decode.d2.loss_cls: 1.4175  decode.d2.loss_mask: 0.7180  decode.d2.loss_dice: 1.4813  decode.d3.loss_cls: 1.5034  decode.d3.loss_mask: 0.6757  decode.d3.loss_dice: 1.3553  decode.d4.loss_cls: 1.5104  decode.d4.loss_mask: 0.6554  decode.d4.loss_dice: 1.3988  decode.d5.loss_cls: 1.4775  decode.d5.loss_mask: 0.6648  decode.d5.loss_dice: 1.3615  decode.d6.loss_cls: 1.4538  decode.d6.loss_mask: 0.6695  decode.d6.loss_dice: 1.3584  decode.d7.loss_cls: 1.4445  decode.d7.loss_mask: 0.6940  decode.d7.loss_dice: 1.3864  decode.d8.loss_cls: 1.4560  decode.d8.loss_mask: 0.6869  decode.d8.loss_dice: 1.4111
2023/05/23 20:13:55 - mmengine - INFO - Iter(train) [ 15700/160000]  lr: 9.1124e-06  eta: 17:06:20  time: 0.4416  data_time: 0.0103  memory: 4839  grad_norm: 92.1857  loss: 45.0719  decode.loss_cls: 1.4615  decode.loss_mask: 0.9543  decode.loss_dice: 1.7489  decode.d0.loss_cls: 3.4384  decode.d0.loss_mask: 1.0583  decode.d0.loss_dice: 1.9597  decode.d1.loss_cls: 1.6564  decode.d1.loss_mask: 1.0331  decode.d1.loss_dice: 1.8606  decode.d2.loss_cls: 1.5621  decode.d2.loss_mask: 0.9849  decode.d2.loss_dice: 1.7800  decode.d3.loss_cls: 1.5463  decode.d3.loss_mask: 0.9907  decode.d3.loss_dice: 1.8002  decode.d4.loss_cls: 1.6114  decode.d4.loss_mask: 0.9611  decode.d4.loss_dice: 1.7174  decode.d5.loss_cls: 1.5268  decode.d5.loss_mask: 0.9882  decode.d5.loss_dice: 1.7684  decode.d6.loss_cls: 1.4909  decode.d6.loss_mask: 0.9368  decode.d6.loss_dice: 1.7922  decode.d7.loss_cls: 1.4683  decode.d7.loss_mask: 0.9472  decode.d7.loss_dice: 1.7573  decode.d8.loss_cls: 1.4762  decode.d8.loss_mask: 0.9615  decode.d8.loss_dice: 1.8327
2023/05/23 20:14:15 - mmengine - INFO - Iter(train) [ 15750/160000]  lr: 9.1096e-06  eta: 17:05:50  time: 0.4055  data_time: 0.0095  memory: 4888  grad_norm: 91.3113  loss: 42.3383  decode.loss_cls: 1.5019  decode.loss_mask: 0.8373  decode.loss_dice: 1.6417  decode.d0.loss_cls: 3.2636  decode.d0.loss_mask: 0.8665  decode.d0.loss_dice: 1.8927  decode.d1.loss_cls: 1.5762  decode.d1.loss_mask: 0.9062  decode.d1.loss_dice: 1.7814  decode.d2.loss_cls: 1.5203  decode.d2.loss_mask: 0.8903  decode.d2.loss_dice: 1.7257  decode.d3.loss_cls: 1.5418  decode.d3.loss_mask: 0.8479  decode.d3.loss_dice: 1.6359  decode.d4.loss_cls: 1.5426  decode.d4.loss_mask: 0.8379  decode.d4.loss_dice: 1.6532  decode.d5.loss_cls: 1.5411  decode.d5.loss_mask: 0.8143  decode.d5.loss_dice: 1.6484  decode.d6.loss_cls: 1.4935  decode.d6.loss_mask: 0.8207  decode.d6.loss_dice: 1.6363  decode.d7.loss_cls: 1.4963  decode.d7.loss_mask: 0.8177  decode.d7.loss_dice: 1.6353  decode.d8.loss_cls: 1.4669  decode.d8.loss_mask: 0.8396  decode.d8.loss_dice: 1.6649
2023/05/23 20:14:36 - mmengine - INFO - Iter(train) [ 15800/160000]  lr: 9.1067e-06  eta: 17:05:20  time: 0.4108  data_time: 0.0099  memory: 4857  grad_norm: 85.6497  loss: 45.9074  decode.loss_cls: 1.5647  decode.loss_mask: 0.9429  decode.loss_dice: 1.7777  decode.d0.loss_cls: 3.6209  decode.d0.loss_mask: 0.9066  decode.d0.loss_dice: 1.9857  decode.d1.loss_cls: 1.6868  decode.d1.loss_mask: 0.9812  decode.d1.loss_dice: 1.9583  decode.d2.loss_cls: 1.7464  decode.d2.loss_mask: 0.9368  decode.d2.loss_dice: 1.7662  decode.d3.loss_cls: 1.6328  decode.d3.loss_mask: 0.9576  decode.d3.loss_dice: 1.7387  decode.d4.loss_cls: 1.5867  decode.d4.loss_mask: 0.9507  decode.d4.loss_dice: 1.7993  decode.d5.loss_cls: 1.6643  decode.d5.loss_mask: 0.9137  decode.d5.loss_dice: 1.7309  decode.d6.loss_cls: 1.6650  decode.d6.loss_mask: 0.9402  decode.d6.loss_dice: 1.7540  decode.d7.loss_cls: 1.6445  decode.d7.loss_mask: 0.9482  decode.d7.loss_dice: 1.7852  decode.d8.loss_cls: 1.6035  decode.d8.loss_mask: 0.9462  decode.d8.loss_dice: 1.7717
2023/05/23 20:14:56 - mmengine - INFO - Iter(train) [ 15850/160000]  lr: 9.1039e-06  eta: 17:04:53  time: 0.4129  data_time: 0.0095  memory: 4887  grad_norm: 106.7062  loss: 41.1827  decode.loss_cls: 1.6874  decode.loss_mask: 0.8380  decode.loss_dice: 1.3694  decode.d0.loss_cls: 3.3884  decode.d0.loss_mask: 0.9158  decode.d0.loss_dice: 1.4670  decode.d1.loss_cls: 1.7438  decode.d1.loss_mask: 0.9142  decode.d1.loss_dice: 1.3997  decode.d2.loss_cls: 1.7233  decode.d2.loss_mask: 0.8963  decode.d2.loss_dice: 1.4167  decode.d3.loss_cls: 1.6319  decode.d3.loss_mask: 0.9032  decode.d3.loss_dice: 1.3914  decode.d4.loss_cls: 1.6422  decode.d4.loss_mask: 0.9026  decode.d4.loss_dice: 1.3804  decode.d5.loss_cls: 1.6574  decode.d5.loss_mask: 0.8798  decode.d5.loss_dice: 1.3598  decode.d6.loss_cls: 1.6917  decode.d6.loss_mask: 0.8350  decode.d6.loss_dice: 1.3608  decode.d7.loss_cls: 1.7031  decode.d7.loss_mask: 0.8646  decode.d7.loss_dice: 1.3469  decode.d8.loss_cls: 1.6655  decode.d8.loss_mask: 0.8727  decode.d8.loss_dice: 1.3336
2023/05/23 20:15:17 - mmengine - INFO - Iter(train) [ 15900/160000]  lr: 9.1011e-06  eta: 17:04:25  time: 0.4154  data_time: 0.0093  memory: 4822  grad_norm: 102.3452  loss: 43.9558  decode.loss_cls: 1.5113  decode.loss_mask: 0.9462  decode.loss_dice: 1.5882  decode.d0.loss_cls: 3.6325  decode.d0.loss_mask: 1.0073  decode.d0.loss_dice: 1.8436  decode.d1.loss_cls: 1.7612  decode.d1.loss_mask: 1.0067  decode.d1.loss_dice: 1.7530  decode.d2.loss_cls: 1.5868  decode.d2.loss_mask: 0.9973  decode.d2.loss_dice: 1.6525  decode.d3.loss_cls: 1.5903  decode.d3.loss_mask: 0.9619  decode.d3.loss_dice: 1.5915  decode.d4.loss_cls: 1.5321  decode.d4.loss_mask: 0.9817  decode.d4.loss_dice: 1.6551  decode.d5.loss_cls: 1.6033  decode.d5.loss_mask: 0.9831  decode.d5.loss_dice: 1.6412  decode.d6.loss_cls: 1.5208  decode.d6.loss_mask: 0.9373  decode.d6.loss_dice: 1.5466  decode.d7.loss_cls: 1.5187  decode.d7.loss_mask: 0.9613  decode.d7.loss_dice: 1.5760  decode.d8.loss_cls: 1.5443  decode.d8.loss_mask: 0.9377  decode.d8.loss_dice: 1.5866
2023/05/23 20:15:38 - mmengine - INFO - Iter(train) [ 15950/160000]  lr: 9.0982e-06  eta: 17:03:57  time: 0.4092  data_time: 0.0093  memory: 4875  grad_norm: 179.3687  loss: 46.2272  decode.loss_cls: 1.6095  decode.loss_mask: 0.9282  decode.loss_dice: 1.8070  decode.d0.loss_cls: 3.5716  decode.d0.loss_mask: 1.0466  decode.d0.loss_dice: 2.0498  decode.d1.loss_cls: 1.7298  decode.d1.loss_mask: 0.9416  decode.d1.loss_dice: 1.9124  decode.d2.loss_cls: 1.6971  decode.d2.loss_mask: 0.9477  decode.d2.loss_dice: 1.8290  decode.d3.loss_cls: 1.6057  decode.d3.loss_mask: 0.9200  decode.d3.loss_dice: 1.8085  decode.d4.loss_cls: 1.6581  decode.d4.loss_mask: 0.9859  decode.d4.loss_dice: 1.7784  decode.d5.loss_cls: 1.6781  decode.d5.loss_mask: 0.9575  decode.d5.loss_dice: 1.8265  decode.d6.loss_cls: 1.5666  decode.d6.loss_mask: 0.9598  decode.d6.loss_dice: 1.7895  decode.d7.loss_cls: 1.5786  decode.d7.loss_mask: 0.9268  decode.d7.loss_dice: 1.7955  decode.d8.loss_cls: 1.5585  decode.d8.loss_mask: 0.9512  decode.d8.loss_dice: 1.8117
2023/05/23 20:15:58 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:15:58 - mmengine - INFO - Iter(train) [ 16000/160000]  lr: 9.0954e-06  eta: 17:03:29  time: 0.4097  data_time: 0.0095  memory: 4804  grad_norm: 103.1417  loss: 44.8275  decode.loss_cls: 1.5614  decode.loss_mask: 1.0016  decode.loss_dice: 1.6142  decode.d0.loss_cls: 3.5368  decode.d0.loss_mask: 0.9857  decode.d0.loss_dice: 1.8519  decode.d1.loss_cls: 1.7869  decode.d1.loss_mask: 1.0743  decode.d1.loss_dice: 1.7631  decode.d2.loss_cls: 1.6975  decode.d2.loss_mask: 1.0083  decode.d2.loss_dice: 1.7248  decode.d3.loss_cls: 1.6206  decode.d3.loss_mask: 1.0040  decode.d3.loss_dice: 1.6322  decode.d4.loss_cls: 1.5774  decode.d4.loss_mask: 0.9969  decode.d4.loss_dice: 1.6127  decode.d5.loss_cls: 1.5527  decode.d5.loss_mask: 1.0057  decode.d5.loss_dice: 1.6083  decode.d6.loss_cls: 1.5743  decode.d6.loss_mask: 1.0078  decode.d6.loss_dice: 1.6204  decode.d7.loss_cls: 1.5653  decode.d7.loss_mask: 0.9861  decode.d7.loss_dice: 1.6123  decode.d8.loss_cls: 1.5673  decode.d8.loss_mask: 1.0201  decode.d8.loss_dice: 1.6569
2023/05/23 20:15:58 - mmengine - INFO - Saving checkpoint at 16000 iterations
2023/05/23 20:16:24 - mmengine - INFO - Iter(train) [ 16050/160000]  lr: 9.0925e-06  eta: 17:03:48  time: 0.4041  data_time: 0.0095  memory: 4829  grad_norm: 106.9087  loss: 47.6792  decode.loss_cls: 2.1134  decode.loss_mask: 0.7845  decode.loss_dice: 1.5838  decode.d0.loss_cls: 3.7788  decode.d0.loss_mask: 0.8412  decode.d0.loss_dice: 1.9040  decode.d1.loss_cls: 2.2783  decode.d1.loss_mask: 0.7967  decode.d1.loss_dice: 1.7563  decode.d2.loss_cls: 2.1490  decode.d2.loss_mask: 0.8188  decode.d2.loss_dice: 1.7411  decode.d3.loss_cls: 2.0367  decode.d3.loss_mask: 0.8227  decode.d3.loss_dice: 1.6407  decode.d4.loss_cls: 2.0225  decode.d4.loss_mask: 0.8080  decode.d4.loss_dice: 1.6958  decode.d5.loss_cls: 2.0973  decode.d5.loss_mask: 0.7974  decode.d5.loss_dice: 1.6585  decode.d6.loss_cls: 2.1388  decode.d6.loss_mask: 0.8225  decode.d6.loss_dice: 1.5998  decode.d7.loss_cls: 2.1246  decode.d7.loss_mask: 0.7818  decode.d7.loss_dice: 1.5955  decode.d8.loss_cls: 2.0977  decode.d8.loss_mask: 0.7847  decode.d8.loss_dice: 1.6086
2023/05/23 20:16:45 - mmengine - INFO - Iter(train) [ 16100/160000]  lr: 9.0897e-06  eta: 17:03:20  time: 0.4148  data_time: 0.0095  memory: 4803  grad_norm: 86.2021  loss: 41.5887  decode.loss_cls: 1.6149  decode.loss_mask: 0.7902  decode.loss_dice: 1.5208  decode.d0.loss_cls: 3.6590  decode.d0.loss_mask: 0.8457  decode.d0.loss_dice: 1.5833  decode.d1.loss_cls: 1.6780  decode.d1.loss_mask: 0.8030  decode.d1.loss_dice: 1.6252  decode.d2.loss_cls: 1.5945  decode.d2.loss_mask: 0.7765  decode.d2.loss_dice: 1.5306  decode.d3.loss_cls: 1.5835  decode.d3.loss_mask: 0.8486  decode.d3.loss_dice: 1.5699  decode.d4.loss_cls: 1.5770  decode.d4.loss_mask: 0.8034  decode.d4.loss_dice: 1.5546  decode.d5.loss_cls: 1.5803  decode.d5.loss_mask: 0.8210  decode.d5.loss_dice: 1.5312  decode.d6.loss_cls: 1.5855  decode.d6.loss_mask: 0.8261  decode.d6.loss_dice: 1.5147  decode.d7.loss_cls: 1.5707  decode.d7.loss_mask: 0.8103  decode.d7.loss_dice: 1.5269  decode.d8.loss_cls: 1.5474  decode.d8.loss_mask: 0.8030  decode.d8.loss_dice: 1.5131
2023/05/23 20:17:05 - mmengine - INFO - Iter(train) [ 16150/160000]  lr: 9.0868e-06  eta: 17:02:54  time: 0.4176  data_time: 0.0098  memory: 4876  grad_norm: 128.4039  loss: 46.3835  decode.loss_cls: 1.6841  decode.loss_mask: 0.8819  decode.loss_dice: 1.7447  decode.d0.loss_cls: 3.7589  decode.d0.loss_mask: 1.0139  decode.d0.loss_dice: 2.0452  decode.d1.loss_cls: 1.9296  decode.d1.loss_mask: 0.9168  decode.d1.loss_dice: 1.8969  decode.d2.loss_cls: 1.6727  decode.d2.loss_mask: 0.9364  decode.d2.loss_dice: 1.8679  decode.d3.loss_cls: 1.7660  decode.d3.loss_mask: 0.8724  decode.d3.loss_dice: 1.7965  decode.d4.loss_cls: 1.6985  decode.d4.loss_mask: 0.9010  decode.d4.loss_dice: 1.7833  decode.d5.loss_cls: 1.6852  decode.d5.loss_mask: 0.8762  decode.d5.loss_dice: 1.7497  decode.d6.loss_cls: 1.6231  decode.d6.loss_mask: 0.8579  decode.d6.loss_dice: 1.7541  decode.d7.loss_cls: 1.7103  decode.d7.loss_mask: 0.8510  decode.d7.loss_dice: 1.7573  decode.d8.loss_cls: 1.7173  decode.d8.loss_mask: 0.8476  decode.d8.loss_dice: 1.7869
2023/05/23 20:17:26 - mmengine - INFO - Iter(train) [ 16200/160000]  lr: 9.0840e-06  eta: 17:02:25  time: 0.4117  data_time: 0.0099  memory: 4857  grad_norm: 98.5560  loss: 40.0014  decode.loss_cls: 1.4415  decode.loss_mask: 0.6895  decode.loss_dice: 1.5739  decode.d0.loss_cls: 3.5345  decode.d0.loss_mask: 0.7603  decode.d0.loss_dice: 1.8511  decode.d1.loss_cls: 1.6027  decode.d1.loss_mask: 0.7324  decode.d1.loss_dice: 1.6931  decode.d2.loss_cls: 1.4965  decode.d2.loss_mask: 0.7006  decode.d2.loss_dice: 1.6643  decode.d3.loss_cls: 1.3985  decode.d3.loss_mask: 0.6817  decode.d3.loss_dice: 1.5993  decode.d4.loss_cls: 1.4378  decode.d4.loss_mask: 0.6662  decode.d4.loss_dice: 1.5880  decode.d5.loss_cls: 1.4100  decode.d5.loss_mask: 0.7169  decode.d5.loss_dice: 1.6095  decode.d6.loss_cls: 1.4865  decode.d6.loss_mask: 0.6675  decode.d6.loss_dice: 1.5883  decode.d7.loss_cls: 1.4551  decode.d7.loss_mask: 0.6688  decode.d7.loss_dice: 1.5849  decode.d8.loss_cls: 1.4286  decode.d8.loss_mask: 0.6807  decode.d8.loss_dice: 1.5927
2023/05/23 20:17:46 - mmengine - INFO - Iter(train) [ 16250/160000]  lr: 9.0812e-06  eta: 17:01:56  time: 0.4134  data_time: 0.0096  memory: 4821  grad_norm: 96.5031  loss: 39.2570  decode.loss_cls: 1.4679  decode.loss_mask: 0.8804  decode.loss_dice: 1.2883  decode.d0.loss_cls: 3.2331  decode.d0.loss_mask: 0.8661  decode.d0.loss_dice: 1.4631  decode.d1.loss_cls: 1.7036  decode.d1.loss_mask: 0.8991  decode.d1.loss_dice: 1.4354  decode.d2.loss_cls: 1.6098  decode.d2.loss_mask: 0.8581  decode.d2.loss_dice: 1.2983  decode.d3.loss_cls: 1.5725  decode.d3.loss_mask: 0.8898  decode.d3.loss_dice: 1.3532  decode.d4.loss_cls: 1.5600  decode.d4.loss_mask: 0.8994  decode.d4.loss_dice: 1.3114  decode.d5.loss_cls: 1.5052  decode.d5.loss_mask: 0.8748  decode.d5.loss_dice: 1.3150  decode.d6.loss_cls: 1.5075  decode.d6.loss_mask: 0.8726  decode.d6.loss_dice: 1.3153  decode.d7.loss_cls: 1.5120  decode.d7.loss_mask: 0.8705  decode.d7.loss_dice: 1.2802  decode.d8.loss_cls: 1.4858  decode.d8.loss_mask: 0.8537  decode.d8.loss_dice: 1.2749
2023/05/23 20:18:08 - mmengine - INFO - Iter(train) [ 16300/160000]  lr: 9.0783e-06  eta: 17:01:34  time: 0.4273  data_time: 0.0100  memory: 4815  grad_norm: 116.7680  loss: 47.9134  decode.loss_cls: 1.7582  decode.loss_mask: 1.0061  decode.loss_dice: 1.6948  decode.d0.loss_cls: 3.8598  decode.d0.loss_mask: 1.0847  decode.d0.loss_dice: 2.0051  decode.d1.loss_cls: 1.8221  decode.d1.loss_mask: 1.1079  decode.d1.loss_dice: 1.8635  decode.d2.loss_cls: 1.8583  decode.d2.loss_mask: 1.0727  decode.d2.loss_dice: 1.7893  decode.d3.loss_cls: 1.8056  decode.d3.loss_mask: 1.0469  decode.d3.loss_dice: 1.7786  decode.d4.loss_cls: 1.7345  decode.d4.loss_mask: 1.0299  decode.d4.loss_dice: 1.7858  decode.d5.loss_cls: 1.7279  decode.d5.loss_mask: 1.0065  decode.d5.loss_dice: 1.7454  decode.d6.loss_cls: 1.7043  decode.d6.loss_mask: 1.0225  decode.d6.loss_dice: 1.7438  decode.d7.loss_cls: 1.6992  decode.d7.loss_mask: 1.0092  decode.d7.loss_dice: 1.7487  decode.d8.loss_cls: 1.6857  decode.d8.loss_mask: 1.0078  decode.d8.loss_dice: 1.7083
2023/05/23 20:18:28 - mmengine - INFO - Iter(train) [ 16350/160000]  lr: 9.0755e-06  eta: 17:01:07  time: 0.4089  data_time: 0.0096  memory: 4823  grad_norm: 118.6948  loss: 43.4702  decode.loss_cls: 1.6589  decode.loss_mask: 0.9173  decode.loss_dice: 1.5462  decode.d0.loss_cls: 3.2160  decode.d0.loss_mask: 0.9473  decode.d0.loss_dice: 1.7491  decode.d1.loss_cls: 1.7299  decode.d1.loss_mask: 0.9749  decode.d1.loss_dice: 1.6835  decode.d2.loss_cls: 1.7032  decode.d2.loss_mask: 0.9163  decode.d2.loss_dice: 1.6236  decode.d3.loss_cls: 1.6548  decode.d3.loss_mask: 0.9001  decode.d3.loss_dice: 1.5295  decode.d4.loss_cls: 1.7540  decode.d4.loss_mask: 0.9021  decode.d4.loss_dice: 1.5563  decode.d5.loss_cls: 1.7322  decode.d5.loss_mask: 0.9090  decode.d5.loss_dice: 1.5043  decode.d6.loss_cls: 1.7189  decode.d6.loss_mask: 0.9194  decode.d6.loss_dice: 1.5263  decode.d7.loss_cls: 1.6450  decode.d7.loss_mask: 0.9243  decode.d7.loss_dice: 1.5436  decode.d8.loss_cls: 1.6611  decode.d8.loss_mask: 0.9020  decode.d8.loss_dice: 1.5208
2023/05/23 20:18:52 - mmengine - INFO - Iter(train) [ 16400/160000]  lr: 9.0726e-06  eta: 17:01:03  time: 0.4646  data_time: 0.0100  memory: 4866  grad_norm: 134.3063  loss: 46.6177  decode.loss_cls: 1.5579  decode.loss_mask: 1.0728  decode.loss_dice: 1.7230  decode.d0.loss_cls: 3.7651  decode.d0.loss_mask: 1.1110  decode.d0.loss_dice: 2.0242  decode.d1.loss_cls: 1.8264  decode.d1.loss_mask: 1.1445  decode.d1.loss_dice: 1.8796  decode.d2.loss_cls: 1.7402  decode.d2.loss_mask: 1.0891  decode.d2.loss_dice: 1.7836  decode.d3.loss_cls: 1.6547  decode.d3.loss_mask: 1.0252  decode.d3.loss_dice: 1.7083  decode.d4.loss_cls: 1.6639  decode.d4.loss_mask: 0.9790  decode.d4.loss_dice: 1.6526  decode.d5.loss_cls: 1.6285  decode.d5.loss_mask: 1.0276  decode.d5.loss_dice: 1.7025  decode.d6.loss_cls: 1.6137  decode.d6.loss_mask: 1.0146  decode.d6.loss_dice: 1.6591  decode.d7.loss_cls: 1.5733  decode.d7.loss_mask: 1.0379  decode.d7.loss_dice: 1.6967  decode.d8.loss_cls: 1.5483  decode.d8.loss_mask: 1.0066  decode.d8.loss_dice: 1.7080
2023/05/23 20:19:12 - mmengine - INFO - Iter(train) [ 16450/160000]  lr: 9.0698e-06  eta: 17:00:36  time: 0.4074  data_time: 0.0098  memory: 4829  grad_norm: 106.2731  loss: 34.4696  decode.loss_cls: 1.2690  decode.loss_mask: 0.7107  decode.loss_dice: 1.1829  decode.d0.loss_cls: 3.1215  decode.d0.loss_mask: 0.7835  decode.d0.loss_dice: 1.3808  decode.d1.loss_cls: 1.3499  decode.d1.loss_mask: 0.7265  decode.d1.loss_dice: 1.2706  decode.d2.loss_cls: 1.3722  decode.d2.loss_mask: 0.7292  decode.d2.loss_dice: 1.2396  decode.d3.loss_cls: 1.3222  decode.d3.loss_mask: 0.7201  decode.d3.loss_dice: 1.2393  decode.d4.loss_cls: 1.3267  decode.d4.loss_mask: 0.7090  decode.d4.loss_dice: 1.2377  decode.d5.loss_cls: 1.3758  decode.d5.loss_mask: 0.6829  decode.d5.loss_dice: 1.2146  decode.d6.loss_cls: 1.3304  decode.d6.loss_mask: 0.7000  decode.d6.loss_dice: 1.1387  decode.d7.loss_cls: 1.2835  decode.d7.loss_mask: 0.7097  decode.d7.loss_dice: 1.1814  decode.d8.loss_cls: 1.2442  decode.d8.loss_mask: 0.7235  decode.d8.loss_dice: 1.1936
2023/05/23 20:19:33 - mmengine - INFO - Iter(train) [ 16500/160000]  lr: 9.0669e-06  eta: 17:00:08  time: 0.4094  data_time: 0.0095  memory: 4878  grad_norm: 111.4637  loss: 46.2996  decode.loss_cls: 1.7770  decode.loss_mask: 0.8138  decode.loss_dice: 1.7466  decode.d0.loss_cls: 3.8720  decode.d0.loss_mask: 0.8083  decode.d0.loss_dice: 1.9930  decode.d1.loss_cls: 2.0091  decode.d1.loss_mask: 0.8277  decode.d1.loss_dice: 1.9446  decode.d2.loss_cls: 1.8674  decode.d2.loss_mask: 0.8318  decode.d2.loss_dice: 1.8198  decode.d3.loss_cls: 1.7402  decode.d3.loss_mask: 0.8334  decode.d3.loss_dice: 1.7454  decode.d4.loss_cls: 1.7642  decode.d4.loss_mask: 0.8073  decode.d4.loss_dice: 1.7511  decode.d5.loss_cls: 1.8357  decode.d5.loss_mask: 0.8066  decode.d5.loss_dice: 1.7459  decode.d6.loss_cls: 1.7844  decode.d6.loss_mask: 0.8105  decode.d6.loss_dice: 1.7372  decode.d7.loss_cls: 1.7634  decode.d7.loss_mask: 0.8214  decode.d7.loss_dice: 1.7572  decode.d8.loss_cls: 1.7296  decode.d8.loss_mask: 0.8077  decode.d8.loss_dice: 1.7472
2023/05/23 20:19:53 - mmengine - INFO - Iter(train) [ 16550/160000]  lr: 9.0641e-06  eta: 16:59:40  time: 0.4142  data_time: 0.0097  memory: 4871  grad_norm: 91.7932  loss: 41.1995  decode.loss_cls: 1.5900  decode.loss_mask: 0.8135  decode.loss_dice: 1.4864  decode.d0.loss_cls: 3.5393  decode.d0.loss_mask: 0.8254  decode.d0.loss_dice: 1.5926  decode.d1.loss_cls: 1.6342  decode.d1.loss_mask: 0.8096  decode.d1.loss_dice: 1.6327  decode.d2.loss_cls: 1.6338  decode.d2.loss_mask: 0.7953  decode.d2.loss_dice: 1.5430  decode.d3.loss_cls: 1.6175  decode.d3.loss_mask: 0.7963  decode.d3.loss_dice: 1.5101  decode.d4.loss_cls: 1.5826  decode.d4.loss_mask: 0.7795  decode.d4.loss_dice: 1.5220  decode.d5.loss_cls: 1.6476  decode.d5.loss_mask: 0.7668  decode.d5.loss_dice: 1.4773  decode.d6.loss_cls: 1.6291  decode.d6.loss_mask: 0.7866  decode.d6.loss_dice: 1.4694  decode.d7.loss_cls: 1.5860  decode.d7.loss_mask: 0.7809  decode.d7.loss_dice: 1.4950  decode.d8.loss_cls: 1.6094  decode.d8.loss_mask: 0.7829  decode.d8.loss_dice: 1.4647
2023/05/23 20:20:14 - mmengine - INFO - Iter(train) [ 16600/160000]  lr: 9.0613e-06  eta: 16:59:13  time: 0.4115  data_time: 0.0096  memory: 4795  grad_norm: 91.1564  loss: 32.8210  decode.loss_cls: 1.1396  decode.loss_mask: 0.7333  decode.loss_dice: 1.1442  decode.d0.loss_cls: 3.1312  decode.d0.loss_mask: 0.7823  decode.d0.loss_dice: 1.3096  decode.d1.loss_cls: 1.3140  decode.d1.loss_mask: 0.7903  decode.d1.loss_dice: 1.2510  decode.d2.loss_cls: 1.2273  decode.d2.loss_mask: 0.7666  decode.d2.loss_dice: 1.1849  decode.d3.loss_cls: 1.2253  decode.d3.loss_mask: 0.7194  decode.d3.loss_dice: 1.1457  decode.d4.loss_cls: 1.1060  decode.d4.loss_mask: 0.7495  decode.d4.loss_dice: 1.1573  decode.d5.loss_cls: 1.1322  decode.d5.loss_mask: 0.7375  decode.d5.loss_dice: 1.1539  decode.d6.loss_cls: 1.1229  decode.d6.loss_mask: 0.7159  decode.d6.loss_dice: 1.1419  decode.d7.loss_cls: 1.1246  decode.d7.loss_mask: 0.7210  decode.d7.loss_dice: 1.1413  decode.d8.loss_cls: 1.0703  decode.d8.loss_mask: 0.7298  decode.d8.loss_dice: 1.1521
2023/05/23 20:20:35 - mmengine - INFO - Iter(train) [ 16650/160000]  lr: 9.0584e-06  eta: 16:58:52  time: 0.4051  data_time: 0.0094  memory: 4836  grad_norm: 94.7107  loss: 39.3352  decode.loss_cls: 1.2696  decode.loss_mask: 0.8823  decode.loss_dice: 1.4952  decode.d0.loss_cls: 3.2988  decode.d0.loss_mask: 0.9452  decode.d0.loss_dice: 1.6530  decode.d1.loss_cls: 1.4998  decode.d1.loss_mask: 0.8404  decode.d1.loss_dice: 1.5939  decode.d2.loss_cls: 1.4256  decode.d2.loss_mask: 0.8737  decode.d2.loss_dice: 1.4946  decode.d3.loss_cls: 1.3409  decode.d3.loss_mask: 0.8457  decode.d3.loss_dice: 1.4750  decode.d4.loss_cls: 1.3305  decode.d4.loss_mask: 0.8842  decode.d4.loss_dice: 1.4810  decode.d5.loss_cls: 1.3508  decode.d5.loss_mask: 0.8544  decode.d5.loss_dice: 1.5029  decode.d6.loss_cls: 1.3042  decode.d6.loss_mask: 0.8681  decode.d6.loss_dice: 1.4857  decode.d7.loss_cls: 1.3107  decode.d7.loss_mask: 0.8729  decode.d7.loss_dice: 1.4822  decode.d8.loss_cls: 1.3068  decode.d8.loss_mask: 0.8768  decode.d8.loss_dice: 1.4907
2023/05/23 20:20:56 - mmengine - INFO - Iter(train) [ 16700/160000]  lr: 9.0556e-06  eta: 16:58:27  time: 0.4204  data_time: 0.0096  memory: 4920  grad_norm: 110.4778  loss: 40.9285  decode.loss_cls: 1.5301  decode.loss_mask: 0.8041  decode.loss_dice: 1.4772  decode.d0.loss_cls: 3.4911  decode.d0.loss_mask: 0.7943  decode.d0.loss_dice: 1.6632  decode.d1.loss_cls: 1.6522  decode.d1.loss_mask: 0.8603  decode.d1.loss_dice: 1.6107  decode.d2.loss_cls: 1.6091  decode.d2.loss_mask: 0.8666  decode.d2.loss_dice: 1.5302  decode.d3.loss_cls: 1.6579  decode.d3.loss_mask: 0.8006  decode.d3.loss_dice: 1.4733  decode.d4.loss_cls: 1.5560  decode.d4.loss_mask: 0.7872  decode.d4.loss_dice: 1.4627  decode.d5.loss_cls: 1.5848  decode.d5.loss_mask: 0.7753  decode.d5.loss_dice: 1.4384  decode.d6.loss_cls: 1.5983  decode.d6.loss_mask: 0.8014  decode.d6.loss_dice: 1.4285  decode.d7.loss_cls: 1.6010  decode.d7.loss_mask: 0.8119  decode.d7.loss_dice: 1.4380  decode.d8.loss_cls: 1.5230  decode.d8.loss_mask: 0.8345  decode.d8.loss_dice: 1.4668
2023/05/23 20:21:18 - mmengine - INFO - Iter(train) [ 16750/160000]  lr: 9.0527e-06  eta: 16:58:04  time: 0.4240  data_time: 0.0094  memory: 4844  grad_norm: 127.7494  loss: 38.7185  decode.loss_cls: 1.5950  decode.loss_mask: 0.7387  decode.loss_dice: 1.3010  decode.d0.loss_cls: 3.3012  decode.d0.loss_mask: 0.7497  decode.d0.loss_dice: 1.4232  decode.d1.loss_cls: 1.6326  decode.d1.loss_mask: 0.8079  decode.d1.loss_dice: 1.3613  decode.d2.loss_cls: 1.7352  decode.d2.loss_mask: 0.7894  decode.d2.loss_dice: 1.2524  decode.d3.loss_cls: 1.6509  decode.d3.loss_mask: 0.7842  decode.d3.loss_dice: 1.2322  decode.d4.loss_cls: 1.6600  decode.d4.loss_mask: 0.7811  decode.d4.loss_dice: 1.2759  decode.d5.loss_cls: 1.6143  decode.d5.loss_mask: 0.7918  decode.d5.loss_dice: 1.2909  decode.d6.loss_cls: 1.5170  decode.d6.loss_mask: 0.8235  decode.d6.loss_dice: 1.2939  decode.d7.loss_cls: 1.6027  decode.d7.loss_mask: 0.7885  decode.d7.loss_dice: 1.2694  decode.d8.loss_cls: 1.5912  decode.d8.loss_mask: 0.7706  decode.d8.loss_dice: 1.2928
2023/05/23 20:21:40 - mmengine - INFO - Iter(train) [ 16800/160000]  lr: 9.0499e-06  eta: 16:57:56  time: 0.4078  data_time: 0.0095  memory: 4836  grad_norm: 92.5695  loss: 41.7776  decode.loss_cls: 1.6038  decode.loss_mask: 0.7350  decode.loss_dice: 1.5594  decode.d0.loss_cls: 3.4342  decode.d0.loss_mask: 0.7892  decode.d0.loss_dice: 1.7503  decode.d1.loss_cls: 1.6289  decode.d1.loss_mask: 0.7757  decode.d1.loss_dice: 1.7180  decode.d2.loss_cls: 1.6906  decode.d2.loss_mask: 0.7676  decode.d2.loss_dice: 1.6125  decode.d3.loss_cls: 1.6733  decode.d3.loss_mask: 0.7272  decode.d3.loss_dice: 1.5671  decode.d4.loss_cls: 1.6820  decode.d4.loss_mask: 0.7391  decode.d4.loss_dice: 1.5365  decode.d5.loss_cls: 1.6858  decode.d5.loss_mask: 0.7287  decode.d5.loss_dice: 1.5367  decode.d6.loss_cls: 1.6530  decode.d6.loss_mask: 0.7653  decode.d6.loss_dice: 1.5440  decode.d7.loss_cls: 1.7020  decode.d7.loss_mask: 0.7369  decode.d7.loss_dice: 1.5330  decode.d8.loss_cls: 1.5847  decode.d8.loss_mask: 0.7605  decode.d8.loss_dice: 1.5566
2023/05/23 20:22:01 - mmengine - INFO - Iter(train) [ 16850/160000]  lr: 9.0470e-06  eta: 16:57:27  time: 0.4044  data_time: 0.0095  memory: 4885  grad_norm: 93.1839  loss: 38.7792  decode.loss_cls: 1.3407  decode.loss_mask: 0.8160  decode.loss_dice: 1.4195  decode.d0.loss_cls: 3.2996  decode.d0.loss_mask: 0.8743  decode.d0.loss_dice: 1.6060  decode.d1.loss_cls: 1.5077  decode.d1.loss_mask: 0.8249  decode.d1.loss_dice: 1.5085  decode.d2.loss_cls: 1.4283  decode.d2.loss_mask: 0.8188  decode.d2.loss_dice: 1.4918  decode.d3.loss_cls: 1.3406  decode.d3.loss_mask: 0.8707  decode.d3.loss_dice: 1.4779  decode.d4.loss_cls: 1.3434  decode.d4.loss_mask: 0.8414  decode.d4.loss_dice: 1.4762  decode.d5.loss_cls: 1.2902  decode.d5.loss_mask: 0.8853  decode.d5.loss_dice: 1.4592  decode.d6.loss_cls: 1.3775  decode.d6.loss_mask: 0.8661  decode.d6.loss_dice: 1.4255  decode.d7.loss_cls: 1.3396  decode.d7.loss_mask: 0.8613  decode.d7.loss_dice: 1.4157  decode.d8.loss_cls: 1.3179  decode.d8.loss_mask: 0.8580  decode.d8.loss_dice: 1.3967
2023/05/23 20:22:21 - mmengine - INFO - Iter(train) [ 16900/160000]  lr: 9.0442e-06  eta: 16:56:58  time: 0.4081  data_time: 0.0097  memory: 4823  grad_norm: 78.6519  loss: 37.9836  decode.loss_cls: 1.4016  decode.loss_mask: 0.7747  decode.loss_dice: 1.3706  decode.d0.loss_cls: 3.3359  decode.d0.loss_mask: 0.8198  decode.d0.loss_dice: 1.4815  decode.d1.loss_cls: 1.5319  decode.d1.loss_mask: 0.8240  decode.d1.loss_dice: 1.4513  decode.d2.loss_cls: 1.4594  decode.d2.loss_mask: 0.8412  decode.d2.loss_dice: 1.4065  decode.d3.loss_cls: 1.4362  decode.d3.loss_mask: 0.8317  decode.d3.loss_dice: 1.3645  decode.d4.loss_cls: 1.4065  decode.d4.loss_mask: 0.8101  decode.d4.loss_dice: 1.3566  decode.d5.loss_cls: 1.3622  decode.d5.loss_mask: 0.8104  decode.d5.loss_dice: 1.3450  decode.d6.loss_cls: 1.4235  decode.d6.loss_mask: 0.7892  decode.d6.loss_dice: 1.3559  decode.d7.loss_cls: 1.3695  decode.d7.loss_mask: 0.7889  decode.d7.loss_dice: 1.3556  decode.d8.loss_cls: 1.3571  decode.d8.loss_mask: 0.7725  decode.d8.loss_dice: 1.3498
2023/05/23 20:22:42 - mmengine - INFO - Iter(train) [ 16950/160000]  lr: 9.0414e-06  eta: 16:56:35  time: 0.4625  data_time: 0.0092  memory: 4829  grad_norm: 104.3711  loss: 37.4141  decode.loss_cls: 1.4186  decode.loss_mask: 0.7790  decode.loss_dice: 1.1866  decode.d0.loss_cls: 3.5630  decode.d0.loss_mask: 0.8576  decode.d0.loss_dice: 1.3721  decode.d1.loss_cls: 1.8117  decode.d1.loss_mask: 0.8198  decode.d1.loss_dice: 1.2969  decode.d2.loss_cls: 1.5012  decode.d2.loss_mask: 0.8585  decode.d2.loss_dice: 1.2515  decode.d3.loss_cls: 1.4616  decode.d3.loss_mask: 0.8009  decode.d3.loss_dice: 1.1944  decode.d4.loss_cls: 1.5088  decode.d4.loss_mask: 0.7583  decode.d4.loss_dice: 1.1944  decode.d5.loss_cls: 1.4661  decode.d5.loss_mask: 0.7808  decode.d5.loss_dice: 1.2269  decode.d6.loss_cls: 1.4862  decode.d6.loss_mask: 0.7686  decode.d6.loss_dice: 1.1725  decode.d7.loss_cls: 1.4794  decode.d7.loss_mask: 0.7827  decode.d7.loss_dice: 1.1592  decode.d8.loss_cls: 1.4706  decode.d8.loss_mask: 0.7974  decode.d8.loss_dice: 1.1889
2023/05/23 20:23:04 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:23:04 - mmengine - INFO - Iter(train) [ 17000/160000]  lr: 9.0385e-06  eta: 16:56:16  time: 0.4075  data_time: 0.0096  memory: 4859  grad_norm: 98.9532  loss: 43.3888  decode.loss_cls: 1.5062  decode.loss_mask: 0.8131  decode.loss_dice: 1.6579  decode.d0.loss_cls: 3.7991  decode.d0.loss_mask: 0.9421  decode.d0.loss_dice: 1.8748  decode.d1.loss_cls: 1.7576  decode.d1.loss_mask: 0.9131  decode.d1.loss_dice: 1.7949  decode.d2.loss_cls: 1.6428  decode.d2.loss_mask: 0.8579  decode.d2.loss_dice: 1.7143  decode.d3.loss_cls: 1.5531  decode.d3.loss_mask: 0.8265  decode.d3.loss_dice: 1.6845  decode.d4.loss_cls: 1.4942  decode.d4.loss_mask: 0.8160  decode.d4.loss_dice: 1.6966  decode.d5.loss_cls: 1.4869  decode.d5.loss_mask: 0.8293  decode.d5.loss_dice: 1.6840  decode.d6.loss_cls: 1.5370  decode.d6.loss_mask: 0.8366  decode.d6.loss_dice: 1.7102  decode.d7.loss_cls: 1.4891  decode.d7.loss_mask: 0.8244  decode.d7.loss_dice: 1.6829  decode.d8.loss_cls: 1.4800  decode.d8.loss_mask: 0.8261  decode.d8.loss_dice: 1.6575
2023/05/23 20:23:04 - mmengine - INFO - Saving checkpoint at 17000 iterations
2023/05/23 20:23:31 - mmengine - INFO - Iter(train) [ 17050/160000]  lr: 9.0357e-06  eta: 16:56:41  time: 0.4615  data_time: 0.0108  memory: 4899  grad_norm: 91.9640  loss: 37.1868  decode.loss_cls: 1.4130  decode.loss_mask: 0.7118  decode.loss_dice: 1.3075  decode.d0.loss_cls: 3.4654  decode.d0.loss_mask: 0.7657  decode.d0.loss_dice: 1.4196  decode.d1.loss_cls: 1.5367  decode.d1.loss_mask: 0.8395  decode.d1.loss_dice: 1.4244  decode.d2.loss_cls: 1.4300  decode.d2.loss_mask: 0.7466  decode.d2.loss_dice: 1.3212  decode.d3.loss_cls: 1.3652  decode.d3.loss_mask: 0.7569  decode.d3.loss_dice: 1.3090  decode.d4.loss_cls: 1.3805  decode.d4.loss_mask: 0.7360  decode.d4.loss_dice: 1.3277  decode.d5.loss_cls: 1.4603  decode.d5.loss_mask: 0.7301  decode.d5.loss_dice: 1.3051  decode.d6.loss_cls: 1.4820  decode.d6.loss_mask: 0.7293  decode.d6.loss_dice: 1.2965  decode.d7.loss_cls: 1.4420  decode.d7.loss_mask: 0.7084  decode.d7.loss_dice: 1.3004  decode.d8.loss_cls: 1.4920  decode.d8.loss_mask: 0.6887  decode.d8.loss_dice: 1.2953
2023/05/23 20:23:51 - mmengine - INFO - Iter(train) [ 17100/160000]  lr: 9.0328e-06  eta: 16:56:13  time: 0.4120  data_time: 0.0098  memory: 4844  grad_norm: 110.9902  loss: 42.6623  decode.loss_cls: 1.6637  decode.loss_mask: 0.8861  decode.loss_dice: 1.4945  decode.d0.loss_cls: 3.4612  decode.d0.loss_mask: 0.9080  decode.d0.loss_dice: 1.6380  decode.d1.loss_cls: 1.7008  decode.d1.loss_mask: 0.9626  decode.d1.loss_dice: 1.5940  decode.d2.loss_cls: 1.7331  decode.d2.loss_mask: 0.8858  decode.d2.loss_dice: 1.5331  decode.d3.loss_cls: 1.6972  decode.d3.loss_mask: 0.8818  decode.d3.loss_dice: 1.4830  decode.d4.loss_cls: 1.7126  decode.d4.loss_mask: 0.8947  decode.d4.loss_dice: 1.5026  decode.d5.loss_cls: 1.6289  decode.d5.loss_mask: 0.8553  decode.d5.loss_dice: 1.5123  decode.d6.loss_cls: 1.6143  decode.d6.loss_mask: 0.8652  decode.d6.loss_dice: 1.4856  decode.d7.loss_cls: 1.6498  decode.d7.loss_mask: 0.8926  decode.d7.loss_dice: 1.5015  decode.d8.loss_cls: 1.5911  decode.d8.loss_mask: 0.9317  decode.d8.loss_dice: 1.5013
2023/05/23 20:24:12 - mmengine - INFO - Iter(train) [ 17150/160000]  lr: 9.0300e-06  eta: 16:55:49  time: 0.4090  data_time: 0.0095  memory: 4829  grad_norm: 87.7379  loss: 46.6669  decode.loss_cls: 1.9138  decode.loss_mask: 0.8088  decode.loss_dice: 1.6996  decode.d0.loss_cls: 3.7748  decode.d0.loss_mask: 0.8635  decode.d0.loss_dice: 1.9428  decode.d1.loss_cls: 1.9737  decode.d1.loss_mask: 0.8574  decode.d1.loss_dice: 1.9263  decode.d2.loss_cls: 1.9630  decode.d2.loss_mask: 0.7854  decode.d2.loss_dice: 1.7650  decode.d3.loss_cls: 1.9946  decode.d3.loss_mask: 0.7909  decode.d3.loss_dice: 1.6830  decode.d4.loss_cls: 1.9571  decode.d4.loss_mask: 0.7822  decode.d4.loss_dice: 1.6857  decode.d5.loss_cls: 1.9182  decode.d5.loss_mask: 0.7865  decode.d5.loss_dice: 1.6969  decode.d6.loss_cls: 1.9017  decode.d6.loss_mask: 0.7775  decode.d6.loss_dice: 1.6853  decode.d7.loss_cls: 1.9008  decode.d7.loss_mask: 0.7748  decode.d7.loss_dice: 1.6667  decode.d8.loss_cls: 1.9258  decode.d8.loss_mask: 0.7835  decode.d8.loss_dice: 1.6817
2023/05/23 20:24:34 - mmengine - INFO - Iter(train) [ 17200/160000]  lr: 9.0271e-06  eta: 16:55:27  time: 0.4656  data_time: 0.0094  memory: 4893  grad_norm: 103.8631  loss: 31.8948  decode.loss_cls: 1.3166  decode.loss_mask: 0.7474  decode.loss_dice: 0.8884  decode.d0.loss_cls: 2.9880  decode.d0.loss_mask: 0.8072  decode.d0.loss_dice: 0.9716  decode.d1.loss_cls: 1.4759  decode.d1.loss_mask: 0.7817  decode.d1.loss_dice: 0.9663  decode.d2.loss_cls: 1.3950  decode.d2.loss_mask: 0.8038  decode.d2.loss_dice: 0.9265  decode.d3.loss_cls: 1.3240  decode.d3.loss_mask: 0.7904  decode.d3.loss_dice: 0.9024  decode.d4.loss_cls: 1.3239  decode.d4.loss_mask: 0.7791  decode.d4.loss_dice: 0.9001  decode.d5.loss_cls: 1.3168  decode.d5.loss_mask: 0.7607  decode.d5.loss_dice: 0.9038  decode.d6.loss_cls: 1.3467  decode.d6.loss_mask: 0.7382  decode.d6.loss_dice: 0.8686  decode.d7.loss_cls: 1.2871  decode.d7.loss_mask: 0.7323  decode.d7.loss_dice: 0.8768  decode.d8.loss_cls: 1.3139  decode.d8.loss_mask: 0.7586  decode.d8.loss_dice: 0.9031
2023/05/23 20:24:55 - mmengine - INFO - Iter(train) [ 17250/160000]  lr: 9.0243e-06  eta: 16:55:10  time: 0.4698  data_time: 0.0111  memory: 4889  grad_norm: 108.2294  loss: 39.0885  decode.loss_cls: 1.4575  decode.loss_mask: 0.9449  decode.loss_dice: 1.3228  decode.d0.loss_cls: 3.2689  decode.d0.loss_mask: 0.9729  decode.d0.loss_dice: 1.4566  decode.d1.loss_cls: 1.6044  decode.d1.loss_mask: 0.9300  decode.d1.loss_dice: 1.3750  decode.d2.loss_cls: 1.3630  decode.d2.loss_mask: 0.9241  decode.d2.loss_dice: 1.3966  decode.d3.loss_cls: 1.4684  decode.d3.loss_mask: 0.8974  decode.d3.loss_dice: 1.3017  decode.d4.loss_cls: 1.4564  decode.d4.loss_mask: 0.9079  decode.d4.loss_dice: 1.3116  decode.d5.loss_cls: 1.4631  decode.d5.loss_mask: 0.9148  decode.d5.loss_dice: 1.3222  decode.d6.loss_cls: 1.4482  decode.d6.loss_mask: 0.9000  decode.d6.loss_dice: 1.3098  decode.d7.loss_cls: 1.4488  decode.d7.loss_mask: 0.8988  decode.d7.loss_dice: 1.3173  decode.d8.loss_cls: 1.4504  decode.d8.loss_mask: 0.9002  decode.d8.loss_dice: 1.3549
2023/05/23 20:25:17 - mmengine - INFO - Iter(train) [ 17300/160000]  lr: 9.0214e-06  eta: 16:54:54  time: 0.4059  data_time: 0.0094  memory: 4869  grad_norm: 81.7655  loss: 32.2007  decode.loss_cls: 1.1292  decode.loss_mask: 0.7281  decode.loss_dice: 1.1340  decode.d0.loss_cls: 2.7841  decode.d0.loss_mask: 0.7927  decode.d0.loss_dice: 1.2825  decode.d1.loss_cls: 1.3341  decode.d1.loss_mask: 0.7411  decode.d1.loss_dice: 1.2276  decode.d2.loss_cls: 1.1439  decode.d2.loss_mask: 0.7386  decode.d2.loss_dice: 1.1943  decode.d3.loss_cls: 1.0839  decode.d3.loss_mask: 0.7521  decode.d3.loss_dice: 1.1828  decode.d4.loss_cls: 1.0594  decode.d4.loss_mask: 0.7661  decode.d4.loss_dice: 1.2126  decode.d5.loss_cls: 1.1111  decode.d5.loss_mask: 0.7295  decode.d5.loss_dice: 1.1546  decode.d6.loss_cls: 1.0535  decode.d6.loss_mask: 0.7634  decode.d6.loss_dice: 1.1791  decode.d7.loss_cls: 1.0752  decode.d7.loss_mask: 0.7448  decode.d7.loss_dice: 1.1242  decode.d8.loss_cls: 1.1077  decode.d8.loss_mask: 0.7299  decode.d8.loss_dice: 1.1406
2023/05/23 20:25:38 - mmengine - INFO - Iter(train) [ 17350/160000]  lr: 9.0186e-06  eta: 16:54:27  time: 0.4109  data_time: 0.0095  memory: 4859  grad_norm: 107.0583  loss: 48.8523  decode.loss_cls: 1.8175  decode.loss_mask: 1.1170  decode.loss_dice: 1.8071  decode.d0.loss_cls: 3.9297  decode.d0.loss_mask: 1.0264  decode.d0.loss_dice: 1.9323  decode.d1.loss_cls: 1.9657  decode.d1.loss_mask: 1.0206  decode.d1.loss_dice: 1.8350  decode.d2.loss_cls: 1.9428  decode.d2.loss_mask: 0.9700  decode.d2.loss_dice: 1.7531  decode.d3.loss_cls: 1.8888  decode.d3.loss_mask: 1.0143  decode.d3.loss_dice: 1.7402  decode.d4.loss_cls: 1.8072  decode.d4.loss_mask: 1.0522  decode.d4.loss_dice: 1.7485  decode.d5.loss_cls: 1.8054  decode.d5.loss_mask: 1.0468  decode.d5.loss_dice: 1.7721  decode.d6.loss_cls: 1.8139  decode.d6.loss_mask: 1.0747  decode.d6.loss_dice: 1.7324  decode.d7.loss_cls: 1.7683  decode.d7.loss_mask: 1.0853  decode.d7.loss_dice: 1.7548  decode.d8.loss_cls: 1.7923  decode.d8.loss_mask: 1.0740  decode.d8.loss_dice: 1.7638
2023/05/23 20:25:59 - mmengine - INFO - Iter(train) [ 17400/160000]  lr: 9.0158e-06  eta: 16:53:59  time: 0.4072  data_time: 0.0096  memory: 4845  grad_norm: 99.6929  loss: 33.4412  decode.loss_cls: 1.1713  decode.loss_mask: 0.8046  decode.loss_dice: 1.1343  decode.d0.loss_cls: 2.9608  decode.d0.loss_mask: 0.8801  decode.d0.loss_dice: 1.3280  decode.d1.loss_cls: 1.2704  decode.d1.loss_mask: 0.8142  decode.d1.loss_dice: 1.2568  decode.d2.loss_cls: 1.1770  decode.d2.loss_mask: 0.8131  decode.d2.loss_dice: 1.1675  decode.d3.loss_cls: 1.1098  decode.d3.loss_mask: 0.8364  decode.d3.loss_dice: 1.1382  decode.d4.loss_cls: 1.1115  decode.d4.loss_mask: 0.8300  decode.d4.loss_dice: 1.1548  decode.d5.loss_cls: 1.1606  decode.d5.loss_mask: 0.8480  decode.d5.loss_dice: 1.1735  decode.d6.loss_cls: 1.1087  decode.d6.loss_mask: 0.8385  decode.d6.loss_dice: 1.1412  decode.d7.loss_cls: 1.1633  decode.d7.loss_mask: 0.8286  decode.d7.loss_dice: 1.1298  decode.d8.loss_cls: 1.1381  decode.d8.loss_mask: 0.8146  decode.d8.loss_dice: 1.1377
2023/05/23 20:26:19 - mmengine - INFO - Iter(train) [ 17450/160000]  lr: 9.0129e-06  eta: 16:53:33  time: 0.4146  data_time: 0.0102  memory: 4876  grad_norm: 123.1254  loss: 35.9678  decode.loss_cls: 1.2740  decode.loss_mask: 0.7260  decode.loss_dice: 1.3176  decode.d0.loss_cls: 3.0860  decode.d0.loss_mask: 0.7695  decode.d0.loss_dice: 1.4992  decode.d1.loss_cls: 1.3933  decode.d1.loss_mask: 0.7286  decode.d1.loss_dice: 1.3991  decode.d2.loss_cls: 1.3518  decode.d2.loss_mask: 0.7491  decode.d2.loss_dice: 1.4068  decode.d3.loss_cls: 1.3705  decode.d3.loss_mask: 0.7406  decode.d3.loss_dice: 1.3945  decode.d4.loss_cls: 1.2993  decode.d4.loss_mask: 0.7622  decode.d4.loss_dice: 1.3441  decode.d5.loss_cls: 1.3281  decode.d5.loss_mask: 0.7108  decode.d5.loss_dice: 1.3088  decode.d6.loss_cls: 1.3127  decode.d6.loss_mask: 0.7460  decode.d6.loss_dice: 1.3142  decode.d7.loss_cls: 1.2629  decode.d7.loss_mask: 0.7273  decode.d7.loss_dice: 1.3203  decode.d8.loss_cls: 1.2892  decode.d8.loss_mask: 0.6956  decode.d8.loss_dice: 1.3396
2023/05/23 20:26:40 - mmengine - INFO - Iter(train) [ 17500/160000]  lr: 9.0101e-06  eta: 16:53:03  time: 0.4033  data_time: 0.0094  memory: 4835  grad_norm: 98.8983  loss: 41.0419  decode.loss_cls: 1.4255  decode.loss_mask: 0.9539  decode.loss_dice: 1.4534  decode.d0.loss_cls: 3.4223  decode.d0.loss_mask: 0.9691  decode.d0.loss_dice: 1.6939  decode.d1.loss_cls: 1.4586  decode.d1.loss_mask: 1.0444  decode.d1.loss_dice: 1.6202  decode.d2.loss_cls: 1.4318  decode.d2.loss_mask: 0.9412  decode.d2.loss_dice: 1.5132  decode.d3.loss_cls: 1.4841  decode.d3.loss_mask: 0.9068  decode.d3.loss_dice: 1.4665  decode.d4.loss_cls: 1.5213  decode.d4.loss_mask: 0.8915  decode.d4.loss_dice: 1.4415  decode.d5.loss_cls: 1.4486  decode.d5.loss_mask: 0.9781  decode.d5.loss_dice: 1.4890  decode.d6.loss_cls: 1.4303  decode.d6.loss_mask: 0.9684  decode.d6.loss_dice: 1.4228  decode.d7.loss_cls: 1.4100  decode.d7.loss_mask: 0.9824  decode.d7.loss_dice: 1.4609  decode.d8.loss_cls: 1.4236  decode.d8.loss_mask: 0.9531  decode.d8.loss_dice: 1.4355
2023/05/23 20:27:00 - mmengine - INFO - Iter(train) [ 17550/160000]  lr: 9.0072e-06  eta: 16:52:37  time: 0.4138  data_time: 0.0096  memory: 4906  grad_norm: 98.7858  loss: 58.2524  decode.loss_cls: 1.9961  decode.loss_mask: 1.0706  decode.loss_dice: 2.3108  decode.d0.loss_cls: 4.1703  decode.d0.loss_mask: 1.1357  decode.d0.loss_dice: 2.7502  decode.d1.loss_cls: 2.2182  decode.d1.loss_mask: 1.2215  decode.d1.loss_dice: 2.5731  decode.d2.loss_cls: 2.1397  decode.d2.loss_mask: 1.1564  decode.d2.loss_dice: 2.3851  decode.d3.loss_cls: 2.1531  decode.d3.loss_mask: 1.0737  decode.d3.loss_dice: 2.3620  decode.d4.loss_cls: 2.1798  decode.d4.loss_mask: 1.0868  decode.d4.loss_dice: 2.3795  decode.d5.loss_cls: 2.0540  decode.d5.loss_mask: 1.0812  decode.d5.loss_dice: 2.3768  decode.d6.loss_cls: 2.0433  decode.d6.loss_mask: 1.0958  decode.d6.loss_dice: 2.3024  decode.d7.loss_cls: 2.0425  decode.d7.loss_mask: 1.0756  decode.d7.loss_dice: 2.3375  decode.d8.loss_cls: 2.0977  decode.d8.loss_mask: 1.0815  decode.d8.loss_dice: 2.3016
2023/05/23 20:27:21 - mmengine - INFO - Iter(train) [ 17600/160000]  lr: 9.0044e-06  eta: 16:52:11  time: 0.4182  data_time: 0.0095  memory: 4908  grad_norm: 96.7594  loss: 49.8671  decode.loss_cls: 1.5850  decode.loss_mask: 1.0738  decode.loss_dice: 1.9999  decode.d0.loss_cls: 3.5513  decode.d0.loss_mask: 1.1895  decode.d0.loss_dice: 2.2081  decode.d1.loss_cls: 1.7328  decode.d1.loss_mask: 1.1604  decode.d1.loss_dice: 2.1542  decode.d2.loss_cls: 1.7016  decode.d2.loss_mask: 1.0748  decode.d2.loss_dice: 2.0720  decode.d3.loss_cls: 1.5957  decode.d3.loss_mask: 1.0249  decode.d3.loss_dice: 2.0381  decode.d4.loss_cls: 1.5973  decode.d4.loss_mask: 1.0324  decode.d4.loss_dice: 2.0549  decode.d5.loss_cls: 1.6762  decode.d5.loss_mask: 1.0619  decode.d5.loss_dice: 2.0579  decode.d6.loss_cls: 1.6689  decode.d6.loss_mask: 1.0543  decode.d6.loss_dice: 2.0529  decode.d7.loss_cls: 1.5456  decode.d7.loss_mask: 1.1036  decode.d7.loss_dice: 2.0677  decode.d8.loss_cls: 1.6200  decode.d8.loss_mask: 1.0923  decode.d8.loss_dice: 2.0190
2023/05/23 20:27:42 - mmengine - INFO - Iter(train) [ 17650/160000]  lr: 9.0015e-06  eta: 16:51:46  time: 0.4213  data_time: 0.0098  memory: 4845  grad_norm: 107.0752  loss: 42.2799  decode.loss_cls: 1.5830  decode.loss_mask: 0.9097  decode.loss_dice: 1.4744  decode.d0.loss_cls: 3.5218  decode.d0.loss_mask: 0.9209  decode.d0.loss_dice: 1.6555  decode.d1.loss_cls: 1.6836  decode.d1.loss_mask: 0.9168  decode.d1.loss_dice: 1.5576  decode.d2.loss_cls: 1.6628  decode.d2.loss_mask: 0.8913  decode.d2.loss_dice: 1.5164  decode.d3.loss_cls: 1.6470  decode.d3.loss_mask: 0.8652  decode.d3.loss_dice: 1.5018  decode.d4.loss_cls: 1.5371  decode.d4.loss_mask: 0.9267  decode.d4.loss_dice: 1.5136  decode.d5.loss_cls: 1.5702  decode.d5.loss_mask: 0.9071  decode.d5.loss_dice: 1.5124  decode.d6.loss_cls: 1.5710  decode.d6.loss_mask: 0.9301  decode.d6.loss_dice: 1.4501  decode.d7.loss_cls: 1.7100  decode.d7.loss_mask: 0.8781  decode.d7.loss_dice: 1.4873  decode.d8.loss_cls: 1.5696  decode.d8.loss_mask: 0.9142  decode.d8.loss_dice: 1.4948
2023/05/23 20:28:03 - mmengine - INFO - Iter(train) [ 17700/160000]  lr: 8.9987e-06  eta: 16:51:21  time: 0.4103  data_time: 0.0097  memory: 4943  grad_norm: 104.9593  loss: 34.0764  decode.loss_cls: 1.2174  decode.loss_mask: 0.7464  decode.loss_dice: 1.2007  decode.d0.loss_cls: 2.9965  decode.d0.loss_mask: 0.7913  decode.d0.loss_dice: 1.3222  decode.d1.loss_cls: 1.3882  decode.d1.loss_mask: 0.7143  decode.d1.loss_dice: 1.2142  decode.d2.loss_cls: 1.2736  decode.d2.loss_mask: 0.7406  decode.d2.loss_dice: 1.2088  decode.d3.loss_cls: 1.2199  decode.d3.loss_mask: 0.7514  decode.d3.loss_dice: 1.2633  decode.d4.loss_cls: 1.2306  decode.d4.loss_mask: 0.7603  decode.d4.loss_dice: 1.2489  decode.d5.loss_cls: 1.2241  decode.d5.loss_mask: 0.7631  decode.d5.loss_dice: 1.2300  decode.d6.loss_cls: 1.2320  decode.d6.loss_mask: 0.7757  decode.d6.loss_dice: 1.2107  decode.d7.loss_cls: 1.2595  decode.d7.loss_mask: 0.7360  decode.d7.loss_dice: 1.1794  decode.d8.loss_cls: 1.2337  decode.d8.loss_mask: 0.7505  decode.d8.loss_dice: 1.1930
2023/05/23 20:28:24 - mmengine - INFO - Iter(train) [ 17750/160000]  lr: 8.9958e-06  eta: 16:50:58  time: 0.4169  data_time: 0.0100  memory: 4839  grad_norm: 105.1535  loss: 51.5152  decode.loss_cls: 1.7676  decode.loss_mask: 1.0825  decode.loss_dice: 1.9569  decode.d0.loss_cls: 3.7608  decode.d0.loss_mask: 1.2093  decode.d0.loss_dice: 2.2897  decode.d1.loss_cls: 1.8525  decode.d1.loss_mask: 1.1989  decode.d1.loss_dice: 2.1309  decode.d2.loss_cls: 1.8150  decode.d2.loss_mask: 1.2018  decode.d2.loss_dice: 2.0830  decode.d3.loss_cls: 1.8896  decode.d3.loss_mask: 1.1261  decode.d3.loss_dice: 1.9694  decode.d4.loss_cls: 1.8349  decode.d4.loss_mask: 1.1422  decode.d4.loss_dice: 1.9589  decode.d5.loss_cls: 1.8261  decode.d5.loss_mask: 1.1075  decode.d5.loss_dice: 1.9153  decode.d6.loss_cls: 1.8160  decode.d6.loss_mask: 1.0561  decode.d6.loss_dice: 1.8939  decode.d7.loss_cls: 1.7953  decode.d7.loss_mask: 1.0903  decode.d7.loss_dice: 1.9288  decode.d8.loss_cls: 1.8125  decode.d8.loss_mask: 1.0685  decode.d8.loss_dice: 1.9347
2023/05/23 20:28:45 - mmengine - INFO - Iter(train) [ 17800/160000]  lr: 8.9930e-06  eta: 16:50:31  time: 0.4287  data_time: 0.0098  memory: 4817  grad_norm: 94.4640  loss: 36.7754  decode.loss_cls: 1.3578  decode.loss_mask: 0.7824  decode.loss_dice: 1.2041  decode.d0.loss_cls: 3.7883  decode.d0.loss_mask: 0.8317  decode.d0.loss_dice: 1.3316  decode.d1.loss_cls: 1.6977  decode.d1.loss_mask: 0.8204  decode.d1.loss_dice: 1.2599  decode.d2.loss_cls: 1.5448  decode.d2.loss_mask: 0.7998  decode.d2.loss_dice: 1.2334  decode.d3.loss_cls: 1.4202  decode.d3.loss_mask: 0.8042  decode.d3.loss_dice: 1.1921  decode.d4.loss_cls: 1.4026  decode.d4.loss_mask: 0.7901  decode.d4.loss_dice: 1.1893  decode.d5.loss_cls: 1.4452  decode.d5.loss_mask: 0.7726  decode.d5.loss_dice: 1.1885  decode.d6.loss_cls: 1.3593  decode.d6.loss_mask: 0.7867  decode.d6.loss_dice: 1.2074  decode.d7.loss_cls: 1.3078  decode.d7.loss_mask: 0.8089  decode.d7.loss_dice: 1.1805  decode.d8.loss_cls: 1.2885  decode.d8.loss_mask: 0.7866  decode.d8.loss_dice: 1.1934
2023/05/23 20:29:05 - mmengine - INFO - Iter(train) [ 17850/160000]  lr: 8.9901e-06  eta: 16:50:03  time: 0.4124  data_time: 0.0097  memory: 4778  grad_norm: 99.5326  loss: 35.1770  decode.loss_cls: 1.4735  decode.loss_mask: 0.7517  decode.loss_dice: 1.0317  decode.d0.loss_cls: 3.2445  decode.d0.loss_mask: 0.7945  decode.d0.loss_dice: 1.2071  decode.d1.loss_cls: 1.4950  decode.d1.loss_mask: 0.7923  decode.d1.loss_dice: 1.1161  decode.d2.loss_cls: 1.5595  decode.d2.loss_mask: 0.7461  decode.d2.loss_dice: 1.0711  decode.d3.loss_cls: 1.4859  decode.d3.loss_mask: 0.7393  decode.d3.loss_dice: 1.0334  decode.d4.loss_cls: 1.5284  decode.d4.loss_mask: 0.7317  decode.d4.loss_dice: 1.0729  decode.d5.loss_cls: 1.4881  decode.d5.loss_mask: 0.7686  decode.d5.loss_dice: 1.0885  decode.d6.loss_cls: 1.4632  decode.d6.loss_mask: 0.7509  decode.d6.loss_dice: 1.0479  decode.d7.loss_cls: 1.5425  decode.d7.loss_mask: 0.7393  decode.d7.loss_dice: 1.0773  decode.d8.loss_cls: 1.5543  decode.d8.loss_mask: 0.7279  decode.d8.loss_dice: 1.0540
2023/05/23 20:29:26 - mmengine - INFO - Iter(train) [ 17900/160000]  lr: 8.9873e-06  eta: 16:49:39  time: 0.4302  data_time: 0.0096  memory: 4848  grad_norm: 100.3914  loss: 41.5637  decode.loss_cls: 1.4999  decode.loss_mask: 0.8109  decode.loss_dice: 1.5716  decode.d0.loss_cls: 3.2691  decode.d0.loss_mask: 0.8368  decode.d0.loss_dice: 1.7523  decode.d1.loss_cls: 1.7196  decode.d1.loss_mask: 0.8243  decode.d1.loss_dice: 1.6644  decode.d2.loss_cls: 1.6521  decode.d2.loss_mask: 0.8277  decode.d2.loss_dice: 1.6422  decode.d3.loss_cls: 1.5290  decode.d3.loss_mask: 0.8319  decode.d3.loss_dice: 1.6038  decode.d4.loss_cls: 1.5665  decode.d4.loss_mask: 0.7935  decode.d4.loss_dice: 1.5874  decode.d5.loss_cls: 1.5022  decode.d5.loss_mask: 0.8178  decode.d5.loss_dice: 1.5753  decode.d6.loss_cls: 1.5280  decode.d6.loss_mask: 0.8174  decode.d6.loss_dice: 1.5663  decode.d7.loss_cls: 1.4971  decode.d7.loss_mask: 0.8265  decode.d7.loss_dice: 1.5806  decode.d8.loss_cls: 1.4643  decode.d8.loss_mask: 0.8206  decode.d8.loss_dice: 1.5846
2023/05/23 20:29:47 - mmengine - INFO - Iter(train) [ 17950/160000]  lr: 8.9845e-06  eta: 16:49:15  time: 0.4194  data_time: 0.0097  memory: 4945  grad_norm: 101.6665  loss: 36.3465  decode.loss_cls: 1.2889  decode.loss_mask: 0.7178  decode.loss_dice: 1.3284  decode.d0.loss_cls: 3.1109  decode.d0.loss_mask: 0.7229  decode.d0.loss_dice: 1.5202  decode.d1.loss_cls: 1.4027  decode.d1.loss_mask: 0.8023  decode.d1.loss_dice: 1.4949  decode.d2.loss_cls: 1.2793  decode.d2.loss_mask: 0.7807  decode.d2.loss_dice: 1.4233  decode.d3.loss_cls: 1.3565  decode.d3.loss_mask: 0.7000  decode.d3.loss_dice: 1.3456  decode.d4.loss_cls: 1.3274  decode.d4.loss_mask: 0.7087  decode.d4.loss_dice: 1.4044  decode.d5.loss_cls: 1.2994  decode.d5.loss_mask: 0.7320  decode.d5.loss_dice: 1.4174  decode.d6.loss_cls: 1.2863  decode.d6.loss_mask: 0.7410  decode.d6.loss_dice: 1.3779  decode.d7.loss_cls: 1.2683  decode.d7.loss_mask: 0.7366  decode.d7.loss_dice: 1.3766  decode.d8.loss_cls: 1.2639  decode.d8.loss_mask: 0.7225  decode.d8.loss_dice: 1.4096
2023/05/23 20:30:09 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:30:09 - mmengine - INFO - Iter(train) [ 18000/160000]  lr: 8.9816e-06  eta: 16:49:00  time: 0.4128  data_time: 0.0098  memory: 4877  grad_norm: 101.0182  loss: 38.0327  decode.loss_cls: 1.6219  decode.loss_mask: 0.8536  decode.loss_dice: 1.0493  decode.d0.loss_cls: 3.4929  decode.d0.loss_mask: 0.9858  decode.d0.loss_dice: 1.2554  decode.d1.loss_cls: 1.6494  decode.d1.loss_mask: 1.0216  decode.d1.loss_dice: 1.2074  decode.d2.loss_cls: 1.5812  decode.d2.loss_mask: 0.9144  decode.d2.loss_dice: 1.1515  decode.d3.loss_cls: 1.5737  decode.d3.loss_mask: 0.9480  decode.d3.loss_dice: 1.1336  decode.d4.loss_cls: 1.5482  decode.d4.loss_mask: 0.9207  decode.d4.loss_dice: 1.1220  decode.d5.loss_cls: 1.5584  decode.d5.loss_mask: 0.8896  decode.d5.loss_dice: 1.0725  decode.d6.loss_cls: 1.5900  decode.d6.loss_mask: 0.8783  decode.d6.loss_dice: 1.0521  decode.d7.loss_cls: 1.5420  decode.d7.loss_mask: 0.8862  decode.d7.loss_dice: 1.0668  decode.d8.loss_cls: 1.4890  decode.d8.loss_mask: 0.9156  decode.d8.loss_dice: 1.0612
2023/05/23 20:30:09 - mmengine - INFO - Saving checkpoint at 18000 iterations
2023/05/23 20:30:35 - mmengine - INFO - Iter(train) [ 18050/160000]  lr: 8.9788e-06  eta: 16:49:16  time: 0.4157  data_time: 0.0095  memory: 4863  grad_norm: 134.3113  loss: 37.6867  decode.loss_cls: 1.4809  decode.loss_mask: 0.6816  decode.loss_dice: 1.2880  decode.d0.loss_cls: 3.5110  decode.d0.loss_mask: 0.8401  decode.d0.loss_dice: 1.6220  decode.d1.loss_cls: 1.5285  decode.d1.loss_mask: 0.7138  decode.d1.loss_dice: 1.4520  decode.d2.loss_cls: 1.4547  decode.d2.loss_mask: 0.7090  decode.d2.loss_dice: 1.4621  decode.d3.loss_cls: 1.4051  decode.d3.loss_mask: 0.7154  decode.d3.loss_dice: 1.4042  decode.d4.loss_cls: 1.4048  decode.d4.loss_mask: 0.7106  decode.d4.loss_dice: 1.4007  decode.d5.loss_cls: 1.3664  decode.d5.loss_mask: 0.7134  decode.d5.loss_dice: 1.3989  decode.d6.loss_cls: 1.4013  decode.d6.loss_mask: 0.6801  decode.d6.loss_dice: 1.3533  decode.d7.loss_cls: 1.4185  decode.d7.loss_mask: 0.7095  decode.d7.loss_dice: 1.3646  decode.d8.loss_cls: 1.4297  decode.d8.loss_mask: 0.6952  decode.d8.loss_dice: 1.3714
2023/05/23 20:30:56 - mmengine - INFO - Iter(train) [ 18100/160000]  lr: 8.9759e-06  eta: 16:48:48  time: 0.4161  data_time: 0.0095  memory: 4838  grad_norm: 93.2456  loss: 36.6003  decode.loss_cls: 1.3622  decode.loss_mask: 0.8678  decode.loss_dice: 1.1554  decode.d0.loss_cls: 3.2567  decode.d0.loss_mask: 0.9844  decode.d0.loss_dice: 1.3166  decode.d1.loss_cls: 1.5255  decode.d1.loss_mask: 0.9134  decode.d1.loss_dice: 1.2712  decode.d2.loss_cls: 1.4946  decode.d2.loss_mask: 0.8940  decode.d2.loss_dice: 1.1889  decode.d3.loss_cls: 1.4427  decode.d3.loss_mask: 0.8768  decode.d3.loss_dice: 1.1697  decode.d4.loss_cls: 1.4430  decode.d4.loss_mask: 0.8452  decode.d4.loss_dice: 1.1280  decode.d5.loss_cls: 1.3975  decode.d5.loss_mask: 0.8309  decode.d5.loss_dice: 1.1713  decode.d6.loss_cls: 1.3723  decode.d6.loss_mask: 0.8287  decode.d6.loss_dice: 1.1430  decode.d7.loss_cls: 1.3632  decode.d7.loss_mask: 0.8356  decode.d7.loss_dice: 1.1610  decode.d8.loss_cls: 1.3898  decode.d8.loss_mask: 0.8440  decode.d8.loss_dice: 1.1267
2023/05/23 20:31:16 - mmengine - INFO - Iter(train) [ 18150/160000]  lr: 8.9731e-06  eta: 16:48:22  time: 0.4069  data_time: 0.0095  memory: 4896  grad_norm: 94.4345  loss: 45.5161  decode.loss_cls: 1.7504  decode.loss_mask: 0.8429  decode.loss_dice: 1.7259  decode.d0.loss_cls: 3.5281  decode.d0.loss_mask: 0.8664  decode.d0.loss_dice: 1.9471  decode.d1.loss_cls: 1.8783  decode.d1.loss_mask: 0.8543  decode.d1.loss_dice: 1.8298  decode.d2.loss_cls: 1.7469  decode.d2.loss_mask: 0.8452  decode.d2.loss_dice: 1.8058  decode.d3.loss_cls: 1.7227  decode.d3.loss_mask: 0.8633  decode.d3.loss_dice: 1.7305  decode.d4.loss_cls: 1.7965  decode.d4.loss_mask: 0.8357  decode.d4.loss_dice: 1.7493  decode.d5.loss_cls: 1.7604  decode.d5.loss_mask: 0.8176  decode.d5.loss_dice: 1.7266  decode.d6.loss_cls: 1.6537  decode.d6.loss_mask: 0.8450  decode.d6.loss_dice: 1.7483  decode.d7.loss_cls: 1.6557  decode.d7.loss_mask: 0.8423  decode.d7.loss_dice: 1.7682  decode.d8.loss_cls: 1.7088  decode.d8.loss_mask: 0.8841  decode.d8.loss_dice: 1.7863
2023/05/23 20:31:38 - mmengine - INFO - Iter(train) [ 18200/160000]  lr: 8.9702e-06  eta: 16:48:02  time: 0.4091  data_time: 0.0094  memory: 4908  grad_norm: 93.0385  loss: 38.5647  decode.loss_cls: 1.2552  decode.loss_mask: 0.7989  decode.loss_dice: 1.5401  decode.d0.loss_cls: 3.3747  decode.d0.loss_mask: 0.7349  decode.d0.loss_dice: 1.7239  decode.d1.loss_cls: 1.4756  decode.d1.loss_mask: 0.7544  decode.d1.loss_dice: 1.6307  decode.d2.loss_cls: 1.3481  decode.d2.loss_mask: 0.7395  decode.d2.loss_dice: 1.5778  decode.d3.loss_cls: 1.3420  decode.d3.loss_mask: 0.7214  decode.d3.loss_dice: 1.5237  decode.d4.loss_cls: 1.3738  decode.d4.loss_mask: 0.7334  decode.d4.loss_dice: 1.5372  decode.d5.loss_cls: 1.3093  decode.d5.loss_mask: 0.7723  decode.d5.loss_dice: 1.5680  decode.d6.loss_cls: 1.2799  decode.d6.loss_mask: 0.7644  decode.d6.loss_dice: 1.5276  decode.d7.loss_cls: 1.3105  decode.d7.loss_mask: 0.7524  decode.d7.loss_dice: 1.5083  decode.d8.loss_cls: 1.2867  decode.d8.loss_mask: 0.7729  decode.d8.loss_dice: 1.5272
2023/05/23 20:31:58 - mmengine - INFO - Iter(train) [ 18250/160000]  lr: 8.9674e-06  eta: 16:47:35  time: 0.4195  data_time: 0.0097  memory: 4855  grad_norm: 84.9748  loss: 39.7129  decode.loss_cls: 1.4904  decode.loss_mask: 0.8960  decode.loss_dice: 1.3050  decode.d0.loss_cls: 3.5291  decode.d0.loss_mask: 0.9016  decode.d0.loss_dice: 1.4660  decode.d1.loss_cls: 1.6874  decode.d1.loss_mask: 0.8792  decode.d1.loss_dice: 1.3848  decode.d2.loss_cls: 1.6206  decode.d2.loss_mask: 0.8885  decode.d2.loss_dice: 1.3349  decode.d3.loss_cls: 1.4699  decode.d3.loss_mask: 0.9421  decode.d3.loss_dice: 1.3308  decode.d4.loss_cls: 1.4769  decode.d4.loss_mask: 0.9377  decode.d4.loss_dice: 1.3216  decode.d5.loss_cls: 1.4605  decode.d5.loss_mask: 0.9017  decode.d5.loss_dice: 1.3034  decode.d6.loss_cls: 1.4960  decode.d6.loss_mask: 0.8998  decode.d6.loss_dice: 1.3063  decode.d7.loss_cls: 1.5261  decode.d7.loss_mask: 0.8956  decode.d7.loss_dice: 1.3497  decode.d8.loss_cls: 1.5147  decode.d8.loss_mask: 0.8865  decode.d8.loss_dice: 1.3103
2023/05/23 20:32:19 - mmengine - INFO - Iter(train) [ 18300/160000]  lr: 8.9645e-06  eta: 16:47:07  time: 0.4137  data_time: 0.0100  memory: 4805  grad_norm: 116.9140  loss: 36.8277  decode.loss_cls: 1.6168  decode.loss_mask: 0.7324  decode.loss_dice: 1.0363  decode.d0.loss_cls: 3.4255  decode.d0.loss_mask: 0.7901  decode.d0.loss_dice: 1.2125  decode.d1.loss_cls: 1.8478  decode.d1.loss_mask: 0.7568  decode.d1.loss_dice: 1.1823  decode.d2.loss_cls: 1.6011  decode.d2.loss_mask: 0.7707  decode.d2.loss_dice: 1.1217  decode.d3.loss_cls: 1.6467  decode.d3.loss_mask: 0.7195  decode.d3.loss_dice: 1.0655  decode.d4.loss_cls: 1.6379  decode.d4.loss_mask: 0.7203  decode.d4.loss_dice: 1.0702  decode.d5.loss_cls: 1.6359  decode.d5.loss_mask: 0.7197  decode.d5.loss_dice: 1.0822  decode.d6.loss_cls: 1.6535  decode.d6.loss_mask: 0.7124  decode.d6.loss_dice: 1.0621  decode.d7.loss_cls: 1.6030  decode.d7.loss_mask: 0.7506  decode.d7.loss_dice: 1.1247  decode.d8.loss_cls: 1.7016  decode.d8.loss_mask: 0.7245  decode.d8.loss_dice: 1.1035
2023/05/23 20:32:42 - mmengine - INFO - Iter(train) [ 18350/160000]  lr: 8.9617e-06  eta: 16:46:58  time: 0.4198  data_time: 0.0094  memory: 4885  grad_norm: 99.0654  loss: 40.7446  decode.loss_cls: 1.4720  decode.loss_mask: 0.9055  decode.loss_dice: 1.4177  decode.d0.loss_cls: 3.2830  decode.d0.loss_mask: 1.0476  decode.d0.loss_dice: 1.6330  decode.d1.loss_cls: 1.5574  decode.d1.loss_mask: 1.0250  decode.d1.loss_dice: 1.5639  decode.d2.loss_cls: 1.5322  decode.d2.loss_mask: 0.9215  decode.d2.loss_dice: 1.4552  decode.d3.loss_cls: 1.5343  decode.d3.loss_mask: 0.8710  decode.d3.loss_dice: 1.4324  decode.d4.loss_cls: 1.5233  decode.d4.loss_mask: 0.8929  decode.d4.loss_dice: 1.4126  decode.d5.loss_cls: 1.5093  decode.d5.loss_mask: 0.8983  decode.d5.loss_dice: 1.4363  decode.d6.loss_cls: 1.4815  decode.d6.loss_mask: 0.9076  decode.d6.loss_dice: 1.3906  decode.d7.loss_cls: 1.4757  decode.d7.loss_mask: 0.9340  decode.d7.loss_dice: 1.4549  decode.d8.loss_cls: 1.4281  decode.d8.loss_mask: 0.9224  decode.d8.loss_dice: 1.4254
2023/05/23 20:33:04 - mmengine - INFO - Iter(train) [ 18400/160000]  lr: 8.9588e-06  eta: 16:46:45  time: 0.4617  data_time: 0.0100  memory: 4865  grad_norm: 81.1785  loss: 48.0126  decode.loss_cls: 1.7265  decode.loss_mask: 0.9523  decode.loss_dice: 1.8305  decode.d0.loss_cls: 3.6098  decode.d0.loss_mask: 0.9278  decode.d0.loss_dice: 2.0669  decode.d1.loss_cls: 1.8941  decode.d1.loss_mask: 0.9358  decode.d1.loss_dice: 2.0118  decode.d2.loss_cls: 1.8725  decode.d2.loss_mask: 0.8883  decode.d2.loss_dice: 1.9499  decode.d3.loss_cls: 1.8272  decode.d3.loss_mask: 0.9119  decode.d3.loss_dice: 1.9000  decode.d4.loss_cls: 1.7790  decode.d4.loss_mask: 0.9177  decode.d4.loss_dice: 1.8980  decode.d5.loss_cls: 1.7521  decode.d5.loss_mask: 0.9177  decode.d5.loss_dice: 1.9048  decode.d6.loss_cls: 1.7616  decode.d6.loss_mask: 0.9228  decode.d6.loss_dice: 1.8507  decode.d7.loss_cls: 1.7628  decode.d7.loss_mask: 0.9201  decode.d7.loss_dice: 1.8378  decode.d8.loss_cls: 1.7162  decode.d8.loss_mask: 0.9182  decode.d8.loss_dice: 1.8476
2023/05/23 20:33:25 - mmengine - INFO - Iter(train) [ 18450/160000]  lr: 8.9560e-06  eta: 16:46:21  time: 0.4127  data_time: 0.0103  memory: 4836  grad_norm: 93.2824  loss: 31.3988  decode.loss_cls: 1.1762  decode.loss_mask: 0.7516  decode.loss_dice: 0.8878  decode.d0.loss_cls: 3.1419  decode.d0.loss_mask: 0.7585  decode.d0.loss_dice: 0.9817  decode.d1.loss_cls: 1.3560  decode.d1.loss_mask: 0.8077  decode.d1.loss_dice: 1.0048  decode.d2.loss_cls: 1.2762  decode.d2.loss_mask: 0.8046  decode.d2.loss_dice: 0.9414  decode.d3.loss_cls: 1.2366  decode.d3.loss_mask: 0.8174  decode.d3.loss_dice: 0.9399  decode.d4.loss_cls: 1.2360  decode.d4.loss_mask: 0.8140  decode.d4.loss_dice: 0.9339  decode.d5.loss_cls: 1.1656  decode.d5.loss_mask: 0.8178  decode.d5.loss_dice: 0.9525  decode.d6.loss_cls: 1.1671  decode.d6.loss_mask: 0.7755  decode.d6.loss_dice: 0.8872  decode.d7.loss_cls: 1.1771  decode.d7.loss_mask: 0.8077  decode.d7.loss_dice: 0.8970  decode.d8.loss_cls: 1.1785  decode.d8.loss_mask: 0.7931  decode.d8.loss_dice: 0.9137
2023/05/23 20:33:46 - mmengine - INFO - Iter(train) [ 18500/160000]  lr: 8.9531e-06  eta: 16:45:55  time: 0.4086  data_time: 0.0094  memory: 4901  grad_norm: 110.8070  loss: 37.5457  decode.loss_cls: 1.3088  decode.loss_mask: 0.9085  decode.loss_dice: 1.2319  decode.d0.loss_cls: 3.5532  decode.d0.loss_mask: 0.8941  decode.d0.loss_dice: 1.3518  decode.d1.loss_cls: 1.5745  decode.d1.loss_mask: 0.8953  decode.d1.loss_dice: 1.3730  decode.d2.loss_cls: 1.4108  decode.d2.loss_mask: 0.9448  decode.d2.loss_dice: 1.3104  decode.d3.loss_cls: 1.3321  decode.d3.loss_mask: 0.8590  decode.d3.loss_dice: 1.2553  decode.d4.loss_cls: 1.3573  decode.d4.loss_mask: 0.8262  decode.d4.loss_dice: 1.2379  decode.d5.loss_cls: 1.3891  decode.d5.loss_mask: 0.8639  decode.d5.loss_dice: 1.2335  decode.d6.loss_cls: 1.3841  decode.d6.loss_mask: 0.8873  decode.d6.loss_dice: 1.2180  decode.d7.loss_cls: 1.3712  decode.d7.loss_mask: 0.9063  decode.d7.loss_dice: 1.2245  decode.d8.loss_cls: 1.3351  decode.d8.loss_mask: 0.8867  decode.d8.loss_dice: 1.2212
2023/05/23 20:34:08 - mmengine - INFO - Iter(train) [ 18550/160000]  lr: 8.9503e-06  eta: 16:45:37  time: 0.4521  data_time: 0.0094  memory: 4962  grad_norm: 135.9241  loss: 28.8269  decode.loss_cls: 1.0153  decode.loss_mask: 0.7475  decode.loss_dice: 0.8224  decode.d0.loss_cls: 2.9531  decode.d0.loss_mask: 0.7471  decode.d0.loss_dice: 0.9455  decode.d1.loss_cls: 1.1596  decode.d1.loss_mask: 0.7503  decode.d1.loss_dice: 0.8647  decode.d2.loss_cls: 1.1772  decode.d2.loss_mask: 0.7431  decode.d2.loss_dice: 0.8293  decode.d3.loss_cls: 1.1365  decode.d3.loss_mask: 0.7525  decode.d3.loss_dice: 0.8286  decode.d4.loss_cls: 1.1510  decode.d4.loss_mask: 0.7667  decode.d4.loss_dice: 0.8621  decode.d5.loss_cls: 1.1155  decode.d5.loss_mask: 0.7392  decode.d5.loss_dice: 0.8703  decode.d6.loss_cls: 1.0659  decode.d6.loss_mask: 0.7441  decode.d6.loss_dice: 0.8400  decode.d7.loss_cls: 1.0578  decode.d7.loss_mask: 0.7446  decode.d7.loss_dice: 0.8052  decode.d8.loss_cls: 1.0319  decode.d8.loss_mask: 0.7434  decode.d8.loss_dice: 0.8163
2023/05/23 20:34:28 - mmengine - INFO - Iter(train) [ 18600/160000]  lr: 8.9474e-06  eta: 16:45:10  time: 0.4082  data_time: 0.0097  memory: 4819  grad_norm: 134.8190  loss: 39.8482  decode.loss_cls: 1.2059  decode.loss_mask: 0.9566  decode.loss_dice: 1.4463  decode.d0.loss_cls: 3.5293  decode.d0.loss_mask: 1.0148  decode.d0.loss_dice: 1.7775  decode.d1.loss_cls: 1.5025  decode.d1.loss_mask: 1.0039  decode.d1.loss_dice: 1.5409  decode.d2.loss_cls: 1.4432  decode.d2.loss_mask: 0.9814  decode.d2.loss_dice: 1.4355  decode.d3.loss_cls: 1.2586  decode.d3.loss_mask: 0.9646  decode.d3.loss_dice: 1.4735  decode.d4.loss_cls: 1.2317  decode.d4.loss_mask: 0.9979  decode.d4.loss_dice: 1.4810  decode.d5.loss_cls: 1.2086  decode.d5.loss_mask: 0.9852  decode.d5.loss_dice: 1.4723  decode.d6.loss_cls: 1.1940  decode.d6.loss_mask: 0.9985  decode.d6.loss_dice: 1.4444  decode.d7.loss_cls: 1.2108  decode.d7.loss_mask: 0.9679  decode.d7.loss_dice: 1.4295  decode.d8.loss_cls: 1.2342  decode.d8.loss_mask: 0.9646  decode.d8.loss_dice: 1.4931
2023/05/23 20:34:49 - mmengine - INFO - Iter(train) [ 18650/160000]  lr: 8.9446e-06  eta: 16:44:42  time: 0.4169  data_time: 0.0099  memory: 4875  grad_norm: 105.9724  loss: 44.3841  decode.loss_cls: 1.5100  decode.loss_mask: 0.8556  decode.loss_dice: 1.7509  decode.d0.loss_cls: 3.6455  decode.d0.loss_mask: 0.8948  decode.d0.loss_dice: 1.9887  decode.d1.loss_cls: 1.5805  decode.d1.loss_mask: 0.9111  decode.d1.loss_dice: 1.8386  decode.d2.loss_cls: 1.5574  decode.d2.loss_mask: 0.8131  decode.d2.loss_dice: 1.7886  decode.d3.loss_cls: 1.5385  decode.d3.loss_mask: 0.8557  decode.d3.loss_dice: 1.7578  decode.d4.loss_cls: 1.5756  decode.d4.loss_mask: 0.9108  decode.d4.loss_dice: 1.7360  decode.d5.loss_cls: 1.5812  decode.d5.loss_mask: 0.8704  decode.d5.loss_dice: 1.7527  decode.d6.loss_cls: 1.5738  decode.d6.loss_mask: 0.8655  decode.d6.loss_dice: 1.7714  decode.d7.loss_cls: 1.6031  decode.d7.loss_mask: 0.8556  decode.d7.loss_dice: 1.7642  decode.d8.loss_cls: 1.6265  decode.d8.loss_mask: 0.8552  decode.d8.loss_dice: 1.7555
2023/05/23 20:35:11 - mmengine - INFO - Iter(train) [ 18700/160000]  lr: 8.9417e-06  eta: 16:44:28  time: 0.4673  data_time: 0.0093  memory: 5113  grad_norm: 135.3372  loss: 38.2952  decode.loss_cls: 1.4463  decode.loss_mask: 0.7407  decode.loss_dice: 1.3290  decode.d0.loss_cls: 3.2205  decode.d0.loss_mask: 0.8039  decode.d0.loss_dice: 1.5576  decode.d1.loss_cls: 1.5839  decode.d1.loss_mask: 0.8284  decode.d1.loss_dice: 1.5233  decode.d2.loss_cls: 1.5536  decode.d2.loss_mask: 0.7896  decode.d2.loss_dice: 1.3935  decode.d3.loss_cls: 1.5785  decode.d3.loss_mask: 0.7483  decode.d3.loss_dice: 1.3801  decode.d4.loss_cls: 1.5048  decode.d4.loss_mask: 0.7563  decode.d4.loss_dice: 1.3505  decode.d5.loss_cls: 1.4890  decode.d5.loss_mask: 0.7306  decode.d5.loss_dice: 1.3781  decode.d6.loss_cls: 1.4487  decode.d6.loss_mask: 0.7431  decode.d6.loss_dice: 1.3559  decode.d7.loss_cls: 1.4218  decode.d7.loss_mask: 0.7582  decode.d7.loss_dice: 1.3415  decode.d8.loss_cls: 1.4664  decode.d8.loss_mask: 0.7467  decode.d8.loss_dice: 1.3265
2023/05/23 20:35:32 - mmengine - INFO - Iter(train) [ 18750/160000]  lr: 8.9389e-06  eta: 16:44:05  time: 0.4207  data_time: 0.0099  memory: 4906  grad_norm: 91.7123  loss: 51.9267  decode.loss_cls: 1.8666  decode.loss_mask: 0.9573  decode.loss_dice: 2.0339  decode.d0.loss_cls: 3.8658  decode.d0.loss_mask: 0.9800  decode.d0.loss_dice: 2.3279  decode.d1.loss_cls: 2.0483  decode.d1.loss_mask: 0.9683  decode.d1.loss_dice: 2.2883  decode.d2.loss_cls: 2.0185  decode.d2.loss_mask: 0.9904  decode.d2.loss_dice: 2.1701  decode.d3.loss_cls: 1.9056  decode.d3.loss_mask: 0.9323  decode.d3.loss_dice: 2.0811  decode.d4.loss_cls: 1.8888  decode.d4.loss_mask: 0.9436  decode.d4.loss_dice: 2.0889  decode.d5.loss_cls: 1.9165  decode.d5.loss_mask: 0.9293  decode.d5.loss_dice: 2.0644  decode.d6.loss_cls: 1.8642  decode.d6.loss_mask: 0.9157  decode.d6.loss_dice: 2.0642  decode.d7.loss_cls: 1.9188  decode.d7.loss_mask: 0.9513  decode.d7.loss_dice: 2.0510  decode.d8.loss_cls: 1.9057  decode.d8.loss_mask: 0.9442  decode.d8.loss_dice: 2.0457
2023/05/23 20:35:55 - mmengine - INFO - Iter(train) [ 18800/160000]  lr: 8.9361e-06  eta: 16:43:52  time: 0.4717  data_time: 0.0096  memory: 4845  grad_norm: 93.2119  loss: 39.7204  decode.loss_cls: 1.3642  decode.loss_mask: 0.9990  decode.loss_dice: 1.3230  decode.d0.loss_cls: 3.5824  decode.d0.loss_mask: 1.0219  decode.d0.loss_dice: 1.4706  decode.d1.loss_cls: 1.5674  decode.d1.loss_mask: 1.0076  decode.d1.loss_dice: 1.4013  decode.d2.loss_cls: 1.4426  decode.d2.loss_mask: 1.0455  decode.d2.loss_dice: 1.3708  decode.d3.loss_cls: 1.3949  decode.d3.loss_mask: 1.0104  decode.d3.loss_dice: 1.3503  decode.d4.loss_cls: 1.4217  decode.d4.loss_mask: 0.9668  decode.d4.loss_dice: 1.3349  decode.d5.loss_cls: 1.4052  decode.d5.loss_mask: 0.9979  decode.d5.loss_dice: 1.3389  decode.d6.loss_cls: 1.3948  decode.d6.loss_mask: 0.9875  decode.d6.loss_dice: 1.2643  decode.d7.loss_cls: 1.3621  decode.d7.loss_mask: 0.9845  decode.d7.loss_dice: 1.2952  decode.d8.loss_cls: 1.3598  decode.d8.loss_mask: 0.9609  decode.d8.loss_dice: 1.2942
2023/05/23 20:36:18 - mmengine - INFO - Iter(train) [ 18850/160000]  lr: 8.9332e-06  eta: 16:43:43  time: 0.4196  data_time: 0.0098  memory: 4857  grad_norm: 96.7385  loss: 29.2574  decode.loss_cls: 1.0737  decode.loss_mask: 0.7089  decode.loss_dice: 0.9072  decode.d0.loss_cls: 2.8655  decode.d0.loss_mask: 0.7619  decode.d0.loss_dice: 1.0457  decode.d1.loss_cls: 1.1543  decode.d1.loss_mask: 0.7334  decode.d1.loss_dice: 1.0606  decode.d2.loss_cls: 1.0918  decode.d2.loss_mask: 0.7260  decode.d2.loss_dice: 0.9864  decode.d3.loss_cls: 1.1221  decode.d3.loss_mask: 0.6933  decode.d3.loss_dice: 0.9492  decode.d4.loss_cls: 1.0208  decode.d4.loss_mask: 0.7260  decode.d4.loss_dice: 0.9084  decode.d5.loss_cls: 1.0082  decode.d5.loss_mask: 0.7594  decode.d5.loss_dice: 0.9240  decode.d6.loss_cls: 1.0470  decode.d6.loss_mask: 0.7270  decode.d6.loss_dice: 0.9416  decode.d7.loss_cls: 1.0488  decode.d7.loss_mask: 0.7154  decode.d7.loss_dice: 0.9410  decode.d8.loss_cls: 1.0271  decode.d8.loss_mask: 0.6751  decode.d8.loss_dice: 0.9078
2023/05/23 20:36:41 - mmengine - INFO - Iter(train) [ 18900/160000]  lr: 8.9304e-06  eta: 16:43:33  time: 0.4668  data_time: 0.0101  memory: 4833  grad_norm: 127.7067  loss: 39.8880  decode.loss_cls: 1.5884  decode.loss_mask: 0.7630  decode.loss_dice: 1.3026  decode.d0.loss_cls: 3.4730  decode.d0.loss_mask: 0.9134  decode.d0.loss_dice: 1.6211  decode.d1.loss_cls: 1.6569  decode.d1.loss_mask: 0.8637  decode.d1.loss_dice: 1.5207  decode.d2.loss_cls: 1.6318  decode.d2.loss_mask: 0.8237  decode.d2.loss_dice: 1.3977  decode.d3.loss_cls: 1.6501  decode.d3.loss_mask: 0.7724  decode.d3.loss_dice: 1.3409  decode.d4.loss_cls: 1.7059  decode.d4.loss_mask: 0.7709  decode.d4.loss_dice: 1.2933  decode.d5.loss_cls: 1.5893  decode.d5.loss_mask: 0.7931  decode.d5.loss_dice: 1.3536  decode.d6.loss_cls: 1.5963  decode.d6.loss_mask: 0.8078  decode.d6.loss_dice: 1.3033  decode.d7.loss_cls: 1.5715  decode.d7.loss_mask: 0.7807  decode.d7.loss_dice: 1.2926  decode.d8.loss_cls: 1.5955  decode.d8.loss_mask: 0.7861  decode.d8.loss_dice: 1.3288
2023/05/23 20:37:04 - mmengine - INFO - Iter(train) [ 18950/160000]  lr: 8.9275e-06  eta: 16:43:28  time: 0.4721  data_time: 0.0101  memory: 4835  grad_norm: 92.5695  loss: 44.8012  decode.loss_cls: 1.8002  decode.loss_mask: 0.8504  decode.loss_dice: 1.5778  decode.d0.loss_cls: 3.4627  decode.d0.loss_mask: 0.8788  decode.d0.loss_dice: 1.7201  decode.d1.loss_cls: 1.9001  decode.d1.loss_mask: 0.8381  decode.d1.loss_dice: 1.7062  decode.d2.loss_cls: 1.9582  decode.d2.loss_mask: 0.8488  decode.d2.loss_dice: 1.6038  decode.d3.loss_cls: 1.8578  decode.d3.loss_mask: 0.8470  decode.d3.loss_dice: 1.5302  decode.d4.loss_cls: 1.8909  decode.d4.loss_mask: 0.8341  decode.d4.loss_dice: 1.5821  decode.d5.loss_cls: 1.8627  decode.d5.loss_mask: 0.8382  decode.d5.loss_dice: 1.5807  decode.d6.loss_cls: 1.7927  decode.d6.loss_mask: 0.8504  decode.d6.loss_dice: 1.5945  decode.d7.loss_cls: 1.8329  decode.d7.loss_mask: 0.8406  decode.d7.loss_dice: 1.6283  decode.d8.loss_cls: 1.8113  decode.d8.loss_mask: 0.8365  decode.d8.loss_dice: 1.6450
2023/05/23 20:37:25 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:37:25 - mmengine - INFO - Iter(train) [ 19000/160000]  lr: 8.9247e-06  eta: 16:43:03  time: 0.4039  data_time: 0.0099  memory: 4886  grad_norm: 98.4032  loss: 34.6837  decode.loss_cls: 1.3742  decode.loss_mask: 0.7878  decode.loss_dice: 1.0952  decode.d0.loss_cls: 2.6738  decode.d0.loss_mask: 0.8634  decode.d0.loss_dice: 1.2788  decode.d1.loss_cls: 1.3833  decode.d1.loss_mask: 0.8130  decode.d1.loss_dice: 1.1694  decode.d2.loss_cls: 1.3884  decode.d2.loss_mask: 0.8603  decode.d2.loss_dice: 1.1387  decode.d3.loss_cls: 1.4915  decode.d3.loss_mask: 0.8178  decode.d3.loss_dice: 1.1355  decode.d4.loss_cls: 1.4353  decode.d4.loss_mask: 0.8365  decode.d4.loss_dice: 1.1214  decode.d5.loss_cls: 1.3568  decode.d5.loss_mask: 0.8015  decode.d5.loss_dice: 1.1124  decode.d6.loss_cls: 1.3384  decode.d6.loss_mask: 0.8213  decode.d6.loss_dice: 1.1077  decode.d7.loss_cls: 1.3460  decode.d7.loss_mask: 0.8126  decode.d7.loss_dice: 1.0904  decode.d8.loss_cls: 1.3254  decode.d8.loss_mask: 0.7985  decode.d8.loss_dice: 1.1081
2023/05/23 20:37:25 - mmengine - INFO - Saving checkpoint at 19000 iterations
2023/05/23 20:37:52 - mmengine - INFO - Iter(train) [ 19050/160000]  lr: 8.9218e-06  eta: 16:43:21  time: 0.4225  data_time: 0.0095  memory: 4866  grad_norm: 121.6627  loss: 44.1063  decode.loss_cls: 1.4713  decode.loss_mask: 0.9953  decode.loss_dice: 1.6177  decode.d0.loss_cls: 3.6502  decode.d0.loss_mask: 1.0632  decode.d0.loss_dice: 1.8866  decode.d1.loss_cls: 1.6885  decode.d1.loss_mask: 1.0459  decode.d1.loss_dice: 1.7777  decode.d2.loss_cls: 1.5588  decode.d2.loss_mask: 1.0133  decode.d2.loss_dice: 1.6847  decode.d3.loss_cls: 1.5506  decode.d3.loss_mask: 0.9818  decode.d3.loss_dice: 1.6576  decode.d4.loss_cls: 1.5518  decode.d4.loss_mask: 0.9897  decode.d4.loss_dice: 1.6287  decode.d5.loss_cls: 1.5236  decode.d5.loss_mask: 0.9527  decode.d5.loss_dice: 1.6210  decode.d6.loss_cls: 1.4987  decode.d6.loss_mask: 0.9867  decode.d6.loss_dice: 1.6107  decode.d7.loss_cls: 1.5064  decode.d7.loss_mask: 0.9654  decode.d7.loss_dice: 1.6022  decode.d8.loss_cls: 1.4661  decode.d8.loss_mask: 0.9766  decode.d8.loss_dice: 1.5829
2023/05/23 20:38:13 - mmengine - INFO - Iter(train) [ 19100/160000]  lr: 8.9190e-06  eta: 16:42:59  time: 0.4169  data_time: 0.0101  memory: 4846  grad_norm: 141.2939  loss: 36.2722  decode.loss_cls: 1.5380  decode.loss_mask: 0.7355  decode.loss_dice: 1.0983  decode.d0.loss_cls: 3.4156  decode.d0.loss_mask: 0.7525  decode.d0.loss_dice: 1.2752  decode.d1.loss_cls: 1.6769  decode.d1.loss_mask: 0.7773  decode.d1.loss_dice: 1.2347  decode.d2.loss_cls: 1.6012  decode.d2.loss_mask: 0.7235  decode.d2.loss_dice: 1.1416  decode.d3.loss_cls: 1.5540  decode.d3.loss_mask: 0.7545  decode.d3.loss_dice: 1.1144  decode.d4.loss_cls: 1.4776  decode.d4.loss_mask: 0.7441  decode.d4.loss_dice: 1.1357  decode.d5.loss_cls: 1.4969  decode.d5.loss_mask: 0.7641  decode.d5.loss_dice: 1.1352  decode.d6.loss_cls: 1.4907  decode.d6.loss_mask: 0.7919  decode.d6.loss_dice: 1.1308  decode.d7.loss_cls: 1.4356  decode.d7.loss_mask: 0.7830  decode.d7.loss_dice: 1.1351  decode.d8.loss_cls: 1.4152  decode.d8.loss_mask: 0.8062  decode.d8.loss_dice: 1.1369
2023/05/23 20:38:34 - mmengine - INFO - Iter(train) [ 19150/160000]  lr: 8.9161e-06  eta: 16:42:33  time: 0.4211  data_time: 0.0100  memory: 4835  grad_norm: 86.6461  loss: 36.0725  decode.loss_cls: 1.3896  decode.loss_mask: 0.6754  decode.loss_dice: 1.2599  decode.d0.loss_cls: 3.3643  decode.d0.loss_mask: 0.6668  decode.d0.loss_dice: 1.4336  decode.d1.loss_cls: 1.4755  decode.d1.loss_mask: 0.7795  decode.d1.loss_dice: 1.3788  decode.d2.loss_cls: 1.4252  decode.d2.loss_mask: 0.7079  decode.d2.loss_dice: 1.2894  decode.d3.loss_cls: 1.3740  decode.d3.loss_mask: 0.7239  decode.d3.loss_dice: 1.2864  decode.d4.loss_cls: 1.3845  decode.d4.loss_mask: 0.7215  decode.d4.loss_dice: 1.3320  decode.d5.loss_cls: 1.4117  decode.d5.loss_mask: 0.6967  decode.d5.loss_dice: 1.3019  decode.d6.loss_cls: 1.3735  decode.d6.loss_mask: 0.6885  decode.d6.loss_dice: 1.2591  decode.d7.loss_cls: 1.3627  decode.d7.loss_mask: 0.6748  decode.d7.loss_dice: 1.2697  decode.d8.loss_cls: 1.4168  decode.d8.loss_mask: 0.6777  decode.d8.loss_dice: 1.2712
2023/05/23 20:38:54 - mmengine - INFO - Iter(train) [ 19200/160000]  lr: 8.9133e-06  eta: 16:42:08  time: 0.4173  data_time: 0.0097  memory: 4919  grad_norm: 86.8407  loss: 46.3660  decode.loss_cls: 1.7221  decode.loss_mask: 0.9673  decode.loss_dice: 1.6909  decode.d0.loss_cls: 3.7671  decode.d0.loss_mask: 1.0173  decode.d0.loss_dice: 1.8914  decode.d1.loss_cls: 1.9720  decode.d1.loss_mask: 0.9464  decode.d1.loss_dice: 1.7381  decode.d2.loss_cls: 1.8507  decode.d2.loss_mask: 0.9157  decode.d2.loss_dice: 1.6221  decode.d3.loss_cls: 1.7798  decode.d3.loss_mask: 0.9891  decode.d3.loss_dice: 1.6643  decode.d4.loss_cls: 1.7271  decode.d4.loss_mask: 0.9622  decode.d4.loss_dice: 1.6284  decode.d5.loss_cls: 1.7343  decode.d5.loss_mask: 0.9593  decode.d5.loss_dice: 1.6724  decode.d6.loss_cls: 1.7930  decode.d6.loss_mask: 0.9471  decode.d6.loss_dice: 1.6579  decode.d7.loss_cls: 1.7580  decode.d7.loss_mask: 0.9416  decode.d7.loss_dice: 1.6832  decode.d8.loss_cls: 1.7564  decode.d8.loss_mask: 0.9317  decode.d8.loss_dice: 1.6794
2023/05/23 20:39:15 - mmengine - INFO - Iter(train) [ 19250/160000]  lr: 8.9104e-06  eta: 16:41:43  time: 0.4186  data_time: 0.0099  memory: 4944  grad_norm: 125.2851  loss: 47.3846  decode.loss_cls: 1.7345  decode.loss_mask: 1.0137  decode.loss_dice: 1.6609  decode.d0.loss_cls: 3.7411  decode.d0.loss_mask: 0.9924  decode.d0.loss_dice: 1.9060  decode.d1.loss_cls: 1.9605  decode.d1.loss_mask: 1.0011  decode.d1.loss_dice: 1.8871  decode.d2.loss_cls: 1.8223  decode.d2.loss_mask: 1.0475  decode.d2.loss_dice: 1.8132  decode.d3.loss_cls: 1.7643  decode.d3.loss_mask: 1.0504  decode.d3.loss_dice: 1.7437  decode.d4.loss_cls: 1.7888  decode.d4.loss_mask: 1.0570  decode.d4.loss_dice: 1.7597  decode.d5.loss_cls: 1.7371  decode.d5.loss_mask: 1.0188  decode.d5.loss_dice: 1.7208  decode.d6.loss_cls: 1.7445  decode.d6.loss_mask: 0.9461  decode.d6.loss_dice: 1.6757  decode.d7.loss_cls: 1.6955  decode.d7.loss_mask: 0.9918  decode.d7.loss_dice: 1.7323  decode.d8.loss_cls: 1.7034  decode.d8.loss_mask: 0.9820  decode.d8.loss_dice: 1.6922
2023/05/23 20:39:36 - mmengine - INFO - Iter(train) [ 19300/160000]  lr: 8.9076e-06  eta: 16:41:19  time: 0.4234  data_time: 0.0097  memory: 4847  grad_norm: 118.5289  loss: 41.9859  decode.loss_cls: 1.6492  decode.loss_mask: 0.8283  decode.loss_dice: 1.4227  decode.d0.loss_cls: 3.2900  decode.d0.loss_mask: 0.8848  decode.d0.loss_dice: 1.7156  decode.d1.loss_cls: 1.8227  decode.d1.loss_mask: 0.8819  decode.d1.loss_dice: 1.6218  decode.d2.loss_cls: 1.6731  decode.d2.loss_mask: 0.8845  decode.d2.loss_dice: 1.5160  decode.d3.loss_cls: 1.7666  decode.d3.loss_mask: 0.7946  decode.d3.loss_dice: 1.4140  decode.d4.loss_cls: 1.7202  decode.d4.loss_mask: 0.8139  decode.d4.loss_dice: 1.4881  decode.d5.loss_cls: 1.7171  decode.d5.loss_mask: 0.7962  decode.d5.loss_dice: 1.5088  decode.d6.loss_cls: 1.6741  decode.d6.loss_mask: 0.8139  decode.d6.loss_dice: 1.4215  decode.d7.loss_cls: 1.6796  decode.d7.loss_mask: 0.8051  decode.d7.loss_dice: 1.4480  decode.d8.loss_cls: 1.6679  decode.d8.loss_mask: 0.8240  decode.d8.loss_dice: 1.4420
2023/05/23 20:39:57 - mmengine - INFO - Iter(train) [ 19350/160000]  lr: 8.9047e-06  eta: 16:40:56  time: 0.4165  data_time: 0.0097  memory: 4788  grad_norm: 102.1286  loss: 39.4357  decode.loss_cls: 1.2689  decode.loss_mask: 0.9250  decode.loss_dice: 1.5302  decode.d0.loss_cls: 3.2796  decode.d0.loss_mask: 0.8322  decode.d0.loss_dice: 1.6498  decode.d1.loss_cls: 1.3649  decode.d1.loss_mask: 0.8839  decode.d1.loss_dice: 1.5762  decode.d2.loss_cls: 1.4593  decode.d2.loss_mask: 0.8420  decode.d2.loss_dice: 1.5248  decode.d3.loss_cls: 1.4135  decode.d3.loss_mask: 0.8353  decode.d3.loss_dice: 1.5101  decode.d4.loss_cls: 1.3411  decode.d4.loss_mask: 0.8830  decode.d4.loss_dice: 1.5150  decode.d5.loss_cls: 1.3598  decode.d5.loss_mask: 0.8592  decode.d5.loss_dice: 1.5100  decode.d6.loss_cls: 1.2921  decode.d6.loss_mask: 0.9054  decode.d6.loss_dice: 1.4947  decode.d7.loss_cls: 1.3017  decode.d7.loss_mask: 0.9062  decode.d7.loss_dice: 1.4805  decode.d8.loss_cls: 1.3081  decode.d8.loss_mask: 0.9002  decode.d8.loss_dice: 1.4831
2023/05/23 20:40:19 - mmengine - INFO - Iter(train) [ 19400/160000]  lr: 8.9019e-06  eta: 16:40:33  time: 0.4263  data_time: 0.0098  memory: 4835  grad_norm: 116.2783  loss: 35.0514  decode.loss_cls: 1.0518  decode.loss_mask: 0.8426  decode.loss_dice: 1.2554  decode.d0.loss_cls: 2.9793  decode.d0.loss_mask: 0.9827  decode.d0.loss_dice: 1.4308  decode.d1.loss_cls: 1.2549  decode.d1.loss_mask: 0.9416  decode.d1.loss_dice: 1.3421  decode.d2.loss_cls: 1.2559  decode.d2.loss_mask: 0.8714  decode.d2.loss_dice: 1.3072  decode.d3.loss_cls: 1.1732  decode.d3.loss_mask: 0.8610  decode.d3.loss_dice: 1.2803  decode.d4.loss_cls: 1.1563  decode.d4.loss_mask: 0.8666  decode.d4.loss_dice: 1.2750  decode.d5.loss_cls: 1.1799  decode.d5.loss_mask: 0.8346  decode.d5.loss_dice: 1.2665  decode.d6.loss_cls: 1.1114  decode.d6.loss_mask: 0.8554  decode.d6.loss_dice: 1.2839  decode.d7.loss_cls: 1.1394  decode.d7.loss_mask: 0.8378  decode.d7.loss_dice: 1.2498  decode.d8.loss_cls: 1.0902  decode.d8.loss_mask: 0.8429  decode.d8.loss_dice: 1.2314
2023/05/23 20:40:39 - mmengine - INFO - Iter(train) [ 19450/160000]  lr: 8.8990e-06  eta: 16:40:06  time: 0.4055  data_time: 0.0094  memory: 4858  grad_norm: 100.6291  loss: 41.5541  decode.loss_cls: 1.7419  decode.loss_mask: 0.8770  decode.loss_dice: 1.3113  decode.d0.loss_cls: 3.6047  decode.d0.loss_mask: 0.9086  decode.d0.loss_dice: 1.5854  decode.d1.loss_cls: 1.8576  decode.d1.loss_mask: 0.9379  decode.d1.loss_dice: 1.4769  decode.d2.loss_cls: 1.8063  decode.d2.loss_mask: 0.8270  decode.d2.loss_dice: 1.3628  decode.d3.loss_cls: 1.7246  decode.d3.loss_mask: 0.8693  decode.d3.loss_dice: 1.3173  decode.d4.loss_cls: 1.6311  decode.d4.loss_mask: 0.8906  decode.d4.loss_dice: 1.3270  decode.d5.loss_cls: 1.6609  decode.d5.loss_mask: 0.8704  decode.d5.loss_dice: 1.3320  decode.d6.loss_cls: 1.7675  decode.d6.loss_mask: 0.8454  decode.d6.loss_dice: 1.3094  decode.d7.loss_cls: 1.7269  decode.d7.loss_mask: 0.8699  decode.d7.loss_dice: 1.3073  decode.d8.loss_cls: 1.7026  decode.d8.loss_mask: 0.8257  decode.d8.loss_dice: 1.2787
2023/05/23 20:40:59 - mmengine - INFO - Iter(train) [ 19500/160000]  lr: 8.8962e-06  eta: 16:39:37  time: 0.4118  data_time: 0.0095  memory: 4876  grad_norm: 135.7290  loss: 43.6929  decode.loss_cls: 1.5782  decode.loss_mask: 0.8417  decode.loss_dice: 1.6774  decode.d0.loss_cls: 3.4996  decode.d0.loss_mask: 0.9105  decode.d0.loss_dice: 1.8861  decode.d1.loss_cls: 1.7898  decode.d1.loss_mask: 0.8731  decode.d1.loss_dice: 1.7797  decode.d2.loss_cls: 1.6230  decode.d2.loss_mask: 0.8904  decode.d2.loss_dice: 1.7433  decode.d3.loss_cls: 1.6155  decode.d3.loss_mask: 0.8780  decode.d3.loss_dice: 1.6898  decode.d4.loss_cls: 1.5743  decode.d4.loss_mask: 0.8677  decode.d4.loss_dice: 1.6947  decode.d5.loss_cls: 1.5658  decode.d5.loss_mask: 0.8628  decode.d5.loss_dice: 1.6820  decode.d6.loss_cls: 1.5854  decode.d6.loss_mask: 0.8469  decode.d6.loss_dice: 1.6617  decode.d7.loss_cls: 1.5240  decode.d7.loss_mask: 0.8692  decode.d7.loss_dice: 1.6830  decode.d8.loss_cls: 1.5452  decode.d8.loss_mask: 0.8389  decode.d8.loss_dice: 1.6153
2023/05/23 20:41:20 - mmengine - INFO - Iter(train) [ 19550/160000]  lr: 8.8933e-06  eta: 16:39:13  time: 0.4167  data_time: 0.0094  memory: 4945  grad_norm: 129.1377  loss: 38.6661  decode.loss_cls: 1.5092  decode.loss_mask: 0.7056  decode.loss_dice: 1.3865  decode.d0.loss_cls: 3.3692  decode.d0.loss_mask: 0.7862  decode.d0.loss_dice: 1.6842  decode.d1.loss_cls: 1.5697  decode.d1.loss_mask: 0.7523  decode.d1.loss_dice: 1.5437  decode.d2.loss_cls: 1.5875  decode.d2.loss_mask: 0.6928  decode.d2.loss_dice: 1.4794  decode.d3.loss_cls: 1.4955  decode.d3.loss_mask: 0.7013  decode.d3.loss_dice: 1.4374  decode.d4.loss_cls: 1.4594  decode.d4.loss_mask: 0.6869  decode.d4.loss_dice: 1.4469  decode.d5.loss_cls: 1.4716  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 1.4224  decode.d6.loss_cls: 1.4855  decode.d6.loss_mask: 0.6852  decode.d6.loss_dice: 1.4222  decode.d7.loss_cls: 1.4860  decode.d7.loss_mask: 0.6996  decode.d7.loss_dice: 1.4355  decode.d8.loss_cls: 1.4778  decode.d8.loss_mask: 0.6738  decode.d8.loss_dice: 1.4191
2023/05/23 20:41:41 - mmengine - INFO - Iter(train) [ 19600/160000]  lr: 8.8905e-06  eta: 16:38:45  time: 0.4062  data_time: 0.0092  memory: 4817  grad_norm: 90.5993  loss: 47.1947  decode.loss_cls: 1.8052  decode.loss_mask: 0.9693  decode.loss_dice: 1.6871  decode.d0.loss_cls: 3.6705  decode.d0.loss_mask: 0.9900  decode.d0.loss_dice: 1.8263  decode.d1.loss_cls: 1.8806  decode.d1.loss_mask: 0.9941  decode.d1.loss_dice: 1.8223  decode.d2.loss_cls: 1.9048  decode.d2.loss_mask: 0.9595  decode.d2.loss_dice: 1.7300  decode.d3.loss_cls: 1.9469  decode.d3.loss_mask: 0.9313  decode.d3.loss_dice: 1.6736  decode.d4.loss_cls: 1.9260  decode.d4.loss_mask: 0.9163  decode.d4.loss_dice: 1.6520  decode.d5.loss_cls: 1.7921  decode.d5.loss_mask: 0.9747  decode.d5.loss_dice: 1.6899  decode.d6.loss_cls: 1.8008  decode.d6.loss_mask: 0.9734  decode.d6.loss_dice: 1.7045  decode.d7.loss_cls: 1.8545  decode.d7.loss_mask: 0.9510  decode.d7.loss_dice: 1.7202  decode.d8.loss_cls: 1.7626  decode.d8.loss_mask: 0.9955  decode.d8.loss_dice: 1.6896
2023/05/23 20:42:02 - mmengine - INFO - Iter(train) [ 19650/160000]  lr: 8.8876e-06  eta: 16:38:23  time: 0.4293  data_time: 0.0099  memory: 4844  grad_norm: 115.9662  loss: 37.7585  decode.loss_cls: 1.3276  decode.loss_mask: 0.7905  decode.loss_dice: 1.3574  decode.d0.loss_cls: 3.3530  decode.d0.loss_mask: 0.8243  decode.d0.loss_dice: 1.5416  decode.d1.loss_cls: 1.5008  decode.d1.loss_mask: 0.8110  decode.d1.loss_dice: 1.5119  decode.d2.loss_cls: 1.4004  decode.d2.loss_mask: 0.8185  decode.d2.loss_dice: 1.4172  decode.d3.loss_cls: 1.3595  decode.d3.loss_mask: 0.7871  decode.d3.loss_dice: 1.3404  decode.d4.loss_cls: 1.3877  decode.d4.loss_mask: 0.8054  decode.d4.loss_dice: 1.4065  decode.d5.loss_cls: 1.3238  decode.d5.loss_mask: 0.7958  decode.d5.loss_dice: 1.3814  decode.d6.loss_cls: 1.3991  decode.d6.loss_mask: 0.7628  decode.d6.loss_dice: 1.3481  decode.d7.loss_cls: 1.3503  decode.d7.loss_mask: 0.7865  decode.d7.loss_dice: 1.3648  decode.d8.loss_cls: 1.3897  decode.d8.loss_mask: 0.7942  decode.d8.loss_dice: 1.3213
2023/05/23 20:42:23 - mmengine - INFO - Iter(train) [ 19700/160000]  lr: 8.8848e-06  eta: 16:37:58  time: 0.4211  data_time: 0.0100  memory: 4866  grad_norm: 132.3709  loss: 49.3885  decode.loss_cls: 1.7418  decode.loss_mask: 1.0403  decode.loss_dice: 1.8441  decode.d0.loss_cls: 3.7966  decode.d0.loss_mask: 1.0733  decode.d0.loss_dice: 2.0111  decode.d1.loss_cls: 1.8779  decode.d1.loss_mask: 1.1600  decode.d1.loss_dice: 1.9455  decode.d2.loss_cls: 1.7899  decode.d2.loss_mask: 1.0828  decode.d2.loss_dice: 1.9256  decode.d3.loss_cls: 1.7387  decode.d3.loss_mask: 1.1602  decode.d3.loss_dice: 1.9160  decode.d4.loss_cls: 1.7479  decode.d4.loss_mask: 1.1213  decode.d4.loss_dice: 1.8723  decode.d5.loss_cls: 1.7796  decode.d5.loss_mask: 1.0752  decode.d5.loss_dice: 1.8375  decode.d6.loss_cls: 1.7395  decode.d6.loss_mask: 1.0626  decode.d6.loss_dice: 1.8076  decode.d7.loss_cls: 1.7354  decode.d7.loss_mask: 1.0248  decode.d7.loss_dice: 1.8507  decode.d8.loss_cls: 1.7418  decode.d8.loss_mask: 1.0250  decode.d8.loss_dice: 1.8635
2023/05/23 20:42:44 - mmengine - INFO - Iter(train) [ 19750/160000]  lr: 8.8819e-06  eta: 16:37:34  time: 0.4053  data_time: 0.0096  memory: 4888  grad_norm: 88.6984  loss: 44.8972  decode.loss_cls: 1.6443  decode.loss_mask: 0.9455  decode.loss_dice: 1.5136  decode.d0.loss_cls: 3.8003  decode.d0.loss_mask: 1.0088  decode.d0.loss_dice: 1.8604  decode.d1.loss_cls: 1.8434  decode.d1.loss_mask: 0.9676  decode.d1.loss_dice: 1.6493  decode.d2.loss_cls: 1.7315  decode.d2.loss_mask: 1.0020  decode.d2.loss_dice: 1.6115  decode.d3.loss_cls: 1.7499  decode.d3.loss_mask: 0.9746  decode.d3.loss_dice: 1.5555  decode.d4.loss_cls: 1.7098  decode.d4.loss_mask: 0.9555  decode.d4.loss_dice: 1.5864  decode.d5.loss_cls: 1.6963  decode.d5.loss_mask: 0.9589  decode.d5.loss_dice: 1.5539  decode.d6.loss_cls: 1.7263  decode.d6.loss_mask: 0.9478  decode.d6.loss_dice: 1.5620  decode.d7.loss_cls: 1.6529  decode.d7.loss_mask: 0.9713  decode.d7.loss_dice: 1.5759  decode.d8.loss_cls: 1.6877  decode.d8.loss_mask: 0.9437  decode.d8.loss_dice: 1.5104
2023/05/23 20:43:05 - mmengine - INFO - Iter(train) [ 19800/160000]  lr: 8.8791e-06  eta: 16:37:11  time: 0.4217  data_time: 0.0097  memory: 4873  grad_norm: 104.3940  loss: 50.7993  decode.loss_cls: 1.7115  decode.loss_mask: 1.0639  decode.loss_dice: 1.8698  decode.d0.loss_cls: 3.9534  decode.d0.loss_mask: 1.1646  decode.d0.loss_dice: 2.2454  decode.d1.loss_cls: 1.8731  decode.d1.loss_mask: 1.1176  decode.d1.loss_dice: 2.1464  decode.d2.loss_cls: 1.7704  decode.d2.loss_mask: 1.0776  decode.d2.loss_dice: 2.0681  decode.d3.loss_cls: 1.7483  decode.d3.loss_mask: 1.1218  decode.d3.loss_dice: 2.0005  decode.d4.loss_cls: 1.6580  decode.d4.loss_mask: 1.1443  decode.d4.loss_dice: 1.9842  decode.d5.loss_cls: 1.7562  decode.d5.loss_mask: 1.0657  decode.d5.loss_dice: 1.9586  decode.d6.loss_cls: 1.7850  decode.d6.loss_mask: 1.0740  decode.d6.loss_dice: 1.9828  decode.d7.loss_cls: 1.7110  decode.d7.loss_mask: 1.0600  decode.d7.loss_dice: 1.9778  decode.d8.loss_cls: 1.6659  decode.d8.loss_mask: 1.0695  decode.d8.loss_dice: 1.9741
2023/05/23 20:43:26 - mmengine - INFO - Iter(train) [ 19850/160000]  lr: 8.8762e-06  eta: 16:36:45  time: 0.4123  data_time: 0.0096  memory: 4868  grad_norm: 93.3282  loss: 46.6428  decode.loss_cls: 1.6680  decode.loss_mask: 0.9470  decode.loss_dice: 1.7286  decode.d0.loss_cls: 3.8862  decode.d0.loss_mask: 0.9475  decode.d0.loss_dice: 2.0651  decode.d1.loss_cls: 1.7330  decode.d1.loss_mask: 1.0268  decode.d1.loss_dice: 1.9239  decode.d2.loss_cls: 1.7375  decode.d2.loss_mask: 0.9573  decode.d2.loss_dice: 1.8631  decode.d3.loss_cls: 1.6937  decode.d3.loss_mask: 0.9103  decode.d3.loss_dice: 1.8000  decode.d4.loss_cls: 1.6589  decode.d4.loss_mask: 0.9460  decode.d4.loss_dice: 1.7611  decode.d5.loss_cls: 1.6470  decode.d5.loss_mask: 0.9699  decode.d5.loss_dice: 1.7684  decode.d6.loss_cls: 1.6827  decode.d6.loss_mask: 0.9542  decode.d6.loss_dice: 1.7352  decode.d7.loss_cls: 1.6605  decode.d7.loss_mask: 0.9495  decode.d7.loss_dice: 1.6793  decode.d8.loss_cls: 1.6492  decode.d8.loss_mask: 0.9469  decode.d8.loss_dice: 1.7460
2023/05/23 20:43:46 - mmengine - INFO - Iter(train) [ 19900/160000]  lr: 8.8734e-06  eta: 16:36:18  time: 0.4072  data_time: 0.0093  memory: 4884  grad_norm: 113.5415  loss: 38.5907  decode.loss_cls: 1.2468  decode.loss_mask: 0.8879  decode.loss_dice: 1.3758  decode.d0.loss_cls: 3.5414  decode.d0.loss_mask: 0.9469  decode.d0.loss_dice: 1.6120  decode.d1.loss_cls: 1.4580  decode.d1.loss_mask: 0.9827  decode.d1.loss_dice: 1.4918  decode.d2.loss_cls: 1.3509  decode.d2.loss_mask: 0.9229  decode.d2.loss_dice: 1.4196  decode.d3.loss_cls: 1.2873  decode.d3.loss_mask: 0.9233  decode.d3.loss_dice: 1.4088  decode.d4.loss_cls: 1.2777  decode.d4.loss_mask: 0.9055  decode.d4.loss_dice: 1.4003  decode.d5.loss_cls: 1.2726  decode.d5.loss_mask: 0.9281  decode.d5.loss_dice: 1.4168  decode.d6.loss_cls: 1.2207  decode.d6.loss_mask: 0.9132  decode.d6.loss_dice: 1.3498  decode.d7.loss_cls: 1.2207  decode.d7.loss_mask: 0.9212  decode.d7.loss_dice: 1.3887  decode.d8.loss_cls: 1.1942  decode.d8.loss_mask: 0.9390  decode.d8.loss_dice: 1.3862
2023/05/23 20:44:07 - mmengine - INFO - Iter(train) [ 19950/160000]  lr: 8.8705e-06  eta: 16:35:57  time: 0.4122  data_time: 0.0098  memory: 4876  grad_norm: 177.7362  loss: 41.6580  decode.loss_cls: 1.3976  decode.loss_mask: 0.8280  decode.loss_dice: 1.5545  decode.d0.loss_cls: 3.3015  decode.d0.loss_mask: 0.8948  decode.d0.loss_dice: 1.7262  decode.d1.loss_cls: 1.6568  decode.d1.loss_mask: 0.8847  decode.d1.loss_dice: 1.8046  decode.d2.loss_cls: 1.5363  decode.d2.loss_mask: 0.9321  decode.d2.loss_dice: 1.7562  decode.d3.loss_cls: 1.5457  decode.d3.loss_mask: 0.8445  decode.d3.loss_dice: 1.5881  decode.d4.loss_cls: 1.4438  decode.d4.loss_mask: 0.8381  decode.d4.loss_dice: 1.6229  decode.d5.loss_cls: 1.4930  decode.d5.loss_mask: 0.8216  decode.d5.loss_dice: 1.6199  decode.d6.loss_cls: 1.4226  decode.d6.loss_mask: 0.8431  decode.d6.loss_dice: 1.6316  decode.d7.loss_cls: 1.4008  decode.d7.loss_mask: 0.8250  decode.d7.loss_dice: 1.6256  decode.d8.loss_cls: 1.4142  decode.d8.loss_mask: 0.8171  decode.d8.loss_dice: 1.5872
2023/05/23 20:44:28 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:44:28 - mmengine - INFO - Iter(train) [ 20000/160000]  lr: 8.8677e-06  eta: 16:35:32  time: 0.4352  data_time: 0.0096  memory: 4919  grad_norm: 91.1467  loss: 34.2600  decode.loss_cls: 1.4256  decode.loss_mask: 0.6234  decode.loss_dice: 1.1613  decode.d0.loss_cls: 3.0207  decode.d0.loss_mask: 0.6564  decode.d0.loss_dice: 1.3741  decode.d1.loss_cls: 1.4957  decode.d1.loss_mask: 0.6329  decode.d1.loss_dice: 1.2831  decode.d2.loss_cls: 1.4107  decode.d2.loss_mask: 0.6270  decode.d2.loss_dice: 1.2309  decode.d3.loss_cls: 1.3797  decode.d3.loss_mask: 0.6285  decode.d3.loss_dice: 1.1817  decode.d4.loss_cls: 1.3996  decode.d4.loss_mask: 0.6259  decode.d4.loss_dice: 1.2094  decode.d5.loss_cls: 1.4112  decode.d5.loss_mask: 0.6236  decode.d5.loss_dice: 1.1802  decode.d6.loss_cls: 1.4138  decode.d6.loss_mask: 0.6321  decode.d6.loss_dice: 1.2084  decode.d7.loss_cls: 1.4017  decode.d7.loss_mask: 0.6321  decode.d7.loss_dice: 1.1739  decode.d8.loss_cls: 1.3776  decode.d8.loss_mask: 0.6333  decode.d8.loss_dice: 1.2054
2023/05/23 20:44:28 - mmengine - INFO - Saving checkpoint at 20000 iterations
2023/05/23 20:44:38 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0801  data_time: 0.0019  memory: 2167  
2023/05/23 20:44:42 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:42  time: 0.0788  data_time: 0.0018  memory: 2216  
2023/05/23 20:44:46 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:37  time: 0.0795  data_time: 0.0018  memory: 2167  
2023/05/23 20:44:50 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0870  data_time: 0.0020  memory: 2104  
2023/05/23 20:44:55 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0908  data_time: 0.0021  memory: 2831  
2023/05/23 20:44:58 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0789  data_time: 0.0018  memory: 2167  
2023/05/23 20:45:03 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0818  data_time: 0.0020  memory: 2167  
2023/05/23 20:45:09 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.1889  data_time: 0.0023  memory: 2167  
2023/05/23 20:45:13 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0815  data_time: 0.0020  memory: 2944  
2023/05/23 20:45:17 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0804  data_time: 0.0020  memory: 2356  
2023/05/23 20:45:21 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0783  data_time: 0.0018  memory: 2217  
2023/05/23 20:45:26 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0958  data_time: 0.0017  memory: 2328  
2023/05/23 20:45:29 - mmengine - INFO - per class results:
2023/05/23 20:45:30 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 84.98 | 92.68 |
|     bicycle      | 64.87 | 77.73 |
|       car        | 57.22 |  72.1 |
|    motorcycle    | 79.72 | 88.87 |
|     airplane     | 76.47 | 90.61 |
|       bus        | 78.56 | 85.77 |
|      train       | 79.07 |  86.8 |
|      truck       | 49.62 | 69.23 |
|       boat       | 51.66 | 76.08 |
|  traffic light   | 60.03 | 83.45 |
|   fire hydrant   | 79.56 | 94.11 |
|    stop sign     |  86.9 |  91.2 |
|  parking meter   | 76.21 | 86.29 |
|      bench       | 44.19 | 65.45 |
|       bird       | 81.26 | 90.08 |
|       cat        |  85.9 | 94.38 |
|       dog        | 77.04 | 86.56 |
|      horse       | 77.83 | 89.58 |
|      sheep       | 85.36 | 90.44 |
|       cow        | 77.96 | 86.21 |
|     elephant     |  90.2 | 94.75 |
|       bear       |  91.8 | 94.58 |
|      zebra       | 89.92 | 93.09 |
|     giraffe      | 86.21 | 92.56 |
|     backpack     | 27.18 | 40.55 |
|     umbrella     | 76.35 | 86.42 |
|     handbag      | 25.36 | 57.08 |
|       tie        | 11.14 | 19.82 |
|     suitcase     | 71.45 | 81.38 |
|     frisbee      | 63.52 | 88.33 |
|       skis       | 25.04 | 33.87 |
|    snowboard     | 26.64 | 66.43 |
|   sports ball    | 52.98 | 65.88 |
|       kite       | 44.44 | 59.19 |
|   baseball bat   | 42.99 | 58.42 |
|  baseball glove  | 63.26 | 85.23 |
|    skateboard    | 46.08 | 65.39 |
|    surfboard     | 64.65 | 88.12 |
|  tennis racket   | 78.98 | 89.51 |
|      bottle      | 43.13 | 62.25 |
|    wine glass    | 54.19 | 70.29 |
|       cup        | 50.35 | 75.03 |
|       fork       |  13.8 |  16.8 |
|      knife       | 23.99 | 44.65 |
|      spoon       | 19.66 | 27.34 |
|       bowl       |  39.3 | 51.74 |
|      banana      |  62.0 | 87.77 |
|      apple       | 40.17 | 53.44 |
|     sandwich     | 38.22 | 48.82 |
|      orange      | 64.91 | 77.54 |
|     broccoli     | 54.33 | 67.31 |
|      carrot      | 52.51 | 69.24 |
|     hot dog      | 46.03 | 57.01 |
|      pizza       | 60.73 |  69.8 |
|      donut       | 59.78 |  69.2 |
|       cake       | 50.89 | 82.46 |
|      chair       | 35.41 | 62.48 |
|      couch       | 46.52 | 65.31 |
|   potted plant   | 27.38 | 41.31 |
|       bed        | 61.66 | 75.48 |
|   dining table   | 40.37 | 77.68 |
|      toilet      | 73.86 | 86.19 |
|        tv        | 68.11 |  78.4 |
|      laptop      | 70.65 | 89.46 |
|      mouse       | 69.56 | 88.74 |
|      remote      | 56.74 | 68.16 |
|     keyboard     | 64.85 | 76.48 |
|    cell phone    | 65.29 | 89.83 |
|    microwave     | 41.97 | 47.88 |
|       oven       | 48.13 | 71.74 |
|     toaster      |  0.0  |  0.0  |
|       sink       | 61.32 | 73.77 |
|   refrigerator   | 73.15 |  89.8 |
|       book       | 45.23 |  71.4 |
|      clock       | 68.94 | 75.32 |
|       vase       | 53.83 | 81.71 |
|     scissors     | 62.76 |  84.1 |
|    teddy bear    | 74.58 | 90.14 |
|    hair drier    | 36.76 | 36.84 |
|    toothbrush    | 21.21 | 28.71 |
|      banner      | 27.28 | 60.33 |
|     blanket      |  0.08 |  0.08 |
|      branch      | 20.49 | 38.73 |
|      bridge      | 27.03 | 34.52 |
|  building-other  | 50.06 | 73.56 |
|       bush       | 25.93 | 30.97 |
|     cabinet      | 51.79 | 64.88 |
|       cage       | 18.64 | 29.16 |
|    cardboard     | 34.32 | 45.92 |
|      carpet      |  45.4 | 67.86 |
|  ceiling-other   | 56.65 | 84.41 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 15.12 |  20.7 |
|      clouds      | 49.28 | 69.12 |
|     counter      | 23.61 | 33.42 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 58.88 | 74.66 |
|    desk-stuff    | 43.63 | 57.68 |
|       dirt       | 39.93 | 58.67 |
|    door-stuff    | 31.66 | 59.65 |
|      fence       | 29.14 | 49.07 |
|   floor-marble   |  0.0  |  0.0  |
|   floor-other    | 17.99 | 26.51 |
|   floor-stone    |  5.24 |  6.79 |
|    floor-tile    | 54.71 | 66.79 |
|    floor-wood    | 58.82 | 70.32 |
|      flower      | 41.66 | 58.72 |
|       fog        |  1.16 |  1.17 |
|    food-other    |  25.8 |  30.5 |
|      fruit       | 30.82 | 51.23 |
| furniture-other  | 13.56 |  19.0 |
|      grass       | 68.87 | 84.42 |
|      gravel      |  22.4 |  26.5 |
|   ground-other   |  3.34 |  3.95 |
|       hill       | 14.93 | 20.24 |
|      house       | 21.41 | 24.93 |
|      leaves      | 30.45 | 51.24 |
|      light       | 33.35 | 51.06 |
|       mat        |  0.0  |  0.0  |
|      metal       | 29.32 | 45.71 |
|   mirror-stuff   |  31.3 | 47.75 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 50.63 | 69.33 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  2.63 |  2.92 |
|       net        | 41.63 | 64.22 |
|      paper       | 22.36 | 29.64 |
|     pavement     | 45.54 |  64.1 |
|      pillow      |  6.13 | 15.86 |
|   plant-other    | 19.27 | 34.01 |
|     plastic      | 13.99 | 20.38 |
|     platform     |  24.0 | 36.42 |
|   playingfield   | 68.53 | 88.49 |
|     railing      |  3.41 |  5.03 |
|     railroad     | 59.32 | 72.34 |
|      river       | 39.39 | 53.87 |
|       road       | 59.62 | 83.07 |
|       rock       | 47.06 | 81.32 |
|       roof       | 14.37 | 19.96 |
|       rug        | 28.71 | 43.54 |
|      salad       |  0.19 |  0.21 |
|       sand       | 60.77 | 64.78 |
|       sea        | 82.83 | 93.84 |
|      shelf       | 32.69 | 46.79 |
|    sky-other     | 69.83 | 84.06 |
|    skyscraper    | 21.65 | 25.78 |
|       snow       | 88.53 | 93.54 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 21.24 | 35.56 |
|      stone       |  1.47 |  1.53 |
|      straw       | 27.06 | 34.86 |
| structural-other |  1.2  |  1.33 |
|      table       | 19.98 | 28.53 |
|       tent       |  5.22 |  6.4  |
|  textile-other   |  8.19 | 15.12 |
|      towel       | 27.25 | 35.88 |
|       tree       | 72.25 | 83.38 |
|    vegetable     |  29.0 | 32.36 |
|    wall-brick    | 44.53 |  54.9 |
|  wall-concrete   | 57.55 |  80.3 |
|    wall-other    | 15.97 | 24.29 |
|    wall-panel    | 10.36 | 12.12 |
|    wall-stone    | 34.72 | 44.14 |
|    wall-tile     | 61.26 |  75.4 |
|    wall-wood     | 34.88 | 48.28 |
|   water-other    | 22.71 | 31.03 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 46.12 | 54.77 |
|   window-other   | 40.87 | 59.46 |
|       wood       | 22.37 | 35.02 |
+------------------+-------+-------+
2023/05/23 20:45:30 - mmengine - INFO - Iter(val) [625/625]    aAcc: 68.7700  mIoU: 42.3200  mAcc: 54.7800  data_time: 0.0020  time: 0.0863
2023/05/23 20:45:30 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_15000.pth is removed
2023/05/23 20:45:33 - mmengine - INFO - The best checkpoint with 42.3200 mIoU at 20000 iter is saved to best_mIoU_iter_20000.pth.
2023/05/23 20:45:53 - mmengine - INFO - Iter(train) [ 20050/160000]  lr: 8.8648e-06  eta: 16:35:42  time: 0.4069  data_time: 0.0100  memory: 4861  grad_norm: 121.2017  loss: 39.3409  decode.loss_cls: 1.2672  decode.loss_mask: 0.8402  decode.loss_dice: 1.5018  decode.d0.loss_cls: 3.1667  decode.d0.loss_mask: 0.8352  decode.d0.loss_dice: 1.7299  decode.d1.loss_cls: 1.5300  decode.d1.loss_mask: 0.8195  decode.d1.loss_dice: 1.6140  decode.d2.loss_cls: 1.4843  decode.d2.loss_mask: 0.8023  decode.d2.loss_dice: 1.5372  decode.d3.loss_cls: 1.4170  decode.d3.loss_mask: 0.8337  decode.d3.loss_dice: 1.5582  decode.d4.loss_cls: 1.3131  decode.d4.loss_mask: 0.8443  decode.d4.loss_dice: 1.5514  decode.d5.loss_cls: 1.3537  decode.d5.loss_mask: 0.8538  decode.d5.loss_dice: 1.5513  decode.d6.loss_cls: 1.2760  decode.d6.loss_mask: 0.8521  decode.d6.loss_dice: 1.5420  decode.d7.loss_cls: 1.2834  decode.d7.loss_mask: 0.8347  decode.d7.loss_dice: 1.5254  decode.d8.loss_cls: 1.2708  decode.d8.loss_mask: 0.8395  decode.d8.loss_dice: 1.5122
2023/05/23 20:46:14 - mmengine - INFO - Iter(train) [ 20100/160000]  lr: 8.8620e-06  eta: 16:35:16  time: 0.4140  data_time: 0.0106  memory: 4787  grad_norm: 92.0008  loss: 35.3938  decode.loss_cls: 1.2480  decode.loss_mask: 0.9063  decode.loss_dice: 1.2194  decode.d0.loss_cls: 2.8800  decode.d0.loss_mask: 0.9042  decode.d0.loss_dice: 1.3130  decode.d1.loss_cls: 1.4044  decode.d1.loss_mask: 0.8780  decode.d1.loss_dice: 1.2291  decode.d2.loss_cls: 1.3112  decode.d2.loss_mask: 0.8347  decode.d2.loss_dice: 1.2439  decode.d3.loss_cls: 1.2967  decode.d3.loss_mask: 0.8476  decode.d3.loss_dice: 1.1901  decode.d4.loss_cls: 1.3019  decode.d4.loss_mask: 0.8265  decode.d4.loss_dice: 1.2118  decode.d5.loss_cls: 1.1984  decode.d5.loss_mask: 0.8655  decode.d5.loss_dice: 1.2506  decode.d6.loss_cls: 1.2290  decode.d6.loss_mask: 0.8939  decode.d6.loss_dice: 1.2027  decode.d7.loss_cls: 1.2189  decode.d7.loss_mask: 0.9238  decode.d7.loss_dice: 1.2087  decode.d8.loss_cls: 1.2296  decode.d8.loss_mask: 0.9030  decode.d8.loss_dice: 1.2230
2023/05/23 20:46:35 - mmengine - INFO - Iter(train) [ 20150/160000]  lr: 8.8591e-06  eta: 16:34:49  time: 0.4142  data_time: 0.0095  memory: 4800  grad_norm: 98.5267  loss: 41.7156  decode.loss_cls: 1.6597  decode.loss_mask: 0.7892  decode.loss_dice: 1.5201  decode.d0.loss_cls: 3.5834  decode.d0.loss_mask: 0.8729  decode.d0.loss_dice: 1.7291  decode.d1.loss_cls: 1.7591  decode.d1.loss_mask: 0.8135  decode.d1.loss_dice: 1.5720  decode.d2.loss_cls: 1.5963  decode.d2.loss_mask: 0.7494  decode.d2.loss_dice: 1.5236  decode.d3.loss_cls: 1.6470  decode.d3.loss_mask: 0.7467  decode.d3.loss_dice: 1.4961  decode.d4.loss_cls: 1.6542  decode.d4.loss_mask: 0.7719  decode.d4.loss_dice: 1.5062  decode.d5.loss_cls: 1.6402  decode.d5.loss_mask: 0.7911  decode.d5.loss_dice: 1.5061  decode.d6.loss_cls: 1.6248  decode.d6.loss_mask: 0.8060  decode.d6.loss_dice: 1.5080  decode.d7.loss_cls: 1.6035  decode.d7.loss_mask: 0.8077  decode.d7.loss_dice: 1.5087  decode.d8.loss_cls: 1.6008  decode.d8.loss_mask: 0.7953  decode.d8.loss_dice: 1.5331
2023/05/23 20:46:55 - mmengine - INFO - Iter(train) [ 20200/160000]  lr: 8.8563e-06  eta: 16:34:22  time: 0.4074  data_time: 0.0098  memory: 4858  grad_norm: 89.6564  loss: 32.2530  decode.loss_cls: 1.4043  decode.loss_mask: 0.6614  decode.loss_dice: 0.9786  decode.d0.loss_cls: 2.9821  decode.d0.loss_mask: 0.6884  decode.d0.loss_dice: 1.2169  decode.d1.loss_cls: 1.4809  decode.d1.loss_mask: 0.6627  decode.d1.loss_dice: 1.1289  decode.d2.loss_cls: 1.3451  decode.d2.loss_mask: 0.6616  decode.d2.loss_dice: 1.0348  decode.d3.loss_cls: 1.3692  decode.d3.loss_mask: 0.6372  decode.d3.loss_dice: 1.0214  decode.d4.loss_cls: 1.3050  decode.d4.loss_mask: 0.6425  decode.d4.loss_dice: 1.0465  decode.d5.loss_cls: 1.3604  decode.d5.loss_mask: 0.6542  decode.d5.loss_dice: 1.0278  decode.d6.loss_cls: 1.3417  decode.d6.loss_mask: 0.6359  decode.d6.loss_dice: 0.9806  decode.d7.loss_cls: 1.3368  decode.d7.loss_mask: 0.6520  decode.d7.loss_dice: 0.9968  decode.d8.loss_cls: 1.3571  decode.d8.loss_mask: 0.6445  decode.d8.loss_dice: 0.9975
2023/05/23 20:47:16 - mmengine - INFO - Iter(train) [ 20250/160000]  lr: 8.8534e-06  eta: 16:33:54  time: 0.4056  data_time: 0.0096  memory: 4829  grad_norm: 93.8369  loss: 33.6759  decode.loss_cls: 1.2944  decode.loss_mask: 0.7593  decode.loss_dice: 1.0889  decode.d0.loss_cls: 3.1620  decode.d0.loss_mask: 0.7708  decode.d0.loss_dice: 1.2635  decode.d1.loss_cls: 1.4215  decode.d1.loss_mask: 0.8034  decode.d1.loss_dice: 1.1061  decode.d2.loss_cls: 1.3366  decode.d2.loss_mask: 0.7765  decode.d2.loss_dice: 1.1051  decode.d3.loss_cls: 1.2602  decode.d3.loss_mask: 0.7571  decode.d3.loss_dice: 1.0817  decode.d4.loss_cls: 1.2458  decode.d4.loss_mask: 0.7435  decode.d4.loss_dice: 1.1028  decode.d5.loss_cls: 1.3127  decode.d5.loss_mask: 0.7661  decode.d5.loss_dice: 1.1323  decode.d6.loss_cls: 1.2462  decode.d6.loss_mask: 0.7477  decode.d6.loss_dice: 1.1013  decode.d7.loss_cls: 1.2771  decode.d7.loss_mask: 0.7648  decode.d7.loss_dice: 1.1021  decode.d8.loss_cls: 1.2906  decode.d8.loss_mask: 0.7451  decode.d8.loss_dice: 1.1108
2023/05/23 20:47:36 - mmengine - INFO - Iter(train) [ 20300/160000]  lr: 8.8506e-06  eta: 16:33:27  time: 0.4120  data_time: 0.0099  memory: 4839  grad_norm: 94.1253  loss: 39.3376  decode.loss_cls: 1.3334  decode.loss_mask: 0.9359  decode.loss_dice: 1.3171  decode.d0.loss_cls: 3.4829  decode.d0.loss_mask: 0.9761  decode.d0.loss_dice: 1.3930  decode.d1.loss_cls: 1.4681  decode.d1.loss_mask: 1.0107  decode.d1.loss_dice: 1.3773  decode.d2.loss_cls: 1.4180  decode.d2.loss_mask: 0.9997  decode.d2.loss_dice: 1.3734  decode.d3.loss_cls: 1.4164  decode.d3.loss_mask: 0.9695  decode.d3.loss_dice: 1.2814  decode.d4.loss_cls: 1.4136  decode.d4.loss_mask: 0.9725  decode.d4.loss_dice: 1.3322  decode.d5.loss_cls: 1.3815  decode.d5.loss_mask: 0.9479  decode.d5.loss_dice: 1.3368  decode.d6.loss_cls: 1.4433  decode.d6.loss_mask: 0.9591  decode.d6.loss_dice: 1.3345  decode.d7.loss_cls: 1.4162  decode.d7.loss_mask: 1.0053  decode.d7.loss_dice: 1.3513  decode.d8.loss_cls: 1.3695  decode.d8.loss_mask: 0.9869  decode.d8.loss_dice: 1.3343
2023/05/23 20:47:57 - mmengine - INFO - Iter(train) [ 20350/160000]  lr: 8.8477e-06  eta: 16:33:05  time: 0.4694  data_time: 0.0101  memory: 4920  grad_norm: 108.1258  loss: 26.0523  decode.loss_cls: 1.0213  decode.loss_mask: 0.5294  decode.loss_dice: 0.8179  decode.d0.loss_cls: 2.7511  decode.d0.loss_mask: 0.5430  decode.d0.loss_dice: 0.9172  decode.d1.loss_cls: 1.2292  decode.d1.loss_mask: 0.5213  decode.d1.loss_dice: 0.8329  decode.d2.loss_cls: 1.0793  decode.d2.loss_mask: 0.5440  decode.d2.loss_dice: 0.8549  decode.d3.loss_cls: 1.0041  decode.d3.loss_mask: 0.5280  decode.d3.loss_dice: 0.8306  decode.d4.loss_cls: 1.0720  decode.d4.loss_mask: 0.5609  decode.d4.loss_dice: 0.8331  decode.d5.loss_cls: 1.0580  decode.d5.loss_mask: 0.5404  decode.d5.loss_dice: 0.8409  decode.d6.loss_cls: 1.0854  decode.d6.loss_mask: 0.5313  decode.d6.loss_dice: 0.8086  decode.d7.loss_cls: 0.9947  decode.d7.loss_mask: 0.5227  decode.d7.loss_dice: 0.8419  decode.d8.loss_cls: 1.0533  decode.d8.loss_mask: 0.5167  decode.d8.loss_dice: 0.7881
2023/05/23 20:48:21 - mmengine - INFO - Iter(train) [ 20400/160000]  lr: 8.8449e-06  eta: 16:32:58  time: 0.4479  data_time: 0.0098  memory: 4876  grad_norm: 165.0584  loss: 38.6238  decode.loss_cls: 1.4734  decode.loss_mask: 0.7242  decode.loss_dice: 1.3036  decode.d0.loss_cls: 3.5945  decode.d0.loss_mask: 0.8214  decode.d0.loss_dice: 1.5572  decode.d1.loss_cls: 1.6833  decode.d1.loss_mask: 0.7532  decode.d1.loss_dice: 1.3997  decode.d2.loss_cls: 1.5324  decode.d2.loss_mask: 0.7297  decode.d2.loss_dice: 1.3831  decode.d3.loss_cls: 1.5320  decode.d3.loss_mask: 0.7532  decode.d3.loss_dice: 1.3658  decode.d4.loss_cls: 1.5849  decode.d4.loss_mask: 0.7056  decode.d4.loss_dice: 1.3446  decode.d5.loss_cls: 1.5890  decode.d5.loss_mask: 0.7047  decode.d5.loss_dice: 1.3608  decode.d6.loss_cls: 1.6017  decode.d6.loss_mask: 0.7013  decode.d6.loss_dice: 1.3126  decode.d7.loss_cls: 1.5076  decode.d7.loss_mask: 0.7250  decode.d7.loss_dice: 1.3180  decode.d8.loss_cls: 1.5001  decode.d8.loss_mask: 0.7201  decode.d8.loss_dice: 1.3411
2023/05/23 20:48:42 - mmengine - INFO - Iter(train) [ 20450/160000]  lr: 8.8420e-06  eta: 16:32:36  time: 0.4083  data_time: 0.0096  memory: 4837  grad_norm: 100.0609  loss: 40.1819  decode.loss_cls: 1.4308  decode.loss_mask: 0.9165  decode.loss_dice: 1.4413  decode.d0.loss_cls: 2.9978  decode.d0.loss_mask: 0.9851  decode.d0.loss_dice: 1.5876  decode.d1.loss_cls: 1.5259  decode.d1.loss_mask: 0.9130  decode.d1.loss_dice: 1.5614  decode.d2.loss_cls: 1.4072  decode.d2.loss_mask: 0.9205  decode.d2.loss_dice: 1.4914  decode.d3.loss_cls: 1.4151  decode.d3.loss_mask: 0.9509  decode.d3.loss_dice: 1.4768  decode.d4.loss_cls: 1.4779  decode.d4.loss_mask: 0.9437  decode.d4.loss_dice: 1.4719  decode.d5.loss_cls: 1.4148  decode.d5.loss_mask: 0.9519  decode.d5.loss_dice: 1.4802  decode.d6.loss_cls: 1.3674  decode.d6.loss_mask: 0.9680  decode.d6.loss_dice: 1.4475  decode.d7.loss_cls: 1.4147  decode.d7.loss_mask: 0.9542  decode.d7.loss_dice: 1.4443  decode.d8.loss_cls: 1.4331  decode.d8.loss_mask: 0.9357  decode.d8.loss_dice: 1.4555
2023/05/23 20:49:03 - mmengine - INFO - Iter(train) [ 20500/160000]  lr: 8.8392e-06  eta: 16:32:10  time: 0.4081  data_time: 0.0097  memory: 4829  grad_norm: 104.9948  loss: 49.0663  decode.loss_cls: 1.8314  decode.loss_mask: 1.1045  decode.loss_dice: 1.6863  decode.d0.loss_cls: 3.8480  decode.d0.loss_mask: 1.1137  decode.d0.loss_dice: 1.9203  decode.d1.loss_cls: 1.8244  decode.d1.loss_mask: 1.1775  decode.d1.loss_dice: 1.8707  decode.d2.loss_cls: 1.7228  decode.d2.loss_mask: 1.1911  decode.d2.loss_dice: 1.8448  decode.d3.loss_cls: 1.7687  decode.d3.loss_mask: 1.1456  decode.d3.loss_dice: 1.7590  decode.d4.loss_cls: 1.7226  decode.d4.loss_mask: 1.1634  decode.d4.loss_dice: 1.7324  decode.d5.loss_cls: 1.7501  decode.d5.loss_mask: 1.1388  decode.d5.loss_dice: 1.7194  decode.d6.loss_cls: 1.8841  decode.d6.loss_mask: 1.0999  decode.d6.loss_dice: 1.7043  decode.d7.loss_cls: 1.7844  decode.d7.loss_mask: 1.1918  decode.d7.loss_dice: 1.7316  decode.d8.loss_cls: 1.8681  decode.d8.loss_mask: 1.0803  decode.d8.loss_dice: 1.6865
2023/05/23 20:49:23 - mmengine - INFO - Iter(train) [ 20550/160000]  lr: 8.8363e-06  eta: 16:31:44  time: 0.4096  data_time: 0.0093  memory: 4812  grad_norm: 131.9325  loss: 38.9146  decode.loss_cls: 1.2166  decode.loss_mask: 0.9847  decode.loss_dice: 1.3326  decode.d0.loss_cls: 3.1225  decode.d0.loss_mask: 1.0368  decode.d0.loss_dice: 1.4784  decode.d1.loss_cls: 1.4994  decode.d1.loss_mask: 1.0545  decode.d1.loss_dice: 1.4438  decode.d2.loss_cls: 1.3233  decode.d2.loss_mask: 1.0696  decode.d2.loss_dice: 1.4197  decode.d3.loss_cls: 1.2887  decode.d3.loss_mask: 1.0111  decode.d3.loss_dice: 1.3766  decode.d4.loss_cls: 1.2522  decode.d4.loss_mask: 0.9692  decode.d4.loss_dice: 1.3928  decode.d5.loss_cls: 1.2809  decode.d5.loss_mask: 1.0229  decode.d5.loss_dice: 1.3746  decode.d6.loss_cls: 1.3407  decode.d6.loss_mask: 0.9937  decode.d6.loss_dice: 1.3547  decode.d7.loss_cls: 1.3190  decode.d7.loss_mask: 0.9891  decode.d7.loss_dice: 1.3578  decode.d8.loss_cls: 1.2561  decode.d8.loss_mask: 0.9950  decode.d8.loss_dice: 1.3576
2023/05/23 20:49:47 - mmengine - INFO - Iter(train) [ 20600/160000]  lr: 8.8335e-06  eta: 16:31:36  time: 0.4674  data_time: 0.0092  memory: 4868  grad_norm: 113.0937  loss: 45.5955  decode.loss_cls: 1.4159  decode.loss_mask: 0.9534  decode.loss_dice: 1.8601  decode.d0.loss_cls: 3.4646  decode.d0.loss_mask: 1.0726  decode.d0.loss_dice: 2.0988  decode.d1.loss_cls: 1.8459  decode.d1.loss_mask: 0.9953  decode.d1.loss_dice: 1.9698  decode.d2.loss_cls: 1.5512  decode.d2.loss_mask: 0.9666  decode.d2.loss_dice: 1.9013  decode.d3.loss_cls: 1.4559  decode.d3.loss_mask: 0.9701  decode.d3.loss_dice: 1.9280  decode.d4.loss_cls: 1.4374  decode.d4.loss_mask: 0.9749  decode.d4.loss_dice: 1.9017  decode.d5.loss_cls: 1.4018  decode.d5.loss_mask: 0.9741  decode.d5.loss_dice: 1.8680  decode.d6.loss_cls: 1.3586  decode.d6.loss_mask: 0.9610  decode.d6.loss_dice: 1.8467  decode.d7.loss_cls: 1.4133  decode.d7.loss_mask: 0.9768  decode.d7.loss_dice: 1.8398  decode.d8.loss_cls: 1.3789  decode.d8.loss_mask: 0.9701  decode.d8.loss_dice: 1.8427
2023/05/23 20:50:07 - mmengine - INFO - Iter(train) [ 20650/160000]  lr: 8.8306e-06  eta: 16:31:09  time: 0.4097  data_time: 0.0101  memory: 4845  grad_norm: 118.8677  loss: 41.0468  decode.loss_cls: 1.4641  decode.loss_mask: 0.8511  decode.loss_dice: 1.4098  decode.d0.loss_cls: 3.4492  decode.d0.loss_mask: 0.9034  decode.d0.loss_dice: 1.6098  decode.d1.loss_cls: 1.8157  decode.d1.loss_mask: 0.9314  decode.d1.loss_dice: 1.5335  decode.d2.loss_cls: 1.6948  decode.d2.loss_mask: 0.8940  decode.d2.loss_dice: 1.4979  decode.d3.loss_cls: 1.5211  decode.d3.loss_mask: 0.9192  decode.d3.loss_dice: 1.4565  decode.d4.loss_cls: 1.5681  decode.d4.loss_mask: 0.8788  decode.d4.loss_dice: 1.4336  decode.d5.loss_cls: 1.5492  decode.d5.loss_mask: 0.8959  decode.d5.loss_dice: 1.4435  decode.d6.loss_cls: 1.4921  decode.d6.loss_mask: 0.8735  decode.d6.loss_dice: 1.3896  decode.d7.loss_cls: 1.5204  decode.d7.loss_mask: 0.8540  decode.d7.loss_dice: 1.3957  decode.d8.loss_cls: 1.5047  decode.d8.loss_mask: 0.8564  decode.d8.loss_dice: 1.4397
2023/05/23 20:50:28 - mmengine - INFO - Iter(train) [ 20700/160000]  lr: 8.8278e-06  eta: 16:30:42  time: 0.4108  data_time: 0.0095  memory: 4926  grad_norm: 91.1768  loss: 52.4182  decode.loss_cls: 1.6325  decode.loss_mask: 1.0151  decode.loss_dice: 2.1957  decode.d0.loss_cls: 4.1732  decode.d0.loss_mask: 1.0666  decode.d0.loss_dice: 2.3888  decode.d1.loss_cls: 1.8898  decode.d1.loss_mask: 1.0433  decode.d1.loss_dice: 2.3419  decode.d2.loss_cls: 1.7106  decode.d2.loss_mask: 1.0500  decode.d2.loss_dice: 2.3341  decode.d3.loss_cls: 1.8565  decode.d3.loss_mask: 1.0574  decode.d3.loss_dice: 2.2542  decode.d4.loss_cls: 1.7198  decode.d4.loss_mask: 1.0146  decode.d4.loss_dice: 2.2324  decode.d5.loss_cls: 1.6892  decode.d5.loss_mask: 1.0061  decode.d5.loss_dice: 2.2390  decode.d6.loss_cls: 1.6611  decode.d6.loss_mask: 1.0234  decode.d6.loss_dice: 2.1861  decode.d7.loss_cls: 1.6426  decode.d7.loss_mask: 0.9913  decode.d7.loss_dice: 2.1893  decode.d8.loss_cls: 1.5999  decode.d8.loss_mask: 1.0067  decode.d8.loss_dice: 2.2069
2023/05/23 20:50:48 - mmengine - INFO - Iter(train) [ 20750/160000]  lr: 8.8249e-06  eta: 16:30:16  time: 0.4056  data_time: 0.0106  memory: 4846  grad_norm: 97.0625  loss: 36.2668  decode.loss_cls: 1.3280  decode.loss_mask: 0.9215  decode.loss_dice: 1.1121  decode.d0.loss_cls: 3.2055  decode.d0.loss_mask: 1.0282  decode.d0.loss_dice: 1.3063  decode.d1.loss_cls: 1.4808  decode.d1.loss_mask: 0.9209  decode.d1.loss_dice: 1.2239  decode.d2.loss_cls: 1.3806  decode.d2.loss_mask: 0.8844  decode.d2.loss_dice: 1.1343  decode.d3.loss_cls: 1.3661  decode.d3.loss_mask: 0.9126  decode.d3.loss_dice: 1.1261  decode.d4.loss_cls: 1.4174  decode.d4.loss_mask: 0.9013  decode.d4.loss_dice: 1.1127  decode.d5.loss_cls: 1.3857  decode.d5.loss_mask: 0.9020  decode.d5.loss_dice: 1.1393  decode.d6.loss_cls: 1.3351  decode.d6.loss_mask: 0.9174  decode.d6.loss_dice: 1.1069  decode.d7.loss_cls: 1.3344  decode.d7.loss_mask: 0.9151  decode.d7.loss_dice: 1.1205  decode.d8.loss_cls: 1.3047  decode.d8.loss_mask: 0.9267  decode.d8.loss_dice: 1.1162
2023/05/23 20:51:09 - mmengine - INFO - Iter(train) [ 20800/160000]  lr: 8.8221e-06  eta: 16:29:51  time: 0.4143  data_time: 0.0102  memory: 4857  grad_norm: 94.0088  loss: 35.1940  decode.loss_cls: 1.1391  decode.loss_mask: 0.7156  decode.loss_dice: 1.3877  decode.d0.loss_cls: 3.1885  decode.d0.loss_mask: 0.7298  decode.d0.loss_dice: 1.5069  decode.d1.loss_cls: 1.3449  decode.d1.loss_mask: 0.7477  decode.d1.loss_dice: 1.5224  decode.d2.loss_cls: 1.2862  decode.d2.loss_mask: 0.7021  decode.d2.loss_dice: 1.4221  decode.d3.loss_cls: 1.2712  decode.d3.loss_mask: 0.7014  decode.d3.loss_dice: 1.3605  decode.d4.loss_cls: 1.1721  decode.d4.loss_mask: 0.7004  decode.d4.loss_dice: 1.3355  decode.d5.loss_cls: 1.1439  decode.d5.loss_mask: 0.7140  decode.d5.loss_dice: 1.3964  decode.d6.loss_cls: 1.1915  decode.d6.loss_mask: 0.6963  decode.d6.loss_dice: 1.3646  decode.d7.loss_cls: 1.1914  decode.d7.loss_mask: 0.7064  decode.d7.loss_dice: 1.3296  decode.d8.loss_cls: 1.1180  decode.d8.loss_mask: 0.7318  decode.d8.loss_dice: 1.3759
2023/05/23 20:51:30 - mmengine - INFO - Iter(train) [ 20850/160000]  lr: 8.8192e-06  eta: 16:29:25  time: 0.4148  data_time: 0.0098  memory: 4839  grad_norm: 104.4992  loss: 44.8425  decode.loss_cls: 1.8777  decode.loss_mask: 0.9394  decode.loss_dice: 1.4349  decode.d0.loss_cls: 3.5983  decode.d0.loss_mask: 0.9952  decode.d0.loss_dice: 1.6181  decode.d1.loss_cls: 1.9122  decode.d1.loss_mask: 0.9984  decode.d1.loss_dice: 1.5489  decode.d2.loss_cls: 1.8575  decode.d2.loss_mask: 0.9654  decode.d2.loss_dice: 1.4617  decode.d3.loss_cls: 1.9372  decode.d3.loss_mask: 0.9714  decode.d3.loss_dice: 1.4940  decode.d4.loss_cls: 1.9211  decode.d4.loss_mask: 0.9585  decode.d4.loss_dice: 1.4641  decode.d5.loss_cls: 1.8710  decode.d5.loss_mask: 0.9498  decode.d5.loss_dice: 1.4333  decode.d6.loss_cls: 1.8505  decode.d6.loss_mask: 0.9545  decode.d6.loss_dice: 1.4278  decode.d7.loss_cls: 1.8334  decode.d7.loss_mask: 0.9395  decode.d7.loss_dice: 1.4241  decode.d8.loss_cls: 1.8096  decode.d8.loss_mask: 0.9410  decode.d8.loss_dice: 1.4540
2023/05/23 20:51:51 - mmengine - INFO - Iter(train) [ 20900/160000]  lr: 8.8164e-06  eta: 16:29:03  time: 0.4673  data_time: 0.0097  memory: 4866  grad_norm: 116.8573  loss: 34.9530  decode.loss_cls: 1.1996  decode.loss_mask: 0.8381  decode.loss_dice: 1.2234  decode.d0.loss_cls: 3.0769  decode.d0.loss_mask: 0.8427  decode.d0.loss_dice: 1.3618  decode.d1.loss_cls: 1.3153  decode.d1.loss_mask: 0.8287  decode.d1.loss_dice: 1.3225  decode.d2.loss_cls: 1.2979  decode.d2.loss_mask: 0.8002  decode.d2.loss_dice: 1.2340  decode.d3.loss_cls: 1.3233  decode.d3.loss_mask: 0.7859  decode.d3.loss_dice: 1.1855  decode.d4.loss_cls: 1.2578  decode.d4.loss_mask: 0.7880  decode.d4.loss_dice: 1.1896  decode.d5.loss_cls: 1.3099  decode.d5.loss_mask: 0.7688  decode.d5.loss_dice: 1.1895  decode.d6.loss_cls: 1.2520  decode.d6.loss_mask: 0.8261  decode.d6.loss_dice: 1.1900  decode.d7.loss_cls: 1.2632  decode.d7.loss_mask: 0.8326  decode.d7.loss_dice: 1.1948  decode.d8.loss_cls: 1.2072  decode.d8.loss_mask: 0.8253  decode.d8.loss_dice: 1.2224
2023/05/23 20:52:13 - mmengine - INFO - Iter(train) [ 20950/160000]  lr: 8.8135e-06  eta: 16:28:50  time: 0.4687  data_time: 0.0098  memory: 4846  grad_norm: 113.1627  loss: 29.9102  decode.loss_cls: 1.1041  decode.loss_mask: 0.6297  decode.loss_dice: 0.9879  decode.d0.loss_cls: 2.8846  decode.d0.loss_mask: 0.6609  decode.d0.loss_dice: 1.1241  decode.d1.loss_cls: 1.2812  decode.d1.loss_mask: 0.6468  decode.d1.loss_dice: 1.0527  decode.d2.loss_cls: 1.1597  decode.d2.loss_mask: 0.6357  decode.d2.loss_dice: 1.0486  decode.d3.loss_cls: 1.2327  decode.d3.loss_mask: 0.6209  decode.d3.loss_dice: 1.0167  decode.d4.loss_cls: 1.1083  decode.d4.loss_mask: 0.6619  decode.d4.loss_dice: 1.0193  decode.d5.loss_cls: 1.1574  decode.d5.loss_mask: 0.6445  decode.d5.loss_dice: 0.9835  decode.d6.loss_cls: 1.1887  decode.d6.loss_mask: 0.6191  decode.d6.loss_dice: 0.9306  decode.d7.loss_cls: 1.2238  decode.d7.loss_mask: 0.6130  decode.d7.loss_dice: 0.9326  decode.d8.loss_cls: 1.1594  decode.d8.loss_mask: 0.6288  decode.d8.loss_dice: 0.9530
2023/05/23 20:52:34 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:52:34 - mmengine - INFO - Iter(train) [ 21000/160000]  lr: 8.8106e-06  eta: 16:28:22  time: 0.4087  data_time: 0.0096  memory: 4855  grad_norm: 104.2045  loss: 42.0462  decode.loss_cls: 1.6605  decode.loss_mask: 0.7519  decode.loss_dice: 1.4998  decode.d0.loss_cls: 3.3790  decode.d0.loss_mask: 0.9086  decode.d0.loss_dice: 1.8284  decode.d1.loss_cls: 1.7896  decode.d1.loss_mask: 0.8184  decode.d1.loss_dice: 1.7079  decode.d2.loss_cls: 1.6940  decode.d2.loss_mask: 0.8051  decode.d2.loss_dice: 1.6007  decode.d3.loss_cls: 1.6611  decode.d3.loss_mask: 0.7839  decode.d3.loss_dice: 1.5166  decode.d4.loss_cls: 1.6753  decode.d4.loss_mask: 0.7859  decode.d4.loss_dice: 1.5380  decode.d5.loss_cls: 1.6200  decode.d5.loss_mask: 0.7834  decode.d5.loss_dice: 1.5303  decode.d6.loss_cls: 1.6501  decode.d6.loss_mask: 0.7809  decode.d6.loss_dice: 1.5261  decode.d7.loss_cls: 1.6133  decode.d7.loss_mask: 0.7731  decode.d7.loss_dice: 1.5095  decode.d8.loss_cls: 1.5935  decode.d8.loss_mask: 0.7717  decode.d8.loss_dice: 1.4898
2023/05/23 20:52:34 - mmengine - INFO - Saving checkpoint at 21000 iterations
2023/05/23 20:53:00 - mmengine - INFO - Iter(train) [ 21050/160000]  lr: 8.8078e-06  eta: 16:28:31  time: 0.4078  data_time: 0.0101  memory: 4836  grad_norm: 100.6494  loss: 43.7972  decode.loss_cls: 1.5726  decode.loss_mask: 0.9953  decode.loss_dice: 1.4932  decode.d0.loss_cls: 3.8156  decode.d0.loss_mask: 1.0245  decode.d0.loss_dice: 1.7839  decode.d1.loss_cls: 1.8540  decode.d1.loss_mask: 1.0208  decode.d1.loss_dice: 1.6323  decode.d2.loss_cls: 1.7400  decode.d2.loss_mask: 0.9768  decode.d2.loss_dice: 1.5258  decode.d3.loss_cls: 1.6150  decode.d3.loss_mask: 0.9595  decode.d3.loss_dice: 1.5176  decode.d4.loss_cls: 1.6156  decode.d4.loss_mask: 0.9511  decode.d4.loss_dice: 1.5234  decode.d5.loss_cls: 1.6114  decode.d5.loss_mask: 0.9620  decode.d5.loss_dice: 1.4908  decode.d6.loss_cls: 1.6083  decode.d6.loss_mask: 0.9691  decode.d6.loss_dice: 1.4814  decode.d7.loss_cls: 1.5815  decode.d7.loss_mask: 0.9774  decode.d7.loss_dice: 1.4850  decode.d8.loss_cls: 1.5811  decode.d8.loss_mask: 0.9455  decode.d8.loss_dice: 1.4871
2023/05/23 20:53:20 - mmengine - INFO - Iter(train) [ 21100/160000]  lr: 8.8049e-06  eta: 16:28:04  time: 0.4145  data_time: 0.0101  memory: 4865  grad_norm: 95.9323  loss: 40.1961  decode.loss_cls: 1.4007  decode.loss_mask: 0.8465  decode.loss_dice: 1.4754  decode.d0.loss_cls: 3.1312  decode.d0.loss_mask: 0.8562  decode.d0.loss_dice: 1.6431  decode.d1.loss_cls: 1.5855  decode.d1.loss_mask: 0.9150  decode.d1.loss_dice: 1.6307  decode.d2.loss_cls: 1.5666  decode.d2.loss_mask: 0.8525  decode.d2.loss_dice: 1.5493  decode.d3.loss_cls: 1.4554  decode.d3.loss_mask: 0.8714  decode.d3.loss_dice: 1.4702  decode.d4.loss_cls: 1.5192  decode.d4.loss_mask: 0.8480  decode.d4.loss_dice: 1.4830  decode.d5.loss_cls: 1.4675  decode.d5.loss_mask: 0.8489  decode.d5.loss_dice: 1.4850  decode.d6.loss_cls: 1.4297  decode.d6.loss_mask: 0.8697  decode.d6.loss_dice: 1.4950  decode.d7.loss_cls: 1.4029  decode.d7.loss_mask: 0.8710  decode.d7.loss_dice: 1.4851  decode.d8.loss_cls: 1.4092  decode.d8.loss_mask: 0.8443  decode.d8.loss_dice: 1.4878
2023/05/23 20:53:42 - mmengine - INFO - Iter(train) [ 21150/160000]  lr: 8.8021e-06  eta: 16:27:45  time: 0.4126  data_time: 0.0098  memory: 4815  grad_norm: 100.7437  loss: 42.4544  decode.loss_cls: 1.5328  decode.loss_mask: 0.8237  decode.loss_dice: 1.6004  decode.d0.loss_cls: 3.3181  decode.d0.loss_mask: 0.9487  decode.d0.loss_dice: 1.8865  decode.d1.loss_cls: 1.7441  decode.d1.loss_mask: 0.8710  decode.d1.loss_dice: 1.7458  decode.d2.loss_cls: 1.6116  decode.d2.loss_mask: 0.8706  decode.d2.loss_dice: 1.6416  decode.d3.loss_cls: 1.6063  decode.d3.loss_mask: 0.8240  decode.d3.loss_dice: 1.6159  decode.d4.loss_cls: 1.5653  decode.d4.loss_mask: 0.8348  decode.d4.loss_dice: 1.5923  decode.d5.loss_cls: 1.5375  decode.d5.loss_mask: 0.8100  decode.d5.loss_dice: 1.5970  decode.d6.loss_cls: 1.5058  decode.d6.loss_mask: 0.8459  decode.d6.loss_dice: 1.5942  decode.d7.loss_cls: 1.5845  decode.d7.loss_mask: 0.8070  decode.d7.loss_dice: 1.6014  decode.d8.loss_cls: 1.5130  decode.d8.loss_mask: 0.8301  decode.d8.loss_dice: 1.5946
2023/05/23 20:54:02 - mmengine - INFO - Iter(train) [ 21200/160000]  lr: 8.7992e-06  eta: 16:27:18  time: 0.4118  data_time: 0.0095  memory: 4860  grad_norm: 113.1022  loss: 39.5846  decode.loss_cls: 1.5009  decode.loss_mask: 0.9452  decode.loss_dice: 1.1782  decode.d0.loss_cls: 3.4056  decode.d0.loss_mask: 1.0108  decode.d0.loss_dice: 1.4356  decode.d1.loss_cls: 1.6677  decode.d1.loss_mask: 1.0061  decode.d1.loss_dice: 1.3577  decode.d2.loss_cls: 1.5563  decode.d2.loss_mask: 0.8944  decode.d2.loss_dice: 1.2595  decode.d3.loss_cls: 1.5932  decode.d3.loss_mask: 0.9134  decode.d3.loss_dice: 1.2326  decode.d4.loss_cls: 1.5594  decode.d4.loss_mask: 0.8872  decode.d4.loss_dice: 1.2543  decode.d5.loss_cls: 1.5412  decode.d5.loss_mask: 0.9044  decode.d5.loss_dice: 1.2425  decode.d6.loss_cls: 1.5806  decode.d6.loss_mask: 0.9341  decode.d6.loss_dice: 1.2407  decode.d7.loss_cls: 1.6146  decode.d7.loss_mask: 0.9423  decode.d7.loss_dice: 1.2046  decode.d8.loss_cls: 1.5746  decode.d8.loss_mask: 0.9586  decode.d8.loss_dice: 1.1881
2023/05/23 20:54:23 - mmengine - INFO - Iter(train) [ 21250/160000]  lr: 8.7964e-06  eta: 16:26:51  time: 0.4076  data_time: 0.0104  memory: 4821  grad_norm: 98.0650  loss: 45.6115  decode.loss_cls: 1.5674  decode.loss_mask: 0.9967  decode.loss_dice: 1.5812  decode.d0.loss_cls: 3.9839  decode.d0.loss_mask: 1.0543  decode.d0.loss_dice: 1.9098  decode.d1.loss_cls: 1.7982  decode.d1.loss_mask: 1.0767  decode.d1.loss_dice: 1.7925  decode.d2.loss_cls: 1.5949  decode.d2.loss_mask: 1.0188  decode.d2.loss_dice: 1.6484  decode.d3.loss_cls: 1.6136  decode.d3.loss_mask: 1.0258  decode.d3.loss_dice: 1.6102  decode.d4.loss_cls: 1.5722  decode.d4.loss_mask: 1.0783  decode.d4.loss_dice: 1.6370  decode.d5.loss_cls: 1.5585  decode.d5.loss_mask: 1.0777  decode.d5.loss_dice: 1.6620  decode.d6.loss_cls: 1.6129  decode.d6.loss_mask: 1.0375  decode.d6.loss_dice: 1.6288  decode.d7.loss_cls: 1.6161  decode.d7.loss_mask: 1.0300  decode.d7.loss_dice: 1.6420  decode.d8.loss_cls: 1.5466  decode.d8.loss_mask: 1.0141  decode.d8.loss_dice: 1.6254
2023/05/23 20:54:44 - mmengine - INFO - Iter(train) [ 21300/160000]  lr: 8.7935e-06  eta: 16:26:30  time: 0.4621  data_time: 0.0095  memory: 4858  grad_norm: 93.3133  loss: 39.0435  decode.loss_cls: 1.6528  decode.loss_mask: 0.7921  decode.loss_dice: 1.2106  decode.d0.loss_cls: 3.4425  decode.d0.loss_mask: 0.8505  decode.d0.loss_dice: 1.3762  decode.d1.loss_cls: 1.8653  decode.d1.loss_mask: 0.8075  decode.d1.loss_dice: 1.2606  decode.d2.loss_cls: 1.8432  decode.d2.loss_mask: 0.7257  decode.d2.loss_dice: 1.1754  decode.d3.loss_cls: 1.7281  decode.d3.loss_mask: 0.7866  decode.d3.loss_dice: 1.1632  decode.d4.loss_cls: 1.6828  decode.d4.loss_mask: 0.8106  decode.d4.loss_dice: 1.2185  decode.d5.loss_cls: 1.6373  decode.d5.loss_mask: 0.8091  decode.d5.loss_dice: 1.2030  decode.d6.loss_cls: 1.7076  decode.d6.loss_mask: 0.7704  decode.d6.loss_dice: 1.2154  decode.d7.loss_cls: 1.7013  decode.d7.loss_mask: 0.7785  decode.d7.loss_dice: 1.2020  decode.d8.loss_cls: 1.6404  decode.d8.loss_mask: 0.7810  decode.d8.loss_dice: 1.2053
2023/05/23 20:55:05 - mmengine - INFO - Iter(train) [ 21350/160000]  lr: 8.7907e-06  eta: 16:26:03  time: 0.4066  data_time: 0.0103  memory: 4859  grad_norm: 98.8577  loss: 35.7421  decode.loss_cls: 1.2858  decode.loss_mask: 0.8877  decode.loss_dice: 1.1192  decode.d0.loss_cls: 2.9687  decode.d0.loss_mask: 1.0115  decode.d0.loss_dice: 1.3166  decode.d1.loss_cls: 1.3982  decode.d1.loss_mask: 0.9976  decode.d1.loss_dice: 1.2200  decode.d2.loss_cls: 1.4082  decode.d2.loss_mask: 0.9356  decode.d2.loss_dice: 1.1628  decode.d3.loss_cls: 1.3801  decode.d3.loss_mask: 0.9189  decode.d3.loss_dice: 1.1189  decode.d4.loss_cls: 1.3103  decode.d4.loss_mask: 0.9673  decode.d4.loss_dice: 1.1224  decode.d5.loss_cls: 1.2787  decode.d5.loss_mask: 0.9508  decode.d5.loss_dice: 1.1417  decode.d6.loss_cls: 1.2472  decode.d6.loss_mask: 0.9435  decode.d6.loss_dice: 1.1337  decode.d7.loss_cls: 1.2827  decode.d7.loss_mask: 0.8945  decode.d7.loss_dice: 1.0825  decode.d8.loss_cls: 1.2806  decode.d8.loss_mask: 0.8934  decode.d8.loss_dice: 1.0830
2023/05/23 20:55:26 - mmengine - INFO - Iter(train) [ 21400/160000]  lr: 8.7878e-06  eta: 16:25:42  time: 0.4712  data_time: 0.0094  memory: 4846  grad_norm: 86.2090  loss: 38.3486  decode.loss_cls: 1.3975  decode.loss_mask: 0.9029  decode.loss_dice: 1.3903  decode.d0.loss_cls: 3.1724  decode.d0.loss_mask: 0.9512  decode.d0.loss_dice: 1.4476  decode.d1.loss_cls: 1.4531  decode.d1.loss_mask: 0.8855  decode.d1.loss_dice: 1.3454  decode.d2.loss_cls: 1.4223  decode.d2.loss_mask: 0.8977  decode.d2.loss_dice: 1.3538  decode.d3.loss_cls: 1.3725  decode.d3.loss_mask: 0.9283  decode.d3.loss_dice: 1.3989  decode.d4.loss_cls: 1.3214  decode.d4.loss_mask: 0.9259  decode.d4.loss_dice: 1.3738  decode.d5.loss_cls: 1.3732  decode.d5.loss_mask: 0.9013  decode.d5.loss_dice: 1.3310  decode.d6.loss_cls: 1.3957  decode.d6.loss_mask: 0.8983  decode.d6.loss_dice: 1.3717  decode.d7.loss_cls: 1.3226  decode.d7.loss_mask: 0.8831  decode.d7.loss_dice: 1.3318  decode.d8.loss_cls: 1.3575  decode.d8.loss_mask: 0.8965  decode.d8.loss_dice: 1.3455
2023/05/23 20:55:47 - mmengine - INFO - Iter(train) [ 21450/160000]  lr: 8.7850e-06  eta: 16:25:18  time: 0.4080  data_time: 0.0095  memory: 4858  grad_norm: 113.1089  loss: 33.8470  decode.loss_cls: 1.2072  decode.loss_mask: 0.8043  decode.loss_dice: 1.1164  decode.d0.loss_cls: 3.1332  decode.d0.loss_mask: 0.7841  decode.d0.loss_dice: 1.2794  decode.d1.loss_cls: 1.3146  decode.d1.loss_mask: 0.7900  decode.d1.loss_dice: 1.2099  decode.d2.loss_cls: 1.2543  decode.d2.loss_mask: 0.8011  decode.d2.loss_dice: 1.2243  decode.d3.loss_cls: 1.2838  decode.d3.loss_mask: 0.7741  decode.d3.loss_dice: 1.1496  decode.d4.loss_cls: 1.2381  decode.d4.loss_mask: 0.7583  decode.d4.loss_dice: 1.1358  decode.d5.loss_cls: 1.2632  decode.d5.loss_mask: 0.7623  decode.d5.loss_dice: 1.1050  decode.d6.loss_cls: 1.2487  decode.d6.loss_mask: 0.7810  decode.d6.loss_dice: 1.1434  decode.d7.loss_cls: 1.2524  decode.d7.loss_mask: 0.7717  decode.d7.loss_dice: 1.1082  decode.d8.loss_cls: 1.2637  decode.d8.loss_mask: 0.7749  decode.d8.loss_dice: 1.1142
2023/05/23 20:56:09 - mmengine - INFO - Iter(train) [ 21500/160000]  lr: 8.7821e-06  eta: 16:25:01  time: 0.4092  data_time: 0.0099  memory: 4905  grad_norm: 100.6450  loss: 44.9021  decode.loss_cls: 1.5089  decode.loss_mask: 1.1426  decode.loss_dice: 1.5243  decode.d0.loss_cls: 3.7290  decode.d0.loss_mask: 1.1266  decode.d0.loss_dice: 1.8222  decode.d1.loss_cls: 1.5842  decode.d1.loss_mask: 1.2838  decode.d1.loss_dice: 1.7135  decode.d2.loss_cls: 1.5366  decode.d2.loss_mask: 1.1919  decode.d2.loss_dice: 1.6203  decode.d3.loss_cls: 1.4985  decode.d3.loss_mask: 1.0672  decode.d3.loss_dice: 1.5562  decode.d4.loss_cls: 1.5436  decode.d4.loss_mask: 1.1431  decode.d4.loss_dice: 1.5852  decode.d5.loss_cls: 1.4983  decode.d5.loss_mask: 1.1358  decode.d5.loss_dice: 1.5548  decode.d6.loss_cls: 1.5259  decode.d6.loss_mask: 1.0966  decode.d6.loss_dice: 1.5086  decode.d7.loss_cls: 1.5662  decode.d7.loss_mask: 1.1174  decode.d7.loss_dice: 1.5305  decode.d8.loss_cls: 1.5106  decode.d8.loss_mask: 1.1407  decode.d8.loss_dice: 1.5389
2023/05/23 20:56:30 - mmengine - INFO - Iter(train) [ 21550/160000]  lr: 8.7793e-06  eta: 16:24:35  time: 0.4131  data_time: 0.0101  memory: 4904  grad_norm: 113.6056  loss: 33.4470  decode.loss_cls: 1.2267  decode.loss_mask: 0.7937  decode.loss_dice: 1.0952  decode.d0.loss_cls: 2.9415  decode.d0.loss_mask: 0.8307  decode.d0.loss_dice: 1.2662  decode.d1.loss_cls: 1.3062  decode.d1.loss_mask: 0.8636  decode.d1.loss_dice: 1.2156  decode.d2.loss_cls: 1.2320  decode.d2.loss_mask: 0.7660  decode.d2.loss_dice: 1.1429  decode.d3.loss_cls: 1.2447  decode.d3.loss_mask: 0.7634  decode.d3.loss_dice: 1.1411  decode.d4.loss_cls: 1.2633  decode.d4.loss_mask: 0.7550  decode.d4.loss_dice: 1.1259  decode.d5.loss_cls: 1.2758  decode.d5.loss_mask: 0.7587  decode.d5.loss_dice: 1.1108  decode.d6.loss_cls: 1.2035  decode.d6.loss_mask: 0.7831  decode.d6.loss_dice: 1.0787  decode.d7.loss_cls: 1.2259  decode.d7.loss_mask: 0.7913  decode.d7.loss_dice: 1.1108  decode.d8.loss_cls: 1.2644  decode.d8.loss_mask: 0.7893  decode.d8.loss_dice: 1.0810
2023/05/23 20:56:50 - mmengine - INFO - Iter(train) [ 21600/160000]  lr: 8.7764e-06  eta: 16:24:09  time: 0.4077  data_time: 0.0095  memory: 4946  grad_norm: 120.0138  loss: 31.0385  decode.loss_cls: 1.0426  decode.loss_mask: 0.6407  decode.loss_dice: 1.1579  decode.d0.loss_cls: 2.8997  decode.d0.loss_mask: 0.7417  decode.d0.loss_dice: 1.2979  decode.d1.loss_cls: 1.1732  decode.d1.loss_mask: 0.6702  decode.d1.loss_dice: 1.1975  decode.d2.loss_cls: 1.1415  decode.d2.loss_mask: 0.6491  decode.d2.loss_dice: 1.1934  decode.d3.loss_cls: 1.1686  decode.d3.loss_mask: 0.6317  decode.d3.loss_dice: 1.1276  decode.d4.loss_cls: 1.1313  decode.d4.loss_mask: 0.6146  decode.d4.loss_dice: 1.1196  decode.d5.loss_cls: 1.1396  decode.d5.loss_mask: 0.6415  decode.d5.loss_dice: 1.1322  decode.d6.loss_cls: 1.0507  decode.d6.loss_mask: 0.6662  decode.d6.loss_dice: 1.1348  decode.d7.loss_cls: 1.0552  decode.d7.loss_mask: 0.6479  decode.d7.loss_dice: 1.1451  decode.d8.loss_cls: 1.0553  decode.d8.loss_mask: 0.6521  decode.d8.loss_dice: 1.1193
2023/05/23 20:57:11 - mmengine - INFO - Iter(train) [ 21650/160000]  lr: 8.7736e-06  eta: 16:23:42  time: 0.4013  data_time: 0.0094  memory: 4904  grad_norm: 123.2000  loss: 48.1832  decode.loss_cls: 1.8608  decode.loss_mask: 0.8010  decode.loss_dice: 1.8233  decode.d0.loss_cls: 3.6172  decode.d0.loss_mask: 0.9165  decode.d0.loss_dice: 2.1260  decode.d1.loss_cls: 1.9929  decode.d1.loss_mask: 0.8685  decode.d1.loss_dice: 2.0277  decode.d2.loss_cls: 1.9010  decode.d2.loss_mask: 0.8203  decode.d2.loss_dice: 1.8941  decode.d3.loss_cls: 1.8800  decode.d3.loss_mask: 0.8442  decode.d3.loss_dice: 1.8894  decode.d4.loss_cls: 1.8697  decode.d4.loss_mask: 0.8278  decode.d4.loss_dice: 1.9084  decode.d5.loss_cls: 1.8912  decode.d5.loss_mask: 0.8277  decode.d5.loss_dice: 1.8878  decode.d6.loss_cls: 1.9133  decode.d6.loss_mask: 0.8008  decode.d6.loss_dice: 1.8459  decode.d7.loss_cls: 1.8431  decode.d7.loss_mask: 0.8313  decode.d7.loss_dice: 1.9008  decode.d8.loss_cls: 1.9644  decode.d8.loss_mask: 0.7871  decode.d8.loss_dice: 1.8209
2023/05/23 20:57:32 - mmengine - INFO - Iter(train) [ 21700/160000]  lr: 8.7707e-06  eta: 16:23:20  time: 0.4707  data_time: 0.0097  memory: 4838  grad_norm: 104.5517  loss: 34.6936  decode.loss_cls: 1.1534  decode.loss_mask: 0.7245  decode.loss_dice: 1.3026  decode.d0.loss_cls: 3.3728  decode.d0.loss_mask: 0.7681  decode.d0.loss_dice: 1.4462  decode.d1.loss_cls: 1.3464  decode.d1.loss_mask: 0.7664  decode.d1.loss_dice: 1.4171  decode.d2.loss_cls: 1.2666  decode.d2.loss_mask: 0.7353  decode.d2.loss_dice: 1.3549  decode.d3.loss_cls: 1.1768  decode.d3.loss_mask: 0.7598  decode.d3.loss_dice: 1.2853  decode.d4.loss_cls: 1.1502  decode.d4.loss_mask: 0.7817  decode.d4.loss_dice: 1.2899  decode.d5.loss_cls: 1.1437  decode.d5.loss_mask: 0.7374  decode.d5.loss_dice: 1.3016  decode.d6.loss_cls: 1.1040  decode.d6.loss_mask: 0.6948  decode.d6.loss_dice: 1.2957  decode.d7.loss_cls: 1.1385  decode.d7.loss_mask: 0.7255  decode.d7.loss_dice: 1.2894  decode.d8.loss_cls: 1.1331  decode.d8.loss_mask: 0.7307  decode.d8.loss_dice: 1.3015
2023/05/23 20:57:53 - mmengine - INFO - Iter(train) [ 21750/160000]  lr: 8.7678e-06  eta: 16:22:56  time: 0.4122  data_time: 0.0100  memory: 4858  grad_norm: 83.8244  loss: 38.4368  decode.loss_cls: 1.5463  decode.loss_mask: 0.7196  decode.loss_dice: 1.3550  decode.d0.loss_cls: 3.4212  decode.d0.loss_mask: 0.7001  decode.d0.loss_dice: 1.5877  decode.d1.loss_cls: 1.6571  decode.d1.loss_mask: 0.7081  decode.d1.loss_dice: 1.4410  decode.d2.loss_cls: 1.5858  decode.d2.loss_mask: 0.6578  decode.d2.loss_dice: 1.3545  decode.d3.loss_cls: 1.5469  decode.d3.loss_mask: 0.6733  decode.d3.loss_dice: 1.3207  decode.d4.loss_cls: 1.5871  decode.d4.loss_mask: 0.6443  decode.d4.loss_dice: 1.3814  decode.d5.loss_cls: 1.6464  decode.d5.loss_mask: 0.6653  decode.d5.loss_dice: 1.3953  decode.d6.loss_cls: 1.5179  decode.d6.loss_mask: 0.7160  decode.d6.loss_dice: 1.3891  decode.d7.loss_cls: 1.5331  decode.d7.loss_mask: 0.7239  decode.d7.loss_dice: 1.3314  decode.d8.loss_cls: 1.5427  decode.d8.loss_mask: 0.7299  decode.d8.loss_dice: 1.3580
2023/05/23 20:58:14 - mmengine - INFO - Iter(train) [ 21800/160000]  lr: 8.7650e-06  eta: 16:22:32  time: 0.4088  data_time: 0.0099  memory: 4872  grad_norm: 118.9790  loss: 40.5273  decode.loss_cls: 1.3562  decode.loss_mask: 0.9205  decode.loss_dice: 1.5011  decode.d0.loss_cls: 3.2699  decode.d0.loss_mask: 0.9830  decode.d0.loss_dice: 1.7385  decode.d1.loss_cls: 1.5999  decode.d1.loss_mask: 0.9664  decode.d1.loss_dice: 1.6337  decode.d2.loss_cls: 1.4628  decode.d2.loss_mask: 0.9223  decode.d2.loss_dice: 1.5311  decode.d3.loss_cls: 1.4045  decode.d3.loss_mask: 0.9304  decode.d3.loss_dice: 1.5144  decode.d4.loss_cls: 1.4220  decode.d4.loss_mask: 0.9063  decode.d4.loss_dice: 1.4815  decode.d5.loss_cls: 1.4082  decode.d5.loss_mask: 0.9033  decode.d5.loss_dice: 1.4645  decode.d6.loss_cls: 1.3698  decode.d6.loss_mask: 0.8852  decode.d6.loss_dice: 1.4647  decode.d7.loss_cls: 1.3643  decode.d7.loss_mask: 0.9000  decode.d7.loss_dice: 1.4810  decode.d8.loss_cls: 1.3215  decode.d8.loss_mask: 0.9150  decode.d8.loss_dice: 1.5055
2023/05/23 20:58:35 - mmengine - INFO - Iter(train) [ 21850/160000]  lr: 8.7621e-06  eta: 16:22:08  time: 0.4230  data_time: 0.0099  memory: 4825  grad_norm: 101.9877  loss: 33.1398  decode.loss_cls: 1.1214  decode.loss_mask: 0.7470  decode.loss_dice: 1.1676  decode.d0.loss_cls: 3.0318  decode.d0.loss_mask: 0.7919  decode.d0.loss_dice: 1.3820  decode.d1.loss_cls: 1.3137  decode.d1.loss_mask: 0.7543  decode.d1.loss_dice: 1.2865  decode.d2.loss_cls: 1.2358  decode.d2.loss_mask: 0.7521  decode.d2.loss_dice: 1.1946  decode.d3.loss_cls: 1.1917  decode.d3.loss_mask: 0.7018  decode.d3.loss_dice: 1.1657  decode.d4.loss_cls: 1.1445  decode.d4.loss_mask: 0.7358  decode.d4.loss_dice: 1.1998  decode.d5.loss_cls: 1.0856  decode.d5.loss_mask: 0.7840  decode.d5.loss_dice: 1.1874  decode.d6.loss_cls: 1.1036  decode.d6.loss_mask: 0.7168  decode.d6.loss_dice: 1.1912  decode.d7.loss_cls: 1.0425  decode.d7.loss_mask: 0.7971  decode.d7.loss_dice: 1.2234  decode.d8.loss_cls: 1.0841  decode.d8.loss_mask: 0.7987  decode.d8.loss_dice: 1.2075
2023/05/23 20:58:55 - mmengine - INFO - Iter(train) [ 21900/160000]  lr: 8.7593e-06  eta: 16:21:42  time: 0.4088  data_time: 0.0096  memory: 4885  grad_norm: 176.1142  loss: 38.9181  decode.loss_cls: 1.4223  decode.loss_mask: 0.7890  decode.loss_dice: 1.3081  decode.d0.loss_cls: 3.4096  decode.d0.loss_mask: 0.8985  decode.d0.loss_dice: 1.5670  decode.d1.loss_cls: 1.5035  decode.d1.loss_mask: 0.8409  decode.d1.loss_dice: 1.4789  decode.d2.loss_cls: 1.5136  decode.d2.loss_mask: 0.7931  decode.d2.loss_dice: 1.4189  decode.d3.loss_cls: 1.5335  decode.d3.loss_mask: 0.8077  decode.d3.loss_dice: 1.3948  decode.d4.loss_cls: 1.4402  decode.d4.loss_mask: 0.8183  decode.d4.loss_dice: 1.4217  decode.d5.loss_cls: 1.3859  decode.d5.loss_mask: 0.8343  decode.d5.loss_dice: 1.4174  decode.d6.loss_cls: 1.4645  decode.d6.loss_mask: 0.7979  decode.d6.loss_dice: 1.3951  decode.d7.loss_cls: 1.4687  decode.d7.loss_mask: 0.8104  decode.d7.loss_dice: 1.3726  decode.d8.loss_cls: 1.4240  decode.d8.loss_mask: 0.8023  decode.d8.loss_dice: 1.3857
2023/05/23 20:59:16 - mmengine - INFO - Iter(train) [ 21950/160000]  lr: 8.7564e-06  eta: 16:21:15  time: 0.4079  data_time: 0.0096  memory: 4847  grad_norm: 112.1734  loss: 27.1917  decode.loss_cls: 0.9520  decode.loss_mask: 0.7399  decode.loss_dice: 0.8271  decode.d0.loss_cls: 2.7451  decode.d0.loss_mask: 0.7451  decode.d0.loss_dice: 0.9564  decode.d1.loss_cls: 1.0933  decode.d1.loss_mask: 0.7985  decode.d1.loss_dice: 0.9178  decode.d2.loss_cls: 0.9672  decode.d2.loss_mask: 0.7336  decode.d2.loss_dice: 0.8729  decode.d3.loss_cls: 0.9109  decode.d3.loss_mask: 0.7374  decode.d3.loss_dice: 0.8467  decode.d4.loss_cls: 0.9107  decode.d4.loss_mask: 0.7426  decode.d4.loss_dice: 0.8601  decode.d5.loss_cls: 0.9295  decode.d5.loss_mask: 0.7231  decode.d5.loss_dice: 0.8265  decode.d6.loss_cls: 0.9207  decode.d6.loss_mask: 0.7043  decode.d6.loss_dice: 0.7860  decode.d7.loss_cls: 0.9051  decode.d7.loss_mask: 0.7202  decode.d7.loss_dice: 0.8277  decode.d8.loss_cls: 0.9144  decode.d8.loss_mask: 0.7355  decode.d8.loss_dice: 0.8413
2023/05/23 20:59:36 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 20:59:36 - mmengine - INFO - Iter(train) [ 22000/160000]  lr: 8.7536e-06  eta: 16:20:50  time: 0.4117  data_time: 0.0094  memory: 4910  grad_norm: 91.8356  loss: 35.9761  decode.loss_cls: 1.4278  decode.loss_mask: 0.7119  decode.loss_dice: 1.1400  decode.d0.loss_cls: 3.2015  decode.d0.loss_mask: 0.8162  decode.d0.loss_dice: 1.3346  decode.d1.loss_cls: 1.5484  decode.d1.loss_mask: 0.7827  decode.d1.loss_dice: 1.2800  decode.d2.loss_cls: 1.5027  decode.d2.loss_mask: 0.7671  decode.d2.loss_dice: 1.2457  decode.d3.loss_cls: 1.4404  decode.d3.loss_mask: 0.7415  decode.d3.loss_dice: 1.1818  decode.d4.loss_cls: 1.4128  decode.d4.loss_mask: 0.7552  decode.d4.loss_dice: 1.1992  decode.d5.loss_cls: 1.4362  decode.d5.loss_mask: 0.7834  decode.d5.loss_dice: 1.1856  decode.d6.loss_cls: 1.4634  decode.d6.loss_mask: 0.7538  decode.d6.loss_dice: 1.1443  decode.d7.loss_cls: 1.4606  decode.d7.loss_mask: 0.7660  decode.d7.loss_dice: 1.1683  decode.d8.loss_cls: 1.4315  decode.d8.loss_mask: 0.7655  decode.d8.loss_dice: 1.1282
2023/05/23 20:59:36 - mmengine - INFO - Saving checkpoint at 22000 iterations
2023/05/23 21:00:02 - mmengine - INFO - Iter(train) [ 22050/160000]  lr: 8.7507e-06  eta: 16:20:58  time: 0.4125  data_time: 0.0095  memory: 4872  grad_norm: 88.9988  loss: 33.9023  decode.loss_cls: 1.2990  decode.loss_mask: 0.7623  decode.loss_dice: 1.1171  decode.d0.loss_cls: 3.1196  decode.d0.loss_mask: 0.8228  decode.d0.loss_dice: 1.2737  decode.d1.loss_cls: 1.4348  decode.d1.loss_mask: 0.7470  decode.d1.loss_dice: 1.1941  decode.d2.loss_cls: 1.3725  decode.d2.loss_mask: 0.7437  decode.d2.loss_dice: 1.1303  decode.d3.loss_cls: 1.2840  decode.d3.loss_mask: 0.7337  decode.d3.loss_dice: 1.0955  decode.d4.loss_cls: 1.2862  decode.d4.loss_mask: 0.7759  decode.d4.loss_dice: 1.1341  decode.d5.loss_cls: 1.2285  decode.d5.loss_mask: 0.7612  decode.d5.loss_dice: 1.1309  decode.d6.loss_cls: 1.3101  decode.d6.loss_mask: 0.7479  decode.d6.loss_dice: 1.1142  decode.d7.loss_cls: 1.2813  decode.d7.loss_mask: 0.7540  decode.d7.loss_dice: 1.0988  decode.d8.loss_cls: 1.2681  decode.d8.loss_mask: 0.7594  decode.d8.loss_dice: 1.1219
2023/05/23 21:00:23 - mmengine - INFO - Iter(train) [ 22100/160000]  lr: 8.7479e-06  eta: 16:20:31  time: 0.4082  data_time: 0.0097  memory: 4835  grad_norm: 98.8770  loss: 47.4350  decode.loss_cls: 1.6195  decode.loss_mask: 1.0518  decode.loss_dice: 1.7872  decode.d0.loss_cls: 3.4556  decode.d0.loss_mask: 1.1394  decode.d0.loss_dice: 2.0274  decode.d1.loss_cls: 1.7622  decode.d1.loss_mask: 1.0968  decode.d1.loss_dice: 1.8768  decode.d2.loss_cls: 1.7077  decode.d2.loss_mask: 1.1093  decode.d2.loss_dice: 1.8379  decode.d3.loss_cls: 1.5914  decode.d3.loss_mask: 1.0923  decode.d3.loss_dice: 1.7967  decode.d4.loss_cls: 1.6059  decode.d4.loss_mask: 1.0562  decode.d4.loss_dice: 1.7971  decode.d5.loss_cls: 1.6219  decode.d5.loss_mask: 1.0398  decode.d5.loss_dice: 1.7761  decode.d6.loss_cls: 1.7040  decode.d6.loss_mask: 1.0549  decode.d6.loss_dice: 1.8129  decode.d7.loss_cls: 1.6327  decode.d7.loss_mask: 1.0523  decode.d7.loss_dice: 1.8099  decode.d8.loss_cls: 1.6715  decode.d8.loss_mask: 1.0714  decode.d8.loss_dice: 1.7764
2023/05/23 21:00:44 - mmengine - INFO - Iter(train) [ 22150/160000]  lr: 8.7450e-06  eta: 16:20:06  time: 0.4125  data_time: 0.0094  memory: 4829  grad_norm: 96.0177  loss: 40.3223  decode.loss_cls: 1.4572  decode.loss_mask: 0.9833  decode.loss_dice: 1.3285  decode.d0.loss_cls: 3.3272  decode.d0.loss_mask: 1.0640  decode.d0.loss_dice: 1.4893  decode.d1.loss_cls: 1.5813  decode.d1.loss_mask: 1.0431  decode.d1.loss_dice: 1.4970  decode.d2.loss_cls: 1.4031  decode.d2.loss_mask: 0.9930  decode.d2.loss_dice: 1.4162  decode.d3.loss_cls: 1.4533  decode.d3.loss_mask: 0.9929  decode.d3.loss_dice: 1.3504  decode.d4.loss_cls: 1.4497  decode.d4.loss_mask: 0.9867  decode.d4.loss_dice: 1.3565  decode.d5.loss_cls: 1.4520  decode.d5.loss_mask: 0.9644  decode.d5.loss_dice: 1.3072  decode.d6.loss_cls: 1.4669  decode.d6.loss_mask: 0.9723  decode.d6.loss_dice: 1.3370  decode.d7.loss_cls: 1.4651  decode.d7.loss_mask: 1.0078  decode.d7.loss_dice: 1.3664  decode.d8.loss_cls: 1.4629  decode.d8.loss_mask: 0.9985  decode.d8.loss_dice: 1.3488
2023/05/23 21:01:04 - mmengine - INFO - Iter(train) [ 22200/160000]  lr: 8.7422e-06  eta: 16:19:40  time: 0.4134  data_time: 0.0102  memory: 4868  grad_norm: 90.5445  loss: 32.8236  decode.loss_cls: 1.0772  decode.loss_mask: 0.7157  decode.loss_dice: 1.1718  decode.d0.loss_cls: 3.2160  decode.d0.loss_mask: 0.7964  decode.d0.loss_dice: 1.2727  decode.d1.loss_cls: 1.2569  decode.d1.loss_mask: 0.8298  decode.d1.loss_dice: 1.3064  decode.d2.loss_cls: 1.2132  decode.d2.loss_mask: 0.7465  decode.d2.loss_dice: 1.2098  decode.d3.loss_cls: 1.1781  decode.d3.loss_mask: 0.7396  decode.d3.loss_dice: 1.1659  decode.d4.loss_cls: 1.1151  decode.d4.loss_mask: 0.7463  decode.d4.loss_dice: 1.1929  decode.d5.loss_cls: 1.1204  decode.d5.loss_mask: 0.7437  decode.d5.loss_dice: 1.1322  decode.d6.loss_cls: 1.1163  decode.d6.loss_mask: 0.7244  decode.d6.loss_dice: 1.1418  decode.d7.loss_cls: 1.0584  decode.d7.loss_mask: 0.7273  decode.d7.loss_dice: 1.1396  decode.d8.loss_cls: 1.0901  decode.d8.loss_mask: 0.7383  decode.d8.loss_dice: 1.1409
2023/05/23 21:01:25 - mmengine - INFO - Iter(train) [ 22250/160000]  lr: 8.7393e-06  eta: 16:19:15  time: 0.4201  data_time: 0.0107  memory: 4864  grad_norm: 124.1948  loss: 36.2718  decode.loss_cls: 1.3297  decode.loss_mask: 0.7622  decode.loss_dice: 1.2509  decode.d0.loss_cls: 3.2903  decode.d0.loss_mask: 0.8026  decode.d0.loss_dice: 1.4393  decode.d1.loss_cls: 1.3172  decode.d1.loss_mask: 0.8789  decode.d1.loss_dice: 1.3998  decode.d2.loss_cls: 1.3385  decode.d2.loss_mask: 0.8117  decode.d2.loss_dice: 1.3159  decode.d3.loss_cls: 1.3649  decode.d3.loss_mask: 0.7824  decode.d3.loss_dice: 1.2787  decode.d4.loss_cls: 1.3031  decode.d4.loss_mask: 0.7929  decode.d4.loss_dice: 1.3076  decode.d5.loss_cls: 1.2509  decode.d5.loss_mask: 0.7962  decode.d5.loss_dice: 1.2752  decode.d6.loss_cls: 1.3644  decode.d6.loss_mask: 0.7680  decode.d6.loss_dice: 1.2422  decode.d7.loss_cls: 1.3534  decode.d7.loss_mask: 0.7831  decode.d7.loss_dice: 1.2543  decode.d8.loss_cls: 1.3599  decode.d8.loss_mask: 0.7957  decode.d8.loss_dice: 1.2619
2023/05/23 21:01:46 - mmengine - INFO - Iter(train) [ 22300/160000]  lr: 8.7365e-06  eta: 16:18:53  time: 0.4080  data_time: 0.0095  memory: 4861  grad_norm: 96.4766  loss: 28.5377  decode.loss_cls: 1.0711  decode.loss_mask: 0.6158  decode.loss_dice: 0.9534  decode.d0.loss_cls: 2.9284  decode.d0.loss_mask: 0.5677  decode.d0.loss_dice: 1.0287  decode.d1.loss_cls: 1.1374  decode.d1.loss_mask: 0.5951  decode.d1.loss_dice: 0.9883  decode.d2.loss_cls: 1.0650  decode.d2.loss_mask: 0.6219  decode.d2.loss_dice: 0.9771  decode.d3.loss_cls: 1.0662  decode.d3.loss_mask: 0.6433  decode.d3.loss_dice: 0.9819  decode.d4.loss_cls: 1.0866  decode.d4.loss_mask: 0.6474  decode.d4.loss_dice: 0.9463  decode.d5.loss_cls: 1.0633  decode.d5.loss_mask: 0.6455  decode.d5.loss_dice: 0.9867  decode.d6.loss_cls: 0.9977  decode.d6.loss_mask: 0.6187  decode.d6.loss_dice: 0.9865  decode.d7.loss_cls: 1.0545  decode.d7.loss_mask: 0.6308  decode.d7.loss_dice: 0.9595  decode.d8.loss_cls: 1.0968  decode.d8.loss_mask: 0.6144  decode.d8.loss_dice: 0.9617
2023/05/23 21:02:08 - mmengine - INFO - Iter(train) [ 22350/160000]  lr: 8.7336e-06  eta: 16:18:32  time: 0.4536  data_time: 0.0099  memory: 4866  grad_norm: 124.3279  loss: 28.2891  decode.loss_cls: 1.1410  decode.loss_mask: 0.6345  decode.loss_dice: 0.8111  decode.d0.loss_cls: 2.9584  decode.d0.loss_mask: 0.6573  decode.d0.loss_dice: 1.0171  decode.d1.loss_cls: 1.1553  decode.d1.loss_mask: 0.6502  decode.d1.loss_dice: 0.9567  decode.d2.loss_cls: 1.1043  decode.d2.loss_mask: 0.6564  decode.d2.loss_dice: 0.8934  decode.d3.loss_cls: 1.1643  decode.d3.loss_mask: 0.6156  decode.d3.loss_dice: 0.8418  decode.d4.loss_cls: 1.1514  decode.d4.loss_mask: 0.6129  decode.d4.loss_dice: 0.8388  decode.d5.loss_cls: 1.1684  decode.d5.loss_mask: 0.6274  decode.d5.loss_dice: 0.8708  decode.d6.loss_cls: 1.1439  decode.d6.loss_mask: 0.6045  decode.d6.loss_dice: 0.8336  decode.d7.loss_cls: 1.1481  decode.d7.loss_mask: 0.6117  decode.d7.loss_dice: 0.8242  decode.d8.loss_cls: 1.1629  decode.d8.loss_mask: 0.6190  decode.d8.loss_dice: 0.8138
2023/05/23 21:02:28 - mmengine - INFO - Iter(train) [ 22400/160000]  lr: 8.7307e-06  eta: 16:18:08  time: 0.4102  data_time: 0.0098  memory: 4837  grad_norm: 100.1585  loss: 34.4804  decode.loss_cls: 1.4380  decode.loss_mask: 0.6398  decode.loss_dice: 1.1781  decode.d0.loss_cls: 3.0262  decode.d0.loss_mask: 0.6673  decode.d0.loss_dice: 1.3206  decode.d1.loss_cls: 1.5513  decode.d1.loss_mask: 0.6634  decode.d1.loss_dice: 1.2894  decode.d2.loss_cls: 1.3902  decode.d2.loss_mask: 0.6187  decode.d2.loss_dice: 1.1891  decode.d3.loss_cls: 1.4354  decode.d3.loss_mask: 0.6285  decode.d3.loss_dice: 1.1609  decode.d4.loss_cls: 1.4887  decode.d4.loss_mask: 0.6200  decode.d4.loss_dice: 1.1684  decode.d5.loss_cls: 1.4316  decode.d5.loss_mask: 0.6302  decode.d5.loss_dice: 1.1800  decode.d6.loss_cls: 1.4665  decode.d6.loss_mask: 0.6401  decode.d6.loss_dice: 1.1444  decode.d7.loss_cls: 1.4488  decode.d7.loss_mask: 0.6251  decode.d7.loss_dice: 1.1732  decode.d8.loss_cls: 1.4622  decode.d8.loss_mask: 0.6291  decode.d8.loss_dice: 1.1754
2023/05/23 21:02:51 - mmengine - INFO - Iter(train) [ 22450/160000]  lr: 8.7279e-06  eta: 16:17:52  time: 0.4703  data_time: 0.0095  memory: 4836  grad_norm: 95.9765  loss: 35.7560  decode.loss_cls: 1.2267  decode.loss_mask: 0.8419  decode.loss_dice: 1.2841  decode.d0.loss_cls: 3.2969  decode.d0.loss_mask: 0.8213  decode.d0.loss_dice: 1.4072  decode.d1.loss_cls: 1.2463  decode.d1.loss_mask: 0.8197  decode.d1.loss_dice: 1.3615  decode.d2.loss_cls: 1.2116  decode.d2.loss_mask: 0.8406  decode.d2.loss_dice: 1.3393  decode.d3.loss_cls: 1.2421  decode.d3.loss_mask: 0.8082  decode.d3.loss_dice: 1.2948  decode.d4.loss_cls: 1.2095  decode.d4.loss_mask: 0.8280  decode.d4.loss_dice: 1.3097  decode.d5.loss_cls: 1.2373  decode.d5.loss_mask: 0.8147  decode.d5.loss_dice: 1.2828  decode.d6.loss_cls: 1.2184  decode.d6.loss_mask: 0.8274  decode.d6.loss_dice: 1.2661  decode.d7.loss_cls: 1.2071  decode.d7.loss_mask: 0.8480  decode.d7.loss_dice: 1.2690  decode.d8.loss_cls: 1.2115  decode.d8.loss_mask: 0.8824  decode.d8.loss_dice: 1.3021
2023/05/23 21:03:14 - mmengine - INFO - Iter(train) [ 22500/160000]  lr: 8.7250e-06  eta: 16:17:40  time: 0.4205  data_time: 0.0095  memory: 4899  grad_norm: 102.5447  loss: 42.0459  decode.loss_cls: 1.6559  decode.loss_mask: 0.8293  decode.loss_dice: 1.4398  decode.d0.loss_cls: 3.6233  decode.d0.loss_mask: 0.9159  decode.d0.loss_dice: 1.6304  decode.d1.loss_cls: 1.7823  decode.d1.loss_mask: 0.8461  decode.d1.loss_dice: 1.6037  decode.d2.loss_cls: 1.7614  decode.d2.loss_mask: 0.7897  decode.d2.loss_dice: 1.4481  decode.d3.loss_cls: 1.6800  decode.d3.loss_mask: 0.8238  decode.d3.loss_dice: 1.4465  decode.d4.loss_cls: 1.6666  decode.d4.loss_mask: 0.8056  decode.d4.loss_dice: 1.4420  decode.d5.loss_cls: 1.6414  decode.d5.loss_mask: 0.8265  decode.d5.loss_dice: 1.4914  decode.d6.loss_cls: 1.6787  decode.d6.loss_mask: 0.8300  decode.d6.loss_dice: 1.4360  decode.d7.loss_cls: 1.7150  decode.d7.loss_mask: 0.8149  decode.d7.loss_dice: 1.4621  decode.d8.loss_cls: 1.7007  decode.d8.loss_mask: 0.8162  decode.d8.loss_dice: 1.4425
2023/05/23 21:03:34 - mmengine - INFO - Iter(train) [ 22550/160000]  lr: 8.7222e-06  eta: 16:17:16  time: 0.4078  data_time: 0.0103  memory: 4860  grad_norm: 94.2728  loss: 42.2545  decode.loss_cls: 1.4864  decode.loss_mask: 0.9162  decode.loss_dice: 1.6012  decode.d0.loss_cls: 3.4481  decode.d0.loss_mask: 0.8717  decode.d0.loss_dice: 1.7118  decode.d1.loss_cls: 1.6173  decode.d1.loss_mask: 0.8623  decode.d1.loss_dice: 1.7050  decode.d2.loss_cls: 1.4634  decode.d2.loss_mask: 0.9305  decode.d2.loss_dice: 1.6692  decode.d3.loss_cls: 1.4734  decode.d3.loss_mask: 0.9129  decode.d3.loss_dice: 1.5868  decode.d4.loss_cls: 1.5069  decode.d4.loss_mask: 0.9120  decode.d4.loss_dice: 1.6623  decode.d5.loss_cls: 1.4831  decode.d5.loss_mask: 0.9031  decode.d5.loss_dice: 1.6092  decode.d6.loss_cls: 1.4507  decode.d6.loss_mask: 0.9207  decode.d6.loss_dice: 1.5770  decode.d7.loss_cls: 1.4314  decode.d7.loss_mask: 0.9468  decode.d7.loss_dice: 1.6250  decode.d8.loss_cls: 1.4024  decode.d8.loss_mask: 0.9125  decode.d8.loss_dice: 1.6551
2023/05/23 21:03:56 - mmengine - INFO - Iter(train) [ 22600/160000]  lr: 8.7193e-06  eta: 16:16:55  time: 0.4661  data_time: 0.0097  memory: 4825  grad_norm: 108.4615  loss: 33.2497  decode.loss_cls: 1.2533  decode.loss_mask: 0.7235  decode.loss_dice: 1.0590  decode.d0.loss_cls: 2.9917  decode.d0.loss_mask: 0.7299  decode.d0.loss_dice: 1.2261  decode.d1.loss_cls: 1.4941  decode.d1.loss_mask: 0.7284  decode.d1.loss_dice: 1.1345  decode.d2.loss_cls: 1.3889  decode.d2.loss_mask: 0.7658  decode.d2.loss_dice: 1.1376  decode.d3.loss_cls: 1.2737  decode.d3.loss_mask: 0.7600  decode.d3.loss_dice: 1.0892  decode.d4.loss_cls: 1.3064  decode.d4.loss_mask: 0.7490  decode.d4.loss_dice: 1.1293  decode.d5.loss_cls: 1.2587  decode.d5.loss_mask: 0.7876  decode.d5.loss_dice: 1.0865  decode.d6.loss_cls: 1.2720  decode.d6.loss_mask: 0.7297  decode.d6.loss_dice: 1.0844  decode.d7.loss_cls: 1.2380  decode.d7.loss_mask: 0.7376  decode.d7.loss_dice: 1.0806  decode.d8.loss_cls: 1.2096  decode.d8.loss_mask: 0.7465  decode.d8.loss_dice: 1.0780
2023/05/23 21:04:18 - mmengine - INFO - Iter(train) [ 22650/160000]  lr: 8.7165e-06  eta: 16:16:38  time: 0.4197  data_time: 0.0100  memory: 4845  grad_norm: 95.1066  loss: 44.4509  decode.loss_cls: 1.4617  decode.loss_mask: 0.9783  decode.loss_dice: 1.7598  decode.d0.loss_cls: 3.2661  decode.d0.loss_mask: 1.0342  decode.d0.loss_dice: 1.9725  decode.d1.loss_cls: 1.6285  decode.d1.loss_mask: 0.9827  decode.d1.loss_dice: 1.8988  decode.d2.loss_cls: 1.5407  decode.d2.loss_mask: 0.9835  decode.d2.loss_dice: 1.7875  decode.d3.loss_cls: 1.4883  decode.d3.loss_mask: 0.9586  decode.d3.loss_dice: 1.7307  decode.d4.loss_cls: 1.4828  decode.d4.loss_mask: 0.9795  decode.d4.loss_dice: 1.7403  decode.d5.loss_cls: 1.4557  decode.d5.loss_mask: 0.9833  decode.d5.loss_dice: 1.7330  decode.d6.loss_cls: 1.4631  decode.d6.loss_mask: 0.9951  decode.d6.loss_dice: 1.7298  decode.d7.loss_cls: 1.4338  decode.d7.loss_mask: 1.0239  decode.d7.loss_dice: 1.7731  decode.d8.loss_cls: 1.4273  decode.d8.loss_mask: 0.9939  decode.d8.loss_dice: 1.7642
2023/05/23 21:04:39 - mmengine - INFO - Iter(train) [ 22700/160000]  lr: 8.7136e-06  eta: 16:16:17  time: 0.4359  data_time: 0.0094  memory: 4823  grad_norm: 114.0555  loss: 35.1945  decode.loss_cls: 1.4992  decode.loss_mask: 0.7209  decode.loss_dice: 1.1109  decode.d0.loss_cls: 3.0016  decode.d0.loss_mask: 0.8083  decode.d0.loss_dice: 1.2429  decode.d1.loss_cls: 1.5542  decode.d1.loss_mask: 0.8139  decode.d1.loss_dice: 1.2632  decode.d2.loss_cls: 1.4753  decode.d2.loss_mask: 0.7099  decode.d2.loss_dice: 1.1371  decode.d3.loss_cls: 1.5130  decode.d3.loss_mask: 0.7260  decode.d3.loss_dice: 1.1274  decode.d4.loss_cls: 1.4638  decode.d4.loss_mask: 0.7428  decode.d4.loss_dice: 1.1393  decode.d5.loss_cls: 1.4504  decode.d5.loss_mask: 0.7306  decode.d5.loss_dice: 1.1124  decode.d6.loss_cls: 1.4017  decode.d6.loss_mask: 0.7158  decode.d6.loss_dice: 1.1279  decode.d7.loss_cls: 1.4387  decode.d7.loss_mask: 0.7604  decode.d7.loss_dice: 1.0980  decode.d8.loss_cls: 1.4937  decode.d8.loss_mask: 0.7103  decode.d8.loss_dice: 1.1050
2023/05/23 21:05:00 - mmengine - INFO - Iter(train) [ 22750/160000]  lr: 8.7108e-06  eta: 16:15:51  time: 0.4033  data_time: 0.0098  memory: 4839  grad_norm: 98.8763  loss: 35.9219  decode.loss_cls: 1.5148  decode.loss_mask: 0.6269  decode.loss_dice: 1.1891  decode.d0.loss_cls: 3.2701  decode.d0.loss_mask: 0.6587  decode.d0.loss_dice: 1.2377  decode.d1.loss_cls: 1.8268  decode.d1.loss_mask: 0.6743  decode.d1.loss_dice: 1.2005  decode.d2.loss_cls: 1.6886  decode.d2.loss_mask: 0.6651  decode.d2.loss_dice: 1.1864  decode.d3.loss_cls: 1.5872  decode.d3.loss_mask: 0.7063  decode.d3.loss_dice: 1.1159  decode.d4.loss_cls: 1.5854  decode.d4.loss_mask: 0.6568  decode.d4.loss_dice: 1.1928  decode.d5.loss_cls: 1.5954  decode.d5.loss_mask: 0.6592  decode.d5.loss_dice: 1.1624  decode.d6.loss_cls: 1.5718  decode.d6.loss_mask: 0.6485  decode.d6.loss_dice: 1.1351  decode.d7.loss_cls: 1.4877  decode.d7.loss_mask: 0.6422  decode.d7.loss_dice: 1.1538  decode.d8.loss_cls: 1.5219  decode.d8.loss_mask: 0.6298  decode.d8.loss_dice: 1.1305
2023/05/23 21:05:22 - mmengine - INFO - Iter(train) [ 22800/160000]  lr: 8.7079e-06  eta: 16:15:33  time: 0.4658  data_time: 0.0096  memory: 4901  grad_norm: 103.7237  loss: 45.9358  decode.loss_cls: 1.6362  decode.loss_mask: 0.9890  decode.loss_dice: 1.5917  decode.d0.loss_cls: 3.8754  decode.d0.loss_mask: 1.1475  decode.d0.loss_dice: 1.8868  decode.d1.loss_cls: 1.8698  decode.d1.loss_mask: 1.0689  decode.d1.loss_dice: 1.7107  decode.d2.loss_cls: 1.6797  decode.d2.loss_mask: 1.0414  decode.d2.loss_dice: 1.6388  decode.d3.loss_cls: 1.7085  decode.d3.loss_mask: 1.0484  decode.d3.loss_dice: 1.6161  decode.d4.loss_cls: 1.7008  decode.d4.loss_mask: 1.0588  decode.d4.loss_dice: 1.6192  decode.d5.loss_cls: 1.6419  decode.d5.loss_mask: 1.0346  decode.d5.loss_dice: 1.5958  decode.d6.loss_cls: 1.6244  decode.d6.loss_mask: 1.0549  decode.d6.loss_dice: 1.5878  decode.d7.loss_cls: 1.6113  decode.d7.loss_mask: 1.0476  decode.d7.loss_dice: 1.5869  decode.d8.loss_cls: 1.6393  decode.d8.loss_mask: 1.0243  decode.d8.loss_dice: 1.5995
2023/05/23 21:05:43 - mmengine - INFO - Iter(train) [ 22850/160000]  lr: 8.7050e-06  eta: 16:15:14  time: 0.4247  data_time: 0.0097  memory: 4905  grad_norm: 86.2571  loss: 35.5332  decode.loss_cls: 1.3263  decode.loss_mask: 0.7448  decode.loss_dice: 1.1986  decode.d0.loss_cls: 3.1054  decode.d0.loss_mask: 0.7419  decode.d0.loss_dice: 1.4328  decode.d1.loss_cls: 1.6318  decode.d1.loss_mask: 0.7874  decode.d1.loss_dice: 1.2560  decode.d2.loss_cls: 1.4152  decode.d2.loss_mask: 0.7860  decode.d2.loss_dice: 1.2414  decode.d3.loss_cls: 1.4413  decode.d3.loss_mask: 0.7553  decode.d3.loss_dice: 1.2138  decode.d4.loss_cls: 1.4171  decode.d4.loss_mask: 0.7593  decode.d4.loss_dice: 1.1862  decode.d5.loss_cls: 1.3814  decode.d5.loss_mask: 0.7343  decode.d5.loss_dice: 1.1952  decode.d6.loss_cls: 1.3001  decode.d6.loss_mask: 0.7317  decode.d6.loss_dice: 1.2166  decode.d7.loss_cls: 1.3015  decode.d7.loss_mask: 0.7431  decode.d7.loss_dice: 1.2184  decode.d8.loss_cls: 1.2923  decode.d8.loss_mask: 0.7687  decode.d8.loss_dice: 1.2091
2023/05/23 21:06:05 - mmengine - INFO - Iter(train) [ 22900/160000]  lr: 8.7022e-06  eta: 16:14:52  time: 0.4385  data_time: 0.0098  memory: 4829  grad_norm: 113.6089  loss: 38.1571  decode.loss_cls: 1.4123  decode.loss_mask: 0.8518  decode.loss_dice: 1.2632  decode.d0.loss_cls: 3.2514  decode.d0.loss_mask: 0.8873  decode.d0.loss_dice: 1.4636  decode.d1.loss_cls: 1.5071  decode.d1.loss_mask: 0.9429  decode.d1.loss_dice: 1.3813  decode.d2.loss_cls: 1.4496  decode.d2.loss_mask: 0.9022  decode.d2.loss_dice: 1.2912  decode.d3.loss_cls: 1.4854  decode.d3.loss_mask: 0.8518  decode.d3.loss_dice: 1.2674  decode.d4.loss_cls: 1.4456  decode.d4.loss_mask: 0.8818  decode.d4.loss_dice: 1.3233  decode.d5.loss_cls: 1.3878  decode.d5.loss_mask: 0.8875  decode.d5.loss_dice: 1.2699  decode.d6.loss_cls: 1.3450  decode.d6.loss_mask: 0.9382  decode.d6.loss_dice: 1.3090  decode.d7.loss_cls: 1.3403  decode.d7.loss_mask: 0.8930  decode.d7.loss_dice: 1.3133  decode.d8.loss_cls: 1.4788  decode.d8.loss_mask: 0.8680  decode.d8.loss_dice: 1.2671
2023/05/23 21:06:27 - mmengine - INFO - Iter(train) [ 22950/160000]  lr: 8.6993e-06  eta: 16:14:37  time: 0.4662  data_time: 0.0097  memory: 4845  grad_norm: 81.9490  loss: 44.9173  decode.loss_cls: 1.3870  decode.loss_mask: 1.0110  decode.loss_dice: 1.7745  decode.d0.loss_cls: 3.5109  decode.d0.loss_mask: 1.0484  decode.d0.loss_dice: 2.1045  decode.d1.loss_cls: 1.6146  decode.d1.loss_mask: 1.0180  decode.d1.loss_dice: 1.9745  decode.d2.loss_cls: 1.5100  decode.d2.loss_mask: 1.0033  decode.d2.loss_dice: 1.8732  decode.d3.loss_cls: 1.4510  decode.d3.loss_mask: 0.9615  decode.d3.loss_dice: 1.8125  decode.d4.loss_cls: 1.4041  decode.d4.loss_mask: 0.9610  decode.d4.loss_dice: 1.8098  decode.d5.loss_cls: 1.4490  decode.d5.loss_mask: 0.9343  decode.d5.loss_dice: 1.7632  decode.d6.loss_cls: 1.3883  decode.d6.loss_mask: 1.0003  decode.d6.loss_dice: 1.7667  decode.d7.loss_cls: 1.3902  decode.d7.loss_mask: 1.0226  decode.d7.loss_dice: 1.8152  decode.d8.loss_cls: 1.3714  decode.d8.loss_mask: 0.9992  decode.d8.loss_dice: 1.7871
2023/05/23 21:06:48 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 21:06:48 - mmengine - INFO - Iter(train) [ 23000/160000]  lr: 8.6965e-06  eta: 16:14:11  time: 0.4168  data_time: 0.0096  memory: 4822  grad_norm: 114.7068  loss: 36.8015  decode.loss_cls: 1.2744  decode.loss_mask: 0.8390  decode.loss_dice: 1.2279  decode.d0.loss_cls: 3.3789  decode.d0.loss_mask: 0.8673  decode.d0.loss_dice: 1.4452  decode.d1.loss_cls: 1.5223  decode.d1.loss_mask: 0.8515  decode.d1.loss_dice: 1.3311  decode.d2.loss_cls: 1.4351  decode.d2.loss_mask: 0.8648  decode.d2.loss_dice: 1.3045  decode.d3.loss_cls: 1.3316  decode.d3.loss_mask: 0.8396  decode.d3.loss_dice: 1.2835  decode.d4.loss_cls: 1.2961  decode.d4.loss_mask: 0.8640  decode.d4.loss_dice: 1.2817  decode.d5.loss_cls: 1.2975  decode.d5.loss_mask: 0.8760  decode.d5.loss_dice: 1.2884  decode.d6.loss_cls: 1.2664  decode.d6.loss_mask: 0.8564  decode.d6.loss_dice: 1.2320  decode.d7.loss_cls: 1.2730  decode.d7.loss_mask: 0.8486  decode.d7.loss_dice: 1.2334  decode.d8.loss_cls: 1.3001  decode.d8.loss_mask: 0.8645  decode.d8.loss_dice: 1.2269
2023/05/23 21:06:48 - mmengine - INFO - Saving checkpoint at 23000 iterations
2023/05/23 21:07:14 - mmengine - INFO - Iter(train) [ 23050/160000]  lr: 8.6936e-06  eta: 16:14:19  time: 0.4113  data_time: 0.0093  memory: 4880  grad_norm: 96.2878  loss: 43.5340  decode.loss_cls: 1.5744  decode.loss_mask: 0.8685  decode.loss_dice: 1.6501  decode.d0.loss_cls: 3.5199  decode.d0.loss_mask: 0.8822  decode.d0.loss_dice: 1.8618  decode.d1.loss_cls: 1.7540  decode.d1.loss_mask: 0.8492  decode.d1.loss_dice: 1.7156  decode.d2.loss_cls: 1.5952  decode.d2.loss_mask: 0.8976  decode.d2.loss_dice: 1.6985  decode.d3.loss_cls: 1.6023  decode.d3.loss_mask: 0.8632  decode.d3.loss_dice: 1.6319  decode.d4.loss_cls: 1.5510  decode.d4.loss_mask: 0.8833  decode.d4.loss_dice: 1.6353  decode.d5.loss_cls: 1.5292  decode.d5.loss_mask: 0.8739  decode.d5.loss_dice: 1.6859  decode.d6.loss_cls: 1.5581  decode.d6.loss_mask: 0.9042  decode.d6.loss_dice: 1.7022  decode.d7.loss_cls: 1.5058  decode.d7.loss_mask: 0.9421  decode.d7.loss_dice: 1.6946  decode.d8.loss_cls: 1.5676  decode.d8.loss_mask: 0.8838  decode.d8.loss_dice: 1.6525
2023/05/23 21:07:35 - mmengine - INFO - Iter(train) [ 23100/160000]  lr: 8.6908e-06  eta: 16:13:56  time: 0.4232  data_time: 0.0096  memory: 4917  grad_norm: 93.8979  loss: 36.5690  decode.loss_cls: 1.3388  decode.loss_mask: 0.8242  decode.loss_dice: 1.2232  decode.d0.loss_cls: 3.3923  decode.d0.loss_mask: 0.9175  decode.d0.loss_dice: 1.5187  decode.d1.loss_cls: 1.3786  decode.d1.loss_mask: 0.8616  decode.d1.loss_dice: 1.3283  decode.d2.loss_cls: 1.4021  decode.d2.loss_mask: 0.8379  decode.d2.loss_dice: 1.2925  decode.d3.loss_cls: 1.4165  decode.d3.loss_mask: 0.8122  decode.d3.loss_dice: 1.2292  decode.d4.loss_cls: 1.3098  decode.d4.loss_mask: 0.8513  decode.d4.loss_dice: 1.2323  decode.d5.loss_cls: 1.3198  decode.d5.loss_mask: 0.8228  decode.d5.loss_dice: 1.2113  decode.d6.loss_cls: 1.3117  decode.d6.loss_mask: 0.8158  decode.d6.loss_dice: 1.1961  decode.d7.loss_cls: 1.3262  decode.d7.loss_mask: 0.8315  decode.d7.loss_dice: 1.2087  decode.d8.loss_cls: 1.2532  decode.d8.loss_mask: 0.8482  decode.d8.loss_dice: 1.2566
2023/05/23 21:07:56 - mmengine - INFO - Iter(train) [ 23150/160000]  lr: 8.6879e-06  eta: 16:13:32  time: 0.4197  data_time: 0.0097  memory: 4845  grad_norm: 105.1828  loss: 27.1113  decode.loss_cls: 1.0998  decode.loss_mask: 0.5435  decode.loss_dice: 0.9141  decode.d0.loss_cls: 2.6112  decode.d0.loss_mask: 0.5453  decode.d0.loss_dice: 0.9933  decode.d1.loss_cls: 1.1674  decode.d1.loss_mask: 0.4986  decode.d1.loss_dice: 0.9590  decode.d2.loss_cls: 1.1181  decode.d2.loss_mask: 0.4980  decode.d2.loss_dice: 0.9191  decode.d3.loss_cls: 1.0893  decode.d3.loss_mask: 0.5257  decode.d3.loss_dice: 0.8989  decode.d4.loss_cls: 1.1136  decode.d4.loss_mask: 0.5162  decode.d4.loss_dice: 0.8894  decode.d5.loss_cls: 1.1532  decode.d5.loss_mask: 0.5207  decode.d5.loss_dice: 0.8942  decode.d6.loss_cls: 1.1168  decode.d6.loss_mask: 0.5544  decode.d6.loss_dice: 0.9049  decode.d7.loss_cls: 1.1016  decode.d7.loss_mask: 0.5378  decode.d7.loss_dice: 0.9100  decode.d8.loss_cls: 1.1033  decode.d8.loss_mask: 0.5081  decode.d8.loss_dice: 0.9058
2023/05/23 21:08:16 - mmengine - INFO - Iter(train) [ 23200/160000]  lr: 8.6850e-06  eta: 16:13:05  time: 0.4118  data_time: 0.0099  memory: 4846  grad_norm: 124.1210  loss: 42.7182  decode.loss_cls: 1.6531  decode.loss_mask: 0.8496  decode.loss_dice: 1.4452  decode.d0.loss_cls: 3.4432  decode.d0.loss_mask: 1.0157  decode.d0.loss_dice: 1.7325  decode.d1.loss_cls: 1.8595  decode.d1.loss_mask: 0.8999  decode.d1.loss_dice: 1.6011  decode.d2.loss_cls: 1.6999  decode.d2.loss_mask: 0.8929  decode.d2.loss_dice: 1.5881  decode.d3.loss_cls: 1.7007  decode.d3.loss_mask: 0.8692  decode.d3.loss_dice: 1.4655  decode.d4.loss_cls: 1.6580  decode.d4.loss_mask: 0.8906  decode.d4.loss_dice: 1.5387  decode.d5.loss_cls: 1.6566  decode.d5.loss_mask: 0.8534  decode.d5.loss_dice: 1.4482  decode.d6.loss_cls: 1.6548  decode.d6.loss_mask: 0.8839  decode.d6.loss_dice: 1.4727  decode.d7.loss_cls: 1.6579  decode.d7.loss_mask: 0.8422  decode.d7.loss_dice: 1.4671  decode.d8.loss_cls: 1.6981  decode.d8.loss_mask: 0.8404  decode.d8.loss_dice: 1.4393
2023/05/23 21:08:38 - mmengine - INFO - Iter(train) [ 23250/160000]  lr: 8.6822e-06  eta: 16:12:44  time: 0.4580  data_time: 0.0095  memory: 4886  grad_norm: 109.2760  loss: 39.3760  decode.loss_cls: 1.3905  decode.loss_mask: 0.7653  decode.loss_dice: 1.4827  decode.d0.loss_cls: 3.1993  decode.d0.loss_mask: 0.8427  decode.d0.loss_dice: 1.6596  decode.d1.loss_cls: 1.6133  decode.d1.loss_mask: 0.8397  decode.d1.loss_dice: 1.5995  decode.d2.loss_cls: 1.5438  decode.d2.loss_mask: 0.8349  decode.d2.loss_dice: 1.4928  decode.d3.loss_cls: 1.5097  decode.d3.loss_mask: 0.7924  decode.d3.loss_dice: 1.4151  decode.d4.loss_cls: 1.4739  decode.d4.loss_mask: 0.7909  decode.d4.loss_dice: 1.4735  decode.d5.loss_cls: 1.4116  decode.d5.loss_mask: 0.7963  decode.d5.loss_dice: 1.4456  decode.d6.loss_cls: 1.4053  decode.d6.loss_mask: 0.7896  decode.d6.loss_dice: 1.4623  decode.d7.loss_cls: 1.3876  decode.d7.loss_mask: 0.7943  decode.d7.loss_dice: 1.4829  decode.d8.loss_cls: 1.4400  decode.d8.loss_mask: 0.7827  decode.d8.loss_dice: 1.4580
2023/05/23 21:08:59 - mmengine - INFO - Iter(train) [ 23300/160000]  lr: 8.6793e-06  eta: 16:12:25  time: 0.4450  data_time: 0.0096  memory: 4877  grad_norm: 96.6622  loss: 41.3900  decode.loss_cls: 1.4021  decode.loss_mask: 0.7607  decode.loss_dice: 1.6167  decode.d0.loss_cls: 3.4978  decode.d0.loss_mask: 0.8957  decode.d0.loss_dice: 1.9040  decode.d1.loss_cls: 1.7000  decode.d1.loss_mask: 0.8002  decode.d1.loss_dice: 1.7239  decode.d2.loss_cls: 1.5355  decode.d2.loss_mask: 0.7712  decode.d2.loss_dice: 1.7009  decode.d3.loss_cls: 1.5236  decode.d3.loss_mask: 0.7506  decode.d3.loss_dice: 1.6223  decode.d4.loss_cls: 1.4497  decode.d4.loss_mask: 0.7909  decode.d4.loss_dice: 1.6763  decode.d5.loss_cls: 1.4873  decode.d5.loss_mask: 0.7814  decode.d5.loss_dice: 1.6250  decode.d6.loss_cls: 1.5143  decode.d6.loss_mask: 0.7537  decode.d6.loss_dice: 1.5580  decode.d7.loss_cls: 1.4359  decode.d7.loss_mask: 0.7598  decode.d7.loss_dice: 1.5640  decode.d8.loss_cls: 1.4401  decode.d8.loss_mask: 0.7523  decode.d8.loss_dice: 1.5960
2023/05/23 21:09:21 - mmengine - INFO - Iter(train) [ 23350/160000]  lr: 8.6765e-06  eta: 16:12:06  time: 0.4064  data_time: 0.0098  memory: 4846  grad_norm: 103.4689  loss: 36.8266  decode.loss_cls: 1.2206  decode.loss_mask: 0.8480  decode.loss_dice: 1.3217  decode.d0.loss_cls: 3.1179  decode.d0.loss_mask: 0.8657  decode.d0.loss_dice: 1.5552  decode.d1.loss_cls: 1.3847  decode.d1.loss_mask: 0.8767  decode.d1.loss_dice: 1.3994  decode.d2.loss_cls: 1.3103  decode.d2.loss_mask: 0.8656  decode.d2.loss_dice: 1.4123  decode.d3.loss_cls: 1.2013  decode.d3.loss_mask: 0.8526  decode.d3.loss_dice: 1.3916  decode.d4.loss_cls: 1.2206  decode.d4.loss_mask: 0.8491  decode.d4.loss_dice: 1.4005  decode.d5.loss_cls: 1.2732  decode.d5.loss_mask: 0.8688  decode.d5.loss_dice: 1.3768  decode.d6.loss_cls: 1.1961  decode.d6.loss_mask: 0.8432  decode.d6.loss_dice: 1.3702  decode.d7.loss_cls: 1.2187  decode.d7.loss_mask: 0.8372  decode.d7.loss_dice: 1.3334  decode.d8.loss_cls: 1.2347  decode.d8.loss_mask: 0.8479  decode.d8.loss_dice: 1.3327
2023/05/23 21:09:42 - mmengine - INFO - Iter(train) [ 23400/160000]  lr: 8.6736e-06  eta: 16:11:40  time: 0.4134  data_time: 0.0094  memory: 4866  grad_norm: 95.1994  loss: 35.3242  decode.loss_cls: 1.3069  decode.loss_mask: 0.6601  decode.loss_dice: 1.2943  decode.d0.loss_cls: 3.2926  decode.d0.loss_mask: 0.6859  decode.d0.loss_dice: 1.5304  decode.d1.loss_cls: 1.4003  decode.d1.loss_mask: 0.6815  decode.d1.loss_dice: 1.4013  decode.d2.loss_cls: 1.3471  decode.d2.loss_mask: 0.6498  decode.d2.loss_dice: 1.3962  decode.d3.loss_cls: 1.3050  decode.d3.loss_mask: 0.6522  decode.d3.loss_dice: 1.3463  decode.d4.loss_cls: 1.3867  decode.d4.loss_mask: 0.6357  decode.d4.loss_dice: 1.3136  decode.d5.loss_cls: 1.2781  decode.d5.loss_mask: 0.6591  decode.d5.loss_dice: 1.3575  decode.d6.loss_cls: 1.3053  decode.d6.loss_mask: 0.6445  decode.d6.loss_dice: 1.3060  decode.d7.loss_cls: 1.3642  decode.d7.loss_mask: 0.6220  decode.d7.loss_dice: 1.2794  decode.d8.loss_cls: 1.2431  decode.d8.loss_mask: 0.6752  decode.d8.loss_dice: 1.3037
2023/05/23 21:10:03 - mmengine - INFO - Iter(train) [ 23450/160000]  lr: 8.6708e-06  eta: 16:11:17  time: 0.4207  data_time: 0.0097  memory: 4846  grad_norm: 107.0626  loss: 28.8565  decode.loss_cls: 1.1352  decode.loss_mask: 0.5973  decode.loss_dice: 0.8828  decode.d0.loss_cls: 2.9027  decode.d0.loss_mask: 0.7145  decode.d0.loss_dice: 1.0823  decode.d1.loss_cls: 1.2418  decode.d1.loss_mask: 0.6579  decode.d1.loss_dice: 1.0359  decode.d2.loss_cls: 1.1088  decode.d2.loss_mask: 0.6544  decode.d2.loss_dice: 0.9767  decode.d3.loss_cls: 1.1139  decode.d3.loss_mask: 0.6095  decode.d3.loss_dice: 0.9355  decode.d4.loss_cls: 1.0854  decode.d4.loss_mask: 0.6263  decode.d4.loss_dice: 0.9577  decode.d5.loss_cls: 1.1253  decode.d5.loss_mask: 0.6188  decode.d5.loss_dice: 0.9460  decode.d6.loss_cls: 1.0771  decode.d6.loss_mask: 0.6012  decode.d6.loss_dice: 0.9290  decode.d7.loss_cls: 1.0825  decode.d7.loss_mask: 0.6227  decode.d7.loss_dice: 0.9067  decode.d8.loss_cls: 1.1058  decode.d8.loss_mask: 0.6106  decode.d8.loss_dice: 0.9121
2023/05/23 21:10:24 - mmengine - INFO - Iter(train) [ 23500/160000]  lr: 8.6679e-06  eta: 16:10:56  time: 0.4679  data_time: 0.0096  memory: 4845  grad_norm: 120.5383  loss: 37.7168  decode.loss_cls: 1.5877  decode.loss_mask: 0.7443  decode.loss_dice: 1.1348  decode.d0.loss_cls: 3.4461  decode.d0.loss_mask: 0.9166  decode.d0.loss_dice: 1.3363  decode.d1.loss_cls: 1.6862  decode.d1.loss_mask: 0.8562  decode.d1.loss_dice: 1.2883  decode.d2.loss_cls: 1.6085  decode.d2.loss_mask: 0.8172  decode.d2.loss_dice: 1.1895  decode.d3.loss_cls: 1.5768  decode.d3.loss_mask: 0.7805  decode.d3.loss_dice: 1.1429  decode.d4.loss_cls: 1.5784  decode.d4.loss_mask: 0.8012  decode.d4.loss_dice: 1.1737  decode.d5.loss_cls: 1.5803  decode.d5.loss_mask: 0.7967  decode.d5.loss_dice: 1.1508  decode.d6.loss_cls: 1.6057  decode.d6.loss_mask: 0.7752  decode.d6.loss_dice: 1.1551  decode.d7.loss_cls: 1.5878  decode.d7.loss_mask: 0.7698  decode.d7.loss_dice: 1.1258  decode.d8.loss_cls: 1.6339  decode.d8.loss_mask: 0.7594  decode.d8.loss_dice: 1.1111
2023/05/23 21:10:45 - mmengine - INFO - Iter(train) [ 23550/160000]  lr: 8.6650e-06  eta: 16:10:32  time: 0.4134  data_time: 0.0095  memory: 4864  grad_norm: 108.0232  loss: 35.9027  decode.loss_cls: 1.3601  decode.loss_mask: 0.8385  decode.loss_dice: 1.1415  decode.d0.loss_cls: 3.2417  decode.d0.loss_mask: 0.9010  decode.d0.loss_dice: 1.2698  decode.d1.loss_cls: 1.4471  decode.d1.loss_mask: 0.8567  decode.d1.loss_dice: 1.2020  decode.d2.loss_cls: 1.3784  decode.d2.loss_mask: 0.8457  decode.d2.loss_dice: 1.1714  decode.d3.loss_cls: 1.4346  decode.d3.loss_mask: 0.8303  decode.d3.loss_dice: 1.1288  decode.d4.loss_cls: 1.3490  decode.d4.loss_mask: 0.8415  decode.d4.loss_dice: 1.1508  decode.d5.loss_cls: 1.2962  decode.d5.loss_mask: 0.8907  decode.d5.loss_dice: 1.1677  decode.d6.loss_cls: 1.3788  decode.d6.loss_mask: 0.8576  decode.d6.loss_dice: 1.1452  decode.d7.loss_cls: 1.3233  decode.d7.loss_mask: 0.8828  decode.d7.loss_dice: 1.1833  decode.d8.loss_cls: 1.3750  decode.d8.loss_mask: 0.8527  decode.d8.loss_dice: 1.1606
2023/05/23 21:11:06 - mmengine - INFO - Iter(train) [ 23600/160000]  lr: 8.6622e-06  eta: 16:10:08  time: 0.4392  data_time: 0.0105  memory: 4918  grad_norm: 89.7738  loss: 29.8520  decode.loss_cls: 1.1314  decode.loss_mask: 0.6147  decode.loss_dice: 0.9510  decode.d0.loss_cls: 2.9295  decode.d0.loss_mask: 0.6525  decode.d0.loss_dice: 1.2169  decode.d1.loss_cls: 1.3722  decode.d1.loss_mask: 0.6381  decode.d1.loss_dice: 1.0728  decode.d2.loss_cls: 1.1804  decode.d2.loss_mask: 0.6432  decode.d2.loss_dice: 1.0425  decode.d3.loss_cls: 1.0831  decode.d3.loss_mask: 0.6361  decode.d3.loss_dice: 0.9939  decode.d4.loss_cls: 1.1317  decode.d4.loss_mask: 0.6521  decode.d4.loss_dice: 1.0262  decode.d5.loss_cls: 1.1368  decode.d5.loss_mask: 0.6068  decode.d5.loss_dice: 1.0244  decode.d6.loss_cls: 1.1584  decode.d6.loss_mask: 0.6137  decode.d6.loss_dice: 0.9773  decode.d7.loss_cls: 1.0895  decode.d7.loss_mask: 0.6118  decode.d7.loss_dice: 0.9640  decode.d8.loss_cls: 1.1224  decode.d8.loss_mask: 0.6191  decode.d8.loss_dice: 0.9594
2023/05/23 21:11:27 - mmengine - INFO - Iter(train) [ 23650/160000]  lr: 8.6593e-06  eta: 16:09:43  time: 0.4095  data_time: 0.0095  memory: 4876  grad_norm: 95.7803  loss: 36.1937  decode.loss_cls: 1.4049  decode.loss_mask: 0.7478  decode.loss_dice: 1.2318  decode.d0.loss_cls: 3.1338  decode.d0.loss_mask: 0.7133  decode.d0.loss_dice: 1.4045  decode.d1.loss_cls: 1.5005  decode.d1.loss_mask: 0.8061  decode.d1.loss_dice: 1.3955  decode.d2.loss_cls: 1.4608  decode.d2.loss_mask: 0.7346  decode.d2.loss_dice: 1.3193  decode.d3.loss_cls: 1.4097  decode.d3.loss_mask: 0.7079  decode.d3.loss_dice: 1.2633  decode.d4.loss_cls: 1.3984  decode.d4.loss_mask: 0.7072  decode.d4.loss_dice: 1.2341  decode.d5.loss_cls: 1.4490  decode.d5.loss_mask: 0.7065  decode.d5.loss_dice: 1.2038  decode.d6.loss_cls: 1.4238  decode.d6.loss_mask: 0.7651  decode.d6.loss_dice: 1.2394  decode.d7.loss_cls: 1.4752  decode.d7.loss_mask: 0.7330  decode.d7.loss_dice: 1.2341  decode.d8.loss_cls: 1.3865  decode.d8.loss_mask: 0.7489  decode.d8.loss_dice: 1.2546
2023/05/23 21:11:48 - mmengine - INFO - Iter(train) [ 23700/160000]  lr: 8.6565e-06  eta: 16:09:24  time: 0.4250  data_time: 0.0096  memory: 4803  grad_norm: 111.9567  loss: 31.1948  decode.loss_cls: 0.8936  decode.loss_mask: 0.7297  decode.loss_dice: 1.1935  decode.d0.loss_cls: 2.6389  decode.d0.loss_mask: 0.7750  decode.d0.loss_dice: 1.3365  decode.d1.loss_cls: 1.1150  decode.d1.loss_mask: 0.7815  decode.d1.loss_dice: 1.2930  decode.d2.loss_cls: 0.9576  decode.d2.loss_mask: 0.7857  decode.d2.loss_dice: 1.2728  decode.d3.loss_cls: 0.9479  decode.d3.loss_mask: 0.8066  decode.d3.loss_dice: 1.2448  decode.d4.loss_cls: 0.9830  decode.d4.loss_mask: 0.7585  decode.d4.loss_dice: 1.2077  decode.d5.loss_cls: 0.9206  decode.d5.loss_mask: 0.7786  decode.d5.loss_dice: 1.2108  decode.d6.loss_cls: 0.8784  decode.d6.loss_mask: 0.7640  decode.d6.loss_dice: 1.2269  decode.d7.loss_cls: 0.8704  decode.d7.loss_mask: 0.7418  decode.d7.loss_dice: 1.2267  decode.d8.loss_cls: 0.8937  decode.d8.loss_mask: 0.7433  decode.d8.loss_dice: 1.2182
2023/05/23 21:12:09 - mmengine - INFO - Iter(train) [ 23750/160000]  lr: 8.6536e-06  eta: 16:09:00  time: 0.4154  data_time: 0.0102  memory: 4837  grad_norm: 105.1499  loss: 36.8311  decode.loss_cls: 1.4356  decode.loss_mask: 0.8395  decode.loss_dice: 1.2047  decode.d0.loss_cls: 3.0367  decode.d0.loss_mask: 0.9170  decode.d0.loss_dice: 1.4049  decode.d1.loss_cls: 1.4184  decode.d1.loss_mask: 0.9036  decode.d1.loss_dice: 1.3307  decode.d2.loss_cls: 1.4009  decode.d2.loss_mask: 0.8470  decode.d2.loss_dice: 1.2775  decode.d3.loss_cls: 1.3998  decode.d3.loss_mask: 0.8948  decode.d3.loss_dice: 1.2309  decode.d4.loss_cls: 1.3722  decode.d4.loss_mask: 0.8902  decode.d4.loss_dice: 1.2700  decode.d5.loss_cls: 1.3640  decode.d5.loss_mask: 0.8704  decode.d5.loss_dice: 1.2141  decode.d6.loss_cls: 1.3677  decode.d6.loss_mask: 0.8657  decode.d6.loss_dice: 1.2053  decode.d7.loss_cls: 1.3194  decode.d7.loss_mask: 0.8974  decode.d7.loss_dice: 1.2456  decode.d8.loss_cls: 1.3218  decode.d8.loss_mask: 0.8601  decode.d8.loss_dice: 1.2254
2023/05/23 21:12:30 - mmengine - INFO - Iter(train) [ 23800/160000]  lr: 8.6508e-06  eta: 16:08:34  time: 0.4064  data_time: 0.0096  memory: 4802  grad_norm: 92.8954  loss: 44.3226  decode.loss_cls: 1.5757  decode.loss_mask: 0.9368  decode.loss_dice: 1.5512  decode.d0.loss_cls: 3.8084  decode.d0.loss_mask: 0.9771  decode.d0.loss_dice: 1.8175  decode.d1.loss_cls: 1.8028  decode.d1.loss_mask: 0.9398  decode.d1.loss_dice: 1.6425  decode.d2.loss_cls: 1.7334  decode.d2.loss_mask: 0.9806  decode.d2.loss_dice: 1.6708  decode.d3.loss_cls: 1.6396  decode.d3.loss_mask: 0.9645  decode.d3.loss_dice: 1.6048  decode.d4.loss_cls: 1.5958  decode.d4.loss_mask: 0.9529  decode.d4.loss_dice: 1.5930  decode.d5.loss_cls: 1.6381  decode.d5.loss_mask: 0.9270  decode.d5.loss_dice: 1.5735  decode.d6.loss_cls: 1.6237  decode.d6.loss_mask: 0.9288  decode.d6.loss_dice: 1.5486  decode.d7.loss_cls: 1.6095  decode.d7.loss_mask: 0.9479  decode.d7.loss_dice: 1.5776  decode.d8.loss_cls: 1.6437  decode.d8.loss_mask: 0.9472  decode.d8.loss_dice: 1.5697
2023/05/23 21:12:50 - mmengine - INFO - Iter(train) [ 23850/160000]  lr: 8.6479e-06  eta: 16:08:07  time: 0.4121  data_time: 0.0098  memory: 4845  grad_norm: 88.3325  loss: 45.1123  decode.loss_cls: 1.5462  decode.loss_mask: 1.0075  decode.loss_dice: 1.6491  decode.d0.loss_cls: 3.5247  decode.d0.loss_mask: 1.1594  decode.d0.loss_dice: 1.9012  decode.d1.loss_cls: 1.7193  decode.d1.loss_mask: 1.0022  decode.d1.loss_dice: 1.7310  decode.d2.loss_cls: 1.6392  decode.d2.loss_mask: 1.0178  decode.d2.loss_dice: 1.6602  decode.d3.loss_cls: 1.6489  decode.d3.loss_mask: 0.9760  decode.d3.loss_dice: 1.6133  decode.d4.loss_cls: 1.5394  decode.d4.loss_mask: 1.0300  decode.d4.loss_dice: 1.6480  decode.d5.loss_cls: 1.5685  decode.d5.loss_mask: 1.0402  decode.d5.loss_dice: 1.6860  decode.d6.loss_cls: 1.6646  decode.d6.loss_mask: 0.9855  decode.d6.loss_dice: 1.6170  decode.d7.loss_cls: 1.5917  decode.d7.loss_mask: 1.0399  decode.d7.loss_dice: 1.6258  decode.d8.loss_cls: 1.6215  decode.d8.loss_mask: 1.0225  decode.d8.loss_dice: 1.6353
2023/05/23 21:13:11 - mmengine - INFO - Iter(train) [ 23900/160000]  lr: 8.6450e-06  eta: 16:07:43  time: 0.4114  data_time: 0.0096  memory: 4866  grad_norm: 96.5030  loss: 36.0737  decode.loss_cls: 1.4294  decode.loss_mask: 0.6786  decode.loss_dice: 1.2329  decode.d0.loss_cls: 3.0374  decode.d0.loss_mask: 0.7944  decode.d0.loss_dice: 1.4285  decode.d1.loss_cls: 1.5735  decode.d1.loss_mask: 0.7512  decode.d1.loss_dice: 1.3510  decode.d2.loss_cls: 1.4265  decode.d2.loss_mask: 0.6998  decode.d2.loss_dice: 1.3096  decode.d3.loss_cls: 1.4053  decode.d3.loss_mask: 0.6751  decode.d3.loss_dice: 1.2831  decode.d4.loss_cls: 1.3889  decode.d4.loss_mask: 0.6910  decode.d4.loss_dice: 1.2380  decode.d5.loss_cls: 1.4339  decode.d5.loss_mask: 0.6900  decode.d5.loss_dice: 1.2940  decode.d6.loss_cls: 1.4058  decode.d6.loss_mask: 0.7276  decode.d6.loss_dice: 1.3014  decode.d7.loss_cls: 1.4827  decode.d7.loss_mask: 0.6893  decode.d7.loss_dice: 1.2808  decode.d8.loss_cls: 1.4743  decode.d8.loss_mask: 0.6803  decode.d8.loss_dice: 1.2189
2023/05/23 21:13:32 - mmengine - INFO - Iter(train) [ 23950/160000]  lr: 8.6422e-06  eta: 16:07:18  time: 0.4101  data_time: 0.0095  memory: 4815  grad_norm: 149.5532  loss: 36.2450  decode.loss_cls: 1.2850  decode.loss_mask: 0.7533  decode.loss_dice: 1.3408  decode.d0.loss_cls: 3.3551  decode.d0.loss_mask: 0.8259  decode.d0.loss_dice: 1.5208  decode.d1.loss_cls: 1.3263  decode.d1.loss_mask: 0.7930  decode.d1.loss_dice: 1.4403  decode.d2.loss_cls: 1.2661  decode.d2.loss_mask: 0.7455  decode.d2.loss_dice: 1.3385  decode.d3.loss_cls: 1.3556  decode.d3.loss_mask: 0.7504  decode.d3.loss_dice: 1.2988  decode.d4.loss_cls: 1.2818  decode.d4.loss_mask: 0.7823  decode.d4.loss_dice: 1.3432  decode.d5.loss_cls: 1.2469  decode.d5.loss_mask: 0.7390  decode.d5.loss_dice: 1.3426  decode.d6.loss_cls: 1.2481  decode.d6.loss_mask: 0.7773  decode.d6.loss_dice: 1.3522  decode.d7.loss_cls: 1.2101  decode.d7.loss_mask: 0.7744  decode.d7.loss_dice: 1.3670  decode.d8.loss_cls: 1.2656  decode.d8.loss_mask: 0.7710  decode.d8.loss_dice: 1.3483
2023/05/23 21:13:53 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 21:13:53 - mmengine - INFO - Iter(train) [ 24000/160000]  lr: 8.6393e-06  eta: 16:06:55  time: 0.4099  data_time: 0.0099  memory: 4828  grad_norm: 84.0214  loss: 44.9674  decode.loss_cls: 1.5551  decode.loss_mask: 1.0542  decode.loss_dice: 1.5865  decode.d0.loss_cls: 3.5994  decode.d0.loss_mask: 1.1869  decode.d0.loss_dice: 1.8737  decode.d1.loss_cls: 1.6823  decode.d1.loss_mask: 1.1211  decode.d1.loss_dice: 1.7123  decode.d2.loss_cls: 1.5614  decode.d2.loss_mask: 1.0890  decode.d2.loss_dice: 1.6529  decode.d3.loss_cls: 1.5961  decode.d3.loss_mask: 1.0843  decode.d3.loss_dice: 1.6195  decode.d4.loss_cls: 1.5566  decode.d4.loss_mask: 1.0632  decode.d4.loss_dice: 1.5949  decode.d5.loss_cls: 1.5095  decode.d5.loss_mask: 1.0680  decode.d5.loss_dice: 1.6214  decode.d6.loss_cls: 1.5885  decode.d6.loss_mask: 1.0187  decode.d6.loss_dice: 1.5949  decode.d7.loss_cls: 1.5382  decode.d7.loss_mask: 1.0313  decode.d7.loss_dice: 1.5951  decode.d8.loss_cls: 1.5800  decode.d8.loss_mask: 1.0489  decode.d8.loss_dice: 1.5834
2023/05/23 21:13:53 - mmengine - INFO - Saving checkpoint at 24000 iterations
2023/05/23 21:14:19 - mmengine - INFO - Iter(train) [ 24050/160000]  lr: 8.6365e-06  eta: 16:07:00  time: 0.4041  data_time: 0.0097  memory: 4847  grad_norm: 97.1851  loss: 30.2987  decode.loss_cls: 1.0380  decode.loss_mask: 0.7333  decode.loss_dice: 0.9937  decode.d0.loss_cls: 2.9699  decode.d0.loss_mask: 0.7461  decode.d0.loss_dice: 1.1103  decode.d1.loss_cls: 1.1414  decode.d1.loss_mask: 0.7486  decode.d1.loss_dice: 1.0874  decode.d2.loss_cls: 1.1015  decode.d2.loss_mask: 0.7296  decode.d2.loss_dice: 1.0464  decode.d3.loss_cls: 1.1473  decode.d3.loss_mask: 0.6904  decode.d3.loss_dice: 0.9917  decode.d4.loss_cls: 1.0854  decode.d4.loss_mask: 0.7449  decode.d4.loss_dice: 1.0296  decode.d5.loss_cls: 1.1483  decode.d5.loss_mask: 0.6991  decode.d5.loss_dice: 1.0114  decode.d6.loss_cls: 1.0748  decode.d6.loss_mask: 0.6796  decode.d6.loss_dice: 1.0408  decode.d7.loss_cls: 1.0529  decode.d7.loss_mask: 0.6984  decode.d7.loss_dice: 1.0095  decode.d8.loss_cls: 1.0419  decode.d8.loss_mask: 0.7128  decode.d8.loss_dice: 0.9939
2023/05/23 21:14:39 - mmengine - INFO - Iter(train) [ 24100/160000]  lr: 8.6336e-06  eta: 16:06:35  time: 0.4027  data_time: 0.0098  memory: 4866  grad_norm: 92.1588  loss: 38.7186  decode.loss_cls: 1.3570  decode.loss_mask: 0.7550  decode.loss_dice: 1.4650  decode.d0.loss_cls: 3.2543  decode.d0.loss_mask: 0.8356  decode.d0.loss_dice: 1.6985  decode.d1.loss_cls: 1.5612  decode.d1.loss_mask: 0.7682  decode.d1.loss_dice: 1.6398  decode.d2.loss_cls: 1.4694  decode.d2.loss_mask: 0.7389  decode.d2.loss_dice: 1.5578  decode.d3.loss_cls: 1.4132  decode.d3.loss_mask: 0.7511  decode.d3.loss_dice: 1.4998  decode.d4.loss_cls: 1.3930  decode.d4.loss_mask: 0.7571  decode.d4.loss_dice: 1.4932  decode.d5.loss_cls: 1.3447  decode.d5.loss_mask: 0.7472  decode.d5.loss_dice: 1.4874  decode.d6.loss_cls: 1.3905  decode.d6.loss_mask: 0.7295  decode.d6.loss_dice: 1.4364  decode.d7.loss_cls: 1.3607  decode.d7.loss_mask: 0.7483  decode.d7.loss_dice: 1.4841  decode.d8.loss_cls: 1.3453  decode.d8.loss_mask: 0.7731  decode.d8.loss_dice: 1.4632
2023/05/23 21:15:00 - mmengine - INFO - Iter(train) [ 24150/160000]  lr: 8.6307e-06  eta: 16:06:09  time: 0.4171  data_time: 0.0100  memory: 4842  grad_norm: 97.9416  loss: 37.3972  decode.loss_cls: 1.4274  decode.loss_mask: 0.8237  decode.loss_dice: 1.2358  decode.d0.loss_cls: 3.3364  decode.d0.loss_mask: 0.9180  decode.d0.loss_dice: 1.4241  decode.d1.loss_cls: 1.5897  decode.d1.loss_mask: 0.8647  decode.d1.loss_dice: 1.3202  decode.d2.loss_cls: 1.4870  decode.d2.loss_mask: 0.8610  decode.d2.loss_dice: 1.2410  decode.d3.loss_cls: 1.4082  decode.d3.loss_mask: 0.8375  decode.d3.loss_dice: 1.2379  decode.d4.loss_cls: 1.3845  decode.d4.loss_mask: 0.8505  decode.d4.loss_dice: 1.2429  decode.d5.loss_cls: 1.4131  decode.d5.loss_mask: 0.8407  decode.d5.loss_dice: 1.2563  decode.d6.loss_cls: 1.3716  decode.d6.loss_mask: 0.8334  decode.d6.loss_dice: 1.2457  decode.d7.loss_cls: 1.4166  decode.d7.loss_mask: 0.8411  decode.d7.loss_dice: 1.2343  decode.d8.loss_cls: 1.3502  decode.d8.loss_mask: 0.8412  decode.d8.loss_dice: 1.2626
2023/05/23 21:15:21 - mmengine - INFO - Iter(train) [ 24200/160000]  lr: 8.6279e-06  eta: 16:05:45  time: 0.4180  data_time: 0.0101  memory: 4875  grad_norm: 98.9976  loss: 36.4436  decode.loss_cls: 1.3070  decode.loss_mask: 0.8233  decode.loss_dice: 1.1891  decode.d0.loss_cls: 3.3595  decode.d0.loss_mask: 0.9467  decode.d0.loss_dice: 1.4729  decode.d1.loss_cls: 1.3899  decode.d1.loss_mask: 0.9277  decode.d1.loss_dice: 1.3907  decode.d2.loss_cls: 1.3498  decode.d2.loss_mask: 0.8663  decode.d2.loss_dice: 1.2975  decode.d3.loss_cls: 1.3453  decode.d3.loss_mask: 0.8227  decode.d3.loss_dice: 1.1921  decode.d4.loss_cls: 1.3078  decode.d4.loss_mask: 0.8325  decode.d4.loss_dice: 1.2264  decode.d5.loss_cls: 1.3040  decode.d5.loss_mask: 0.8450  decode.d5.loss_dice: 1.2390  decode.d6.loss_cls: 1.3272  decode.d6.loss_mask: 0.8183  decode.d6.loss_dice: 1.1890  decode.d7.loss_cls: 1.3015  decode.d7.loss_mask: 0.8210  decode.d7.loss_dice: 1.2217  decode.d8.loss_cls: 1.2859  decode.d8.loss_mask: 0.8232  decode.d8.loss_dice: 1.2205
2023/05/23 21:15:44 - mmengine - INFO - Iter(train) [ 24250/160000]  lr: 8.6250e-06  eta: 16:05:34  time: 0.4657  data_time: 0.0095  memory: 4859  grad_norm: 99.1442  loss: 40.5734  decode.loss_cls: 1.4254  decode.loss_mask: 0.8587  decode.loss_dice: 1.5109  decode.d0.loss_cls: 3.5188  decode.d0.loss_mask: 0.8456  decode.d0.loss_dice: 1.6843  decode.d1.loss_cls: 1.6347  decode.d1.loss_mask: 0.8204  decode.d1.loss_dice: 1.6397  decode.d2.loss_cls: 1.4177  decode.d2.loss_mask: 0.8482  decode.d2.loss_dice: 1.5576  decode.d3.loss_cls: 1.5268  decode.d3.loss_mask: 0.8658  decode.d3.loss_dice: 1.4782  decode.d4.loss_cls: 1.5093  decode.d4.loss_mask: 0.8400  decode.d4.loss_dice: 1.5098  decode.d5.loss_cls: 1.4503  decode.d5.loss_mask: 0.7911  decode.d5.loss_dice: 1.4890  decode.d6.loss_cls: 1.5277  decode.d6.loss_mask: 0.8130  decode.d6.loss_dice: 1.4790  decode.d7.loss_cls: 1.4158  decode.d7.loss_mask: 0.8625  decode.d7.loss_dice: 1.4614  decode.d8.loss_cls: 1.4520  decode.d8.loss_mask: 0.8615  decode.d8.loss_dice: 1.4780
2023/05/23 21:16:06 - mmengine - INFO - Iter(train) [ 24300/160000]  lr: 8.6222e-06  eta: 16:05:14  time: 0.4131  data_time: 0.0101  memory: 4898  grad_norm: 91.5581  loss: 35.4467  decode.loss_cls: 1.3430  decode.loss_mask: 0.7615  decode.loss_dice: 1.1419  decode.d0.loss_cls: 3.1055  decode.d0.loss_mask: 0.8942  decode.d0.loss_dice: 1.3732  decode.d1.loss_cls: 1.4804  decode.d1.loss_mask: 0.8411  decode.d1.loss_dice: 1.2797  decode.d2.loss_cls: 1.3551  decode.d2.loss_mask: 0.8689  decode.d2.loss_dice: 1.2397  decode.d3.loss_cls: 1.3429  decode.d3.loss_mask: 0.8052  decode.d3.loss_dice: 1.1483  decode.d4.loss_cls: 1.3572  decode.d4.loss_mask: 0.7895  decode.d4.loss_dice: 1.1887  decode.d5.loss_cls: 1.3438  decode.d5.loss_mask: 0.7998  decode.d5.loss_dice: 1.1544  decode.d6.loss_cls: 1.3123  decode.d6.loss_mask: 0.7904  decode.d6.loss_dice: 1.1676  decode.d7.loss_cls: 1.3330  decode.d7.loss_mask: 0.7858  decode.d7.loss_dice: 1.1682  decode.d8.loss_cls: 1.3508  decode.d8.loss_mask: 0.7799  decode.d8.loss_dice: 1.1449
2023/05/23 21:16:26 - mmengine - INFO - Iter(train) [ 24350/160000]  lr: 8.6193e-06  eta: 16:04:49  time: 0.4122  data_time: 0.0105  memory: 4829  grad_norm: 97.7542  loss: 45.6454  decode.loss_cls: 1.4085  decode.loss_mask: 1.0855  decode.loss_dice: 1.7012  decode.d0.loss_cls: 3.5532  decode.d0.loss_mask: 1.2133  decode.d0.loss_dice: 2.0168  decode.d1.loss_cls: 1.6628  decode.d1.loss_mask: 1.1477  decode.d1.loss_dice: 1.8979  decode.d2.loss_cls: 1.5300  decode.d2.loss_mask: 1.1226  decode.d2.loss_dice: 1.8103  decode.d3.loss_cls: 1.4220  decode.d3.loss_mask: 1.1014  decode.d3.loss_dice: 1.7612  decode.d4.loss_cls: 1.4274  decode.d4.loss_mask: 1.0877  decode.d4.loss_dice: 1.7444  decode.d5.loss_cls: 1.4247  decode.d5.loss_mask: 1.0992  decode.d5.loss_dice: 1.7128  decode.d6.loss_cls: 1.4739  decode.d6.loss_mask: 1.0676  decode.d6.loss_dice: 1.7159  decode.d7.loss_cls: 1.4176  decode.d7.loss_mask: 1.1058  decode.d7.loss_dice: 1.7197  decode.d8.loss_cls: 1.3921  decode.d8.loss_mask: 1.1033  decode.d8.loss_dice: 1.7189
2023/05/23 21:16:47 - mmengine - INFO - Iter(train) [ 24400/160000]  lr: 8.6164e-06  eta: 16:04:27  time: 0.4120  data_time: 0.0096  memory: 4882  grad_norm: 88.3798  loss: 49.5133  decode.loss_cls: 1.8009  decode.loss_mask: 0.9144  decode.loss_dice: 1.8737  decode.d0.loss_cls: 3.8493  decode.d0.loss_mask: 1.0169  decode.d0.loss_dice: 2.1770  decode.d1.loss_cls: 2.0090  decode.d1.loss_mask: 0.9560  decode.d1.loss_dice: 2.0453  decode.d2.loss_cls: 1.9569  decode.d2.loss_mask: 0.8971  decode.d2.loss_dice: 1.9408  decode.d3.loss_cls: 1.8253  decode.d3.loss_mask: 0.9543  decode.d3.loss_dice: 1.9069  decode.d4.loss_cls: 1.7804  decode.d4.loss_mask: 0.9336  decode.d4.loss_dice: 1.9322  decode.d5.loss_cls: 1.8940  decode.d5.loss_mask: 0.9200  decode.d5.loss_dice: 1.8832  decode.d6.loss_cls: 1.8253  decode.d6.loss_mask: 0.9174  decode.d6.loss_dice: 1.8925  decode.d7.loss_cls: 1.9061  decode.d7.loss_mask: 0.9210  decode.d7.loss_dice: 1.9241  decode.d8.loss_cls: 1.8241  decode.d8.loss_mask: 0.9244  decode.d8.loss_dice: 1.9111
2023/05/23 21:17:08 - mmengine - INFO - Iter(train) [ 24450/160000]  lr: 8.6136e-06  eta: 16:04:02  time: 0.4052  data_time: 0.0095  memory: 4890  grad_norm: 97.7382  loss: 41.3490  decode.loss_cls: 1.7742  decode.loss_mask: 0.7546  decode.loss_dice: 1.3433  decode.d0.loss_cls: 3.5402  decode.d0.loss_mask: 0.7727  decode.d0.loss_dice: 1.5126  decode.d1.loss_cls: 1.8075  decode.d1.loss_mask: 0.7853  decode.d1.loss_dice: 1.4646  decode.d2.loss_cls: 1.7361  decode.d2.loss_mask: 0.8030  decode.d2.loss_dice: 1.4030  decode.d3.loss_cls: 1.7766  decode.d3.loss_mask: 0.8418  decode.d3.loss_dice: 1.3983  decode.d4.loss_cls: 1.7760  decode.d4.loss_mask: 0.7908  decode.d4.loss_dice: 1.4137  decode.d5.loss_cls: 1.8218  decode.d5.loss_mask: 0.8242  decode.d5.loss_dice: 1.3959  decode.d6.loss_cls: 1.6933  decode.d6.loss_mask: 0.8231  decode.d6.loss_dice: 1.4019  decode.d7.loss_cls: 1.7886  decode.d7.loss_mask: 0.7426  decode.d7.loss_dice: 1.3454  decode.d8.loss_cls: 1.7406  decode.d8.loss_mask: 0.7434  decode.d8.loss_dice: 1.3339
2023/05/23 21:17:29 - mmengine - INFO - Iter(train) [ 24500/160000]  lr: 8.6107e-06  eta: 16:03:36  time: 0.4127  data_time: 0.0097  memory: 4900  grad_norm: 112.1601  loss: 26.2206  decode.loss_cls: 0.6989  decode.loss_mask: 0.5657  decode.loss_dice: 1.1068  decode.d0.loss_cls: 2.6545  decode.d0.loss_mask: 0.5699  decode.d0.loss_dice: 1.1668  decode.d1.loss_cls: 0.9417  decode.d1.loss_mask: 0.5692  decode.d1.loss_dice: 1.1429  decode.d2.loss_cls: 0.8218  decode.d2.loss_mask: 0.5570  decode.d2.loss_dice: 1.0798  decode.d3.loss_cls: 0.7508  decode.d3.loss_mask: 0.5680  decode.d3.loss_dice: 1.0760  decode.d4.loss_cls: 0.7190  decode.d4.loss_mask: 0.5741  decode.d4.loss_dice: 1.1314  decode.d5.loss_cls: 0.7404  decode.d5.loss_mask: 0.5726  decode.d5.loss_dice: 1.0964  decode.d6.loss_cls: 0.7068  decode.d6.loss_mask: 0.5785  decode.d6.loss_dice: 1.1120  decode.d7.loss_cls: 0.7590  decode.d7.loss_mask: 0.5157  decode.d7.loss_dice: 1.1011  decode.d8.loss_cls: 0.7395  decode.d8.loss_mask: 0.5414  decode.d8.loss_dice: 1.0627
2023/05/23 21:17:49 - mmengine - INFO - Iter(train) [ 24550/160000]  lr: 8.6079e-06  eta: 16:03:10  time: 0.4135  data_time: 0.0097  memory: 4929  grad_norm: 94.3441  loss: 38.6945  decode.loss_cls: 1.5399  decode.loss_mask: 0.7256  decode.loss_dice: 1.3597  decode.d0.loss_cls: 3.1087  decode.d0.loss_mask: 0.8148  decode.d0.loss_dice: 1.6322  decode.d1.loss_cls: 1.6232  decode.d1.loss_mask: 0.7999  decode.d1.loss_dice: 1.4532  decode.d2.loss_cls: 1.5367  decode.d2.loss_mask: 0.7824  decode.d2.loss_dice: 1.4243  decode.d3.loss_cls: 1.5347  decode.d3.loss_mask: 0.7474  decode.d3.loss_dice: 1.3835  decode.d4.loss_cls: 1.5606  decode.d4.loss_mask: 0.7349  decode.d4.loss_dice: 1.3991  decode.d5.loss_cls: 1.5451  decode.d5.loss_mask: 0.7474  decode.d5.loss_dice: 1.4053  decode.d6.loss_cls: 1.5176  decode.d6.loss_mask: 0.7189  decode.d6.loss_dice: 1.3775  decode.d7.loss_cls: 1.5095  decode.d7.loss_mask: 0.7493  decode.d7.loss_dice: 1.3628  decode.d8.loss_cls: 1.4754  decode.d8.loss_mask: 0.7522  decode.d8.loss_dice: 1.3728
2023/05/23 21:18:10 - mmengine - INFO - Iter(train) [ 24600/160000]  lr: 8.6050e-06  eta: 16:02:46  time: 0.4114  data_time: 0.0096  memory: 4804  grad_norm: 127.2378  loss: 35.5964  decode.loss_cls: 1.3017  decode.loss_mask: 0.7858  decode.loss_dice: 1.1926  decode.d0.loss_cls: 3.0364  decode.d0.loss_mask: 0.8340  decode.d0.loss_dice: 1.3552  decode.d1.loss_cls: 1.4486  decode.d1.loss_mask: 0.8231  decode.d1.loss_dice: 1.2464  decode.d2.loss_cls: 1.4933  decode.d2.loss_mask: 0.7943  decode.d2.loss_dice: 1.2220  decode.d3.loss_cls: 1.4456  decode.d3.loss_mask: 0.7643  decode.d3.loss_dice: 1.2194  decode.d4.loss_cls: 1.4374  decode.d4.loss_mask: 0.7712  decode.d4.loss_dice: 1.2123  decode.d5.loss_cls: 1.3398  decode.d5.loss_mask: 0.8177  decode.d5.loss_dice: 1.2479  decode.d6.loss_cls: 1.3300  decode.d6.loss_mask: 0.7803  decode.d6.loss_dice: 1.1732  decode.d7.loss_cls: 1.3365  decode.d7.loss_mask: 0.7708  decode.d7.loss_dice: 1.1526  decode.d8.loss_cls: 1.3770  decode.d8.loss_mask: 0.7520  decode.d8.loss_dice: 1.1350
2023/05/23 21:18:31 - mmengine - INFO - Iter(train) [ 24650/160000]  lr: 8.6021e-06  eta: 16:02:22  time: 0.4204  data_time: 0.0098  memory: 4830  grad_norm: 94.1956  loss: 43.8460  decode.loss_cls: 1.6219  decode.loss_mask: 0.9264  decode.loss_dice: 1.4950  decode.d0.loss_cls: 3.6213  decode.d0.loss_mask: 0.9542  decode.d0.loss_dice: 1.8181  decode.d1.loss_cls: 1.8512  decode.d1.loss_mask: 0.9528  decode.d1.loss_dice: 1.6595  decode.d2.loss_cls: 1.7223  decode.d2.loss_mask: 0.9983  decode.d2.loss_dice: 1.6272  decode.d3.loss_cls: 1.6346  decode.d3.loss_mask: 0.9276  decode.d3.loss_dice: 1.5103  decode.d4.loss_cls: 1.6633  decode.d4.loss_mask: 0.9318  decode.d4.loss_dice: 1.5610  decode.d5.loss_cls: 1.6331  decode.d5.loss_mask: 0.9521  decode.d5.loss_dice: 1.5728  decode.d6.loss_cls: 1.6560  decode.d6.loss_mask: 0.9239  decode.d6.loss_dice: 1.5033  decode.d7.loss_cls: 1.6446  decode.d7.loss_mask: 0.9240  decode.d7.loss_dice: 1.4798  decode.d8.loss_cls: 1.6529  decode.d8.loss_mask: 0.9162  decode.d8.loss_dice: 1.5103
2023/05/23 21:18:52 - mmengine - INFO - Iter(train) [ 24700/160000]  lr: 8.5993e-06  eta: 16:02:00  time: 0.4065  data_time: 0.0096  memory: 4837  grad_norm: 90.6908  loss: 47.6358  decode.loss_cls: 1.8615  decode.loss_mask: 0.9803  decode.loss_dice: 1.6804  decode.d0.loss_cls: 3.6893  decode.d0.loss_mask: 0.9989  decode.d0.loss_dice: 1.8106  decode.d1.loss_cls: 1.9378  decode.d1.loss_mask: 0.9885  decode.d1.loss_dice: 1.7027  decode.d2.loss_cls: 1.9802  decode.d2.loss_mask: 0.9681  decode.d2.loss_dice: 1.6882  decode.d3.loss_cls: 1.8813  decode.d3.loss_mask: 0.9651  decode.d3.loss_dice: 1.6512  decode.d4.loss_cls: 1.9536  decode.d4.loss_mask: 0.9754  decode.d4.loss_dice: 1.6589  decode.d5.loss_cls: 1.9070  decode.d5.loss_mask: 0.9616  decode.d5.loss_dice: 1.7082  decode.d6.loss_cls: 1.9120  decode.d6.loss_mask: 0.9595  decode.d6.loss_dice: 1.6770  decode.d7.loss_cls: 1.9225  decode.d7.loss_mask: 0.9731  decode.d7.loss_dice: 1.6555  decode.d8.loss_cls: 1.9116  decode.d8.loss_mask: 0.9887  decode.d8.loss_dice: 1.6871
2023/05/23 21:19:13 - mmengine - INFO - Iter(train) [ 24750/160000]  lr: 8.5964e-06  eta: 16:01:36  time: 0.4292  data_time: 0.0098  memory: 4898  grad_norm: 127.2244  loss: 43.8380  decode.loss_cls: 1.7249  decode.loss_mask: 0.8629  decode.loss_dice: 1.5162  decode.d0.loss_cls: 3.5104  decode.d0.loss_mask: 0.9425  decode.d0.loss_dice: 1.7540  decode.d1.loss_cls: 1.8341  decode.d1.loss_mask: 0.9780  decode.d1.loss_dice: 1.6678  decode.d2.loss_cls: 1.8174  decode.d2.loss_mask: 0.9019  decode.d2.loss_dice: 1.5939  decode.d3.loss_cls: 1.7716  decode.d3.loss_mask: 0.8769  decode.d3.loss_dice: 1.5719  decode.d4.loss_cls: 1.7694  decode.d4.loss_mask: 0.8449  decode.d4.loss_dice: 1.5038  decode.d5.loss_cls: 1.7454  decode.d5.loss_mask: 0.8512  decode.d5.loss_dice: 1.5270  decode.d6.loss_cls: 1.7229  decode.d6.loss_mask: 0.8529  decode.d6.loss_dice: 1.5276  decode.d7.loss_cls: 1.7055  decode.d7.loss_mask: 0.8530  decode.d7.loss_dice: 1.5374  decode.d8.loss_cls: 1.6849  decode.d8.loss_mask: 0.8570  decode.d8.loss_dice: 1.5308
2023/05/23 21:19:34 - mmengine - INFO - Iter(train) [ 24800/160000]  lr: 8.5936e-06  eta: 16:01:14  time: 0.4507  data_time: 0.0107  memory: 4867  grad_norm: 132.9302  loss: 35.2405  decode.loss_cls: 1.3312  decode.loss_mask: 0.7379  decode.loss_dice: 1.2308  decode.d0.loss_cls: 3.0934  decode.d0.loss_mask: 0.7911  decode.d0.loss_dice: 1.4666  decode.d1.loss_cls: 1.4962  decode.d1.loss_mask: 0.7477  decode.d1.loss_dice: 1.3310  decode.d2.loss_cls: 1.3251  decode.d2.loss_mask: 0.7349  decode.d2.loss_dice: 1.3095  decode.d3.loss_cls: 1.3238  decode.d3.loss_mask: 0.7027  decode.d3.loss_dice: 1.2528  decode.d4.loss_cls: 1.3488  decode.d4.loss_mask: 0.7267  decode.d4.loss_dice: 1.2640  decode.d5.loss_cls: 1.2899  decode.d5.loss_mask: 0.7206  decode.d5.loss_dice: 1.2402  decode.d6.loss_cls: 1.3015  decode.d6.loss_mask: 0.7146  decode.d6.loss_dice: 1.2279  decode.d7.loss_cls: 1.3335  decode.d7.loss_mask: 0.7031  decode.d7.loss_dice: 1.2221  decode.d8.loss_cls: 1.3425  decode.d8.loss_mask: 0.7062  decode.d8.loss_dice: 1.2241
2023/05/23 21:19:58 - mmengine - INFO - Iter(train) [ 24850/160000]  lr: 8.5907e-06  eta: 16:01:06  time: 0.4808  data_time: 0.0107  memory: 4845  grad_norm: 111.6002  loss: 39.3887  decode.loss_cls: 1.3883  decode.loss_mask: 0.9522  decode.loss_dice: 1.3629  decode.d0.loss_cls: 3.3297  decode.d0.loss_mask: 0.9309  decode.d0.loss_dice: 1.5306  decode.d1.loss_cls: 1.5426  decode.d1.loss_mask: 0.9498  decode.d1.loss_dice: 1.4252  decode.d2.loss_cls: 1.5764  decode.d2.loss_mask: 0.9054  decode.d2.loss_dice: 1.3864  decode.d3.loss_cls: 1.5185  decode.d3.loss_mask: 0.8931  decode.d3.loss_dice: 1.3238  decode.d4.loss_cls: 1.4146  decode.d4.loss_mask: 0.9013  decode.d4.loss_dice: 1.3361  decode.d5.loss_cls: 1.3583  decode.d5.loss_mask: 0.9047  decode.d5.loss_dice: 1.3149  decode.d6.loss_cls: 1.4238  decode.d6.loss_mask: 0.9143  decode.d6.loss_dice: 1.3353  decode.d7.loss_cls: 1.4317  decode.d7.loss_mask: 0.9331  decode.d7.loss_dice: 1.3605  decode.d8.loss_cls: 1.4323  decode.d8.loss_mask: 0.9546  decode.d8.loss_dice: 1.3571
2023/05/23 21:20:19 - mmengine - INFO - Iter(train) [ 24900/160000]  lr: 8.5878e-06  eta: 16:00:46  time: 0.4219  data_time: 0.0100  memory: 4824  grad_norm: 114.3461  loss: 45.2450  decode.loss_cls: 1.6470  decode.loss_mask: 1.0769  decode.loss_dice: 1.4813  decode.d0.loss_cls: 3.3553  decode.d0.loss_mask: 1.1749  decode.d0.loss_dice: 1.7436  decode.d1.loss_cls: 1.7762  decode.d1.loss_mask: 1.0875  decode.d1.loss_dice: 1.6533  decode.d2.loss_cls: 1.7256  decode.d2.loss_mask: 1.1121  decode.d2.loss_dice: 1.5852  decode.d3.loss_cls: 1.7955  decode.d3.loss_mask: 1.0686  decode.d3.loss_dice: 1.5266  decode.d4.loss_cls: 1.7402  decode.d4.loss_mask: 1.1028  decode.d4.loss_dice: 1.5276  decode.d5.loss_cls: 1.6614  decode.d5.loss_mask: 1.0935  decode.d5.loss_dice: 1.5275  decode.d6.loss_cls: 1.6866  decode.d6.loss_mask: 1.1051  decode.d6.loss_dice: 1.5397  decode.d7.loss_cls: 1.7004  decode.d7.loss_mask: 1.0765  decode.d7.loss_dice: 1.5056  decode.d8.loss_cls: 1.6292  decode.d8.loss_mask: 1.0620  decode.d8.loss_dice: 1.4771
2023/05/23 21:20:40 - mmengine - INFO - Iter(train) [ 24950/160000]  lr: 8.5850e-06  eta: 16:00:19  time: 0.4095  data_time: 0.0099  memory: 4876  grad_norm: 91.8435  loss: 41.5865  decode.loss_cls: 1.5713  decode.loss_mask: 0.8126  decode.loss_dice: 1.4490  decode.d0.loss_cls: 3.6872  decode.d0.loss_mask: 0.8069  decode.d0.loss_dice: 1.7223  decode.d1.loss_cls: 1.6323  decode.d1.loss_mask: 0.8266  decode.d1.loss_dice: 1.5813  decode.d2.loss_cls: 1.6162  decode.d2.loss_mask: 0.8262  decode.d2.loss_dice: 1.5568  decode.d3.loss_cls: 1.6134  decode.d3.loss_mask: 0.8478  decode.d3.loss_dice: 1.5322  decode.d4.loss_cls: 1.6383  decode.d4.loss_mask: 0.8178  decode.d4.loss_dice: 1.4950  decode.d5.loss_cls: 1.6103  decode.d5.loss_mask: 0.8002  decode.d5.loss_dice: 1.4676  decode.d6.loss_cls: 1.5762  decode.d6.loss_mask: 0.8071  decode.d6.loss_dice: 1.4971  decode.d7.loss_cls: 1.5830  decode.d7.loss_mask: 0.8135  decode.d7.loss_dice: 1.5282  decode.d8.loss_cls: 1.5856  decode.d8.loss_mask: 0.8103  decode.d8.loss_dice: 1.4742
2023/05/23 21:21:03 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 21:21:03 - mmengine - INFO - Iter(train) [ 25000/160000]  lr: 8.5821e-06  eta: 16:00:07  time: 0.4653  data_time: 0.0095  memory: 4896  grad_norm: 94.7300  loss: 40.6126  decode.loss_cls: 1.5318  decode.loss_mask: 0.7540  decode.loss_dice: 1.4534  decode.d0.loss_cls: 3.6320  decode.d0.loss_mask: 0.8115  decode.d0.loss_dice: 1.6807  decode.d1.loss_cls: 1.6661  decode.d1.loss_mask: 0.8371  decode.d1.loss_dice: 1.6484  decode.d2.loss_cls: 1.6366  decode.d2.loss_mask: 0.7657  decode.d2.loss_dice: 1.5377  decode.d3.loss_cls: 1.4926  decode.d3.loss_mask: 0.7730  decode.d3.loss_dice: 1.5708  decode.d4.loss_cls: 1.5388  decode.d4.loss_mask: 0.7520  decode.d4.loss_dice: 1.5281  decode.d5.loss_cls: 1.5167  decode.d5.loss_mask: 0.7316  decode.d5.loss_dice: 1.5171  decode.d6.loss_cls: 1.4450  decode.d6.loss_mask: 0.7435  decode.d6.loss_dice: 1.5311  decode.d7.loss_cls: 1.5228  decode.d7.loss_mask: 0.7492  decode.d7.loss_dice: 1.5057  decode.d8.loss_cls: 1.5513  decode.d8.loss_mask: 0.7385  decode.d8.loss_dice: 1.4502
2023/05/23 21:21:03 - mmengine - INFO - Saving checkpoint at 25000 iterations
2023/05/23 21:21:14 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:01:02  time: 0.1014  data_time: 0.0021  memory: 2167  
2023/05/23 21:21:18 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:52  time: 0.0804  data_time: 0.0020  memory: 2216  
2023/05/23 21:21:22 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:43  time: 0.0804  data_time: 0.0018  memory: 2167  
2023/05/23 21:21:26 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:38  time: 0.0852  data_time: 0.0019  memory: 2104  
2023/05/23 21:21:31 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:33  time: 0.0796  data_time: 0.0019  memory: 2831  
2023/05/23 21:21:35 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:28  time: 0.0789  data_time: 0.0018  memory: 2167  
2023/05/23 21:21:39 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:23  time: 0.0798  data_time: 0.0018  memory: 2167  
2023/05/23 21:21:43 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0805  data_time: 0.0019  memory: 2167  
2023/05/23 21:21:47 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0899  data_time: 0.0020  memory: 2944  
2023/05/23 21:21:51 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0878  data_time: 0.0022  memory: 2356  
2023/05/23 21:21:55 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0789  data_time: 0.0018  memory: 2217  
2023/05/23 21:21:59 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0808  data_time: 0.0019  memory: 2328  
2023/05/23 21:22:03 - mmengine - INFO - per class results:
2023/05/23 21:22:03 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 84.83 | 92.59 |
|     bicycle      | 62.66 | 80.26 |
|       car        | 54.03 | 83.95 |
|    motorcycle    | 81.29 | 90.66 |
|     airplane     | 81.84 | 88.12 |
|       bus        | 77.67 | 84.28 |
|      train       | 79.93 | 87.52 |
|      truck       | 44.02 | 62.73 |
|       boat       | 53.26 | 66.94 |
|  traffic light   | 63.21 | 83.07 |
|   fire hydrant   | 86.16 | 94.42 |
|    stop sign     | 89.15 | 96.45 |
|  parking meter   | 71.72 | 80.81 |
|      bench       | 44.46 | 66.18 |
|       bird       | 80.21 | 88.21 |
|       cat        | 84.88 | 93.01 |
|       dog        |  77.2 |  86.9 |
|      horse       | 80.29 | 88.14 |
|      sheep       | 84.43 | 91.38 |
|       cow        | 77.21 | 88.25 |
|     elephant     | 88.94 |  94.6 |
|       bear       | 91.24 | 94.53 |
|      zebra       | 89.82 |  93.1 |
|     giraffe      | 83.21 |  92.8 |
|     backpack     | 25.91 | 57.28 |
|     umbrella     | 74.79 | 88.32 |
|     handbag      |  29.2 | 43.71 |
|       tie        |  9.38 |  12.3 |
|     suitcase     | 64.12 | 91.83 |
|     frisbee      | 70.45 | 85.83 |
|       skis       | 35.84 | 51.81 |
|    snowboard     | 37.54 | 50.14 |
|   sports ball    | 44.78 | 73.72 |
|       kite       | 46.26 | 53.23 |
|   baseball bat   | 46.56 |  58.8 |
|  baseball glove  | 61.58 | 76.95 |
|    skateboard    | 70.48 | 85.59 |
|    surfboard     | 74.09 | 85.38 |
|  tennis racket   | 81.91 | 89.05 |
|      bottle      | 32.48 | 40.73 |
|    wine glass    | 49.62 | 66.86 |
|       cup        | 45.44 | 69.47 |
|       fork       | 20.66 |  26.3 |
|      knife       | 22.36 | 37.99 |
|      spoon       | 27.52 | 37.17 |
|       bowl       | 44.87 | 65.77 |
|      banana      | 65.02 | 83.86 |
|      apple       | 49.74 | 60.21 |
|     sandwich     | 41.88 |  73.7 |
|      orange      | 68.57 |  83.5 |
|     broccoli     | 48.39 | 82.38 |
|      carrot      |  43.4 | 48.99 |
|     hot dog      |  49.3 | 55.25 |
|      pizza       | 63.62 | 76.06 |
|      donut       | 54.43 | 65.82 |
|       cake       |  52.3 | 64.98 |
|      chair       | 36.14 | 58.67 |
|      couch       | 46.89 | 78.42 |
|   potted plant   | 27.56 | 55.44 |
|       bed        | 57.76 | 70.24 |
|   dining table   | 39.72 | 75.69 |
|      toilet      | 77.44 | 90.02 |
|        tv        | 71.11 | 80.82 |
|      laptop      | 71.27 | 87.38 |
|      mouse       | 66.68 | 84.96 |
|      remote      | 54.11 | 74.65 |
|     keyboard     |  61.2 | 73.25 |
|    cell phone    | 66.21 | 84.97 |
|    microwave     | 49.71 | 75.25 |
|       oven       | 45.25 | 71.47 |
|     toaster      |  0.07 |  0.07 |
|       sink       | 58.77 | 72.09 |
|   refrigerator   | 67.52 | 88.17 |
|       book       |  42.5 | 57.56 |
|      clock       | 73.22 | 84.11 |
|       vase       | 53.31 | 77.44 |
|     scissors     | 53.51 | 60.35 |
|    teddy bear    | 73.63 | 82.66 |
|    hair drier    |  0.0  |  0.0  |
|    toothbrush    | 10.72 | 66.55 |
|      banner      | 31.26 | 65.84 |
|     blanket      |  3.74 |  4.6  |
|      branch      | 23.61 | 38.85 |
|      bridge      | 30.56 | 38.09 |
|  building-other  | 47.82 | 71.31 |
|       bush       | 31.65 | 53.99 |
|     cabinet      | 50.07 | 70.69 |
|       cage       |  5.79 |  6.56 |
|    cardboard     | 38.56 | 51.92 |
|      carpet      |  46.1 | 65.23 |
|  ceiling-other   | 60.32 |  74.6 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 14.99 | 19.05 |
|      clouds      | 48.52 | 64.49 |
|     counter      | 22.48 | 40.66 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 60.34 | 69.65 |
|    desk-stuff    | 41.14 | 53.81 |
|       dirt       | 38.79 | 65.17 |
|    door-stuff    | 29.73 | 49.37 |
|      fence       | 36.02 | 70.33 |
|   floor-marble   |  0.0  |  0.0  |
|   floor-other    |  16.4 | 22.57 |
|   floor-stone    |  2.46 |  3.0  |
|    floor-tile    |  57.2 | 73.03 |
|    floor-wood    | 59.39 |  71.4 |
|      flower      | 22.62 | 26.74 |
|       fog        |  1.65 |  1.66 |
|    food-other    | 19.17 | 22.35 |
|      fruit       | 35.78 | 51.36 |
| furniture-other  | 13.25 | 18.31 |
|      grass       | 70.79 | 82.47 |
|      gravel      | 23.57 | 42.23 |
|   ground-other   |  4.26 |  5.72 |
|       hill       | 19.29 | 28.41 |
|      house       | 23.63 | 31.27 |
|      leaves      | 24.27 | 31.58 |
|      light       |  34.5 | 49.99 |
|       mat        |  0.0  |  0.0  |
|      metal       |  27.7 | 41.35 |
|   mirror-stuff   | 37.79 | 62.09 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 48.96 | 65.53 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  1.49 |  1.65 |
|       net        | 46.91 | 52.55 |
|      paper       | 23.75 | 28.93 |
|     pavement     | 47.88 | 65.34 |
|      pillow      |  2.13 |  4.18 |
|   plant-other    | 16.78 | 28.96 |
|     plastic      | 13.04 | 15.57 |
|     platform     | 23.41 | 36.38 |
|   playingfield   | 66.44 | 83.72 |
|     railing      |  0.51 |  0.62 |
|     railroad     |  56.1 | 78.34 |
|      river       | 36.06 | 48.87 |
|       road       | 62.41 | 81.13 |
|       rock       | 31.36 | 45.37 |
|       roof       | 17.29 | 24.41 |
|       rug        | 32.98 | 60.89 |
|      salad       |  0.0  |  0.0  |
|       sand       | 58.42 | 64.22 |
|       sea        | 82.46 | 85.48 |
|      shelf       | 28.36 | 35.06 |
|    sky-other     | 70.33 | 86.82 |
|    skyscraper    |  21.3 |  24.6 |
|       snow       | 88.65 | 92.31 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 17.88 |  28.3 |
|      stone       | 15.73 | 30.83 |
|      straw       | 26.16 | 36.57 |
| structural-other |  0.0  |  0.0  |
|      table       | 19.21 |  28.9 |
|       tent       |  4.95 |  5.82 |
|  textile-other   | 10.29 | 19.39 |
|      towel       | 29.05 | 36.55 |
|       tree       | 72.35 |  85.6 |
|    vegetable     | 26.32 |  34.2 |
|    wall-brick    | 41.29 | 48.74 |
|  wall-concrete   | 57.56 | 72.42 |
|    wall-other    | 15.88 | 27.31 |
|    wall-panel    |  5.99 |  7.13 |
|    wall-stone    | 31.04 | 45.33 |
|    wall-tile     |  59.9 | 71.79 |
|    wall-wood     | 38.48 | 46.07 |
|   water-other    | 22.09 | 49.73 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 44.29 | 49.81 |
|   window-other   | 38.75 | 71.98 |
|       wood       |  22.4 | 36.79 |
+------------------+-------+-------+
2023/05/23 21:22:03 - mmengine - INFO - Iter(val) [625/625]    aAcc: 68.3500  mIoU: 42.1100  mAcc: 54.6600  data_time: 0.0020  time: 0.0846
2023/05/23 21:22:26 - mmengine - INFO - Iter(train) [ 25050/160000]  lr: 8.5793e-06  eta: 16:00:04  time: 0.4742  data_time: 0.0096  memory: 4857  grad_norm: 140.4631  loss: 41.4553  decode.loss_cls: 1.4221  decode.loss_mask: 0.8921  decode.loss_dice: 1.5841  decode.d0.loss_cls: 3.2748  decode.d0.loss_mask: 0.9282  decode.d0.loss_dice: 1.7464  decode.d1.loss_cls: 1.6298  decode.d1.loss_mask: 0.9133  decode.d1.loss_dice: 1.6419  decode.d2.loss_cls: 1.5447  decode.d2.loss_mask: 0.8549  decode.d2.loss_dice: 1.5984  decode.d3.loss_cls: 1.4605  decode.d3.loss_mask: 0.9124  decode.d3.loss_dice: 1.5521  decode.d4.loss_cls: 1.4711  decode.d4.loss_mask: 0.8873  decode.d4.loss_dice: 1.5624  decode.d5.loss_cls: 1.4245  decode.d5.loss_mask: 0.8693  decode.d5.loss_dice: 1.5205  decode.d6.loss_cls: 1.4811  decode.d6.loss_mask: 0.8805  decode.d6.loss_dice: 1.5493  decode.d7.loss_cls: 1.5079  decode.d7.loss_mask: 0.8899  decode.d7.loss_dice: 1.5571  decode.d8.loss_cls: 1.4517  decode.d8.loss_mask: 0.8777  decode.d8.loss_dice: 1.5693
2023/05/23 21:22:47 - mmengine - INFO - Iter(train) [ 25100/160000]  lr: 8.5764e-06  eta: 15:59:40  time: 0.4096  data_time: 0.0098  memory: 4829  grad_norm: 105.8670  loss: 40.9411  decode.loss_cls: 1.6366  decode.loss_mask: 0.7129  decode.loss_dice: 1.4740  decode.d0.loss_cls: 3.5309  decode.d0.loss_mask: 0.7484  decode.d0.loss_dice: 1.6300  decode.d1.loss_cls: 1.8595  decode.d1.loss_mask: 0.7622  decode.d1.loss_dice: 1.5689  decode.d2.loss_cls: 1.6766  decode.d2.loss_mask: 0.7140  decode.d2.loss_dice: 1.5321  decode.d3.loss_cls: 1.6067  decode.d3.loss_mask: 0.7087  decode.d3.loss_dice: 1.5296  decode.d4.loss_cls: 1.6407  decode.d4.loss_mask: 0.7122  decode.d4.loss_dice: 1.5222  decode.d5.loss_cls: 1.6499  decode.d5.loss_mask: 0.7352  decode.d5.loss_dice: 1.4896  decode.d6.loss_cls: 1.6603  decode.d6.loss_mask: 0.7216  decode.d6.loss_dice: 1.4752  decode.d7.loss_cls: 1.6364  decode.d7.loss_mask: 0.7081  decode.d7.loss_dice: 1.4766  decode.d8.loss_cls: 1.6430  decode.d8.loss_mask: 0.7089  decode.d8.loss_dice: 1.4703
2023/05/23 21:23:08 - mmengine - INFO - Iter(train) [ 25150/160000]  lr: 8.5735e-06  eta: 15:59:16  time: 0.4082  data_time: 0.0095  memory: 4865  grad_norm: 112.2105  loss: 26.4027  decode.loss_cls: 0.7057  decode.loss_mask: 0.8377  decode.loss_dice: 0.8550  decode.d0.loss_cls: 2.5647  decode.d0.loss_mask: 0.8576  decode.d0.loss_dice: 0.9858  decode.d1.loss_cls: 0.8571  decode.d1.loss_mask: 0.8390  decode.d1.loss_dice: 0.9332  decode.d2.loss_cls: 0.7792  decode.d2.loss_mask: 0.8473  decode.d2.loss_dice: 0.8903  decode.d3.loss_cls: 0.7774  decode.d3.loss_mask: 0.7935  decode.d3.loss_dice: 0.8741  decode.d4.loss_cls: 0.7664  decode.d4.loss_mask: 0.7831  decode.d4.loss_dice: 0.8644  decode.d5.loss_cls: 0.7666  decode.d5.loss_mask: 0.7923  decode.d5.loss_dice: 0.8565  decode.d6.loss_cls: 0.7577  decode.d6.loss_mask: 0.8027  decode.d6.loss_dice: 0.8605  decode.d7.loss_cls: 0.7136  decode.d7.loss_mask: 0.8121  decode.d7.loss_dice: 0.8394  decode.d8.loss_cls: 0.7097  decode.d8.loss_mask: 0.8449  decode.d8.loss_dice: 0.8354
2023/05/23 21:23:28 - mmengine - INFO - Iter(train) [ 25200/160000]  lr: 8.5707e-06  eta: 15:58:51  time: 0.4171  data_time: 0.0104  memory: 4908  grad_norm: 103.2232  loss: 35.5193  decode.loss_cls: 1.2195  decode.loss_mask: 0.7569  decode.loss_dice: 1.3272  decode.d0.loss_cls: 2.8064  decode.d0.loss_mask: 0.8160  decode.d0.loss_dice: 1.4838  decode.d1.loss_cls: 1.3316  decode.d1.loss_mask: 0.8243  decode.d1.loss_dice: 1.4661  decode.d2.loss_cls: 1.2865  decode.d2.loss_mask: 0.7829  decode.d2.loss_dice: 1.3962  decode.d3.loss_cls: 1.2639  decode.d3.loss_mask: 0.7861  decode.d3.loss_dice: 1.3687  decode.d4.loss_cls: 1.2535  decode.d4.loss_mask: 0.7729  decode.d4.loss_dice: 1.3633  decode.d5.loss_cls: 1.2587  decode.d5.loss_mask: 0.7617  decode.d5.loss_dice: 1.3072  decode.d6.loss_cls: 1.2429  decode.d6.loss_mask: 0.7538  decode.d6.loss_dice: 1.3307  decode.d7.loss_cls: 1.1888  decode.d7.loss_mask: 0.7737  decode.d7.loss_dice: 1.3435  decode.d8.loss_cls: 1.1570  decode.d8.loss_mask: 0.7523  decode.d8.loss_dice: 1.3434
2023/05/23 21:23:49 - mmengine - INFO - Iter(train) [ 25250/160000]  lr: 8.5678e-06  eta: 15:58:26  time: 0.4076  data_time: 0.0102  memory: 4792  grad_norm: 93.9417  loss: 31.3611  decode.loss_cls: 1.2699  decode.loss_mask: 0.5372  decode.loss_dice: 1.0306  decode.d0.loss_cls: 3.0930  decode.d0.loss_mask: 0.5749  decode.d0.loss_dice: 1.1818  decode.d1.loss_cls: 1.4687  decode.d1.loss_mask: 0.5824  decode.d1.loss_dice: 1.1168  decode.d2.loss_cls: 1.3705  decode.d2.loss_mask: 0.5721  decode.d2.loss_dice: 1.0779  decode.d3.loss_cls: 1.3591  decode.d3.loss_mask: 0.5578  decode.d3.loss_dice: 1.0489  decode.d4.loss_cls: 1.3322  decode.d4.loss_mask: 0.5744  decode.d4.loss_dice: 1.0458  decode.d5.loss_cls: 1.3050  decode.d5.loss_mask: 0.5533  decode.d5.loss_dice: 1.0406  decode.d6.loss_cls: 1.3247  decode.d6.loss_mask: 0.5459  decode.d6.loss_dice: 1.0257  decode.d7.loss_cls: 1.2915  decode.d7.loss_mask: 0.5531  decode.d7.loss_dice: 1.0468  decode.d8.loss_cls: 1.2712  decode.d8.loss_mask: 0.5613  decode.d8.loss_dice: 1.0482
2023/05/23 21:24:10 - mmengine - INFO - Iter(train) [ 25300/160000]  lr: 8.5650e-06  eta: 15:58:02  time: 0.4223  data_time: 0.0095  memory: 4925  grad_norm: 92.0684  loss: 42.5098  decode.loss_cls: 1.3843  decode.loss_mask: 1.0229  decode.loss_dice: 1.5836  decode.d0.loss_cls: 3.0463  decode.d0.loss_mask: 1.1269  decode.d0.loss_dice: 1.7797  decode.d1.loss_cls: 1.4241  decode.d1.loss_mask: 1.1042  decode.d1.loss_dice: 1.6660  decode.d2.loss_cls: 1.4221  decode.d2.loss_mask: 1.0682  decode.d2.loss_dice: 1.6150  decode.d3.loss_cls: 1.4474  decode.d3.loss_mask: 1.0794  decode.d3.loss_dice: 1.5796  decode.d4.loss_cls: 1.3889  decode.d4.loss_mask: 1.0842  decode.d4.loss_dice: 1.6148  decode.d5.loss_cls: 1.3568  decode.d5.loss_mask: 1.0834  decode.d5.loss_dice: 1.5800  decode.d6.loss_cls: 1.4127  decode.d6.loss_mask: 1.0415  decode.d6.loss_dice: 1.5448  decode.d7.loss_cls: 1.3833  decode.d7.loss_mask: 1.0727  decode.d7.loss_dice: 1.5742  decode.d8.loss_cls: 1.4336  decode.d8.loss_mask: 1.0183  decode.d8.loss_dice: 1.5710
2023/05/23 21:24:31 - mmengine - INFO - Iter(train) [ 25350/160000]  lr: 8.5621e-06  eta: 15:57:39  time: 0.4202  data_time: 0.0097  memory: 4882  grad_norm: 100.1841  loss: 36.4458  decode.loss_cls: 1.1112  decode.loss_mask: 1.0010  decode.loss_dice: 1.2097  decode.d0.loss_cls: 2.8121  decode.d0.loss_mask: 1.0564  decode.d0.loss_dice: 1.4423  decode.d1.loss_cls: 1.3000  decode.d1.loss_mask: 1.0320  decode.d1.loss_dice: 1.3508  decode.d2.loss_cls: 1.1430  decode.d2.loss_mask: 1.0499  decode.d2.loss_dice: 1.3021  decode.d3.loss_cls: 1.1722  decode.d3.loss_mask: 1.0293  decode.d3.loss_dice: 1.2617  decode.d4.loss_cls: 1.1651  decode.d4.loss_mask: 1.0519  decode.d4.loss_dice: 1.2128  decode.d5.loss_cls: 1.0951  decode.d5.loss_mask: 1.0359  decode.d5.loss_dice: 1.2393  decode.d6.loss_cls: 1.1566  decode.d6.loss_mask: 1.0709  decode.d6.loss_dice: 1.2544  decode.d7.loss_cls: 1.1604  decode.d7.loss_mask: 1.0923  decode.d7.loss_dice: 1.2700  decode.d8.loss_cls: 1.0726  decode.d8.loss_mask: 1.0454  decode.d8.loss_dice: 1.2494
2023/05/23 21:24:54 - mmengine - INFO - Iter(train) [ 25400/160000]  lr: 8.5592e-06  eta: 15:57:29  time: 0.4729  data_time: 0.0100  memory: 4876  grad_norm: 84.6322  loss: 44.1951  decode.loss_cls: 1.4969  decode.loss_mask: 1.0124  decode.loss_dice: 1.6278  decode.d0.loss_cls: 3.5137  decode.d0.loss_mask: 1.1062  decode.d0.loss_dice: 1.8639  decode.d1.loss_cls: 1.6808  decode.d1.loss_mask: 1.0435  decode.d1.loss_dice: 1.7500  decode.d2.loss_cls: 1.5100  decode.d2.loss_mask: 1.0519  decode.d2.loss_dice: 1.6981  decode.d3.loss_cls: 1.4931  decode.d3.loss_mask: 1.0197  decode.d3.loss_dice: 1.6366  decode.d4.loss_cls: 1.4882  decode.d4.loss_mask: 1.0349  decode.d4.loss_dice: 1.6439  decode.d5.loss_cls: 1.4561  decode.d5.loss_mask: 1.0321  decode.d5.loss_dice: 1.6490  decode.d6.loss_cls: 1.4919  decode.d6.loss_mask: 1.0471  decode.d6.loss_dice: 1.6180  decode.d7.loss_cls: 1.5140  decode.d7.loss_mask: 0.9997  decode.d7.loss_dice: 1.6058  decode.d8.loss_cls: 1.4885  decode.d8.loss_mask: 1.0198  decode.d8.loss_dice: 1.6015
2023/05/23 21:25:16 - mmengine - INFO - Iter(train) [ 25450/160000]  lr: 8.5564e-06  eta: 15:57:10  time: 0.4226  data_time: 0.0105  memory: 4984  grad_norm: 93.5585  loss: 41.6601  decode.loss_cls: 1.5364  decode.loss_mask: 0.7035  decode.loss_dice: 1.5935  decode.d0.loss_cls: 3.4612  decode.d0.loss_mask: 0.7928  decode.d0.loss_dice: 1.8565  decode.d1.loss_cls: 1.7193  decode.d1.loss_mask: 0.7656  decode.d1.loss_dice: 1.7758  decode.d2.loss_cls: 1.6387  decode.d2.loss_mask: 0.7410  decode.d2.loss_dice: 1.6521  decode.d3.loss_cls: 1.6247  decode.d3.loss_mask: 0.7643  decode.d3.loss_dice: 1.6470  decode.d4.loss_cls: 1.5716  decode.d4.loss_mask: 0.7457  decode.d4.loss_dice: 1.6375  decode.d5.loss_cls: 1.5650  decode.d5.loss_mask: 0.7496  decode.d5.loss_dice: 1.5973  decode.d6.loss_cls: 1.5517  decode.d6.loss_mask: 0.7371  decode.d6.loss_dice: 1.5883  decode.d7.loss_cls: 1.4693  decode.d7.loss_mask: 0.7274  decode.d7.loss_dice: 1.6158  decode.d8.loss_cls: 1.4842  decode.d8.loss_mask: 0.7322  decode.d8.loss_dice: 1.6153
2023/05/23 21:25:37 - mmengine - INFO - Iter(train) [ 25500/160000]  lr: 8.5535e-06  eta: 15:56:48  time: 0.4173  data_time: 0.0098  memory: 4848  grad_norm: 90.5937  loss: 42.2173  decode.loss_cls: 1.5521  decode.loss_mask: 0.8420  decode.loss_dice: 1.5504  decode.d0.loss_cls: 3.5353  decode.d0.loss_mask: 0.8984  decode.d0.loss_dice: 1.8080  decode.d1.loss_cls: 1.7636  decode.d1.loss_mask: 0.8570  decode.d1.loss_dice: 1.7264  decode.d2.loss_cls: 1.6210  decode.d2.loss_mask: 0.8023  decode.d2.loss_dice: 1.5922  decode.d3.loss_cls: 1.6139  decode.d3.loss_mask: 0.8225  decode.d3.loss_dice: 1.5510  decode.d4.loss_cls: 1.5057  decode.d4.loss_mask: 0.8300  decode.d4.loss_dice: 1.5807  decode.d5.loss_cls: 1.4809  decode.d5.loss_mask: 0.8469  decode.d5.loss_dice: 1.5585  decode.d6.loss_cls: 1.5958  decode.d6.loss_mask: 0.8442  decode.d6.loss_dice: 1.5352  decode.d7.loss_cls: 1.5086  decode.d7.loss_mask: 0.8572  decode.d7.loss_dice: 1.5698  decode.d8.loss_cls: 1.5996  decode.d8.loss_mask: 0.8357  decode.d8.loss_dice: 1.5323
2023/05/23 21:25:58 - mmengine - INFO - Iter(train) [ 25550/160000]  lr: 8.5507e-06  eta: 15:56:23  time: 0.4068  data_time: 0.0095  memory: 4857  grad_norm: 95.1366  loss: 44.3969  decode.loss_cls: 1.5652  decode.loss_mask: 0.9566  decode.loss_dice: 1.6160  decode.d0.loss_cls: 3.3031  decode.d0.loss_mask: 1.1082  decode.d0.loss_dice: 1.9744  decode.d1.loss_cls: 1.5323  decode.d1.loss_mask: 1.1200  decode.d1.loss_dice: 1.8823  decode.d2.loss_cls: 1.4987  decode.d2.loss_mask: 1.0859  decode.d2.loss_dice: 1.7645  decode.d3.loss_cls: 1.5092  decode.d3.loss_mask: 1.0279  decode.d3.loss_dice: 1.6641  decode.d4.loss_cls: 1.5784  decode.d4.loss_mask: 0.9875  decode.d4.loss_dice: 1.6523  decode.d5.loss_cls: 1.5800  decode.d5.loss_mask: 0.9916  decode.d5.loss_dice: 1.6736  decode.d6.loss_cls: 1.5006  decode.d6.loss_mask: 0.9496  decode.d6.loss_dice: 1.6308  decode.d7.loss_cls: 1.5489  decode.d7.loss_mask: 0.9481  decode.d7.loss_dice: 1.6173  decode.d8.loss_cls: 1.5342  decode.d8.loss_mask: 0.9616  decode.d8.loss_dice: 1.6340
2023/05/23 21:26:19 - mmengine - INFO - Iter(train) [ 25600/160000]  lr: 8.5478e-06  eta: 15:56:02  time: 0.4672  data_time: 0.0097  memory: 4877  grad_norm: 86.2610  loss: 36.6884  decode.loss_cls: 1.3080  decode.loss_mask: 0.7328  decode.loss_dice: 1.3608  decode.d0.loss_cls: 3.1148  decode.d0.loss_mask: 0.6858  decode.d0.loss_dice: 1.5556  decode.d1.loss_cls: 1.3735  decode.d1.loss_mask: 0.8258  decode.d1.loss_dice: 1.5661  decode.d2.loss_cls: 1.3494  decode.d2.loss_mask: 0.7398  decode.d2.loss_dice: 1.4568  decode.d3.loss_cls: 1.2911  decode.d3.loss_mask: 0.6881  decode.d3.loss_dice: 1.3699  decode.d4.loss_cls: 1.3637  decode.d4.loss_mask: 0.7042  decode.d4.loss_dice: 1.3801  decode.d5.loss_cls: 1.3653  decode.d5.loss_mask: 0.7080  decode.d5.loss_dice: 1.3912  decode.d6.loss_cls: 1.3571  decode.d6.loss_mask: 0.7110  decode.d6.loss_dice: 1.3891  decode.d7.loss_cls: 1.3826  decode.d7.loss_mask: 0.6822  decode.d7.loss_dice: 1.3684  decode.d8.loss_cls: 1.3431  decode.d8.loss_mask: 0.7219  decode.d8.loss_dice: 1.4022
2023/05/23 21:26:41 - mmengine - INFO - Iter(train) [ 25650/160000]  lr: 8.5449e-06  eta: 15:55:40  time: 0.4010  data_time: 0.0098  memory: 4890  grad_norm: 117.1922  loss: 36.0915  decode.loss_cls: 1.2524  decode.loss_mask: 0.7583  decode.loss_dice: 1.3305  decode.d0.loss_cls: 2.9421  decode.d0.loss_mask: 0.8166  decode.d0.loss_dice: 1.5751  decode.d1.loss_cls: 1.4332  decode.d1.loss_mask: 0.7901  decode.d1.loss_dice: 1.4214  decode.d2.loss_cls: 1.3359  decode.d2.loss_mask: 0.7469  decode.d2.loss_dice: 1.3492  decode.d3.loss_cls: 1.3319  decode.d3.loss_mask: 0.7602  decode.d3.loss_dice: 1.3623  decode.d4.loss_cls: 1.3172  decode.d4.loss_mask: 0.7573  decode.d4.loss_dice: 1.3416  decode.d5.loss_cls: 1.2908  decode.d5.loss_mask: 0.7550  decode.d5.loss_dice: 1.3401  decode.d6.loss_cls: 1.2694  decode.d6.loss_mask: 0.7662  decode.d6.loss_dice: 1.3417  decode.d7.loss_cls: 1.2637  decode.d7.loss_mask: 0.7357  decode.d7.loss_dice: 1.3451  decode.d8.loss_cls: 1.2550  decode.d8.loss_mask: 0.7544  decode.d8.loss_dice: 1.3524
2023/05/23 21:27:01 - mmengine - INFO - Iter(train) [ 25700/160000]  lr: 8.5421e-06  eta: 15:55:14  time: 0.4074  data_time: 0.0097  memory: 4840  grad_norm: 104.7249  loss: 38.2076  decode.loss_cls: 1.4098  decode.loss_mask: 0.8450  decode.loss_dice: 1.2761  decode.d0.loss_cls: 3.2098  decode.d0.loss_mask: 0.9593  decode.d0.loss_dice: 1.4564  decode.d1.loss_cls: 1.4689  decode.d1.loss_mask: 0.9405  decode.d1.loss_dice: 1.3958  decode.d2.loss_cls: 1.5011  decode.d2.loss_mask: 0.8880  decode.d2.loss_dice: 1.3444  decode.d3.loss_cls: 1.4303  decode.d3.loss_mask: 0.8780  decode.d3.loss_dice: 1.2782  decode.d4.loss_cls: 1.4361  decode.d4.loss_mask: 0.8724  decode.d4.loss_dice: 1.2966  decode.d5.loss_cls: 1.4610  decode.d5.loss_mask: 0.8487  decode.d5.loss_dice: 1.2758  decode.d6.loss_cls: 1.4697  decode.d6.loss_mask: 0.8589  decode.d6.loss_dice: 1.2276  decode.d7.loss_cls: 1.4841  decode.d7.loss_mask: 0.8618  decode.d7.loss_dice: 1.2531  decode.d8.loss_cls: 1.4176  decode.d8.loss_mask: 0.8968  decode.d8.loss_dice: 1.2658
2023/05/23 21:27:22 - mmengine - INFO - Iter(train) [ 25750/160000]  lr: 8.5392e-06  eta: 15:54:51  time: 0.4171  data_time: 0.0096  memory: 4925  grad_norm: 112.2848  loss: 39.9305  decode.loss_cls: 1.2925  decode.loss_mask: 0.9317  decode.loss_dice: 1.5166  decode.d0.loss_cls: 3.1435  decode.d0.loss_mask: 0.9722  decode.d0.loss_dice: 1.6261  decode.d1.loss_cls: 1.4315  decode.d1.loss_mask: 0.9570  decode.d1.loss_dice: 1.6451  decode.d2.loss_cls: 1.3555  decode.d2.loss_mask: 0.9478  decode.d2.loss_dice: 1.5690  decode.d3.loss_cls: 1.2922  decode.d3.loss_mask: 0.9754  decode.d3.loss_dice: 1.4926  decode.d4.loss_cls: 1.2753  decode.d4.loss_mask: 0.9555  decode.d4.loss_dice: 1.5288  decode.d5.loss_cls: 1.2303  decode.d5.loss_mask: 0.9421  decode.d5.loss_dice: 1.5170  decode.d6.loss_cls: 1.3190  decode.d6.loss_mask: 0.9438  decode.d6.loss_dice: 1.5073  decode.d7.loss_cls: 1.2546  decode.d7.loss_mask: 0.9449  decode.d7.loss_dice: 1.5465  decode.d8.loss_cls: 1.3452  decode.d8.loss_mask: 0.9408  decode.d8.loss_dice: 1.5305
2023/05/23 21:27:44 - mmengine - INFO - Iter(train) [ 25800/160000]  lr: 8.5363e-06  eta: 15:54:32  time: 0.4722  data_time: 0.0101  memory: 4844  grad_norm: 86.4602  loss: 36.8360  decode.loss_cls: 1.2592  decode.loss_mask: 0.9671  decode.loss_dice: 1.1822  decode.d0.loss_cls: 3.1438  decode.d0.loss_mask: 1.0001  decode.d0.loss_dice: 1.3640  decode.d1.loss_cls: 1.2610  decode.d1.loss_mask: 0.9971  decode.d1.loss_dice: 1.3880  decode.d2.loss_cls: 1.2877  decode.d2.loss_mask: 0.9774  decode.d2.loss_dice: 1.2752  decode.d3.loss_cls: 1.1813  decode.d3.loss_mask: 1.0361  decode.d3.loss_dice: 1.2574  decode.d4.loss_cls: 1.2098  decode.d4.loss_mask: 1.0056  decode.d4.loss_dice: 1.2408  decode.d5.loss_cls: 1.2224  decode.d5.loss_mask: 0.9984  decode.d5.loss_dice: 1.2322  decode.d6.loss_cls: 1.2589  decode.d6.loss_mask: 0.9847  decode.d6.loss_dice: 1.2123  decode.d7.loss_cls: 1.2647  decode.d7.loss_mask: 0.9824  decode.d7.loss_dice: 1.2108  decode.d8.loss_cls: 1.3074  decode.d8.loss_mask: 0.9398  decode.d8.loss_dice: 1.1882
2023/05/23 21:28:05 - mmengine - INFO - Iter(train) [ 25850/160000]  lr: 8.5335e-06  eta: 15:54:12  time: 0.4105  data_time: 0.0096  memory: 4876  grad_norm: 99.2123  loss: 42.9572  decode.loss_cls: 1.4887  decode.loss_mask: 0.8768  decode.loss_dice: 1.6951  decode.d0.loss_cls: 3.2939  decode.d0.loss_mask: 0.9317  decode.d0.loss_dice: 1.9375  decode.d1.loss_cls: 1.6519  decode.d1.loss_mask: 0.9048  decode.d1.loss_dice: 1.7671  decode.d2.loss_cls: 1.6021  decode.d2.loss_mask: 0.8288  decode.d2.loss_dice: 1.7010  decode.d3.loss_cls: 1.4840  decode.d3.loss_mask: 0.8505  decode.d3.loss_dice: 1.7010  decode.d4.loss_cls: 1.4681  decode.d4.loss_mask: 0.8372  decode.d4.loss_dice: 1.6829  decode.d5.loss_cls: 1.5070  decode.d5.loss_mask: 0.8327  decode.d5.loss_dice: 1.6788  decode.d6.loss_cls: 1.5403  decode.d6.loss_mask: 0.8506  decode.d6.loss_dice: 1.6991  decode.d7.loss_cls: 1.5198  decode.d7.loss_mask: 0.8435  decode.d7.loss_dice: 1.7088  decode.d8.loss_cls: 1.5530  decode.d8.loss_mask: 0.8496  decode.d8.loss_dice: 1.6708
2023/05/23 21:28:26 - mmengine - INFO - Iter(train) [ 25900/160000]  lr: 8.5306e-06  eta: 15:53:46  time: 0.4057  data_time: 0.0095  memory: 4829  grad_norm: 129.5178  loss: 32.4697  decode.loss_cls: 1.3637  decode.loss_mask: 0.6692  decode.loss_dice: 0.9667  decode.d0.loss_cls: 2.9995  decode.d0.loss_mask: 0.7420  decode.d0.loss_dice: 1.0894  decode.d1.loss_cls: 1.5325  decode.d1.loss_mask: 0.7424  decode.d1.loss_dice: 1.0554  decode.d2.loss_cls: 1.5706  decode.d2.loss_mask: 0.6985  decode.d2.loss_dice: 0.9708  decode.d3.loss_cls: 1.4732  decode.d3.loss_mask: 0.6682  decode.d3.loss_dice: 0.9271  decode.d4.loss_cls: 1.4091  decode.d4.loss_mask: 0.6756  decode.d4.loss_dice: 0.9190  decode.d5.loss_cls: 1.4156  decode.d5.loss_mask: 0.6624  decode.d5.loss_dice: 0.9252  decode.d6.loss_cls: 1.4504  decode.d6.loss_mask: 0.6504  decode.d6.loss_dice: 0.9678  decode.d7.loss_cls: 1.3507  decode.d7.loss_mask: 0.6690  decode.d7.loss_dice: 0.9321  decode.d8.loss_cls: 1.3458  decode.d8.loss_mask: 0.6871  decode.d8.loss_dice: 0.9404
2023/05/23 21:28:47 - mmengine - INFO - Iter(train) [ 25950/160000]  lr: 8.5278e-06  eta: 15:53:22  time: 0.4175  data_time: 0.0098  memory: 4830  grad_norm: 102.6228  loss: 38.3046  decode.loss_cls: 1.3861  decode.loss_mask: 0.7975  decode.loss_dice: 1.3352  decode.d0.loss_cls: 3.4689  decode.d0.loss_mask: 0.8888  decode.d0.loss_dice: 1.5281  decode.d1.loss_cls: 1.5501  decode.d1.loss_mask: 0.8820  decode.d1.loss_dice: 1.4780  decode.d2.loss_cls: 1.3809  decode.d2.loss_mask: 0.8831  decode.d2.loss_dice: 1.4124  decode.d3.loss_cls: 1.4056  decode.d3.loss_mask: 0.7882  decode.d3.loss_dice: 1.4081  decode.d4.loss_cls: 1.3891  decode.d4.loss_mask: 0.8160  decode.d4.loss_dice: 1.3851  decode.d5.loss_cls: 1.3648  decode.d5.loss_mask: 0.7765  decode.d5.loss_dice: 1.3821  decode.d6.loss_cls: 1.3995  decode.d6.loss_mask: 0.8044  decode.d6.loss_dice: 1.3497  decode.d7.loss_cls: 1.3148  decode.d7.loss_mask: 0.8195  decode.d7.loss_dice: 1.3743  decode.d8.loss_cls: 1.3619  decode.d8.loss_mask: 0.8139  decode.d8.loss_dice: 1.3602
2023/05/23 21:29:07 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 21:29:07 - mmengine - INFO - Iter(train) [ 26000/160000]  lr: 8.5249e-06  eta: 15:52:56  time: 0.4148  data_time: 0.0100  memory: 4804  grad_norm: 137.5153  loss: 40.7982  decode.loss_cls: 1.5283  decode.loss_mask: 0.8862  decode.loss_dice: 1.3582  decode.d0.loss_cls: 3.2895  decode.d0.loss_mask: 0.9855  decode.d0.loss_dice: 1.5622  decode.d1.loss_cls: 1.6767  decode.d1.loss_mask: 0.8873  decode.d1.loss_dice: 1.4621  decode.d2.loss_cls: 1.5705  decode.d2.loss_mask: 0.9921  decode.d2.loss_dice: 1.4179  decode.d3.loss_cls: 1.6284  decode.d3.loss_mask: 0.9614  decode.d3.loss_dice: 1.3939  decode.d4.loss_cls: 1.5801  decode.d4.loss_mask: 0.9611  decode.d4.loss_dice: 1.3766  decode.d5.loss_cls: 1.5507  decode.d5.loss_mask: 0.9537  decode.d5.loss_dice: 1.3680  decode.d6.loss_cls: 1.5107  decode.d6.loss_mask: 0.9344  decode.d6.loss_dice: 1.3766  decode.d7.loss_cls: 1.5031  decode.d7.loss_mask: 0.9232  decode.d7.loss_dice: 1.3789  decode.d8.loss_cls: 1.5074  decode.d8.loss_mask: 0.9212  decode.d8.loss_dice: 1.3524
2023/05/23 21:29:07 - mmengine - INFO - Saving checkpoint at 26000 iterations
2023/05/23 21:29:34 - mmengine - INFO - Iter(train) [ 26050/160000]  lr: 8.5220e-06  eta: 15:53:03  time: 0.4052  data_time: 0.0095  memory: 4846  grad_norm: 99.8669  loss: 39.0848  decode.loss_cls: 1.6147  decode.loss_mask: 0.8199  decode.loss_dice: 1.1640  decode.d0.loss_cls: 3.3558  decode.d0.loss_mask: 0.9661  decode.d0.loss_dice: 1.4540  decode.d1.loss_cls: 1.7123  decode.d1.loss_mask: 0.8674  decode.d1.loss_dice: 1.4132  decode.d2.loss_cls: 1.6468  decode.d2.loss_mask: 0.8106  decode.d2.loss_dice: 1.2491  decode.d3.loss_cls: 1.5772  decode.d3.loss_mask: 0.8080  decode.d3.loss_dice: 1.2442  decode.d4.loss_cls: 1.5521  decode.d4.loss_mask: 0.8508  decode.d4.loss_dice: 1.2618  decode.d5.loss_cls: 1.6968  decode.d5.loss_mask: 0.8258  decode.d5.loss_dice: 1.2459  decode.d6.loss_cls: 1.7048  decode.d6.loss_mask: 0.7916  decode.d6.loss_dice: 1.2106  decode.d7.loss_cls: 1.6096  decode.d7.loss_mask: 0.8116  decode.d7.loss_dice: 1.1929  decode.d8.loss_cls: 1.5914  decode.d8.loss_mask: 0.8255  decode.d8.loss_dice: 1.2105
2023/05/23 21:29:54 - mmengine - INFO - Iter(train) [ 26100/160000]  lr: 8.5192e-06  eta: 15:52:37  time: 0.4041  data_time: 0.0098  memory: 4857  grad_norm: 94.9919  loss: 40.4260  decode.loss_cls: 1.5506  decode.loss_mask: 0.7751  decode.loss_dice: 1.4000  decode.d0.loss_cls: 3.5699  decode.d0.loss_mask: 0.8179  decode.d0.loss_dice: 1.6339  decode.d1.loss_cls: 1.7065  decode.d1.loss_mask: 0.7850  decode.d1.loss_dice: 1.5120  decode.d2.loss_cls: 1.5770  decode.d2.loss_mask: 0.7901  decode.d2.loss_dice: 1.4676  decode.d3.loss_cls: 1.6065  decode.d3.loss_mask: 0.7569  decode.d3.loss_dice: 1.4258  decode.d4.loss_cls: 1.6560  decode.d4.loss_mask: 0.7756  decode.d4.loss_dice: 1.4282  decode.d5.loss_cls: 1.5995  decode.d5.loss_mask: 0.7735  decode.d5.loss_dice: 1.4352  decode.d6.loss_cls: 1.6560  decode.d6.loss_mask: 0.7473  decode.d6.loss_dice: 1.4079  decode.d7.loss_cls: 1.6243  decode.d7.loss_mask: 0.7624  decode.d7.loss_dice: 1.4160  decode.d8.loss_cls: 1.5868  decode.d8.loss_mask: 0.7689  decode.d8.loss_dice: 1.4140
2023/05/23 21:30:15 - mmengine - INFO - Iter(train) [ 26150/160000]  lr: 8.5163e-06  eta: 15:52:12  time: 0.4172  data_time: 0.0096  memory: 4820  grad_norm: 120.0435  loss: 36.7390  decode.loss_cls: 1.2506  decode.loss_mask: 0.8918  decode.loss_dice: 1.2707  decode.d0.loss_cls: 3.1105  decode.d0.loss_mask: 0.8797  decode.d0.loss_dice: 1.4257  decode.d1.loss_cls: 1.3302  decode.d1.loss_mask: 0.9130  decode.d1.loss_dice: 1.3876  decode.d2.loss_cls: 1.3203  decode.d2.loss_mask: 0.8942  decode.d2.loss_dice: 1.3262  decode.d3.loss_cls: 1.3050  decode.d3.loss_mask: 0.8916  decode.d3.loss_dice: 1.2855  decode.d4.loss_cls: 1.2808  decode.d4.loss_mask: 0.9182  decode.d4.loss_dice: 1.2951  decode.d5.loss_cls: 1.2580  decode.d5.loss_mask: 0.9066  decode.d5.loss_dice: 1.2800  decode.d6.loss_cls: 1.2746  decode.d6.loss_mask: 0.8961  decode.d6.loss_dice: 1.2900  decode.d7.loss_cls: 1.3256  decode.d7.loss_mask: 0.8449  decode.d7.loss_dice: 1.2895  decode.d8.loss_cls: 1.2585  decode.d8.loss_mask: 0.8830  decode.d8.loss_dice: 1.2553
2023/05/23 21:30:36 - mmengine - INFO - Iter(train) [ 26200/160000]  lr: 8.5134e-06  eta: 15:51:47  time: 0.4067  data_time: 0.0099  memory: 4823  grad_norm: 84.1768  loss: 40.7152  decode.loss_cls: 1.5410  decode.loss_mask: 0.9465  decode.loss_dice: 1.2999  decode.d0.loss_cls: 3.6024  decode.d0.loss_mask: 0.9503  decode.d0.loss_dice: 1.5133  decode.d1.loss_cls: 1.7503  decode.d1.loss_mask: 0.9527  decode.d1.loss_dice: 1.4023  decode.d2.loss_cls: 1.6408  decode.d2.loss_mask: 0.9397  decode.d2.loss_dice: 1.3411  decode.d3.loss_cls: 1.6083  decode.d3.loss_mask: 0.9261  decode.d3.loss_dice: 1.3323  decode.d4.loss_cls: 1.6080  decode.d4.loss_mask: 0.9487  decode.d4.loss_dice: 1.3314  decode.d5.loss_cls: 1.5967  decode.d5.loss_mask: 0.8956  decode.d5.loss_dice: 1.3136  decode.d6.loss_cls: 1.5367  decode.d6.loss_mask: 0.9663  decode.d6.loss_dice: 1.3073  decode.d7.loss_cls: 1.5284  decode.d7.loss_mask: 0.9273  decode.d7.loss_dice: 1.2890  decode.d8.loss_cls: 1.4425  decode.d8.loss_mask: 0.9618  decode.d8.loss_dice: 1.3151
2023/05/23 21:30:56 - mmengine - INFO - Iter(train) [ 26250/160000]  lr: 8.5106e-06  eta: 15:51:23  time: 0.4214  data_time: 0.0102  memory: 4888  grad_norm: 107.5916  loss: 45.6326  decode.loss_cls: 1.5888  decode.loss_mask: 0.9024  decode.loss_dice: 1.7611  decode.d0.loss_cls: 3.3777  decode.d0.loss_mask: 0.9870  decode.d0.loss_dice: 2.1277  decode.d1.loss_cls: 1.8724  decode.d1.loss_mask: 0.9676  decode.d1.loss_dice: 1.8999  decode.d2.loss_cls: 1.7002  decode.d2.loss_mask: 0.9102  decode.d2.loss_dice: 1.7897  decode.d3.loss_cls: 1.6023  decode.d3.loss_mask: 0.9031  decode.d3.loss_dice: 1.7351  decode.d4.loss_cls: 1.6244  decode.d4.loss_mask: 0.9338  decode.d4.loss_dice: 1.7657  decode.d5.loss_cls: 1.6341  decode.d5.loss_mask: 0.9277  decode.d5.loss_dice: 1.7700  decode.d6.loss_cls: 1.6062  decode.d6.loss_mask: 0.9182  decode.d6.loss_dice: 1.7670  decode.d7.loss_cls: 1.5960  decode.d7.loss_mask: 0.9319  decode.d7.loss_dice: 1.7849  decode.d8.loss_cls: 1.5542  decode.d8.loss_mask: 0.9211  decode.d8.loss_dice: 1.7720
2023/05/23 21:31:18 - mmengine - INFO - Iter(train) [ 26300/160000]  lr: 8.5077e-06  eta: 15:51:00  time: 0.4153  data_time: 0.0095  memory: 4837  grad_norm: 102.5936  loss: 32.5692  decode.loss_cls: 1.0172  decode.loss_mask: 0.8572  decode.loss_dice: 1.1390  decode.d0.loss_cls: 3.0287  decode.d0.loss_mask: 0.8188  decode.d0.loss_dice: 1.2740  decode.d1.loss_cls: 1.2143  decode.d1.loss_mask: 0.8472  decode.d1.loss_dice: 1.1843  decode.d2.loss_cls: 1.0821  decode.d2.loss_mask: 0.8668  decode.d2.loss_dice: 1.1981  decode.d3.loss_cls: 0.9980  decode.d3.loss_mask: 0.8682  decode.d3.loss_dice: 1.1753  decode.d4.loss_cls: 0.9992  decode.d4.loss_mask: 0.8685  decode.d4.loss_dice: 1.1505  decode.d5.loss_cls: 1.0671  decode.d5.loss_mask: 0.7959  decode.d5.loss_dice: 1.1117  decode.d6.loss_cls: 1.0579  decode.d6.loss_mask: 0.8233  decode.d6.loss_dice: 1.1117  decode.d7.loss_cls: 1.0665  decode.d7.loss_mask: 0.8158  decode.d7.loss_dice: 1.1023  decode.d8.loss_cls: 1.0693  decode.d8.loss_mask: 0.8340  decode.d8.loss_dice: 1.1263
2023/05/23 21:31:39 - mmengine - INFO - Iter(train) [ 26350/160000]  lr: 8.5048e-06  eta: 15:50:38  time: 0.4237  data_time: 0.0100  memory: 4821  grad_norm: 121.6898  loss: 31.2242  decode.loss_cls: 1.0501  decode.loss_mask: 0.7180  decode.loss_dice: 1.1766  decode.d0.loss_cls: 2.7383  decode.d0.loss_mask: 0.7153  decode.d0.loss_dice: 1.3036  decode.d1.loss_cls: 1.1232  decode.d1.loss_mask: 0.7536  decode.d1.loss_dice: 1.2592  decode.d2.loss_cls: 1.0044  decode.d2.loss_mask: 0.7352  decode.d2.loss_dice: 1.1977  decode.d3.loss_cls: 1.0333  decode.d3.loss_mask: 0.7428  decode.d3.loss_dice: 1.1895  decode.d4.loss_cls: 1.0125  decode.d4.loss_mask: 0.7085  decode.d4.loss_dice: 1.2002  decode.d5.loss_cls: 1.0417  decode.d5.loss_mask: 0.6891  decode.d5.loss_dice: 1.1821  decode.d6.loss_cls: 0.9692  decode.d6.loss_mask: 0.7000  decode.d6.loss_dice: 1.1625  decode.d7.loss_cls: 1.0797  decode.d7.loss_mask: 0.6906  decode.d7.loss_dice: 1.1716  decode.d8.loss_cls: 1.0182  decode.d8.loss_mask: 0.6852  decode.d8.loss_dice: 1.1723
2023/05/23 21:31:59 - mmengine - INFO - Iter(train) [ 26400/160000]  lr: 8.5020e-06  eta: 15:50:12  time: 0.4109  data_time: 0.0099  memory: 4919  grad_norm: 128.6103  loss: 38.7254  decode.loss_cls: 1.4982  decode.loss_mask: 0.7861  decode.loss_dice: 1.3755  decode.d0.loss_cls: 3.3154  decode.d0.loss_mask: 0.8539  decode.d0.loss_dice: 1.4985  decode.d1.loss_cls: 1.6055  decode.d1.loss_mask: 0.8052  decode.d1.loss_dice: 1.4052  decode.d2.loss_cls: 1.6072  decode.d2.loss_mask: 0.7649  decode.d2.loss_dice: 1.3270  decode.d3.loss_cls: 1.5127  decode.d3.loss_mask: 0.7716  decode.d3.loss_dice: 1.3396  decode.d4.loss_cls: 1.4997  decode.d4.loss_mask: 0.7951  decode.d4.loss_dice: 1.3448  decode.d5.loss_cls: 1.4333  decode.d5.loss_mask: 0.8132  decode.d5.loss_dice: 1.3643  decode.d6.loss_cls: 1.4958  decode.d6.loss_mask: 0.7805  decode.d6.loss_dice: 1.3600  decode.d7.loss_cls: 1.5237  decode.d7.loss_mask: 0.7920  decode.d7.loss_dice: 1.3787  decode.d8.loss_cls: 1.5341  decode.d8.loss_mask: 0.7868  decode.d8.loss_dice: 1.3571
2023/05/23 21:32:20 - mmengine - INFO - Iter(train) [ 26450/160000]  lr: 8.4991e-06  eta: 15:49:50  time: 0.4230  data_time: 0.0097  memory: 4823  grad_norm: 96.6842  loss: 37.2786  decode.loss_cls: 1.2141  decode.loss_mask: 0.9397  decode.loss_dice: 1.2558  decode.d0.loss_cls: 3.3878  decode.d0.loss_mask: 0.9660  decode.d0.loss_dice: 1.4463  decode.d1.loss_cls: 1.3357  decode.d1.loss_mask: 1.0232  decode.d1.loss_dice: 1.3830  decode.d2.loss_cls: 1.2662  decode.d2.loss_mask: 1.0258  decode.d2.loss_dice: 1.3518  decode.d3.loss_cls: 1.2293  decode.d3.loss_mask: 0.9747  decode.d3.loss_dice: 1.3058  decode.d4.loss_cls: 1.2226  decode.d4.loss_mask: 0.9918  decode.d4.loss_dice: 1.2995  decode.d5.loss_cls: 1.1800  decode.d5.loss_mask: 0.9517  decode.d5.loss_dice: 1.3052  decode.d6.loss_cls: 1.2233  decode.d6.loss_mask: 0.9239  decode.d6.loss_dice: 1.2644  decode.d7.loss_cls: 1.2094  decode.d7.loss_mask: 0.9144  decode.d7.loss_dice: 1.2793  decode.d8.loss_cls: 1.2737  decode.d8.loss_mask: 0.8950  decode.d8.loss_dice: 1.2391
2023/05/23 21:32:42 - mmengine - INFO - Iter(train) [ 26500/160000]  lr: 8.4963e-06  eta: 15:49:31  time: 0.4700  data_time: 0.0102  memory: 4883  grad_norm: 86.7137  loss: 36.8354  decode.loss_cls: 1.3744  decode.loss_mask: 0.7712  decode.loss_dice: 1.2216  decode.d0.loss_cls: 3.2580  decode.d0.loss_mask: 0.7702  decode.d0.loss_dice: 1.4489  decode.d1.loss_cls: 1.5638  decode.d1.loss_mask: 0.8046  decode.d1.loss_dice: 1.4306  decode.d2.loss_cls: 1.4657  decode.d2.loss_mask: 0.8246  decode.d2.loss_dice: 1.3254  decode.d3.loss_cls: 1.4273  decode.d3.loss_mask: 0.7943  decode.d3.loss_dice: 1.2896  decode.d4.loss_cls: 1.3950  decode.d4.loss_mask: 0.7822  decode.d4.loss_dice: 1.2915  decode.d5.loss_cls: 1.3538  decode.d5.loss_mask: 0.7596  decode.d5.loss_dice: 1.2988  decode.d6.loss_cls: 1.3876  decode.d6.loss_mask: 0.7645  decode.d6.loss_dice: 1.2374  decode.d7.loss_cls: 1.3476  decode.d7.loss_mask: 0.7613  decode.d7.loss_dice: 1.2736  decode.d8.loss_cls: 1.3750  decode.d8.loss_mask: 0.7698  decode.d8.loss_dice: 1.2673
2023/05/23 21:33:06 - mmengine - INFO - Iter(train) [ 26550/160000]  lr: 8.4934e-06  eta: 15:49:21  time: 0.4655  data_time: 0.0102  memory: 4944  grad_norm: 94.9476  loss: 43.6489  decode.loss_cls: 1.4453  decode.loss_mask: 1.0526  decode.loss_dice: 1.5575  decode.d0.loss_cls: 3.4009  decode.d0.loss_mask: 1.0754  decode.d0.loss_dice: 1.7926  decode.d1.loss_cls: 1.7911  decode.d1.loss_mask: 1.0861  decode.d1.loss_dice: 1.7290  decode.d2.loss_cls: 1.5639  decode.d2.loss_mask: 1.0631  decode.d2.loss_dice: 1.6624  decode.d3.loss_cls: 1.4721  decode.d3.loss_mask: 1.0206  decode.d3.loss_dice: 1.5634  decode.d4.loss_cls: 1.5012  decode.d4.loss_mask: 1.0417  decode.d4.loss_dice: 1.5690  decode.d5.loss_cls: 1.4369  decode.d5.loss_mask: 1.0652  decode.d5.loss_dice: 1.5744  decode.d6.loss_cls: 1.4337  decode.d6.loss_mask: 1.0302  decode.d6.loss_dice: 1.5562  decode.d7.loss_cls: 1.5113  decode.d7.loss_mask: 1.0654  decode.d7.loss_dice: 1.5455  decode.d8.loss_cls: 1.4608  decode.d8.loss_mask: 1.0356  decode.d8.loss_dice: 1.5457
2023/05/23 21:33:27 - mmengine - INFO - Iter(train) [ 26600/160000]  lr: 8.4905e-06  eta: 15:49:00  time: 0.4170  data_time: 0.0096  memory: 4858  grad_norm: 101.4819  loss: 51.4727  decode.loss_cls: 1.7524  decode.loss_mask: 1.0961  decode.loss_dice: 1.9111  decode.d0.loss_cls: 3.8646  decode.d0.loss_mask: 1.2427  decode.d0.loss_dice: 2.1948  decode.d1.loss_cls: 1.9585  decode.d1.loss_mask: 1.1564  decode.d1.loss_dice: 2.0267  decode.d2.loss_cls: 1.9575  decode.d2.loss_mask: 1.1041  decode.d2.loss_dice: 1.9252  decode.d3.loss_cls: 1.8832  decode.d3.loss_mask: 1.1589  decode.d3.loss_dice: 1.9364  decode.d4.loss_cls: 1.8084  decode.d4.loss_mask: 1.1397  decode.d4.loss_dice: 1.9544  decode.d5.loss_cls: 1.8134  decode.d5.loss_mask: 1.1084  decode.d5.loss_dice: 1.9346  decode.d6.loss_cls: 1.8793  decode.d6.loss_mask: 1.1267  decode.d6.loss_dice: 1.8937  decode.d7.loss_cls: 1.7777  decode.d7.loss_mask: 1.1505  decode.d7.loss_dice: 1.9045  decode.d8.loss_cls: 1.7819  decode.d8.loss_mask: 1.1273  decode.d8.loss_dice: 1.9036
2023/05/23 21:33:48 - mmengine - INFO - Iter(train) [ 26650/160000]  lr: 8.4877e-06  eta: 15:48:35  time: 0.4100  data_time: 0.0100  memory: 4846  grad_norm: 99.1462  loss: 40.2472  decode.loss_cls: 1.2221  decode.loss_mask: 1.0389  decode.loss_dice: 1.4813  decode.d0.loss_cls: 3.4032  decode.d0.loss_mask: 1.0336  decode.d0.loss_dice: 1.6260  decode.d1.loss_cls: 1.3303  decode.d1.loss_mask: 1.0832  decode.d1.loss_dice: 1.6472  decode.d2.loss_cls: 1.2839  decode.d2.loss_mask: 1.1071  decode.d2.loss_dice: 1.5861  decode.d3.loss_cls: 1.2449  decode.d3.loss_mask: 1.0166  decode.d3.loss_dice: 1.5274  decode.d4.loss_cls: 1.2756  decode.d4.loss_mask: 0.9813  decode.d4.loss_dice: 1.4959  decode.d5.loss_cls: 1.3179  decode.d5.loss_mask: 0.9665  decode.d5.loss_dice: 1.4740  decode.d6.loss_cls: 1.2550  decode.d6.loss_mask: 1.0142  decode.d6.loss_dice: 1.4527  decode.d7.loss_cls: 1.1966  decode.d7.loss_mask: 1.0316  decode.d7.loss_dice: 1.4617  decode.d8.loss_cls: 1.1587  decode.d8.loss_mask: 1.0623  decode.d8.loss_dice: 1.4713
2023/05/23 21:34:09 - mmengine - INFO - Iter(train) [ 26700/160000]  lr: 8.4848e-06  eta: 15:48:15  time: 0.4103  data_time: 0.0095  memory: 4896  grad_norm: 90.9756  loss: 39.5459  decode.loss_cls: 1.4170  decode.loss_mask: 0.8329  decode.loss_dice: 1.3702  decode.d0.loss_cls: 3.2817  decode.d0.loss_mask: 0.8623  decode.d0.loss_dice: 1.6215  decode.d1.loss_cls: 1.6570  decode.d1.loss_mask: 0.8865  decode.d1.loss_dice: 1.5001  decode.d2.loss_cls: 1.5630  decode.d2.loss_mask: 0.8243  decode.d2.loss_dice: 1.4440  decode.d3.loss_cls: 1.5030  decode.d3.loss_mask: 0.8321  decode.d3.loss_dice: 1.4221  decode.d4.loss_cls: 1.5017  decode.d4.loss_mask: 0.8706  decode.d4.loss_dice: 1.4155  decode.d5.loss_cls: 1.5024  decode.d5.loss_mask: 0.8090  decode.d5.loss_dice: 1.4092  decode.d6.loss_cls: 1.4283  decode.d6.loss_mask: 0.8566  decode.d6.loss_dice: 1.4005  decode.d7.loss_cls: 1.4679  decode.d7.loss_mask: 0.8377  decode.d7.loss_dice: 1.3692  decode.d8.loss_cls: 1.4651  decode.d8.loss_mask: 0.8203  decode.d8.loss_dice: 1.3739
2023/05/23 21:34:30 - mmengine - INFO - Iter(train) [ 26750/160000]  lr: 8.4819e-06  eta: 15:47:51  time: 0.4156  data_time: 0.0095  memory: 4802  grad_norm: 114.7302  loss: 33.0728  decode.loss_cls: 1.0772  decode.loss_mask: 0.7992  decode.loss_dice: 1.1668  decode.d0.loss_cls: 3.1822  decode.d0.loss_mask: 0.7935  decode.d0.loss_dice: 1.3350  decode.d1.loss_cls: 1.2154  decode.d1.loss_mask: 0.7716  decode.d1.loss_dice: 1.2525  decode.d2.loss_cls: 1.1439  decode.d2.loss_mask: 0.7896  decode.d2.loss_dice: 1.2095  decode.d3.loss_cls: 1.1713  decode.d3.loss_mask: 0.7517  decode.d3.loss_dice: 1.1776  decode.d4.loss_cls: 1.1512  decode.d4.loss_mask: 0.7819  decode.d4.loss_dice: 1.1314  decode.d5.loss_cls: 1.1319  decode.d5.loss_mask: 0.7744  decode.d5.loss_dice: 1.1589  decode.d6.loss_cls: 1.0669  decode.d6.loss_mask: 0.7855  decode.d6.loss_dice: 1.1503  decode.d7.loss_cls: 1.0855  decode.d7.loss_mask: 0.7858  decode.d7.loss_dice: 1.1680  decode.d8.loss_cls: 1.1031  decode.d8.loss_mask: 0.7980  decode.d8.loss_dice: 1.1632
2023/05/23 21:34:51 - mmengine - INFO - Iter(train) [ 26800/160000]  lr: 8.4791e-06  eta: 15:47:27  time: 0.4156  data_time: 0.0099  memory: 4843  grad_norm: 110.6237  loss: 36.0938  decode.loss_cls: 1.4561  decode.loss_mask: 0.6199  decode.loss_dice: 1.2977  decode.d0.loss_cls: 3.1026  decode.d0.loss_mask: 0.6175  decode.d0.loss_dice: 1.4181  decode.d1.loss_cls: 1.6850  decode.d1.loss_mask: 0.5860  decode.d1.loss_dice: 1.3507  decode.d2.loss_cls: 1.5017  decode.d2.loss_mask: 0.6859  decode.d2.loss_dice: 1.3389  decode.d3.loss_cls: 1.4069  decode.d3.loss_mask: 0.6404  decode.d3.loss_dice: 1.3218  decode.d4.loss_cls: 1.4872  decode.d4.loss_mask: 0.6576  decode.d4.loss_dice: 1.2757  decode.d5.loss_cls: 1.4601  decode.d5.loss_mask: 0.6479  decode.d5.loss_dice: 1.3070  decode.d6.loss_cls: 1.4832  decode.d6.loss_mask: 0.6318  decode.d6.loss_dice: 1.3094  decode.d7.loss_cls: 1.4380  decode.d7.loss_mask: 0.6422  decode.d7.loss_dice: 1.3262  decode.d8.loss_cls: 1.4379  decode.d8.loss_mask: 0.6398  decode.d8.loss_dice: 1.3208
2023/05/23 21:35:12 - mmengine - INFO - Iter(train) [ 26850/160000]  lr: 8.4762e-06  eta: 15:47:02  time: 0.4165  data_time: 0.0104  memory: 4863  grad_norm: 100.3559  loss: 40.2703  decode.loss_cls: 1.4555  decode.loss_mask: 0.7895  decode.loss_dice: 1.4667  decode.d0.loss_cls: 3.5651  decode.d0.loss_mask: 0.8195  decode.d0.loss_dice: 1.8138  decode.d1.loss_cls: 1.5783  decode.d1.loss_mask: 0.8369  decode.d1.loss_dice: 1.6210  decode.d2.loss_cls: 1.4564  decode.d2.loss_mask: 0.8043  decode.d2.loss_dice: 1.5680  decode.d3.loss_cls: 1.4669  decode.d3.loss_mask: 0.7845  decode.d3.loss_dice: 1.5263  decode.d4.loss_cls: 1.4743  decode.d4.loss_mask: 0.7810  decode.d4.loss_dice: 1.5226  decode.d5.loss_cls: 1.4849  decode.d5.loss_mask: 0.7802  decode.d5.loss_dice: 1.4928  decode.d6.loss_cls: 1.4412  decode.d6.loss_mask: 0.8063  decode.d6.loss_dice: 1.4931  decode.d7.loss_cls: 1.4673  decode.d7.loss_mask: 0.7916  decode.d7.loss_dice: 1.4930  decode.d8.loss_cls: 1.4533  decode.d8.loss_mask: 0.7796  decode.d8.loss_dice: 1.4562
2023/05/23 21:35:33 - mmengine - INFO - Iter(train) [ 26900/160000]  lr: 8.4733e-06  eta: 15:46:38  time: 0.4122  data_time: 0.0095  memory: 4972  grad_norm: 105.5410  loss: 35.2724  decode.loss_cls: 1.3008  decode.loss_mask: 0.7345  decode.loss_dice: 1.2351  decode.d0.loss_cls: 3.2451  decode.d0.loss_mask: 0.7750  decode.d0.loss_dice: 1.4100  decode.d1.loss_cls: 1.4307  decode.d1.loss_mask: 0.7619  decode.d1.loss_dice: 1.2975  decode.d2.loss_cls: 1.3837  decode.d2.loss_mask: 0.7396  decode.d2.loss_dice: 1.2311  decode.d3.loss_cls: 1.3804  decode.d3.loss_mask: 0.7584  decode.d3.loss_dice: 1.2381  decode.d4.loss_cls: 1.2938  decode.d4.loss_mask: 0.7617  decode.d4.loss_dice: 1.2763  decode.d5.loss_cls: 1.3226  decode.d5.loss_mask: 0.7186  decode.d5.loss_dice: 1.2544  decode.d6.loss_cls: 1.3068  decode.d6.loss_mask: 0.6785  decode.d6.loss_dice: 1.2127  decode.d7.loss_cls: 1.2879  decode.d7.loss_mask: 0.7154  decode.d7.loss_dice: 1.2117  decode.d8.loss_cls: 1.3037  decode.d8.loss_mask: 0.7399  decode.d8.loss_dice: 1.2662
2023/05/23 21:35:53 - mmengine - INFO - Iter(train) [ 26950/160000]  lr: 8.4705e-06  eta: 15:46:13  time: 0.4136  data_time: 0.0098  memory: 4835  grad_norm: 106.7506  loss: 46.7010  decode.loss_cls: 1.9977  decode.loss_mask: 0.8817  decode.loss_dice: 1.5641  decode.d0.loss_cls: 3.6795  decode.d0.loss_mask: 0.9215  decode.d0.loss_dice: 1.8373  decode.d1.loss_cls: 2.0677  decode.d1.loss_mask: 0.9340  decode.d1.loss_dice: 1.7117  decode.d2.loss_cls: 1.9877  decode.d2.loss_mask: 0.8926  decode.d2.loss_dice: 1.6035  decode.d3.loss_cls: 2.0666  decode.d3.loss_mask: 0.8724  decode.d3.loss_dice: 1.5667  decode.d4.loss_cls: 1.9873  decode.d4.loss_mask: 0.9120  decode.d4.loss_dice: 1.6230  decode.d5.loss_cls: 1.9593  decode.d5.loss_mask: 0.8721  decode.d5.loss_dice: 1.5800  decode.d6.loss_cls: 1.9444  decode.d6.loss_mask: 0.8598  decode.d6.loss_dice: 1.5479  decode.d7.loss_cls: 1.9564  decode.d7.loss_mask: 0.8666  decode.d7.loss_dice: 1.5525  decode.d8.loss_cls: 2.0183  decode.d8.loss_mask: 0.8562  decode.d8.loss_dice: 1.5805
2023/05/23 21:36:15 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 21:36:15 - mmengine - INFO - Iter(train) [ 27000/160000]  lr: 8.4676e-06  eta: 15:45:54  time: 0.4100  data_time: 0.0096  memory: 4863  grad_norm: 102.3819  loss: 46.0291  decode.loss_cls: 1.6730  decode.loss_mask: 0.9759  decode.loss_dice: 1.6835  decode.d0.loss_cls: 3.7605  decode.d0.loss_mask: 0.9696  decode.d0.loss_dice: 1.8845  decode.d1.loss_cls: 1.8463  decode.d1.loss_mask: 0.9534  decode.d1.loss_dice: 1.8364  decode.d2.loss_cls: 1.7527  decode.d2.loss_mask: 0.9767  decode.d2.loss_dice: 1.7696  decode.d3.loss_cls: 1.6528  decode.d3.loss_mask: 0.9501  decode.d3.loss_dice: 1.7407  decode.d4.loss_cls: 1.6022  decode.d4.loss_mask: 0.9508  decode.d4.loss_dice: 1.7528  decode.d5.loss_cls: 1.6412  decode.d5.loss_mask: 0.9894  decode.d5.loss_dice: 1.7658  decode.d6.loss_cls: 1.6244  decode.d6.loss_mask: 0.9814  decode.d6.loss_dice: 1.6880  decode.d7.loss_cls: 1.6023  decode.d7.loss_mask: 0.9963  decode.d7.loss_dice: 1.7235  decode.d8.loss_cls: 1.5775  decode.d8.loss_mask: 1.0078  decode.d8.loss_dice: 1.7002
2023/05/23 21:36:15 - mmengine - INFO - Saving checkpoint at 27000 iterations
2023/05/23 21:36:41 - mmengine - INFO - Iter(train) [ 27050/160000]  lr: 8.4647e-06  eta: 15:45:56  time: 0.4065  data_time: 0.0096  memory: 4847  grad_norm: 104.8220  loss: 37.6514  decode.loss_cls: 1.3635  decode.loss_mask: 0.7432  decode.loss_dice: 1.3988  decode.d0.loss_cls: 3.2678  decode.d0.loss_mask: 0.8261  decode.d0.loss_dice: 1.5300  decode.d1.loss_cls: 1.4263  decode.d1.loss_mask: 0.8384  decode.d1.loss_dice: 1.5394  decode.d2.loss_cls: 1.3358  decode.d2.loss_mask: 0.8138  decode.d2.loss_dice: 1.4723  decode.d3.loss_cls: 1.3161  decode.d3.loss_mask: 0.8049  decode.d3.loss_dice: 1.4266  decode.d4.loss_cls: 1.4045  decode.d4.loss_mask: 0.7392  decode.d4.loss_dice: 1.3913  decode.d5.loss_cls: 1.3626  decode.d5.loss_mask: 0.7428  decode.d5.loss_dice: 1.4126  decode.d6.loss_cls: 1.4385  decode.d6.loss_mask: 0.7232  decode.d6.loss_dice: 1.3738  decode.d7.loss_cls: 1.3537  decode.d7.loss_mask: 0.7357  decode.d7.loss_dice: 1.3639  decode.d8.loss_cls: 1.3561  decode.d8.loss_mask: 0.7385  decode.d8.loss_dice: 1.4120
2023/05/23 21:37:03 - mmengine - INFO - Iter(train) [ 27100/160000]  lr: 8.4619e-06  eta: 15:45:37  time: 0.4695  data_time: 0.0101  memory: 4906  grad_norm: 87.9363  loss: 26.0415  decode.loss_cls: 0.9875  decode.loss_mask: 0.5689  decode.loss_dice: 0.7864  decode.d0.loss_cls: 3.1069  decode.d0.loss_mask: 0.5556  decode.d0.loss_dice: 0.8870  decode.d1.loss_cls: 1.1743  decode.d1.loss_mask: 0.5742  decode.d1.loss_dice: 0.8291  decode.d2.loss_cls: 1.1022  decode.d2.loss_mask: 0.5578  decode.d2.loss_dice: 0.8103  decode.d3.loss_cls: 0.9850  decode.d3.loss_mask: 0.5744  decode.d3.loss_dice: 0.7891  decode.d4.loss_cls: 0.9657  decode.d4.loss_mask: 0.5847  decode.d4.loss_dice: 0.8126  decode.d5.loss_cls: 0.9725  decode.d5.loss_mask: 0.5915  decode.d5.loss_dice: 0.8078  decode.d6.loss_cls: 0.9295  decode.d6.loss_mask: 0.6033  decode.d6.loss_dice: 0.7979  decode.d7.loss_cls: 0.9535  decode.d7.loss_mask: 0.5787  decode.d7.loss_dice: 0.7719  decode.d8.loss_cls: 0.9955  decode.d8.loss_mask: 0.5960  decode.d8.loss_dice: 0.7917
2023/05/23 21:37:26 - mmengine - INFO - Iter(train) [ 27150/160000]  lr: 8.4590e-06  eta: 15:45:22  time: 0.4126  data_time: 0.0100  memory: 4838  grad_norm: 85.7012  loss: 36.7990  decode.loss_cls: 1.2133  decode.loss_mask: 0.9718  decode.loss_dice: 1.2905  decode.d0.loss_cls: 2.8629  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 1.4095  decode.d1.loss_cls: 1.2881  decode.d1.loss_mask: 0.9909  decode.d1.loss_dice: 1.4317  decode.d2.loss_cls: 1.2913  decode.d2.loss_mask: 0.9878  decode.d2.loss_dice: 1.3659  decode.d3.loss_cls: 1.3092  decode.d3.loss_mask: 0.9254  decode.d3.loss_dice: 1.2912  decode.d4.loss_cls: 1.2655  decode.d4.loss_mask: 0.8862  decode.d4.loss_dice: 1.2899  decode.d5.loss_cls: 1.3038  decode.d5.loss_mask: 0.8844  decode.d5.loss_dice: 1.2830  decode.d6.loss_cls: 1.2168  decode.d6.loss_mask: 0.9510  decode.d6.loss_dice: 1.2804  decode.d7.loss_cls: 1.1908  decode.d7.loss_mask: 0.9573  decode.d7.loss_dice: 1.2860  decode.d8.loss_cls: 1.2081  decode.d8.loss_mask: 0.9572  decode.d8.loss_dice: 1.2603
2023/05/23 21:37:47 - mmengine - INFO - Iter(train) [ 27200/160000]  lr: 8.4562e-06  eta: 15:45:00  time: 0.4225  data_time: 0.0097  memory: 4835  grad_norm: 77.4704  loss: 36.1883  decode.loss_cls: 1.2708  decode.loss_mask: 0.7172  decode.loss_dice: 1.3424  decode.d0.loss_cls: 3.1587  decode.d0.loss_mask: 0.7847  decode.d0.loss_dice: 1.5356  decode.d1.loss_cls: 1.5863  decode.d1.loss_mask: 0.7389  decode.d1.loss_dice: 1.4447  decode.d2.loss_cls: 1.3670  decode.d2.loss_mask: 0.7421  decode.d2.loss_dice: 1.3776  decode.d3.loss_cls: 1.3113  decode.d3.loss_mask: 0.7058  decode.d3.loss_dice: 1.3489  decode.d4.loss_cls: 1.3028  decode.d4.loss_mask: 0.7325  decode.d4.loss_dice: 1.3250  decode.d5.loss_cls: 1.2836  decode.d5.loss_mask: 0.7179  decode.d5.loss_dice: 1.3425  decode.d6.loss_cls: 1.2944  decode.d6.loss_mask: 0.7259  decode.d6.loss_dice: 1.3325  decode.d7.loss_cls: 1.3215  decode.d7.loss_mask: 0.7143  decode.d7.loss_dice: 1.3093  decode.d8.loss_cls: 1.2960  decode.d8.loss_mask: 0.7174  decode.d8.loss_dice: 1.3407
2023/05/23 21:38:07 - mmengine - INFO - Iter(train) [ 27250/160000]  lr: 8.4533e-06  eta: 15:44:35  time: 0.4169  data_time: 0.0097  memory: 4856  grad_norm: 109.5507  loss: 31.9634  decode.loss_cls: 1.2121  decode.loss_mask: 0.6077  decode.loss_dice: 1.1566  decode.d0.loss_cls: 3.2327  decode.d0.loss_mask: 0.6678  decode.d0.loss_dice: 1.2919  decode.d1.loss_cls: 1.2572  decode.d1.loss_mask: 0.6427  decode.d1.loss_dice: 1.2594  decode.d2.loss_cls: 1.1573  decode.d2.loss_mask: 0.6048  decode.d2.loss_dice: 1.2029  decode.d3.loss_cls: 1.1065  decode.d3.loss_mask: 0.6259  decode.d3.loss_dice: 1.1663  decode.d4.loss_cls: 1.1296  decode.d4.loss_mask: 0.6168  decode.d4.loss_dice: 1.1452  decode.d5.loss_cls: 1.1502  decode.d5.loss_mask: 0.6509  decode.d5.loss_dice: 1.2068  decode.d6.loss_cls: 1.1605  decode.d6.loss_mask: 0.6299  decode.d6.loss_dice: 1.1551  decode.d7.loss_cls: 1.1532  decode.d7.loss_mask: 0.6507  decode.d7.loss_dice: 1.1664  decode.d8.loss_cls: 1.1731  decode.d8.loss_mask: 0.6327  decode.d8.loss_dice: 1.1504
2023/05/23 21:38:28 - mmengine - INFO - Iter(train) [ 27300/160000]  lr: 8.4504e-06  eta: 15:44:10  time: 0.4106  data_time: 0.0102  memory: 4856  grad_norm: 133.8506  loss: 31.5402  decode.loss_cls: 1.1055  decode.loss_mask: 0.6658  decode.loss_dice: 1.0266  decode.d0.loss_cls: 3.0280  decode.d0.loss_mask: 0.7548  decode.d0.loss_dice: 1.2964  decode.d1.loss_cls: 1.2793  decode.d1.loss_mask: 0.8314  decode.d1.loss_dice: 1.1937  decode.d2.loss_cls: 1.2326  decode.d2.loss_mask: 0.7585  decode.d2.loss_dice: 1.1136  decode.d3.loss_cls: 1.1780  decode.d3.loss_mask: 0.7046  decode.d3.loss_dice: 1.0506  decode.d4.loss_cls: 1.1637  decode.d4.loss_mask: 0.7023  decode.d4.loss_dice: 1.0628  decode.d5.loss_cls: 1.1240  decode.d5.loss_mask: 0.6858  decode.d5.loss_dice: 1.0491  decode.d6.loss_cls: 1.1639  decode.d6.loss_mask: 0.6837  decode.d6.loss_dice: 1.0323  decode.d7.loss_cls: 1.1293  decode.d7.loss_mask: 0.6659  decode.d7.loss_dice: 1.0374  decode.d8.loss_cls: 1.1248  decode.d8.loss_mask: 0.6545  decode.d8.loss_dice: 1.0416
2023/05/23 21:38:48 - mmengine - INFO - Iter(train) [ 27350/160000]  lr: 8.4476e-06  eta: 15:43:44  time: 0.4081  data_time: 0.0101  memory: 4838  grad_norm: 88.2570  loss: 41.5155  decode.loss_cls: 1.6538  decode.loss_mask: 0.7216  decode.loss_dice: 1.4695  decode.d0.loss_cls: 3.6215  decode.d0.loss_mask: 0.7923  decode.d0.loss_dice: 1.6760  decode.d1.loss_cls: 1.8295  decode.d1.loss_mask: 0.7509  decode.d1.loss_dice: 1.6374  decode.d2.loss_cls: 1.7455  decode.d2.loss_mask: 0.7313  decode.d2.loss_dice: 1.5758  decode.d3.loss_cls: 1.6630  decode.d3.loss_mask: 0.7873  decode.d3.loss_dice: 1.4961  decode.d4.loss_cls: 1.6074  decode.d4.loss_mask: 0.7633  decode.d4.loss_dice: 1.5246  decode.d5.loss_cls: 1.6563  decode.d5.loss_mask: 0.7325  decode.d5.loss_dice: 1.5058  decode.d6.loss_cls: 1.6685  decode.d6.loss_mask: 0.7451  decode.d6.loss_dice: 1.4964  decode.d7.loss_cls: 1.6831  decode.d7.loss_mask: 0.7192  decode.d7.loss_dice: 1.4629  decode.d8.loss_cls: 1.6494  decode.d8.loss_mask: 0.7280  decode.d8.loss_dice: 1.4213
2023/05/23 21:39:09 - mmengine - INFO - Iter(train) [ 27400/160000]  lr: 8.4447e-06  eta: 15:43:19  time: 0.4116  data_time: 0.0097  memory: 4907  grad_norm: 99.6699  loss: 40.7596  decode.loss_cls: 1.4553  decode.loss_mask: 0.9216  decode.loss_dice: 1.5167  decode.d0.loss_cls: 3.3013  decode.d0.loss_mask: 0.8823  decode.d0.loss_dice: 1.6591  decode.d1.loss_cls: 1.5716  decode.d1.loss_mask: 0.8478  decode.d1.loss_dice: 1.5759  decode.d2.loss_cls: 1.5110  decode.d2.loss_mask: 0.8367  decode.d2.loss_dice: 1.5531  decode.d3.loss_cls: 1.5722  decode.d3.loss_mask: 0.7867  decode.d3.loss_dice: 1.4846  decode.d4.loss_cls: 1.5251  decode.d4.loss_mask: 0.8074  decode.d4.loss_dice: 1.5089  decode.d5.loss_cls: 1.5427  decode.d5.loss_mask: 0.8766  decode.d5.loss_dice: 1.4987  decode.d6.loss_cls: 1.4926  decode.d6.loss_mask: 0.8382  decode.d6.loss_dice: 1.4984  decode.d7.loss_cls: 1.4990  decode.d7.loss_mask: 0.8461  decode.d7.loss_dice: 1.5056  decode.d8.loss_cls: 1.4766  decode.d8.loss_mask: 0.8855  decode.d8.loss_dice: 1.4825
2023/05/23 21:39:30 - mmengine - INFO - Iter(train) [ 27450/160000]  lr: 8.4418e-06  eta: 15:42:59  time: 0.4102  data_time: 0.0095  memory: 4846  grad_norm: 93.3242  loss: 39.9498  decode.loss_cls: 1.4734  decode.loss_mask: 0.7432  decode.loss_dice: 1.4897  decode.d0.loss_cls: 3.4936  decode.d0.loss_mask: 0.7708  decode.d0.loss_dice: 1.6867  decode.d1.loss_cls: 1.6633  decode.d1.loss_mask: 0.7609  decode.d1.loss_dice: 1.5776  decode.d2.loss_cls: 1.5380  decode.d2.loss_mask: 0.7439  decode.d2.loss_dice: 1.5269  decode.d3.loss_cls: 1.5491  decode.d3.loss_mask: 0.7231  decode.d3.loss_dice: 1.5204  decode.d4.loss_cls: 1.5299  decode.d4.loss_mask: 0.7340  decode.d4.loss_dice: 1.4792  decode.d5.loss_cls: 1.5407  decode.d5.loss_mask: 0.7460  decode.d5.loss_dice: 1.4728  decode.d6.loss_cls: 1.4915  decode.d6.loss_mask: 0.7436  decode.d6.loss_dice: 1.4857  decode.d7.loss_cls: 1.5051  decode.d7.loss_mask: 0.7458  decode.d7.loss_dice: 1.4829  decode.d8.loss_cls: 1.5076  decode.d8.loss_mask: 0.7531  decode.d8.loss_dice: 1.4714
2023/05/23 21:39:51 - mmengine - INFO - Iter(train) [ 27500/160000]  lr: 8.4390e-06  eta: 15:42:36  time: 0.4113  data_time: 0.0098  memory: 4884  grad_norm: 93.8667  loss: 32.4373  decode.loss_cls: 1.1958  decode.loss_mask: 0.7366  decode.loss_dice: 1.0248  decode.d0.loss_cls: 3.0810  decode.d0.loss_mask: 0.8395  decode.d0.loss_dice: 1.3157  decode.d1.loss_cls: 1.2745  decode.d1.loss_mask: 0.7957  decode.d1.loss_dice: 1.1856  decode.d2.loss_cls: 1.2751  decode.d2.loss_mask: 0.7356  decode.d2.loss_dice: 1.1394  decode.d3.loss_cls: 1.2401  decode.d3.loss_mask: 0.7186  decode.d3.loss_dice: 1.0614  decode.d4.loss_cls: 1.2178  decode.d4.loss_mask: 0.7405  decode.d4.loss_dice: 1.0596  decode.d5.loss_cls: 1.2093  decode.d5.loss_mask: 0.7181  decode.d5.loss_dice: 1.0652  decode.d6.loss_cls: 1.1787  decode.d6.loss_mask: 0.7184  decode.d6.loss_dice: 1.0293  decode.d7.loss_cls: 1.1940  decode.d7.loss_mask: 0.7104  decode.d7.loss_dice: 1.0338  decode.d8.loss_cls: 1.1709  decode.d8.loss_mask: 0.7244  decode.d8.loss_dice: 1.0475
2023/05/23 21:40:12 - mmengine - INFO - Iter(train) [ 27550/160000]  lr: 8.4361e-06  eta: 15:42:12  time: 0.4115  data_time: 0.0096  memory: 4885  grad_norm: 127.0181  loss: 38.8229  decode.loss_cls: 1.1557  decode.loss_mask: 0.8472  decode.loss_dice: 1.6171  decode.d0.loss_cls: 3.1512  decode.d0.loss_mask: 0.8819  decode.d0.loss_dice: 1.8386  decode.d1.loss_cls: 1.2711  decode.d1.loss_mask: 0.8823  decode.d1.loss_dice: 1.7509  decode.d2.loss_cls: 1.1421  decode.d2.loss_mask: 0.8650  decode.d2.loss_dice: 1.6876  decode.d3.loss_cls: 1.1129  decode.d3.loss_mask: 0.8812  decode.d3.loss_dice: 1.6447  decode.d4.loss_cls: 1.1628  decode.d4.loss_mask: 0.8193  decode.d4.loss_dice: 1.6219  decode.d5.loss_cls: 1.2146  decode.d5.loss_mask: 0.8323  decode.d5.loss_dice: 1.5945  decode.d6.loss_cls: 1.1466  decode.d6.loss_mask: 0.8457  decode.d6.loss_dice: 1.6273  decode.d7.loss_cls: 1.1740  decode.d7.loss_mask: 0.8260  decode.d7.loss_dice: 1.6050  decode.d8.loss_cls: 1.1990  decode.d8.loss_mask: 0.8238  decode.d8.loss_dice: 1.6006
2023/05/23 21:40:33 - mmengine - INFO - Iter(train) [ 27600/160000]  lr: 8.4332e-06  eta: 15:41:47  time: 0.4096  data_time: 0.0097  memory: 4846  grad_norm: 100.3345  loss: 44.0134  decode.loss_cls: 1.6182  decode.loss_mask: 0.9104  decode.loss_dice: 1.5987  decode.d0.loss_cls: 3.4967  decode.d0.loss_mask: 1.0106  decode.d0.loss_dice: 1.8665  decode.d1.loss_cls: 1.7385  decode.d1.loss_mask: 0.9246  decode.d1.loss_dice: 1.7913  decode.d2.loss_cls: 1.6488  decode.d2.loss_mask: 0.9156  decode.d2.loss_dice: 1.6949  decode.d3.loss_cls: 1.6269  decode.d3.loss_mask: 0.8972  decode.d3.loss_dice: 1.6968  decode.d4.loss_cls: 1.6102  decode.d4.loss_mask: 0.9219  decode.d4.loss_dice: 1.6360  decode.d5.loss_cls: 1.5868  decode.d5.loss_mask: 0.9060  decode.d5.loss_dice: 1.6048  decode.d6.loss_cls: 1.6372  decode.d6.loss_mask: 0.9033  decode.d6.loss_dice: 1.5932  decode.d7.loss_cls: 1.5899  decode.d7.loss_mask: 0.9100  decode.d7.loss_dice: 1.5922  decode.d8.loss_cls: 1.5700  decode.d8.loss_mask: 0.9245  decode.d8.loss_dice: 1.5918
2023/05/23 21:40:53 - mmengine - INFO - Iter(train) [ 27650/160000]  lr: 8.4304e-06  eta: 15:41:21  time: 0.4105  data_time: 0.0097  memory: 4906  grad_norm: 83.8855  loss: 45.3317  decode.loss_cls: 1.6739  decode.loss_mask: 0.9079  decode.loss_dice: 1.6510  decode.d0.loss_cls: 3.6033  decode.d0.loss_mask: 1.0269  decode.d0.loss_dice: 1.9241  decode.d1.loss_cls: 1.8189  decode.d1.loss_mask: 0.9918  decode.d1.loss_dice: 1.8716  decode.d2.loss_cls: 1.8073  decode.d2.loss_mask: 0.9019  decode.d2.loss_dice: 1.7038  decode.d3.loss_cls: 1.7607  decode.d3.loss_mask: 0.8800  decode.d3.loss_dice: 1.6266  decode.d4.loss_cls: 1.6263  decode.d4.loss_mask: 0.8880  decode.d4.loss_dice: 1.6533  decode.d5.loss_cls: 1.6347  decode.d5.loss_mask: 0.9376  decode.d5.loss_dice: 1.6904  decode.d6.loss_cls: 1.7149  decode.d6.loss_mask: 0.8969  decode.d6.loss_dice: 1.5902  decode.d7.loss_cls: 1.7808  decode.d7.loss_mask: 0.8916  decode.d7.loss_dice: 1.6434  decode.d8.loss_cls: 1.7195  decode.d8.loss_mask: 0.8890  decode.d8.loss_dice: 1.6252
2023/05/23 21:41:14 - mmengine - INFO - Iter(train) [ 27700/160000]  lr: 8.4275e-06  eta: 15:40:57  time: 0.4098  data_time: 0.0096  memory: 4944  grad_norm: 84.0105  loss: 48.8874  decode.loss_cls: 1.6066  decode.loss_mask: 0.9710  decode.loss_dice: 1.9790  decode.d0.loss_cls: 3.8329  decode.d0.loss_mask: 1.0172  decode.d0.loss_dice: 2.3471  decode.d1.loss_cls: 1.7853  decode.d1.loss_mask: 1.0220  decode.d1.loss_dice: 2.1558  decode.d2.loss_cls: 1.7410  decode.d2.loss_mask: 1.0134  decode.d2.loss_dice: 2.0707  decode.d3.loss_cls: 1.6978  decode.d3.loss_mask: 0.9382  decode.d3.loss_dice: 1.9645  decode.d4.loss_cls: 1.6704  decode.d4.loss_mask: 0.9330  decode.d4.loss_dice: 1.9786  decode.d5.loss_cls: 1.7289  decode.d5.loss_mask: 0.9368  decode.d5.loss_dice: 1.9543  decode.d6.loss_cls: 1.5977  decode.d6.loss_mask: 0.9413  decode.d6.loss_dice: 1.9446  decode.d7.loss_cls: 1.6193  decode.d7.loss_mask: 0.9404  decode.d7.loss_dice: 1.9781  decode.d8.loss_cls: 1.7013  decode.d8.loss_mask: 0.8581  decode.d8.loss_dice: 1.9622
2023/05/23 21:41:35 - mmengine - INFO - Iter(train) [ 27750/160000]  lr: 8.4246e-06  eta: 15:40:33  time: 0.4095  data_time: 0.0094  memory: 4836  grad_norm: 87.1239  loss: 32.5256  decode.loss_cls: 1.1262  decode.loss_mask: 0.6291  decode.loss_dice: 1.2660  decode.d0.loss_cls: 3.0525  decode.d0.loss_mask: 0.6722  decode.d0.loss_dice: 1.4203  decode.d1.loss_cls: 1.2829  decode.d1.loss_mask: 0.6354  decode.d1.loss_dice: 1.3565  decode.d2.loss_cls: 1.1568  decode.d2.loss_mask: 0.6482  decode.d2.loss_dice: 1.3143  decode.d3.loss_cls: 1.0610  decode.d3.loss_mask: 0.6292  decode.d3.loss_dice: 1.2839  decode.d4.loss_cls: 1.0407  decode.d4.loss_mask: 0.6389  decode.d4.loss_dice: 1.3048  decode.d5.loss_cls: 1.1278  decode.d5.loss_mask: 0.6362  decode.d5.loss_dice: 1.2798  decode.d6.loss_cls: 1.1026  decode.d6.loss_mask: 0.6214  decode.d6.loss_dice: 1.2538  decode.d7.loss_cls: 1.0882  decode.d7.loss_mask: 0.6610  decode.d7.loss_dice: 1.2547  decode.d8.loss_cls: 1.1123  decode.d8.loss_mask: 0.6274  decode.d8.loss_dice: 1.2413
2023/05/23 21:41:56 - mmengine - INFO - Iter(train) [ 27800/160000]  lr: 8.4218e-06  eta: 15:40:09  time: 0.4122  data_time: 0.0100  memory: 4857  grad_norm: 95.2917  loss: 46.9162  decode.loss_cls: 1.7279  decode.loss_mask: 1.0305  decode.loss_dice: 1.6250  decode.d0.loss_cls: 3.6122  decode.d0.loss_mask: 1.0184  decode.d0.loss_dice: 1.8591  decode.d1.loss_cls: 1.8941  decode.d1.loss_mask: 1.0470  decode.d1.loss_dice: 1.7861  decode.d2.loss_cls: 1.7553  decode.d2.loss_mask: 1.0148  decode.d2.loss_dice: 1.7115  decode.d3.loss_cls: 1.7817  decode.d3.loss_mask: 1.0399  decode.d3.loss_dice: 1.6490  decode.d4.loss_cls: 1.7396  decode.d4.loss_mask: 1.0775  decode.d4.loss_dice: 1.6603  decode.d5.loss_cls: 1.7662  decode.d5.loss_mask: 1.0801  decode.d5.loss_dice: 1.6474  decode.d6.loss_cls: 1.7554  decode.d6.loss_mask: 1.0341  decode.d6.loss_dice: 1.6449  decode.d7.loss_cls: 1.8045  decode.d7.loss_mask: 1.0340  decode.d7.loss_dice: 1.6528  decode.d8.loss_cls: 1.8102  decode.d8.loss_mask: 1.0383  decode.d8.loss_dice: 1.6182
2023/05/23 21:42:17 - mmengine - INFO - Iter(train) [ 27850/160000]  lr: 8.4189e-06  eta: 15:39:46  time: 0.4073  data_time: 0.0096  memory: 4875  grad_norm: 89.7773  loss: 42.6384  decode.loss_cls: 1.6250  decode.loss_mask: 0.8917  decode.loss_dice: 1.4673  decode.d0.loss_cls: 3.2260  decode.d0.loss_mask: 0.9848  decode.d0.loss_dice: 1.6936  decode.d1.loss_cls: 1.8495  decode.d1.loss_mask: 0.9343  decode.d1.loss_dice: 1.6009  decode.d2.loss_cls: 1.6683  decode.d2.loss_mask: 0.9091  decode.d2.loss_dice: 1.5272  decode.d3.loss_cls: 1.5981  decode.d3.loss_mask: 0.9212  decode.d3.loss_dice: 1.4984  decode.d4.loss_cls: 1.5207  decode.d4.loss_mask: 0.9711  decode.d4.loss_dice: 1.5629  decode.d5.loss_cls: 1.5749  decode.d5.loss_mask: 0.9858  decode.d5.loss_dice: 1.5289  decode.d6.loss_cls: 1.6521  decode.d6.loss_mask: 0.9322  decode.d6.loss_dice: 1.4546  decode.d7.loss_cls: 1.6116  decode.d7.loss_mask: 0.9391  decode.d7.loss_dice: 1.4829  decode.d8.loss_cls: 1.6511  decode.d8.loss_mask: 0.8991  decode.d8.loss_dice: 1.4761
2023/05/23 21:42:37 - mmengine - INFO - Iter(train) [ 27900/160000]  lr: 8.4160e-06  eta: 15:39:21  time: 0.4081  data_time: 0.0097  memory: 4877  grad_norm: 139.6952  loss: 31.6680  decode.loss_cls: 0.9746  decode.loss_mask: 0.7911  decode.loss_dice: 1.0254  decode.d0.loss_cls: 2.9635  decode.d0.loss_mask: 0.8738  decode.d0.loss_dice: 1.2125  decode.d1.loss_cls: 1.1740  decode.d1.loss_mask: 0.8657  decode.d1.loss_dice: 1.1560  decode.d2.loss_cls: 1.0896  decode.d2.loss_mask: 0.8511  decode.d2.loss_dice: 1.1175  decode.d3.loss_cls: 1.0947  decode.d3.loss_mask: 0.8253  decode.d3.loss_dice: 1.0452  decode.d4.loss_cls: 1.0568  decode.d4.loss_mask: 0.8447  decode.d4.loss_dice: 1.0601  decode.d5.loss_cls: 1.0677  decode.d5.loss_mask: 0.7951  decode.d5.loss_dice: 1.0547  decode.d6.loss_cls: 1.0942  decode.d6.loss_mask: 0.7958  decode.d6.loss_dice: 1.0602  decode.d7.loss_cls: 1.0350  decode.d7.loss_mask: 0.7848  decode.d7.loss_dice: 1.0754  decode.d8.loss_cls: 1.0184  decode.d8.loss_mask: 0.8143  decode.d8.loss_dice: 1.0508
2023/05/23 21:42:59 - mmengine - INFO - Iter(train) [ 27950/160000]  lr: 8.4132e-06  eta: 15:39:00  time: 0.4672  data_time: 0.0095  memory: 4925  grad_norm: 116.6995  loss: 36.0730  decode.loss_cls: 1.3243  decode.loss_mask: 0.7824  decode.loss_dice: 1.1928  decode.d0.loss_cls: 3.4281  decode.d0.loss_mask: 0.8069  decode.d0.loss_dice: 1.3105  decode.d1.loss_cls: 1.4892  decode.d1.loss_mask: 0.8159  decode.d1.loss_dice: 1.3384  decode.d2.loss_cls: 1.3560  decode.d2.loss_mask: 0.8122  decode.d2.loss_dice: 1.2869  decode.d3.loss_cls: 1.4677  decode.d3.loss_mask: 0.7461  decode.d3.loss_dice: 1.1859  decode.d4.loss_cls: 1.4194  decode.d4.loss_mask: 0.7705  decode.d4.loss_dice: 1.1944  decode.d5.loss_cls: 1.3379  decode.d5.loss_mask: 0.7846  decode.d5.loss_dice: 1.2211  decode.d6.loss_cls: 1.3017  decode.d6.loss_mask: 0.7938  decode.d6.loss_dice: 1.2330  decode.d7.loss_cls: 1.3015  decode.d7.loss_mask: 0.7978  decode.d7.loss_dice: 1.2705  decode.d8.loss_cls: 1.3034  decode.d8.loss_mask: 0.7728  decode.d8.loss_dice: 1.2270
2023/05/23 21:43:20 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 21:43:20 - mmengine - INFO - Iter(train) [ 28000/160000]  lr: 8.4103e-06  eta: 15:38:41  time: 0.4180  data_time: 0.0098  memory: 4989  grad_norm: 100.4034  loss: 45.8479  decode.loss_cls: 1.7886  decode.loss_mask: 1.0169  decode.loss_dice: 1.5058  decode.d0.loss_cls: 3.2853  decode.d0.loss_mask: 1.1780  decode.d0.loss_dice: 1.7220  decode.d1.loss_cls: 1.8229  decode.d1.loss_mask: 1.0360  decode.d1.loss_dice: 1.6958  decode.d2.loss_cls: 1.8130  decode.d2.loss_mask: 1.0400  decode.d2.loss_dice: 1.6114  decode.d3.loss_cls: 1.8167  decode.d3.loss_mask: 1.0297  decode.d3.loss_dice: 1.5814  decode.d4.loss_cls: 1.8198  decode.d4.loss_mask: 0.9884  decode.d4.loss_dice: 1.5507  decode.d5.loss_cls: 1.8295  decode.d5.loss_mask: 1.0265  decode.d5.loss_dice: 1.5318  decode.d6.loss_cls: 1.8135  decode.d6.loss_mask: 1.0453  decode.d6.loss_dice: 1.5698  decode.d7.loss_cls: 1.7591  decode.d7.loss_mask: 1.0453  decode.d7.loss_dice: 1.5426  decode.d8.loss_cls: 1.7747  decode.d8.loss_mask: 1.0782  decode.d8.loss_dice: 1.5292
2023/05/23 21:43:20 - mmengine - INFO - Saving checkpoint at 28000 iterations
2023/05/23 21:43:47 - mmengine - INFO - Iter(train) [ 28050/160000]  lr: 8.4074e-06  eta: 15:38:45  time: 0.4138  data_time: 0.0101  memory: 4835  grad_norm: 134.5610  loss: 40.3818  decode.loss_cls: 1.2458  decode.loss_mask: 0.8742  decode.loss_dice: 1.6255  decode.d0.loss_cls: 3.3574  decode.d0.loss_mask: 0.8004  decode.d0.loss_dice: 1.8289  decode.d1.loss_cls: 1.5624  decode.d1.loss_mask: 0.8879  decode.d1.loss_dice: 1.7310  decode.d2.loss_cls: 1.3398  decode.d2.loss_mask: 0.9189  decode.d2.loss_dice: 1.6924  decode.d3.loss_cls: 1.2887  decode.d3.loss_mask: 0.9091  decode.d3.loss_dice: 1.6348  decode.d4.loss_cls: 1.2169  decode.d4.loss_mask: 0.8916  decode.d4.loss_dice: 1.6610  decode.d5.loss_cls: 1.1952  decode.d5.loss_mask: 0.8842  decode.d5.loss_dice: 1.6287  decode.d6.loss_cls: 1.2290  decode.d6.loss_mask: 0.8846  decode.d6.loss_dice: 1.6377  decode.d7.loss_cls: 1.2211  decode.d7.loss_mask: 0.8587  decode.d7.loss_dice: 1.6357  decode.d8.loss_cls: 1.2758  decode.d8.loss_mask: 0.8650  decode.d8.loss_dice: 1.5990
2023/05/23 21:44:08 - mmengine - INFO - Iter(train) [ 28100/160000]  lr: 8.4046e-06  eta: 15:38:22  time: 0.4214  data_time: 0.0094  memory: 4861  grad_norm: 105.4448  loss: 37.2211  decode.loss_cls: 1.1550  decode.loss_mask: 0.8514  decode.loss_dice: 1.3952  decode.d0.loss_cls: 3.0402  decode.d0.loss_mask: 0.9568  decode.d0.loss_dice: 1.6141  decode.d1.loss_cls: 1.4064  decode.d1.loss_mask: 0.8608  decode.d1.loss_dice: 1.5101  decode.d2.loss_cls: 1.3137  decode.d2.loss_mask: 0.8278  decode.d2.loss_dice: 1.4437  decode.d3.loss_cls: 1.2598  decode.d3.loss_mask: 0.8384  decode.d3.loss_dice: 1.4309  decode.d4.loss_cls: 1.2564  decode.d4.loss_mask: 0.8395  decode.d4.loss_dice: 1.4043  decode.d5.loss_cls: 1.1933  decode.d5.loss_mask: 0.8542  decode.d5.loss_dice: 1.4233  decode.d6.loss_cls: 1.2294  decode.d6.loss_mask: 0.8636  decode.d6.loss_dice: 1.3880  decode.d7.loss_cls: 1.1831  decode.d7.loss_mask: 0.8605  decode.d7.loss_dice: 1.3872  decode.d8.loss_cls: 1.1987  decode.d8.loss_mask: 0.8534  decode.d8.loss_dice: 1.3821
2023/05/23 21:44:30 - mmengine - INFO - Iter(train) [ 28150/160000]  lr: 8.4017e-06  eta: 15:38:02  time: 0.4668  data_time: 0.0098  memory: 4845  grad_norm: 102.5940  loss: 34.5380  decode.loss_cls: 1.2261  decode.loss_mask: 0.7435  decode.loss_dice: 1.1854  decode.d0.loss_cls: 3.0884  decode.d0.loss_mask: 0.8690  decode.d0.loss_dice: 1.3832  decode.d1.loss_cls: 1.3497  decode.d1.loss_mask: 0.8221  decode.d1.loss_dice: 1.2863  decode.d2.loss_cls: 1.3086  decode.d2.loss_mask: 0.8057  decode.d2.loss_dice: 1.2324  decode.d3.loss_cls: 1.2490  decode.d3.loss_mask: 0.7605  decode.d3.loss_dice: 1.2269  decode.d4.loss_cls: 1.2764  decode.d4.loss_mask: 0.7398  decode.d4.loss_dice: 1.2159  decode.d5.loss_cls: 1.2506  decode.d5.loss_mask: 0.7635  decode.d5.loss_dice: 1.2102  decode.d6.loss_cls: 1.2668  decode.d6.loss_mask: 0.7616  decode.d6.loss_dice: 1.1840  decode.d7.loss_cls: 1.2613  decode.d7.loss_mask: 0.7383  decode.d7.loss_dice: 1.1631  decode.d8.loss_cls: 1.2398  decode.d8.loss_mask: 0.7425  decode.d8.loss_dice: 1.1872
2023/05/23 21:44:50 - mmengine - INFO - Iter(train) [ 28200/160000]  lr: 8.3988e-06  eta: 15:37:37  time: 0.4095  data_time: 0.0096  memory: 4821  grad_norm: 83.1895  loss: 37.9681  decode.loss_cls: 1.4322  decode.loss_mask: 0.8673  decode.loss_dice: 1.2244  decode.d0.loss_cls: 3.6159  decode.d0.loss_mask: 0.9005  decode.d0.loss_dice: 1.3844  decode.d1.loss_cls: 1.5672  decode.d1.loss_mask: 0.8116  decode.d1.loss_dice: 1.3022  decode.d2.loss_cls: 1.5198  decode.d2.loss_mask: 0.8547  decode.d2.loss_dice: 1.3079  decode.d3.loss_cls: 1.5474  decode.d3.loss_mask: 0.7856  decode.d3.loss_dice: 1.2437  decode.d4.loss_cls: 1.4762  decode.d4.loss_mask: 0.8431  decode.d4.loss_dice: 1.2311  decode.d5.loss_cls: 1.4432  decode.d5.loss_mask: 0.8287  decode.d5.loss_dice: 1.2124  decode.d6.loss_cls: 1.5038  decode.d6.loss_mask: 0.8536  decode.d6.loss_dice: 1.2038  decode.d7.loss_cls: 1.4054  decode.d7.loss_mask: 0.8842  decode.d7.loss_dice: 1.2139  decode.d8.loss_cls: 1.4220  decode.d8.loss_mask: 0.8765  decode.d8.loss_dice: 1.2055
2023/05/23 21:45:11 - mmengine - INFO - Iter(train) [ 28250/160000]  lr: 8.3960e-06  eta: 15:37:13  time: 0.4129  data_time: 0.0097  memory: 4866  grad_norm: 113.6917  loss: 37.6977  decode.loss_cls: 1.4693  decode.loss_mask: 0.8180  decode.loss_dice: 1.2260  decode.d0.loss_cls: 3.4489  decode.d0.loss_mask: 0.8561  decode.d0.loss_dice: 1.2982  decode.d1.loss_cls: 1.7360  decode.d1.loss_mask: 0.7994  decode.d1.loss_dice: 1.2660  decode.d2.loss_cls: 1.6376  decode.d2.loss_mask: 0.8308  decode.d2.loss_dice: 1.2265  decode.d3.loss_cls: 1.4809  decode.d3.loss_mask: 0.8144  decode.d3.loss_dice: 1.2369  decode.d4.loss_cls: 1.5214  decode.d4.loss_mask: 0.7883  decode.d4.loss_dice: 1.1952  decode.d5.loss_cls: 1.5136  decode.d5.loss_mask: 0.7891  decode.d5.loss_dice: 1.1832  decode.d6.loss_cls: 1.5150  decode.d6.loss_mask: 0.7963  decode.d6.loss_dice: 1.1988  decode.d7.loss_cls: 1.4790  decode.d7.loss_mask: 0.8178  decode.d7.loss_dice: 1.2372  decode.d8.loss_cls: 1.4553  decode.d8.loss_mask: 0.8263  decode.d8.loss_dice: 1.2365
2023/05/23 21:45:32 - mmengine - INFO - Iter(train) [ 28300/160000]  lr: 8.3931e-06  eta: 15:36:49  time: 0.4214  data_time: 0.0099  memory: 4906  grad_norm: 119.1082  loss: 36.9075  decode.loss_cls: 1.2259  decode.loss_mask: 0.8395  decode.loss_dice: 1.2389  decode.d0.loss_cls: 3.2386  decode.d0.loss_mask: 0.9475  decode.d0.loss_dice: 1.4084  decode.d1.loss_cls: 1.4020  decode.d1.loss_mask: 0.9121  decode.d1.loss_dice: 1.3799  decode.d2.loss_cls: 1.3310  decode.d2.loss_mask: 0.8351  decode.d2.loss_dice: 1.2902  decode.d3.loss_cls: 1.3238  decode.d3.loss_mask: 0.8687  decode.d3.loss_dice: 1.3033  decode.d4.loss_cls: 1.3276  decode.d4.loss_mask: 0.8673  decode.d4.loss_dice: 1.3115  decode.d5.loss_cls: 1.3886  decode.d5.loss_mask: 0.8621  decode.d5.loss_dice: 1.3018  decode.d6.loss_cls: 1.3538  decode.d6.loss_mask: 0.8432  decode.d6.loss_dice: 1.2852  decode.d7.loss_cls: 1.2749  decode.d7.loss_mask: 0.8497  decode.d7.loss_dice: 1.2957  decode.d8.loss_cls: 1.2968  decode.d8.loss_mask: 0.8363  decode.d8.loss_dice: 1.2681
2023/05/23 21:45:52 - mmengine - INFO - Iter(train) [ 28350/160000]  lr: 8.3902e-06  eta: 15:36:24  time: 0.4086  data_time: 0.0097  memory: 4839  grad_norm: 104.9162  loss: 47.3686  decode.loss_cls: 1.6011  decode.loss_mask: 0.9148  decode.loss_dice: 1.8475  decode.d0.loss_cls: 3.5806  decode.d0.loss_mask: 1.0669  decode.d0.loss_dice: 2.2718  decode.d1.loss_cls: 1.7680  decode.d1.loss_mask: 1.0223  decode.d1.loss_dice: 2.0636  decode.d2.loss_cls: 1.7433  decode.d2.loss_mask: 0.9593  decode.d2.loss_dice: 1.9232  decode.d3.loss_cls: 1.6248  decode.d3.loss_mask: 0.9496  decode.d3.loss_dice: 1.8751  decode.d4.loss_cls: 1.6955  decode.d4.loss_mask: 0.9347  decode.d4.loss_dice: 1.9162  decode.d5.loss_cls: 1.6674  decode.d5.loss_mask: 0.9328  decode.d5.loss_dice: 1.8806  decode.d6.loss_cls: 1.6477  decode.d6.loss_mask: 0.8940  decode.d6.loss_dice: 1.8831  decode.d7.loss_cls: 1.5552  decode.d7.loss_mask: 0.9012  decode.d7.loss_dice: 1.9001  decode.d8.loss_cls: 1.5683  decode.d8.loss_mask: 0.9130  decode.d8.loss_dice: 1.8669
2023/05/23 21:46:13 - mmengine - INFO - Iter(train) [ 28400/160000]  lr: 8.3873e-06  eta: 15:36:01  time: 0.4336  data_time: 0.0094  memory: 4893  grad_norm: 92.5118  loss: 45.0089  decode.loss_cls: 1.5949  decode.loss_mask: 0.8752  decode.loss_dice: 1.7052  decode.d0.loss_cls: 3.6215  decode.d0.loss_mask: 0.9079  decode.d0.loss_dice: 1.9234  decode.d1.loss_cls: 1.7852  decode.d1.loss_mask: 0.8882  decode.d1.loss_dice: 1.7882  decode.d2.loss_cls: 1.6893  decode.d2.loss_mask: 0.8928  decode.d2.loss_dice: 1.7713  decode.d3.loss_cls: 1.7193  decode.d3.loss_mask: 0.8752  decode.d3.loss_dice: 1.7215  decode.d4.loss_cls: 1.6445  decode.d4.loss_mask: 0.8976  decode.d4.loss_dice: 1.7295  decode.d5.loss_cls: 1.6084  decode.d5.loss_mask: 0.9048  decode.d5.loss_dice: 1.7438  decode.d6.loss_cls: 1.6778  decode.d6.loss_mask: 0.8688  decode.d6.loss_dice: 1.7021  decode.d7.loss_cls: 1.5942  decode.d7.loss_mask: 0.9066  decode.d7.loss_dice: 1.7598  decode.d8.loss_cls: 1.6215  decode.d8.loss_mask: 0.8837  decode.d8.loss_dice: 1.7064
2023/05/23 21:46:35 - mmengine - INFO - Iter(train) [ 28450/160000]  lr: 8.3845e-06  eta: 15:35:41  time: 0.4191  data_time: 0.0097  memory: 4904  grad_norm: 93.7095  loss: 33.8684  decode.loss_cls: 1.3270  decode.loss_mask: 0.7281  decode.loss_dice: 1.0907  decode.d0.loss_cls: 3.1780  decode.d0.loss_mask: 0.7314  decode.d0.loss_dice: 1.1730  decode.d1.loss_cls: 1.4493  decode.d1.loss_mask: 0.7801  decode.d1.loss_dice: 1.1466  decode.d2.loss_cls: 1.4367  decode.d2.loss_mask: 0.7465  decode.d2.loss_dice: 1.1488  decode.d3.loss_cls: 1.3514  decode.d3.loss_mask: 0.7433  decode.d3.loss_dice: 1.1000  decode.d4.loss_cls: 1.2995  decode.d4.loss_mask: 0.7439  decode.d4.loss_dice: 1.0960  decode.d5.loss_cls: 1.3041  decode.d5.loss_mask: 0.7415  decode.d5.loss_dice: 1.1225  decode.d6.loss_cls: 1.2944  decode.d6.loss_mask: 0.7415  decode.d6.loss_dice: 1.0866  decode.d7.loss_cls: 1.2767  decode.d7.loss_mask: 0.7768  decode.d7.loss_dice: 1.0905  decode.d8.loss_cls: 1.3191  decode.d8.loss_mask: 0.7657  decode.d8.loss_dice: 1.0785
2023/05/23 21:46:56 - mmengine - INFO - Iter(train) [ 28500/160000]  lr: 8.3816e-06  eta: 15:35:17  time: 0.4145  data_time: 0.0096  memory: 4845  grad_norm: 109.1602  loss: 40.1201  decode.loss_cls: 1.3393  decode.loss_mask: 0.9275  decode.loss_dice: 1.4393  decode.d0.loss_cls: 3.3292  decode.d0.loss_mask: 0.9990  decode.d0.loss_dice: 1.6677  decode.d1.loss_cls: 1.5533  decode.d1.loss_mask: 0.9130  decode.d1.loss_dice: 1.5981  decode.d2.loss_cls: 1.4298  decode.d2.loss_mask: 0.9549  decode.d2.loss_dice: 1.5400  decode.d3.loss_cls: 1.4596  decode.d3.loss_mask: 0.9104  decode.d3.loss_dice: 1.4591  decode.d4.loss_cls: 1.3842  decode.d4.loss_mask: 0.9291  decode.d4.loss_dice: 1.4832  decode.d5.loss_cls: 1.2930  decode.d5.loss_mask: 0.9356  decode.d5.loss_dice: 1.5296  decode.d6.loss_cls: 1.3137  decode.d6.loss_mask: 0.8865  decode.d6.loss_dice: 1.4442  decode.d7.loss_cls: 1.3455  decode.d7.loss_mask: 0.9017  decode.d7.loss_dice: 1.4518  decode.d8.loss_cls: 1.3227  decode.d8.loss_mask: 0.9182  decode.d8.loss_dice: 1.4613
2023/05/23 21:47:17 - mmengine - INFO - Iter(train) [ 28550/160000]  lr: 8.3787e-06  eta: 15:34:54  time: 0.4310  data_time: 0.0098  memory: 4877  grad_norm: 87.2370  loss: 44.8270  decode.loss_cls: 1.4615  decode.loss_mask: 0.9409  decode.loss_dice: 1.8379  decode.d0.loss_cls: 3.2516  decode.d0.loss_mask: 1.0443  decode.d0.loss_dice: 2.1050  decode.d1.loss_cls: 1.5449  decode.d1.loss_mask: 0.9495  decode.d1.loss_dice: 2.0274  decode.d2.loss_cls: 1.5200  decode.d2.loss_mask: 0.9289  decode.d2.loss_dice: 1.8717  decode.d3.loss_cls: 1.4938  decode.d3.loss_mask: 0.9129  decode.d3.loss_dice: 1.8221  decode.d4.loss_cls: 1.4594  decode.d4.loss_mask: 0.9278  decode.d4.loss_dice: 1.8624  decode.d5.loss_cls: 1.4256  decode.d5.loss_mask: 0.9493  decode.d5.loss_dice: 1.8296  decode.d6.loss_cls: 1.4890  decode.d6.loss_mask: 0.9366  decode.d6.loss_dice: 1.8319  decode.d7.loss_cls: 1.4508  decode.d7.loss_mask: 0.9314  decode.d7.loss_dice: 1.8234  decode.d8.loss_cls: 1.4470  decode.d8.loss_mask: 0.9419  decode.d8.loss_dice: 1.8086
2023/05/23 21:47:38 - mmengine - INFO - Iter(train) [ 28600/160000]  lr: 8.3759e-06  eta: 15:34:33  time: 0.4620  data_time: 0.0094  memory: 4858  grad_norm: 120.5924  loss: 45.5627  decode.loss_cls: 1.6294  decode.loss_mask: 1.0025  decode.loss_dice: 1.6223  decode.d0.loss_cls: 3.8183  decode.d0.loss_mask: 0.9952  decode.d0.loss_dice: 1.9084  decode.d1.loss_cls: 1.8142  decode.d1.loss_mask: 0.9577  decode.d1.loss_dice: 1.7658  decode.d2.loss_cls: 1.7405  decode.d2.loss_mask: 0.9897  decode.d2.loss_dice: 1.6773  decode.d3.loss_cls: 1.6954  decode.d3.loss_mask: 0.9621  decode.d3.loss_dice: 1.6767  decode.d4.loss_cls: 1.6193  decode.d4.loss_mask: 0.9861  decode.d4.loss_dice: 1.6565  decode.d5.loss_cls: 1.6658  decode.d5.loss_mask: 1.0352  decode.d5.loss_dice: 1.6395  decode.d6.loss_cls: 1.5855  decode.d6.loss_mask: 1.0187  decode.d6.loss_dice: 1.6357  decode.d7.loss_cls: 1.6083  decode.d7.loss_mask: 0.9966  decode.d7.loss_dice: 1.6085  decode.d8.loss_cls: 1.6547  decode.d8.loss_mask: 0.9824  decode.d8.loss_dice: 1.6143
2023/05/23 21:48:00 - mmengine - INFO - Iter(train) [ 28650/160000]  lr: 8.3730e-06  eta: 15:34:12  time: 0.4082  data_time: 0.0097  memory: 4839  grad_norm: 102.9027  loss: 34.2607  decode.loss_cls: 1.2260  decode.loss_mask: 0.7004  decode.loss_dice: 1.2335  decode.d0.loss_cls: 2.9308  decode.d0.loss_mask: 0.7645  decode.d0.loss_dice: 1.3847  decode.d1.loss_cls: 1.3255  decode.d1.loss_mask: 0.7802  decode.d1.loss_dice: 1.3514  decode.d2.loss_cls: 1.2158  decode.d2.loss_mask: 0.7861  decode.d2.loss_dice: 1.3341  decode.d3.loss_cls: 1.2542  decode.d3.loss_mask: 0.7199  decode.d3.loss_dice: 1.2746  decode.d4.loss_cls: 1.2592  decode.d4.loss_mask: 0.7036  decode.d4.loss_dice: 1.2644  decode.d5.loss_cls: 1.2348  decode.d5.loss_mask: 0.7060  decode.d5.loss_dice: 1.2507  decode.d6.loss_cls: 1.2193  decode.d6.loss_mask: 0.7042  decode.d6.loss_dice: 1.2690  decode.d7.loss_cls: 1.1829  decode.d7.loss_mask: 0.7176  decode.d7.loss_dice: 1.2648  decode.d8.loss_cls: 1.2432  decode.d8.loss_mask: 0.7107  decode.d8.loss_dice: 1.2487
2023/05/23 21:48:20 - mmengine - INFO - Iter(train) [ 28700/160000]  lr: 8.3701e-06  eta: 15:33:47  time: 0.4106  data_time: 0.0100  memory: 5010  grad_norm: 96.1193  loss: 37.3404  decode.loss_cls: 1.2776  decode.loss_mask: 0.6972  decode.loss_dice: 1.4632  decode.d0.loss_cls: 3.4634  decode.d0.loss_mask: 0.7579  decode.d0.loss_dice: 1.6541  decode.d1.loss_cls: 1.4069  decode.d1.loss_mask: 0.7361  decode.d1.loss_dice: 1.5977  decode.d2.loss_cls: 1.3834  decode.d2.loss_mask: 0.7034  decode.d2.loss_dice: 1.5124  decode.d3.loss_cls: 1.3290  decode.d3.loss_mask: 0.7122  decode.d3.loss_dice: 1.4633  decode.d4.loss_cls: 1.2928  decode.d4.loss_mask: 0.7185  decode.d4.loss_dice: 1.4712  decode.d5.loss_cls: 1.3159  decode.d5.loss_mask: 0.6845  decode.d5.loss_dice: 1.4242  decode.d6.loss_cls: 1.3347  decode.d6.loss_mask: 0.6871  decode.d6.loss_dice: 1.4212  decode.d7.loss_cls: 1.2881  decode.d7.loss_mask: 0.6818  decode.d7.loss_dice: 1.4592  decode.d8.loss_cls: 1.2808  decode.d8.loss_mask: 0.6737  decode.d8.loss_dice: 1.4490
2023/05/23 21:48:41 - mmengine - INFO - Iter(train) [ 28750/160000]  lr: 8.3673e-06  eta: 15:33:22  time: 0.4088  data_time: 0.0101  memory: 4909  grad_norm: 147.2932  loss: 47.3981  decode.loss_cls: 1.6454  decode.loss_mask: 1.0068  decode.loss_dice: 1.8352  decode.d0.loss_cls: 3.5512  decode.d0.loss_mask: 1.0921  decode.d0.loss_dice: 2.1757  decode.d1.loss_cls: 1.6241  decode.d1.loss_mask: 1.0524  decode.d1.loss_dice: 2.1272  decode.d2.loss_cls: 1.7131  decode.d2.loss_mask: 0.9972  decode.d2.loss_dice: 1.9553  decode.d3.loss_cls: 1.6397  decode.d3.loss_mask: 0.9832  decode.d3.loss_dice: 1.8867  decode.d4.loss_cls: 1.6066  decode.d4.loss_mask: 0.9728  decode.d4.loss_dice: 1.9011  decode.d5.loss_cls: 1.5339  decode.d5.loss_mask: 1.0003  decode.d5.loss_dice: 1.8954  decode.d6.loss_cls: 1.5744  decode.d6.loss_mask: 0.9945  decode.d6.loss_dice: 1.8295  decode.d7.loss_cls: 1.5529  decode.d7.loss_mask: 1.0102  decode.d7.loss_dice: 1.8455  decode.d8.loss_cls: 1.5717  decode.d8.loss_mask: 0.9911  decode.d8.loss_dice: 1.8329
2023/05/23 21:49:01 - mmengine - INFO - Iter(train) [ 28800/160000]  lr: 8.3644e-06  eta: 15:32:57  time: 0.4104  data_time: 0.0104  memory: 4837  grad_norm: 99.8153  loss: 34.3814  decode.loss_cls: 1.3080  decode.loss_mask: 0.7317  decode.loss_dice: 1.1382  decode.d0.loss_cls: 3.0351  decode.d0.loss_mask: 0.9168  decode.d0.loss_dice: 1.3972  decode.d1.loss_cls: 1.3931  decode.d1.loss_mask: 0.7918  decode.d1.loss_dice: 1.2961  decode.d2.loss_cls: 1.2457  decode.d2.loss_mask: 0.7902  decode.d2.loss_dice: 1.2219  decode.d3.loss_cls: 1.3299  decode.d3.loss_mask: 0.7703  decode.d3.loss_dice: 1.1950  decode.d4.loss_cls: 1.3237  decode.d4.loss_mask: 0.7573  decode.d4.loss_dice: 1.1912  decode.d5.loss_cls: 1.2988  decode.d5.loss_mask: 0.7650  decode.d5.loss_dice: 1.1588  decode.d6.loss_cls: 1.1970  decode.d6.loss_mask: 0.7355  decode.d6.loss_dice: 1.1513  decode.d7.loss_cls: 1.2080  decode.d7.loss_mask: 0.7435  decode.d7.loss_dice: 1.1661  decode.d8.loss_cls: 1.2280  decode.d8.loss_mask: 0.7293  decode.d8.loss_dice: 1.1669
2023/05/23 21:49:22 - mmengine - INFO - Iter(train) [ 28850/160000]  lr: 8.3615e-06  eta: 15:32:34  time: 0.3997  data_time: 0.0096  memory: 4836  grad_norm: 123.4025  loss: 41.4998  decode.loss_cls: 1.5924  decode.loss_mask: 0.8106  decode.loss_dice: 1.4563  decode.d0.loss_cls: 3.2868  decode.d0.loss_mask: 0.9389  decode.d0.loss_dice: 1.6526  decode.d1.loss_cls: 1.8132  decode.d1.loss_mask: 0.8323  decode.d1.loss_dice: 1.6245  decode.d2.loss_cls: 1.6967  decode.d2.loss_mask: 0.8319  decode.d2.loss_dice: 1.5109  decode.d3.loss_cls: 1.6429  decode.d3.loss_mask: 0.8442  decode.d3.loss_dice: 1.4980  decode.d4.loss_cls: 1.6578  decode.d4.loss_mask: 0.8419  decode.d4.loss_dice: 1.4758  decode.d5.loss_cls: 1.5663  decode.d5.loss_mask: 0.8287  decode.d5.loss_dice: 1.5080  decode.d6.loss_cls: 1.5744  decode.d6.loss_mask: 0.8426  decode.d6.loss_dice: 1.4738  decode.d7.loss_cls: 1.5857  decode.d7.loss_mask: 0.8259  decode.d7.loss_dice: 1.4377  decode.d8.loss_cls: 1.5347  decode.d8.loss_mask: 0.8345  decode.d8.loss_dice: 1.4797
2023/05/23 21:49:43 - mmengine - INFO - Iter(train) [ 28900/160000]  lr: 8.3587e-06  eta: 15:32:09  time: 0.4039  data_time: 0.0095  memory: 4847  grad_norm: 104.7791  loss: 33.3392  decode.loss_cls: 0.9888  decode.loss_mask: 0.7954  decode.loss_dice: 1.2903  decode.d0.loss_cls: 3.0034  decode.d0.loss_mask: 0.8820  decode.d0.loss_dice: 1.4559  decode.d1.loss_cls: 1.1582  decode.d1.loss_mask: 0.7939  decode.d1.loss_dice: 1.3621  decode.d2.loss_cls: 1.0860  decode.d2.loss_mask: 0.7871  decode.d2.loss_dice: 1.3436  decode.d3.loss_cls: 0.9749  decode.d3.loss_mask: 0.7932  decode.d3.loss_dice: 1.3102  decode.d4.loss_cls: 0.9809  decode.d4.loss_mask: 0.7694  decode.d4.loss_dice: 1.2805  decode.d5.loss_cls: 1.0453  decode.d5.loss_mask: 0.7694  decode.d5.loss_dice: 1.2534  decode.d6.loss_cls: 0.9870  decode.d6.loss_mask: 0.7908  decode.d6.loss_dice: 1.2903  decode.d7.loss_cls: 0.9715  decode.d7.loss_mask: 0.7977  decode.d7.loss_dice: 1.2826  decode.d8.loss_cls: 0.9957  decode.d8.loss_mask: 0.7955  decode.d8.loss_dice: 1.3041
2023/05/23 21:50:03 - mmengine - INFO - Iter(train) [ 28950/160000]  lr: 8.3558e-06  eta: 15:31:44  time: 0.4157  data_time: 0.0097  memory: 4844  grad_norm: 89.9181  loss: 37.2671  decode.loss_cls: 1.1626  decode.loss_mask: 0.7755  decode.loss_dice: 1.4720  decode.d0.loss_cls: 3.0855  decode.d0.loss_mask: 0.8387  decode.d0.loss_dice: 1.6409  decode.d1.loss_cls: 1.3099  decode.d1.loss_mask: 0.8795  decode.d1.loss_dice: 1.6286  decode.d2.loss_cls: 1.1770  decode.d2.loss_mask: 0.8834  decode.d2.loss_dice: 1.5818  decode.d3.loss_cls: 1.1805  decode.d3.loss_mask: 0.8127  decode.d3.loss_dice: 1.5187  decode.d4.loss_cls: 1.1416  decode.d4.loss_mask: 0.8373  decode.d4.loss_dice: 1.5736  decode.d5.loss_cls: 1.1165  decode.d5.loss_mask: 0.7964  decode.d5.loss_dice: 1.5377  decode.d6.loss_cls: 1.2043  decode.d6.loss_mask: 0.7777  decode.d6.loss_dice: 1.4867  decode.d7.loss_cls: 1.0749  decode.d7.loss_mask: 0.8002  decode.d7.loss_dice: 1.5578  decode.d8.loss_cls: 1.0896  decode.d8.loss_mask: 0.8022  decode.d8.loss_dice: 1.5234
2023/05/23 21:50:24 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 21:50:24 - mmengine - INFO - Iter(train) [ 29000/160000]  lr: 8.3529e-06  eta: 15:31:20  time: 0.4093  data_time: 0.0095  memory: 4942  grad_norm: 93.4517  loss: 40.0058  decode.loss_cls: 1.4094  decode.loss_mask: 0.9452  decode.loss_dice: 1.4246  decode.d0.loss_cls: 3.2947  decode.d0.loss_mask: 0.9391  decode.d0.loss_dice: 1.5648  decode.d1.loss_cls: 1.5795  decode.d1.loss_mask: 0.9033  decode.d1.loss_dice: 1.4590  decode.d2.loss_cls: 1.4173  decode.d2.loss_mask: 0.9212  decode.d2.loss_dice: 1.4487  decode.d3.loss_cls: 1.4301  decode.d3.loss_mask: 0.9321  decode.d3.loss_dice: 1.3953  decode.d4.loss_cls: 1.4694  decode.d4.loss_mask: 0.9279  decode.d4.loss_dice: 1.4331  decode.d5.loss_cls: 1.4854  decode.d5.loss_mask: 0.9318  decode.d5.loss_dice: 1.3970  decode.d6.loss_cls: 1.4522  decode.d6.loss_mask: 0.9358  decode.d6.loss_dice: 1.4000  decode.d7.loss_cls: 1.4715  decode.d7.loss_mask: 0.9225  decode.d7.loss_dice: 1.3889  decode.d8.loss_cls: 1.3695  decode.d8.loss_mask: 0.9561  decode.d8.loss_dice: 1.4003
2023/05/23 21:50:24 - mmengine - INFO - Saving checkpoint at 29000 iterations
2023/05/23 21:50:50 - mmengine - INFO - Iter(train) [ 29050/160000]  lr: 8.3501e-06  eta: 15:31:20  time: 0.4133  data_time: 0.0097  memory: 4882  grad_norm: 100.5267  loss: 44.1632  decode.loss_cls: 1.3687  decode.loss_mask: 1.0499  decode.loss_dice: 1.6982  decode.d0.loss_cls: 3.4455  decode.d0.loss_mask: 1.1863  decode.d0.loss_dice: 1.9815  decode.d1.loss_cls: 1.4468  decode.d1.loss_mask: 1.0701  decode.d1.loss_dice: 1.8217  decode.d2.loss_cls: 1.3631  decode.d2.loss_mask: 1.0790  decode.d2.loss_dice: 1.7565  decode.d3.loss_cls: 1.4356  decode.d3.loss_mask: 1.0442  decode.d3.loss_dice: 1.7138  decode.d4.loss_cls: 1.4332  decode.d4.loss_mask: 1.0331  decode.d4.loss_dice: 1.6453  decode.d5.loss_cls: 1.4124  decode.d5.loss_mask: 1.0826  decode.d5.loss_dice: 1.6720  decode.d6.loss_cls: 1.4539  decode.d6.loss_mask: 1.0671  decode.d6.loss_dice: 1.6470  decode.d7.loss_cls: 1.4256  decode.d7.loss_mask: 1.0506  decode.d7.loss_dice: 1.6346  decode.d8.loss_cls: 1.4074  decode.d8.loss_mask: 1.0401  decode.d8.loss_dice: 1.6972
2023/05/23 21:51:11 - mmengine - INFO - Iter(train) [ 29100/160000]  lr: 8.3472e-06  eta: 15:30:56  time: 0.4117  data_time: 0.0097  memory: 4910  grad_norm: 93.9150  loss: 42.7088  decode.loss_cls: 1.6453  decode.loss_mask: 0.7585  decode.loss_dice: 1.5610  decode.d0.loss_cls: 3.6059  decode.d0.loss_mask: 0.8380  decode.d0.loss_dice: 1.9251  decode.d1.loss_cls: 1.7653  decode.d1.loss_mask: 0.8263  decode.d1.loss_dice: 1.7646  decode.d2.loss_cls: 1.6995  decode.d2.loss_mask: 0.8321  decode.d2.loss_dice: 1.6472  decode.d3.loss_cls: 1.6014  decode.d3.loss_mask: 0.7858  decode.d3.loss_dice: 1.6158  decode.d4.loss_cls: 1.5421  decode.d4.loss_mask: 0.8261  decode.d4.loss_dice: 1.6001  decode.d5.loss_cls: 1.6114  decode.d5.loss_mask: 0.7667  decode.d5.loss_dice: 1.6350  decode.d6.loss_cls: 1.6556  decode.d6.loss_mask: 0.7695  decode.d6.loss_dice: 1.5498  decode.d7.loss_cls: 1.5655  decode.d7.loss_mask: 0.7811  decode.d7.loss_dice: 1.5962  decode.d8.loss_cls: 1.5979  decode.d8.loss_mask: 0.7593  decode.d8.loss_dice: 1.5807
2023/05/23 21:51:32 - mmengine - INFO - Iter(train) [ 29150/160000]  lr: 8.3443e-06  eta: 15:30:35  time: 0.4256  data_time: 0.0102  memory: 4885  grad_norm: 111.9242  loss: 38.4097  decode.loss_cls: 1.4626  decode.loss_mask: 0.7017  decode.loss_dice: 1.4161  decode.d0.loss_cls: 3.2020  decode.d0.loss_mask: 0.7407  decode.d0.loss_dice: 1.5427  decode.d1.loss_cls: 1.6115  decode.d1.loss_mask: 0.6756  decode.d1.loss_dice: 1.5546  decode.d2.loss_cls: 1.5246  decode.d2.loss_mask: 0.6870  decode.d2.loss_dice: 1.4861  decode.d3.loss_cls: 1.4532  decode.d3.loss_mask: 0.7006  decode.d3.loss_dice: 1.4221  decode.d4.loss_cls: 1.5456  decode.d4.loss_mask: 0.6835  decode.d4.loss_dice: 1.4465  decode.d5.loss_cls: 1.5611  decode.d5.loss_mask: 0.6744  decode.d5.loss_dice: 1.4493  decode.d6.loss_cls: 1.5108  decode.d6.loss_mask: 0.6705  decode.d6.loss_dice: 1.4105  decode.d7.loss_cls: 1.5534  decode.d7.loss_mask: 0.6679  decode.d7.loss_dice: 1.4281  decode.d8.loss_cls: 1.5025  decode.d8.loss_mask: 0.7031  decode.d8.loss_dice: 1.4213
2023/05/23 21:51:55 - mmengine - INFO - Iter(train) [ 29200/160000]  lr: 8.3414e-06  eta: 15:30:18  time: 0.4397  data_time: 0.0098  memory: 4815  grad_norm: 128.7612  loss: 39.1218  decode.loss_cls: 1.4785  decode.loss_mask: 0.7811  decode.loss_dice: 1.3486  decode.d0.loss_cls: 3.3157  decode.d0.loss_mask: 0.9659  decode.d0.loss_dice: 1.5857  decode.d1.loss_cls: 1.7725  decode.d1.loss_mask: 0.8366  decode.d1.loss_dice: 1.4639  decode.d2.loss_cls: 1.6105  decode.d2.loss_mask: 0.7993  decode.d2.loss_dice: 1.3986  decode.d3.loss_cls: 1.5100  decode.d3.loss_mask: 0.7881  decode.d3.loss_dice: 1.3677  decode.d4.loss_cls: 1.5557  decode.d4.loss_mask: 0.7708  decode.d4.loss_dice: 1.3593  decode.d5.loss_cls: 1.4905  decode.d5.loss_mask: 0.7686  decode.d5.loss_dice: 1.3533  decode.d6.loss_cls: 1.5072  decode.d6.loss_mask: 0.7559  decode.d6.loss_dice: 1.3177  decode.d7.loss_cls: 1.4945  decode.d7.loss_mask: 0.7784  decode.d7.loss_dice: 1.3209  decode.d8.loss_cls: 1.5224  decode.d8.loss_mask: 0.7739  decode.d8.loss_dice: 1.3301
2023/05/23 21:52:16 - mmengine - INFO - Iter(train) [ 29250/160000]  lr: 8.3386e-06  eta: 15:29:57  time: 0.4269  data_time: 0.0102  memory: 4804  grad_norm: 107.8986  loss: 36.6009  decode.loss_cls: 1.4282  decode.loss_mask: 0.6224  decode.loss_dice: 1.2635  decode.d0.loss_cls: 3.3627  decode.d0.loss_mask: 0.7720  decode.d0.loss_dice: 1.5869  decode.d1.loss_cls: 1.6769  decode.d1.loss_mask: 0.7494  decode.d1.loss_dice: 1.3725  decode.d2.loss_cls: 1.5595  decode.d2.loss_mask: 0.6827  decode.d2.loss_dice: 1.3502  decode.d3.loss_cls: 1.5322  decode.d3.loss_mask: 0.6490  decode.d3.loss_dice: 1.3079  decode.d4.loss_cls: 1.4431  decode.d4.loss_mask: 0.6554  decode.d4.loss_dice: 1.3066  decode.d5.loss_cls: 1.4545  decode.d5.loss_mask: 0.6444  decode.d5.loss_dice: 1.2657  decode.d6.loss_cls: 1.4755  decode.d6.loss_mask: 0.6072  decode.d6.loss_dice: 1.2297  decode.d7.loss_cls: 1.4181  decode.d7.loss_mask: 0.6199  decode.d7.loss_dice: 1.2292  decode.d8.loss_cls: 1.4600  decode.d8.loss_mask: 0.6268  decode.d8.loss_dice: 1.2487
2023/05/23 21:52:37 - mmengine - INFO - Iter(train) [ 29300/160000]  lr: 8.3357e-06  eta: 15:29:32  time: 0.4135  data_time: 0.0097  memory: 4891  grad_norm: 82.5762  loss: 32.7901  decode.loss_cls: 1.3226  decode.loss_mask: 0.6180  decode.loss_dice: 1.1132  decode.d0.loss_cls: 3.1166  decode.d0.loss_mask: 0.6517  decode.d0.loss_dice: 1.3052  decode.d1.loss_cls: 1.4027  decode.d1.loss_mask: 0.6633  decode.d1.loss_dice: 1.1974  decode.d2.loss_cls: 1.2870  decode.d2.loss_mask: 0.6356  decode.d2.loss_dice: 1.1388  decode.d3.loss_cls: 1.3075  decode.d3.loss_mask: 0.6181  decode.d3.loss_dice: 1.0958  decode.d4.loss_cls: 1.4019  decode.d4.loss_mask: 0.6115  decode.d4.loss_dice: 1.0861  decode.d5.loss_cls: 1.3815  decode.d5.loss_mask: 0.6155  decode.d5.loss_dice: 1.0737  decode.d6.loss_cls: 1.3757  decode.d6.loss_mask: 0.6246  decode.d6.loss_dice: 1.0738  decode.d7.loss_cls: 1.3179  decode.d7.loss_mask: 0.6250  decode.d7.loss_dice: 1.0616  decode.d8.loss_cls: 1.3368  decode.d8.loss_mask: 0.6283  decode.d8.loss_dice: 1.1027
2023/05/23 21:52:57 - mmengine - INFO - Iter(train) [ 29350/160000]  lr: 8.3328e-06  eta: 15:29:07  time: 0.4128  data_time: 0.0096  memory: 4845  grad_norm: 107.9639  loss: 41.5369  decode.loss_cls: 1.4942  decode.loss_mask: 0.8162  decode.loss_dice: 1.5832  decode.d0.loss_cls: 3.3996  decode.d0.loss_mask: 0.8636  decode.d0.loss_dice: 1.8161  decode.d1.loss_cls: 1.5613  decode.d1.loss_mask: 0.8950  decode.d1.loss_dice: 1.7183  decode.d2.loss_cls: 1.4480  decode.d2.loss_mask: 0.8725  decode.d2.loss_dice: 1.6538  decode.d3.loss_cls: 1.4540  decode.d3.loss_mask: 0.8394  decode.d3.loss_dice: 1.6179  decode.d4.loss_cls: 1.4319  decode.d4.loss_mask: 0.8387  decode.d4.loss_dice: 1.6233  decode.d5.loss_cls: 1.4332  decode.d5.loss_mask: 0.8352  decode.d5.loss_dice: 1.6369  decode.d6.loss_cls: 1.5154  decode.d6.loss_mask: 0.8200  decode.d6.loss_dice: 1.5729  decode.d7.loss_cls: 1.4658  decode.d7.loss_mask: 0.8343  decode.d7.loss_dice: 1.5595  decode.d8.loss_cls: 1.5063  decode.d8.loss_mask: 0.8464  decode.d8.loss_dice: 1.5839
2023/05/23 21:53:20 - mmengine - INFO - Iter(train) [ 29400/160000]  lr: 8.3300e-06  eta: 15:28:53  time: 0.4688  data_time: 0.0102  memory: 4845  grad_norm: 96.8532  loss: 36.8782  decode.loss_cls: 1.4028  decode.loss_mask: 0.7843  decode.loss_dice: 1.2243  decode.d0.loss_cls: 3.0566  decode.d0.loss_mask: 0.8700  decode.d0.loss_dice: 1.3838  decode.d1.loss_cls: 1.6587  decode.d1.loss_mask: 0.8035  decode.d1.loss_dice: 1.2747  decode.d2.loss_cls: 1.5964  decode.d2.loss_mask: 0.7982  decode.d2.loss_dice: 1.2345  decode.d3.loss_cls: 1.5092  decode.d3.loss_mask: 0.8270  decode.d3.loss_dice: 1.2131  decode.d4.loss_cls: 1.5294  decode.d4.loss_mask: 0.7946  decode.d4.loss_dice: 1.2105  decode.d5.loss_cls: 1.4891  decode.d5.loss_mask: 0.7829  decode.d5.loss_dice: 1.2146  decode.d6.loss_cls: 1.4242  decode.d6.loss_mask: 0.7921  decode.d6.loss_dice: 1.1965  decode.d7.loss_cls: 1.4284  decode.d7.loss_mask: 0.7832  decode.d7.loss_dice: 1.2074  decode.d8.loss_cls: 1.4001  decode.d8.loss_mask: 0.7893  decode.d8.loss_dice: 1.1987
2023/05/23 21:53:42 - mmengine - INFO - Iter(train) [ 29450/160000]  lr: 8.3271e-06  eta: 15:28:33  time: 0.4172  data_time: 0.0100  memory: 4845  grad_norm: 102.7951  loss: 31.5422  decode.loss_cls: 1.1138  decode.loss_mask: 0.6739  decode.loss_dice: 1.0359  decode.d0.loss_cls: 2.9161  decode.d0.loss_mask: 0.7812  decode.d0.loss_dice: 1.1887  decode.d1.loss_cls: 1.2272  decode.d1.loss_mask: 0.7200  decode.d1.loss_dice: 1.1878  decode.d2.loss_cls: 1.2817  decode.d2.loss_mask: 0.6896  decode.d2.loss_dice: 1.1384  decode.d3.loss_cls: 1.1804  decode.d3.loss_mask: 0.7293  decode.d3.loss_dice: 1.1333  decode.d4.loss_cls: 1.1837  decode.d4.loss_mask: 0.7094  decode.d4.loss_dice: 1.0968  decode.d5.loss_cls: 1.1388  decode.d5.loss_mask: 0.7076  decode.d5.loss_dice: 1.0924  decode.d6.loss_cls: 1.1392  decode.d6.loss_mask: 0.7178  decode.d6.loss_dice: 1.0451  decode.d7.loss_cls: 1.1436  decode.d7.loss_mask: 0.6637  decode.d7.loss_dice: 1.0416  decode.d8.loss_cls: 1.1327  decode.d8.loss_mask: 0.6706  decode.d8.loss_dice: 1.0619
2023/05/23 21:54:03 - mmengine - INFO - Iter(train) [ 29500/160000]  lr: 8.3242e-06  eta: 15:28:14  time: 0.4117  data_time: 0.0097  memory: 4907  grad_norm: 82.6666  loss: 40.8905  decode.loss_cls: 1.5185  decode.loss_mask: 0.8440  decode.loss_dice: 1.4097  decode.d0.loss_cls: 3.4113  decode.d0.loss_mask: 0.9484  decode.d0.loss_dice: 1.6537  decode.d1.loss_cls: 1.6719  decode.d1.loss_mask: 0.8539  decode.d1.loss_dice: 1.5765  decode.d2.loss_cls: 1.5626  decode.d2.loss_mask: 0.8647  decode.d2.loss_dice: 1.5528  decode.d3.loss_cls: 1.5675  decode.d3.loss_mask: 0.8380  decode.d3.loss_dice: 1.4270  decode.d4.loss_cls: 1.5427  decode.d4.loss_mask: 0.8703  decode.d4.loss_dice: 1.4413  decode.d5.loss_cls: 1.5609  decode.d5.loss_mask: 0.8591  decode.d5.loss_dice: 1.4485  decode.d6.loss_cls: 1.5914  decode.d6.loss_mask: 0.8411  decode.d6.loss_dice: 1.4250  decode.d7.loss_cls: 1.5562  decode.d7.loss_mask: 0.8542  decode.d7.loss_dice: 1.4222  decode.d8.loss_cls: 1.4973  decode.d8.loss_mask: 0.8482  decode.d8.loss_dice: 1.4315
2023/05/23 21:54:25 - mmengine - INFO - Iter(train) [ 29550/160000]  lr: 8.3214e-06  eta: 15:27:52  time: 0.4099  data_time: 0.0099  memory: 4915  grad_norm: 107.0680  loss: 41.9668  decode.loss_cls: 1.5951  decode.loss_mask: 0.8235  decode.loss_dice: 1.5281  decode.d0.loss_cls: 3.4221  decode.d0.loss_mask: 0.8802  decode.d0.loss_dice: 1.7716  decode.d1.loss_cls: 1.5138  decode.d1.loss_mask: 0.9550  decode.d1.loss_dice: 1.6813  decode.d2.loss_cls: 1.5099  decode.d2.loss_mask: 0.9076  decode.d2.loss_dice: 1.6019  decode.d3.loss_cls: 1.4881  decode.d3.loss_mask: 0.8965  decode.d3.loss_dice: 1.5575  decode.d4.loss_cls: 1.5012  decode.d4.loss_mask: 0.8924  decode.d4.loss_dice: 1.5833  decode.d5.loss_cls: 1.5225  decode.d5.loss_mask: 0.8757  decode.d5.loss_dice: 1.5463  decode.d6.loss_cls: 1.6192  decode.d6.loss_mask: 0.8379  decode.d6.loss_dice: 1.5389  decode.d7.loss_cls: 1.5721  decode.d7.loss_mask: 0.8386  decode.d7.loss_dice: 1.5363  decode.d8.loss_cls: 1.5909  decode.d8.loss_mask: 0.8416  decode.d8.loss_dice: 1.5378
2023/05/23 21:54:47 - mmengine - INFO - Iter(train) [ 29600/160000]  lr: 8.3185e-06  eta: 15:27:36  time: 0.4279  data_time: 0.0096  memory: 4835  grad_norm: 94.1009  loss: 44.0023  decode.loss_cls: 1.5760  decode.loss_mask: 0.9515  decode.loss_dice: 1.5408  decode.d0.loss_cls: 3.5835  decode.d0.loss_mask: 1.0444  decode.d0.loss_dice: 1.6868  decode.d1.loss_cls: 1.7263  decode.d1.loss_mask: 1.1019  decode.d1.loss_dice: 1.7003  decode.d2.loss_cls: 1.6876  decode.d2.loss_mask: 1.0935  decode.d2.loss_dice: 1.6443  decode.d3.loss_cls: 1.5937  decode.d3.loss_mask: 1.0042  decode.d3.loss_dice: 1.5550  decode.d4.loss_cls: 1.6040  decode.d4.loss_mask: 0.9762  decode.d4.loss_dice: 1.6008  decode.d5.loss_cls: 1.6567  decode.d5.loss_mask: 0.9663  decode.d5.loss_dice: 1.5196  decode.d6.loss_cls: 1.6138  decode.d6.loss_mask: 0.9627  decode.d6.loss_dice: 1.5034  decode.d7.loss_cls: 1.6188  decode.d7.loss_mask: 0.9509  decode.d7.loss_dice: 1.5072  decode.d8.loss_cls: 1.5483  decode.d8.loss_mask: 0.9613  decode.d8.loss_dice: 1.5225
2023/05/23 21:55:08 - mmengine - INFO - Iter(train) [ 29650/160000]  lr: 8.3156e-06  eta: 15:27:11  time: 0.4086  data_time: 0.0094  memory: 4845  grad_norm: 112.7754  loss: 40.8089  decode.loss_cls: 1.3146  decode.loss_mask: 1.0106  decode.loss_dice: 1.4292  decode.d0.loss_cls: 3.6750  decode.d0.loss_mask: 0.9944  decode.d0.loss_dice: 1.6823  decode.d1.loss_cls: 1.5531  decode.d1.loss_mask: 0.9936  decode.d1.loss_dice: 1.5415  decode.d2.loss_cls: 1.4831  decode.d2.loss_mask: 0.9881  decode.d2.loss_dice: 1.4905  decode.d3.loss_cls: 1.3485  decode.d3.loss_mask: 1.0134  decode.d3.loss_dice: 1.4740  decode.d4.loss_cls: 1.3415  decode.d4.loss_mask: 1.0102  decode.d4.loss_dice: 1.4486  decode.d5.loss_cls: 1.3382  decode.d5.loss_mask: 0.9568  decode.d5.loss_dice: 1.4507  decode.d6.loss_cls: 1.3375  decode.d6.loss_mask: 0.9977  decode.d6.loss_dice: 1.4448  decode.d7.loss_cls: 1.2981  decode.d7.loss_mask: 1.0114  decode.d7.loss_dice: 1.4190  decode.d8.loss_cls: 1.3206  decode.d8.loss_mask: 0.9923  decode.d8.loss_dice: 1.4495
2023/05/23 21:55:28 - mmengine - INFO - Iter(train) [ 29700/160000]  lr: 8.3127e-06  eta: 15:26:47  time: 0.4170  data_time: 0.0097  memory: 4906  grad_norm: 92.0074  loss: 44.2156  decode.loss_cls: 1.5125  decode.loss_mask: 0.8156  decode.loss_dice: 1.7036  decode.d0.loss_cls: 3.5304  decode.d0.loss_mask: 0.9588  decode.d0.loss_dice: 2.0446  decode.d1.loss_cls: 1.8298  decode.d1.loss_mask: 0.9060  decode.d1.loss_dice: 1.8916  decode.d2.loss_cls: 1.6492  decode.d2.loss_mask: 0.8881  decode.d2.loss_dice: 1.8191  decode.d3.loss_cls: 1.6230  decode.d3.loss_mask: 0.8393  decode.d3.loss_dice: 1.6898  decode.d4.loss_cls: 1.6182  decode.d4.loss_mask: 0.8194  decode.d4.loss_dice: 1.6877  decode.d5.loss_cls: 1.6107  decode.d5.loss_mask: 0.8326  decode.d5.loss_dice: 1.7358  decode.d6.loss_cls: 1.5227  decode.d6.loss_mask: 0.8335  decode.d6.loss_dice: 1.6948  decode.d7.loss_cls: 1.5114  decode.d7.loss_mask: 0.8263  decode.d7.loss_dice: 1.7487  decode.d8.loss_cls: 1.5423  decode.d8.loss_mask: 0.8200  decode.d8.loss_dice: 1.7098
2023/05/23 21:55:50 - mmengine - INFO - Iter(train) [ 29750/160000]  lr: 8.3099e-06  eta: 15:26:29  time: 0.4750  data_time: 0.0109  memory: 4886  grad_norm: 169.0783  loss: 47.9997  decode.loss_cls: 1.6558  decode.loss_mask: 1.0550  decode.loss_dice: 1.7947  decode.d0.loss_cls: 3.7434  decode.d0.loss_mask: 1.1609  decode.d0.loss_dice: 2.0281  decode.d1.loss_cls: 1.8012  decode.d1.loss_mask: 1.1493  decode.d1.loss_dice: 1.9107  decode.d2.loss_cls: 1.7385  decode.d2.loss_mask: 1.0854  decode.d2.loss_dice: 1.8458  decode.d3.loss_cls: 1.7147  decode.d3.loss_mask: 1.0427  decode.d3.loss_dice: 1.8084  decode.d4.loss_cls: 1.6558  decode.d4.loss_mask: 1.0351  decode.d4.loss_dice: 1.8023  decode.d5.loss_cls: 1.6748  decode.d5.loss_mask: 1.0333  decode.d5.loss_dice: 1.7632  decode.d6.loss_cls: 1.6920  decode.d6.loss_mask: 1.0820  decode.d6.loss_dice: 1.7864  decode.d7.loss_cls: 1.6297  decode.d7.loss_mask: 1.0621  decode.d7.loss_dice: 1.8061  decode.d8.loss_cls: 1.6260  decode.d8.loss_mask: 1.0452  decode.d8.loss_dice: 1.7711
2023/05/23 21:56:13 - mmengine - INFO - Iter(train) [ 29800/160000]  lr: 8.3070e-06  eta: 15:26:11  time: 0.4148  data_time: 0.0095  memory: 4867  grad_norm: 100.7216  loss: 42.2284  decode.loss_cls: 1.5236  decode.loss_mask: 0.8631  decode.loss_dice: 1.5141  decode.d0.loss_cls: 3.5943  decode.d0.loss_mask: 0.9422  decode.d0.loss_dice: 1.7521  decode.d1.loss_cls: 1.6536  decode.d1.loss_mask: 0.9052  decode.d1.loss_dice: 1.6573  decode.d2.loss_cls: 1.5250  decode.d2.loss_mask: 0.9102  decode.d2.loss_dice: 1.6289  decode.d3.loss_cls: 1.5460  decode.d3.loss_mask: 0.8874  decode.d3.loss_dice: 1.5827  decode.d4.loss_cls: 1.5204  decode.d4.loss_mask: 0.8983  decode.d4.loss_dice: 1.5866  decode.d5.loss_cls: 1.5423  decode.d5.loss_mask: 0.8662  decode.d5.loss_dice: 1.5535  decode.d6.loss_cls: 1.5155  decode.d6.loss_mask: 0.8788  decode.d6.loss_dice: 1.5174  decode.d7.loss_cls: 1.5558  decode.d7.loss_mask: 0.8653  decode.d7.loss_dice: 1.5464  decode.d8.loss_cls: 1.5378  decode.d8.loss_mask: 0.8578  decode.d8.loss_dice: 1.5007
2023/05/23 21:56:34 - mmengine - INFO - Iter(train) [ 29850/160000]  lr: 8.3041e-06  eta: 15:25:50  time: 0.4203  data_time: 0.0096  memory: 4786  grad_norm: 98.7174  loss: 34.1134  decode.loss_cls: 1.2611  decode.loss_mask: 0.6501  decode.loss_dice: 1.2706  decode.d0.loss_cls: 3.0170  decode.d0.loss_mask: 0.7357  decode.d0.loss_dice: 1.4601  decode.d1.loss_cls: 1.3836  decode.d1.loss_mask: 0.6724  decode.d1.loss_dice: 1.3934  decode.d2.loss_cls: 1.2898  decode.d2.loss_mask: 0.6496  decode.d2.loss_dice: 1.2794  decode.d3.loss_cls: 1.1999  decode.d3.loss_mask: 0.6425  decode.d3.loss_dice: 1.3155  decode.d4.loss_cls: 1.2595  decode.d4.loss_mask: 0.6417  decode.d4.loss_dice: 1.2673  decode.d5.loss_cls: 1.1917  decode.d5.loss_mask: 0.6763  decode.d5.loss_dice: 1.2843  decode.d6.loss_cls: 1.2860  decode.d6.loss_mask: 0.6562  decode.d6.loss_dice: 1.2599  decode.d7.loss_cls: 1.2373  decode.d7.loss_mask: 0.6705  decode.d7.loss_dice: 1.2744  decode.d8.loss_cls: 1.2970  decode.d8.loss_mask: 0.6431  decode.d8.loss_dice: 1.2473
2023/05/23 21:56:55 - mmengine - INFO - Iter(train) [ 29900/160000]  lr: 8.3013e-06  eta: 15:25:26  time: 0.4209  data_time: 0.0103  memory: 4857  grad_norm: 103.1359  loss: 35.0027  decode.loss_cls: 1.1508  decode.loss_mask: 0.8372  decode.loss_dice: 1.2368  decode.d0.loss_cls: 3.1074  decode.d0.loss_mask: 0.8456  decode.d0.loss_dice: 1.3985  decode.d1.loss_cls: 1.2638  decode.d1.loss_mask: 0.8527  decode.d1.loss_dice: 1.3005  decode.d2.loss_cls: 1.3051  decode.d2.loss_mask: 0.8354  decode.d2.loss_dice: 1.2492  decode.d3.loss_cls: 1.1487  decode.d3.loss_mask: 0.8814  decode.d3.loss_dice: 1.2296  decode.d4.loss_cls: 1.1613  decode.d4.loss_mask: 0.8733  decode.d4.loss_dice: 1.2408  decode.d5.loss_cls: 1.2173  decode.d5.loss_mask: 0.8782  decode.d5.loss_dice: 1.2286  decode.d6.loss_cls: 1.1399  decode.d6.loss_mask: 0.8827  decode.d6.loss_dice: 1.2325  decode.d7.loss_cls: 1.1354  decode.d7.loss_mask: 0.8728  decode.d7.loss_dice: 1.2288  decode.d8.loss_cls: 1.2225  decode.d8.loss_mask: 0.8384  decode.d8.loss_dice: 1.2075
2023/05/23 21:57:16 - mmengine - INFO - Iter(train) [ 29950/160000]  lr: 8.2984e-06  eta: 15:25:02  time: 0.4114  data_time: 0.0095  memory: 4845  grad_norm: 91.3639  loss: 31.4184  decode.loss_cls: 1.0747  decode.loss_mask: 0.7132  decode.loss_dice: 1.0791  decode.d0.loss_cls: 2.9032  decode.d0.loss_mask: 0.7542  decode.d0.loss_dice: 1.2356  decode.d1.loss_cls: 1.2673  decode.d1.loss_mask: 0.7132  decode.d1.loss_dice: 1.1565  decode.d2.loss_cls: 1.1340  decode.d2.loss_mask: 0.7413  decode.d2.loss_dice: 1.1121  decode.d3.loss_cls: 1.0804  decode.d3.loss_mask: 0.7216  decode.d3.loss_dice: 1.0963  decode.d4.loss_cls: 1.0299  decode.d4.loss_mask: 0.7833  decode.d4.loss_dice: 1.1126  decode.d5.loss_cls: 1.0792  decode.d5.loss_mask: 0.7587  decode.d5.loss_dice: 1.1011  decode.d6.loss_cls: 1.1517  decode.d6.loss_mask: 0.7138  decode.d6.loss_dice: 1.0793  decode.d7.loss_cls: 1.1168  decode.d7.loss_mask: 0.7307  decode.d7.loss_dice: 1.0995  decode.d8.loss_cls: 1.0737  decode.d8.loss_mask: 0.7142  decode.d8.loss_dice: 1.0910
2023/05/23 21:57:36 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 21:57:36 - mmengine - INFO - Iter(train) [ 30000/160000]  lr: 8.2955e-06  eta: 15:24:38  time: 0.4092  data_time: 0.0097  memory: 4890  grad_norm: 115.5135  loss: 37.7888  decode.loss_cls: 1.5682  decode.loss_mask: 0.6927  decode.loss_dice: 1.2822  decode.d0.loss_cls: 3.3596  decode.d0.loss_mask: 0.7449  decode.d0.loss_dice: 1.4588  decode.d1.loss_cls: 1.6555  decode.d1.loss_mask: 0.7412  decode.d1.loss_dice: 1.3427  decode.d2.loss_cls: 1.6020  decode.d2.loss_mask: 0.7528  decode.d2.loss_dice: 1.3220  decode.d3.loss_cls: 1.5389  decode.d3.loss_mask: 0.7544  decode.d3.loss_dice: 1.2929  decode.d4.loss_cls: 1.5045  decode.d4.loss_mask: 0.7446  decode.d4.loss_dice: 1.3013  decode.d5.loss_cls: 1.5528  decode.d5.loss_mask: 0.7102  decode.d5.loss_dice: 1.2960  decode.d6.loss_cls: 1.5638  decode.d6.loss_mask: 0.7113  decode.d6.loss_dice: 1.2807  decode.d7.loss_cls: 1.5231  decode.d7.loss_mask: 0.7055  decode.d7.loss_dice: 1.2830  decode.d8.loss_cls: 1.5324  decode.d8.loss_mask: 0.7016  decode.d8.loss_dice: 1.2692
2023/05/23 21:57:36 - mmengine - INFO - Saving checkpoint at 30000 iterations
2023/05/23 21:57:46 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0795  data_time: 0.0019  memory: 2167  
2023/05/23 21:57:50 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:42  time: 0.0892  data_time: 0.0019  memory: 2216  
2023/05/23 21:57:54 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:39  time: 0.0839  data_time: 0.0021  memory: 2167  
2023/05/23 21:57:58 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0792  data_time: 0.0018  memory: 2104  
2023/05/23 21:58:02 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0815  data_time: 0.0019  memory: 2831  
2023/05/23 21:58:08 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:28  time: 0.2890  data_time: 0.0021  memory: 2167  
2023/05/23 21:58:13 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0885  data_time: 0.0018  memory: 2167  
2023/05/23 21:58:17 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0822  data_time: 0.0021  memory: 2167  
2023/05/23 21:58:21 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0801  data_time: 0.0018  memory: 2944  
2023/05/23 21:58:25 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0880  data_time: 0.0019  memory: 2356  
2023/05/23 21:58:29 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0910  data_time: 0.0018  memory: 2217  
2023/05/23 21:58:33 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0769  data_time: 0.0017  memory: 2328  
2023/05/23 21:58:37 - mmengine - INFO - per class results:
2023/05/23 21:58:37 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      |  84.8 |  90.8 |
|     bicycle      | 66.07 | 80.62 |
|       car        |  56.6 | 76.25 |
|    motorcycle    | 81.19 | 89.19 |
|     airplane     | 84.21 |  89.5 |
|       bus        | 79.94 | 86.28 |
|      train       | 79.52 | 87.56 |
|      truck       | 50.26 | 68.75 |
|       boat       | 53.09 | 74.86 |
|  traffic light   | 63.96 | 83.53 |
|   fire hydrant   |  84.2 | 95.17 |
|    stop sign     | 87.71 |  92.2 |
|  parking meter   | 76.52 | 85.55 |
|      bench       |  45.7 | 68.79 |
|       bird       |  81.4 |  88.4 |
|       cat        | 84.81 | 92.15 |
|       dog        | 78.12 | 86.79 |
|      horse       | 78.15 | 89.32 |
|      sheep       |  85.6 | 91.86 |
|       cow        | 79.94 | 88.64 |
|     elephant     | 88.46 | 91.85 |
|       bear       | 91.54 |  93.8 |
|      zebra       | 89.59 | 92.21 |
|     giraffe      | 86.07 | 91.79 |
|     backpack     | 26.04 | 52.92 |
|     umbrella     | 75.49 | 83.74 |
|     handbag      | 28.34 | 54.39 |
|       tie        | 10.86 | 18.06 |
|     suitcase     | 67.13 | 93.79 |
|     frisbee      | 64.44 | 86.13 |
|       skis       | 34.66 | 53.81 |
|    snowboard     | 36.78 | 56.05 |
|   sports ball    | 52.28 | 69.01 |
|       kite       | 46.37 | 54.09 |
|   baseball bat   |  37.6 | 49.75 |
|  baseball glove  | 63.67 |  81.6 |
|    skateboard    | 51.17 | 68.06 |
|    surfboard     | 76.29 | 86.59 |
|  tennis racket   | 74.46 | 88.45 |
|      bottle      | 48.78 | 66.15 |
|    wine glass    | 52.32 | 77.28 |
|       cup        | 50.43 | 69.54 |
|       fork       |  34.6 | 54.12 |
|      knife       | 28.02 | 48.86 |
|      spoon       |  24.0 | 35.18 |
|       bowl       | 45.18 | 71.11 |
|      banana      | 63.58 | 86.87 |
|      apple       |  40.5 | 60.99 |
|     sandwich     | 43.78 | 60.11 |
|      orange      | 72.67 | 81.37 |
|     broccoli     | 54.32 | 68.75 |
|      carrot      |  52.5 | 61.56 |
|     hot dog      | 53.08 | 63.77 |
|      pizza       | 69.11 |  86.7 |
|      donut       | 62.98 | 85.93 |
|       cake       | 52.77 | 62.06 |
|      chair       | 38.41 | 54.87 |
|      couch       | 48.29 | 80.76 |
|   potted plant   | 27.52 | 44.64 |
|       bed        | 58.01 | 75.54 |
|   dining table   | 40.89 | 74.31 |
|      toilet      |  77.0 | 85.87 |
|        tv        | 68.27 | 80.33 |
|      laptop      |  66.3 | 80.23 |
|      mouse       | 69.64 | 81.73 |
|      remote      | 49.02 | 70.84 |
|     keyboard     | 58.98 | 75.23 |
|    cell phone    | 69.99 | 87.32 |
|    microwave     | 63.05 | 74.53 |
|       oven       | 51.57 |  65.4 |
|     toaster      | 29.14 | 35.86 |
|       sink       | 58.36 | 76.29 |
|   refrigerator   | 74.41 | 87.67 |
|       book       | 42.27 | 63.48 |
|      clock       | 70.92 | 77.19 |
|       vase       | 57.22 | 80.84 |
|     scissors     | 55.35 | 62.83 |
|    teddy bear    | 72.65 | 84.81 |
|    hair drier    | 26.19 | 26.74 |
|    toothbrush    |  11.2 | 73.88 |
|      banner      | 25.53 | 38.73 |
|     blanket      |  1.56 |  1.73 |
|      branch      | 21.24 | 44.63 |
|      bridge      | 30.66 | 46.57 |
|  building-other  | 50.89 | 69.45 |
|       bush       | 25.83 | 32.23 |
|     cabinet      |  52.0 | 67.09 |
|       cage       |  9.52 | 12.08 |
|    cardboard     | 37.06 | 43.46 |
|      carpet      | 49.95 | 74.53 |
|  ceiling-other   | 61.16 | 77.94 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 16.29 | 21.02 |
|      clouds      | 46.83 | 63.22 |
|     counter      | 26.13 | 43.43 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 57.24 | 66.57 |
|    desk-stuff    | 46.74 | 66.22 |
|       dirt       |  38.1 | 58.39 |
|    door-stuff    | 32.64 | 58.99 |
|      fence       | 33.26 | 66.85 |
|   floor-marble   |  1.4  |  1.6  |
|   floor-other    | 16.15 | 21.75 |
|   floor-stone    | 15.04 | 20.83 |
|    floor-tile    | 55.37 | 66.54 |
|    floor-wood    | 57.32 | 75.77 |
|      flower      | 45.02 | 71.94 |
|       fog        |  2.18 |  2.23 |
|    food-other    | 27.41 | 35.28 |
|      fruit       | 32.99 | 50.32 |
| furniture-other  | 15.37 | 24.45 |
|      grass       | 68.63 | 83.78 |
|      gravel      | 20.19 | 23.56 |
|   ground-other   |  0.04 |  0.05 |
|       hill       | 20.72 | 34.86 |
|      house       | 18.97 | 20.38 |
|      leaves      | 28.01 |  38.7 |
|      light       | 33.86 | 50.33 |
|       mat        |  0.0  |  0.0  |
|      metal       |  29.9 | 44.02 |
|   mirror-stuff   | 34.63 | 59.95 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 42.81 | 53.01 |
|       mud        |  0.0  |  0.0  |
|      napkin      | 21.71 | 26.44 |
|       net        | 45.11 | 60.91 |
|      paper       | 24.93 | 32.32 |
|     pavement     | 51.76 | 72.62 |
|      pillow      |  6.58 |  8.36 |
|   plant-other    | 19.96 | 36.89 |
|     plastic      | 16.52 | 23.01 |
|     platform     | 21.62 | 38.54 |
|   playingfield   |  67.4 | 89.48 |
|     railing      |  4.58 |  7.85 |
|     railroad     | 58.33 | 82.52 |
|      river       | 27.36 |  30.8 |
|       road       | 63.28 | 73.78 |
|       rock       | 32.48 | 47.66 |
|       roof       | 15.74 | 21.74 |
|       rug        | 33.91 | 47.76 |
|      salad       |  0.0  |  0.0  |
|       sand       | 59.37 | 70.65 |
|       sea        |  83.7 | 87.57 |
|      shelf       | 32.66 | 43.82 |
|    sky-other     |  69.8 | 86.19 |
|    skyscraper    | 24.05 | 28.01 |
|       snow       | 88.12 | 92.69 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 15.81 | 26.01 |
|      stone       |  8.18 | 16.26 |
|      straw       | 24.24 | 30.49 |
| structural-other |  0.03 |  0.03 |
|      table       | 16.08 | 21.32 |
|       tent       |  6.28 |  8.08 |
|  textile-other   |  7.77 | 12.19 |
|      towel       | 26.51 | 41.25 |
|       tree       | 72.63 | 85.11 |
|    vegetable     | 32.63 |  40.0 |
|    wall-brick    | 46.12 | 63.37 |
|  wall-concrete   | 57.51 | 75.34 |
|    wall-other    | 15.73 |  30.9 |
|    wall-panel    | 14.97 | 20.13 |
|    wall-stone    | 28.75 | 37.49 |
|    wall-tile     | 62.49 | 79.33 |
|    wall-wood     | 37.75 | 53.01 |
|   water-other    | 29.74 | 74.98 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   |  44.3 | 54.04 |
|   window-other   | 39.78 | 74.23 |
|       wood       | 23.88 | 33.93 |
+------------------+-------+-------+
2023/05/23 21:58:37 - mmengine - INFO - Iter(val) [625/625]    aAcc: 68.8600  mIoU: 43.4200  mAcc: 56.3400  data_time: 0.0019  time: 0.0857
2023/05/23 21:58:37 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_20000.pth is removed
2023/05/23 21:58:40 - mmengine - INFO - The best checkpoint with 43.4200 mIoU at 30000 iter is saved to best_mIoU_iter_30000.pth.
2023/05/23 21:59:02 - mmengine - INFO - Iter(train) [ 30050/160000]  lr: 8.2926e-06  eta: 15:24:40  time: 0.4113  data_time: 0.0098  memory: 4802  grad_norm: 110.3404  loss: 32.3425  decode.loss_cls: 1.1491  decode.loss_mask: 0.8110  decode.loss_dice: 1.0917  decode.d0.loss_cls: 2.9332  decode.d0.loss_mask: 0.7200  decode.d0.loss_dice: 1.1808  decode.d1.loss_cls: 1.2097  decode.d1.loss_mask: 0.7521  decode.d1.loss_dice: 1.1465  decode.d2.loss_cls: 1.2263  decode.d2.loss_mask: 0.7553  decode.d2.loss_dice: 1.1253  decode.d3.loss_cls: 1.1944  decode.d3.loss_mask: 0.7527  decode.d3.loss_dice: 1.0982  decode.d4.loss_cls: 1.2810  decode.d4.loss_mask: 0.6992  decode.d4.loss_dice: 1.1171  decode.d5.loss_cls: 1.2086  decode.d5.loss_mask: 0.7216  decode.d5.loss_dice: 1.1060  decode.d6.loss_cls: 1.1980  decode.d6.loss_mask: 0.7129  decode.d6.loss_dice: 1.0966  decode.d7.loss_cls: 1.1375  decode.d7.loss_mask: 0.8003  decode.d7.loss_dice: 1.1088  decode.d8.loss_cls: 1.1342  decode.d8.loss_mask: 0.7960  decode.d8.loss_dice: 1.0787
2023/05/23 21:59:24 - mmengine - INFO - Iter(train) [ 30100/160000]  lr: 8.2898e-06  eta: 15:24:19  time: 0.4331  data_time: 0.0098  memory: 4836  grad_norm: 103.0893  loss: 40.4178  decode.loss_cls: 1.3268  decode.loss_mask: 0.8994  decode.loss_dice: 1.5679  decode.d0.loss_cls: 3.1697  decode.d0.loss_mask: 0.9364  decode.d0.loss_dice: 1.8100  decode.d1.loss_cls: 1.4104  decode.d1.loss_mask: 0.9397  decode.d1.loss_dice: 1.6801  decode.d2.loss_cls: 1.3943  decode.d2.loss_mask: 0.8914  decode.d2.loss_dice: 1.6418  decode.d3.loss_cls: 1.3722  decode.d3.loss_mask: 0.8794  decode.d3.loss_dice: 1.5401  decode.d4.loss_cls: 1.3423  decode.d4.loss_mask: 0.8908  decode.d4.loss_dice: 1.5342  decode.d5.loss_cls: 1.3621  decode.d5.loss_mask: 0.8832  decode.d5.loss_dice: 1.5701  decode.d6.loss_cls: 1.4098  decode.d6.loss_mask: 0.8717  decode.d6.loss_dice: 1.4944  decode.d7.loss_cls: 1.3627  decode.d7.loss_mask: 0.8972  decode.d7.loss_dice: 1.5462  decode.d8.loss_cls: 1.3252  decode.d8.loss_mask: 0.9134  decode.d8.loss_dice: 1.5547
2023/05/23 21:59:45 - mmengine - INFO - Iter(train) [ 30150/160000]  lr: 8.2869e-06  eta: 15:23:56  time: 0.4213  data_time: 0.0098  memory: 4815  grad_norm: 107.8207  loss: 34.8410  decode.loss_cls: 1.2288  decode.loss_mask: 0.7692  decode.loss_dice: 1.2212  decode.d0.loss_cls: 3.0554  decode.d0.loss_mask: 0.8025  decode.d0.loss_dice: 1.4048  decode.d1.loss_cls: 1.2825  decode.d1.loss_mask: 0.7882  decode.d1.loss_dice: 1.3197  decode.d2.loss_cls: 1.2715  decode.d2.loss_mask: 0.7580  decode.d2.loss_dice: 1.3016  decode.d3.loss_cls: 1.2978  decode.d3.loss_mask: 0.7510  decode.d3.loss_dice: 1.2649  decode.d4.loss_cls: 1.2604  decode.d4.loss_mask: 0.7720  decode.d4.loss_dice: 1.2784  decode.d5.loss_cls: 1.2361  decode.d5.loss_mask: 0.7546  decode.d5.loss_dice: 1.2661  decode.d6.loss_cls: 1.2559  decode.d6.loss_mask: 0.7654  decode.d6.loss_dice: 1.2398  decode.d7.loss_cls: 1.2390  decode.d7.loss_mask: 0.7460  decode.d7.loss_dice: 1.2373  decode.d8.loss_cls: 1.2397  decode.d8.loss_mask: 0.7792  decode.d8.loss_dice: 1.2542
2023/05/23 22:00:06 - mmengine - INFO - Iter(train) [ 30200/160000]  lr: 8.2840e-06  eta: 15:23:36  time: 0.4084  data_time: 0.0097  memory: 4839  grad_norm: 97.0818  loss: 42.5021  decode.loss_cls: 1.4007  decode.loss_mask: 0.9387  decode.loss_dice: 1.5528  decode.d0.loss_cls: 3.5719  decode.d0.loss_mask: 1.0280  decode.d0.loss_dice: 1.8942  decode.d1.loss_cls: 1.5448  decode.d1.loss_mask: 1.0078  decode.d1.loss_dice: 1.7737  decode.d2.loss_cls: 1.5264  decode.d2.loss_mask: 0.9685  decode.d2.loss_dice: 1.6426  decode.d3.loss_cls: 1.4492  decode.d3.loss_mask: 0.9648  decode.d3.loss_dice: 1.5799  decode.d4.loss_cls: 1.5298  decode.d4.loss_mask: 0.9108  decode.d4.loss_dice: 1.5645  decode.d5.loss_cls: 1.5182  decode.d5.loss_mask: 0.9642  decode.d5.loss_dice: 1.5762  decode.d6.loss_cls: 1.4307  decode.d6.loss_mask: 0.8935  decode.d6.loss_dice: 1.5293  decode.d7.loss_cls: 1.4283  decode.d7.loss_mask: 0.8902  decode.d7.loss_dice: 1.5415  decode.d8.loss_cls: 1.4091  decode.d8.loss_mask: 0.9242  decode.d8.loss_dice: 1.5475
2023/05/23 22:00:27 - mmengine - INFO - Iter(train) [ 30250/160000]  lr: 8.2812e-06  eta: 15:23:12  time: 0.4201  data_time: 0.0097  memory: 4830  grad_norm: 107.1364  loss: 43.1897  decode.loss_cls: 1.5932  decode.loss_mask: 0.8099  decode.loss_dice: 1.5724  decode.d0.loss_cls: 3.5177  decode.d0.loss_mask: 0.8728  decode.d0.loss_dice: 1.8730  decode.d1.loss_cls: 1.7265  decode.d1.loss_mask: 0.8481  decode.d1.loss_dice: 1.8027  decode.d2.loss_cls: 1.6085  decode.d2.loss_mask: 0.8590  decode.d2.loss_dice: 1.7300  decode.d3.loss_cls: 1.6439  decode.d3.loss_mask: 0.7888  decode.d3.loss_dice: 1.6827  decode.d4.loss_cls: 1.6286  decode.d4.loss_mask: 0.8180  decode.d4.loss_dice: 1.6826  decode.d5.loss_cls: 1.6179  decode.d5.loss_mask: 0.8042  decode.d5.loss_dice: 1.6985  decode.d6.loss_cls: 1.5888  decode.d6.loss_mask: 0.7958  decode.d6.loss_dice: 1.6372  decode.d7.loss_cls: 1.5155  decode.d7.loss_mask: 0.8237  decode.d7.loss_dice: 1.6734  decode.d8.loss_cls: 1.5855  decode.d8.loss_mask: 0.8015  decode.d8.loss_dice: 1.5891
2023/05/23 22:00:48 - mmengine - INFO - Iter(train) [ 30300/160000]  lr: 8.2783e-06  eta: 15:22:48  time: 0.4279  data_time: 0.0101  memory: 4897  grad_norm: 146.9127  loss: 33.6727  decode.loss_cls: 1.2382  decode.loss_mask: 0.6365  decode.loss_dice: 1.2268  decode.d0.loss_cls: 3.2478  decode.d0.loss_mask: 0.6948  decode.d0.loss_dice: 1.4617  decode.d1.loss_cls: 1.3046  decode.d1.loss_mask: 0.7018  decode.d1.loss_dice: 1.3550  decode.d2.loss_cls: 1.2525  decode.d2.loss_mask: 0.6746  decode.d2.loss_dice: 1.2793  decode.d3.loss_cls: 1.2356  decode.d3.loss_mask: 0.6452  decode.d3.loss_dice: 1.2748  decode.d4.loss_cls: 1.2234  decode.d4.loss_mask: 0.6272  decode.d4.loss_dice: 1.2266  decode.d5.loss_cls: 1.2208  decode.d5.loss_mask: 0.6256  decode.d5.loss_dice: 1.2254  decode.d6.loss_cls: 1.2471  decode.d6.loss_mask: 0.6102  decode.d6.loss_dice: 1.2253  decode.d7.loss_cls: 1.2262  decode.d7.loss_mask: 0.6239  decode.d7.loss_dice: 1.2080  decode.d8.loss_cls: 1.2774  decode.d8.loss_mask: 0.6449  decode.d8.loss_dice: 1.2314
2023/05/23 22:01:11 - mmengine - INFO - Iter(train) [ 30350/160000]  lr: 8.2754e-06  eta: 15:22:36  time: 0.4695  data_time: 0.0102  memory: 4837  grad_norm: 101.9898  loss: 34.3476  decode.loss_cls: 1.1066  decode.loss_mask: 0.6767  decode.loss_dice: 1.3509  decode.d0.loss_cls: 2.9633  decode.d0.loss_mask: 0.7567  decode.d0.loss_dice: 1.6210  decode.d1.loss_cls: 1.1932  decode.d1.loss_mask: 0.7368  decode.d1.loss_dice: 1.4642  decode.d2.loss_cls: 1.1464  decode.d2.loss_mask: 0.7453  decode.d2.loss_dice: 1.4054  decode.d3.loss_cls: 1.1192  decode.d3.loss_mask: 0.6942  decode.d3.loss_dice: 1.3863  decode.d4.loss_cls: 1.1385  decode.d4.loss_mask: 0.7291  decode.d4.loss_dice: 1.3661  decode.d5.loss_cls: 1.1197  decode.d5.loss_mask: 0.6841  decode.d5.loss_dice: 1.3829  decode.d6.loss_cls: 1.1781  decode.d6.loss_mask: 0.6843  decode.d6.loss_dice: 1.3377  decode.d7.loss_cls: 1.1880  decode.d7.loss_mask: 0.6735  decode.d7.loss_dice: 1.3325  decode.d8.loss_cls: 1.1337  decode.d8.loss_mask: 0.6904  decode.d8.loss_dice: 1.3429
2023/05/23 22:01:33 - mmengine - INFO - Iter(train) [ 30400/160000]  lr: 8.2725e-06  eta: 15:22:15  time: 0.4167  data_time: 0.0099  memory: 4899  grad_norm: 102.5569  loss: 53.0945  decode.loss_cls: 1.8201  decode.loss_mask: 1.0531  decode.loss_dice: 2.0157  decode.d0.loss_cls: 4.0419  decode.d0.loss_mask: 1.1870  decode.d0.loss_dice: 2.2635  decode.d1.loss_cls: 2.0581  decode.d1.loss_mask: 1.0978  decode.d1.loss_dice: 2.1838  decode.d2.loss_cls: 2.0125  decode.d2.loss_mask: 1.0639  decode.d2.loss_dice: 2.1287  decode.d3.loss_cls: 1.9622  decode.d3.loss_mask: 1.0919  decode.d3.loss_dice: 2.1021  decode.d4.loss_cls: 1.9235  decode.d4.loss_mask: 1.0823  decode.d4.loss_dice: 2.1027  decode.d5.loss_cls: 1.8501  decode.d5.loss_mask: 1.0688  decode.d5.loss_dice: 2.1065  decode.d6.loss_cls: 1.8520  decode.d6.loss_mask: 1.0835  decode.d6.loss_dice: 2.0047  decode.d7.loss_cls: 1.8864  decode.d7.loss_mask: 1.0758  decode.d7.loss_dice: 2.0480  decode.d8.loss_cls: 1.8911  decode.d8.loss_mask: 1.0509  decode.d8.loss_dice: 1.9858
2023/05/23 22:01:54 - mmengine - INFO - Iter(train) [ 30450/160000]  lr: 8.2697e-06  eta: 15:21:52  time: 0.4094  data_time: 0.0097  memory: 4939  grad_norm: 86.1233  loss: 38.4683  decode.loss_cls: 1.4391  decode.loss_mask: 0.8653  decode.loss_dice: 1.3288  decode.d0.loss_cls: 3.3805  decode.d0.loss_mask: 0.8435  decode.d0.loss_dice: 1.5927  decode.d1.loss_cls: 1.4496  decode.d1.loss_mask: 0.8892  decode.d1.loss_dice: 1.4420  decode.d2.loss_cls: 1.4575  decode.d2.loss_mask: 0.8564  decode.d2.loss_dice: 1.3483  decode.d3.loss_cls: 1.4576  decode.d3.loss_mask: 0.8389  decode.d3.loss_dice: 1.3391  decode.d4.loss_cls: 1.4658  decode.d4.loss_mask: 0.8640  decode.d4.loss_dice: 1.3637  decode.d5.loss_cls: 1.3757  decode.d5.loss_mask: 0.8695  decode.d5.loss_dice: 1.3618  decode.d6.loss_cls: 1.3768  decode.d6.loss_mask: 0.8317  decode.d6.loss_dice: 1.3024  decode.d7.loss_cls: 1.3861  decode.d7.loss_mask: 0.8366  decode.d7.loss_dice: 1.3235  decode.d8.loss_cls: 1.4112  decode.d8.loss_mask: 0.8485  decode.d8.loss_dice: 1.3224
2023/05/23 22:02:14 - mmengine - INFO - Iter(train) [ 30500/160000]  lr: 8.2668e-06  eta: 15:21:27  time: 0.4133  data_time: 0.0095  memory: 4983  grad_norm: 98.2020  loss: 40.6484  decode.loss_cls: 1.3530  decode.loss_mask: 0.9591  decode.loss_dice: 1.4823  decode.d0.loss_cls: 3.2447  decode.d0.loss_mask: 0.9334  decode.d0.loss_dice: 1.6404  decode.d1.loss_cls: 1.5222  decode.d1.loss_mask: 0.9434  decode.d1.loss_dice: 1.5637  decode.d2.loss_cls: 1.5421  decode.d2.loss_mask: 0.8971  decode.d2.loss_dice: 1.4958  decode.d3.loss_cls: 1.4307  decode.d3.loss_mask: 0.8880  decode.d3.loss_dice: 1.4931  decode.d4.loss_cls: 1.4470  decode.d4.loss_mask: 0.9169  decode.d4.loss_dice: 1.4902  decode.d5.loss_cls: 1.4590  decode.d5.loss_mask: 0.9738  decode.d5.loss_dice: 1.4744  decode.d6.loss_cls: 1.4122  decode.d6.loss_mask: 0.9302  decode.d6.loss_dice: 1.4832  decode.d7.loss_cls: 1.4234  decode.d7.loss_mask: 0.9354  decode.d7.loss_dice: 1.5039  decode.d8.loss_cls: 1.3579  decode.d8.loss_mask: 0.9678  decode.d8.loss_dice: 1.4842
2023/05/23 22:02:35 - mmengine - INFO - Iter(train) [ 30550/160000]  lr: 8.2639e-06  eta: 15:21:04  time: 0.4164  data_time: 0.0098  memory: 4898  grad_norm: 101.0412  loss: 41.3092  decode.loss_cls: 1.5240  decode.loss_mask: 0.9289  decode.loss_dice: 1.4016  decode.d0.loss_cls: 3.3759  decode.d0.loss_mask: 0.9100  decode.d0.loss_dice: 1.6399  decode.d1.loss_cls: 1.6035  decode.d1.loss_mask: 0.9036  decode.d1.loss_dice: 1.5674  decode.d2.loss_cls: 1.5316  decode.d2.loss_mask: 0.9362  decode.d2.loss_dice: 1.5118  decode.d3.loss_cls: 1.5301  decode.d3.loss_mask: 0.9793  decode.d3.loss_dice: 1.4786  decode.d4.loss_cls: 1.5736  decode.d4.loss_mask: 0.9268  decode.d4.loss_dice: 1.4662  decode.d5.loss_cls: 1.4745  decode.d5.loss_mask: 0.9405  decode.d5.loss_dice: 1.4777  decode.d6.loss_cls: 1.5486  decode.d6.loss_mask: 0.9470  decode.d6.loss_dice: 1.4356  decode.d7.loss_cls: 1.5361  decode.d7.loss_mask: 0.9123  decode.d7.loss_dice: 1.4184  decode.d8.loss_cls: 1.5014  decode.d8.loss_mask: 0.9197  decode.d8.loss_dice: 1.4081
2023/05/23 22:02:56 - mmengine - INFO - Iter(train) [ 30600/160000]  lr: 8.2611e-06  eta: 15:20:42  time: 0.4132  data_time: 0.0102  memory: 4856  grad_norm: 95.3099  loss: 44.4859  decode.loss_cls: 1.4732  decode.loss_mask: 1.0230  decode.loss_dice: 1.6872  decode.d0.loss_cls: 3.2199  decode.d0.loss_mask: 1.0601  decode.d0.loss_dice: 1.9175  decode.d1.loss_cls: 1.5920  decode.d1.loss_mask: 1.0867  decode.d1.loss_dice: 1.8554  decode.d2.loss_cls: 1.5815  decode.d2.loss_mask: 1.0267  decode.d2.loss_dice: 1.7438  decode.d3.loss_cls: 1.4558  decode.d3.loss_mask: 1.0183  decode.d3.loss_dice: 1.7084  decode.d4.loss_cls: 1.4620  decode.d4.loss_mask: 1.0521  decode.d4.loss_dice: 1.7326  decode.d5.loss_cls: 1.5148  decode.d5.loss_mask: 1.0166  decode.d5.loss_dice: 1.6454  decode.d6.loss_cls: 1.4846  decode.d6.loss_mask: 1.0201  decode.d6.loss_dice: 1.7183  decode.d7.loss_cls: 1.4983  decode.d7.loss_mask: 1.0297  decode.d7.loss_dice: 1.7164  decode.d8.loss_cls: 1.4122  decode.d8.loss_mask: 1.0164  decode.d8.loss_dice: 1.7169
2023/05/23 22:03:17 - mmengine - INFO - Iter(train) [ 30650/160000]  lr: 8.2582e-06  eta: 15:20:18  time: 0.4140  data_time: 0.0099  memory: 4876  grad_norm: 82.8752  loss: 37.3267  decode.loss_cls: 1.2108  decode.loss_mask: 0.8049  decode.loss_dice: 1.3633  decode.d0.loss_cls: 3.3149  decode.d0.loss_mask: 0.8837  decode.d0.loss_dice: 1.6351  decode.d1.loss_cls: 1.4428  decode.d1.loss_mask: 0.8274  decode.d1.loss_dice: 1.4874  decode.d2.loss_cls: 1.3772  decode.d2.loss_mask: 0.8578  decode.d2.loss_dice: 1.3965  decode.d3.loss_cls: 1.2954  decode.d3.loss_mask: 0.8133  decode.d3.loss_dice: 1.3393  decode.d4.loss_cls: 1.2964  decode.d4.loss_mask: 0.8021  decode.d4.loss_dice: 1.4102  decode.d5.loss_cls: 1.2462  decode.d5.loss_mask: 0.8069  decode.d5.loss_dice: 1.4065  decode.d6.loss_cls: 1.2725  decode.d6.loss_mask: 0.8100  decode.d6.loss_dice: 1.3868  decode.d7.loss_cls: 1.2385  decode.d7.loss_mask: 0.8076  decode.d7.loss_dice: 1.3809  decode.d8.loss_cls: 1.2246  decode.d8.loss_mask: 0.8040  decode.d8.loss_dice: 1.3839
2023/05/23 22:03:39 - mmengine - INFO - Iter(train) [ 30700/160000]  lr: 8.2553e-06  eta: 15:19:58  time: 0.4666  data_time: 0.0096  memory: 4821  grad_norm: 112.3870  loss: 40.7008  decode.loss_cls: 1.5748  decode.loss_mask: 0.9082  decode.loss_dice: 1.3379  decode.d0.loss_cls: 3.4107  decode.d0.loss_mask: 1.0119  decode.d0.loss_dice: 1.5185  decode.d1.loss_cls: 1.7748  decode.d1.loss_mask: 0.9379  decode.d1.loss_dice: 1.3911  decode.d2.loss_cls: 1.6954  decode.d2.loss_mask: 0.8918  decode.d2.loss_dice: 1.3321  decode.d3.loss_cls: 1.6067  decode.d3.loss_mask: 0.8965  decode.d3.loss_dice: 1.3713  decode.d4.loss_cls: 1.5953  decode.d4.loss_mask: 0.9179  decode.d4.loss_dice: 1.3449  decode.d5.loss_cls: 1.6115  decode.d5.loss_mask: 0.8771  decode.d5.loss_dice: 1.3323  decode.d6.loss_cls: 1.6275  decode.d6.loss_mask: 0.8656  decode.d6.loss_dice: 1.2823  decode.d7.loss_cls: 1.5813  decode.d7.loss_mask: 0.8997  decode.d7.loss_dice: 1.3516  decode.d8.loss_cls: 1.5191  decode.d8.loss_mask: 0.9181  decode.d8.loss_dice: 1.3171
2023/05/23 22:04:00 - mmengine - INFO - Iter(train) [ 30750/160000]  lr: 8.2524e-06  eta: 15:19:36  time: 0.4154  data_time: 0.0099  memory: 4869  grad_norm: 90.3985  loss: 44.2234  decode.loss_cls: 1.5680  decode.loss_mask: 0.8730  decode.loss_dice: 1.6173  decode.d0.loss_cls: 3.6506  decode.d0.loss_mask: 1.0160  decode.d0.loss_dice: 1.8350  decode.d1.loss_cls: 1.7998  decode.d1.loss_mask: 0.9227  decode.d1.loss_dice: 1.7691  decode.d2.loss_cls: 1.7264  decode.d2.loss_mask: 0.9216  decode.d2.loss_dice: 1.6752  decode.d3.loss_cls: 1.6841  decode.d3.loss_mask: 0.8968  decode.d3.loss_dice: 1.6502  decode.d4.loss_cls: 1.6603  decode.d4.loss_mask: 0.8924  decode.d4.loss_dice: 1.6288  decode.d5.loss_cls: 1.6503  decode.d5.loss_mask: 0.9186  decode.d5.loss_dice: 1.6179  decode.d6.loss_cls: 1.5271  decode.d6.loss_mask: 0.9481  decode.d6.loss_dice: 1.6228  decode.d7.loss_cls: 1.5619  decode.d7.loss_mask: 0.9044  decode.d7.loss_dice: 1.5992  decode.d8.loss_cls: 1.5455  decode.d8.loss_mask: 0.8990  decode.d8.loss_dice: 1.6410
2023/05/23 22:04:21 - mmengine - INFO - Iter(train) [ 30800/160000]  lr: 8.2496e-06  eta: 15:19:13  time: 0.4199  data_time: 0.0098  memory: 4865  grad_norm: 94.1188  loss: 41.9071  decode.loss_cls: 1.3724  decode.loss_mask: 0.7538  decode.loss_dice: 1.6436  decode.d0.loss_cls: 3.7505  decode.d0.loss_mask: 0.8262  decode.d0.loss_dice: 1.9332  decode.d1.loss_cls: 1.6801  decode.d1.loss_mask: 0.8020  decode.d1.loss_dice: 1.8110  decode.d2.loss_cls: 1.5106  decode.d2.loss_mask: 0.8019  decode.d2.loss_dice: 1.7182  decode.d3.loss_cls: 1.5052  decode.d3.loss_mask: 0.7625  decode.d3.loss_dice: 1.6646  decode.d4.loss_cls: 1.4468  decode.d4.loss_mask: 0.7763  decode.d4.loss_dice: 1.7021  decode.d5.loss_cls: 1.4789  decode.d5.loss_mask: 0.7738  decode.d5.loss_dice: 1.6444  decode.d6.loss_cls: 1.4823  decode.d6.loss_mask: 0.7453  decode.d6.loss_dice: 1.6230  decode.d7.loss_cls: 1.4881  decode.d7.loss_mask: 0.7504  decode.d7.loss_dice: 1.6230  decode.d8.loss_cls: 1.4104  decode.d8.loss_mask: 0.7609  decode.d8.loss_dice: 1.6657
2023/05/23 22:04:42 - mmengine - INFO - Iter(train) [ 30850/160000]  lr: 8.2467e-06  eta: 15:18:50  time: 0.4061  data_time: 0.0095  memory: 4796  grad_norm: 107.2351  loss: 24.5235  decode.loss_cls: 0.8871  decode.loss_mask: 0.5354  decode.loss_dice: 0.8239  decode.d0.loss_cls: 2.4932  decode.d0.loss_mask: 0.5303  decode.d0.loss_dice: 0.9543  decode.d1.loss_cls: 0.9674  decode.d1.loss_mask: 0.5030  decode.d1.loss_dice: 0.9017  decode.d2.loss_cls: 1.0554  decode.d2.loss_mask: 0.4937  decode.d2.loss_dice: 0.8526  decode.d3.loss_cls: 0.9917  decode.d3.loss_mask: 0.4850  decode.d3.loss_dice: 0.8437  decode.d4.loss_cls: 0.9279  decode.d4.loss_mask: 0.4907  decode.d4.loss_dice: 0.8447  decode.d5.loss_cls: 0.8965  decode.d5.loss_mask: 0.4810  decode.d5.loss_dice: 0.8438  decode.d6.loss_cls: 0.9313  decode.d6.loss_mask: 0.4698  decode.d6.loss_dice: 0.8096  decode.d7.loss_cls: 0.9615  decode.d7.loss_mask: 0.4885  decode.d7.loss_dice: 0.8170  decode.d8.loss_cls: 0.9468  decode.d8.loss_mask: 0.4901  decode.d8.loss_dice: 0.8060
2023/05/23 22:05:02 - mmengine - INFO - Iter(train) [ 30900/160000]  lr: 8.2438e-06  eta: 15:18:26  time: 0.4197  data_time: 0.0098  memory: 4804  grad_norm: 115.9470  loss: 33.2317  decode.loss_cls: 1.1512  decode.loss_mask: 0.7861  decode.loss_dice: 1.1241  decode.d0.loss_cls: 2.9163  decode.d0.loss_mask: 0.8982  decode.d0.loss_dice: 1.3161  decode.d1.loss_cls: 1.2607  decode.d1.loss_mask: 0.8839  decode.d1.loss_dice: 1.2166  decode.d2.loss_cls: 1.1429  decode.d2.loss_mask: 0.8791  decode.d2.loss_dice: 1.1557  decode.d3.loss_cls: 1.1578  decode.d3.loss_mask: 0.8302  decode.d3.loss_dice: 1.1699  decode.d4.loss_cls: 1.1293  decode.d4.loss_mask: 0.8014  decode.d4.loss_dice: 1.1241  decode.d5.loss_cls: 1.1385  decode.d5.loss_mask: 0.8065  decode.d5.loss_dice: 1.1200  decode.d6.loss_cls: 1.1413  decode.d6.loss_mask: 0.8021  decode.d6.loss_dice: 1.1372  decode.d7.loss_cls: 1.1143  decode.d7.loss_mask: 0.8143  decode.d7.loss_dice: 1.1235  decode.d8.loss_cls: 1.1746  decode.d8.loss_mask: 0.7944  decode.d8.loss_dice: 1.1214
2023/05/23 22:05:24 - mmengine - INFO - Iter(train) [ 30950/160000]  lr: 8.2409e-06  eta: 15:18:04  time: 0.4450  data_time: 0.0097  memory: 4811  grad_norm: 106.3001  loss: 39.3051  decode.loss_cls: 1.2402  decode.loss_mask: 0.9464  decode.loss_dice: 1.4544  decode.d0.loss_cls: 3.2394  decode.d0.loss_mask: 0.9498  decode.d0.loss_dice: 1.6214  decode.d1.loss_cls: 1.3897  decode.d1.loss_mask: 0.8958  decode.d1.loss_dice: 1.4921  decode.d2.loss_cls: 1.4344  decode.d2.loss_mask: 0.8741  decode.d2.loss_dice: 1.4758  decode.d3.loss_cls: 1.3709  decode.d3.loss_mask: 0.9305  decode.d3.loss_dice: 1.4596  decode.d4.loss_cls: 1.3442  decode.d4.loss_mask: 0.8980  decode.d4.loss_dice: 1.4472  decode.d5.loss_cls: 1.2889  decode.d5.loss_mask: 0.9234  decode.d5.loss_dice: 1.4818  decode.d6.loss_cls: 1.3207  decode.d6.loss_mask: 0.9436  decode.d6.loss_dice: 1.4773  decode.d7.loss_cls: 1.3454  decode.d7.loss_mask: 0.9264  decode.d7.loss_dice: 1.4466  decode.d8.loss_cls: 1.2635  decode.d8.loss_mask: 0.9316  decode.d8.loss_dice: 1.4923
2023/05/23 22:05:44 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 22:05:44 - mmengine - INFO - Iter(train) [ 31000/160000]  lr: 8.2381e-06  eta: 15:17:40  time: 0.4118  data_time: 0.0096  memory: 4876  grad_norm: 101.5217  loss: 42.7778  decode.loss_cls: 1.3800  decode.loss_mask: 0.9872  decode.loss_dice: 1.5946  decode.d0.loss_cls: 3.2592  decode.d0.loss_mask: 1.0824  decode.d0.loss_dice: 1.7750  decode.d1.loss_cls: 1.5699  decode.d1.loss_mask: 1.0231  decode.d1.loss_dice: 1.7546  decode.d2.loss_cls: 1.4204  decode.d2.loss_mask: 1.0458  decode.d2.loss_dice: 1.6521  decode.d3.loss_cls: 1.4468  decode.d3.loss_mask: 1.0291  decode.d3.loss_dice: 1.5676  decode.d4.loss_cls: 1.4059  decode.d4.loss_mask: 1.0070  decode.d4.loss_dice: 1.6247  decode.d5.loss_cls: 1.3826  decode.d5.loss_mask: 1.0403  decode.d5.loss_dice: 1.6379  decode.d6.loss_cls: 1.3735  decode.d6.loss_mask: 0.9985  decode.d6.loss_dice: 1.6007  decode.d7.loss_cls: 1.4458  decode.d7.loss_mask: 1.0042  decode.d7.loss_dice: 1.5979  decode.d8.loss_cls: 1.4351  decode.d8.loss_mask: 1.0134  decode.d8.loss_dice: 1.6226
2023/05/23 22:05:45 - mmengine - INFO - Saving checkpoint at 31000 iterations
2023/05/23 22:06:14 - mmengine - INFO - Iter(train) [ 31050/160000]  lr: 8.2352e-06  eta: 15:17:51  time: 0.4677  data_time: 0.0100  memory: 4818  grad_norm: 92.6754  loss: 36.4610  decode.loss_cls: 1.4805  decode.loss_mask: 0.7309  decode.loss_dice: 1.1422  decode.d0.loss_cls: 3.2607  decode.d0.loss_mask: 0.8080  decode.d0.loss_dice: 1.3266  decode.d1.loss_cls: 1.6165  decode.d1.loss_mask: 0.8378  decode.d1.loss_dice: 1.2471  decode.d2.loss_cls: 1.5304  decode.d2.loss_mask: 0.7586  decode.d2.loss_dice: 1.2159  decode.d3.loss_cls: 1.5148  decode.d3.loss_mask: 0.7759  decode.d3.loss_dice: 1.1912  decode.d4.loss_cls: 1.5124  decode.d4.loss_mask: 0.7694  decode.d4.loss_dice: 1.1950  decode.d5.loss_cls: 1.5111  decode.d5.loss_mask: 0.7582  decode.d5.loss_dice: 1.1631  decode.d6.loss_cls: 1.4951  decode.d6.loss_mask: 0.7510  decode.d6.loss_dice: 1.1460  decode.d7.loss_cls: 1.4197  decode.d7.loss_mask: 0.7644  decode.d7.loss_dice: 1.1457  decode.d8.loss_cls: 1.4989  decode.d8.loss_mask: 0.7496  decode.d8.loss_dice: 1.1440
2023/05/23 22:06:36 - mmengine - INFO - Iter(train) [ 31100/160000]  lr: 8.2323e-06  eta: 15:17:34  time: 0.4636  data_time: 0.0104  memory: 4906  grad_norm: 101.0463  loss: 31.7733  decode.loss_cls: 1.2786  decode.loss_mask: 0.7427  decode.loss_dice: 0.8994  decode.d0.loss_cls: 2.8764  decode.d0.loss_mask: 0.8227  decode.d0.loss_dice: 1.0451  decode.d1.loss_cls: 1.2285  decode.d1.loss_mask: 0.8927  decode.d1.loss_dice: 1.0478  decode.d2.loss_cls: 1.2705  decode.d2.loss_mask: 0.8099  decode.d2.loss_dice: 0.9684  decode.d3.loss_cls: 1.2940  decode.d3.loss_mask: 0.7499  decode.d3.loss_dice: 0.9301  decode.d4.loss_cls: 1.3013  decode.d4.loss_mask: 0.7618  decode.d4.loss_dice: 0.9319  decode.d5.loss_cls: 1.2890  decode.d5.loss_mask: 0.7958  decode.d5.loss_dice: 0.9413  decode.d6.loss_cls: 1.3085  decode.d6.loss_mask: 0.7612  decode.d6.loss_dice: 0.8991  decode.d7.loss_cls: 1.2867  decode.d7.loss_mask: 0.7844  decode.d7.loss_dice: 0.9004  decode.d8.loss_cls: 1.2844  decode.d8.loss_mask: 0.7629  decode.d8.loss_dice: 0.9078
2023/05/23 22:06:59 - mmengine - INFO - Iter(train) [ 31150/160000]  lr: 8.2294e-06  eta: 15:17:21  time: 0.4810  data_time: 0.0096  memory: 4907  grad_norm: 95.9231  loss: 32.9867  decode.loss_cls: 1.2326  decode.loss_mask: 0.8283  decode.loss_dice: 1.0338  decode.d0.loss_cls: 2.9177  decode.d0.loss_mask: 0.9373  decode.d0.loss_dice: 1.2190  decode.d1.loss_cls: 1.3945  decode.d1.loss_mask: 0.8537  decode.d1.loss_dice: 1.1311  decode.d2.loss_cls: 1.2250  decode.d2.loss_mask: 0.8241  decode.d2.loss_dice: 1.0630  decode.d3.loss_cls: 1.2720  decode.d3.loss_mask: 0.7877  decode.d3.loss_dice: 1.0497  decode.d4.loss_cls: 1.2866  decode.d4.loss_mask: 0.7780  decode.d4.loss_dice: 1.0335  decode.d5.loss_cls: 1.1540  decode.d5.loss_mask: 0.8315  decode.d5.loss_dice: 1.0391  decode.d6.loss_cls: 1.1092  decode.d6.loss_mask: 0.8640  decode.d6.loss_dice: 1.0554  decode.d7.loss_cls: 1.1717  decode.d7.loss_mask: 0.8255  decode.d7.loss_dice: 1.0549  decode.d8.loss_cls: 1.1278  decode.d8.loss_mask: 0.8354  decode.d8.loss_dice: 1.0506
2023/05/23 22:07:21 - mmengine - INFO - Iter(train) [ 31200/160000]  lr: 8.2266e-06  eta: 15:16:59  time: 0.4099  data_time: 0.0100  memory: 4867  grad_norm: 145.9241  loss: 37.7327  decode.loss_cls: 1.1864  decode.loss_mask: 0.8807  decode.loss_dice: 1.4708  decode.d0.loss_cls: 3.2145  decode.d0.loss_mask: 0.9391  decode.d0.loss_dice: 1.6178  decode.d1.loss_cls: 1.3745  decode.d1.loss_mask: 0.8804  decode.d1.loss_dice: 1.5267  decode.d2.loss_cls: 1.2606  decode.d2.loss_mask: 0.8942  decode.d2.loss_dice: 1.4869  decode.d3.loss_cls: 1.2292  decode.d3.loss_mask: 0.8461  decode.d3.loss_dice: 1.4390  decode.d4.loss_cls: 1.2035  decode.d4.loss_mask: 0.8489  decode.d4.loss_dice: 1.4202  decode.d5.loss_cls: 1.2261  decode.d5.loss_mask: 0.8419  decode.d5.loss_dice: 1.3940  decode.d6.loss_cls: 1.1637  decode.d6.loss_mask: 0.8757  decode.d6.loss_dice: 1.4658  decode.d7.loss_cls: 1.1918  decode.d7.loss_mask: 0.8777  decode.d7.loss_dice: 1.4852  decode.d8.loss_cls: 1.2253  decode.d8.loss_mask: 0.8377  decode.d8.loss_dice: 1.4283
2023/05/23 22:07:41 - mmengine - INFO - Iter(train) [ 31250/160000]  lr: 8.2237e-06  eta: 15:16:35  time: 0.4234  data_time: 0.0101  memory: 4816  grad_norm: 109.1345  loss: 43.3657  decode.loss_cls: 1.5091  decode.loss_mask: 0.9129  decode.loss_dice: 1.5351  decode.d0.loss_cls: 3.4388  decode.d0.loss_mask: 1.0400  decode.d0.loss_dice: 1.7251  decode.d1.loss_cls: 1.7462  decode.d1.loss_mask: 0.9794  decode.d1.loss_dice: 1.6483  decode.d2.loss_cls: 1.6947  decode.d2.loss_mask: 0.9539  decode.d2.loss_dice: 1.5877  decode.d3.loss_cls: 1.7737  decode.d3.loss_mask: 0.8975  decode.d3.loss_dice: 1.5727  decode.d4.loss_cls: 1.6327  decode.d4.loss_mask: 0.9117  decode.d4.loss_dice: 1.5714  decode.d5.loss_cls: 1.6568  decode.d5.loss_mask: 0.9131  decode.d5.loss_dice: 1.5619  decode.d6.loss_cls: 1.6439  decode.d6.loss_mask: 0.8929  decode.d6.loss_dice: 1.5442  decode.d7.loss_cls: 1.6235  decode.d7.loss_mask: 0.8852  decode.d7.loss_dice: 1.5377  decode.d8.loss_cls: 1.5530  decode.d8.loss_mask: 0.8912  decode.d8.loss_dice: 1.5315
2023/05/23 22:08:02 - mmengine - INFO - Iter(train) [ 31300/160000]  lr: 8.2208e-06  eta: 15:16:11  time: 0.4123  data_time: 0.0096  memory: 4802  grad_norm: 85.8613  loss: 38.7134  decode.loss_cls: 1.3886  decode.loss_mask: 0.8703  decode.loss_dice: 1.4048  decode.d0.loss_cls: 3.2937  decode.d0.loss_mask: 0.8907  decode.d0.loss_dice: 1.5170  decode.d1.loss_cls: 1.4654  decode.d1.loss_mask: 0.9072  decode.d1.loss_dice: 1.4432  decode.d2.loss_cls: 1.4364  decode.d2.loss_mask: 0.8646  decode.d2.loss_dice: 1.4401  decode.d3.loss_cls: 1.3577  decode.d3.loss_mask: 0.8928  decode.d3.loss_dice: 1.3906  decode.d4.loss_cls: 1.3652  decode.d4.loss_mask: 0.8945  decode.d4.loss_dice: 1.4137  decode.d5.loss_cls: 1.3663  decode.d5.loss_mask: 0.8970  decode.d5.loss_dice: 1.4107  decode.d6.loss_cls: 1.3325  decode.d6.loss_mask: 0.8669  decode.d6.loss_dice: 1.4078  decode.d7.loss_cls: 1.3230  decode.d7.loss_mask: 0.8883  decode.d7.loss_dice: 1.3676  decode.d8.loss_cls: 1.3334  decode.d8.loss_mask: 0.8896  decode.d8.loss_dice: 1.3940
2023/05/23 22:08:24 - mmengine - INFO - Iter(train) [ 31350/160000]  lr: 8.2179e-06  eta: 15:15:51  time: 0.4570  data_time: 0.0099  memory: 4951  grad_norm: 102.7240  loss: 41.9132  decode.loss_cls: 1.4567  decode.loss_mask: 0.8609  decode.loss_dice: 1.6115  decode.d0.loss_cls: 3.5154  decode.d0.loss_mask: 0.9181  decode.d0.loss_dice: 1.8262  decode.d1.loss_cls: 1.4880  decode.d1.loss_mask: 0.8823  decode.d1.loss_dice: 1.7427  decode.d2.loss_cls: 1.5200  decode.d2.loss_mask: 0.8706  decode.d2.loss_dice: 1.6510  decode.d3.loss_cls: 1.4700  decode.d3.loss_mask: 0.8566  decode.d3.loss_dice: 1.6255  decode.d4.loss_cls: 1.4708  decode.d4.loss_mask: 0.8421  decode.d4.loss_dice: 1.6023  decode.d5.loss_cls: 1.4571  decode.d5.loss_mask: 0.8558  decode.d5.loss_dice: 1.6150  decode.d6.loss_cls: 1.4436  decode.d6.loss_mask: 0.8758  decode.d6.loss_dice: 1.5914  decode.d7.loss_cls: 1.4380  decode.d7.loss_mask: 0.8574  decode.d7.loss_dice: 1.6119  decode.d8.loss_cls: 1.4738  decode.d8.loss_mask: 0.8603  decode.d8.loss_dice: 1.6223
2023/05/23 22:08:44 - mmengine - INFO - Iter(train) [ 31400/160000]  lr: 8.2151e-06  eta: 15:15:26  time: 0.4203  data_time: 0.0099  memory: 4852  grad_norm: 88.2677  loss: 37.4764  decode.loss_cls: 1.4837  decode.loss_mask: 0.7775  decode.loss_dice: 1.2529  decode.d0.loss_cls: 3.2677  decode.d0.loss_mask: 0.8200  decode.d0.loss_dice: 1.4080  decode.d1.loss_cls: 1.4688  decode.d1.loss_mask: 0.8167  decode.d1.loss_dice: 1.3367  decode.d2.loss_cls: 1.4593  decode.d2.loss_mask: 0.7914  decode.d2.loss_dice: 1.2820  decode.d3.loss_cls: 1.4729  decode.d3.loss_mask: 0.8446  decode.d3.loss_dice: 1.2904  decode.d4.loss_cls: 1.4561  decode.d4.loss_mask: 0.7984  decode.d4.loss_dice: 1.2607  decode.d5.loss_cls: 1.5134  decode.d5.loss_mask: 0.8007  decode.d5.loss_dice: 1.2785  decode.d6.loss_cls: 1.4776  decode.d6.loss_mask: 0.8189  decode.d6.loss_dice: 1.2268  decode.d7.loss_cls: 1.4955  decode.d7.loss_mask: 0.8097  decode.d7.loss_dice: 1.2235  decode.d8.loss_cls: 1.5043  decode.d8.loss_mask: 0.8035  decode.d8.loss_dice: 1.2362
2023/05/23 22:09:06 - mmengine - INFO - Iter(train) [ 31450/160000]  lr: 8.2122e-06  eta: 15:15:05  time: 0.4308  data_time: 0.0113  memory: 4860  grad_norm: 97.7079  loss: 39.9489  decode.loss_cls: 1.5011  decode.loss_mask: 0.8815  decode.loss_dice: 1.2970  decode.d0.loss_cls: 3.3521  decode.d0.loss_mask: 0.9617  decode.d0.loss_dice: 1.5602  decode.d1.loss_cls: 1.6695  decode.d1.loss_mask: 0.9267  decode.d1.loss_dice: 1.4857  decode.d2.loss_cls: 1.5815  decode.d2.loss_mask: 0.9031  decode.d2.loss_dice: 1.3864  decode.d3.loss_cls: 1.5031  decode.d3.loss_mask: 0.9489  decode.d3.loss_dice: 1.3649  decode.d4.loss_cls: 1.4628  decode.d4.loss_mask: 0.9527  decode.d4.loss_dice: 1.3517  decode.d5.loss_cls: 1.4477  decode.d5.loss_mask: 0.9655  decode.d5.loss_dice: 1.3517  decode.d6.loss_cls: 1.4164  decode.d6.loss_mask: 0.9479  decode.d6.loss_dice: 1.3324  decode.d7.loss_cls: 1.4706  decode.d7.loss_mask: 0.9075  decode.d7.loss_dice: 1.3304  decode.d8.loss_cls: 1.4471  decode.d8.loss_mask: 0.9260  decode.d8.loss_dice: 1.3152
2023/05/23 22:09:27 - mmengine - INFO - Iter(train) [ 31500/160000]  lr: 8.2093e-06  eta: 15:14:42  time: 0.4135  data_time: 0.0097  memory: 4844  grad_norm: 96.1276  loss: 34.3430  decode.loss_cls: 1.2240  decode.loss_mask: 0.7862  decode.loss_dice: 1.1858  decode.d0.loss_cls: 3.0312  decode.d0.loss_mask: 0.7804  decode.d0.loss_dice: 1.3586  decode.d1.loss_cls: 1.4258  decode.d1.loss_mask: 0.8249  decode.d1.loss_dice: 1.2997  decode.d2.loss_cls: 1.3650  decode.d2.loss_mask: 0.7549  decode.d2.loss_dice: 1.1919  decode.d3.loss_cls: 1.2660  decode.d3.loss_mask: 0.8006  decode.d3.loss_dice: 1.1580  decode.d4.loss_cls: 1.2379  decode.d4.loss_mask: 0.7693  decode.d4.loss_dice: 1.1914  decode.d5.loss_cls: 1.2538  decode.d5.loss_mask: 0.7536  decode.d5.loss_dice: 1.1691  decode.d6.loss_cls: 1.2228  decode.d6.loss_mask: 0.8043  decode.d6.loss_dice: 1.1858  decode.d7.loss_cls: 1.1691  decode.d7.loss_mask: 0.8138  decode.d7.loss_dice: 1.1581  decode.d8.loss_cls: 1.1907  decode.d8.loss_mask: 0.7635  decode.d8.loss_dice: 1.2066
2023/05/23 22:09:48 - mmengine - INFO - Iter(train) [ 31550/160000]  lr: 8.2064e-06  eta: 15:14:19  time: 0.4230  data_time: 0.0096  memory: 4829  grad_norm: 111.9885  loss: 33.6813  decode.loss_cls: 1.1949  decode.loss_mask: 0.8062  decode.loss_dice: 1.1922  decode.d0.loss_cls: 2.9835  decode.d0.loss_mask: 0.7852  decode.d0.loss_dice: 1.2932  decode.d1.loss_cls: 1.3815  decode.d1.loss_mask: 0.7615  decode.d1.loss_dice: 1.2060  decode.d2.loss_cls: 1.2961  decode.d2.loss_mask: 0.7592  decode.d2.loss_dice: 1.1715  decode.d3.loss_cls: 1.2768  decode.d3.loss_mask: 0.7425  decode.d3.loss_dice: 1.1448  decode.d4.loss_cls: 1.2765  decode.d4.loss_mask: 0.7536  decode.d4.loss_dice: 1.1300  decode.d5.loss_cls: 1.2509  decode.d5.loss_mask: 0.7626  decode.d5.loss_dice: 1.1418  decode.d6.loss_cls: 1.2157  decode.d6.loss_mask: 0.7497  decode.d6.loss_dice: 1.1146  decode.d7.loss_cls: 1.1891  decode.d7.loss_mask: 0.8134  decode.d7.loss_dice: 1.1274  decode.d8.loss_cls: 1.2372  decode.d8.loss_mask: 0.7749  decode.d8.loss_dice: 1.1487
2023/05/23 22:10:08 - mmengine - INFO - Iter(train) [ 31600/160000]  lr: 8.2036e-06  eta: 15:13:55  time: 0.4152  data_time: 0.0101  memory: 4865  grad_norm: 87.6085  loss: 39.1414  decode.loss_cls: 1.5353  decode.loss_mask: 0.8553  decode.loss_dice: 1.2729  decode.d0.loss_cls: 3.1676  decode.d0.loss_mask: 0.9525  decode.d0.loss_dice: 1.4742  decode.d1.loss_cls: 1.6589  decode.d1.loss_mask: 0.9048  decode.d1.loss_dice: 1.3856  decode.d2.loss_cls: 1.5798  decode.d2.loss_mask: 0.9209  decode.d2.loss_dice: 1.3341  decode.d3.loss_cls: 1.4807  decode.d3.loss_mask: 0.9363  decode.d3.loss_dice: 1.2726  decode.d4.loss_cls: 1.4882  decode.d4.loss_mask: 0.9433  decode.d4.loss_dice: 1.2921  decode.d5.loss_cls: 1.5178  decode.d5.loss_mask: 0.9043  decode.d5.loss_dice: 1.2762  decode.d6.loss_cls: 1.4795  decode.d6.loss_mask: 0.9028  decode.d6.loss_dice: 1.2522  decode.d7.loss_cls: 1.4958  decode.d7.loss_mask: 0.9181  decode.d7.loss_dice: 1.2892  decode.d8.loss_cls: 1.4983  decode.d8.loss_mask: 0.9238  decode.d8.loss_dice: 1.2279
2023/05/23 22:10:29 - mmengine - INFO - Iter(train) [ 31650/160000]  lr: 8.2007e-06  eta: 15:13:32  time: 0.4236  data_time: 0.0096  memory: 4865  grad_norm: 94.2648  loss: 40.7315  decode.loss_cls: 1.4255  decode.loss_mask: 0.8459  decode.loss_dice: 1.5747  decode.d0.loss_cls: 3.1711  decode.d0.loss_mask: 0.9201  decode.d0.loss_dice: 1.8755  decode.d1.loss_cls: 1.5205  decode.d1.loss_mask: 0.8895  decode.d1.loss_dice: 1.6989  decode.d2.loss_cls: 1.3862  decode.d2.loss_mask: 0.8832  decode.d2.loss_dice: 1.6499  decode.d3.loss_cls: 1.4907  decode.d3.loss_mask: 0.8604  decode.d3.loss_dice: 1.5721  decode.d4.loss_cls: 1.3601  decode.d4.loss_mask: 0.8376  decode.d4.loss_dice: 1.6068  decode.d5.loss_cls: 1.4101  decode.d5.loss_mask: 0.8437  decode.d5.loss_dice: 1.5804  decode.d6.loss_cls: 1.4359  decode.d6.loss_mask: 0.8371  decode.d6.loss_dice: 1.5349  decode.d7.loss_cls: 1.4046  decode.d7.loss_mask: 0.8158  decode.d7.loss_dice: 1.5392  decode.d8.loss_cls: 1.3975  decode.d8.loss_mask: 0.8251  decode.d8.loss_dice: 1.5386
2023/05/23 22:10:50 - mmengine - INFO - Iter(train) [ 31700/160000]  lr: 8.1978e-06  eta: 15:13:07  time: 0.4113  data_time: 0.0098  memory: 4846  grad_norm: 84.0345  loss: 42.4081  decode.loss_cls: 1.5902  decode.loss_mask: 0.8385  decode.loss_dice: 1.4725  decode.d0.loss_cls: 3.6038  decode.d0.loss_mask: 0.9957  decode.d0.loss_dice: 1.7337  decode.d1.loss_cls: 1.8203  decode.d1.loss_mask: 0.9080  decode.d1.loss_dice: 1.5665  decode.d2.loss_cls: 1.6393  decode.d2.loss_mask: 0.8930  decode.d2.loss_dice: 1.5356  decode.d3.loss_cls: 1.6203  decode.d3.loss_mask: 0.8344  decode.d3.loss_dice: 1.4937  decode.d4.loss_cls: 1.6290  decode.d4.loss_mask: 0.8491  decode.d4.loss_dice: 1.4991  decode.d5.loss_cls: 1.5888  decode.d5.loss_mask: 0.8492  decode.d5.loss_dice: 1.4861  decode.d6.loss_cls: 1.6149  decode.d6.loss_mask: 0.8676  decode.d6.loss_dice: 1.5021  decode.d7.loss_cls: 1.6231  decode.d7.loss_mask: 0.8780  decode.d7.loss_dice: 1.4971  decode.d8.loss_cls: 1.5978  decode.d8.loss_mask: 0.8720  decode.d8.loss_dice: 1.5087
2023/05/23 22:11:10 - mmengine - INFO - Iter(train) [ 31750/160000]  lr: 8.1949e-06  eta: 15:12:42  time: 0.4129  data_time: 0.0098  memory: 4845  grad_norm: 104.6239  loss: 38.6525  decode.loss_cls: 1.2385  decode.loss_mask: 0.8746  decode.loss_dice: 1.5081  decode.d0.loss_cls: 3.0949  decode.d0.loss_mask: 0.8961  decode.d0.loss_dice: 1.6787  decode.d1.loss_cls: 1.3565  decode.d1.loss_mask: 0.8720  decode.d1.loss_dice: 1.6126  decode.d2.loss_cls: 1.3386  decode.d2.loss_mask: 0.8611  decode.d2.loss_dice: 1.6219  decode.d3.loss_cls: 1.2963  decode.d3.loss_mask: 0.8408  decode.d3.loss_dice: 1.4656  decode.d4.loss_cls: 1.2490  decode.d4.loss_mask: 0.8175  decode.d4.loss_dice: 1.5099  decode.d5.loss_cls: 1.2906  decode.d5.loss_mask: 0.8312  decode.d5.loss_dice: 1.5411  decode.d6.loss_cls: 1.3020  decode.d6.loss_mask: 0.8357  decode.d6.loss_dice: 1.4791  decode.d7.loss_cls: 1.2369  decode.d7.loss_mask: 0.8790  decode.d7.loss_dice: 1.4939  decode.d8.loss_cls: 1.2176  decode.d8.loss_mask: 0.8968  decode.d8.loss_dice: 1.5159
2023/05/23 22:11:31 - mmengine - INFO - Iter(train) [ 31800/160000]  lr: 8.1921e-06  eta: 15:12:18  time: 0.4089  data_time: 0.0096  memory: 4857  grad_norm: 119.1626  loss: 35.5056  decode.loss_cls: 1.2349  decode.loss_mask: 0.8276  decode.loss_dice: 1.1817  decode.d0.loss_cls: 3.1953  decode.d0.loss_mask: 0.8746  decode.d0.loss_dice: 1.3276  decode.d1.loss_cls: 1.3919  decode.d1.loss_mask: 0.8890  decode.d1.loss_dice: 1.3006  decode.d2.loss_cls: 1.3152  decode.d2.loss_mask: 0.8885  decode.d2.loss_dice: 1.2717  decode.d3.loss_cls: 1.3244  decode.d3.loss_mask: 0.8411  decode.d3.loss_dice: 1.2128  decode.d4.loss_cls: 1.2346  decode.d4.loss_mask: 0.8649  decode.d4.loss_dice: 1.2411  decode.d5.loss_cls: 1.2516  decode.d5.loss_mask: 0.8694  decode.d5.loss_dice: 1.2101  decode.d6.loss_cls: 1.2779  decode.d6.loss_mask: 0.8290  decode.d6.loss_dice: 1.1862  decode.d7.loss_cls: 1.2327  decode.d7.loss_mask: 0.8245  decode.d7.loss_dice: 1.1924  decode.d8.loss_cls: 1.2264  decode.d8.loss_mask: 0.8176  decode.d8.loss_dice: 1.1704
2023/05/23 22:11:52 - mmengine - INFO - Iter(train) [ 31850/160000]  lr: 8.1892e-06  eta: 15:11:55  time: 0.4200  data_time: 0.0100  memory: 4889  grad_norm: 107.9011  loss: 35.9178  decode.loss_cls: 1.3605  decode.loss_mask: 0.7585  decode.loss_dice: 1.2147  decode.d0.loss_cls: 3.1173  decode.d0.loss_mask: 0.8002  decode.d0.loss_dice: 1.4539  decode.d1.loss_cls: 1.5161  decode.d1.loss_mask: 0.7349  decode.d1.loss_dice: 1.3102  decode.d2.loss_cls: 1.4071  decode.d2.loss_mask: 0.7504  decode.d2.loss_dice: 1.2862  decode.d3.loss_cls: 1.4038  decode.d3.loss_mask: 0.7954  decode.d3.loss_dice: 1.2190  decode.d4.loss_cls: 1.3460  decode.d4.loss_mask: 0.7683  decode.d4.loss_dice: 1.2540  decode.d5.loss_cls: 1.3808  decode.d5.loss_mask: 0.7482  decode.d5.loss_dice: 1.2207  decode.d6.loss_cls: 1.4223  decode.d6.loss_mask: 0.7342  decode.d6.loss_dice: 1.2118  decode.d7.loss_cls: 1.3576  decode.d7.loss_mask: 0.7612  decode.d7.loss_dice: 1.2486  decode.d8.loss_cls: 1.3636  decode.d8.loss_mask: 0.7606  decode.d8.loss_dice: 1.2116
2023/05/23 22:12:12 - mmengine - INFO - Iter(train) [ 31900/160000]  lr: 8.1863e-06  eta: 15:11:31  time: 0.4129  data_time: 0.0095  memory: 4875  grad_norm: 92.8239  loss: 34.7367  decode.loss_cls: 1.3650  decode.loss_mask: 0.7813  decode.loss_dice: 1.1382  decode.d0.loss_cls: 2.9339  decode.d0.loss_mask: 0.8765  decode.d0.loss_dice: 1.2831  decode.d1.loss_cls: 1.4479  decode.d1.loss_mask: 0.8394  decode.d1.loss_dice: 1.2315  decode.d2.loss_cls: 1.5094  decode.d2.loss_mask: 0.7644  decode.d2.loss_dice: 1.1347  decode.d3.loss_cls: 1.3502  decode.d3.loss_mask: 0.7988  decode.d3.loss_dice: 1.1498  decode.d4.loss_cls: 1.3623  decode.d4.loss_mask: 0.7863  decode.d4.loss_dice: 1.1219  decode.d5.loss_cls: 1.3066  decode.d5.loss_mask: 0.7973  decode.d5.loss_dice: 1.1471  decode.d6.loss_cls: 1.3389  decode.d6.loss_mask: 0.7577  decode.d6.loss_dice: 1.1097  decode.d7.loss_cls: 1.3540  decode.d7.loss_mask: 0.7468  decode.d7.loss_dice: 1.0832  decode.d8.loss_cls: 1.4099  decode.d8.loss_mask: 0.7331  decode.d8.loss_dice: 1.0778
2023/05/23 22:12:33 - mmengine - INFO - Iter(train) [ 31950/160000]  lr: 8.1834e-06  eta: 15:11:07  time: 0.4113  data_time: 0.0098  memory: 4859  grad_norm: 103.4275  loss: 40.6340  decode.loss_cls: 1.5351  decode.loss_mask: 0.8603  decode.loss_dice: 1.3099  decode.d0.loss_cls: 3.3006  decode.d0.loss_mask: 0.9703  decode.d0.loss_dice: 1.5540  decode.d1.loss_cls: 1.7839  decode.d1.loss_mask: 0.9270  decode.d1.loss_dice: 1.4848  decode.d2.loss_cls: 1.7038  decode.d2.loss_mask: 0.8903  decode.d2.loss_dice: 1.3929  decode.d3.loss_cls: 1.6716  decode.d3.loss_mask: 0.9017  decode.d3.loss_dice: 1.3451  decode.d4.loss_cls: 1.6769  decode.d4.loss_mask: 0.8434  decode.d4.loss_dice: 1.3225  decode.d5.loss_cls: 1.6691  decode.d5.loss_mask: 0.8426  decode.d5.loss_dice: 1.3288  decode.d6.loss_cls: 1.6277  decode.d6.loss_mask: 0.8530  decode.d6.loss_dice: 1.3073  decode.d7.loss_cls: 1.5906  decode.d7.loss_mask: 0.8573  decode.d7.loss_dice: 1.3097  decode.d8.loss_cls: 1.5889  decode.d8.loss_mask: 0.8663  decode.d8.loss_dice: 1.3185
2023/05/23 22:12:54 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 22:12:54 - mmengine - INFO - Iter(train) [ 32000/160000]  lr: 8.1806e-06  eta: 15:10:42  time: 0.4141  data_time: 0.0105  memory: 4876  grad_norm: 106.7162  loss: 28.5511  decode.loss_cls: 1.0812  decode.loss_mask: 0.6326  decode.loss_dice: 0.9631  decode.d0.loss_cls: 2.6695  decode.d0.loss_mask: 0.6697  decode.d0.loss_dice: 1.1031  decode.d1.loss_cls: 1.1363  decode.d1.loss_mask: 0.6458  decode.d1.loss_dice: 1.0113  decode.d2.loss_cls: 1.0785  decode.d2.loss_mask: 0.6335  decode.d2.loss_dice: 0.9721  decode.d3.loss_cls: 1.0268  decode.d3.loss_mask: 0.6365  decode.d3.loss_dice: 0.9720  decode.d4.loss_cls: 1.1043  decode.d4.loss_mask: 0.6064  decode.d4.loss_dice: 0.9615  decode.d5.loss_cls: 1.0738  decode.d5.loss_mask: 0.6146  decode.d5.loss_dice: 0.9624  decode.d6.loss_cls: 1.0517  decode.d6.loss_mask: 0.6172  decode.d6.loss_dice: 0.9892  decode.d7.loss_cls: 1.0625  decode.d7.loss_mask: 0.6322  decode.d7.loss_dice: 0.9937  decode.d8.loss_cls: 1.0579  decode.d8.loss_mask: 0.6216  decode.d8.loss_dice: 0.9701
2023/05/23 22:12:54 - mmengine - INFO - Saving checkpoint at 32000 iterations
2023/05/23 22:13:20 - mmengine - INFO - Iter(train) [ 32050/160000]  lr: 8.1777e-06  eta: 15:10:40  time: 0.4144  data_time: 0.0099  memory: 4829  grad_norm: 138.7965  loss: 38.0464  decode.loss_cls: 1.3744  decode.loss_mask: 0.9127  decode.loss_dice: 1.2726  decode.d0.loss_cls: 3.3147  decode.d0.loss_mask: 0.9215  decode.d0.loss_dice: 1.4607  decode.d1.loss_cls: 1.3153  decode.d1.loss_mask: 0.9851  decode.d1.loss_dice: 1.3742  decode.d2.loss_cls: 1.2819  decode.d2.loss_mask: 0.9830  decode.d2.loss_dice: 1.3708  decode.d3.loss_cls: 1.3539  decode.d3.loss_mask: 0.9668  decode.d3.loss_dice: 1.2906  decode.d4.loss_cls: 1.2997  decode.d4.loss_mask: 0.9763  decode.d4.loss_dice: 1.2885  decode.d5.loss_cls: 1.3418  decode.d5.loss_mask: 0.9401  decode.d5.loss_dice: 1.3078  decode.d6.loss_cls: 1.3641  decode.d6.loss_mask: 0.9423  decode.d6.loss_dice: 1.2696  decode.d7.loss_cls: 1.3158  decode.d7.loss_mask: 0.9484  decode.d7.loss_dice: 1.2840  decode.d8.loss_cls: 1.3382  decode.d8.loss_mask: 0.9672  decode.d8.loss_dice: 1.2846
2023/05/23 22:13:40 - mmengine - INFO - Iter(train) [ 32100/160000]  lr: 8.1748e-06  eta: 15:10:15  time: 0.4060  data_time: 0.0097  memory: 4818  grad_norm: 95.3359  loss: 36.3019  decode.loss_cls: 1.2479  decode.loss_mask: 0.6534  decode.loss_dice: 1.4343  decode.d0.loss_cls: 2.9844  decode.d0.loss_mask: 0.7598  decode.d0.loss_dice: 1.6902  decode.d1.loss_cls: 1.4255  decode.d1.loss_mask: 0.6735  decode.d1.loss_dice: 1.5926  decode.d2.loss_cls: 1.3259  decode.d2.loss_mask: 0.6714  decode.d2.loss_dice: 1.5263  decode.d3.loss_cls: 1.3178  decode.d3.loss_mask: 0.6650  decode.d3.loss_dice: 1.4968  decode.d4.loss_cls: 1.2823  decode.d4.loss_mask: 0.6640  decode.d4.loss_dice: 1.4678  decode.d5.loss_cls: 1.2437  decode.d5.loss_mask: 0.6659  decode.d5.loss_dice: 1.4641  decode.d6.loss_cls: 1.2518  decode.d6.loss_mask: 0.6672  decode.d6.loss_dice: 1.4428  decode.d7.loss_cls: 1.2348  decode.d7.loss_mask: 0.6768  decode.d7.loss_dice: 1.4130  decode.d8.loss_cls: 1.2457  decode.d8.loss_mask: 0.6598  decode.d8.loss_dice: 1.4574
2023/05/23 22:14:02 - mmengine - INFO - Iter(train) [ 32150/160000]  lr: 8.1719e-06  eta: 15:09:55  time: 0.4056  data_time: 0.0101  memory: 4836  grad_norm: 123.5759  loss: 36.7962  decode.loss_cls: 1.3670  decode.loss_mask: 0.8446  decode.loss_dice: 1.1908  decode.d0.loss_cls: 3.2649  decode.d0.loss_mask: 0.8589  decode.d0.loss_dice: 1.4104  decode.d1.loss_cls: 1.4991  decode.d1.loss_mask: 0.8488  decode.d1.loss_dice: 1.3067  decode.d2.loss_cls: 1.3591  decode.d2.loss_mask: 0.8647  decode.d2.loss_dice: 1.2525  decode.d3.loss_cls: 1.3706  decode.d3.loss_mask: 0.8693  decode.d3.loss_dice: 1.2512  decode.d4.loss_cls: 1.3574  decode.d4.loss_mask: 0.8589  decode.d4.loss_dice: 1.2234  decode.d5.loss_cls: 1.3972  decode.d5.loss_mask: 0.8441  decode.d5.loss_dice: 1.2285  decode.d6.loss_cls: 1.3874  decode.d6.loss_mask: 0.8433  decode.d6.loss_dice: 1.2196  decode.d7.loss_cls: 1.3681  decode.d7.loss_mask: 0.8398  decode.d7.loss_dice: 1.2285  decode.d8.loss_cls: 1.3585  decode.d8.loss_mask: 0.8482  decode.d8.loss_dice: 1.2347
2023/05/23 22:14:23 - mmengine - INFO - Iter(train) [ 32200/160000]  lr: 8.1691e-06  eta: 15:09:32  time: 0.4264  data_time: 0.0099  memory: 4841  grad_norm: 93.7137  loss: 38.8083  decode.loss_cls: 1.5523  decode.loss_mask: 0.8418  decode.loss_dice: 1.1979  decode.d0.loss_cls: 3.4202  decode.d0.loss_mask: 0.9355  decode.d0.loss_dice: 1.3954  decode.d1.loss_cls: 1.5912  decode.d1.loss_mask: 0.8987  decode.d1.loss_dice: 1.3692  decode.d2.loss_cls: 1.5940  decode.d2.loss_mask: 0.8560  decode.d2.loss_dice: 1.2668  decode.d3.loss_cls: 1.5452  decode.d3.loss_mask: 0.8449  decode.d3.loss_dice: 1.2803  decode.d4.loss_cls: 1.5492  decode.d4.loss_mask: 0.8444  decode.d4.loss_dice: 1.3072  decode.d5.loss_cls: 1.5095  decode.d5.loss_mask: 0.8307  decode.d5.loss_dice: 1.2340  decode.d6.loss_cls: 1.5809  decode.d6.loss_mask: 0.8592  decode.d6.loss_dice: 1.2649  decode.d7.loss_cls: 1.5251  decode.d7.loss_mask: 0.8473  decode.d7.loss_dice: 1.2267  decode.d8.loss_cls: 1.5921  decode.d8.loss_mask: 0.8386  decode.d8.loss_dice: 1.2092
2023/05/23 22:14:46 - mmengine - INFO - Iter(train) [ 32250/160000]  lr: 8.1662e-06  eta: 15:09:17  time: 0.4590  data_time: 0.0095  memory: 4957  grad_norm: 100.6319  loss: 35.5881  decode.loss_cls: 1.3398  decode.loss_mask: 0.7527  decode.loss_dice: 1.2102  decode.d0.loss_cls: 3.3118  decode.d0.loss_mask: 0.8959  decode.d0.loss_dice: 1.4008  decode.d1.loss_cls: 1.3683  decode.d1.loss_mask: 0.8277  decode.d1.loss_dice: 1.3599  decode.d2.loss_cls: 1.3242  decode.d2.loss_mask: 0.7868  decode.d2.loss_dice: 1.2189  decode.d3.loss_cls: 1.2778  decode.d3.loss_mask: 0.7690  decode.d3.loss_dice: 1.1960  decode.d4.loss_cls: 1.2747  decode.d4.loss_mask: 0.7694  decode.d4.loss_dice: 1.2199  decode.d5.loss_cls: 1.3324  decode.d5.loss_mask: 0.7831  decode.d5.loss_dice: 1.2201  decode.d6.loss_cls: 1.3107  decode.d6.loss_mask: 0.7614  decode.d6.loss_dice: 1.2174  decode.d7.loss_cls: 1.3261  decode.d7.loss_mask: 0.7647  decode.d7.loss_dice: 1.2282  decode.d8.loss_cls: 1.3250  decode.d8.loss_mask: 0.7654  decode.d8.loss_dice: 1.2496
2023/05/23 22:15:06 - mmengine - INFO - Iter(train) [ 32300/160000]  lr: 8.1633e-06  eta: 15:08:53  time: 0.4088  data_time: 0.0097  memory: 4846  grad_norm: 91.9292  loss: 45.0440  decode.loss_cls: 1.5308  decode.loss_mask: 0.9904  decode.loss_dice: 1.7196  decode.d0.loss_cls: 3.5767  decode.d0.loss_mask: 1.0030  decode.d0.loss_dice: 1.9309  decode.d1.loss_cls: 1.6593  decode.d1.loss_mask: 1.0517  decode.d1.loss_dice: 1.8396  decode.d2.loss_cls: 1.6000  decode.d2.loss_mask: 1.0239  decode.d2.loss_dice: 1.7664  decode.d3.loss_cls: 1.5460  decode.d3.loss_mask: 0.9899  decode.d3.loss_dice: 1.7000  decode.d4.loss_cls: 1.5296  decode.d4.loss_mask: 0.9801  decode.d4.loss_dice: 1.7373  decode.d5.loss_cls: 1.5674  decode.d5.loss_mask: 0.9536  decode.d5.loss_dice: 1.7415  decode.d6.loss_cls: 1.4726  decode.d6.loss_mask: 0.9821  decode.d6.loss_dice: 1.7166  decode.d7.loss_cls: 1.5036  decode.d7.loss_mask: 0.9946  decode.d7.loss_dice: 1.7118  decode.d8.loss_cls: 1.4967  decode.d8.loss_mask: 1.0118  decode.d8.loss_dice: 1.7165
2023/05/23 22:15:27 - mmengine - INFO - Iter(train) [ 32350/160000]  lr: 8.1604e-06  eta: 15:08:28  time: 0.4144  data_time: 0.0101  memory: 4869  grad_norm: 138.1628  loss: 41.2496  decode.loss_cls: 1.3648  decode.loss_mask: 0.8384  decode.loss_dice: 1.6442  decode.d0.loss_cls: 3.4775  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 1.8549  decode.d1.loss_cls: 1.5344  decode.d1.loss_mask: 0.8836  decode.d1.loss_dice: 1.7509  decode.d2.loss_cls: 1.4382  decode.d2.loss_mask: 0.8392  decode.d2.loss_dice: 1.6721  decode.d3.loss_cls: 1.3796  decode.d3.loss_mask: 0.8382  decode.d3.loss_dice: 1.6385  decode.d4.loss_cls: 1.3458  decode.d4.loss_mask: 0.8422  decode.d4.loss_dice: 1.6458  decode.d5.loss_cls: 1.3221  decode.d5.loss_mask: 0.8359  decode.d5.loss_dice: 1.6824  decode.d6.loss_cls: 1.3539  decode.d6.loss_mask: 0.8341  decode.d6.loss_dice: 1.6190  decode.d7.loss_cls: 1.3331  decode.d7.loss_mask: 0.8286  decode.d7.loss_dice: 1.6536  decode.d8.loss_cls: 1.3580  decode.d8.loss_mask: 0.8246  decode.d8.loss_dice: 1.6673
2023/05/23 22:15:48 - mmengine - INFO - Iter(train) [ 32400/160000]  lr: 8.1576e-06  eta: 15:08:04  time: 0.4128  data_time: 0.0097  memory: 4844  grad_norm: 125.3993  loss: 34.5343  decode.loss_cls: 1.0437  decode.loss_mask: 0.9454  decode.loss_dice: 1.1790  decode.d0.loss_cls: 2.8853  decode.d0.loss_mask: 0.9766  decode.d0.loss_dice: 1.3414  decode.d1.loss_cls: 1.1786  decode.d1.loss_mask: 1.0134  decode.d1.loss_dice: 1.2542  decode.d2.loss_cls: 1.2136  decode.d2.loss_mask: 0.9463  decode.d2.loss_dice: 1.1766  decode.d3.loss_cls: 1.1165  decode.d3.loss_mask: 0.9653  decode.d3.loss_dice: 1.2279  decode.d4.loss_cls: 1.0551  decode.d4.loss_mask: 0.9635  decode.d4.loss_dice: 1.2255  decode.d5.loss_cls: 1.0278  decode.d5.loss_mask: 0.9847  decode.d5.loss_dice: 1.2164  decode.d6.loss_cls: 1.0648  decode.d6.loss_mask: 0.9755  decode.d6.loss_dice: 1.1661  decode.d7.loss_cls: 1.1406  decode.d7.loss_mask: 0.8922  decode.d7.loss_dice: 1.1751  decode.d8.loss_cls: 1.0946  decode.d8.loss_mask: 0.9276  decode.d8.loss_dice: 1.1607
2023/05/23 22:16:09 - mmengine - INFO - Iter(train) [ 32450/160000]  lr: 8.1547e-06  eta: 15:07:41  time: 0.4204  data_time: 0.0099  memory: 4844  grad_norm: 114.2516  loss: 35.8299  decode.loss_cls: 1.3713  decode.loss_mask: 0.7325  decode.loss_dice: 1.1173  decode.d0.loss_cls: 3.5043  decode.d0.loss_mask: 0.8261  decode.d0.loss_dice: 1.4554  decode.d1.loss_cls: 1.5546  decode.d1.loss_mask: 0.7639  decode.d1.loss_dice: 1.3575  decode.d2.loss_cls: 1.5164  decode.d2.loss_mask: 0.7074  decode.d2.loss_dice: 1.2362  decode.d3.loss_cls: 1.4851  decode.d3.loss_mask: 0.6890  decode.d3.loss_dice: 1.1232  decode.d4.loss_cls: 1.4401  decode.d4.loss_mask: 0.6710  decode.d4.loss_dice: 1.1302  decode.d5.loss_cls: 1.4546  decode.d5.loss_mask: 0.7200  decode.d5.loss_dice: 1.1526  decode.d6.loss_cls: 1.3899  decode.d6.loss_mask: 0.7450  decode.d6.loss_dice: 1.1420  decode.d7.loss_cls: 1.3336  decode.d7.loss_mask: 0.7633  decode.d7.loss_dice: 1.1865  decode.d8.loss_cls: 1.3309  decode.d8.loss_mask: 0.7585  decode.d8.loss_dice: 1.1717
2023/05/23 22:16:30 - mmengine - INFO - Iter(train) [ 32500/160000]  lr: 8.1518e-06  eta: 15:07:19  time: 0.4134  data_time: 0.0103  memory: 4845  grad_norm: 103.5613  loss: 36.6598  decode.loss_cls: 1.4677  decode.loss_mask: 0.8260  decode.loss_dice: 1.1118  decode.d0.loss_cls: 3.2697  decode.d0.loss_mask: 0.9161  decode.d0.loss_dice: 1.3065  decode.d1.loss_cls: 1.6161  decode.d1.loss_mask: 0.9085  decode.d1.loss_dice: 1.2613  decode.d2.loss_cls: 1.4784  decode.d2.loss_mask: 0.8807  decode.d2.loss_dice: 1.1845  decode.d3.loss_cls: 1.4238  decode.d3.loss_mask: 0.8358  decode.d3.loss_dice: 1.1220  decode.d4.loss_cls: 1.3678  decode.d4.loss_mask: 0.8661  decode.d4.loss_dice: 1.1569  decode.d5.loss_cls: 1.3780  decode.d5.loss_mask: 0.8898  decode.d5.loss_dice: 1.1647  decode.d6.loss_cls: 1.4219  decode.d6.loss_mask: 0.8483  decode.d6.loss_dice: 1.1372  decode.d7.loss_cls: 1.4599  decode.d7.loss_mask: 0.8385  decode.d7.loss_dice: 1.0975  decode.d8.loss_cls: 1.4851  decode.d8.loss_mask: 0.8263  decode.d8.loss_dice: 1.1126
2023/05/23 22:16:50 - mmengine - INFO - Iter(train) [ 32550/160000]  lr: 8.1489e-06  eta: 15:06:54  time: 0.4094  data_time: 0.0097  memory: 4836  grad_norm: 96.3197  loss: 34.3814  decode.loss_cls: 1.1698  decode.loss_mask: 0.7474  decode.loss_dice: 1.2818  decode.d0.loss_cls: 3.0713  decode.d0.loss_mask: 0.7501  decode.d0.loss_dice: 1.3994  decode.d1.loss_cls: 1.4073  decode.d1.loss_mask: 0.6975  decode.d1.loss_dice: 1.3395  decode.d2.loss_cls: 1.2672  decode.d2.loss_mask: 0.6815  decode.d2.loss_dice: 1.3522  decode.d3.loss_cls: 1.2328  decode.d3.loss_mask: 0.6629  decode.d3.loss_dice: 1.2697  decode.d4.loss_cls: 1.2437  decode.d4.loss_mask: 0.6637  decode.d4.loss_dice: 1.2749  decode.d5.loss_cls: 1.2728  decode.d5.loss_mask: 0.6821  decode.d5.loss_dice: 1.3086  decode.d6.loss_cls: 1.2010  decode.d6.loss_mask: 0.6885  decode.d6.loss_dice: 1.3246  decode.d7.loss_cls: 1.2088  decode.d7.loss_mask: 0.6840  decode.d7.loss_dice: 1.3068  decode.d8.loss_cls: 1.1683  decode.d8.loss_mask: 0.7464  decode.d8.loss_dice: 1.2768
2023/05/23 22:17:11 - mmengine - INFO - Iter(train) [ 32600/160000]  lr: 8.1460e-06  eta: 15:06:31  time: 0.4212  data_time: 0.0098  memory: 4889  grad_norm: 114.5971  loss: 35.8160  decode.loss_cls: 1.3640  decode.loss_mask: 0.6809  decode.loss_dice: 1.3416  decode.d0.loss_cls: 3.1918  decode.d0.loss_mask: 0.6658  decode.d0.loss_dice: 1.4876  decode.d1.loss_cls: 1.5039  decode.d1.loss_mask: 0.6939  decode.d1.loss_dice: 1.3817  decode.d2.loss_cls: 1.3324  decode.d2.loss_mask: 0.6881  decode.d2.loss_dice: 1.3845  decode.d3.loss_cls: 1.3256  decode.d3.loss_mask: 0.6842  decode.d3.loss_dice: 1.3264  decode.d4.loss_cls: 1.2978  decode.d4.loss_mask: 0.6839  decode.d4.loss_dice: 1.3824  decode.d5.loss_cls: 1.3295  decode.d5.loss_mask: 0.6832  decode.d5.loss_dice: 1.3493  decode.d6.loss_cls: 1.2873  decode.d6.loss_mask: 0.7013  decode.d6.loss_dice: 1.3397  decode.d7.loss_cls: 1.3778  decode.d7.loss_mask: 0.6776  decode.d7.loss_dice: 1.3150  decode.d8.loss_cls: 1.2804  decode.d8.loss_mask: 0.6967  decode.d8.loss_dice: 1.3618
2023/05/23 22:17:32 - mmengine - INFO - Iter(train) [ 32650/160000]  lr: 8.1432e-06  eta: 15:06:08  time: 0.4151  data_time: 0.0105  memory: 4784  grad_norm: 137.8121  loss: 34.3262  decode.loss_cls: 1.1980  decode.loss_mask: 0.8021  decode.loss_dice: 1.1270  decode.d0.loss_cls: 3.3274  decode.d0.loss_mask: 0.8003  decode.d0.loss_dice: 1.3286  decode.d1.loss_cls: 1.5129  decode.d1.loss_mask: 0.7800  decode.d1.loss_dice: 1.2573  decode.d2.loss_cls: 1.3253  decode.d2.loss_mask: 0.8007  decode.d2.loss_dice: 1.1491  decode.d3.loss_cls: 1.2908  decode.d3.loss_mask: 0.7583  decode.d3.loss_dice: 1.1061  decode.d4.loss_cls: 1.2579  decode.d4.loss_mask: 0.7649  decode.d4.loss_dice: 1.1122  decode.d5.loss_cls: 1.2578  decode.d5.loss_mask: 0.7936  decode.d5.loss_dice: 1.1132  decode.d6.loss_cls: 1.2016  decode.d6.loss_mask: 0.8194  decode.d6.loss_dice: 1.1155  decode.d7.loss_cls: 1.1968  decode.d7.loss_mask: 0.8110  decode.d7.loss_dice: 1.1477  decode.d8.loss_cls: 1.2030  decode.d8.loss_mask: 0.8264  decode.d8.loss_dice: 1.1413
2023/05/23 22:17:53 - mmengine - INFO - Iter(train) [ 32700/160000]  lr: 8.1403e-06  eta: 15:05:45  time: 0.4134  data_time: 0.0096  memory: 4835  grad_norm: 93.7907  loss: 35.9336  decode.loss_cls: 1.2450  decode.loss_mask: 0.7526  decode.loss_dice: 1.2804  decode.d0.loss_cls: 3.4862  decode.d0.loss_mask: 0.8123  decode.d0.loss_dice: 1.5304  decode.d1.loss_cls: 1.3487  decode.d1.loss_mask: 0.7553  decode.d1.loss_dice: 1.3761  decode.d2.loss_cls: 1.3252  decode.d2.loss_mask: 0.7531  decode.d2.loss_dice: 1.3497  decode.d3.loss_cls: 1.2335  decode.d3.loss_mask: 0.7635  decode.d3.loss_dice: 1.3254  decode.d4.loss_cls: 1.2455  decode.d4.loss_mask: 0.7710  decode.d4.loss_dice: 1.3413  decode.d5.loss_cls: 1.2398  decode.d5.loss_mask: 0.7725  decode.d5.loss_dice: 1.3001  decode.d6.loss_cls: 1.2031  decode.d6.loss_mask: 0.7757  decode.d6.loss_dice: 1.3280  decode.d7.loss_cls: 1.2203  decode.d7.loss_mask: 0.8042  decode.d7.loss_dice: 1.3276  decode.d8.loss_cls: 1.2659  decode.d8.loss_mask: 0.7349  decode.d8.loss_dice: 1.2664
2023/05/23 22:18:14 - mmengine - INFO - Iter(train) [ 32750/160000]  lr: 8.1374e-06  eta: 15:05:21  time: 0.4488  data_time: 0.0101  memory: 4875  grad_norm: 115.3315  loss: 41.0076  decode.loss_cls: 1.5475  decode.loss_mask: 0.7942  decode.loss_dice: 1.4860  decode.d0.loss_cls: 3.3193  decode.d0.loss_mask: 0.8465  decode.d0.loss_dice: 1.7111  decode.d1.loss_cls: 1.6053  decode.d1.loss_mask: 0.8428  decode.d1.loss_dice: 1.6623  decode.d2.loss_cls: 1.6804  decode.d2.loss_mask: 0.8273  decode.d2.loss_dice: 1.5814  decode.d3.loss_cls: 1.5730  decode.d3.loss_mask: 0.8259  decode.d3.loss_dice: 1.5137  decode.d4.loss_cls: 1.5083  decode.d4.loss_mask: 0.8221  decode.d4.loss_dice: 1.5156  decode.d5.loss_cls: 1.4889  decode.d5.loss_mask: 0.8251  decode.d5.loss_dice: 1.5283  decode.d6.loss_cls: 1.5145  decode.d6.loss_mask: 0.8361  decode.d6.loss_dice: 1.4999  decode.d7.loss_cls: 1.5143  decode.d7.loss_mask: 0.8137  decode.d7.loss_dice: 1.4933  decode.d8.loss_cls: 1.5512  decode.d8.loss_mask: 0.8084  decode.d8.loss_dice: 1.4715
2023/05/23 22:18:36 - mmengine - INFO - Iter(train) [ 32800/160000]  lr: 8.1345e-06  eta: 15:05:04  time: 0.4169  data_time: 0.0101  memory: 4850  grad_norm: 96.7385  loss: 39.9304  decode.loss_cls: 1.4285  decode.loss_mask: 0.9043  decode.loss_dice: 1.4499  decode.d0.loss_cls: 3.3444  decode.d0.loss_mask: 0.9298  decode.d0.loss_dice: 1.6731  decode.d1.loss_cls: 1.5406  decode.d1.loss_mask: 0.8733  decode.d1.loss_dice: 1.4959  decode.d2.loss_cls: 1.4187  decode.d2.loss_mask: 0.8838  decode.d2.loss_dice: 1.4733  decode.d3.loss_cls: 1.4214  decode.d3.loss_mask: 0.8949  decode.d3.loss_dice: 1.4396  decode.d4.loss_cls: 1.4075  decode.d4.loss_mask: 0.8931  decode.d4.loss_dice: 1.4550  decode.d5.loss_cls: 1.4575  decode.d5.loss_mask: 0.8664  decode.d5.loss_dice: 1.4991  decode.d6.loss_cls: 1.4338  decode.d6.loss_mask: 0.8910  decode.d6.loss_dice: 1.4111  decode.d7.loss_cls: 1.3564  decode.d7.loss_mask: 0.9140  decode.d7.loss_dice: 1.4520  decode.d8.loss_cls: 1.3729  decode.d8.loss_mask: 0.9079  decode.d8.loss_dice: 1.4412
2023/05/23 22:18:57 - mmengine - INFO - Iter(train) [ 32850/160000]  lr: 8.1317e-06  eta: 15:04:41  time: 0.4210  data_time: 0.0103  memory: 4857  grad_norm: 96.2502  loss: 38.4169  decode.loss_cls: 1.2890  decode.loss_mask: 0.8789  decode.loss_dice: 1.3905  decode.d0.loss_cls: 3.2112  decode.d0.loss_mask: 0.8909  decode.d0.loss_dice: 1.4976  decode.d1.loss_cls: 1.5206  decode.d1.loss_mask: 0.8775  decode.d1.loss_dice: 1.4514  decode.d2.loss_cls: 1.3969  decode.d2.loss_mask: 0.8709  decode.d2.loss_dice: 1.4365  decode.d3.loss_cls: 1.3905  decode.d3.loss_mask: 0.8886  decode.d3.loss_dice: 1.4411  decode.d4.loss_cls: 1.3315  decode.d4.loss_mask: 0.8684  decode.d4.loss_dice: 1.4327  decode.d5.loss_cls: 1.2921  decode.d5.loss_mask: 0.8886  decode.d5.loss_dice: 1.4227  decode.d6.loss_cls: 1.3397  decode.d6.loss_mask: 0.8702  decode.d6.loss_dice: 1.3985  decode.d7.loss_cls: 1.3386  decode.d7.loss_mask: 0.8585  decode.d7.loss_dice: 1.3975  decode.d8.loss_cls: 1.3245  decode.d8.loss_mask: 0.8676  decode.d8.loss_dice: 1.3534
2023/05/23 22:19:18 - mmengine - INFO - Iter(train) [ 32900/160000]  lr: 8.1288e-06  eta: 15:04:17  time: 0.4214  data_time: 0.0100  memory: 4829  grad_norm: 100.9640  loss: 29.3765  decode.loss_cls: 0.9843  decode.loss_mask: 0.7102  decode.loss_dice: 0.9675  decode.d0.loss_cls: 2.9662  decode.d0.loss_mask: 0.7839  decode.d0.loss_dice: 1.1514  decode.d1.loss_cls: 1.1096  decode.d1.loss_mask: 0.7239  decode.d1.loss_dice: 1.0454  decode.d2.loss_cls: 0.9820  decode.d2.loss_mask: 0.7616  decode.d2.loss_dice: 1.0663  decode.d3.loss_cls: 0.9914  decode.d3.loss_mask: 0.7356  decode.d3.loss_dice: 0.9613  decode.d4.loss_cls: 1.0116  decode.d4.loss_mask: 0.7061  decode.d4.loss_dice: 0.9793  decode.d5.loss_cls: 1.0561  decode.d5.loss_mask: 0.6886  decode.d5.loss_dice: 0.9288  decode.d6.loss_cls: 1.0351  decode.d6.loss_mask: 0.6880  decode.d6.loss_dice: 0.9660  decode.d7.loss_cls: 0.9724  decode.d7.loss_mask: 0.7100  decode.d7.loss_dice: 1.0004  decode.d8.loss_cls: 1.0185  decode.d8.loss_mask: 0.7138  decode.d8.loss_dice: 0.9612
2023/05/23 22:19:38 - mmengine - INFO - Iter(train) [ 32950/160000]  lr: 8.1259e-06  eta: 15:03:54  time: 0.4354  data_time: 0.0094  memory: 4845  grad_norm: 126.1348  loss: 37.0900  decode.loss_cls: 1.3047  decode.loss_mask: 0.6962  decode.loss_dice: 1.3621  decode.d0.loss_cls: 3.4534  decode.d0.loss_mask: 0.8000  decode.d0.loss_dice: 1.6180  decode.d1.loss_cls: 1.4848  decode.d1.loss_mask: 0.7463  decode.d1.loss_dice: 1.4658  decode.d2.loss_cls: 1.3637  decode.d2.loss_mask: 0.7476  decode.d2.loss_dice: 1.4328  decode.d3.loss_cls: 1.3682  decode.d3.loss_mask: 0.7455  decode.d3.loss_dice: 1.3997  decode.d4.loss_cls: 1.3608  decode.d4.loss_mask: 0.7237  decode.d4.loss_dice: 1.3858  decode.d5.loss_cls: 1.3376  decode.d5.loss_mask: 0.6928  decode.d5.loss_dice: 1.3902  decode.d6.loss_cls: 1.3492  decode.d6.loss_mask: 0.6835  decode.d6.loss_dice: 1.3533  decode.d7.loss_cls: 1.3411  decode.d7.loss_mask: 0.6892  decode.d7.loss_dice: 1.3748  decode.d8.loss_cls: 1.3510  decode.d8.loss_mask: 0.7064  decode.d8.loss_dice: 1.3615
2023/05/23 22:19:59 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 22:19:59 - mmengine - INFO - Iter(train) [ 33000/160000]  lr: 8.1230e-06  eta: 15:03:30  time: 0.4221  data_time: 0.0098  memory: 4846  grad_norm: 111.0622  loss: 42.0832  decode.loss_cls: 1.7630  decode.loss_mask: 0.8372  decode.loss_dice: 1.4324  decode.d0.loss_cls: 3.3329  decode.d0.loss_mask: 0.9112  decode.d0.loss_dice: 1.6753  decode.d1.loss_cls: 1.7046  decode.d1.loss_mask: 0.8665  decode.d1.loss_dice: 1.5767  decode.d2.loss_cls: 1.7544  decode.d2.loss_mask: 0.8514  decode.d2.loss_dice: 1.4800  decode.d3.loss_cls: 1.6874  decode.d3.loss_mask: 0.8417  decode.d3.loss_dice: 1.4506  decode.d4.loss_cls: 1.6999  decode.d4.loss_mask: 0.8528  decode.d4.loss_dice: 1.4578  decode.d5.loss_cls: 1.7171  decode.d5.loss_mask: 0.8309  decode.d5.loss_dice: 1.4307  decode.d6.loss_cls: 1.6734  decode.d6.loss_mask: 0.8389  decode.d6.loss_dice: 1.4599  decode.d7.loss_cls: 1.6862  decode.d7.loss_mask: 0.8408  decode.d7.loss_dice: 1.4632  decode.d8.loss_cls: 1.6796  decode.d8.loss_mask: 0.8494  decode.d8.loss_dice: 1.4374
2023/05/23 22:19:59 - mmengine - INFO - Saving checkpoint at 33000 iterations
2023/05/23 22:20:25 - mmengine - INFO - Iter(train) [ 33050/160000]  lr: 8.1201e-06  eta: 15:03:26  time: 0.4133  data_time: 0.0097  memory: 4818  grad_norm: 88.0258  loss: 35.2336  decode.loss_cls: 1.5184  decode.loss_mask: 0.6739  decode.loss_dice: 1.1117  decode.d0.loss_cls: 3.2040  decode.d0.loss_mask: 0.7200  decode.d0.loss_dice: 1.2662  decode.d1.loss_cls: 1.6817  decode.d1.loss_mask: 0.6927  decode.d1.loss_dice: 1.2198  decode.d2.loss_cls: 1.5735  decode.d2.loss_mask: 0.6709  decode.d2.loss_dice: 1.1340  decode.d3.loss_cls: 1.4851  decode.d3.loss_mask: 0.6441  decode.d3.loss_dice: 1.1213  decode.d4.loss_cls: 1.5649  decode.d4.loss_mask: 0.6776  decode.d4.loss_dice: 1.1699  decode.d5.loss_cls: 1.5085  decode.d5.loss_mask: 0.6704  decode.d5.loss_dice: 1.0981  decode.d6.loss_cls: 1.5067  decode.d6.loss_mask: 0.6663  decode.d6.loss_dice: 1.1100  decode.d7.loss_cls: 1.4804  decode.d7.loss_mask: 0.6358  decode.d7.loss_dice: 1.0726  decode.d8.loss_cls: 1.5512  decode.d8.loss_mask: 0.6668  decode.d8.loss_dice: 1.1370
2023/05/23 22:20:46 - mmengine - INFO - Iter(train) [ 33100/160000]  lr: 8.1173e-06  eta: 15:03:03  time: 0.4269  data_time: 0.0096  memory: 4866  grad_norm: 169.3854  loss: 37.4178  decode.loss_cls: 1.3879  decode.loss_mask: 0.8434  decode.loss_dice: 1.2283  decode.d0.loss_cls: 3.3195  decode.d0.loss_mask: 0.8606  decode.d0.loss_dice: 1.4430  decode.d1.loss_cls: 1.5838  decode.d1.loss_mask: 0.8723  decode.d1.loss_dice: 1.3579  decode.d2.loss_cls: 1.4630  decode.d2.loss_mask: 0.8908  decode.d2.loss_dice: 1.2655  decode.d3.loss_cls: 1.4549  decode.d3.loss_mask: 0.8637  decode.d3.loss_dice: 1.2431  decode.d4.loss_cls: 1.3796  decode.d4.loss_mask: 0.8354  decode.d4.loss_dice: 1.2446  decode.d5.loss_cls: 1.4111  decode.d5.loss_mask: 0.8231  decode.d5.loss_dice: 1.2652  decode.d6.loss_cls: 1.4062  decode.d6.loss_mask: 0.8108  decode.d6.loss_dice: 1.2516  decode.d7.loss_cls: 1.3849  decode.d7.loss_mask: 0.8183  decode.d7.loss_dice: 1.2393  decode.d8.loss_cls: 1.3660  decode.d8.loss_mask: 0.8354  decode.d8.loss_dice: 1.2689
2023/05/23 22:21:08 - mmengine - INFO - Iter(train) [ 33150/160000]  lr: 8.1144e-06  eta: 15:02:44  time: 0.4153  data_time: 0.0100  memory: 4819  grad_norm: 111.4734  loss: 39.0698  decode.loss_cls: 1.0832  decode.loss_mask: 1.0041  decode.loss_dice: 1.4673  decode.d0.loss_cls: 3.1172  decode.d0.loss_mask: 0.9737  decode.d0.loss_dice: 1.7384  decode.d1.loss_cls: 1.2477  decode.d1.loss_mask: 0.9603  decode.d1.loss_dice: 1.6146  decode.d2.loss_cls: 1.2255  decode.d2.loss_mask: 0.9872  decode.d2.loss_dice: 1.5756  decode.d3.loss_cls: 1.1709  decode.d3.loss_mask: 0.9715  decode.d3.loss_dice: 1.4801  decode.d4.loss_cls: 1.2257  decode.d4.loss_mask: 0.9907  decode.d4.loss_dice: 1.5078  decode.d5.loss_cls: 1.3210  decode.d5.loss_mask: 0.9285  decode.d5.loss_dice: 1.4930  decode.d6.loss_cls: 1.2385  decode.d6.loss_mask: 0.9767  decode.d6.loss_dice: 1.4911  decode.d7.loss_cls: 1.1117  decode.d7.loss_mask: 1.0092  decode.d7.loss_dice: 1.5180  decode.d8.loss_cls: 1.1133  decode.d8.loss_mask: 1.0127  decode.d8.loss_dice: 1.5145
2023/05/23 22:21:29 - mmengine - INFO - Iter(train) [ 33200/160000]  lr: 8.1115e-06  eta: 15:02:23  time: 0.4639  data_time: 0.0101  memory: 4886  grad_norm: 96.0035  loss: 35.4596  decode.loss_cls: 1.2497  decode.loss_mask: 0.8020  decode.loss_dice: 1.2207  decode.d0.loss_cls: 2.9518  decode.d0.loss_mask: 0.9110  decode.d0.loss_dice: 1.4284  decode.d1.loss_cls: 1.4740  decode.d1.loss_mask: 0.8460  decode.d1.loss_dice: 1.2409  decode.d2.loss_cls: 1.3214  decode.d2.loss_mask: 0.8392  decode.d2.loss_dice: 1.2709  decode.d3.loss_cls: 1.3406  decode.d3.loss_mask: 0.8190  decode.d3.loss_dice: 1.2233  decode.d4.loss_cls: 1.3023  decode.d4.loss_mask: 0.8264  decode.d4.loss_dice: 1.1848  decode.d5.loss_cls: 1.2944  decode.d5.loss_mask: 0.8121  decode.d5.loss_dice: 1.1800  decode.d6.loss_cls: 1.3053  decode.d6.loss_mask: 0.8076  decode.d6.loss_dice: 1.1991  decode.d7.loss_cls: 1.3226  decode.d7.loss_mask: 0.8011  decode.d7.loss_dice: 1.2002  decode.d8.loss_cls: 1.2866  decode.d8.loss_mask: 0.7908  decode.d8.loss_dice: 1.2073
2023/05/23 22:21:51 - mmengine - INFO - Iter(train) [ 33250/160000]  lr: 8.1086e-06  eta: 15:02:01  time: 0.4222  data_time: 0.0103  memory: 4787  grad_norm: 115.5856  loss: 32.0518  decode.loss_cls: 1.0806  decode.loss_mask: 0.6801  decode.loss_dice: 1.1183  decode.d0.loss_cls: 2.8851  decode.d0.loss_mask: 0.7153  decode.d0.loss_dice: 1.3604  decode.d1.loss_cls: 1.1697  decode.d1.loss_mask: 0.7901  decode.d1.loss_dice: 1.2244  decode.d2.loss_cls: 1.1107  decode.d2.loss_mask: 0.8160  decode.d2.loss_dice: 1.1984  decode.d3.loss_cls: 1.1411  decode.d3.loss_mask: 0.7343  decode.d3.loss_dice: 1.1638  decode.d4.loss_cls: 1.0833  decode.d4.loss_mask: 0.7390  decode.d4.loss_dice: 1.1744  decode.d5.loss_cls: 1.1017  decode.d5.loss_mask: 0.7142  decode.d5.loss_dice: 1.1639  decode.d6.loss_cls: 1.1497  decode.d6.loss_mask: 0.7019  decode.d6.loss_dice: 1.1299  decode.d7.loss_cls: 1.1133  decode.d7.loss_mask: 0.6912  decode.d7.loss_dice: 1.1754  decode.d8.loss_cls: 1.0849  decode.d8.loss_mask: 0.6893  decode.d8.loss_dice: 1.1515
2023/05/23 22:22:12 - mmengine - INFO - Iter(train) [ 33300/160000]  lr: 8.1058e-06  eta: 15:01:41  time: 0.4734  data_time: 0.0094  memory: 4894  grad_norm: 85.8241  loss: 38.7264  decode.loss_cls: 1.2192  decode.loss_mask: 0.9080  decode.loss_dice: 1.5057  decode.d0.loss_cls: 3.3882  decode.d0.loss_mask: 0.9130  decode.d0.loss_dice: 1.6762  decode.d1.loss_cls: 1.3097  decode.d1.loss_mask: 0.8544  decode.d1.loss_dice: 1.5721  decode.d2.loss_cls: 1.2266  decode.d2.loss_mask: 0.9060  decode.d2.loss_dice: 1.5448  decode.d3.loss_cls: 1.2171  decode.d3.loss_mask: 0.8706  decode.d3.loss_dice: 1.5055  decode.d4.loss_cls: 1.1663  decode.d4.loss_mask: 0.9005  decode.d4.loss_dice: 1.5142  decode.d5.loss_cls: 1.2018  decode.d5.loss_mask: 0.8906  decode.d5.loss_dice: 1.5399  decode.d6.loss_cls: 1.2291  decode.d6.loss_mask: 0.9077  decode.d6.loss_dice: 1.4939  decode.d7.loss_cls: 1.2197  decode.d7.loss_mask: 0.8925  decode.d7.loss_dice: 1.5142  decode.d8.loss_cls: 1.2202  decode.d8.loss_mask: 0.9133  decode.d8.loss_dice: 1.5053
2023/05/23 22:22:33 - mmengine - INFO - Iter(train) [ 33350/160000]  lr: 8.1029e-06  eta: 15:01:17  time: 0.4129  data_time: 0.0102  memory: 4859  grad_norm: 97.4819  loss: 44.0799  decode.loss_cls: 1.6805  decode.loss_mask: 0.9392  decode.loss_dice: 1.4521  decode.d0.loss_cls: 3.3917  decode.d0.loss_mask: 1.1226  decode.d0.loss_dice: 1.7340  decode.d1.loss_cls: 1.7416  decode.d1.loss_mask: 1.0451  decode.d1.loss_dice: 1.6611  decode.d2.loss_cls: 1.7409  decode.d2.loss_mask: 1.0105  decode.d2.loss_dice: 1.6073  decode.d3.loss_cls: 1.7376  decode.d3.loss_mask: 1.0088  decode.d3.loss_dice: 1.4952  decode.d4.loss_cls: 1.7203  decode.d4.loss_mask: 0.9922  decode.d4.loss_dice: 1.5276  decode.d5.loss_cls: 1.6758  decode.d5.loss_mask: 0.9706  decode.d5.loss_dice: 1.5223  decode.d6.loss_cls: 1.7423  decode.d6.loss_mask: 0.9529  decode.d6.loss_dice: 1.4745  decode.d7.loss_cls: 1.6378  decode.d7.loss_mask: 0.9572  decode.d7.loss_dice: 1.4624  decode.d8.loss_cls: 1.6223  decode.d8.loss_mask: 0.9530  decode.d8.loss_dice: 1.5003
2023/05/23 22:22:55 - mmengine - INFO - Iter(train) [ 33400/160000]  lr: 8.1000e-06  eta: 15:00:56  time: 0.4737  data_time: 0.0095  memory: 4926  grad_norm: 89.4465  loss: 41.9590  decode.loss_cls: 1.3383  decode.loss_mask: 0.9619  decode.loss_dice: 1.6167  decode.d0.loss_cls: 3.5112  decode.d0.loss_mask: 0.9661  decode.d0.loss_dice: 1.8673  decode.d1.loss_cls: 1.5703  decode.d1.loss_mask: 0.8989  decode.d1.loss_dice: 1.6868  decode.d2.loss_cls: 1.4079  decode.d2.loss_mask: 0.9359  decode.d2.loss_dice: 1.6549  decode.d3.loss_cls: 1.4830  decode.d3.loss_mask: 0.8991  decode.d3.loss_dice: 1.5972  decode.d4.loss_cls: 1.3532  decode.d4.loss_mask: 0.9418  decode.d4.loss_dice: 1.6012  decode.d5.loss_cls: 1.4105  decode.d5.loss_mask: 0.9050  decode.d5.loss_dice: 1.5646  decode.d6.loss_cls: 1.3754  decode.d6.loss_mask: 0.8928  decode.d6.loss_dice: 1.6057  decode.d7.loss_cls: 1.4194  decode.d7.loss_mask: 0.9544  decode.d7.loss_dice: 1.6029  decode.d8.loss_cls: 1.3638  decode.d8.loss_mask: 0.9473  decode.d8.loss_dice: 1.6254
2023/05/23 22:23:16 - mmengine - INFO - Iter(train) [ 33450/160000]  lr: 8.0971e-06  eta: 15:00:36  time: 0.4684  data_time: 0.0098  memory: 4857  grad_norm: 96.2107  loss: 29.1080  decode.loss_cls: 1.1465  decode.loss_mask: 0.5898  decode.loss_dice: 0.8912  decode.d0.loss_cls: 3.0824  decode.d0.loss_mask: 0.6388  decode.d0.loss_dice: 1.0788  decode.d1.loss_cls: 1.2824  decode.d1.loss_mask: 0.6212  decode.d1.loss_dice: 0.9600  decode.d2.loss_cls: 1.2723  decode.d2.loss_mask: 0.5820  decode.d2.loss_dice: 0.9245  decode.d3.loss_cls: 1.2027  decode.d3.loss_mask: 0.6158  decode.d3.loss_dice: 0.9150  decode.d4.loss_cls: 1.1527  decode.d4.loss_mask: 0.6068  decode.d4.loss_dice: 0.9372  decode.d5.loss_cls: 1.1865  decode.d5.loss_mask: 0.5839  decode.d5.loss_dice: 0.9230  decode.d6.loss_cls: 1.1647  decode.d6.loss_mask: 0.5768  decode.d6.loss_dice: 0.8824  decode.d7.loss_cls: 1.1717  decode.d7.loss_mask: 0.5824  decode.d7.loss_dice: 0.9261  decode.d8.loss_cls: 1.1413  decode.d8.loss_mask: 0.5745  decode.d8.loss_dice: 0.8948
2023/05/23 22:23:38 - mmengine - INFO - Iter(train) [ 33500/160000]  lr: 8.0942e-06  eta: 15:00:16  time: 0.4232  data_time: 0.0103  memory: 4888  grad_norm: 98.4158  loss: 36.6669  decode.loss_cls: 1.2257  decode.loss_mask: 0.7781  decode.loss_dice: 1.4120  decode.d0.loss_cls: 3.2158  decode.d0.loss_mask: 0.7990  decode.d0.loss_dice: 1.6681  decode.d1.loss_cls: 1.2790  decode.d1.loss_mask: 0.8225  decode.d1.loss_dice: 1.4765  decode.d2.loss_cls: 1.2747  decode.d2.loss_mask: 0.7661  decode.d2.loss_dice: 1.4542  decode.d3.loss_cls: 1.2283  decode.d3.loss_mask: 0.7817  decode.d3.loss_dice: 1.4137  decode.d4.loss_cls: 1.2504  decode.d4.loss_mask: 0.7700  decode.d4.loss_dice: 1.4828  decode.d5.loss_cls: 1.2117  decode.d5.loss_mask: 0.7915  decode.d5.loss_dice: 1.4056  decode.d6.loss_cls: 1.1264  decode.d6.loss_mask: 0.7837  decode.d6.loss_dice: 1.4465  decode.d7.loss_cls: 1.2137  decode.d7.loss_mask: 0.7645  decode.d7.loss_dice: 1.4098  decode.d8.loss_cls: 1.2294  decode.d8.loss_mask: 0.7679  decode.d8.loss_dice: 1.4176
2023/05/23 22:23:59 - mmengine - INFO - Iter(train) [ 33550/160000]  lr: 8.0914e-06  eta: 14:59:54  time: 0.4218  data_time: 0.0100  memory: 4874  grad_norm: 114.7380  loss: 31.3837  decode.loss_cls: 1.1947  decode.loss_mask: 0.7177  decode.loss_dice: 0.9946  decode.d0.loss_cls: 2.9248  decode.d0.loss_mask: 0.8683  decode.d0.loss_dice: 1.2344  decode.d1.loss_cls: 1.3154  decode.d1.loss_mask: 0.7068  decode.d1.loss_dice: 1.1079  decode.d2.loss_cls: 1.1963  decode.d2.loss_mask: 0.7230  decode.d2.loss_dice: 1.0227  decode.d3.loss_cls: 1.1814  decode.d3.loss_mask: 0.6938  decode.d3.loss_dice: 0.9930  decode.d4.loss_cls: 1.2164  decode.d4.loss_mask: 0.7070  decode.d4.loss_dice: 0.9995  decode.d5.loss_cls: 1.1818  decode.d5.loss_mask: 0.7096  decode.d5.loss_dice: 1.0055  decode.d6.loss_cls: 1.1723  decode.d6.loss_mask: 0.7354  decode.d6.loss_dice: 0.9774  decode.d7.loss_cls: 1.2103  decode.d7.loss_mask: 0.7090  decode.d7.loss_dice: 0.9679  decode.d8.loss_cls: 1.2345  decode.d8.loss_mask: 0.7124  decode.d8.loss_dice: 0.9701
2023/05/23 22:24:20 - mmengine - INFO - Iter(train) [ 33600/160000]  lr: 8.0885e-06  eta: 14:59:31  time: 0.4074  data_time: 0.0097  memory: 4920  grad_norm: 88.9257  loss: 37.3654  decode.loss_cls: 1.2584  decode.loss_mask: 0.8530  decode.loss_dice: 1.3472  decode.d0.loss_cls: 3.2601  decode.d0.loss_mask: 0.9797  decode.d0.loss_dice: 1.6417  decode.d1.loss_cls: 1.3617  decode.d1.loss_mask: 0.9231  decode.d1.loss_dice: 1.5063  decode.d2.loss_cls: 1.2591  decode.d2.loss_mask: 0.9112  decode.d2.loss_dice: 1.4147  decode.d3.loss_cls: 1.2195  decode.d3.loss_mask: 0.8815  decode.d3.loss_dice: 1.3695  decode.d4.loss_cls: 1.1813  decode.d4.loss_mask: 0.8854  decode.d4.loss_dice: 1.4165  decode.d5.loss_cls: 1.2251  decode.d5.loss_mask: 0.8853  decode.d5.loss_dice: 1.3722  decode.d6.loss_cls: 1.2087  decode.d6.loss_mask: 0.8768  decode.d6.loss_dice: 1.3288  decode.d7.loss_cls: 1.1771  decode.d7.loss_mask: 0.8850  decode.d7.loss_dice: 1.3421  decode.d8.loss_cls: 1.1990  decode.d8.loss_mask: 0.8778  decode.d8.loss_dice: 1.3177
2023/05/23 22:24:43 - mmengine - INFO - Iter(train) [ 33650/160000]  lr: 8.0856e-06  eta: 14:59:15  time: 0.4622  data_time: 0.0096  memory: 4855  grad_norm: 105.5228  loss: 33.9463  decode.loss_cls: 1.1536  decode.loss_mask: 0.7739  decode.loss_dice: 1.1847  decode.d0.loss_cls: 3.3966  decode.d0.loss_mask: 0.8912  decode.d0.loss_dice: 1.4728  decode.d1.loss_cls: 1.2371  decode.d1.loss_mask: 0.8490  decode.d1.loss_dice: 1.2905  decode.d2.loss_cls: 1.1897  decode.d2.loss_mask: 0.7564  decode.d2.loss_dice: 1.2198  decode.d3.loss_cls: 1.2006  decode.d3.loss_mask: 0.7496  decode.d3.loss_dice: 1.1646  decode.d4.loss_cls: 1.1416  decode.d4.loss_mask: 0.7534  decode.d4.loss_dice: 1.1866  decode.d5.loss_cls: 1.1910  decode.d5.loss_mask: 0.7506  decode.d5.loss_dice: 1.1439  decode.d6.loss_cls: 1.1531  decode.d6.loss_mask: 0.7600  decode.d6.loss_dice: 1.1514  decode.d7.loss_cls: 1.1717  decode.d7.loss_mask: 0.7485  decode.d7.loss_dice: 1.1715  decode.d8.loss_cls: 1.1971  decode.d8.loss_mask: 0.7296  decode.d8.loss_dice: 1.1665
2023/05/23 22:25:04 - mmengine - INFO - Iter(train) [ 33700/160000]  lr: 8.0827e-06  eta: 14:58:52  time: 0.4084  data_time: 0.0098  memory: 4895  grad_norm: 101.1793  loss: 40.9714  decode.loss_cls: 1.5578  decode.loss_mask: 0.9886  decode.loss_dice: 1.2178  decode.d0.loss_cls: 3.3292  decode.d0.loss_mask: 1.1165  decode.d0.loss_dice: 1.5098  decode.d1.loss_cls: 1.6957  decode.d1.loss_mask: 1.0179  decode.d1.loss_dice: 1.4451  decode.d2.loss_cls: 1.6308  decode.d2.loss_mask: 1.0183  decode.d2.loss_dice: 1.3382  decode.d3.loss_cls: 1.6098  decode.d3.loss_mask: 1.0266  decode.d3.loss_dice: 1.2596  decode.d4.loss_cls: 1.5889  decode.d4.loss_mask: 1.0277  decode.d4.loss_dice: 1.2386  decode.d5.loss_cls: 1.5917  decode.d5.loss_mask: 1.0305  decode.d5.loss_dice: 1.2604  decode.d6.loss_cls: 1.5944  decode.d6.loss_mask: 1.0084  decode.d6.loss_dice: 1.2245  decode.d7.loss_cls: 1.5634  decode.d7.loss_mask: 0.9768  decode.d7.loss_dice: 1.2613  decode.d8.loss_cls: 1.6191  decode.d8.loss_mask: 0.9698  decode.d8.loss_dice: 1.2540
2023/05/23 22:25:26 - mmengine - INFO - Iter(train) [ 33750/160000]  lr: 8.0798e-06  eta: 14:58:36  time: 0.4656  data_time: 0.0101  memory: 4857  grad_norm: 118.2278  loss: 40.9952  decode.loss_cls: 1.2646  decode.loss_mask: 0.8845  decode.loss_dice: 1.6061  decode.d0.loss_cls: 3.4245  decode.d0.loss_mask: 0.9209  decode.d0.loss_dice: 1.8637  decode.d1.loss_cls: 1.4306  decode.d1.loss_mask: 0.9636  decode.d1.loss_dice: 1.7961  decode.d2.loss_cls: 1.3007  decode.d2.loss_mask: 0.9090  decode.d2.loss_dice: 1.7145  decode.d3.loss_cls: 1.2537  decode.d3.loss_mask: 0.9274  decode.d3.loss_dice: 1.6849  decode.d4.loss_cls: 1.2683  decode.d4.loss_mask: 0.8946  decode.d4.loss_dice: 1.6689  decode.d5.loss_cls: 1.3184  decode.d5.loss_mask: 0.8800  decode.d5.loss_dice: 1.6413  decode.d6.loss_cls: 1.3294  decode.d6.loss_mask: 0.8605  decode.d6.loss_dice: 1.6074  decode.d7.loss_cls: 1.3082  decode.d7.loss_mask: 0.8927  decode.d7.loss_dice: 1.5966  decode.d8.loss_cls: 1.2757  decode.d8.loss_mask: 0.9074  decode.d8.loss_dice: 1.6010
2023/05/23 22:25:47 - mmengine - INFO - Iter(train) [ 33800/160000]  lr: 8.0770e-06  eta: 14:58:13  time: 0.4114  data_time: 0.0104  memory: 4928  grad_norm: 95.0083  loss: 43.6695  decode.loss_cls: 1.4767  decode.loss_mask: 0.9810  decode.loss_dice: 1.5948  decode.d0.loss_cls: 3.3596  decode.d0.loss_mask: 1.0062  decode.d0.loss_dice: 1.8339  decode.d1.loss_cls: 1.7255  decode.d1.loss_mask: 1.0205  decode.d1.loss_dice: 1.7949  decode.d2.loss_cls: 1.5629  decode.d2.loss_mask: 1.0018  decode.d2.loss_dice: 1.6450  decode.d3.loss_cls: 1.6556  decode.d3.loss_mask: 0.9591  decode.d3.loss_dice: 1.6187  decode.d4.loss_cls: 1.5345  decode.d4.loss_mask: 0.9725  decode.d4.loss_dice: 1.6190  decode.d5.loss_cls: 1.5552  decode.d5.loss_mask: 0.9559  decode.d5.loss_dice: 1.5781  decode.d6.loss_cls: 1.4898  decode.d6.loss_mask: 0.9758  decode.d6.loss_dice: 1.6047  decode.d7.loss_cls: 1.5187  decode.d7.loss_mask: 0.9953  decode.d7.loss_dice: 1.5809  decode.d8.loss_cls: 1.4898  decode.d8.loss_mask: 0.9749  decode.d8.loss_dice: 1.5881
2023/05/23 22:26:08 - mmengine - INFO - Iter(train) [ 33850/160000]  lr: 8.0741e-06  eta: 14:57:49  time: 0.4123  data_time: 0.0098  memory: 4816  grad_norm: 94.4636  loss: 43.0670  decode.loss_cls: 1.4250  decode.loss_mask: 1.0479  decode.loss_dice: 1.4795  decode.d0.loss_cls: 3.2600  decode.d0.loss_mask: 1.2041  decode.d0.loss_dice: 1.7953  decode.d1.loss_cls: 1.5607  decode.d1.loss_mask: 1.1626  decode.d1.loss_dice: 1.7037  decode.d2.loss_cls: 1.4580  decode.d2.loss_mask: 1.1204  decode.d2.loss_dice: 1.6071  decode.d3.loss_cls: 1.4717  decode.d3.loss_mask: 1.0983  decode.d3.loss_dice: 1.5405  decode.d4.loss_cls: 1.4232  decode.d4.loss_mask: 1.1256  decode.d4.loss_dice: 1.5754  decode.d5.loss_cls: 1.4172  decode.d5.loss_mask: 1.0854  decode.d5.loss_dice: 1.5200  decode.d6.loss_cls: 1.4858  decode.d6.loss_mask: 1.0548  decode.d6.loss_dice: 1.4807  decode.d7.loss_cls: 1.4063  decode.d7.loss_mask: 1.0597  decode.d7.loss_dice: 1.4956  decode.d8.loss_cls: 1.4402  decode.d8.loss_mask: 1.0491  decode.d8.loss_dice: 1.5134
2023/05/23 22:26:29 - mmengine - INFO - Iter(train) [ 33900/160000]  lr: 8.0712e-06  eta: 14:57:27  time: 0.4445  data_time: 0.0108  memory: 4835  grad_norm: 95.5763  loss: 27.2041  decode.loss_cls: 0.9167  decode.loss_mask: 0.6849  decode.loss_dice: 0.8884  decode.d0.loss_cls: 2.6593  decode.d0.loss_mask: 0.6463  decode.d0.loss_dice: 0.9710  decode.d1.loss_cls: 1.0539  decode.d1.loss_mask: 0.7074  decode.d1.loss_dice: 0.9588  decode.d2.loss_cls: 0.9945  decode.d2.loss_mask: 0.7127  decode.d2.loss_dice: 0.9286  decode.d3.loss_cls: 0.9345  decode.d3.loss_mask: 0.7010  decode.d3.loss_dice: 0.9374  decode.d4.loss_cls: 0.9593  decode.d4.loss_mask: 0.6773  decode.d4.loss_dice: 0.9106  decode.d5.loss_cls: 0.9311  decode.d5.loss_mask: 0.6995  decode.d5.loss_dice: 0.8905  decode.d6.loss_cls: 0.8868  decode.d6.loss_mask: 0.7049  decode.d6.loss_dice: 0.8813  decode.d7.loss_cls: 0.9305  decode.d7.loss_mask: 0.6709  decode.d7.loss_dice: 0.8691  decode.d8.loss_cls: 0.9385  decode.d8.loss_mask: 0.7042  decode.d8.loss_dice: 0.8543
2023/05/23 22:26:50 - mmengine - INFO - Iter(train) [ 33950/160000]  lr: 8.0683e-06  eta: 14:57:03  time: 0.4096  data_time: 0.0099  memory: 4875  grad_norm: 95.8278  loss: 35.6213  decode.loss_cls: 1.1411  decode.loss_mask: 0.8542  decode.loss_dice: 1.3051  decode.d0.loss_cls: 3.1124  decode.d0.loss_mask: 0.8512  decode.d0.loss_dice: 1.4799  decode.d1.loss_cls: 1.2244  decode.d1.loss_mask: 0.8475  decode.d1.loss_dice: 1.3525  decode.d2.loss_cls: 1.2252  decode.d2.loss_mask: 0.8205  decode.d2.loss_dice: 1.3449  decode.d3.loss_cls: 1.2135  decode.d3.loss_mask: 0.8635  decode.d3.loss_dice: 1.3001  decode.d4.loss_cls: 1.1891  decode.d4.loss_mask: 0.8702  decode.d4.loss_dice: 1.3210  decode.d5.loss_cls: 1.1580  decode.d5.loss_mask: 0.8460  decode.d5.loss_dice: 1.3016  decode.d6.loss_cls: 1.2167  decode.d6.loss_mask: 0.8345  decode.d6.loss_dice: 1.2949  decode.d7.loss_cls: 1.2151  decode.d7.loss_mask: 0.8385  decode.d7.loss_dice: 1.2946  decode.d8.loss_cls: 1.1669  decode.d8.loss_mask: 0.8470  decode.d8.loss_dice: 1.2915
2023/05/23 22:27:12 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 22:27:12 - mmengine - INFO - Iter(train) [ 34000/160000]  lr: 8.0654e-06  eta: 14:56:44  time: 0.4726  data_time: 0.0096  memory: 4868  grad_norm: 104.2984  loss: 30.5593  decode.loss_cls: 1.1042  decode.loss_mask: 0.7230  decode.loss_dice: 0.9965  decode.d0.loss_cls: 3.0034  decode.d0.loss_mask: 0.7527  decode.d0.loss_dice: 1.1269  decode.d1.loss_cls: 1.1952  decode.d1.loss_mask: 0.7450  decode.d1.loss_dice: 1.0479  decode.d2.loss_cls: 1.1192  decode.d2.loss_mask: 0.7575  decode.d2.loss_dice: 1.0262  decode.d3.loss_cls: 1.0936  decode.d3.loss_mask: 0.7447  decode.d3.loss_dice: 1.0103  decode.d4.loss_cls: 1.0897  decode.d4.loss_mask: 0.7438  decode.d4.loss_dice: 1.0122  decode.d5.loss_cls: 1.1414  decode.d5.loss_mask: 0.7259  decode.d5.loss_dice: 0.9890  decode.d6.loss_cls: 1.1383  decode.d6.loss_mask: 0.7266  decode.d6.loss_dice: 0.9739  decode.d7.loss_cls: 1.1006  decode.d7.loss_mask: 0.7193  decode.d7.loss_dice: 0.9765  decode.d8.loss_cls: 1.0601  decode.d8.loss_mask: 0.7271  decode.d8.loss_dice: 0.9885
2023/05/23 22:27:12 - mmengine - INFO - Saving checkpoint at 34000 iterations
2023/05/23 22:27:38 - mmengine - INFO - Iter(train) [ 34050/160000]  lr: 8.0626e-06  eta: 14:56:41  time: 0.4097  data_time: 0.0095  memory: 4858  grad_norm: 107.4554  loss: 35.5469  decode.loss_cls: 1.2744  decode.loss_mask: 0.7715  decode.loss_dice: 1.2446  decode.d0.loss_cls: 2.9917  decode.d0.loss_mask: 0.7509  decode.d0.loss_dice: 1.4236  decode.d1.loss_cls: 1.4959  decode.d1.loss_mask: 0.7625  decode.d1.loss_dice: 1.3374  decode.d2.loss_cls: 1.4000  decode.d2.loss_mask: 0.7373  decode.d2.loss_dice: 1.2752  decode.d3.loss_cls: 1.2947  decode.d3.loss_mask: 0.7871  decode.d3.loss_dice: 1.2365  decode.d4.loss_cls: 1.3230  decode.d4.loss_mask: 0.7691  decode.d4.loss_dice: 1.2781  decode.d5.loss_cls: 1.3435  decode.d5.loss_mask: 0.7587  decode.d5.loss_dice: 1.2737  decode.d6.loss_cls: 1.3460  decode.d6.loss_mask: 0.7550  decode.d6.loss_dice: 1.2245  decode.d7.loss_cls: 1.3212  decode.d7.loss_mask: 0.7476  decode.d7.loss_dice: 1.2493  decode.d8.loss_cls: 1.3759  decode.d8.loss_mask: 0.7426  decode.d8.loss_dice: 1.2555
2023/05/23 22:28:00 - mmengine - INFO - Iter(train) [ 34100/160000]  lr: 8.0597e-06  eta: 14:56:20  time: 0.4474  data_time: 0.0100  memory: 4845  grad_norm: 89.1128  loss: 33.5995  decode.loss_cls: 1.2247  decode.loss_mask: 0.6869  decode.loss_dice: 1.1729  decode.d0.loss_cls: 3.1525  decode.d0.loss_mask: 0.7401  decode.d0.loss_dice: 1.3818  decode.d1.loss_cls: 1.2646  decode.d1.loss_mask: 0.7606  decode.d1.loss_dice: 1.3347  decode.d2.loss_cls: 1.1984  decode.d2.loss_mask: 0.7453  decode.d2.loss_dice: 1.2526  decode.d3.loss_cls: 1.2228  decode.d3.loss_mask: 0.6994  decode.d3.loss_dice: 1.2050  decode.d4.loss_cls: 1.2455  decode.d4.loss_mask: 0.6931  decode.d4.loss_dice: 1.2044  decode.d5.loss_cls: 1.2290  decode.d5.loss_mask: 0.6951  decode.d5.loss_dice: 1.2191  decode.d6.loss_cls: 1.2446  decode.d6.loss_mask: 0.6940  decode.d6.loss_dice: 1.1510  decode.d7.loss_cls: 1.2068  decode.d7.loss_mask: 0.7066  decode.d7.loss_dice: 1.1821  decode.d8.loss_cls: 1.2077  decode.d8.loss_mask: 0.7073  decode.d8.loss_dice: 1.1708
2023/05/23 22:28:21 - mmengine - INFO - Iter(train) [ 34150/160000]  lr: 8.0568e-06  eta: 14:55:58  time: 0.4056  data_time: 0.0098  memory: 4877  grad_norm: 119.7781  loss: 38.2255  decode.loss_cls: 1.4345  decode.loss_mask: 0.7979  decode.loss_dice: 1.3653  decode.d0.loss_cls: 3.3276  decode.d0.loss_mask: 0.8676  decode.d0.loss_dice: 1.5394  decode.d1.loss_cls: 1.5511  decode.d1.loss_mask: 0.7827  decode.d1.loss_dice: 1.4684  decode.d2.loss_cls: 1.5234  decode.d2.loss_mask: 0.7810  decode.d2.loss_dice: 1.3726  decode.d3.loss_cls: 1.4959  decode.d3.loss_mask: 0.7772  decode.d3.loss_dice: 1.3533  decode.d4.loss_cls: 1.4256  decode.d4.loss_mask: 0.7953  decode.d4.loss_dice: 1.3646  decode.d5.loss_cls: 1.4069  decode.d5.loss_mask: 0.7968  decode.d5.loss_dice: 1.3557  decode.d6.loss_cls: 1.4386  decode.d6.loss_mask: 0.8005  decode.d6.loss_dice: 1.3123  decode.d7.loss_cls: 1.4101  decode.d7.loss_mask: 0.8075  decode.d7.loss_dice: 1.3129  decode.d8.loss_cls: 1.3723  decode.d8.loss_mask: 0.8688  decode.d8.loss_dice: 1.3195
2023/05/23 22:28:43 - mmengine - INFO - Iter(train) [ 34200/160000]  lr: 8.0539e-06  eta: 14:55:39  time: 0.4166  data_time: 0.0096  memory: 4875  grad_norm: 105.9156  loss: 35.5696  decode.loss_cls: 1.2246  decode.loss_mask: 0.8358  decode.loss_dice: 1.2389  decode.d0.loss_cls: 3.0132  decode.d0.loss_mask: 0.8651  decode.d0.loss_dice: 1.4129  decode.d1.loss_cls: 1.3565  decode.d1.loss_mask: 0.9187  decode.d1.loss_dice: 1.3370  decode.d2.loss_cls: 1.1983  decode.d2.loss_mask: 0.8921  decode.d2.loss_dice: 1.3022  decode.d3.loss_cls: 1.2541  decode.d3.loss_mask: 0.8746  decode.d3.loss_dice: 1.2390  decode.d4.loss_cls: 1.1969  decode.d4.loss_mask: 0.9075  decode.d4.loss_dice: 1.2457  decode.d5.loss_cls: 1.2313  decode.d5.loss_mask: 0.8704  decode.d5.loss_dice: 1.2371  decode.d6.loss_cls: 1.3316  decode.d6.loss_mask: 0.8176  decode.d6.loss_dice: 1.1827  decode.d7.loss_cls: 1.2490  decode.d7.loss_mask: 0.8220  decode.d7.loss_dice: 1.2064  decode.d8.loss_cls: 1.2804  decode.d8.loss_mask: 0.7956  decode.d8.loss_dice: 1.2326
2023/05/23 22:29:04 - mmengine - INFO - Iter(train) [ 34250/160000]  lr: 8.0510e-06  eta: 14:55:16  time: 0.4109  data_time: 0.0100  memory: 4946  grad_norm: 138.7367  loss: 48.8119  decode.loss_cls: 1.6589  decode.loss_mask: 1.0371  decode.loss_dice: 1.8600  decode.d0.loss_cls: 3.8525  decode.d0.loss_mask: 1.0590  decode.d0.loss_dice: 2.0953  decode.d1.loss_cls: 1.9344  decode.d1.loss_mask: 0.9478  decode.d1.loss_dice: 1.9484  decode.d2.loss_cls: 1.8316  decode.d2.loss_mask: 0.9935  decode.d2.loss_dice: 1.8862  decode.d3.loss_cls: 1.8102  decode.d3.loss_mask: 0.9565  decode.d3.loss_dice: 1.8515  decode.d4.loss_cls: 1.8112  decode.d4.loss_mask: 0.9674  decode.d4.loss_dice: 1.8568  decode.d5.loss_cls: 1.8092  decode.d5.loss_mask: 0.9874  decode.d5.loss_dice: 1.8657  decode.d6.loss_cls: 1.7212  decode.d6.loss_mask: 1.0324  decode.d6.loss_dice: 1.8462  decode.d7.loss_cls: 1.7246  decode.d7.loss_mask: 1.0298  decode.d7.loss_dice: 1.8235  decode.d8.loss_cls: 1.6771  decode.d8.loss_mask: 1.0573  decode.d8.loss_dice: 1.8791
2023/05/23 22:29:24 - mmengine - INFO - Iter(train) [ 34300/160000]  lr: 8.0482e-06  eta: 14:54:52  time: 0.4204  data_time: 0.0098  memory: 4846  grad_norm: 93.0370  loss: 43.0530  decode.loss_cls: 1.6222  decode.loss_mask: 1.0037  decode.loss_dice: 1.4195  decode.d0.loss_cls: 3.3718  decode.d0.loss_mask: 0.9858  decode.d0.loss_dice: 1.6130  decode.d1.loss_cls: 1.7427  decode.d1.loss_mask: 0.9725  decode.d1.loss_dice: 1.5485  decode.d2.loss_cls: 1.7909  decode.d2.loss_mask: 0.9657  decode.d2.loss_dice: 1.5283  decode.d3.loss_cls: 1.7541  decode.d3.loss_mask: 0.9329  decode.d3.loss_dice: 1.4436  decode.d4.loss_cls: 1.6997  decode.d4.loss_mask: 0.9081  decode.d4.loss_dice: 1.4322  decode.d5.loss_cls: 1.7907  decode.d5.loss_mask: 0.9467  decode.d5.loss_dice: 1.3890  decode.d6.loss_cls: 1.7303  decode.d6.loss_mask: 0.9384  decode.d6.loss_dice: 1.3881  decode.d7.loss_cls: 1.6887  decode.d7.loss_mask: 0.9568  decode.d7.loss_dice: 1.4100  decode.d8.loss_cls: 1.7020  decode.d8.loss_mask: 0.9568  decode.d8.loss_dice: 1.4204
2023/05/23 22:29:45 - mmengine - INFO - Iter(train) [ 34350/160000]  lr: 8.0453e-06  eta: 14:54:28  time: 0.4075  data_time: 0.0098  memory: 4856  grad_norm: 90.3008  loss: 34.3182  decode.loss_cls: 1.0878  decode.loss_mask: 0.8879  decode.loss_dice: 1.2086  decode.d0.loss_cls: 2.8947  decode.d0.loss_mask: 0.8906  decode.d0.loss_dice: 1.3959  decode.d1.loss_cls: 1.1772  decode.d1.loss_mask: 0.8833  decode.d1.loss_dice: 1.3585  decode.d2.loss_cls: 1.1360  decode.d2.loss_mask: 0.8620  decode.d2.loss_dice: 1.2696  decode.d3.loss_cls: 1.2039  decode.d3.loss_mask: 0.8224  decode.d3.loss_dice: 1.2345  decode.d4.loss_cls: 1.1881  decode.d4.loss_mask: 0.8249  decode.d4.loss_dice: 1.2182  decode.d5.loss_cls: 1.1541  decode.d5.loss_mask: 0.8555  decode.d5.loss_dice: 1.1941  decode.d6.loss_cls: 1.1331  decode.d6.loss_mask: 0.8547  decode.d6.loss_dice: 1.1828  decode.d7.loss_cls: 1.1538  decode.d7.loss_mask: 0.8495  decode.d7.loss_dice: 1.1941  decode.d8.loss_cls: 1.1515  decode.d8.loss_mask: 0.8561  decode.d8.loss_dice: 1.1948
2023/05/23 22:30:06 - mmengine - INFO - Iter(train) [ 34400/160000]  lr: 8.0424e-06  eta: 14:54:04  time: 0.4179  data_time: 0.0098  memory: 4821  grad_norm: 87.8060  loss: 31.7398  decode.loss_cls: 1.2366  decode.loss_mask: 0.6144  decode.loss_dice: 1.1369  decode.d0.loss_cls: 3.0303  decode.d0.loss_mask: 0.6541  decode.d0.loss_dice: 1.3233  decode.d1.loss_cls: 1.3591  decode.d1.loss_mask: 0.6134  decode.d1.loss_dice: 1.2116  decode.d2.loss_cls: 1.2322  decode.d2.loss_mask: 0.6081  decode.d2.loss_dice: 1.1579  decode.d3.loss_cls: 1.1951  decode.d3.loss_mask: 0.6138  decode.d3.loss_dice: 1.1271  decode.d4.loss_cls: 1.1667  decode.d4.loss_mask: 0.6221  decode.d4.loss_dice: 1.1513  decode.d5.loss_cls: 1.1629  decode.d5.loss_mask: 0.6070  decode.d5.loss_dice: 1.1107  decode.d6.loss_cls: 1.1977  decode.d6.loss_mask: 0.5975  decode.d6.loss_dice: 1.1100  decode.d7.loss_cls: 1.1755  decode.d7.loss_mask: 0.6255  decode.d7.loss_dice: 1.1420  decode.d8.loss_cls: 1.2059  decode.d8.loss_mask: 0.6344  decode.d8.loss_dice: 1.1164
2023/05/23 22:30:26 - mmengine - INFO - Iter(train) [ 34450/160000]  lr: 8.0395e-06  eta: 14:53:41  time: 0.4145  data_time: 0.0101  memory: 4901  grad_norm: 101.5256  loss: 36.8268  decode.loss_cls: 1.4070  decode.loss_mask: 0.9286  decode.loss_dice: 1.1646  decode.d0.loss_cls: 3.1103  decode.d0.loss_mask: 0.9473  decode.d0.loss_dice: 1.2213  decode.d1.loss_cls: 1.4214  decode.d1.loss_mask: 0.9479  decode.d1.loss_dice: 1.2275  decode.d2.loss_cls: 1.3806  decode.d2.loss_mask: 0.9641  decode.d2.loss_dice: 1.2122  decode.d3.loss_cls: 1.3815  decode.d3.loss_mask: 0.9387  decode.d3.loss_dice: 1.1755  decode.d4.loss_cls: 1.3402  decode.d4.loss_mask: 0.9303  decode.d4.loss_dice: 1.1715  decode.d5.loss_cls: 1.4012  decode.d5.loss_mask: 0.9473  decode.d5.loss_dice: 1.1951  decode.d6.loss_cls: 1.3310  decode.d6.loss_mask: 0.9174  decode.d6.loss_dice: 1.1408  decode.d7.loss_cls: 1.3679  decode.d7.loss_mask: 0.9430  decode.d7.loss_dice: 1.1622  decode.d8.loss_cls: 1.3972  decode.d8.loss_mask: 0.9677  decode.d8.loss_dice: 1.1856
2023/05/23 22:30:47 - mmengine - INFO - Iter(train) [ 34500/160000]  lr: 8.0366e-06  eta: 14:53:17  time: 0.4161  data_time: 0.0102  memory: 4856  grad_norm: 90.5664  loss: 40.8502  decode.loss_cls: 1.4209  decode.loss_mask: 0.8792  decode.loss_dice: 1.5180  decode.d0.loss_cls: 3.1825  decode.d0.loss_mask: 0.8655  decode.d0.loss_dice: 1.6873  decode.d1.loss_cls: 1.5706  decode.d1.loss_mask: 0.9277  decode.d1.loss_dice: 1.6857  decode.d2.loss_cls: 1.5366  decode.d2.loss_mask: 0.8960  decode.d2.loss_dice: 1.5533  decode.d3.loss_cls: 1.5444  decode.d3.loss_mask: 0.8722  decode.d3.loss_dice: 1.5028  decode.d4.loss_cls: 1.5019  decode.d4.loss_mask: 0.8939  decode.d4.loss_dice: 1.4903  decode.d5.loss_cls: 1.5257  decode.d5.loss_mask: 0.8827  decode.d5.loss_dice: 1.4687  decode.d6.loss_cls: 1.4302  decode.d6.loss_mask: 0.8794  decode.d6.loss_dice: 1.5078  decode.d7.loss_cls: 1.4636  decode.d7.loss_mask: 0.8742  decode.d7.loss_dice: 1.4644  decode.d8.loss_cls: 1.4490  decode.d8.loss_mask: 0.8824  decode.d8.loss_dice: 1.4935
2023/05/23 22:31:08 - mmengine - INFO - Iter(train) [ 34550/160000]  lr: 8.0337e-06  eta: 14:52:53  time: 0.4099  data_time: 0.0098  memory: 4856  grad_norm: 93.9808  loss: 35.5818  decode.loss_cls: 1.3308  decode.loss_mask: 0.7176  decode.loss_dice: 1.1569  decode.d0.loss_cls: 3.5432  decode.d0.loss_mask: 0.8646  decode.d0.loss_dice: 1.3559  decode.d1.loss_cls: 1.5108  decode.d1.loss_mask: 0.8263  decode.d1.loss_dice: 1.2736  decode.d2.loss_cls: 1.4451  decode.d2.loss_mask: 0.7869  decode.d2.loss_dice: 1.2154  decode.d3.loss_cls: 1.4313  decode.d3.loss_mask: 0.7725  decode.d3.loss_dice: 1.1564  decode.d4.loss_cls: 1.3559  decode.d4.loss_mask: 0.7608  decode.d4.loss_dice: 1.1432  decode.d5.loss_cls: 1.3666  decode.d5.loss_mask: 0.7563  decode.d5.loss_dice: 1.1886  decode.d6.loss_cls: 1.3663  decode.d6.loss_mask: 0.7302  decode.d6.loss_dice: 1.1548  decode.d7.loss_cls: 1.3298  decode.d7.loss_mask: 0.7317  decode.d7.loss_dice: 1.1224  decode.d8.loss_cls: 1.3354  decode.d8.loss_mask: 0.7206  decode.d8.loss_dice: 1.1318
2023/05/23 22:31:28 - mmengine - INFO - Iter(train) [ 34600/160000]  lr: 8.0309e-06  eta: 14:52:29  time: 0.4137  data_time: 0.0096  memory: 4808  grad_norm: 89.6616  loss: 28.6541  decode.loss_cls: 1.0919  decode.loss_mask: 0.5874  decode.loss_dice: 0.8648  decode.d0.loss_cls: 2.7951  decode.d0.loss_mask: 0.6841  decode.d0.loss_dice: 1.0979  decode.d1.loss_cls: 1.2718  decode.d1.loss_mask: 0.6405  decode.d1.loss_dice: 1.0135  decode.d2.loss_cls: 1.1761  decode.d2.loss_mask: 0.6450  decode.d2.loss_dice: 0.9668  decode.d3.loss_cls: 1.1815  decode.d3.loss_mask: 0.6237  decode.d3.loss_dice: 0.8968  decode.d4.loss_cls: 1.1689  decode.d4.loss_mask: 0.6307  decode.d4.loss_dice: 0.8885  decode.d5.loss_cls: 1.1414  decode.d5.loss_mask: 0.6081  decode.d5.loss_dice: 0.9049  decode.d6.loss_cls: 1.1338  decode.d6.loss_mask: 0.6083  decode.d6.loss_dice: 0.8744  decode.d7.loss_cls: 1.1277  decode.d7.loss_mask: 0.5942  decode.d7.loss_dice: 0.8654  decode.d8.loss_cls: 1.1287  decode.d8.loss_mask: 0.5762  decode.d8.loss_dice: 0.8660
2023/05/23 22:31:50 - mmengine - INFO - Iter(train) [ 34650/160000]  lr: 8.0280e-06  eta: 14:52:07  time: 0.4148  data_time: 0.0100  memory: 4804  grad_norm: 108.5903  loss: 41.5749  decode.loss_cls: 1.3984  decode.loss_mask: 1.1092  decode.loss_dice: 1.4473  decode.d0.loss_cls: 3.1740  decode.d0.loss_mask: 1.1351  decode.d0.loss_dice: 1.6120  decode.d1.loss_cls: 1.4308  decode.d1.loss_mask: 1.1408  decode.d1.loss_dice: 1.5349  decode.d2.loss_cls: 1.3340  decode.d2.loss_mask: 1.1202  decode.d2.loss_dice: 1.5262  decode.d3.loss_cls: 1.3791  decode.d3.loss_mask: 1.1083  decode.d3.loss_dice: 1.4377  decode.d4.loss_cls: 1.3586  decode.d4.loss_mask: 1.1067  decode.d4.loss_dice: 1.4619  decode.d5.loss_cls: 1.3695  decode.d5.loss_mask: 1.1122  decode.d5.loss_dice: 1.4601  decode.d6.loss_cls: 1.4020  decode.d6.loss_mask: 1.1182  decode.d6.loss_dice: 1.4272  decode.d7.loss_cls: 1.3750  decode.d7.loss_mask: 1.1085  decode.d7.loss_dice: 1.4283  decode.d8.loss_cls: 1.3674  decode.d8.loss_mask: 1.1440  decode.d8.loss_dice: 1.4474
2023/05/23 22:32:12 - mmengine - INFO - Iter(train) [ 34700/160000]  lr: 8.0251e-06  eta: 14:51:50  time: 0.4660  data_time: 0.0095  memory: 4830  grad_norm: 109.2223  loss: 33.9887  decode.loss_cls: 1.0919  decode.loss_mask: 0.7632  decode.loss_dice: 1.2791  decode.d0.loss_cls: 3.1988  decode.d0.loss_mask: 0.6979  decode.d0.loss_dice: 1.3706  decode.d1.loss_cls: 1.2522  decode.d1.loss_mask: 0.7568  decode.d1.loss_dice: 1.3388  decode.d2.loss_cls: 1.1620  decode.d2.loss_mask: 0.7562  decode.d2.loss_dice: 1.2960  decode.d3.loss_cls: 1.2018  decode.d3.loss_mask: 0.7608  decode.d3.loss_dice: 1.2813  decode.d4.loss_cls: 1.1481  decode.d4.loss_mask: 0.7728  decode.d4.loss_dice: 1.2885  decode.d5.loss_cls: 1.1534  decode.d5.loss_mask: 0.7645  decode.d5.loss_dice: 1.2563  decode.d6.loss_cls: 1.1090  decode.d6.loss_mask: 0.7635  decode.d6.loss_dice: 1.2475  decode.d7.loss_cls: 1.0975  decode.d7.loss_mask: 0.7682  decode.d7.loss_dice: 1.2639  decode.d8.loss_cls: 1.0815  decode.d8.loss_mask: 0.7780  decode.d8.loss_dice: 1.2884
2023/05/23 22:32:34 - mmengine - INFO - Iter(train) [ 34750/160000]  lr: 8.0222e-06  eta: 14:51:31  time: 0.4159  data_time: 0.0101  memory: 4838  grad_norm: 95.3110  loss: 37.5173  decode.loss_cls: 1.2165  decode.loss_mask: 0.7622  decode.loss_dice: 1.4215  decode.d0.loss_cls: 3.3425  decode.d0.loss_mask: 0.7776  decode.d0.loss_dice: 1.6632  decode.d1.loss_cls: 1.3703  decode.d1.loss_mask: 0.8339  decode.d1.loss_dice: 1.6131  decode.d2.loss_cls: 1.3622  decode.d2.loss_mask: 0.7793  decode.d2.loss_dice: 1.4813  decode.d3.loss_cls: 1.2774  decode.d3.loss_mask: 0.7919  decode.d3.loss_dice: 1.4479  decode.d4.loss_cls: 1.2941  decode.d4.loss_mask: 0.7680  decode.d4.loss_dice: 1.4507  decode.d5.loss_cls: 1.3182  decode.d5.loss_mask: 0.7650  decode.d5.loss_dice: 1.4241  decode.d6.loss_cls: 1.2822  decode.d6.loss_mask: 0.7684  decode.d6.loss_dice: 1.3996  decode.d7.loss_cls: 1.2593  decode.d7.loss_mask: 0.7625  decode.d7.loss_dice: 1.4198  decode.d8.loss_cls: 1.2522  decode.d8.loss_mask: 0.7754  decode.d8.loss_dice: 1.4369
2023/05/23 22:32:55 - mmengine - INFO - Iter(train) [ 34800/160000]  lr: 8.0193e-06  eta: 14:51:08  time: 0.4073  data_time: 0.0100  memory: 4857  grad_norm: 93.9816  loss: 34.0081  decode.loss_cls: 1.3005  decode.loss_mask: 0.8632  decode.loss_dice: 1.0084  decode.d0.loss_cls: 2.9664  decode.d0.loss_mask: 0.9371  decode.d0.loss_dice: 1.1096  decode.d1.loss_cls: 1.3129  decode.d1.loss_mask: 0.9480  decode.d1.loss_dice: 1.0985  decode.d2.loss_cls: 1.3523  decode.d2.loss_mask: 0.8914  decode.d2.loss_dice: 1.0282  decode.d3.loss_cls: 1.3284  decode.d3.loss_mask: 0.9010  decode.d3.loss_dice: 1.0268  decode.d4.loss_cls: 1.3863  decode.d4.loss_mask: 0.8921  decode.d4.loss_dice: 1.0025  decode.d5.loss_cls: 1.3232  decode.d5.loss_mask: 0.8789  decode.d5.loss_dice: 1.0155  decode.d6.loss_cls: 1.3095  decode.d6.loss_mask: 0.8353  decode.d6.loss_dice: 1.0003  decode.d7.loss_cls: 1.2824  decode.d7.loss_mask: 0.8570  decode.d7.loss_dice: 1.0148  decode.d8.loss_cls: 1.2754  decode.d8.loss_mask: 0.8596  decode.d8.loss_dice: 1.0026
2023/05/23 22:33:15 - mmengine - INFO - Iter(train) [ 34850/160000]  lr: 8.0165e-06  eta: 14:50:43  time: 0.4122  data_time: 0.0096  memory: 4829  grad_norm: 102.6670  loss: 31.6082  decode.loss_cls: 1.1370  decode.loss_mask: 0.6560  decode.loss_dice: 1.0638  decode.d0.loss_cls: 3.0316  decode.d0.loss_mask: 0.7776  decode.d0.loss_dice: 1.3166  decode.d1.loss_cls: 1.3078  decode.d1.loss_mask: 0.7051  decode.d1.loss_dice: 1.2130  decode.d2.loss_cls: 1.1230  decode.d2.loss_mask: 0.6908  decode.d2.loss_dice: 1.1642  decode.d3.loss_cls: 1.1519  decode.d3.loss_mask: 0.6787  decode.d3.loss_dice: 1.1441  decode.d4.loss_cls: 1.1588  decode.d4.loss_mask: 0.6674  decode.d4.loss_dice: 1.0947  decode.d5.loss_cls: 1.1583  decode.d5.loss_mask: 0.6489  decode.d5.loss_dice: 1.0746  decode.d6.loss_cls: 1.1249  decode.d6.loss_mask: 0.6518  decode.d6.loss_dice: 1.0964  decode.d7.loss_cls: 1.1377  decode.d7.loss_mask: 0.6560  decode.d7.loss_dice: 1.0835  decode.d8.loss_cls: 1.1690  decode.d8.loss_mask: 0.6633  decode.d8.loss_dice: 1.0618
2023/05/23 22:33:37 - mmengine - INFO - Iter(train) [ 34900/160000]  lr: 8.0136e-06  eta: 14:50:23  time: 0.4220  data_time: 0.0103  memory: 4836  grad_norm: 95.9404  loss: 39.1538  decode.loss_cls: 1.1809  decode.loss_mask: 0.9307  decode.loss_dice: 1.4555  decode.d0.loss_cls: 3.4563  decode.d0.loss_mask: 0.9575  decode.d0.loss_dice: 1.6418  decode.d1.loss_cls: 1.3977  decode.d1.loss_mask: 0.9326  decode.d1.loss_dice: 1.5185  decode.d2.loss_cls: 1.3464  decode.d2.loss_mask: 0.9121  decode.d2.loss_dice: 1.4873  decode.d3.loss_cls: 1.2906  decode.d3.loss_mask: 0.9195  decode.d3.loss_dice: 1.4688  decode.d4.loss_cls: 1.2300  decode.d4.loss_mask: 0.9479  decode.d4.loss_dice: 1.5022  decode.d5.loss_cls: 1.3233  decode.d5.loss_mask: 0.9097  decode.d5.loss_dice: 1.4500  decode.d6.loss_cls: 1.2659  decode.d6.loss_mask: 0.9561  decode.d6.loss_dice: 1.4465  decode.d7.loss_cls: 1.2458  decode.d7.loss_mask: 0.9436  decode.d7.loss_dice: 1.4390  decode.d8.loss_cls: 1.2101  decode.d8.loss_mask: 0.9256  decode.d8.loss_dice: 1.4621
2023/05/23 22:33:58 - mmengine - INFO - Iter(train) [ 34950/160000]  lr: 8.0107e-06  eta: 14:50:01  time: 0.4163  data_time: 0.0100  memory: 4857  grad_norm: 101.2433  loss: 32.5067  decode.loss_cls: 1.0036  decode.loss_mask: 0.7188  decode.loss_dice: 1.2423  decode.d0.loss_cls: 2.9573  decode.d0.loss_mask: 0.6945  decode.d0.loss_dice: 1.4139  decode.d1.loss_cls: 1.1596  decode.d1.loss_mask: 0.7602  decode.d1.loss_dice: 1.2915  decode.d2.loss_cls: 1.1594  decode.d2.loss_mask: 0.7131  decode.d2.loss_dice: 1.2724  decode.d3.loss_cls: 1.0854  decode.d3.loss_mask: 0.7277  decode.d3.loss_dice: 1.2499  decode.d4.loss_cls: 1.0928  decode.d4.loss_mask: 0.6809  decode.d4.loss_dice: 1.2803  decode.d5.loss_cls: 1.0997  decode.d5.loss_mask: 0.6766  decode.d5.loss_dice: 1.2554  decode.d6.loss_cls: 1.0950  decode.d6.loss_mask: 0.6484  decode.d6.loss_dice: 1.2372  decode.d7.loss_cls: 1.0170  decode.d7.loss_mask: 0.7187  decode.d7.loss_dice: 1.2637  decode.d8.loss_cls: 1.0156  decode.d8.loss_mask: 0.7250  decode.d8.loss_dice: 1.2508
2023/05/23 22:34:19 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 22:34:19 - mmengine - INFO - Iter(train) [ 35000/160000]  lr: 8.0078e-06  eta: 14:49:39  time: 0.4071  data_time: 0.0101  memory: 4927  grad_norm: 113.0047  loss: 53.2956  decode.loss_cls: 1.7747  decode.loss_mask: 1.1560  decode.loss_dice: 2.1029  decode.d0.loss_cls: 3.7472  decode.d0.loss_mask: 1.2367  decode.d0.loss_dice: 2.4459  decode.d1.loss_cls: 1.9276  decode.d1.loss_mask: 1.1516  decode.d1.loss_dice: 2.2236  decode.d2.loss_cls: 1.8267  decode.d2.loss_mask: 1.1853  decode.d2.loss_dice: 2.1944  decode.d3.loss_cls: 1.8164  decode.d3.loss_mask: 1.1766  decode.d3.loss_dice: 2.1366  decode.d4.loss_cls: 1.7980  decode.d4.loss_mask: 1.1524  decode.d4.loss_dice: 2.1355  decode.d5.loss_cls: 1.7567  decode.d5.loss_mask: 1.1339  decode.d5.loss_dice: 2.1314  decode.d6.loss_cls: 1.8147  decode.d6.loss_mask: 1.1354  decode.d6.loss_dice: 2.0815  decode.d7.loss_cls: 1.7785  decode.d7.loss_mask: 1.1361  decode.d7.loss_dice: 2.0692  decode.d8.loss_cls: 1.7682  decode.d8.loss_mask: 1.1572  decode.d8.loss_dice: 2.1445
2023/05/23 22:34:20 - mmengine - INFO - Saving checkpoint at 35000 iterations
2023/05/23 22:34:29 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:50  time: 0.0775  data_time: 0.0018  memory: 2167  
2023/05/23 22:34:33 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0787  data_time: 0.0019  memory: 2216  
2023/05/23 22:34:37 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:38  time: 0.0798  data_time: 0.0018  memory: 2167  
2023/05/23 22:34:41 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0788  data_time: 0.0018  memory: 2104  
2023/05/23 22:34:45 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0787  data_time: 0.0018  memory: 2831  
2023/05/23 22:34:49 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0906  data_time: 0.0019  memory: 2167  
2023/05/23 22:34:54 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0861  data_time: 0.0020  memory: 2167  
2023/05/23 22:34:58 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0908  data_time: 0.0019  memory: 2167  
2023/05/23 22:35:02 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0791  data_time: 0.0019  memory: 2944  
2023/05/23 22:35:06 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0789  data_time: 0.0019  memory: 2356  
2023/05/23 22:35:13 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.3066  data_time: 0.0021  memory: 2217  
2023/05/23 22:35:17 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0909  data_time: 0.0018  memory: 2328  
2023/05/23 22:35:21 - mmengine - INFO - per class results:
2023/05/23 22:35:21 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 84.71 |  93.7 |
|     bicycle      |  66.5 | 78.76 |
|       car        | 56.22 | 80.79 |
|    motorcycle    | 81.17 | 88.98 |
|     airplane     | 81.63 | 90.77 |
|       bus        | 77.95 | 86.27 |
|      train       | 81.31 | 91.55 |
|      truck       |  46.8 | 58.17 |
|       boat       | 52.13 | 74.38 |
|  traffic light   |  66.1 | 84.85 |
|   fire hydrant   | 75.62 | 95.32 |
|    stop sign     | 81.11 | 97.16 |
|  parking meter   | 79.49 | 84.82 |
|      bench       | 46.43 | 69.23 |
|       bird       | 81.08 | 90.69 |
|       cat        |  84.5 | 93.23 |
|       dog        | 77.55 | 87.61 |
|      horse       | 77.95 |  90.0 |
|      sheep       |  85.8 | 93.67 |
|       cow        |  80.4 | 85.74 |
|     elephant     | 89.25 | 94.74 |
|       bear       | 92.06 | 94.92 |
|      zebra       | 89.89 | 92.77 |
|     giraffe      | 86.43 | 92.63 |
|     backpack     | 26.25 | 55.99 |
|     umbrella     | 73.95 | 82.28 |
|     handbag      | 28.41 | 42.66 |
|       tie        |  12.7 | 19.13 |
|     suitcase     | 74.57 | 87.24 |
|     frisbee      | 74.22 | 88.08 |
|       skis       | 32.35 | 42.38 |
|    snowboard     | 36.07 | 55.55 |
|   sports ball    | 52.84 | 71.97 |
|       kite       | 48.24 | 69.61 |
|   baseball bat   | 40.41 | 50.19 |
|  baseball glove  | 67.96 | 78.85 |
|    skateboard    |  70.9 | 86.99 |
|    surfboard     | 72.94 | 86.95 |
|  tennis racket   | 79.22 | 88.05 |
|      bottle      |  49.0 | 67.07 |
|    wine glass    | 48.38 | 81.06 |
|       cup        | 50.36 | 73.25 |
|       fork       | 37.26 | 54.76 |
|      knife       | 26.91 | 43.76 |
|      spoon       | 27.37 |  39.9 |
|       bowl       |  46.5 | 64.94 |
|      banana      | 64.81 | 87.41 |
|      apple       | 50.36 | 69.77 |
|     sandwich     |  49.6 | 74.21 |
|      orange      | 70.89 | 85.72 |
|     broccoli     |  58.4 | 81.97 |
|      carrot      | 51.52 | 69.08 |
|     hot dog      | 49.86 | 61.13 |
|      pizza       | 69.29 | 90.67 |
|      donut       | 62.11 | 87.46 |
|       cake       | 54.68 | 77.27 |
|      chair       | 39.82 | 57.85 |
|      couch       | 51.08 | 74.43 |
|   potted plant   | 26.15 | 38.58 |
|       bed        | 59.73 | 72.51 |
|   dining table   | 43.03 | 66.08 |
|      toilet      | 78.41 | 91.42 |
|        tv        | 71.66 | 80.88 |
|      laptop      | 72.41 | 85.74 |
|      mouse       | 66.22 | 89.01 |
|      remote      | 50.89 | 72.15 |
|     keyboard     | 58.54 | 71.91 |
|    cell phone    | 68.81 | 87.63 |
|    microwave     | 57.81 | 76.19 |
|       oven       | 50.05 | 63.29 |
|     toaster      |  0.55 |  0.7  |
|       sink       | 58.39 | 67.95 |
|   refrigerator   | 72.37 | 87.32 |
|       book       | 48.12 | 65.66 |
|      clock       |  70.4 | 77.92 |
|       vase       | 52.47 | 80.48 |
|     scissors     | 51.08 |  70.7 |
|    teddy bear    | 74.78 | 87.81 |
|    hair drier    | 36.58 | 36.64 |
|    toothbrush    |  14.2 | 72.12 |
|      banner      | 26.12 | 65.03 |
|     blanket      |  5.16 |  6.36 |
|      branch      | 18.73 | 25.74 |
|      bridge      | 30.49 | 51.62 |
|  building-other  | 49.94 | 67.39 |
|       bush       | 30.46 | 41.33 |
|     cabinet      | 48.48 | 64.86 |
|       cage       |  9.1  | 11.77 |
|    cardboard     | 41.02 | 48.86 |
|      carpet      | 50.04 | 67.99 |
|  ceiling-other   | 58.41 | 73.47 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 16.64 | 24.52 |
|      clouds      | 47.05 | 60.01 |
|     counter      | 23.43 | 56.83 |
|     cupboard     |  1.04 |  2.28 |
|     curtain      | 58.53 | 77.59 |
|    desk-stuff    | 45.56 | 56.96 |
|       dirt       | 37.37 | 53.74 |
|    door-stuff    |  33.8 | 52.87 |
|      fence       |  34.0 | 64.03 |
|   floor-marble   |  2.03 |  2.26 |
|   floor-other    | 19.35 | 27.66 |
|   floor-stone    |  9.62 | 11.24 |
|    floor-tile    | 55.69 | 71.55 |
|    floor-wood    | 60.38 | 74.63 |
|      flower      | 44.31 | 63.38 |
|       fog        |  1.59 |  1.6  |
|    food-other    | 30.08 | 43.16 |
|      fruit       | 37.13 | 52.36 |
| furniture-other  | 13.33 | 17.29 |
|      grass       | 68.75 |  80.9 |
|      gravel      | 27.14 | 48.79 |
|   ground-other   |  5.61 |  6.6  |
|       hill       | 22.08 | 34.62 |
|      house       | 25.96 | 33.96 |
|      leaves      | 25.83 | 30.47 |
|      light       | 34.07 |  53.0 |
|       mat        |  0.0  |  0.0  |
|      metal       | 29.24 | 44.81 |
|   mirror-stuff   | 36.93 | 47.12 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 45.28 | 59.55 |
|       mud        |  0.89 |  1.61 |
|      napkin      | 15.48 | 18.85 |
|       net        | 41.84 | 59.91 |
|      paper       |  32.6 | 47.81 |
|     pavement     | 47.43 | 63.49 |
|      pillow      |  5.86 |  8.72 |
|   plant-other    | 20.79 | 40.66 |
|     plastic      | 15.47 | 20.58 |
|     platform     | 21.63 | 45.02 |
|   playingfield   | 68.46 | 87.76 |
|     railing      |  4.38 |  7.73 |
|     railroad     | 58.37 | 76.77 |
|      river       | 48.35 |  77.1 |
|       road       | 61.35 | 78.76 |
|       rock       | 46.79 | 79.91 |
|       roof       | 12.42 | 16.65 |
|       rug        | 34.92 | 58.21 |
|      salad       |  0.0  |  0.0  |
|       sand       | 58.84 | 66.58 |
|       sea        | 83.31 | 90.39 |
|      shelf       | 34.13 | 43.89 |
|    sky-other     | 70.43 | 88.49 |
|    skyscraper    | 37.11 | 45.82 |
|       snow       | 89.99 | 94.19 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      |  13.7 | 21.09 |
|      stone       |  0.0  |  0.0  |
|      straw       | 27.35 | 52.76 |
| structural-other |  0.24 |  0.25 |
|      table       | 22.82 | 31.83 |
|       tent       |  7.63 | 10.12 |
|  textile-other   |  9.09 | 15.63 |
|      towel       | 29.59 | 39.86 |
|       tree       | 72.27 | 86.68 |
|    vegetable     | 30.65 |  44.6 |
|    wall-brick    | 46.67 | 63.46 |
|  wall-concrete   | 55.47 | 73.09 |
|    wall-other    | 16.03 | 33.02 |
|    wall-panel    |  8.39 | 10.35 |
|    wall-stone    | 25.84 | 31.06 |
|    wall-tile     | 63.76 | 80.31 |
|    wall-wood     | 37.49 | 51.47 |
|   water-other    | 22.99 |  32.3 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 45.69 | 57.38 |
|   window-other   | 41.98 | 70.12 |
|       wood       | 25.34 | 38.76 |
+------------------+-------+-------+
2023/05/23 22:35:21 - mmengine - INFO - Iter(val) [625/625]    aAcc: 69.3300  mIoU: 44.0200  mAcc: 57.4400  data_time: 0.0019  time: 0.0864
2023/05/23 22:35:21 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_30000.pth is removed
2023/05/23 22:35:24 - mmengine - INFO - The best checkpoint with 44.0200 mIoU at 35000 iter is saved to best_mIoU_iter_35000.pth.
2023/05/23 22:35:45 - mmengine - INFO - Iter(train) [ 35050/160000]  lr: 8.0049e-06  eta: 14:49:36  time: 0.4123  data_time: 0.0098  memory: 4807  grad_norm: 96.2994  loss: 29.6824  decode.loss_cls: 1.0558  decode.loss_mask: 0.6423  decode.loss_dice: 1.0147  decode.d0.loss_cls: 2.7157  decode.d0.loss_mask: 0.7197  decode.d0.loss_dice: 1.1188  decode.d1.loss_cls: 1.1943  decode.d1.loss_mask: 0.6818  decode.d1.loss_dice: 1.0402  decode.d2.loss_cls: 1.1448  decode.d2.loss_mask: 0.6628  decode.d2.loss_dice: 1.0235  decode.d3.loss_cls: 1.1472  decode.d3.loss_mask: 0.6547  decode.d3.loss_dice: 1.0226  decode.d4.loss_cls: 1.1386  decode.d4.loss_mask: 0.6484  decode.d4.loss_dice: 1.0216  decode.d5.loss_cls: 1.1136  decode.d5.loss_mask: 0.6566  decode.d5.loss_dice: 1.0189  decode.d6.loss_cls: 1.0856  decode.d6.loss_mask: 0.6446  decode.d6.loss_dice: 1.0239  decode.d7.loss_cls: 1.1335  decode.d7.loss_mask: 0.6238  decode.d7.loss_dice: 1.0017  decode.d8.loss_cls: 1.0862  decode.d8.loss_mask: 0.6360  decode.d8.loss_dice: 1.0106
2023/05/23 22:36:06 - mmengine - INFO - Iter(train) [ 35100/160000]  lr: 8.0020e-06  eta: 14:49:12  time: 0.4230  data_time: 0.0104  memory: 4952  grad_norm: 94.8275  loss: 33.9792  decode.loss_cls: 1.2093  decode.loss_mask: 0.7956  decode.loss_dice: 1.1279  decode.d0.loss_cls: 2.9954  decode.d0.loss_mask: 0.8711  decode.d0.loss_dice: 1.2639  decode.d1.loss_cls: 1.3820  decode.d1.loss_mask: 0.8671  decode.d1.loss_dice: 1.2220  decode.d2.loss_cls: 1.2326  decode.d2.loss_mask: 0.8452  decode.d2.loss_dice: 1.1928  decode.d3.loss_cls: 1.2296  decode.d3.loss_mask: 0.7926  decode.d3.loss_dice: 1.1714  decode.d4.loss_cls: 1.2370  decode.d4.loss_mask: 0.7833  decode.d4.loss_dice: 1.1531  decode.d5.loss_cls: 1.2834  decode.d5.loss_mask: 0.7805  decode.d5.loss_dice: 1.1340  decode.d6.loss_cls: 1.2202  decode.d6.loss_mask: 0.7888  decode.d6.loss_dice: 1.1540  decode.d7.loss_cls: 1.1953  decode.d7.loss_mask: 0.7769  decode.d7.loss_dice: 1.1383  decode.d8.loss_cls: 1.2076  decode.d8.loss_mask: 0.7842  decode.d8.loss_dice: 1.1441
2023/05/23 22:36:27 - mmengine - INFO - Iter(train) [ 35150/160000]  lr: 7.9992e-06  eta: 14:48:50  time: 0.4156  data_time: 0.0098  memory: 4857  grad_norm: 97.9177  loss: 45.6729  decode.loss_cls: 1.5564  decode.loss_mask: 1.1283  decode.loss_dice: 1.6112  decode.d0.loss_cls: 3.4782  decode.d0.loss_mask: 1.1471  decode.d0.loss_dice: 1.8050  decode.d1.loss_cls: 1.5379  decode.d1.loss_mask: 1.2089  decode.d1.loss_dice: 1.7865  decode.d2.loss_cls: 1.5803  decode.d2.loss_mask: 1.1354  decode.d2.loss_dice: 1.6628  decode.d3.loss_cls: 1.5668  decode.d3.loss_mask: 1.1063  decode.d3.loss_dice: 1.6046  decode.d4.loss_cls: 1.5579  decode.d4.loss_mask: 1.1452  decode.d4.loss_dice: 1.6176  decode.d5.loss_cls: 1.6123  decode.d5.loss_mask: 1.1203  decode.d5.loss_dice: 1.6664  decode.d6.loss_cls: 1.6109  decode.d6.loss_mask: 1.1326  decode.d6.loss_dice: 1.6081  decode.d7.loss_cls: 1.5568  decode.d7.loss_mask: 1.1339  decode.d7.loss_dice: 1.6390  decode.d8.loss_cls: 1.5768  decode.d8.loss_mask: 1.1357  decode.d8.loss_dice: 1.6436
2023/05/23 22:36:48 - mmengine - INFO - Iter(train) [ 35200/160000]  lr: 7.9963e-06  eta: 14:48:26  time: 0.4161  data_time: 0.0101  memory: 4837  grad_norm: 123.6006  loss: 48.1953  decode.loss_cls: 1.6863  decode.loss_mask: 1.1187  decode.loss_dice: 1.7232  decode.d0.loss_cls: 3.3763  decode.d0.loss_mask: 1.1790  decode.d0.loss_dice: 1.9951  decode.d1.loss_cls: 1.8237  decode.d1.loss_mask: 1.1387  decode.d1.loss_dice: 1.8771  decode.d2.loss_cls: 1.7294  decode.d2.loss_mask: 1.1765  decode.d2.loss_dice: 1.8559  decode.d3.loss_cls: 1.7990  decode.d3.loss_mask: 1.1960  decode.d3.loss_dice: 1.7713  decode.d4.loss_cls: 1.7432  decode.d4.loss_mask: 1.1086  decode.d4.loss_dice: 1.7617  decode.d5.loss_cls: 1.7155  decode.d5.loss_mask: 1.1063  decode.d5.loss_dice: 1.7484  decode.d6.loss_cls: 1.6657  decode.d6.loss_mask: 1.1206  decode.d6.loss_dice: 1.7317  decode.d7.loss_cls: 1.6534  decode.d7.loss_mask: 1.1501  decode.d7.loss_dice: 1.7534  decode.d8.loss_cls: 1.6755  decode.d8.loss_mask: 1.1051  decode.d8.loss_dice: 1.7101
2023/05/23 22:37:09 - mmengine - INFO - Iter(train) [ 35250/160000]  lr: 7.9934e-06  eta: 14:48:02  time: 0.4027  data_time: 0.0094  memory: 4838  grad_norm: 184.8473  loss: 32.4090  decode.loss_cls: 1.2409  decode.loss_mask: 0.5952  decode.loss_dice: 1.1428  decode.d0.loss_cls: 3.1570  decode.d0.loss_mask: 0.6525  decode.d0.loss_dice: 1.3056  decode.d1.loss_cls: 1.3047  decode.d1.loss_mask: 0.5984  decode.d1.loss_dice: 1.2259  decode.d2.loss_cls: 1.3687  decode.d2.loss_mask: 0.5736  decode.d2.loss_dice: 1.1397  decode.d3.loss_cls: 1.3372  decode.d3.loss_mask: 0.6053  decode.d3.loss_dice: 1.1579  decode.d4.loss_cls: 1.2788  decode.d4.loss_mask: 0.6476  decode.d4.loss_dice: 1.1903  decode.d5.loss_cls: 1.2862  decode.d5.loss_mask: 0.5876  decode.d5.loss_dice: 1.1573  decode.d6.loss_cls: 1.2366  decode.d6.loss_mask: 0.5995  decode.d6.loss_dice: 1.1444  decode.d7.loss_cls: 1.2047  decode.d7.loss_mask: 0.5979  decode.d7.loss_dice: 1.1635  decode.d8.loss_cls: 1.2112  decode.d8.loss_mask: 0.5834  decode.d8.loss_dice: 1.1147
2023/05/23 22:37:29 - mmengine - INFO - Iter(train) [ 35300/160000]  lr: 7.9905e-06  eta: 14:47:37  time: 0.4050  data_time: 0.0097  memory: 4804  grad_norm: 108.4280  loss: 31.5094  decode.loss_cls: 1.2072  decode.loss_mask: 0.6783  decode.loss_dice: 1.0118  decode.d0.loss_cls: 2.9343  decode.d0.loss_mask: 0.7801  decode.d0.loss_dice: 1.1665  decode.d1.loss_cls: 1.3504  decode.d1.loss_mask: 0.6786  decode.d1.loss_dice: 1.0180  decode.d2.loss_cls: 1.2627  decode.d2.loss_mask: 0.7134  decode.d2.loss_dice: 1.0427  decode.d3.loss_cls: 1.2706  decode.d3.loss_mask: 0.6914  decode.d3.loss_dice: 1.0313  decode.d4.loss_cls: 1.2779  decode.d4.loss_mask: 0.6810  decode.d4.loss_dice: 1.0346  decode.d5.loss_cls: 1.2207  decode.d5.loss_mask: 0.7066  decode.d5.loss_dice: 1.0357  decode.d6.loss_cls: 1.1814  decode.d6.loss_mask: 0.7004  decode.d6.loss_dice: 1.0340  decode.d7.loss_cls: 1.1674  decode.d7.loss_mask: 0.7087  decode.d7.loss_dice: 1.0194  decode.d8.loss_cls: 1.1756  decode.d8.loss_mask: 0.6964  decode.d8.loss_dice: 1.0327
2023/05/23 22:37:50 - mmengine - INFO - Iter(train) [ 35350/160000]  lr: 7.9876e-06  eta: 14:47:13  time: 0.4053  data_time: 0.0097  memory: 4804  grad_norm: 119.2163  loss: 29.1028  decode.loss_cls: 1.1506  decode.loss_mask: 0.6351  decode.loss_dice: 0.8121  decode.d0.loss_cls: 3.0113  decode.d0.loss_mask: 0.7868  decode.d0.loss_dice: 1.0298  decode.d1.loss_cls: 1.3283  decode.d1.loss_mask: 0.6844  decode.d1.loss_dice: 0.9006  decode.d2.loss_cls: 1.2292  decode.d2.loss_mask: 0.6939  decode.d2.loss_dice: 0.8950  decode.d3.loss_cls: 1.2261  decode.d3.loss_mask: 0.6556  decode.d3.loss_dice: 0.8414  decode.d4.loss_cls: 1.1977  decode.d4.loss_mask: 0.6524  decode.d4.loss_dice: 0.8400  decode.d5.loss_cls: 1.1357  decode.d5.loss_mask: 0.6614  decode.d5.loss_dice: 0.8341  decode.d6.loss_cls: 1.1418  decode.d6.loss_mask: 0.6676  decode.d6.loss_dice: 0.8380  decode.d7.loss_cls: 1.1147  decode.d7.loss_mask: 0.6559  decode.d7.loss_dice: 0.8188  decode.d8.loss_cls: 1.1564  decode.d8.loss_mask: 0.6623  decode.d8.loss_dice: 0.8458
2023/05/23 22:38:11 - mmengine - INFO - Iter(train) [ 35400/160000]  lr: 7.9847e-06  eta: 14:46:51  time: 0.4208  data_time: 0.0097  memory: 4792  grad_norm: 113.8310  loss: 36.5604  decode.loss_cls: 1.1702  decode.loss_mask: 0.8983  decode.loss_dice: 1.3212  decode.d0.loss_cls: 2.8746  decode.d0.loss_mask: 0.9358  decode.d0.loss_dice: 1.5332  decode.d1.loss_cls: 1.3748  decode.d1.loss_mask: 0.9081  decode.d1.loss_dice: 1.4881  decode.d2.loss_cls: 1.2498  decode.d2.loss_mask: 0.8526  decode.d2.loss_dice: 1.3756  decode.d3.loss_cls: 1.2349  decode.d3.loss_mask: 0.8429  decode.d3.loss_dice: 1.3640  decode.d4.loss_cls: 1.2564  decode.d4.loss_mask: 0.8507  decode.d4.loss_dice: 1.3845  decode.d5.loss_cls: 1.2307  decode.d5.loss_mask: 0.8330  decode.d5.loss_dice: 1.3415  decode.d6.loss_cls: 1.1690  decode.d6.loss_mask: 0.8544  decode.d6.loss_dice: 1.3950  decode.d7.loss_cls: 1.1750  decode.d7.loss_mask: 0.8548  decode.d7.loss_dice: 1.3832  decode.d8.loss_cls: 1.2033  decode.d8.loss_mask: 0.8620  decode.d8.loss_dice: 1.3429
2023/05/23 22:38:31 - mmengine - INFO - Iter(train) [ 35450/160000]  lr: 7.9819e-06  eta: 14:46:27  time: 0.4051  data_time: 0.0097  memory: 4837  grad_norm: 102.3242  loss: 35.5938  decode.loss_cls: 1.3606  decode.loss_mask: 0.7284  decode.loss_dice: 1.2056  decode.d0.loss_cls: 3.2970  decode.d0.loss_mask: 0.8449  decode.d0.loss_dice: 1.4338  decode.d1.loss_cls: 1.4724  decode.d1.loss_mask: 0.7466  decode.d1.loss_dice: 1.3263  decode.d2.loss_cls: 1.4023  decode.d2.loss_mask: 0.7426  decode.d2.loss_dice: 1.2430  decode.d3.loss_cls: 1.4382  decode.d3.loss_mask: 0.7441  decode.d3.loss_dice: 1.1976  decode.d4.loss_cls: 1.4105  decode.d4.loss_mask: 0.7220  decode.d4.loss_dice: 1.1673  decode.d5.loss_cls: 1.3922  decode.d5.loss_mask: 0.7195  decode.d5.loss_dice: 1.1721  decode.d6.loss_cls: 1.3818  decode.d6.loss_mask: 0.7316  decode.d6.loss_dice: 1.1775  decode.d7.loss_cls: 1.3605  decode.d7.loss_mask: 0.7187  decode.d7.loss_dice: 1.1823  decode.d8.loss_cls: 1.3401  decode.d8.loss_mask: 0.7351  decode.d8.loss_dice: 1.1991
2023/05/23 22:38:54 - mmengine - INFO - Iter(train) [ 35500/160000]  lr: 7.9790e-06  eta: 14:46:10  time: 0.4736  data_time: 0.0111  memory: 4825  grad_norm: 87.1014  loss: 38.8036  decode.loss_cls: 1.1726  decode.loss_mask: 1.0235  decode.loss_dice: 1.4296  decode.d0.loss_cls: 3.1273  decode.d0.loss_mask: 1.0797  decode.d0.loss_dice: 1.5591  decode.d1.loss_cls: 1.3486  decode.d1.loss_mask: 1.0786  decode.d1.loss_dice: 1.4846  decode.d2.loss_cls: 1.1973  decode.d2.loss_mask: 1.0243  decode.d2.loss_dice: 1.4340  decode.d3.loss_cls: 1.2345  decode.d3.loss_mask: 0.9790  decode.d3.loss_dice: 1.3961  decode.d4.loss_cls: 1.2382  decode.d4.loss_mask: 0.9941  decode.d4.loss_dice: 1.4361  decode.d5.loss_cls: 1.2287  decode.d5.loss_mask: 1.0102  decode.d5.loss_dice: 1.4370  decode.d6.loss_cls: 1.2276  decode.d6.loss_mask: 1.0164  decode.d6.loss_dice: 1.4189  decode.d7.loss_cls: 1.2040  decode.d7.loss_mask: 1.0267  decode.d7.loss_dice: 1.3842  decode.d8.loss_cls: 1.2002  decode.d8.loss_mask: 1.0088  decode.d8.loss_dice: 1.4035
2023/05/23 22:39:15 - mmengine - INFO - Iter(train) [ 35550/160000]  lr: 7.9761e-06  eta: 14:45:49  time: 0.4140  data_time: 0.0096  memory: 4866  grad_norm: 106.0621  loss: 34.6976  decode.loss_cls: 1.1114  decode.loss_mask: 0.9076  decode.loss_dice: 1.2287  decode.d0.loss_cls: 3.1081  decode.d0.loss_mask: 0.9141  decode.d0.loss_dice: 1.3683  decode.d1.loss_cls: 1.2001  decode.d1.loss_mask: 0.9407  decode.d1.loss_dice: 1.2644  decode.d2.loss_cls: 1.1285  decode.d2.loss_mask: 0.9309  decode.d2.loss_dice: 1.2336  decode.d3.loss_cls: 1.1297  decode.d3.loss_mask: 0.8984  decode.d3.loss_dice: 1.2084  decode.d4.loss_cls: 1.0707  decode.d4.loss_mask: 0.8980  decode.d4.loss_dice: 1.2305  decode.d5.loss_cls: 1.1306  decode.d5.loss_mask: 0.9171  decode.d5.loss_dice: 1.2077  decode.d6.loss_cls: 1.1167  decode.d6.loss_mask: 0.8983  decode.d6.loss_dice: 1.2267  decode.d7.loss_cls: 1.1172  decode.d7.loss_mask: 0.8927  decode.d7.loss_dice: 1.2105  decode.d8.loss_cls: 1.0665  decode.d8.loss_mask: 0.9044  decode.d8.loss_dice: 1.2371
2023/05/23 22:39:38 - mmengine - INFO - Iter(train) [ 35600/160000]  lr: 7.9732e-06  eta: 14:45:31  time: 0.4170  data_time: 0.0098  memory: 4824  grad_norm: 113.2071  loss: 40.1001  decode.loss_cls: 1.3859  decode.loss_mask: 0.7948  decode.loss_dice: 1.5182  decode.d0.loss_cls: 3.4419  decode.d0.loss_mask: 0.8893  decode.d0.loss_dice: 1.7711  decode.d1.loss_cls: 1.4601  decode.d1.loss_mask: 0.8530  decode.d1.loss_dice: 1.6439  decode.d2.loss_cls: 1.4652  decode.d2.loss_mask: 0.8137  decode.d2.loss_dice: 1.5799  decode.d3.loss_cls: 1.4875  decode.d3.loss_mask: 0.7872  decode.d3.loss_dice: 1.5447  decode.d4.loss_cls: 1.4258  decode.d4.loss_mask: 0.7890  decode.d4.loss_dice: 1.5307  decode.d5.loss_cls: 1.4053  decode.d5.loss_mask: 0.7927  decode.d5.loss_dice: 1.5517  decode.d6.loss_cls: 1.3598  decode.d6.loss_mask: 0.7962  decode.d6.loss_dice: 1.5469  decode.d7.loss_cls: 1.4015  decode.d7.loss_mask: 0.7873  decode.d7.loss_dice: 1.5288  decode.d8.loss_cls: 1.4202  decode.d8.loss_mask: 0.7959  decode.d8.loss_dice: 1.5319
2023/05/23 22:39:58 - mmengine - INFO - Iter(train) [ 35650/160000]  lr: 7.9703e-06  eta: 14:45:07  time: 0.4082  data_time: 0.0098  memory: 4830  grad_norm: 87.6557  loss: 34.3004  decode.loss_cls: 1.3263  decode.loss_mask: 0.6750  decode.loss_dice: 1.1986  decode.d0.loss_cls: 3.1837  decode.d0.loss_mask: 0.7153  decode.d0.loss_dice: 1.3473  decode.d1.loss_cls: 1.3923  decode.d1.loss_mask: 0.7516  decode.d1.loss_dice: 1.2480  decode.d2.loss_cls: 1.3454  decode.d2.loss_mask: 0.7219  decode.d2.loss_dice: 1.2170  decode.d3.loss_cls: 1.4117  decode.d3.loss_mask: 0.6763  decode.d3.loss_dice: 1.1855  decode.d4.loss_cls: 1.2906  decode.d4.loss_mask: 0.6744  decode.d4.loss_dice: 1.2228  decode.d5.loss_cls: 1.3616  decode.d5.loss_mask: 0.6754  decode.d5.loss_dice: 1.1523  decode.d6.loss_cls: 1.3499  decode.d6.loss_mask: 0.6884  decode.d6.loss_dice: 1.1600  decode.d7.loss_cls: 1.3281  decode.d7.loss_mask: 0.6783  decode.d7.loss_dice: 1.1813  decode.d8.loss_cls: 1.3220  decode.d8.loss_mask: 0.6668  decode.d8.loss_dice: 1.1526
2023/05/23 22:40:19 - mmengine - INFO - Iter(train) [ 35700/160000]  lr: 7.9674e-06  eta: 14:44:44  time: 0.4062  data_time: 0.0098  memory: 4837  grad_norm: 118.2054  loss: 26.9596  decode.loss_cls: 0.8645  decode.loss_mask: 0.6540  decode.loss_dice: 0.8812  decode.d0.loss_cls: 2.9226  decode.d0.loss_mask: 0.6961  decode.d0.loss_dice: 0.9941  decode.d1.loss_cls: 1.0586  decode.d1.loss_mask: 0.6689  decode.d1.loss_dice: 0.9198  decode.d2.loss_cls: 0.9825  decode.d2.loss_mask: 0.6639  decode.d2.loss_dice: 0.9081  decode.d3.loss_cls: 0.9538  decode.d3.loss_mask: 0.6654  decode.d3.loss_dice: 0.9176  decode.d4.loss_cls: 0.8987  decode.d4.loss_mask: 0.6661  decode.d4.loss_dice: 0.9227  decode.d5.loss_cls: 0.9069  decode.d5.loss_mask: 0.6442  decode.d5.loss_dice: 0.8931  decode.d6.loss_cls: 0.8741  decode.d6.loss_mask: 0.6745  decode.d6.loss_dice: 0.9082  decode.d7.loss_cls: 0.8631  decode.d7.loss_mask: 0.6546  decode.d7.loss_dice: 0.8969  decode.d8.loss_cls: 0.8261  decode.d8.loss_mask: 0.6711  decode.d8.loss_dice: 0.9080
2023/05/23 22:40:40 - mmengine - INFO - Iter(train) [ 35750/160000]  lr: 7.9645e-06  eta: 14:44:21  time: 0.4202  data_time: 0.0112  memory: 4821  grad_norm: 114.3936  loss: 32.6021  decode.loss_cls: 1.0242  decode.loss_mask: 0.6625  decode.loss_dice: 1.2221  decode.d0.loss_cls: 2.9345  decode.d0.loss_mask: 0.7582  decode.d0.loss_dice: 1.4686  decode.d1.loss_cls: 1.0859  decode.d1.loss_mask: 0.7573  decode.d1.loss_dice: 1.4277  decode.d2.loss_cls: 1.0666  decode.d2.loss_mask: 0.7826  decode.d2.loss_dice: 1.3659  decode.d3.loss_cls: 1.1235  decode.d3.loss_mask: 0.7062  decode.d3.loss_dice: 1.3294  decode.d4.loss_cls: 1.0175  decode.d4.loss_mask: 0.7094  decode.d4.loss_dice: 1.3275  decode.d5.loss_cls: 1.0742  decode.d5.loss_mask: 0.6733  decode.d5.loss_dice: 1.2821  decode.d6.loss_cls: 1.0140  decode.d6.loss_mask: 0.6666  decode.d6.loss_dice: 1.2469  decode.d7.loss_cls: 1.0400  decode.d7.loss_mask: 0.6609  decode.d7.loss_dice: 1.2300  decode.d8.loss_cls: 1.0126  decode.d8.loss_mask: 0.6552  decode.d8.loss_dice: 1.2766
2023/05/23 22:41:01 - mmengine - INFO - Iter(train) [ 35800/160000]  lr: 7.9617e-06  eta: 14:43:58  time: 0.4075  data_time: 0.0098  memory: 4845  grad_norm: 98.3704  loss: 44.3768  decode.loss_cls: 1.4711  decode.loss_mask: 1.1078  decode.loss_dice: 1.6485  decode.d0.loss_cls: 3.3525  decode.d0.loss_mask: 1.1620  decode.d0.loss_dice: 1.8396  decode.d1.loss_cls: 1.5868  decode.d1.loss_mask: 1.1252  decode.d1.loss_dice: 1.7379  decode.d2.loss_cls: 1.4034  decode.d2.loss_mask: 1.1148  decode.d2.loss_dice: 1.7056  decode.d3.loss_cls: 1.4761  decode.d3.loss_mask: 1.1036  decode.d3.loss_dice: 1.6239  decode.d4.loss_cls: 1.4444  decode.d4.loss_mask: 1.1165  decode.d4.loss_dice: 1.6652  decode.d5.loss_cls: 1.4017  decode.d5.loss_mask: 1.1416  decode.d5.loss_dice: 1.6381  decode.d6.loss_cls: 1.4319  decode.d6.loss_mask: 1.1013  decode.d6.loss_dice: 1.6761  decode.d7.loss_cls: 1.4449  decode.d7.loss_mask: 1.0938  decode.d7.loss_dice: 1.6341  decode.d8.loss_cls: 1.4020  decode.d8.loss_mask: 1.1069  decode.d8.loss_dice: 1.6200
2023/05/23 22:41:21 - mmengine - INFO - Iter(train) [ 35850/160000]  lr: 7.9588e-06  eta: 14:43:34  time: 0.4036  data_time: 0.0096  memory: 4955  grad_norm: 99.6730  loss: 38.3529  decode.loss_cls: 1.2814  decode.loss_mask: 0.8851  decode.loss_dice: 1.3994  decode.d0.loss_cls: 3.1321  decode.d0.loss_mask: 0.8426  decode.d0.loss_dice: 1.6921  decode.d1.loss_cls: 1.4162  decode.d1.loss_mask: 0.8128  decode.d1.loss_dice: 1.5532  decode.d2.loss_cls: 1.3543  decode.d2.loss_mask: 0.7855  decode.d2.loss_dice: 1.5163  decode.d3.loss_cls: 1.3604  decode.d3.loss_mask: 0.8041  decode.d3.loss_dice: 1.5325  decode.d4.loss_cls: 1.3279  decode.d4.loss_mask: 0.8475  decode.d4.loss_dice: 1.5120  decode.d5.loss_cls: 1.3398  decode.d5.loss_mask: 0.7660  decode.d5.loss_dice: 1.4201  decode.d6.loss_cls: 1.3920  decode.d6.loss_mask: 0.7839  decode.d6.loss_dice: 1.4445  decode.d7.loss_cls: 1.3875  decode.d7.loss_mask: 0.7871  decode.d7.loss_dice: 1.3911  decode.d8.loss_cls: 1.3610  decode.d8.loss_mask: 0.7857  decode.d8.loss_dice: 1.4387
2023/05/23 22:41:43 - mmengine - INFO - Iter(train) [ 35900/160000]  lr: 7.9559e-06  eta: 14:43:12  time: 0.4138  data_time: 0.0095  memory: 4837  grad_norm: 101.9477  loss: 35.1869  decode.loss_cls: 1.2858  decode.loss_mask: 0.7281  decode.loss_dice: 1.2121  decode.d0.loss_cls: 3.2128  decode.d0.loss_mask: 0.7708  decode.d0.loss_dice: 1.4997  decode.d1.loss_cls: 1.4972  decode.d1.loss_mask: 0.7205  decode.d1.loss_dice: 1.2855  decode.d2.loss_cls: 1.4182  decode.d2.loss_mask: 0.7208  decode.d2.loss_dice: 1.2811  decode.d3.loss_cls: 1.2369  decode.d3.loss_mask: 0.7568  decode.d3.loss_dice: 1.2804  decode.d4.loss_cls: 1.2344  decode.d4.loss_mask: 0.7823  decode.d4.loss_dice: 1.2610  decode.d5.loss_cls: 1.3161  decode.d5.loss_mask: 0.7347  decode.d5.loss_dice: 1.2449  decode.d6.loss_cls: 1.3042  decode.d6.loss_mask: 0.7101  decode.d6.loss_dice: 1.1970  decode.d7.loss_cls: 1.3211  decode.d7.loss_mask: 0.7578  decode.d7.loss_dice: 1.1530  decode.d8.loss_cls: 1.2977  decode.d8.loss_mask: 0.7440  decode.d8.loss_dice: 1.2221
2023/05/23 22:42:03 - mmengine - INFO - Iter(train) [ 35950/160000]  lr: 7.9530e-06  eta: 14:42:48  time: 0.4189  data_time: 0.0102  memory: 4895  grad_norm: 112.3634  loss: 52.0842  decode.loss_cls: 1.9283  decode.loss_mask: 0.9923  decode.loss_dice: 1.9844  decode.d0.loss_cls: 3.7486  decode.d0.loss_mask: 1.0678  decode.d0.loss_dice: 2.3667  decode.d1.loss_cls: 2.0234  decode.d1.loss_mask: 1.0184  decode.d1.loss_dice: 2.1534  decode.d2.loss_cls: 2.0680  decode.d2.loss_mask: 0.9948  decode.d2.loss_dice: 2.1223  decode.d3.loss_cls: 1.9553  decode.d3.loss_mask: 0.9904  decode.d3.loss_dice: 2.0366  decode.d4.loss_cls: 1.9484  decode.d4.loss_mask: 0.9682  decode.d4.loss_dice: 1.9784  decode.d5.loss_cls: 1.8690  decode.d5.loss_mask: 0.9785  decode.d5.loss_dice: 2.0407  decode.d6.loss_cls: 1.9352  decode.d6.loss_mask: 0.9775  decode.d6.loss_dice: 2.0367  decode.d7.loss_cls: 1.9259  decode.d7.loss_mask: 0.9819  decode.d7.loss_dice: 2.0318  decode.d8.loss_cls: 1.9608  decode.d8.loss_mask: 0.9904  decode.d8.loss_dice: 2.0101
2023/05/23 22:42:24 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 22:42:24 - mmengine - INFO - Iter(train) [ 36000/160000]  lr: 7.9501e-06  eta: 14:42:24  time: 0.4199  data_time: 0.0099  memory: 4824  grad_norm: 97.4308  loss: 44.5326  decode.loss_cls: 1.6055  decode.loss_mask: 0.8841  decode.loss_dice: 1.6263  decode.d0.loss_cls: 3.7255  decode.d0.loss_mask: 1.0077  decode.d0.loss_dice: 1.9063  decode.d1.loss_cls: 1.7590  decode.d1.loss_mask: 0.9572  decode.d1.loss_dice: 1.7926  decode.d2.loss_cls: 1.6158  decode.d2.loss_mask: 0.9900  decode.d2.loss_dice: 1.7617  decode.d3.loss_cls: 1.6587  decode.d3.loss_mask: 0.8909  decode.d3.loss_dice: 1.6785  decode.d4.loss_cls: 1.6662  decode.d4.loss_mask: 0.8657  decode.d4.loss_dice: 1.6578  decode.d5.loss_cls: 1.6162  decode.d5.loss_mask: 0.8658  decode.d5.loss_dice: 1.6252  decode.d6.loss_cls: 1.6314  decode.d6.loss_mask: 0.8674  decode.d6.loss_dice: 1.6473  decode.d7.loss_cls: 1.6119  decode.d7.loss_mask: 0.8679  decode.d7.loss_dice: 1.6351  decode.d8.loss_cls: 1.6221  decode.d8.loss_mask: 0.8649  decode.d8.loss_dice: 1.6279
2023/05/23 22:42:24 - mmengine - INFO - Saving checkpoint at 36000 iterations
2023/05/23 22:42:49 - mmengine - INFO - Iter(train) [ 36050/160000]  lr: 7.9472e-06  eta: 14:42:16  time: 0.4093  data_time: 0.0098  memory: 4888  grad_norm: 92.1739  loss: 35.8377  decode.loss_cls: 1.2543  decode.loss_mask: 0.8262  decode.loss_dice: 1.2142  decode.d0.loss_cls: 3.1907  decode.d0.loss_mask: 0.8258  decode.d0.loss_dice: 1.3372  decode.d1.loss_cls: 1.4024  decode.d1.loss_mask: 0.9021  decode.d1.loss_dice: 1.2973  decode.d2.loss_cls: 1.3823  decode.d2.loss_mask: 0.8493  decode.d2.loss_dice: 1.2690  decode.d3.loss_cls: 1.2919  decode.d3.loss_mask: 0.8597  decode.d3.loss_dice: 1.2562  decode.d4.loss_cls: 1.2866  decode.d4.loss_mask: 0.8432  decode.d4.loss_dice: 1.2520  decode.d5.loss_cls: 1.3072  decode.d5.loss_mask: 0.8152  decode.d5.loss_dice: 1.2114  decode.d6.loss_cls: 1.3013  decode.d6.loss_mask: 0.8293  decode.d6.loss_dice: 1.2111  decode.d7.loss_cls: 1.2997  decode.d7.loss_mask: 0.8288  decode.d7.loss_dice: 1.2056  decode.d8.loss_cls: 1.2831  decode.d8.loss_mask: 0.8045  decode.d8.loss_dice: 1.2001
2023/05/23 22:43:10 - mmengine - INFO - Iter(train) [ 36100/160000]  lr: 7.9444e-06  eta: 14:41:53  time: 0.4131  data_time: 0.0102  memory: 4872  grad_norm: 97.8984  loss: 47.9757  decode.loss_cls: 2.0537  decode.loss_mask: 0.8314  decode.loss_dice: 1.6033  decode.d0.loss_cls: 3.5237  decode.d0.loss_mask: 0.9800  decode.d0.loss_dice: 1.9255  decode.d1.loss_cls: 2.1948  decode.d1.loss_mask: 0.9007  decode.d1.loss_dice: 1.7982  decode.d2.loss_cls: 2.1177  decode.d2.loss_mask: 0.9070  decode.d2.loss_dice: 1.7503  decode.d3.loss_cls: 1.9827  decode.d3.loss_mask: 0.8775  decode.d3.loss_dice: 1.6900  decode.d4.loss_cls: 1.9968  decode.d4.loss_mask: 0.8611  decode.d4.loss_dice: 1.7138  decode.d5.loss_cls: 1.9742  decode.d5.loss_mask: 0.8566  decode.d5.loss_dice: 1.7179  decode.d6.loss_cls: 2.0096  decode.d6.loss_mask: 0.8434  decode.d6.loss_dice: 1.6947  decode.d7.loss_cls: 1.9983  decode.d7.loss_mask: 0.8745  decode.d7.loss_dice: 1.6600  decode.d8.loss_cls: 2.0810  decode.d8.loss_mask: 0.8752  decode.d8.loss_dice: 1.6821
2023/05/23 22:43:30 - mmengine - INFO - Iter(train) [ 36150/160000]  lr: 7.9415e-06  eta: 14:41:28  time: 0.4058  data_time: 0.0101  memory: 4948  grad_norm: 98.5881  loss: 46.8248  decode.loss_cls: 1.6655  decode.loss_mask: 1.0187  decode.loss_dice: 1.7689  decode.d0.loss_cls: 3.9441  decode.d0.loss_mask: 1.1036  decode.d0.loss_dice: 2.0328  decode.d1.loss_cls: 1.7329  decode.d1.loss_mask: 1.0122  decode.d1.loss_dice: 1.8142  decode.d2.loss_cls: 1.6366  decode.d2.loss_mask: 1.0204  decode.d2.loss_dice: 1.7946  decode.d3.loss_cls: 1.6803  decode.d3.loss_mask: 1.0487  decode.d3.loss_dice: 1.7667  decode.d4.loss_cls: 1.6244  decode.d4.loss_mask: 1.0240  decode.d4.loss_dice: 1.7888  decode.d5.loss_cls: 1.5559  decode.d5.loss_mask: 1.0112  decode.d5.loss_dice: 1.6972  decode.d6.loss_cls: 1.6120  decode.d6.loss_mask: 1.0171  decode.d6.loss_dice: 1.6816  decode.d7.loss_cls: 1.6650  decode.d7.loss_mask: 1.0007  decode.d7.loss_dice: 1.7558  decode.d8.loss_cls: 1.5744  decode.d8.loss_mask: 1.0013  decode.d8.loss_dice: 1.7749
2023/05/23 22:43:51 - mmengine - INFO - Iter(train) [ 36200/160000]  lr: 7.9386e-06  eta: 14:41:03  time: 0.4162  data_time: 0.0103  memory: 4865  grad_norm: 98.3028  loss: 38.7990  decode.loss_cls: 1.5499  decode.loss_mask: 0.6099  decode.loss_dice: 1.3613  decode.d0.loss_cls: 3.5039  decode.d0.loss_mask: 0.7313  decode.d0.loss_dice: 1.7115  decode.d1.loss_cls: 1.5725  decode.d1.loss_mask: 0.7137  decode.d1.loss_dice: 1.6183  decode.d2.loss_cls: 1.5564  decode.d2.loss_mask: 0.7052  decode.d2.loss_dice: 1.5450  decode.d3.loss_cls: 1.5291  decode.d3.loss_mask: 0.6430  decode.d3.loss_dice: 1.4285  decode.d4.loss_cls: 1.5434  decode.d4.loss_mask: 0.6237  decode.d4.loss_dice: 1.4564  decode.d5.loss_cls: 1.5394  decode.d5.loss_mask: 0.6242  decode.d5.loss_dice: 1.4042  decode.d6.loss_cls: 1.6424  decode.d6.loss_mask: 0.6013  decode.d6.loss_dice: 1.3662  decode.d7.loss_cls: 1.6339  decode.d7.loss_mask: 0.5928  decode.d7.loss_dice: 1.3824  decode.d8.loss_cls: 1.5263  decode.d8.loss_mask: 0.6310  decode.d8.loss_dice: 1.4519
2023/05/23 22:44:12 - mmengine - INFO - Iter(train) [ 36250/160000]  lr: 7.9357e-06  eta: 14:40:40  time: 0.4191  data_time: 0.0097  memory: 4821  grad_norm: 109.9714  loss: 39.8232  decode.loss_cls: 1.4692  decode.loss_mask: 0.8947  decode.loss_dice: 1.2341  decode.d0.loss_cls: 3.2704  decode.d0.loss_mask: 1.0196  decode.d0.loss_dice: 1.4995  decode.d1.loss_cls: 1.8163  decode.d1.loss_mask: 0.9107  decode.d1.loss_dice: 1.3985  decode.d2.loss_cls: 1.7292  decode.d2.loss_mask: 0.9137  decode.d2.loss_dice: 1.3017  decode.d3.loss_cls: 1.6734  decode.d3.loss_mask: 0.9141  decode.d3.loss_dice: 1.2882  decode.d4.loss_cls: 1.5784  decode.d4.loss_mask: 0.9429  decode.d4.loss_dice: 1.2877  decode.d5.loss_cls: 1.5656  decode.d5.loss_mask: 0.8815  decode.d5.loss_dice: 1.2773  decode.d6.loss_cls: 1.4933  decode.d6.loss_mask: 0.9216  decode.d6.loss_dice: 1.2707  decode.d7.loss_cls: 1.5037  decode.d7.loss_mask: 0.8903  decode.d7.loss_dice: 1.2878  decode.d8.loss_cls: 1.4526  decode.d8.loss_mask: 0.8912  decode.d8.loss_dice: 1.2455
2023/05/23 22:44:35 - mmengine - INFO - Iter(train) [ 36300/160000]  lr: 7.9328e-06  eta: 14:40:27  time: 0.4694  data_time: 0.0100  memory: 4877  grad_norm: 89.0939  loss: 37.3078  decode.loss_cls: 1.5628  decode.loss_mask: 0.6726  decode.loss_dice: 1.1100  decode.d0.loss_cls: 3.5998  decode.d0.loss_mask: 0.8365  decode.d0.loss_dice: 1.4582  decode.d1.loss_cls: 1.5906  decode.d1.loss_mask: 0.7821  decode.d1.loss_dice: 1.3482  decode.d2.loss_cls: 1.5979  decode.d2.loss_mask: 0.7209  decode.d2.loss_dice: 1.2421  decode.d3.loss_cls: 1.5741  decode.d3.loss_mask: 0.7249  decode.d3.loss_dice: 1.1994  decode.d4.loss_cls: 1.5835  decode.d4.loss_mask: 0.7211  decode.d4.loss_dice: 1.2206  decode.d5.loss_cls: 1.5319  decode.d5.loss_mask: 0.7260  decode.d5.loss_dice: 1.2052  decode.d6.loss_cls: 1.5553  decode.d6.loss_mask: 0.7072  decode.d6.loss_dice: 1.2085  decode.d7.loss_cls: 1.5503  decode.d7.loss_mask: 0.7030  decode.d7.loss_dice: 1.1842  decode.d8.loss_cls: 1.5348  decode.d8.loss_mask: 0.6933  decode.d8.loss_dice: 1.1627
2023/05/23 22:44:56 - mmengine - INFO - Iter(train) [ 36350/160000]  lr: 7.9299e-06  eta: 14:40:04  time: 0.4191  data_time: 0.0099  memory: 4845  grad_norm: 102.1222  loss: 32.2333  decode.loss_cls: 1.3401  decode.loss_mask: 0.6257  decode.loss_dice: 1.0000  decode.d0.loss_cls: 2.9527  decode.d0.loss_mask: 0.7269  decode.d0.loss_dice: 1.2255  decode.d1.loss_cls: 1.3974  decode.d1.loss_mask: 0.6539  decode.d1.loss_dice: 1.0599  decode.d2.loss_cls: 1.4381  decode.d2.loss_mask: 0.6559  decode.d2.loss_dice: 1.0609  decode.d3.loss_cls: 1.3143  decode.d3.loss_mask: 0.6250  decode.d3.loss_dice: 0.9980  decode.d4.loss_cls: 1.3809  decode.d4.loss_mask: 0.6106  decode.d4.loss_dice: 0.9855  decode.d5.loss_cls: 1.3775  decode.d5.loss_mask: 0.6647  decode.d5.loss_dice: 1.0056  decode.d6.loss_cls: 1.3854  decode.d6.loss_mask: 0.6662  decode.d6.loss_dice: 1.0493  decode.d7.loss_cls: 1.3725  decode.d7.loss_mask: 0.6564  decode.d7.loss_dice: 0.9937  decode.d8.loss_cls: 1.3434  decode.d8.loss_mask: 0.6525  decode.d8.loss_dice: 1.0150
2023/05/23 22:45:17 - mmengine - INFO - Iter(train) [ 36400/160000]  lr: 7.9270e-06  eta: 14:39:41  time: 0.4428  data_time: 0.0097  memory: 4835  grad_norm: 94.7280  loss: 34.8951  decode.loss_cls: 1.1795  decode.loss_mask: 0.7694  decode.loss_dice: 1.1926  decode.d0.loss_cls: 3.2127  decode.d0.loss_mask: 0.7824  decode.d0.loss_dice: 1.4220  decode.d1.loss_cls: 1.3844  decode.d1.loss_mask: 0.7407  decode.d1.loss_dice: 1.3529  decode.d2.loss_cls: 1.2388  decode.d2.loss_mask: 0.7761  decode.d2.loss_dice: 1.3050  decode.d3.loss_cls: 1.2499  decode.d3.loss_mask: 0.7871  decode.d3.loss_dice: 1.2610  decode.d4.loss_cls: 1.2622  decode.d4.loss_mask: 0.8261  decode.d4.loss_dice: 1.2483  decode.d5.loss_cls: 1.1944  decode.d5.loss_mask: 0.8657  decode.d5.loss_dice: 1.2473  decode.d6.loss_cls: 1.2110  decode.d6.loss_mask: 0.7803  decode.d6.loss_dice: 1.2322  decode.d7.loss_cls: 1.1339  decode.d7.loss_mask: 0.8569  decode.d7.loss_dice: 1.2126  decode.d8.loss_cls: 1.1507  decode.d8.loss_mask: 0.8039  decode.d8.loss_dice: 1.2153
2023/05/23 22:45:38 - mmengine - INFO - Iter(train) [ 36450/160000]  lr: 7.9242e-06  eta: 14:39:17  time: 0.4062  data_time: 0.0096  memory: 4821  grad_norm: 95.5420  loss: 39.6840  decode.loss_cls: 1.3659  decode.loss_mask: 0.8822  decode.loss_dice: 1.3807  decode.d0.loss_cls: 3.1688  decode.d0.loss_mask: 0.9024  decode.d0.loss_dice: 1.6839  decode.d1.loss_cls: 1.3922  decode.d1.loss_mask: 0.9954  decode.d1.loss_dice: 1.5931  decode.d2.loss_cls: 1.3691  decode.d2.loss_mask: 0.9329  decode.d2.loss_dice: 1.5323  decode.d3.loss_cls: 1.3702  decode.d3.loss_mask: 0.9116  decode.d3.loss_dice: 1.4952  decode.d4.loss_cls: 1.4424  decode.d4.loss_mask: 0.8847  decode.d4.loss_dice: 1.4717  decode.d5.loss_cls: 1.4781  decode.d5.loss_mask: 0.9063  decode.d5.loss_dice: 1.4322  decode.d6.loss_cls: 1.3903  decode.d6.loss_mask: 0.9024  decode.d6.loss_dice: 1.4511  decode.d7.loss_cls: 1.3727  decode.d7.loss_mask: 0.8742  decode.d7.loss_dice: 1.4185  decode.d8.loss_cls: 1.3428  decode.d8.loss_mask: 0.8920  decode.d8.loss_dice: 1.4487
2023/05/23 22:45:58 - mmengine - INFO - Iter(train) [ 36500/160000]  lr: 7.9213e-06  eta: 14:38:54  time: 0.4332  data_time: 0.0104  memory: 4848  grad_norm: 101.1990  loss: 38.6252  decode.loss_cls: 1.2390  decode.loss_mask: 0.9475  decode.loss_dice: 1.3907  decode.d0.loss_cls: 3.2984  decode.d0.loss_mask: 0.9252  decode.d0.loss_dice: 1.5624  decode.d1.loss_cls: 1.4781  decode.d1.loss_mask: 0.9389  decode.d1.loss_dice: 1.4458  decode.d2.loss_cls: 1.3683  decode.d2.loss_mask: 0.9034  decode.d2.loss_dice: 1.4560  decode.d3.loss_cls: 1.2323  decode.d3.loss_mask: 0.9740  decode.d3.loss_dice: 1.4201  decode.d4.loss_cls: 1.2307  decode.d4.loss_mask: 0.9396  decode.d4.loss_dice: 1.4076  decode.d5.loss_cls: 1.2926  decode.d5.loss_mask: 0.9346  decode.d5.loss_dice: 1.4030  decode.d6.loss_cls: 1.2932  decode.d6.loss_mask: 0.9574  decode.d6.loss_dice: 1.3961  decode.d7.loss_cls: 1.2656  decode.d7.loss_mask: 0.9658  decode.d7.loss_dice: 1.3783  decode.d8.loss_cls: 1.2272  decode.d8.loss_mask: 0.9474  decode.d8.loss_dice: 1.4059
2023/05/23 22:46:20 - mmengine - INFO - Iter(train) [ 36550/160000]  lr: 7.9184e-06  eta: 14:38:33  time: 0.4703  data_time: 0.0095  memory: 4998  grad_norm: 109.8781  loss: 38.7866  decode.loss_cls: 1.4114  decode.loss_mask: 0.7696  decode.loss_dice: 1.5121  decode.d0.loss_cls: 3.2820  decode.d0.loss_mask: 0.7434  decode.d0.loss_dice: 1.6941  decode.d1.loss_cls: 1.4382  decode.d1.loss_mask: 0.7348  decode.d1.loss_dice: 1.6112  decode.d2.loss_cls: 1.4058  decode.d2.loss_mask: 0.7491  decode.d2.loss_dice: 1.5731  decode.d3.loss_cls: 1.3544  decode.d3.loss_mask: 0.7871  decode.d3.loss_dice: 1.5251  decode.d4.loss_cls: 1.2579  decode.d4.loss_mask: 0.7804  decode.d4.loss_dice: 1.5424  decode.d5.loss_cls: 1.3455  decode.d5.loss_mask: 0.7752  decode.d5.loss_dice: 1.4996  decode.d6.loss_cls: 1.3874  decode.d6.loss_mask: 0.7588  decode.d6.loss_dice: 1.5039  decode.d7.loss_cls: 1.3595  decode.d7.loss_mask: 0.7649  decode.d7.loss_dice: 1.5482  decode.d8.loss_cls: 1.4199  decode.d8.loss_mask: 0.7460  decode.d8.loss_dice: 1.5056
2023/05/23 22:46:41 - mmengine - INFO - Iter(train) [ 36600/160000]  lr: 7.9155e-06  eta: 14:38:10  time: 0.4138  data_time: 0.0097  memory: 4857  grad_norm: 82.2434  loss: 33.4117  decode.loss_cls: 1.1693  decode.loss_mask: 0.6387  decode.loss_dice: 1.2315  decode.d0.loss_cls: 3.0680  decode.d0.loss_mask: 0.6969  decode.d0.loss_dice: 1.3750  decode.d1.loss_cls: 1.3961  decode.d1.loss_mask: 0.6957  decode.d1.loss_dice: 1.2979  decode.d2.loss_cls: 1.2741  decode.d2.loss_mask: 0.6545  decode.d2.loss_dice: 1.2672  decode.d3.loss_cls: 1.2152  decode.d3.loss_mask: 0.6858  decode.d3.loss_dice: 1.2448  decode.d4.loss_cls: 1.2219  decode.d4.loss_mask: 0.6654  decode.d4.loss_dice: 1.2473  decode.d5.loss_cls: 1.1747  decode.d5.loss_mask: 0.6706  decode.d5.loss_dice: 1.2551  decode.d6.loss_cls: 1.2484  decode.d6.loss_mask: 0.6492  decode.d6.loss_dice: 1.2230  decode.d7.loss_cls: 1.2144  decode.d7.loss_mask: 0.6403  decode.d7.loss_dice: 1.2133  decode.d8.loss_cls: 1.1919  decode.d8.loss_mask: 0.6454  decode.d8.loss_dice: 1.2403
2023/05/23 22:47:01 - mmengine - INFO - Iter(train) [ 36650/160000]  lr: 7.9126e-06  eta: 14:37:46  time: 0.4163  data_time: 0.0098  memory: 4890  grad_norm: 90.5446  loss: 36.8200  decode.loss_cls: 1.1829  decode.loss_mask: 0.8821  decode.loss_dice: 1.3035  decode.d0.loss_cls: 3.0503  decode.d0.loss_mask: 0.9559  decode.d0.loss_dice: 1.5370  decode.d1.loss_cls: 1.3083  decode.d1.loss_mask: 0.9993  decode.d1.loss_dice: 1.4997  decode.d2.loss_cls: 1.2419  decode.d2.loss_mask: 0.9436  decode.d2.loss_dice: 1.4118  decode.d3.loss_cls: 1.1155  decode.d3.loss_mask: 0.9367  decode.d3.loss_dice: 1.3505  decode.d4.loss_cls: 1.1472  decode.d4.loss_mask: 0.9135  decode.d4.loss_dice: 1.3492  decode.d5.loss_cls: 1.1658  decode.d5.loss_mask: 0.9095  decode.d5.loss_dice: 1.3217  decode.d6.loss_cls: 1.2037  decode.d6.loss_mask: 0.8907  decode.d6.loss_dice: 1.3383  decode.d7.loss_cls: 1.1996  decode.d7.loss_mask: 0.8961  decode.d7.loss_dice: 1.3389  decode.d8.loss_cls: 1.2306  decode.d8.loss_mask: 0.8570  decode.d8.loss_dice: 1.3395
2023/05/23 22:47:23 - mmengine - INFO - Iter(train) [ 36700/160000]  lr: 7.9097e-06  eta: 14:37:24  time: 0.4122  data_time: 0.0097  memory: 4853  grad_norm: 98.1693  loss: 31.2566  decode.loss_cls: 1.1594  decode.loss_mask: 0.6984  decode.loss_dice: 0.9538  decode.d0.loss_cls: 3.1597  decode.d0.loss_mask: 0.7574  decode.d0.loss_dice: 1.1167  decode.d1.loss_cls: 1.3570  decode.d1.loss_mask: 0.6889  decode.d1.loss_dice: 1.0836  decode.d2.loss_cls: 1.3221  decode.d2.loss_mask: 0.7151  decode.d2.loss_dice: 1.0488  decode.d3.loss_cls: 1.2838  decode.d3.loss_mask: 0.6735  decode.d3.loss_dice: 0.9810  decode.d4.loss_cls: 1.2385  decode.d4.loss_mask: 0.6866  decode.d4.loss_dice: 0.9998  decode.d5.loss_cls: 1.1898  decode.d5.loss_mask: 0.6880  decode.d5.loss_dice: 0.9667  decode.d6.loss_cls: 1.2053  decode.d6.loss_mask: 0.6792  decode.d6.loss_dice: 0.9390  decode.d7.loss_cls: 1.1862  decode.d7.loss_mask: 0.6829  decode.d7.loss_dice: 0.9662  decode.d8.loss_cls: 1.1749  decode.d8.loss_mask: 0.6955  decode.d8.loss_dice: 0.9589
2023/05/23 22:47:43 - mmengine - INFO - Iter(train) [ 36750/160000]  lr: 7.9068e-06  eta: 14:37:00  time: 0.4036  data_time: 0.0097  memory: 4795  grad_norm: 148.4304  loss: 33.9727  decode.loss_cls: 1.3578  decode.loss_mask: 0.7420  decode.loss_dice: 1.0083  decode.d0.loss_cls: 3.1525  decode.d0.loss_mask: 0.8336  decode.d0.loss_dice: 1.1815  decode.d1.loss_cls: 1.5733  decode.d1.loss_mask: 0.7349  decode.d1.loss_dice: 1.1668  decode.d2.loss_cls: 1.4728  decode.d2.loss_mask: 0.7126  decode.d2.loss_dice: 1.1012  decode.d3.loss_cls: 1.4010  decode.d3.loss_mask: 0.7241  decode.d3.loss_dice: 1.0671  decode.d4.loss_cls: 1.4196  decode.d4.loss_mask: 0.7155  decode.d4.loss_dice: 1.0401  decode.d5.loss_cls: 1.4389  decode.d5.loss_mask: 0.7106  decode.d5.loss_dice: 1.0166  decode.d6.loss_cls: 1.3759  decode.d6.loss_mask: 0.6955  decode.d6.loss_dice: 1.0520  decode.d7.loss_cls: 1.3716  decode.d7.loss_mask: 0.7131  decode.d7.loss_dice: 1.0380  decode.d8.loss_cls: 1.3924  decode.d8.loss_mask: 0.7265  decode.d8.loss_dice: 1.0371
2023/05/23 22:48:04 - mmengine - INFO - Iter(train) [ 36800/160000]  lr: 7.9039e-06  eta: 14:36:38  time: 0.4239  data_time: 0.0097  memory: 4845  grad_norm: 82.4099  loss: 29.7532  decode.loss_cls: 1.0446  decode.loss_mask: 0.6933  decode.loss_dice: 0.9419  decode.d0.loss_cls: 2.8992  decode.d0.loss_mask: 0.7574  decode.d0.loss_dice: 1.1725  decode.d1.loss_cls: 1.1955  decode.d1.loss_mask: 0.7161  decode.d1.loss_dice: 1.0583  decode.d2.loss_cls: 1.0991  decode.d2.loss_mask: 0.6975  decode.d2.loss_dice: 1.0243  decode.d3.loss_cls: 1.1423  decode.d3.loss_mask: 0.6442  decode.d3.loss_dice: 0.9858  decode.d4.loss_cls: 1.0825  decode.d4.loss_mask: 0.7025  decode.d4.loss_dice: 0.9661  decode.d5.loss_cls: 1.0583  decode.d5.loss_mask: 0.6724  decode.d5.loss_dice: 0.9846  decode.d6.loss_cls: 1.0617  decode.d6.loss_mask: 0.6934  decode.d6.loss_dice: 0.9726  decode.d7.loss_cls: 1.0728  decode.d7.loss_mask: 0.7104  decode.d7.loss_dice: 0.9885  decode.d8.loss_cls: 1.0551  decode.d8.loss_mask: 0.7018  decode.d8.loss_dice: 0.9584
2023/05/23 22:48:26 - mmengine - INFO - Iter(train) [ 36850/160000]  lr: 7.9011e-06  eta: 14:36:17  time: 0.4388  data_time: 0.0101  memory: 4819  grad_norm: 113.5878  loss: 33.0359  decode.loss_cls: 1.2135  decode.loss_mask: 0.7841  decode.loss_dice: 1.0987  decode.d0.loss_cls: 2.8986  decode.d0.loss_mask: 0.8098  decode.d0.loss_dice: 1.2475  decode.d1.loss_cls: 1.2656  decode.d1.loss_mask: 0.7936  decode.d1.loss_dice: 1.2137  decode.d2.loss_cls: 1.1958  decode.d2.loss_mask: 0.7742  decode.d2.loss_dice: 1.1465  decode.d3.loss_cls: 1.2064  decode.d3.loss_mask: 0.7927  decode.d3.loss_dice: 1.1158  decode.d4.loss_cls: 1.2298  decode.d4.loss_mask: 0.8171  decode.d4.loss_dice: 1.1413  decode.d5.loss_cls: 1.1832  decode.d5.loss_mask: 0.7751  decode.d5.loss_dice: 1.1162  decode.d6.loss_cls: 1.1676  decode.d6.loss_mask: 0.7763  decode.d6.loss_dice: 1.1185  decode.d7.loss_cls: 1.1851  decode.d7.loss_mask: 0.7900  decode.d7.loss_dice: 1.1080  decode.d8.loss_cls: 1.1674  decode.d8.loss_mask: 0.7860  decode.d8.loss_dice: 1.1178
2023/05/23 22:48:49 - mmengine - INFO - Iter(train) [ 36900/160000]  lr: 7.8982e-06  eta: 14:36:02  time: 0.4646  data_time: 0.0099  memory: 4857  grad_norm: 99.9584  loss: 41.2855  decode.loss_cls: 1.4406  decode.loss_mask: 0.7778  decode.loss_dice: 1.6127  decode.d0.loss_cls: 3.4979  decode.d0.loss_mask: 0.9691  decode.d0.loss_dice: 1.8773  decode.d1.loss_cls: 1.5602  decode.d1.loss_mask: 0.9310  decode.d1.loss_dice: 1.7644  decode.d2.loss_cls: 1.4462  decode.d2.loss_mask: 0.8883  decode.d2.loss_dice: 1.7122  decode.d3.loss_cls: 1.3940  decode.d3.loss_mask: 0.8474  decode.d3.loss_dice: 1.6221  decode.d4.loss_cls: 1.4362  decode.d4.loss_mask: 0.7841  decode.d4.loss_dice: 1.5970  decode.d5.loss_cls: 1.3845  decode.d5.loss_mask: 0.7642  decode.d5.loss_dice: 1.6121  decode.d6.loss_cls: 1.3735  decode.d6.loss_mask: 0.7577  decode.d6.loss_dice: 1.6171  decode.d7.loss_cls: 1.4282  decode.d7.loss_mask: 0.7450  decode.d7.loss_dice: 1.6261  decode.d8.loss_cls: 1.4042  decode.d8.loss_mask: 0.7690  decode.d8.loss_dice: 1.6457
2023/05/23 22:49:10 - mmengine - INFO - Iter(train) [ 36950/160000]  lr: 7.8953e-06  eta: 14:35:38  time: 0.4020  data_time: 0.0096  memory: 4802  grad_norm: 100.4440  loss: 34.0474  decode.loss_cls: 1.2391  decode.loss_mask: 0.7404  decode.loss_dice: 1.1461  decode.d0.loss_cls: 3.1718  decode.d0.loss_mask: 0.7983  decode.d0.loss_dice: 1.3085  decode.d1.loss_cls: 1.4436  decode.d1.loss_mask: 0.7860  decode.d1.loss_dice: 1.2500  decode.d2.loss_cls: 1.2620  decode.d2.loss_mask: 0.7837  decode.d2.loss_dice: 1.1657  decode.d3.loss_cls: 1.2762  decode.d3.loss_mask: 0.7926  decode.d3.loss_dice: 1.1483  decode.d4.loss_cls: 1.2237  decode.d4.loss_mask: 0.7921  decode.d4.loss_dice: 1.1597  decode.d5.loss_cls: 1.2624  decode.d5.loss_mask: 0.7798  decode.d5.loss_dice: 1.1488  decode.d6.loss_cls: 1.2224  decode.d6.loss_mask: 0.7863  decode.d6.loss_dice: 1.1332  decode.d7.loss_cls: 1.2134  decode.d7.loss_mask: 0.7532  decode.d7.loss_dice: 1.1320  decode.d8.loss_cls: 1.2127  decode.d8.loss_mask: 0.7676  decode.d8.loss_dice: 1.1476
2023/05/23 22:49:30 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 22:49:30 - mmengine - INFO - Iter(train) [ 37000/160000]  lr: 7.8924e-06  eta: 14:35:14  time: 0.4047  data_time: 0.0098  memory: 4857  grad_norm: 103.4000  loss: 39.8281  decode.loss_cls: 1.5283  decode.loss_mask: 0.8926  decode.loss_dice: 1.2924  decode.d0.loss_cls: 3.2092  decode.d0.loss_mask: 1.0012  decode.d0.loss_dice: 1.5025  decode.d1.loss_cls: 1.6085  decode.d1.loss_mask: 0.9867  decode.d1.loss_dice: 1.4236  decode.d2.loss_cls: 1.5824  decode.d2.loss_mask: 0.9398  decode.d2.loss_dice: 1.3908  decode.d3.loss_cls: 1.5567  decode.d3.loss_mask: 0.8955  decode.d3.loss_dice: 1.3084  decode.d4.loss_cls: 1.5161  decode.d4.loss_mask: 0.8989  decode.d4.loss_dice: 1.3078  decode.d5.loss_cls: 1.5996  decode.d5.loss_mask: 0.8801  decode.d5.loss_dice: 1.3217  decode.d6.loss_cls: 1.5094  decode.d6.loss_mask: 0.8920  decode.d6.loss_dice: 1.3000  decode.d7.loss_cls: 1.5339  decode.d7.loss_mask: 0.8803  decode.d7.loss_dice: 1.3009  decode.d8.loss_cls: 1.5154  decode.d8.loss_mask: 0.9211  decode.d8.loss_dice: 1.3322
2023/05/23 22:49:30 - mmengine - INFO - Saving checkpoint at 37000 iterations
2023/05/23 22:49:57 - mmengine - INFO - Iter(train) [ 37050/160000]  lr: 7.8895e-06  eta: 14:35:12  time: 0.4209  data_time: 0.0097  memory: 4829  grad_norm: 95.8669  loss: 32.8850  decode.loss_cls: 1.1691  decode.loss_mask: 0.6689  decode.loss_dice: 1.1262  decode.d0.loss_cls: 2.9951  decode.d0.loss_mask: 0.7411  decode.d0.loss_dice: 1.2847  decode.d1.loss_cls: 1.3959  decode.d1.loss_mask: 0.7386  decode.d1.loss_dice: 1.2168  decode.d2.loss_cls: 1.3724  decode.d2.loss_mask: 0.6610  decode.d2.loss_dice: 1.1383  decode.d3.loss_cls: 1.3142  decode.d3.loss_mask: 0.6887  decode.d3.loss_dice: 1.1518  decode.d4.loss_cls: 1.3266  decode.d4.loss_mask: 0.6538  decode.d4.loss_dice: 1.0930  decode.d5.loss_cls: 1.2161  decode.d5.loss_mask: 0.7079  decode.d5.loss_dice: 1.1506  decode.d6.loss_cls: 1.3001  decode.d6.loss_mask: 0.6451  decode.d6.loss_dice: 1.1146  decode.d7.loss_cls: 1.2150  decode.d7.loss_mask: 0.6678  decode.d7.loss_dice: 1.1355  decode.d8.loss_cls: 1.2011  decode.d8.loss_mask: 0.6648  decode.d8.loss_dice: 1.1302
2023/05/23 22:50:18 - mmengine - INFO - Iter(train) [ 37100/160000]  lr: 7.8866e-06  eta: 14:34:50  time: 0.4147  data_time: 0.0096  memory: 5019  grad_norm: 101.8730  loss: 43.5510  decode.loss_cls: 1.5041  decode.loss_mask: 0.8485  decode.loss_dice: 1.6296  decode.d0.loss_cls: 3.6145  decode.d0.loss_mask: 0.9322  decode.d0.loss_dice: 1.9319  decode.d1.loss_cls: 1.6194  decode.d1.loss_mask: 0.9222  decode.d1.loss_dice: 1.8668  decode.d2.loss_cls: 1.5615  decode.d2.loss_mask: 0.9214  decode.d2.loss_dice: 1.7968  decode.d3.loss_cls: 1.5612  decode.d3.loss_mask: 0.8630  decode.d3.loss_dice: 1.7160  decode.d4.loss_cls: 1.5633  decode.d4.loss_mask: 0.8594  decode.d4.loss_dice: 1.6757  decode.d5.loss_cls: 1.5845  decode.d5.loss_mask: 0.8489  decode.d5.loss_dice: 1.6452  decode.d6.loss_cls: 1.5336  decode.d6.loss_mask: 0.8602  decode.d6.loss_dice: 1.6748  decode.d7.loss_cls: 1.5070  decode.d7.loss_mask: 0.8604  decode.d7.loss_dice: 1.6523  decode.d8.loss_cls: 1.4618  decode.d8.loss_mask: 0.8558  decode.d8.loss_dice: 1.6789
2023/05/23 22:50:39 - mmengine - INFO - Iter(train) [ 37150/160000]  lr: 7.8837e-06  eta: 14:34:26  time: 0.4127  data_time: 0.0096  memory: 4992  grad_norm: 104.7961  loss: 36.0280  decode.loss_cls: 1.2627  decode.loss_mask: 0.7192  decode.loss_dice: 1.3412  decode.d0.loss_cls: 3.3095  decode.d0.loss_mask: 0.7901  decode.d0.loss_dice: 1.5805  decode.d1.loss_cls: 1.2419  decode.d1.loss_mask: 0.7695  decode.d1.loss_dice: 1.4680  decode.d2.loss_cls: 1.2937  decode.d2.loss_mask: 0.7439  decode.d2.loss_dice: 1.4253  decode.d3.loss_cls: 1.2382  decode.d3.loss_mask: 0.7285  decode.d3.loss_dice: 1.3830  decode.d4.loss_cls: 1.1956  decode.d4.loss_mask: 0.7614  decode.d4.loss_dice: 1.3941  decode.d5.loss_cls: 1.2342  decode.d5.loss_mask: 0.7579  decode.d5.loss_dice: 1.3654  decode.d6.loss_cls: 1.3144  decode.d6.loss_mask: 0.7013  decode.d6.loss_dice: 1.3550  decode.d7.loss_cls: 1.2677  decode.d7.loss_mask: 0.7030  decode.d7.loss_dice: 1.3375  decode.d8.loss_cls: 1.2478  decode.d8.loss_mask: 0.7302  decode.d8.loss_dice: 1.3674
2023/05/23 22:51:00 - mmengine - INFO - Iter(train) [ 37200/160000]  lr: 7.8808e-06  eta: 14:34:02  time: 0.4102  data_time: 0.0098  memory: 4829  grad_norm: 81.7275  loss: 32.8930  decode.loss_cls: 1.2256  decode.loss_mask: 0.7478  decode.loss_dice: 1.0554  decode.d0.loss_cls: 2.7959  decode.d0.loss_mask: 0.8115  decode.d0.loss_dice: 1.1908  decode.d1.loss_cls: 1.3730  decode.d1.loss_mask: 0.8024  decode.d1.loss_dice: 1.1597  decode.d2.loss_cls: 1.3283  decode.d2.loss_mask: 0.7933  decode.d2.loss_dice: 1.1171  decode.d3.loss_cls: 1.2632  decode.d3.loss_mask: 0.7664  decode.d3.loss_dice: 1.1077  decode.d4.loss_cls: 1.2376  decode.d4.loss_mask: 0.7560  decode.d4.loss_dice: 1.1046  decode.d5.loss_cls: 1.2479  decode.d5.loss_mask: 0.7362  decode.d5.loss_dice: 1.0786  decode.d6.loss_cls: 1.2706  decode.d6.loss_mask: 0.7237  decode.d6.loss_dice: 1.0685  decode.d7.loss_cls: 1.2901  decode.d7.loss_mask: 0.7138  decode.d7.loss_dice: 1.0727  decode.d8.loss_cls: 1.2732  decode.d8.loss_mask: 0.7271  decode.d8.loss_dice: 1.0544
2023/05/23 22:51:20 - mmengine - INFO - Iter(train) [ 37250/160000]  lr: 7.8780e-06  eta: 14:33:39  time: 0.4211  data_time: 0.0096  memory: 4874  grad_norm: 95.5065  loss: 39.0733  decode.loss_cls: 1.3992  decode.loss_mask: 0.8854  decode.loss_dice: 1.3080  decode.d0.loss_cls: 3.5340  decode.d0.loss_mask: 0.8790  decode.d0.loss_dice: 1.5059  decode.d1.loss_cls: 1.5526  decode.d1.loss_mask: 0.9416  decode.d1.loss_dice: 1.4645  decode.d2.loss_cls: 1.4663  decode.d2.loss_mask: 0.9269  decode.d2.loss_dice: 1.4044  decode.d3.loss_cls: 1.5068  decode.d3.loss_mask: 0.8690  decode.d3.loss_dice: 1.3198  decode.d4.loss_cls: 1.4737  decode.d4.loss_mask: 0.8660  decode.d4.loss_dice: 1.3363  decode.d5.loss_cls: 1.4433  decode.d5.loss_mask: 0.8517  decode.d5.loss_dice: 1.3219  decode.d6.loss_cls: 1.4663  decode.d6.loss_mask: 0.8562  decode.d6.loss_dice: 1.2831  decode.d7.loss_cls: 1.4365  decode.d7.loss_mask: 0.8608  decode.d7.loss_dice: 1.3009  decode.d8.loss_cls: 1.4172  decode.d8.loss_mask: 0.8865  decode.d8.loss_dice: 1.3094
2023/05/23 22:51:42 - mmengine - INFO - Iter(train) [ 37300/160000]  lr: 7.8751e-06  eta: 14:33:19  time: 0.4114  data_time: 0.0098  memory: 4876  grad_norm: 99.1401  loss: 38.0636  decode.loss_cls: 1.3017  decode.loss_mask: 0.8628  decode.loss_dice: 1.3835  decode.d0.loss_cls: 3.3005  decode.d0.loss_mask: 0.9188  decode.d0.loss_dice: 1.7087  decode.d1.loss_cls: 1.3723  decode.d1.loss_mask: 0.8857  decode.d1.loss_dice: 1.5107  decode.d2.loss_cls: 1.2624  decode.d2.loss_mask: 0.8328  decode.d2.loss_dice: 1.4666  decode.d3.loss_cls: 1.2568  decode.d3.loss_mask: 0.8507  decode.d3.loss_dice: 1.4028  decode.d4.loss_cls: 1.2058  decode.d4.loss_mask: 0.8543  decode.d4.loss_dice: 1.4695  decode.d5.loss_cls: 1.2479  decode.d5.loss_mask: 0.8441  decode.d5.loss_dice: 1.4489  decode.d6.loss_cls: 1.2594  decode.d6.loss_mask: 0.8933  decode.d6.loss_dice: 1.4558  decode.d7.loss_cls: 1.2619  decode.d7.loss_mask: 0.8707  decode.d7.loss_dice: 1.4013  decode.d8.loss_cls: 1.3038  decode.d8.loss_mask: 0.8508  decode.d8.loss_dice: 1.3791
2023/05/23 22:52:03 - mmengine - INFO - Iter(train) [ 37350/160000]  lr: 7.8722e-06  eta: 14:32:56  time: 0.4077  data_time: 0.0101  memory: 4838  grad_norm: 103.6865  loss: 37.3599  decode.loss_cls: 1.2221  decode.loss_mask: 0.8297  decode.loss_dice: 1.3290  decode.d0.loss_cls: 3.1666  decode.d0.loss_mask: 0.8657  decode.d0.loss_dice: 1.5636  decode.d1.loss_cls: 1.4145  decode.d1.loss_mask: 0.8791  decode.d1.loss_dice: 1.4736  decode.d2.loss_cls: 1.2830  decode.d2.loss_mask: 0.8419  decode.d2.loss_dice: 1.4045  decode.d3.loss_cls: 1.3522  decode.d3.loss_mask: 0.8406  decode.d3.loss_dice: 1.3963  decode.d4.loss_cls: 1.2482  decode.d4.loss_mask: 0.9078  decode.d4.loss_dice: 1.3903  decode.d5.loss_cls: 1.3072  decode.d5.loss_mask: 0.8405  decode.d5.loss_dice: 1.3988  decode.d6.loss_cls: 1.3396  decode.d6.loss_mask: 0.7898  decode.d6.loss_dice: 1.3569  decode.d7.loss_cls: 1.3604  decode.d7.loss_mask: 0.7692  decode.d7.loss_dice: 1.3542  decode.d8.loss_cls: 1.3304  decode.d8.loss_mask: 0.7991  decode.d8.loss_dice: 1.3049
2023/05/23 22:52:24 - mmengine - INFO - Iter(train) [ 37400/160000]  lr: 7.8693e-06  eta: 14:32:34  time: 0.4254  data_time: 0.0099  memory: 4846  grad_norm: 86.6223  loss: 42.1192  decode.loss_cls: 1.4952  decode.loss_mask: 0.8766  decode.loss_dice: 1.5214  decode.d0.loss_cls: 3.6124  decode.d0.loss_mask: 0.9423  decode.d0.loss_dice: 1.7830  decode.d1.loss_cls: 1.6867  decode.d1.loss_mask: 0.9154  decode.d1.loss_dice: 1.6329  decode.d2.loss_cls: 1.6079  decode.d2.loss_mask: 0.8780  decode.d2.loss_dice: 1.5322  decode.d3.loss_cls: 1.5416  decode.d3.loss_mask: 0.8941  decode.d3.loss_dice: 1.5412  decode.d4.loss_cls: 1.4999  decode.d4.loss_mask: 0.9005  decode.d4.loss_dice: 1.5635  decode.d5.loss_cls: 1.4811  decode.d5.loss_mask: 0.9075  decode.d5.loss_dice: 1.5845  decode.d6.loss_cls: 1.4966  decode.d6.loss_mask: 0.8782  decode.d6.loss_dice: 1.5300  decode.d7.loss_cls: 1.5019  decode.d7.loss_mask: 0.8917  decode.d7.loss_dice: 1.4906  decode.d8.loss_cls: 1.4974  decode.d8.loss_mask: 0.8942  decode.d8.loss_dice: 1.5409
2023/05/23 22:52:45 - mmengine - INFO - Iter(train) [ 37450/160000]  lr: 7.8664e-06  eta: 14:32:11  time: 0.4135  data_time: 0.0097  memory: 4826  grad_norm: 89.0761  loss: 39.2661  decode.loss_cls: 1.3847  decode.loss_mask: 0.7244  decode.loss_dice: 1.5594  decode.d0.loss_cls: 3.0832  decode.d0.loss_mask: 0.8289  decode.d0.loss_dice: 1.7580  decode.d1.loss_cls: 1.4930  decode.d1.loss_mask: 0.7580  decode.d1.loss_dice: 1.6934  decode.d2.loss_cls: 1.4200  decode.d2.loss_mask: 0.7278  decode.d2.loss_dice: 1.6116  decode.d3.loss_cls: 1.4005  decode.d3.loss_mask: 0.7345  decode.d3.loss_dice: 1.5847  decode.d4.loss_cls: 1.4053  decode.d4.loss_mask: 0.7356  decode.d4.loss_dice: 1.6078  decode.d5.loss_cls: 1.3629  decode.d5.loss_mask: 0.7522  decode.d5.loss_dice: 1.5962  decode.d6.loss_cls: 1.3329  decode.d6.loss_mask: 0.7715  decode.d6.loss_dice: 1.5586  decode.d7.loss_cls: 1.2889  decode.d7.loss_mask: 0.7991  decode.d7.loss_dice: 1.5840  decode.d8.loss_cls: 1.4049  decode.d8.loss_mask: 0.7235  decode.d8.loss_dice: 1.5808
2023/05/23 22:53:06 - mmengine - INFO - Iter(train) [ 37500/160000]  lr: 7.8635e-06  eta: 14:31:48  time: 0.4059  data_time: 0.0099  memory: 4829  grad_norm: 113.5625  loss: 35.8460  decode.loss_cls: 1.1479  decode.loss_mask: 0.8134  decode.loss_dice: 1.3569  decode.d0.loss_cls: 3.1585  decode.d0.loss_mask: 0.7872  decode.d0.loss_dice: 1.5247  decode.d1.loss_cls: 1.2014  decode.d1.loss_mask: 0.8843  decode.d1.loss_dice: 1.5098  decode.d2.loss_cls: 1.1879  decode.d2.loss_mask: 0.8497  decode.d2.loss_dice: 1.4306  decode.d3.loss_cls: 1.1320  decode.d3.loss_mask: 0.8415  decode.d3.loss_dice: 1.4315  decode.d4.loss_cls: 1.0948  decode.d4.loss_mask: 0.8231  decode.d4.loss_dice: 1.3877  decode.d5.loss_cls: 1.1349  decode.d5.loss_mask: 0.8157  decode.d5.loss_dice: 1.3845  decode.d6.loss_cls: 1.1382  decode.d6.loss_mask: 0.8307  decode.d6.loss_dice: 1.3941  decode.d7.loss_cls: 1.1505  decode.d7.loss_mask: 0.8126  decode.d7.loss_dice: 1.3633  decode.d8.loss_cls: 1.1181  decode.d8.loss_mask: 0.8093  decode.d8.loss_dice: 1.3315
2023/05/23 22:53:27 - mmengine - INFO - Iter(train) [ 37550/160000]  lr: 7.8606e-06  eta: 14:31:25  time: 0.4153  data_time: 0.0103  memory: 4845  grad_norm: 91.2989  loss: 39.5046  decode.loss_cls: 1.1613  decode.loss_mask: 1.0086  decode.loss_dice: 1.4202  decode.d0.loss_cls: 3.2229  decode.d0.loss_mask: 1.0224  decode.d0.loss_dice: 1.6679  decode.d1.loss_cls: 1.2816  decode.d1.loss_mask: 1.0901  decode.d1.loss_dice: 1.5938  decode.d2.loss_cls: 1.3293  decode.d2.loss_mask: 1.0535  decode.d2.loss_dice: 1.5218  decode.d3.loss_cls: 1.2075  decode.d3.loss_mask: 1.0755  decode.d3.loss_dice: 1.4870  decode.d4.loss_cls: 1.1818  decode.d4.loss_mask: 1.0646  decode.d4.loss_dice: 1.4728  decode.d5.loss_cls: 1.1932  decode.d5.loss_mask: 1.0872  decode.d5.loss_dice: 1.4863  decode.d6.loss_cls: 1.1558  decode.d6.loss_mask: 1.0537  decode.d6.loss_dice: 1.4744  decode.d7.loss_cls: 1.1650  decode.d7.loss_mask: 1.0106  decode.d7.loss_dice: 1.4234  decode.d8.loss_cls: 1.1422  decode.d8.loss_mask: 1.0022  decode.d8.loss_dice: 1.4480
2023/05/23 22:53:50 - mmengine - INFO - Iter(train) [ 37600/160000]  lr: 7.8577e-06  eta: 14:31:12  time: 0.4742  data_time: 0.0097  memory: 4838  grad_norm: 81.3714  loss: 34.4183  decode.loss_cls: 1.2110  decode.loss_mask: 0.7231  decode.loss_dice: 1.1770  decode.d0.loss_cls: 3.2329  decode.d0.loss_mask: 0.7956  decode.d0.loss_dice: 1.3761  decode.d1.loss_cls: 1.3433  decode.d1.loss_mask: 0.8113  decode.d1.loss_dice: 1.3314  decode.d2.loss_cls: 1.2959  decode.d2.loss_mask: 0.7543  decode.d2.loss_dice: 1.2782  decode.d3.loss_cls: 1.2612  decode.d3.loss_mask: 0.7257  decode.d3.loss_dice: 1.2452  decode.d4.loss_cls: 1.1735  decode.d4.loss_mask: 0.7483  decode.d4.loss_dice: 1.2481  decode.d5.loss_cls: 1.2305  decode.d5.loss_mask: 0.7188  decode.d5.loss_dice: 1.2316  decode.d6.loss_cls: 1.1993  decode.d6.loss_mask: 0.7308  decode.d6.loss_dice: 1.2335  decode.d7.loss_cls: 1.1930  decode.d7.loss_mask: 0.7415  decode.d7.loss_dice: 1.2390  decode.d8.loss_cls: 1.2140  decode.d8.loss_mask: 0.7223  decode.d8.loss_dice: 1.2322
2023/05/23 22:54:12 - mmengine - INFO - Iter(train) [ 37650/160000]  lr: 7.8549e-06  eta: 14:30:50  time: 0.4241  data_time: 0.0097  memory: 4875  grad_norm: 133.8582  loss: 36.4777  decode.loss_cls: 1.3392  decode.loss_mask: 0.7082  decode.loss_dice: 1.3030  decode.d0.loss_cls: 3.2831  decode.d0.loss_mask: 0.7372  decode.d0.loss_dice: 1.4861  decode.d1.loss_cls: 1.5011  decode.d1.loss_mask: 0.7116  decode.d1.loss_dice: 1.4034  decode.d2.loss_cls: 1.5369  decode.d2.loss_mask: 0.7218  decode.d2.loss_dice: 1.3525  decode.d3.loss_cls: 1.4105  decode.d3.loss_mask: 0.7033  decode.d3.loss_dice: 1.3329  decode.d4.loss_cls: 1.3488  decode.d4.loss_mask: 0.7047  decode.d4.loss_dice: 1.3575  decode.d5.loss_cls: 1.4057  decode.d5.loss_mask: 0.6917  decode.d5.loss_dice: 1.3197  decode.d6.loss_cls: 1.3785  decode.d6.loss_mask: 0.7230  decode.d6.loss_dice: 1.3341  decode.d7.loss_cls: 1.3445  decode.d7.loss_mask: 0.6971  decode.d7.loss_dice: 1.3171  decode.d8.loss_cls: 1.3258  decode.d8.loss_mask: 0.6993  decode.d8.loss_dice: 1.2993
2023/05/23 22:54:32 - mmengine - INFO - Iter(train) [ 37700/160000]  lr: 7.8520e-06  eta: 14:30:26  time: 0.4156  data_time: 0.0098  memory: 4895  grad_norm: 104.3938  loss: 37.0715  decode.loss_cls: 1.3539  decode.loss_mask: 0.7439  decode.loss_dice: 1.3251  decode.d0.loss_cls: 3.2831  decode.d0.loss_mask: 0.8181  decode.d0.loss_dice: 1.5172  decode.d1.loss_cls: 1.4518  decode.d1.loss_mask: 0.8123  decode.d1.loss_dice: 1.4997  decode.d2.loss_cls: 1.3311  decode.d2.loss_mask: 0.7904  decode.d2.loss_dice: 1.4488  decode.d3.loss_cls: 1.3609  decode.d3.loss_mask: 0.7719  decode.d3.loss_dice: 1.3746  decode.d4.loss_cls: 1.3362  decode.d4.loss_mask: 0.8129  decode.d4.loss_dice: 1.3772  decode.d5.loss_cls: 1.3254  decode.d5.loss_mask: 0.7765  decode.d5.loss_dice: 1.3601  decode.d6.loss_cls: 1.3235  decode.d6.loss_mask: 0.7361  decode.d6.loss_dice: 1.3398  decode.d7.loss_cls: 1.3321  decode.d7.loss_mask: 0.7207  decode.d7.loss_dice: 1.3460  decode.d8.loss_cls: 1.3570  decode.d8.loss_mask: 0.7322  decode.d8.loss_dice: 1.3129
2023/05/23 22:54:54 - mmengine - INFO - Iter(train) [ 37750/160000]  lr: 7.8491e-06  eta: 14:30:07  time: 0.4793  data_time: 0.0100  memory: 4838  grad_norm: 113.9066  loss: 45.9858  decode.loss_cls: 1.2899  decode.loss_mask: 1.0598  decode.loss_dice: 2.0007  decode.d0.loss_cls: 2.9372  decode.d0.loss_mask: 1.0973  decode.d0.loss_dice: 2.2424  decode.d1.loss_cls: 1.3491  decode.d1.loss_mask: 1.0678  decode.d1.loss_dice: 2.1344  decode.d2.loss_cls: 1.3488  decode.d2.loss_mask: 1.0462  decode.d2.loss_dice: 2.0872  decode.d3.loss_cls: 1.4265  decode.d3.loss_mask: 1.0269  decode.d3.loss_dice: 1.9840  decode.d4.loss_cls: 1.3450  decode.d4.loss_mask: 1.0114  decode.d4.loss_dice: 1.9988  decode.d5.loss_cls: 1.2999  decode.d5.loss_mask: 1.0454  decode.d5.loss_dice: 2.0410  decode.d6.loss_cls: 1.3365  decode.d6.loss_mask: 1.0329  decode.d6.loss_dice: 2.0020  decode.d7.loss_cls: 1.2954  decode.d7.loss_mask: 1.0627  decode.d7.loss_dice: 2.0498  decode.d8.loss_cls: 1.2848  decode.d8.loss_mask: 1.0664  decode.d8.loss_dice: 2.0155
2023/05/23 22:55:16 - mmengine - INFO - Iter(train) [ 37800/160000]  lr: 7.8462e-06  eta: 14:29:45  time: 0.4132  data_time: 0.0099  memory: 4829  grad_norm: 117.9703  loss: 46.0948  decode.loss_cls: 1.4532  decode.loss_mask: 0.9101  decode.loss_dice: 1.8978  decode.d0.loss_cls: 3.4369  decode.d0.loss_mask: 1.0322  decode.d0.loss_dice: 2.1550  decode.d1.loss_cls: 1.7007  decode.d1.loss_mask: 0.9690  decode.d1.loss_dice: 2.0763  decode.d2.loss_cls: 1.5377  decode.d2.loss_mask: 0.9564  decode.d2.loss_dice: 1.9985  decode.d3.loss_cls: 1.5544  decode.d3.loss_mask: 0.9145  decode.d3.loss_dice: 1.9243  decode.d4.loss_cls: 1.5039  decode.d4.loss_mask: 0.9045  decode.d4.loss_dice: 2.0106  decode.d5.loss_cls: 1.4577  decode.d5.loss_mask: 0.9014  decode.d5.loss_dice: 1.9333  decode.d6.loss_cls: 1.5078  decode.d6.loss_mask: 0.9057  decode.d6.loss_dice: 1.9376  decode.d7.loss_cls: 1.4404  decode.d7.loss_mask: 0.8954  decode.d7.loss_dice: 1.8851  decode.d8.loss_cls: 1.4638  decode.d8.loss_mask: 0.8853  decode.d8.loss_dice: 1.9451
2023/05/23 22:55:36 - mmengine - INFO - Iter(train) [ 37850/160000]  lr: 7.8433e-06  eta: 14:29:21  time: 0.4196  data_time: 0.0096  memory: 4848  grad_norm: 158.6879  loss: 42.5922  decode.loss_cls: 1.6874  decode.loss_mask: 0.7667  decode.loss_dice: 1.4372  decode.d0.loss_cls: 3.5078  decode.d0.loss_mask: 0.8458  decode.d0.loss_dice: 1.7498  decode.d1.loss_cls: 1.9334  decode.d1.loss_mask: 0.8767  decode.d1.loss_dice: 1.6160  decode.d2.loss_cls: 1.7503  decode.d2.loss_mask: 0.8317  decode.d2.loss_dice: 1.5627  decode.d3.loss_cls: 1.8373  decode.d3.loss_mask: 0.8199  decode.d3.loss_dice: 1.4969  decode.d4.loss_cls: 1.7602  decode.d4.loss_mask: 0.8003  decode.d4.loss_dice: 1.5173  decode.d5.loss_cls: 1.7683  decode.d5.loss_mask: 0.7531  decode.d5.loss_dice: 1.4714  decode.d6.loss_cls: 1.6795  decode.d6.loss_mask: 0.8152  decode.d6.loss_dice: 1.4349  decode.d7.loss_cls: 1.7169  decode.d7.loss_mask: 0.7960  decode.d7.loss_dice: 1.4529  decode.d8.loss_cls: 1.6663  decode.d8.loss_mask: 0.7715  decode.d8.loss_dice: 1.4686
2023/05/23 22:55:57 - mmengine - INFO - Iter(train) [ 37900/160000]  lr: 7.8404e-06  eta: 14:28:58  time: 0.4157  data_time: 0.0097  memory: 4847  grad_norm: 116.4392  loss: 36.4564  decode.loss_cls: 1.2152  decode.loss_mask: 0.8258  decode.loss_dice: 1.3276  decode.d0.loss_cls: 2.8384  decode.d0.loss_mask: 0.9262  decode.d0.loss_dice: 1.4581  decode.d1.loss_cls: 1.4289  decode.d1.loss_mask: 0.8917  decode.d1.loss_dice: 1.3207  decode.d2.loss_cls: 1.2498  decode.d2.loss_mask: 0.8645  decode.d2.loss_dice: 1.3357  decode.d3.loss_cls: 1.3081  decode.d3.loss_mask: 0.8882  decode.d3.loss_dice: 1.3506  decode.d4.loss_cls: 1.3277  decode.d4.loss_mask: 0.8355  decode.d4.loss_dice: 1.3284  decode.d5.loss_cls: 1.2842  decode.d5.loss_mask: 0.8662  decode.d5.loss_dice: 1.3188  decode.d6.loss_cls: 1.2749  decode.d6.loss_mask: 0.8433  decode.d6.loss_dice: 1.3186  decode.d7.loss_cls: 1.2387  decode.d7.loss_mask: 0.8613  decode.d7.loss_dice: 1.3193  decode.d8.loss_cls: 1.2508  decode.d8.loss_mask: 0.8295  decode.d8.loss_dice: 1.3297
2023/05/23 22:56:18 - mmengine - INFO - Iter(train) [ 37950/160000]  lr: 7.8375e-06  eta: 14:28:35  time: 0.4189  data_time: 0.0100  memory: 4874  grad_norm: 143.4397  loss: 35.3428  decode.loss_cls: 1.3297  decode.loss_mask: 0.7622  decode.loss_dice: 1.1883  decode.d0.loss_cls: 2.8555  decode.d0.loss_mask: 0.8188  decode.d0.loss_dice: 1.4093  decode.d1.loss_cls: 1.4822  decode.d1.loss_mask: 0.7945  decode.d1.loss_dice: 1.3483  decode.d2.loss_cls: 1.4314  decode.d2.loss_mask: 0.7696  decode.d2.loss_dice: 1.2583  decode.d3.loss_cls: 1.4015  decode.d3.loss_mask: 0.7851  decode.d3.loss_dice: 1.2526  decode.d4.loss_cls: 1.3756  decode.d4.loss_mask: 0.7799  decode.d4.loss_dice: 1.2118  decode.d5.loss_cls: 1.3636  decode.d5.loss_mask: 0.7674  decode.d5.loss_dice: 1.1508  decode.d6.loss_cls: 1.3500  decode.d6.loss_mask: 0.7480  decode.d6.loss_dice: 1.1924  decode.d7.loss_cls: 1.2878  decode.d7.loss_mask: 0.7601  decode.d7.loss_dice: 1.2079  decode.d8.loss_cls: 1.3353  decode.d8.loss_mask: 0.7641  decode.d8.loss_dice: 1.1607
2023/05/23 22:56:39 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 22:56:39 - mmengine - INFO - Iter(train) [ 38000/160000]  lr: 7.8346e-06  eta: 14:28:12  time: 0.4176  data_time: 0.0102  memory: 4796  grad_norm: 87.9949  loss: 32.5888  decode.loss_cls: 1.1188  decode.loss_mask: 0.8587  decode.loss_dice: 1.0785  decode.d0.loss_cls: 2.9966  decode.d0.loss_mask: 0.8546  decode.d0.loss_dice: 1.1958  decode.d1.loss_cls: 1.1703  decode.d1.loss_mask: 0.8485  decode.d1.loss_dice: 1.1397  decode.d2.loss_cls: 1.1438  decode.d2.loss_mask: 0.8207  decode.d2.loss_dice: 1.0935  decode.d3.loss_cls: 1.1147  decode.d3.loss_mask: 0.8235  decode.d3.loss_dice: 1.0805  decode.d4.loss_cls: 1.1379  decode.d4.loss_mask: 0.8255  decode.d4.loss_dice: 1.0729  decode.d5.loss_cls: 1.1372  decode.d5.loss_mask: 0.8450  decode.d5.loss_dice: 1.0610  decode.d6.loss_cls: 1.1741  decode.d6.loss_mask: 0.8318  decode.d6.loss_dice: 1.0663  decode.d7.loss_cls: 1.1565  decode.d7.loss_mask: 0.8432  decode.d7.loss_dice: 1.0369  decode.d8.loss_cls: 1.1392  decode.d8.loss_mask: 0.8559  decode.d8.loss_dice: 1.0671
2023/05/23 22:56:39 - mmengine - INFO - Saving checkpoint at 38000 iterations
2023/05/23 22:57:05 - mmengine - INFO - Iter(train) [ 38050/160000]  lr: 7.8317e-06  eta: 14:28:07  time: 0.4124  data_time: 0.0099  memory: 4847  grad_norm: 100.6189  loss: 42.3156  decode.loss_cls: 1.6155  decode.loss_mask: 0.9376  decode.loss_dice: 1.3768  decode.d0.loss_cls: 3.5308  decode.d0.loss_mask: 1.0128  decode.d0.loss_dice: 1.6746  decode.d1.loss_cls: 1.7800  decode.d1.loss_mask: 0.9624  decode.d1.loss_dice: 1.5375  decode.d2.loss_cls: 1.6352  decode.d2.loss_mask: 0.9513  decode.d2.loss_dice: 1.4796  decode.d3.loss_cls: 1.6694  decode.d3.loss_mask: 0.9119  decode.d3.loss_dice: 1.3962  decode.d4.loss_cls: 1.6840  decode.d4.loss_mask: 0.9133  decode.d4.loss_dice: 1.4116  decode.d5.loss_cls: 1.5926  decode.d5.loss_mask: 0.9312  decode.d5.loss_dice: 1.4045  decode.d6.loss_cls: 1.6191  decode.d6.loss_mask: 0.9297  decode.d6.loss_dice: 1.3932  decode.d7.loss_cls: 1.6348  decode.d7.loss_mask: 0.9378  decode.d7.loss_dice: 1.4370  decode.d8.loss_cls: 1.6371  decode.d8.loss_mask: 0.9369  decode.d8.loss_dice: 1.3814
2023/05/23 22:57:26 - mmengine - INFO - Iter(train) [ 38100/160000]  lr: 7.8288e-06  eta: 14:27:46  time: 0.4419  data_time: 0.0096  memory: 4928  grad_norm: 130.3954  loss: 34.5650  decode.loss_cls: 1.3714  decode.loss_mask: 0.5324  decode.loss_dice: 1.3069  decode.d0.loss_cls: 3.1038  decode.d0.loss_mask: 0.5668  decode.d0.loss_dice: 1.5289  decode.d1.loss_cls: 1.4582  decode.d1.loss_mask: 0.5647  decode.d1.loss_dice: 1.4092  decode.d2.loss_cls: 1.3560  decode.d2.loss_mask: 0.5563  decode.d2.loss_dice: 1.3511  decode.d3.loss_cls: 1.3865  decode.d3.loss_mask: 0.5430  decode.d3.loss_dice: 1.3135  decode.d4.loss_cls: 1.4088  decode.d4.loss_mask: 0.5370  decode.d4.loss_dice: 1.3678  decode.d5.loss_cls: 1.4174  decode.d5.loss_mask: 0.5312  decode.d5.loss_dice: 1.3046  decode.d6.loss_cls: 1.4297  decode.d6.loss_mask: 0.5318  decode.d6.loss_dice: 1.2665  decode.d7.loss_cls: 1.3830  decode.d7.loss_mask: 0.5293  decode.d7.loss_dice: 1.2813  decode.d8.loss_cls: 1.3915  decode.d8.loss_mask: 0.5360  decode.d8.loss_dice: 1.3003
2023/05/23 22:57:48 - mmengine - INFO - Iter(train) [ 38150/160000]  lr: 7.8260e-06  eta: 14:27:25  time: 0.4705  data_time: 0.0110  memory: 4903  grad_norm: 94.7635  loss: 40.1185  decode.loss_cls: 1.5540  decode.loss_mask: 0.7959  decode.loss_dice: 1.3201  decode.d0.loss_cls: 3.5814  decode.d0.loss_mask: 0.8819  decode.d0.loss_dice: 1.6187  decode.d1.loss_cls: 1.6625  decode.d1.loss_mask: 0.8563  decode.d1.loss_dice: 1.4713  decode.d2.loss_cls: 1.6283  decode.d2.loss_mask: 0.8133  decode.d2.loss_dice: 1.4163  decode.d3.loss_cls: 1.6210  decode.d3.loss_mask: 0.7850  decode.d3.loss_dice: 1.3648  decode.d4.loss_cls: 1.5949  decode.d4.loss_mask: 0.7961  decode.d4.loss_dice: 1.3727  decode.d5.loss_cls: 1.5628  decode.d5.loss_mask: 0.7821  decode.d5.loss_dice: 1.3855  decode.d6.loss_cls: 1.5943  decode.d6.loss_mask: 0.8075  decode.d6.loss_dice: 1.3554  decode.d7.loss_cls: 1.5829  decode.d7.loss_mask: 0.8233  decode.d7.loss_dice: 1.3722  decode.d8.loss_cls: 1.5522  decode.d8.loss_mask: 0.8061  decode.d8.loss_dice: 1.3599
2023/05/23 22:58:11 - mmengine - INFO - Iter(train) [ 38200/160000]  lr: 7.8231e-06  eta: 14:27:09  time: 0.4308  data_time: 0.0103  memory: 4822  grad_norm: 93.2998  loss: 37.1185  decode.loss_cls: 1.4418  decode.loss_mask: 0.8520  decode.loss_dice: 1.1215  decode.d0.loss_cls: 3.5097  decode.d0.loss_mask: 0.9997  decode.d0.loss_dice: 1.3128  decode.d1.loss_cls: 1.6761  decode.d1.loss_mask: 0.8800  decode.d1.loss_dice: 1.1795  decode.d2.loss_cls: 1.5234  decode.d2.loss_mask: 0.8740  decode.d2.loss_dice: 1.1741  decode.d3.loss_cls: 1.5113  decode.d3.loss_mask: 0.8641  decode.d3.loss_dice: 1.1507  decode.d4.loss_cls: 1.4246  decode.d4.loss_mask: 0.8673  decode.d4.loss_dice: 1.1645  decode.d5.loss_cls: 1.4890  decode.d5.loss_mask: 0.8633  decode.d5.loss_dice: 1.1213  decode.d6.loss_cls: 1.4480  decode.d6.loss_mask: 0.8395  decode.d6.loss_dice: 1.1152  decode.d7.loss_cls: 1.3244  decode.d7.loss_mask: 0.8612  decode.d7.loss_dice: 1.1664  decode.d8.loss_cls: 1.3947  decode.d8.loss_mask: 0.8456  decode.d8.loss_dice: 1.1226
2023/05/23 22:58:32 - mmengine - INFO - Iter(train) [ 38250/160000]  lr: 7.8202e-06  eta: 14:26:46  time: 0.4115  data_time: 0.0097  memory: 4847  grad_norm: 104.9240  loss: 39.0104  decode.loss_cls: 1.3248  decode.loss_mask: 0.7372  decode.loss_dice: 1.4858  decode.d0.loss_cls: 3.2807  decode.d0.loss_mask: 0.8786  decode.d0.loss_dice: 1.7736  decode.d1.loss_cls: 1.2523  decode.d1.loss_mask: 0.8693  decode.d1.loss_dice: 1.7101  decode.d2.loss_cls: 1.3269  decode.d2.loss_mask: 0.8565  decode.d2.loss_dice: 1.5698  decode.d3.loss_cls: 1.3766  decode.d3.loss_mask: 0.7837  decode.d3.loss_dice: 1.5772  decode.d4.loss_cls: 1.3421  decode.d4.loss_mask: 0.8093  decode.d4.loss_dice: 1.5696  decode.d5.loss_cls: 1.3142  decode.d5.loss_mask: 0.7940  decode.d5.loss_dice: 1.5281  decode.d6.loss_cls: 1.3522  decode.d6.loss_mask: 0.7792  decode.d6.loss_dice: 1.5121  decode.d7.loss_cls: 1.2732  decode.d7.loss_mask: 0.7950  decode.d7.loss_dice: 1.5664  decode.d8.loss_cls: 1.2644  decode.d8.loss_mask: 0.7827  decode.d8.loss_dice: 1.5248
2023/05/23 22:58:53 - mmengine - INFO - Iter(train) [ 38300/160000]  lr: 7.8173e-06  eta: 14:26:25  time: 0.4447  data_time: 0.0106  memory: 4845  grad_norm: 97.1101  loss: 45.1727  decode.loss_cls: 1.6101  decode.loss_mask: 1.0123  decode.loss_dice: 1.5812  decode.d0.loss_cls: 3.6526  decode.d0.loss_mask: 1.0257  decode.d0.loss_dice: 1.8817  decode.d1.loss_cls: 1.7560  decode.d1.loss_mask: 1.0252  decode.d1.loss_dice: 1.7976  decode.d2.loss_cls: 1.6712  decode.d2.loss_mask: 0.9909  decode.d2.loss_dice: 1.6486  decode.d3.loss_cls: 1.6271  decode.d3.loss_mask: 1.0229  decode.d3.loss_dice: 1.6514  decode.d4.loss_cls: 1.6055  decode.d4.loss_mask: 1.0012  decode.d4.loss_dice: 1.6581  decode.d5.loss_cls: 1.6621  decode.d5.loss_mask: 0.9877  decode.d5.loss_dice: 1.6038  decode.d6.loss_cls: 1.6474  decode.d6.loss_mask: 0.9716  decode.d6.loss_dice: 1.5777  decode.d7.loss_cls: 1.6335  decode.d7.loss_mask: 1.0252  decode.d7.loss_dice: 1.6176  decode.d8.loss_cls: 1.6608  decode.d8.loss_mask: 1.0070  decode.d8.loss_dice: 1.5590
2023/05/23 22:59:14 - mmengine - INFO - Iter(train) [ 38350/160000]  lr: 7.8144e-06  eta: 14:26:01  time: 0.4204  data_time: 0.0098  memory: 4788  grad_norm: 118.6249  loss: 39.5719  decode.loss_cls: 1.4077  decode.loss_mask: 0.8245  decode.loss_dice: 1.4504  decode.d0.loss_cls: 3.3631  decode.d0.loss_mask: 0.8650  decode.d0.loss_dice: 1.6152  decode.d1.loss_cls: 1.5581  decode.d1.loss_mask: 0.8720  decode.d1.loss_dice: 1.5734  decode.d2.loss_cls: 1.4822  decode.d2.loss_mask: 0.8432  decode.d2.loss_dice: 1.5129  decode.d3.loss_cls: 1.4064  decode.d3.loss_mask: 0.8362  decode.d3.loss_dice: 1.4902  decode.d4.loss_cls: 1.4705  decode.d4.loss_mask: 0.8473  decode.d4.loss_dice: 1.4654  decode.d5.loss_cls: 1.4519  decode.d5.loss_mask: 0.8354  decode.d5.loss_dice: 1.4479  decode.d6.loss_cls: 1.3412  decode.d6.loss_mask: 0.8392  decode.d6.loss_dice: 1.4325  decode.d7.loss_cls: 1.3178  decode.d7.loss_mask: 0.8647  decode.d7.loss_dice: 1.4638  decode.d8.loss_cls: 1.4104  decode.d8.loss_mask: 0.8264  decode.d8.loss_dice: 1.4569
2023/05/23 22:59:35 - mmengine - INFO - Iter(train) [ 38400/160000]  lr: 7.8115e-06  eta: 14:25:38  time: 0.4116  data_time: 0.0097  memory: 4832  grad_norm: 102.2586  loss: 36.8860  decode.loss_cls: 1.2532  decode.loss_mask: 0.8411  decode.loss_dice: 1.3661  decode.d0.loss_cls: 3.1412  decode.d0.loss_mask: 0.8577  decode.d0.loss_dice: 1.5466  decode.d1.loss_cls: 1.3824  decode.d1.loss_mask: 0.9159  decode.d1.loss_dice: 1.4731  decode.d2.loss_cls: 1.2434  decode.d2.loss_mask: 0.8737  decode.d2.loss_dice: 1.3659  decode.d3.loss_cls: 1.2104  decode.d3.loss_mask: 0.8499  decode.d3.loss_dice: 1.3932  decode.d4.loss_cls: 1.2078  decode.d4.loss_mask: 0.8444  decode.d4.loss_dice: 1.3963  decode.d5.loss_cls: 1.2375  decode.d5.loss_mask: 0.8133  decode.d5.loss_dice: 1.3913  decode.d6.loss_cls: 1.2125  decode.d6.loss_mask: 0.8118  decode.d6.loss_dice: 1.3524  decode.d7.loss_cls: 1.2418  decode.d7.loss_mask: 0.8252  decode.d7.loss_dice: 1.3789  decode.d8.loss_cls: 1.2184  decode.d8.loss_mask: 0.8620  decode.d8.loss_dice: 1.3787
2023/05/23 22:59:56 - mmengine - INFO - Iter(train) [ 38450/160000]  lr: 7.8086e-06  eta: 14:25:16  time: 0.4231  data_time: 0.0099  memory: 4857  grad_norm: 96.3354  loss: 39.8078  decode.loss_cls: 1.3364  decode.loss_mask: 0.8557  decode.loss_dice: 1.4767  decode.d0.loss_cls: 2.9964  decode.d0.loss_mask: 0.8728  decode.d0.loss_dice: 1.6807  decode.d1.loss_cls: 1.5456  decode.d1.loss_mask: 0.9433  decode.d1.loss_dice: 1.6722  decode.d2.loss_cls: 1.5046  decode.d2.loss_mask: 0.9033  decode.d2.loss_dice: 1.5721  decode.d3.loss_cls: 1.4134  decode.d3.loss_mask: 0.8605  decode.d3.loss_dice: 1.5481  decode.d4.loss_cls: 1.3730  decode.d4.loss_mask: 0.8669  decode.d4.loss_dice: 1.5423  decode.d5.loss_cls: 1.3754  decode.d5.loss_mask: 0.8773  decode.d5.loss_dice: 1.5182  decode.d6.loss_cls: 1.3495  decode.d6.loss_mask: 0.8664  decode.d6.loss_dice: 1.5082  decode.d7.loss_cls: 1.3271  decode.d7.loss_mask: 0.8578  decode.d7.loss_dice: 1.5145  decode.d8.loss_cls: 1.2775  decode.d8.loss_mask: 0.8458  decode.d8.loss_dice: 1.5262
2023/05/23 23:00:17 - mmengine - INFO - Iter(train) [ 38500/160000]  lr: 7.8057e-06  eta: 14:24:53  time: 0.4125  data_time: 0.0096  memory: 4857  grad_norm: 118.1367  loss: 43.1432  decode.loss_cls: 1.2590  decode.loss_mask: 0.9968  decode.loss_dice: 1.7512  decode.d0.loss_cls: 3.5109  decode.d0.loss_mask: 1.0489  decode.d0.loss_dice: 2.0168  decode.d1.loss_cls: 1.3790  decode.d1.loss_mask: 1.0465  decode.d1.loss_dice: 1.9290  decode.d2.loss_cls: 1.3202  decode.d2.loss_mask: 1.0063  decode.d2.loss_dice: 1.8253  decode.d3.loss_cls: 1.3125  decode.d3.loss_mask: 0.9991  decode.d3.loss_dice: 1.8099  decode.d4.loss_cls: 1.3268  decode.d4.loss_mask: 0.9875  decode.d4.loss_dice: 1.7598  decode.d5.loss_cls: 1.2292  decode.d5.loss_mask: 0.9618  decode.d5.loss_dice: 1.7539  decode.d6.loss_cls: 1.2204  decode.d6.loss_mask: 0.9644  decode.d6.loss_dice: 1.7724  decode.d7.loss_cls: 1.2739  decode.d7.loss_mask: 0.9630  decode.d7.loss_dice: 1.7545  decode.d8.loss_cls: 1.2285  decode.d8.loss_mask: 0.9722  decode.d8.loss_dice: 1.7637
2023/05/23 23:00:38 - mmengine - INFO - Iter(train) [ 38550/160000]  lr: 7.8028e-06  eta: 14:24:30  time: 0.4103  data_time: 0.0095  memory: 4837  grad_norm: 102.8224  loss: 39.5799  decode.loss_cls: 1.5034  decode.loss_mask: 0.8661  decode.loss_dice: 1.3355  decode.d0.loss_cls: 3.4741  decode.d0.loss_mask: 0.8914  decode.d0.loss_dice: 1.5006  decode.d1.loss_cls: 1.6780  decode.d1.loss_mask: 0.9203  decode.d1.loss_dice: 1.3791  decode.d2.loss_cls: 1.5223  decode.d2.loss_mask: 0.8916  decode.d2.loss_dice: 1.3591  decode.d3.loss_cls: 1.4765  decode.d3.loss_mask: 0.9214  decode.d3.loss_dice: 1.3014  decode.d4.loss_cls: 1.5347  decode.d4.loss_mask: 0.8723  decode.d4.loss_dice: 1.3074  decode.d5.loss_cls: 1.5874  decode.d5.loss_mask: 0.8557  decode.d5.loss_dice: 1.3023  decode.d6.loss_cls: 1.5414  decode.d6.loss_mask: 0.8647  decode.d6.loss_dice: 1.3128  decode.d7.loss_cls: 1.5298  decode.d7.loss_mask: 0.8361  decode.d7.loss_dice: 1.3170  decode.d8.loss_cls: 1.4795  decode.d8.loss_mask: 0.8696  decode.d8.loss_dice: 1.3484
2023/05/23 23:00:58 - mmengine - INFO - Iter(train) [ 38600/160000]  lr: 7.7999e-06  eta: 14:24:06  time: 0.4160  data_time: 0.0098  memory: 4826  grad_norm: 103.5765  loss: 30.4577  decode.loss_cls: 1.1873  decode.loss_mask: 0.7347  decode.loss_dice: 0.9609  decode.d0.loss_cls: 2.6414  decode.d0.loss_mask: 0.8151  decode.d0.loss_dice: 1.0244  decode.d1.loss_cls: 1.2404  decode.d1.loss_mask: 0.7429  decode.d1.loss_dice: 0.9873  decode.d2.loss_cls: 1.1710  decode.d2.loss_mask: 0.7508  decode.d2.loss_dice: 0.9878  decode.d3.loss_cls: 1.1783  decode.d3.loss_mask: 0.7317  decode.d3.loss_dice: 0.9600  decode.d4.loss_cls: 1.1268  decode.d4.loss_mask: 0.7361  decode.d4.loss_dice: 0.9387  decode.d5.loss_cls: 1.1102  decode.d5.loss_mask: 0.7362  decode.d5.loss_dice: 0.9942  decode.d6.loss_cls: 1.1947  decode.d6.loss_mask: 0.7317  decode.d6.loss_dice: 0.9739  decode.d7.loss_cls: 1.2108  decode.d7.loss_mask: 0.7389  decode.d7.loss_dice: 0.9715  decode.d8.loss_cls: 1.1831  decode.d8.loss_mask: 0.7384  decode.d8.loss_dice: 0.9582
2023/05/23 23:01:19 - mmengine - INFO - Iter(train) [ 38650/160000]  lr: 7.7970e-06  eta: 14:23:44  time: 0.4275  data_time: 0.0100  memory: 4835  grad_norm: 105.4099  loss: 39.4950  decode.loss_cls: 1.4159  decode.loss_mask: 0.8680  decode.loss_dice: 1.3734  decode.d0.loss_cls: 3.2440  decode.d0.loss_mask: 0.8954  decode.d0.loss_dice: 1.5922  decode.d1.loss_cls: 1.5252  decode.d1.loss_mask: 0.9903  decode.d1.loss_dice: 1.5527  decode.d2.loss_cls: 1.5643  decode.d2.loss_mask: 0.8985  decode.d2.loss_dice: 1.4250  decode.d3.loss_cls: 1.4942  decode.d3.loss_mask: 0.8460  decode.d3.loss_dice: 1.3636  decode.d4.loss_cls: 1.4863  decode.d4.loss_mask: 0.8310  decode.d4.loss_dice: 1.3662  decode.d5.loss_cls: 1.5234  decode.d5.loss_mask: 0.8260  decode.d5.loss_dice: 1.3905  decode.d6.loss_cls: 1.5061  decode.d6.loss_mask: 0.8357  decode.d6.loss_dice: 1.3446  decode.d7.loss_cls: 1.5000  decode.d7.loss_mask: 0.8283  decode.d7.loss_dice: 1.3441  decode.d8.loss_cls: 1.4897  decode.d8.loss_mask: 0.8185  decode.d8.loss_dice: 1.3557
2023/05/23 23:01:40 - mmengine - INFO - Iter(train) [ 38700/160000]  lr: 7.7942e-06  eta: 14:23:21  time: 0.4138  data_time: 0.0100  memory: 4869  grad_norm: 94.9932  loss: 44.2390  decode.loss_cls: 1.7176  decode.loss_mask: 0.8185  decode.loss_dice: 1.5258  decode.d0.loss_cls: 3.7531  decode.d0.loss_mask: 0.9923  decode.d0.loss_dice: 1.8701  decode.d1.loss_cls: 1.7954  decode.d1.loss_mask: 0.8784  decode.d1.loss_dice: 1.7159  decode.d2.loss_cls: 1.7655  decode.d2.loss_mask: 0.8827  decode.d2.loss_dice: 1.6861  decode.d3.loss_cls: 1.7214  decode.d3.loss_mask: 0.8806  decode.d3.loss_dice: 1.6120  decode.d4.loss_cls: 1.6663  decode.d4.loss_mask: 0.8680  decode.d4.loss_dice: 1.6354  decode.d5.loss_cls: 1.7277  decode.d5.loss_mask: 0.8286  decode.d5.loss_dice: 1.6012  decode.d6.loss_cls: 1.7363  decode.d6.loss_mask: 0.8281  decode.d6.loss_dice: 1.5709  decode.d7.loss_cls: 1.6509  decode.d7.loss_mask: 0.8296  decode.d7.loss_dice: 1.5714  decode.d8.loss_cls: 1.7277  decode.d8.loss_mask: 0.8321  decode.d8.loss_dice: 1.5491
2023/05/23 23:02:01 - mmengine - INFO - Iter(train) [ 38750/160000]  lr: 7.7913e-06  eta: 14:22:57  time: 0.4258  data_time: 0.0098  memory: 4829  grad_norm: 80.3778  loss: 34.1749  decode.loss_cls: 1.2491  decode.loss_mask: 0.7851  decode.loss_dice: 1.1071  decode.d0.loss_cls: 3.3853  decode.d0.loss_mask: 0.8471  decode.d0.loss_dice: 1.2835  decode.d1.loss_cls: 1.3288  decode.d1.loss_mask: 0.8250  decode.d1.loss_dice: 1.1807  decode.d2.loss_cls: 1.2948  decode.d2.loss_mask: 0.7660  decode.d2.loss_dice: 1.1621  decode.d3.loss_cls: 1.2694  decode.d3.loss_mask: 0.7612  decode.d3.loss_dice: 1.1151  decode.d4.loss_cls: 1.2733  decode.d4.loss_mask: 0.7492  decode.d4.loss_dice: 1.1220  decode.d5.loss_cls: 1.2944  decode.d5.loss_mask: 0.7599  decode.d5.loss_dice: 1.1116  decode.d6.loss_cls: 1.2726  decode.d6.loss_mask: 0.7804  decode.d6.loss_dice: 1.1251  decode.d7.loss_cls: 1.2502  decode.d7.loss_mask: 0.7708  decode.d7.loss_dice: 1.1316  decode.d8.loss_cls: 1.2930  decode.d8.loss_mask: 0.7685  decode.d8.loss_dice: 1.1121
2023/05/23 23:02:22 - mmengine - INFO - Iter(train) [ 38800/160000]  lr: 7.7884e-06  eta: 14:22:37  time: 0.4242  data_time: 0.0099  memory: 4880  grad_norm: 98.3072  loss: 45.8033  decode.loss_cls: 1.5267  decode.loss_mask: 0.9354  decode.loss_dice: 1.8451  decode.d0.loss_cls: 3.6734  decode.d0.loss_mask: 0.9159  decode.d0.loss_dice: 2.0972  decode.d1.loss_cls: 1.7452  decode.d1.loss_mask: 0.8522  decode.d1.loss_dice: 1.9231  decode.d2.loss_cls: 1.7426  decode.d2.loss_mask: 0.8856  decode.d2.loss_dice: 1.8892  decode.d3.loss_cls: 1.6336  decode.d3.loss_mask: 0.9033  decode.d3.loss_dice: 1.8178  decode.d4.loss_cls: 1.5746  decode.d4.loss_mask: 0.8993  decode.d4.loss_dice: 1.8138  decode.d5.loss_cls: 1.5908  decode.d5.loss_mask: 0.8881  decode.d5.loss_dice: 1.8198  decode.d6.loss_cls: 1.5407  decode.d6.loss_mask: 0.9307  decode.d6.loss_dice: 1.8154  decode.d7.loss_cls: 1.5397  decode.d7.loss_mask: 0.8902  decode.d7.loss_dice: 1.8529  decode.d8.loss_cls: 1.5659  decode.d8.loss_mask: 0.8840  decode.d8.loss_dice: 1.8110
2023/05/23 23:02:43 - mmengine - INFO - Iter(train) [ 38850/160000]  lr: 7.7855e-06  eta: 14:22:14  time: 0.4120  data_time: 0.0099  memory: 4848  grad_norm: 90.3165  loss: 32.1512  decode.loss_cls: 1.0381  decode.loss_mask: 0.7424  decode.loss_dice: 1.1662  decode.d0.loss_cls: 2.9992  decode.d0.loss_mask: 0.7566  decode.d0.loss_dice: 1.3703  decode.d1.loss_cls: 1.0413  decode.d1.loss_mask: 0.8019  decode.d1.loss_dice: 1.3122  decode.d2.loss_cls: 1.0777  decode.d2.loss_mask: 0.7786  decode.d2.loss_dice: 1.2395  decode.d3.loss_cls: 1.0398  decode.d3.loss_mask: 0.7512  decode.d3.loss_dice: 1.2145  decode.d4.loss_cls: 1.0358  decode.d4.loss_mask: 0.7731  decode.d4.loss_dice: 1.2104  decode.d5.loss_cls: 1.0335  decode.d5.loss_mask: 0.7257  decode.d5.loss_dice: 1.1573  decode.d6.loss_cls: 1.0463  decode.d6.loss_mask: 0.7315  decode.d6.loss_dice: 1.1778  decode.d7.loss_cls: 1.0678  decode.d7.loss_mask: 0.7223  decode.d7.loss_dice: 1.1761  decode.d8.loss_cls: 1.0638  decode.d8.loss_mask: 0.7264  decode.d8.loss_dice: 1.1738
2023/05/23 23:03:04 - mmengine - INFO - Iter(train) [ 38900/160000]  lr: 7.7826e-06  eta: 14:21:50  time: 0.4049  data_time: 0.0097  memory: 4820  grad_norm: 124.7550  loss: 33.5929  decode.loss_cls: 1.1580  decode.loss_mask: 0.7239  decode.loss_dice: 1.2308  decode.d0.loss_cls: 2.9760  decode.d0.loss_mask: 0.7972  decode.d0.loss_dice: 1.4185  decode.d1.loss_cls: 1.2152  decode.d1.loss_mask: 0.7373  decode.d1.loss_dice: 1.2958  decode.d2.loss_cls: 1.2173  decode.d2.loss_mask: 0.7349  decode.d2.loss_dice: 1.2432  decode.d3.loss_cls: 1.1544  decode.d3.loss_mask: 0.8007  decode.d3.loss_dice: 1.2574  decode.d4.loss_cls: 1.1449  decode.d4.loss_mask: 0.7663  decode.d4.loss_dice: 1.2596  decode.d5.loss_cls: 1.1890  decode.d5.loss_mask: 0.7235  decode.d5.loss_dice: 1.2693  decode.d6.loss_cls: 1.2058  decode.d6.loss_mask: 0.7031  decode.d6.loss_dice: 1.2159  decode.d7.loss_cls: 1.1631  decode.d7.loss_mask: 0.6992  decode.d7.loss_dice: 1.2044  decode.d8.loss_cls: 1.1765  decode.d8.loss_mask: 0.7078  decode.d8.loss_dice: 1.2038
2023/05/23 23:03:25 - mmengine - INFO - Iter(train) [ 38950/160000]  lr: 7.7797e-06  eta: 14:21:28  time: 0.4699  data_time: 0.0100  memory: 4824  grad_norm: 101.8769  loss: 27.8097  decode.loss_cls: 0.9771  decode.loss_mask: 0.6319  decode.loss_dice: 0.9782  decode.d0.loss_cls: 2.8033  decode.d0.loss_mask: 0.6501  decode.d0.loss_dice: 1.0957  decode.d1.loss_cls: 1.0873  decode.d1.loss_mask: 0.6088  decode.d1.loss_dice: 1.0050  decode.d2.loss_cls: 0.9845  decode.d2.loss_mask: 0.5960  decode.d2.loss_dice: 0.9709  decode.d3.loss_cls: 0.9298  decode.d3.loss_mask: 0.6254  decode.d3.loss_dice: 0.9966  decode.d4.loss_cls: 0.9606  decode.d4.loss_mask: 0.6247  decode.d4.loss_dice: 0.9831  decode.d5.loss_cls: 0.9006  decode.d5.loss_mask: 0.6381  decode.d5.loss_dice: 0.9998  decode.d6.loss_cls: 0.8931  decode.d6.loss_mask: 0.6534  decode.d6.loss_dice: 0.9920  decode.d7.loss_cls: 0.9924  decode.d7.loss_mask: 0.6393  decode.d7.loss_dice: 0.9902  decode.d8.loss_cls: 0.9776  decode.d8.loss_mask: 0.6402  decode.d8.loss_dice: 0.9840
2023/05/23 23:03:48 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 23:03:48 - mmengine - INFO - Iter(train) [ 39000/160000]  lr: 7.7768e-06  eta: 14:21:13  time: 0.4706  data_time: 0.0096  memory: 4918  grad_norm: 97.9395  loss: 40.1960  decode.loss_cls: 1.2429  decode.loss_mask: 0.9219  decode.loss_dice: 1.6160  decode.d0.loss_cls: 3.1605  decode.d0.loss_mask: 0.8977  decode.d0.loss_dice: 1.7818  decode.d1.loss_cls: 1.4317  decode.d1.loss_mask: 0.8983  decode.d1.loss_dice: 1.7082  decode.d2.loss_cls: 1.3421  decode.d2.loss_mask: 0.9134  decode.d2.loss_dice: 1.6732  decode.d3.loss_cls: 1.2282  decode.d3.loss_mask: 0.9465  decode.d3.loss_dice: 1.5992  decode.d4.loss_cls: 1.2676  decode.d4.loss_mask: 0.9313  decode.d4.loss_dice: 1.6219  decode.d5.loss_cls: 1.2839  decode.d5.loss_mask: 0.8799  decode.d5.loss_dice: 1.6085  decode.d6.loss_cls: 1.2559  decode.d6.loss_mask: 0.9010  decode.d6.loss_dice: 1.5582  decode.d7.loss_cls: 1.1994  decode.d7.loss_mask: 0.9383  decode.d7.loss_dice: 1.6257  decode.d8.loss_cls: 1.2470  decode.d8.loss_mask: 0.9116  decode.d8.loss_dice: 1.6041
2023/05/23 23:03:48 - mmengine - INFO - Saving checkpoint at 39000 iterations
2023/05/23 23:04:16 - mmengine - INFO - Iter(train) [ 39050/160000]  lr: 7.7739e-06  eta: 14:21:13  time: 0.4566  data_time: 0.0104  memory: 4844  grad_norm: 102.8811  loss: 37.3091  decode.loss_cls: 1.1865  decode.loss_mask: 0.8720  decode.loss_dice: 1.3917  decode.d0.loss_cls: 3.1427  decode.d0.loss_mask: 0.9380  decode.d0.loss_dice: 1.7394  decode.d1.loss_cls: 1.3661  decode.d1.loss_mask: 0.9250  decode.d1.loss_dice: 1.5375  decode.d2.loss_cls: 1.2203  decode.d2.loss_mask: 0.9036  decode.d2.loss_dice: 1.4716  decode.d3.loss_cls: 1.1807  decode.d3.loss_mask: 0.8930  decode.d3.loss_dice: 1.3914  decode.d4.loss_cls: 1.1355  decode.d4.loss_mask: 0.8849  decode.d4.loss_dice: 1.3876  decode.d5.loss_cls: 1.1610  decode.d5.loss_mask: 0.8615  decode.d5.loss_dice: 1.3694  decode.d6.loss_cls: 1.2028  decode.d6.loss_mask: 0.8592  decode.d6.loss_dice: 1.4148  decode.d7.loss_cls: 1.1988  decode.d7.loss_mask: 0.8595  decode.d7.loss_dice: 1.3798  decode.d8.loss_cls: 1.1979  decode.d8.loss_mask: 0.8619  decode.d8.loss_dice: 1.3750
2023/05/23 23:04:38 - mmengine - INFO - Iter(train) [ 39100/160000]  lr: 7.7710e-06  eta: 14:20:50  time: 0.4067  data_time: 0.0096  memory: 4783  grad_norm: 90.6114  loss: 38.7528  decode.loss_cls: 1.3856  decode.loss_mask: 0.8938  decode.loss_dice: 1.3742  decode.d0.loss_cls: 3.3203  decode.d0.loss_mask: 0.9260  decode.d0.loss_dice: 1.5453  decode.d1.loss_cls: 1.4368  decode.d1.loss_mask: 0.9744  decode.d1.loss_dice: 1.4690  decode.d2.loss_cls: 1.3818  decode.d2.loss_mask: 0.9549  decode.d2.loss_dice: 1.4013  decode.d3.loss_cls: 1.3788  decode.d3.loss_mask: 0.9183  decode.d3.loss_dice: 1.3647  decode.d4.loss_cls: 1.3706  decode.d4.loss_mask: 0.8968  decode.d4.loss_dice: 1.3684  decode.d5.loss_cls: 1.3535  decode.d5.loss_mask: 0.8760  decode.d5.loss_dice: 1.3466  decode.d6.loss_cls: 1.3436  decode.d6.loss_mask: 0.8851  decode.d6.loss_dice: 1.3395  decode.d7.loss_cls: 1.3833  decode.d7.loss_mask: 0.8868  decode.d7.loss_dice: 1.3717  decode.d8.loss_cls: 1.3456  decode.d8.loss_mask: 0.8818  decode.d8.loss_dice: 1.3781
2023/05/23 23:04:58 - mmengine - INFO - Iter(train) [ 39150/160000]  lr: 7.7681e-06  eta: 14:20:27  time: 0.4178  data_time: 0.0099  memory: 4888  grad_norm: 104.3631  loss: 38.7791  decode.loss_cls: 1.1355  decode.loss_mask: 0.8579  decode.loss_dice: 1.6074  decode.d0.loss_cls: 3.2563  decode.d0.loss_mask: 0.8646  decode.d0.loss_dice: 1.7579  decode.d1.loss_cls: 1.2951  decode.d1.loss_mask: 0.8097  decode.d1.loss_dice: 1.6898  decode.d2.loss_cls: 1.2096  decode.d2.loss_mask: 0.8328  decode.d2.loss_dice: 1.6379  decode.d3.loss_cls: 1.2536  decode.d3.loss_mask: 0.8304  decode.d3.loss_dice: 1.6070  decode.d4.loss_cls: 1.1399  decode.d4.loss_mask: 0.8446  decode.d4.loss_dice: 1.6340  decode.d5.loss_cls: 1.1658  decode.d5.loss_mask: 0.8543  decode.d5.loss_dice: 1.6305  decode.d6.loss_cls: 1.1815  decode.d6.loss_mask: 0.8525  decode.d6.loss_dice: 1.5888  decode.d7.loss_cls: 1.1547  decode.d7.loss_mask: 0.8531  decode.d7.loss_dice: 1.5950  decode.d8.loss_cls: 1.1800  decode.d8.loss_mask: 0.8593  decode.d8.loss_dice: 1.5999
2023/05/23 23:05:19 - mmengine - INFO - Iter(train) [ 39200/160000]  lr: 7.7652e-06  eta: 14:20:05  time: 0.4416  data_time: 0.0104  memory: 4856  grad_norm: 97.0000  loss: 35.8061  decode.loss_cls: 1.1542  decode.loss_mask: 0.8859  decode.loss_dice: 1.2410  decode.d0.loss_cls: 3.0885  decode.d0.loss_mask: 0.9696  decode.d0.loss_dice: 1.4635  decode.d1.loss_cls: 1.3600  decode.d1.loss_mask: 0.9186  decode.d1.loss_dice: 1.3509  decode.d2.loss_cls: 1.2113  decode.d2.loss_mask: 0.8800  decode.d2.loss_dice: 1.3184  decode.d3.loss_cls: 1.1548  decode.d3.loss_mask: 0.9147  decode.d3.loss_dice: 1.3194  decode.d4.loss_cls: 1.1221  decode.d4.loss_mask: 0.9242  decode.d4.loss_dice: 1.3523  decode.d5.loss_cls: 1.1459  decode.d5.loss_mask: 0.8678  decode.d5.loss_dice: 1.2981  decode.d6.loss_cls: 1.1374  decode.d6.loss_mask: 0.9155  decode.d6.loss_dice: 1.2702  decode.d7.loss_cls: 1.0956  decode.d7.loss_mask: 0.8863  decode.d7.loss_dice: 1.3162  decode.d8.loss_cls: 1.1147  decode.d8.loss_mask: 0.8694  decode.d8.loss_dice: 1.2596
2023/05/23 23:05:40 - mmengine - INFO - Iter(train) [ 39250/160000]  lr: 7.7623e-06  eta: 14:19:41  time: 0.4078  data_time: 0.0098  memory: 4835  grad_norm: 92.1679  loss: 39.1563  decode.loss_cls: 1.3778  decode.loss_mask: 0.8473  decode.loss_dice: 1.4539  decode.d0.loss_cls: 3.0698  decode.d0.loss_mask: 0.9726  decode.d0.loss_dice: 1.6157  decode.d1.loss_cls: 1.3518  decode.d1.loss_mask: 0.9389  decode.d1.loss_dice: 1.5955  decode.d2.loss_cls: 1.3509  decode.d2.loss_mask: 0.8968  decode.d2.loss_dice: 1.5181  decode.d3.loss_cls: 1.3963  decode.d3.loss_mask: 0.8486  decode.d3.loss_dice: 1.4881  decode.d4.loss_cls: 1.3406  decode.d4.loss_mask: 0.8750  decode.d4.loss_dice: 1.5009  decode.d5.loss_cls: 1.3220  decode.d5.loss_mask: 0.8985  decode.d5.loss_dice: 1.5133  decode.d6.loss_cls: 1.3466  decode.d6.loss_mask: 0.8741  decode.d6.loss_dice: 1.4732  decode.d7.loss_cls: 1.3031  decode.d7.loss_mask: 0.8714  decode.d7.loss_dice: 1.4482  decode.d8.loss_cls: 1.3430  decode.d8.loss_mask: 0.8528  decode.d8.loss_dice: 1.4717
2023/05/23 23:06:01 - mmengine - INFO - Iter(train) [ 39300/160000]  lr: 7.7595e-06  eta: 14:19:19  time: 0.4080  data_time: 0.0098  memory: 4834  grad_norm: 88.8385  loss: 31.9545  decode.loss_cls: 1.1006  decode.loss_mask: 0.7847  decode.loss_dice: 1.0431  decode.d0.loss_cls: 2.9450  decode.d0.loss_mask: 0.8178  decode.d0.loss_dice: 1.0670  decode.d1.loss_cls: 1.2749  decode.d1.loss_mask: 0.8029  decode.d1.loss_dice: 1.0962  decode.d2.loss_cls: 1.1741  decode.d2.loss_mask: 0.7974  decode.d2.loss_dice: 1.0725  decode.d3.loss_cls: 1.2039  decode.d3.loss_mask: 0.7922  decode.d3.loss_dice: 1.0427  decode.d4.loss_cls: 1.1455  decode.d4.loss_mask: 0.7967  decode.d4.loss_dice: 1.0379  decode.d5.loss_cls: 1.1305  decode.d5.loss_mask: 0.7930  decode.d5.loss_dice: 1.0257  decode.d6.loss_cls: 1.1338  decode.d6.loss_mask: 0.8192  decode.d6.loss_dice: 1.0739  decode.d7.loss_cls: 1.0953  decode.d7.loss_mask: 0.8208  decode.d7.loss_dice: 1.0979  decode.d8.loss_cls: 1.1192  decode.d8.loss_mask: 0.7977  decode.d8.loss_dice: 1.0526
2023/05/23 23:06:24 - mmengine - INFO - Iter(train) [ 39350/160000]  lr: 7.7566e-06  eta: 14:19:03  time: 0.4267  data_time: 0.0103  memory: 4859  grad_norm: 85.5265  loss: 36.0748  decode.loss_cls: 1.3712  decode.loss_mask: 0.7744  decode.loss_dice: 1.1608  decode.d0.loss_cls: 3.0726  decode.d0.loss_mask: 0.8936  decode.d0.loss_dice: 1.4334  decode.d1.loss_cls: 1.3952  decode.d1.loss_mask: 0.8696  decode.d1.loss_dice: 1.2804  decode.d2.loss_cls: 1.3842  decode.d2.loss_mask: 0.8696  decode.d2.loss_dice: 1.2437  decode.d3.loss_cls: 1.3947  decode.d3.loss_mask: 0.8304  decode.d3.loss_dice: 1.2136  decode.d4.loss_cls: 1.3732  decode.d4.loss_mask: 0.8001  decode.d4.loss_dice: 1.2113  decode.d5.loss_cls: 1.3457  decode.d5.loss_mask: 0.8036  decode.d5.loss_dice: 1.1973  decode.d6.loss_cls: 1.3853  decode.d6.loss_mask: 0.8232  decode.d6.loss_dice: 1.1992  decode.d7.loss_cls: 1.3762  decode.d7.loss_mask: 0.8153  decode.d7.loss_dice: 1.2152  decode.d8.loss_cls: 1.3448  decode.d8.loss_mask: 0.8005  decode.d8.loss_dice: 1.1964
2023/05/23 23:06:45 - mmengine - INFO - Iter(train) [ 39400/160000]  lr: 7.7537e-06  eta: 14:18:40  time: 0.4084  data_time: 0.0097  memory: 4843  grad_norm: 86.1886  loss: 40.1783  decode.loss_cls: 1.4878  decode.loss_mask: 0.7950  decode.loss_dice: 1.4302  decode.d0.loss_cls: 3.4762  decode.d0.loss_mask: 0.8356  decode.d0.loss_dice: 1.6254  decode.d1.loss_cls: 1.6631  decode.d1.loss_mask: 0.8654  decode.d1.loss_dice: 1.5695  decode.d2.loss_cls: 1.5520  decode.d2.loss_mask: 0.8017  decode.d2.loss_dice: 1.4844  decode.d3.loss_cls: 1.5295  decode.d3.loss_mask: 0.8312  decode.d3.loss_dice: 1.4409  decode.d4.loss_cls: 1.4785  decode.d4.loss_mask: 0.8369  decode.d4.loss_dice: 1.4635  decode.d5.loss_cls: 1.4859  decode.d5.loss_mask: 0.8436  decode.d5.loss_dice: 1.4538  decode.d6.loss_cls: 1.4723  decode.d6.loss_mask: 0.8458  decode.d6.loss_dice: 1.4500  decode.d7.loss_cls: 1.4446  decode.d7.loss_mask: 0.8417  decode.d7.loss_dice: 1.4491  decode.d8.loss_cls: 1.4494  decode.d8.loss_mask: 0.8414  decode.d8.loss_dice: 1.4340
2023/05/23 23:07:06 - mmengine - INFO - Iter(train) [ 39450/160000]  lr: 7.7508e-06  eta: 14:18:17  time: 0.4159  data_time: 0.0102  memory: 4845  grad_norm: 95.1006  loss: 41.3400  decode.loss_cls: 1.5638  decode.loss_mask: 0.8873  decode.loss_dice: 1.4691  decode.d0.loss_cls: 3.5573  decode.d0.loss_mask: 0.9178  decode.d0.loss_dice: 1.6394  decode.d1.loss_cls: 1.6642  decode.d1.loss_mask: 0.8605  decode.d1.loss_dice: 1.5309  decode.d2.loss_cls: 1.5786  decode.d2.loss_mask: 0.8494  decode.d2.loss_dice: 1.4758  decode.d3.loss_cls: 1.6085  decode.d3.loss_mask: 0.8874  decode.d3.loss_dice: 1.4511  decode.d4.loss_cls: 1.5233  decode.d4.loss_mask: 0.9166  decode.d4.loss_dice: 1.4714  decode.d5.loss_cls: 1.5381  decode.d5.loss_mask: 0.8803  decode.d5.loss_dice: 1.4813  decode.d6.loss_cls: 1.5330  decode.d6.loss_mask: 0.8307  decode.d6.loss_dice: 1.4689  decode.d7.loss_cls: 1.5257  decode.d7.loss_mask: 0.8367  decode.d7.loss_dice: 1.4826  decode.d8.loss_cls: 1.5740  decode.d8.loss_mask: 0.8524  decode.d8.loss_dice: 1.4837
2023/05/23 23:07:27 - mmengine - INFO - Iter(train) [ 39500/160000]  lr: 7.7479e-06  eta: 14:17:54  time: 0.4256  data_time: 0.0097  memory: 4837  grad_norm: 80.4326  loss: 36.9658  decode.loss_cls: 1.3883  decode.loss_mask: 0.7089  decode.loss_dice: 1.2873  decode.d0.loss_cls: 3.1052  decode.d0.loss_mask: 0.8448  decode.d0.loss_dice: 1.5461  decode.d1.loss_cls: 1.6149  decode.d1.loss_mask: 0.7850  decode.d1.loss_dice: 1.4468  decode.d2.loss_cls: 1.5435  decode.d2.loss_mask: 0.7320  decode.d2.loss_dice: 1.2995  decode.d3.loss_cls: 1.5388  decode.d3.loss_mask: 0.7135  decode.d3.loss_dice: 1.2753  decode.d4.loss_cls: 1.4536  decode.d4.loss_mask: 0.7307  decode.d4.loss_dice: 1.2903  decode.d5.loss_cls: 1.4348  decode.d5.loss_mask: 0.7213  decode.d5.loss_dice: 1.3033  decode.d6.loss_cls: 1.4081  decode.d6.loss_mask: 0.7103  decode.d6.loss_dice: 1.2800  decode.d7.loss_cls: 1.4036  decode.d7.loss_mask: 0.7178  decode.d7.loss_dice: 1.2990  decode.d8.loss_cls: 1.3894  decode.d8.loss_mask: 0.7038  decode.d8.loss_dice: 1.2900
2023/05/23 23:07:48 - mmengine - INFO - Iter(train) [ 39550/160000]  lr: 7.7450e-06  eta: 14:17:34  time: 0.4695  data_time: 0.0105  memory: 4828  grad_norm: 94.1253  loss: 35.1515  decode.loss_cls: 1.2060  decode.loss_mask: 0.7444  decode.loss_dice: 1.2458  decode.d0.loss_cls: 3.3486  decode.d0.loss_mask: 0.7791  decode.d0.loss_dice: 1.3705  decode.d1.loss_cls: 1.3868  decode.d1.loss_mask: 0.8478  decode.d1.loss_dice: 1.3191  decode.d2.loss_cls: 1.3033  decode.d2.loss_mask: 0.7902  decode.d2.loss_dice: 1.2354  decode.d3.loss_cls: 1.2795  decode.d3.loss_mask: 0.7555  decode.d3.loss_dice: 1.2600  decode.d4.loss_cls: 1.2777  decode.d4.loss_mask: 0.7450  decode.d4.loss_dice: 1.2422  decode.d5.loss_cls: 1.2802  decode.d5.loss_mask: 0.7459  decode.d5.loss_dice: 1.2434  decode.d6.loss_cls: 1.3046  decode.d6.loss_mask: 0.7449  decode.d6.loss_dice: 1.2747  decode.d7.loss_cls: 1.2135  decode.d7.loss_mask: 0.7665  decode.d7.loss_dice: 1.2782  decode.d8.loss_cls: 1.1998  decode.d8.loss_mask: 0.7597  decode.d8.loss_dice: 1.2034
2023/05/23 23:08:10 - mmengine - INFO - Iter(train) [ 39600/160000]  lr: 7.7421e-06  eta: 14:17:14  time: 0.4457  data_time: 0.0096  memory: 4844  grad_norm: 101.1963  loss: 52.4001  decode.loss_cls: 1.7152  decode.loss_mask: 1.1869  decode.loss_dice: 2.0349  decode.d0.loss_cls: 3.7042  decode.d0.loss_mask: 1.2610  decode.d0.loss_dice: 2.3576  decode.d1.loss_cls: 1.8486  decode.d1.loss_mask: 1.3321  decode.d1.loss_dice: 2.1523  decode.d2.loss_cls: 1.7355  decode.d2.loss_mask: 1.2790  decode.d2.loss_dice: 2.0921  decode.d3.loss_cls: 1.7119  decode.d3.loss_mask: 1.2350  decode.d3.loss_dice: 2.0873  decode.d4.loss_cls: 1.6968  decode.d4.loss_mask: 1.2624  decode.d4.loss_dice: 2.0653  decode.d5.loss_cls: 1.6913  decode.d5.loss_mask: 1.2523  decode.d5.loss_dice: 2.0431  decode.d6.loss_cls: 1.6610  decode.d6.loss_mask: 1.2273  decode.d6.loss_dice: 2.0303  decode.d7.loss_cls: 1.7346  decode.d7.loss_mask: 1.1696  decode.d7.loss_dice: 1.9595  decode.d8.loss_cls: 1.7170  decode.d8.loss_mask: 1.1616  decode.d8.loss_dice: 1.9945
2023/05/23 23:08:33 - mmengine - INFO - Iter(train) [ 39650/160000]  lr: 7.7392e-06  eta: 14:16:56  time: 0.4658  data_time: 0.0105  memory: 4803  grad_norm: 95.9055  loss: 40.8849  decode.loss_cls: 1.3878  decode.loss_mask: 0.9346  decode.loss_dice: 1.5113  decode.d0.loss_cls: 3.4798  decode.d0.loss_mask: 0.9250  decode.d0.loss_dice: 1.6945  decode.d1.loss_cls: 1.5277  decode.d1.loss_mask: 0.9343  decode.d1.loss_dice: 1.5938  decode.d2.loss_cls: 1.4016  decode.d2.loss_mask: 0.9450  decode.d2.loss_dice: 1.5618  decode.d3.loss_cls: 1.4154  decode.d3.loss_mask: 0.9241  decode.d3.loss_dice: 1.5235  decode.d4.loss_cls: 1.3760  decode.d4.loss_mask: 0.9028  decode.d4.loss_dice: 1.4710  decode.d5.loss_cls: 1.3981  decode.d5.loss_mask: 0.9136  decode.d5.loss_dice: 1.4931  decode.d6.loss_cls: 1.4317  decode.d6.loss_mask: 0.9144  decode.d6.loss_dice: 1.4955  decode.d7.loss_cls: 1.3529  decode.d7.loss_mask: 0.9468  decode.d7.loss_dice: 1.5327  decode.d8.loss_cls: 1.4272  decode.d8.loss_mask: 0.9460  decode.d8.loss_dice: 1.5227
2023/05/23 23:08:56 - mmengine - INFO - Iter(train) [ 39700/160000]  lr: 7.7363e-06  eta: 14:16:40  time: 0.4629  data_time: 0.0096  memory: 4846  grad_norm: 88.9847  loss: 31.1883  decode.loss_cls: 1.0688  decode.loss_mask: 0.7316  decode.loss_dice: 1.0581  decode.d0.loss_cls: 2.8787  decode.d0.loss_mask: 0.7937  decode.d0.loss_dice: 1.3018  decode.d1.loss_cls: 1.1417  decode.d1.loss_mask: 0.7992  decode.d1.loss_dice: 1.2458  decode.d2.loss_cls: 1.0489  decode.d2.loss_mask: 0.7347  decode.d2.loss_dice: 1.1317  decode.d3.loss_cls: 1.0773  decode.d3.loss_mask: 0.7067  decode.d3.loss_dice: 1.0936  decode.d4.loss_cls: 1.0372  decode.d4.loss_mask: 0.7010  decode.d4.loss_dice: 1.0855  decode.d5.loss_cls: 1.0696  decode.d5.loss_mask: 0.7053  decode.d5.loss_dice: 1.0950  decode.d6.loss_cls: 1.0473  decode.d6.loss_mask: 0.7382  decode.d6.loss_dice: 1.0824  decode.d7.loss_cls: 1.0420  decode.d7.loss_mask: 0.7224  decode.d7.loss_dice: 1.1313  decode.d8.loss_cls: 1.0532  decode.d8.loss_mask: 0.7444  decode.d8.loss_dice: 1.1212
2023/05/23 23:09:17 - mmengine - INFO - Iter(train) [ 39750/160000]  lr: 7.7334e-06  eta: 14:16:19  time: 0.4169  data_time: 0.0098  memory: 4870  grad_norm: 90.3762  loss: 34.8332  decode.loss_cls: 1.1117  decode.loss_mask: 0.6865  decode.loss_dice: 1.3476  decode.d0.loss_cls: 3.0951  decode.d0.loss_mask: 0.7725  decode.d0.loss_dice: 1.5942  decode.d1.loss_cls: 1.2798  decode.d1.loss_mask: 0.7972  decode.d1.loss_dice: 1.5158  decode.d2.loss_cls: 1.2804  decode.d2.loss_mask: 0.7114  decode.d2.loss_dice: 1.3751  decode.d3.loss_cls: 1.2462  decode.d3.loss_mask: 0.6936  decode.d3.loss_dice: 1.3254  decode.d4.loss_cls: 1.2282  decode.d4.loss_mask: 0.6940  decode.d4.loss_dice: 1.3308  decode.d5.loss_cls: 1.2276  decode.d5.loss_mask: 0.6862  decode.d5.loss_dice: 1.3225  decode.d6.loss_cls: 1.1955  decode.d6.loss_mask: 0.6853  decode.d6.loss_dice: 1.3267  decode.d7.loss_cls: 1.1657  decode.d7.loss_mask: 0.6744  decode.d7.loss_dice: 1.3326  decode.d8.loss_cls: 1.1116  decode.d8.loss_mask: 0.6885  decode.d8.loss_dice: 1.3314
2023/05/23 23:09:38 - mmengine - INFO - Iter(train) [ 39800/160000]  lr: 7.7305e-06  eta: 14:15:56  time: 0.4122  data_time: 0.0097  memory: 4836  grad_norm: 101.2900  loss: 46.2819  decode.loss_cls: 1.5956  decode.loss_mask: 0.9823  decode.loss_dice: 1.7330  decode.d0.loss_cls: 3.5427  decode.d0.loss_mask: 0.9667  decode.d0.loss_dice: 1.9754  decode.d1.loss_cls: 1.8127  decode.d1.loss_mask: 0.9399  decode.d1.loss_dice: 1.8815  decode.d2.loss_cls: 1.7069  decode.d2.loss_mask: 0.9352  decode.d2.loss_dice: 1.8137  decode.d3.loss_cls: 1.6947  decode.d3.loss_mask: 0.9141  decode.d3.loss_dice: 1.7616  decode.d4.loss_cls: 1.6918  decode.d4.loss_mask: 0.9405  decode.d4.loss_dice: 1.7716  decode.d5.loss_cls: 1.6480  decode.d5.loss_mask: 0.9927  decode.d5.loss_dice: 1.7869  decode.d6.loss_cls: 1.5613  decode.d6.loss_mask: 0.9893  decode.d6.loss_dice: 1.8129  decode.d7.loss_cls: 1.6817  decode.d7.loss_mask: 0.9851  decode.d7.loss_dice: 1.7868  decode.d8.loss_cls: 1.5935  decode.d8.loss_mask: 0.9855  decode.d8.loss_dice: 1.7984
2023/05/23 23:09:59 - mmengine - INFO - Iter(train) [ 39850/160000]  lr: 7.7276e-06  eta: 14:15:33  time: 0.4402  data_time: 0.0103  memory: 4802  grad_norm: 92.8358  loss: 30.7883  decode.loss_cls: 1.1238  decode.loss_mask: 0.6186  decode.loss_dice: 1.0286  decode.d0.loss_cls: 3.2164  decode.d0.loss_mask: 0.6790  decode.d0.loss_dice: 1.2101  decode.d1.loss_cls: 1.3604  decode.d1.loss_mask: 0.6388  decode.d1.loss_dice: 1.1389  decode.d2.loss_cls: 1.1541  decode.d2.loss_mask: 0.6732  decode.d2.loss_dice: 1.0824  decode.d3.loss_cls: 1.1965  decode.d3.loss_mask: 0.6454  decode.d3.loss_dice: 1.0395  decode.d4.loss_cls: 1.1709  decode.d4.loss_mask: 0.6404  decode.d4.loss_dice: 1.0580  decode.d5.loss_cls: 1.1617  decode.d5.loss_mask: 0.6294  decode.d5.loss_dice: 1.0461  decode.d6.loss_cls: 1.1171  decode.d6.loss_mask: 0.6184  decode.d6.loss_dice: 1.0310  decode.d7.loss_cls: 1.1263  decode.d7.loss_mask: 0.6171  decode.d7.loss_dice: 1.0048  decode.d8.loss_cls: 1.1193  decode.d8.loss_mask: 0.6226  decode.d8.loss_dice: 1.0196
2023/05/23 23:10:21 - mmengine - INFO - Iter(train) [ 39900/160000]  lr: 7.7247e-06  eta: 14:15:13  time: 0.4379  data_time: 0.0101  memory: 4844  grad_norm: 129.1014  loss: 32.2512  decode.loss_cls: 1.1812  decode.loss_mask: 0.8024  decode.loss_dice: 1.0232  decode.d0.loss_cls: 2.8610  decode.d0.loss_mask: 0.8563  decode.d0.loss_dice: 1.1958  decode.d1.loss_cls: 1.2922  decode.d1.loss_mask: 0.7813  decode.d1.loss_dice: 1.0977  decode.d2.loss_cls: 1.3243  decode.d2.loss_mask: 0.7743  decode.d2.loss_dice: 1.1023  decode.d3.loss_cls: 1.3211  decode.d3.loss_mask: 0.7571  decode.d3.loss_dice: 1.0247  decode.d4.loss_cls: 1.1640  decode.d4.loss_mask: 0.7638  decode.d4.loss_dice: 1.0601  decode.d5.loss_cls: 1.1637  decode.d5.loss_mask: 0.7523  decode.d5.loss_dice: 1.0333  decode.d6.loss_cls: 1.1741  decode.d6.loss_mask: 0.7745  decode.d6.loss_dice: 1.0585  decode.d7.loss_cls: 1.1110  decode.d7.loss_mask: 0.7646  decode.d7.loss_dice: 1.0529  decode.d8.loss_cls: 1.1555  decode.d8.loss_mask: 0.7695  decode.d8.loss_dice: 1.0586
2023/05/23 23:10:42 - mmengine - INFO - Iter(train) [ 39950/160000]  lr: 7.7218e-06  eta: 14:14:50  time: 0.4141  data_time: 0.0095  memory: 4878  grad_norm: 92.7947  loss: 41.7484  decode.loss_cls: 1.7011  decode.loss_mask: 0.7888  decode.loss_dice: 1.3973  decode.d0.loss_cls: 3.5811  decode.d0.loss_mask: 0.9000  decode.d0.loss_dice: 1.6559  decode.d1.loss_cls: 1.7957  decode.d1.loss_mask: 0.8375  decode.d1.loss_dice: 1.5510  decode.d2.loss_cls: 1.7676  decode.d2.loss_mask: 0.8065  decode.d2.loss_dice: 1.4472  decode.d3.loss_cls: 1.7258  decode.d3.loss_mask: 0.7893  decode.d3.loss_dice: 1.4246  decode.d4.loss_cls: 1.7282  decode.d4.loss_mask: 0.8104  decode.d4.loss_dice: 1.3942  decode.d5.loss_cls: 1.7973  decode.d5.loss_mask: 0.8007  decode.d5.loss_dice: 1.4319  decode.d6.loss_cls: 1.7591  decode.d6.loss_mask: 0.7991  decode.d6.loss_dice: 1.3960  decode.d7.loss_cls: 1.6739  decode.d7.loss_mask: 0.8047  decode.d7.loss_dice: 1.3800  decode.d8.loss_cls: 1.6745  decode.d8.loss_mask: 0.7939  decode.d8.loss_dice: 1.3352
2023/05/23 23:11:02 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 23:11:02 - mmengine - INFO - Iter(train) [ 40000/160000]  lr: 7.7189e-06  eta: 14:14:26  time: 0.4150  data_time: 0.0099  memory: 4878  grad_norm: 93.1004  loss: 41.1416  decode.loss_cls: 1.5077  decode.loss_mask: 0.8334  decode.loss_dice: 1.4788  decode.d0.loss_cls: 3.5186  decode.d0.loss_mask: 0.9425  decode.d0.loss_dice: 1.7864  decode.d1.loss_cls: 1.5913  decode.d1.loss_mask: 0.8654  decode.d1.loss_dice: 1.6132  decode.d2.loss_cls: 1.5036  decode.d2.loss_mask: 0.9150  decode.d2.loss_dice: 1.6370  decode.d3.loss_cls: 1.4420  decode.d3.loss_mask: 0.8923  decode.d3.loss_dice: 1.5427  decode.d4.loss_cls: 1.4203  decode.d4.loss_mask: 0.8791  decode.d4.loss_dice: 1.5573  decode.d5.loss_cls: 1.4426  decode.d5.loss_mask: 0.8595  decode.d5.loss_dice: 1.5097  decode.d6.loss_cls: 1.4716  decode.d6.loss_mask: 0.8239  decode.d6.loss_dice: 1.4778  decode.d7.loss_cls: 1.5040  decode.d7.loss_mask: 0.8342  decode.d7.loss_dice: 1.4965  decode.d8.loss_cls: 1.4874  decode.d8.loss_mask: 0.8307  decode.d8.loss_dice: 1.4772
2023/05/23 23:11:02 - mmengine - INFO - Saving checkpoint at 40000 iterations
2023/05/23 23:11:12 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:48  time: 0.0792  data_time: 0.0018  memory: 2167  
2023/05/23 23:11:16 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0816  data_time: 0.0018  memory: 2216  
2023/05/23 23:11:20 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:40  time: 0.0813  data_time: 0.0020  memory: 2167  
2023/05/23 23:11:25 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:36  time: 0.0852  data_time: 0.0020  memory: 2104  
2023/05/23 23:11:29 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0806  data_time: 0.0020  memory: 2831  
2023/05/23 23:11:33 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:27  time: 0.0801  data_time: 0.0018  memory: 2167  
2023/05/23 23:11:38 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:23  time: 0.1526  data_time: 0.0019  memory: 2167  
2023/05/23 23:11:44 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:20  time: 0.1025  data_time: 0.0019  memory: 2167  
2023/05/23 23:11:49 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0936  data_time: 0.0018  memory: 2944  
2023/05/23 23:11:53 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:11  time: 0.0806  data_time: 0.0019  memory: 2356  
2023/05/23 23:11:57 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0981  data_time: 0.0019  memory: 2217  
2023/05/23 23:12:02 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0870  data_time: 0.0019  memory: 2328  
2023/05/23 23:12:06 - mmengine - INFO - per class results:
2023/05/23 23:12:06 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 84.77 | 94.14 |
|     bicycle      | 66.13 | 81.88 |
|       car        | 57.19 | 78.59 |
|    motorcycle    | 82.05 | 88.21 |
|     airplane     | 86.09 | 93.11 |
|       bus        | 79.23 | 88.02 |
|      train       | 82.69 | 93.17 |
|      truck       | 50.97 | 72.35 |
|       boat       | 52.17 | 75.99 |
|  traffic light   |  61.5 | 82.19 |
|   fire hydrant   | 81.67 | 95.22 |
|    stop sign     | 90.11 |  94.0 |
|  parking meter   | 75.15 | 84.91 |
|      bench       | 42.69 |  75.3 |
|       bird       | 81.22 | 90.32 |
|       cat        | 85.94 | 94.01 |
|       dog        | 80.87 | 89.05 |
|      horse       | 78.67 | 90.19 |
|      sheep       | 85.01 | 92.36 |
|       cow        | 82.66 | 91.49 |
|     elephant     | 90.87 | 95.42 |
|       bear       | 92.26 | 95.22 |
|      zebra       | 90.11 | 93.47 |
|     giraffe      | 86.76 | 93.25 |
|     backpack     | 29.14 | 61.33 |
|     umbrella     | 75.19 | 89.92 |
|     handbag      | 29.99 | 49.01 |
|       tie        | 10.61 | 16.33 |
|     suitcase     | 69.09 | 91.42 |
|     frisbee      | 64.36 | 88.88 |
|       skis       | 37.93 | 50.39 |
|    snowboard     | 52.69 |  72.4 |
|   sports ball    | 51.08 |  71.8 |
|       kite       | 50.99 | 60.65 |
|   baseball bat   | 42.14 | 51.81 |
|  baseball glove  | 64.24 | 75.93 |
|    skateboard    | 75.48 | 86.03 |
|    surfboard     | 71.68 | 86.54 |
|  tennis racket   | 80.39 | 88.43 |
|      bottle      |  49.1 | 77.92 |
|    wine glass    | 53.92 | 79.15 |
|       cup        | 51.93 | 77.68 |
|       fork       | 32.33 |  45.7 |
|      knife       | 22.58 | 32.87 |
|      spoon       | 33.43 | 47.96 |
|       bowl       | 46.57 | 65.85 |
|      banana      | 65.17 | 88.36 |
|      apple       | 49.42 | 69.89 |
|     sandwich     | 42.78 | 62.63 |
|      orange      | 68.51 | 85.38 |
|     broccoli     | 51.82 | 68.59 |
|      carrot      | 50.54 | 58.02 |
|     hot dog      | 45.77 | 52.99 |
|      pizza       | 66.54 | 78.96 |
|      donut       | 65.57 | 80.73 |
|       cake       |  62.0 | 70.07 |
|      chair       | 39.49 | 58.55 |
|      couch       | 50.18 | 76.57 |
|   potted plant   | 28.63 | 44.75 |
|       bed        | 56.71 |  70.2 |
|   dining table   |  41.8 | 74.02 |
|      toilet      |  79.6 | 92.78 |
|        tv        | 70.04 | 82.26 |
|      laptop      | 71.81 | 91.15 |
|      mouse       |  69.1 | 81.84 |
|      remote      | 52.37 |  70.4 |
|     keyboard     | 59.24 | 66.57 |
|    cell phone    | 69.81 | 87.03 |
|    microwave     | 55.26 | 76.34 |
|       oven       | 55.32 | 80.55 |
|     toaster      |  0.45 |  0.45 |
|       sink       | 60.59 | 76.05 |
|   refrigerator   | 73.83 | 89.16 |
|       book       | 44.19 | 69.33 |
|      clock       | 72.97 |  79.8 |
|       vase       | 57.11 | 83.37 |
|     scissors     | 60.06 | 68.74 |
|    teddy bear    | 73.79 | 85.87 |
|    hair drier    | 20.69 | 21.35 |
|    toothbrush    | 13.85 | 70.09 |
|      banner      | 26.69 |  72.2 |
|     blanket      |  2.62 |  2.66 |
|      branch      | 21.56 |  26.2 |
|      bridge      | 29.86 |  38.2 |
|  building-other  | 49.27 | 78.21 |
|       bush       | 32.77 | 45.81 |
|     cabinet      | 48.82 |  72.2 |
|       cage       |  8.59 |  9.05 |
|    cardboard     | 40.58 | 56.04 |
|      carpet      | 47.72 | 70.37 |
|  ceiling-other   | 61.35 | 80.06 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 13.68 |  17.4 |
|      clouds      | 46.83 | 63.84 |
|     counter      | 24.24 | 36.46 |
|     cupboard     |  2.37 |  2.63 |
|     curtain      | 62.39 | 80.27 |
|    desk-stuff    | 46.03 | 58.76 |
|       dirt       | 38.55 |  57.3 |
|    door-stuff    | 34.62 | 57.18 |
|      fence       | 35.93 | 65.83 |
|   floor-marble   |  0.0  |  0.0  |
|   floor-other    | 18.07 | 23.89 |
|   floor-stone    |  0.43 |  0.46 |
|    floor-tile    | 54.67 | 63.11 |
|    floor-wood    | 60.11 | 68.71 |
|      flower      | 41.99 |  70.9 |
|       fog        |  2.14 |  2.19 |
|    food-other    | 22.65 |  26.4 |
|      fruit       | 33.91 | 45.24 |
| furniture-other  | 16.83 | 26.91 |
|      grass       | 70.11 | 83.66 |
|      gravel      | 25.73 | 42.38 |
|   ground-other   |  3.59 |  4.41 |
|       hill       | 11.51 | 13.66 |
|      house       | 18.92 | 20.38 |
|      leaves      | 26.32 | 32.31 |
|      light       | 34.03 | 50.57 |
|       mat        |  0.0  |  0.0  |
|      metal       | 30.34 | 43.66 |
|   mirror-stuff   |  43.0 | 51.05 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 51.73 | 66.28 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  7.92 |  8.47 |
|       net        | 36.86 | 63.16 |
|      paper       | 33.11 | 47.82 |
|     pavement     | 44.19 | 64.41 |
|      pillow      |  8.23 | 12.57 |
|   plant-other    | 16.85 | 26.65 |
|     plastic      | 15.77 |  21.1 |
|     platform     | 31.17 | 47.03 |
|   playingfield   | 69.43 | 90.38 |
|     railing      |  2.78 |  4.3  |
|     railroad     | 58.94 |  74.5 |
|      river       | 25.23 | 28.08 |
|       road       | 61.58 |  84.1 |
|       rock       | 46.11 | 78.37 |
|       roof       | 11.77 | 14.37 |
|       rug        | 30.87 | 42.04 |
|      salad       |  0.0  |  0.0  |
|       sand       | 58.95 | 68.11 |
|       sea        | 84.81 | 90.24 |
|      shelf       | 27.53 | 36.03 |
|    sky-other     |  69.6 | 86.27 |
|    skyscraper    | 33.59 | 40.37 |
|       snow       | 89.12 |  92.7 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 22.12 | 37.74 |
|      stone       |  2.42 |  2.64 |
|      straw       |  21.3 | 25.44 |
| structural-other |  0.57 |  0.61 |
|      table       | 22.25 |  33.0 |
|       tent       |  5.46 |  6.59 |
|  textile-other   | 10.81 | 19.14 |
|      towel       | 31.91 | 39.53 |
|       tree       | 73.07 |  86.6 |
|    vegetable     | 32.21 | 36.72 |
|    wall-brick    | 41.13 | 49.49 |
|  wall-concrete   | 59.21 | 78.87 |
|    wall-other    | 16.45 |  22.0 |
|    wall-panel    |  1.37 |  1.49 |
|    wall-stone    | 28.48 | 31.29 |
|    wall-tile     | 62.56 | 75.92 |
|    wall-wood     | 37.93 |  45.8 |
|   water-other    | 27.62 | 59.96 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 51.34 | 64.18 |
|   window-other   | 42.69 | 60.67 |
|       wood       | 21.35 | 29.36 |
+------------------+-------+-------+
2023/05/23 23:12:06 - mmengine - INFO - Iter(val) [625/625]    aAcc: 69.7800  mIoU: 43.8800  mAcc: 56.4800  data_time: 0.0021  time: 0.0898
2023/05/23 23:12:27 - mmengine - INFO - Iter(train) [ 40050/160000]  lr: 7.7160e-06  eta: 14:14:10  time: 0.4536  data_time: 0.0100  memory: 4851  grad_norm: 90.5015  loss: 42.7383  decode.loss_cls: 1.4609  decode.loss_mask: 0.8462  decode.loss_dice: 1.6587  decode.d0.loss_cls: 3.5015  decode.d0.loss_mask: 0.9617  decode.d0.loss_dice: 1.8910  decode.d1.loss_cls: 1.5970  decode.d1.loss_mask: 0.9002  decode.d1.loss_dice: 1.7529  decode.d2.loss_cls: 1.5407  decode.d2.loss_mask: 0.8541  decode.d2.loss_dice: 1.7041  decode.d3.loss_cls: 1.4899  decode.d3.loss_mask: 0.8626  decode.d3.loss_dice: 1.6980  decode.d4.loss_cls: 1.4972  decode.d4.loss_mask: 0.8524  decode.d4.loss_dice: 1.6618  decode.d5.loss_cls: 1.4906  decode.d5.loss_mask: 0.8570  decode.d5.loss_dice: 1.6881  decode.d6.loss_cls: 1.4724  decode.d6.loss_mask: 0.8747  decode.d6.loss_dice: 1.6766  decode.d7.loss_cls: 1.4438  decode.d7.loss_mask: 0.8830  decode.d7.loss_dice: 1.6481  decode.d8.loss_cls: 1.4457  decode.d8.loss_mask: 0.8708  decode.d8.loss_dice: 1.6564
2023/05/23 23:12:48 - mmengine - INFO - Iter(train) [ 40100/160000]  lr: 7.7131e-06  eta: 14:13:46  time: 0.4141  data_time: 0.0105  memory: 4906  grad_norm: 113.6379  loss: 39.2598  decode.loss_cls: 1.5655  decode.loss_mask: 0.6613  decode.loss_dice: 1.3434  decode.d0.loss_cls: 3.3604  decode.d0.loss_mask: 0.7259  decode.d0.loss_dice: 1.6828  decode.d1.loss_cls: 1.6803  decode.d1.loss_mask: 0.7369  decode.d1.loss_dice: 1.6191  decode.d2.loss_cls: 1.6466  decode.d2.loss_mask: 0.6900  decode.d2.loss_dice: 1.5288  decode.d3.loss_cls: 1.6190  decode.d3.loss_mask: 0.6908  decode.d3.loss_dice: 1.4764  decode.d4.loss_cls: 1.5870  decode.d4.loss_mask: 0.6729  decode.d4.loss_dice: 1.5037  decode.d5.loss_cls: 1.5480  decode.d5.loss_mask: 0.6629  decode.d5.loss_dice: 1.4415  decode.d6.loss_cls: 1.5291  decode.d6.loss_mask: 0.6600  decode.d6.loss_dice: 1.4180  decode.d7.loss_cls: 1.5755  decode.d7.loss_mask: 0.6428  decode.d7.loss_dice: 1.4319  decode.d8.loss_cls: 1.5015  decode.d8.loss_mask: 0.6528  decode.d8.loss_dice: 1.4050
2023/05/23 23:13:08 - mmengine - INFO - Iter(train) [ 40150/160000]  lr: 7.7103e-06  eta: 14:13:23  time: 0.4221  data_time: 0.0097  memory: 4877  grad_norm: 95.9094  loss: 32.6212  decode.loss_cls: 1.1679  decode.loss_mask: 0.6870  decode.loss_dice: 1.1443  decode.d0.loss_cls: 3.2547  decode.d0.loss_mask: 0.7612  decode.d0.loss_dice: 1.2668  decode.d1.loss_cls: 1.2535  decode.d1.loss_mask: 0.7478  decode.d1.loss_dice: 1.2368  decode.d2.loss_cls: 1.1722  decode.d2.loss_mask: 0.7070  decode.d2.loss_dice: 1.2271  decode.d3.loss_cls: 1.1593  decode.d3.loss_mask: 0.7264  decode.d3.loss_dice: 1.1367  decode.d4.loss_cls: 1.1896  decode.d4.loss_mask: 0.7074  decode.d4.loss_dice: 1.1647  decode.d5.loss_cls: 1.1661  decode.d5.loss_mask: 0.7218  decode.d5.loss_dice: 1.1848  decode.d6.loss_cls: 1.1418  decode.d6.loss_mask: 0.7078  decode.d6.loss_dice: 1.1559  decode.d7.loss_cls: 1.0788  decode.d7.loss_mask: 0.7063  decode.d7.loss_dice: 1.1357  decode.d8.loss_cls: 1.0396  decode.d8.loss_mask: 0.7020  decode.d8.loss_dice: 1.1703
2023/05/23 23:13:29 - mmengine - INFO - Iter(train) [ 40200/160000]  lr: 7.7074e-06  eta: 14:13:00  time: 0.4174  data_time: 0.0100  memory: 4836  grad_norm: 83.0376  loss: 35.3203  decode.loss_cls: 1.1944  decode.loss_mask: 0.7486  decode.loss_dice: 1.2853  decode.d0.loss_cls: 3.1304  decode.d0.loss_mask: 0.8003  decode.d0.loss_dice: 1.4862  decode.d1.loss_cls: 1.3919  decode.d1.loss_mask: 0.7786  decode.d1.loss_dice: 1.4027  decode.d2.loss_cls: 1.3347  decode.d2.loss_mask: 0.7667  decode.d2.loss_dice: 1.3367  decode.d3.loss_cls: 1.2909  decode.d3.loss_mask: 0.7455  decode.d3.loss_dice: 1.3191  decode.d4.loss_cls: 1.3084  decode.d4.loss_mask: 0.7298  decode.d4.loss_dice: 1.2921  decode.d5.loss_cls: 1.2504  decode.d5.loss_mask: 0.7396  decode.d5.loss_dice: 1.2882  decode.d6.loss_cls: 1.2245  decode.d6.loss_mask: 0.7497  decode.d6.loss_dice: 1.2916  decode.d7.loss_cls: 1.1712  decode.d7.loss_mask: 0.7524  decode.d7.loss_dice: 1.2989  decode.d8.loss_cls: 1.1566  decode.d8.loss_mask: 0.7582  decode.d8.loss_dice: 1.2967
2023/05/23 23:13:50 - mmengine - INFO - Iter(train) [ 40250/160000]  lr: 7.7045e-06  eta: 14:12:38  time: 0.4463  data_time: 0.0101  memory: 4821  grad_norm: 116.0723  loss: 37.1089  decode.loss_cls: 1.1935  decode.loss_mask: 0.9458  decode.loss_dice: 1.3191  decode.d0.loss_cls: 3.0376  decode.d0.loss_mask: 0.8996  decode.d0.loss_dice: 1.4887  decode.d1.loss_cls: 1.3186  decode.d1.loss_mask: 0.9722  decode.d1.loss_dice: 1.4623  decode.d2.loss_cls: 1.2639  decode.d2.loss_mask: 0.9366  decode.d2.loss_dice: 1.4025  decode.d3.loss_cls: 1.2729  decode.d3.loss_mask: 0.9020  decode.d3.loss_dice: 1.3342  decode.d4.loss_cls: 1.2553  decode.d4.loss_mask: 0.8917  decode.d4.loss_dice: 1.3093  decode.d5.loss_cls: 1.2353  decode.d5.loss_mask: 0.9296  decode.d5.loss_dice: 1.3446  decode.d6.loss_cls: 1.2174  decode.d6.loss_mask: 0.9305  decode.d6.loss_dice: 1.3168  decode.d7.loss_cls: 1.2258  decode.d7.loss_mask: 0.9375  decode.d7.loss_dice: 1.3125  decode.d8.loss_cls: 1.2044  decode.d8.loss_mask: 0.9195  decode.d8.loss_dice: 1.3291
2023/05/23 23:14:13 - mmengine - INFO - Iter(train) [ 40300/160000]  lr: 7.7016e-06  eta: 14:12:22  time: 0.4414  data_time: 0.0095  memory: 4847  grad_norm: 88.2486  loss: 42.8274  decode.loss_cls: 1.5071  decode.loss_mask: 0.7583  decode.loss_dice: 1.6405  decode.d0.loss_cls: 3.6537  decode.d0.loss_mask: 0.8675  decode.d0.loss_dice: 1.8961  decode.d1.loss_cls: 1.7450  decode.d1.loss_mask: 0.8906  decode.d1.loss_dice: 1.8147  decode.d2.loss_cls: 1.5990  decode.d2.loss_mask: 0.8495  decode.d2.loss_dice: 1.7224  decode.d3.loss_cls: 1.6390  decode.d3.loss_mask: 0.7985  decode.d3.loss_dice: 1.6372  decode.d4.loss_cls: 1.5640  decode.d4.loss_mask: 0.7966  decode.d4.loss_dice: 1.6078  decode.d5.loss_cls: 1.5697  decode.d5.loss_mask: 0.7995  decode.d5.loss_dice: 1.6192  decode.d6.loss_cls: 1.5866  decode.d6.loss_mask: 0.7587  decode.d6.loss_dice: 1.6098  decode.d7.loss_cls: 1.5879  decode.d7.loss_mask: 0.7596  decode.d7.loss_dice: 1.5853  decode.d8.loss_cls: 1.5531  decode.d8.loss_mask: 0.7672  decode.d8.loss_dice: 1.6432
2023/05/23 23:14:34 - mmengine - INFO - Iter(train) [ 40350/160000]  lr: 7.6987e-06  eta: 14:11:59  time: 0.4077  data_time: 0.0099  memory: 4890  grad_norm: 91.9112  loss: 41.0952  decode.loss_cls: 1.4238  decode.loss_mask: 0.9778  decode.loss_dice: 1.3953  decode.d0.loss_cls: 3.3934  decode.d0.loss_mask: 0.9794  decode.d0.loss_dice: 1.6608  decode.d1.loss_cls: 1.5709  decode.d1.loss_mask: 0.9896  decode.d1.loss_dice: 1.5764  decode.d2.loss_cls: 1.5034  decode.d2.loss_mask: 0.9842  decode.d2.loss_dice: 1.4605  decode.d3.loss_cls: 1.4924  decode.d3.loss_mask: 0.9640  decode.d3.loss_dice: 1.4275  decode.d4.loss_cls: 1.4000  decode.d4.loss_mask: 0.9802  decode.d4.loss_dice: 1.4800  decode.d5.loss_cls: 1.4284  decode.d5.loss_mask: 0.9698  decode.d5.loss_dice: 1.4127  decode.d6.loss_cls: 1.5267  decode.d6.loss_mask: 0.9663  decode.d6.loss_dice: 1.4002  decode.d7.loss_cls: 1.5220  decode.d7.loss_mask: 0.9518  decode.d7.loss_dice: 1.4315  decode.d8.loss_cls: 1.4711  decode.d8.loss_mask: 0.9424  decode.d8.loss_dice: 1.4125
2023/05/23 23:14:56 - mmengine - INFO - Iter(train) [ 40400/160000]  lr: 7.6958e-06  eta: 14:11:40  time: 0.4725  data_time: 0.0096  memory: 4836  grad_norm: 98.3089  loss: 35.5656  decode.loss_cls: 1.2968  decode.loss_mask: 0.7395  decode.loss_dice: 1.2851  decode.d0.loss_cls: 2.8177  decode.d0.loss_mask: 0.8352  decode.d0.loss_dice: 1.4406  decode.d1.loss_cls: 1.4223  decode.d1.loss_mask: 0.8054  decode.d1.loss_dice: 1.4233  decode.d2.loss_cls: 1.3694  decode.d2.loss_mask: 0.7691  decode.d2.loss_dice: 1.3021  decode.d3.loss_cls: 1.2736  decode.d3.loss_mask: 0.7923  decode.d3.loss_dice: 1.3275  decode.d4.loss_cls: 1.2703  decode.d4.loss_mask: 0.7846  decode.d4.loss_dice: 1.2846  decode.d5.loss_cls: 1.2831  decode.d5.loss_mask: 0.7893  decode.d5.loss_dice: 1.2594  decode.d6.loss_cls: 1.2908  decode.d6.loss_mask: 0.7574  decode.d6.loss_dice: 1.3051  decode.d7.loss_cls: 1.2189  decode.d7.loss_mask: 0.7768  decode.d7.loss_dice: 1.3239  decode.d8.loss_cls: 1.2866  decode.d8.loss_mask: 0.7436  decode.d8.loss_dice: 1.2912
2023/05/23 23:15:19 - mmengine - INFO - Iter(train) [ 40450/160000]  lr: 7.6929e-06  eta: 14:11:23  time: 0.4181  data_time: 0.0098  memory: 4920  grad_norm: 96.1912  loss: 40.0260  decode.loss_cls: 1.4334  decode.loss_mask: 0.7803  decode.loss_dice: 1.4541  decode.d0.loss_cls: 3.2187  decode.d0.loss_mask: 0.8640  decode.d0.loss_dice: 1.6887  decode.d1.loss_cls: 1.5031  decode.d1.loss_mask: 0.8885  decode.d1.loss_dice: 1.6354  decode.d2.loss_cls: 1.5471  decode.d2.loss_mask: 0.8749  decode.d2.loss_dice: 1.5475  decode.d3.loss_cls: 1.4820  decode.d3.loss_mask: 0.8393  decode.d3.loss_dice: 1.5075  decode.d4.loss_cls: 1.4566  decode.d4.loss_mask: 0.8620  decode.d4.loss_dice: 1.5032  decode.d5.loss_cls: 1.5353  decode.d5.loss_mask: 0.7802  decode.d5.loss_dice: 1.4960  decode.d6.loss_cls: 1.4582  decode.d6.loss_mask: 0.8086  decode.d6.loss_dice: 1.4756  decode.d7.loss_cls: 1.4266  decode.d7.loss_mask: 0.7925  decode.d7.loss_dice: 1.4755  decode.d8.loss_cls: 1.4642  decode.d8.loss_mask: 0.7874  decode.d8.loss_dice: 1.4397
2023/05/23 23:15:41 - mmengine - INFO - Iter(train) [ 40500/160000]  lr: 7.6900e-06  eta: 14:11:01  time: 0.4224  data_time: 0.0097  memory: 4829  grad_norm: 91.9563  loss: 37.2940  decode.loss_cls: 1.2901  decode.loss_mask: 0.7899  decode.loss_dice: 1.4059  decode.d0.loss_cls: 3.1483  decode.d0.loss_mask: 0.8547  decode.d0.loss_dice: 1.5932  decode.d1.loss_cls: 1.4334  decode.d1.loss_mask: 0.8266  decode.d1.loss_dice: 1.5105  decode.d2.loss_cls: 1.3741  decode.d2.loss_mask: 0.7766  decode.d2.loss_dice: 1.3883  decode.d3.loss_cls: 1.2817  decode.d3.loss_mask: 0.8219  decode.d3.loss_dice: 1.4094  decode.d4.loss_cls: 1.3230  decode.d4.loss_mask: 0.7792  decode.d4.loss_dice: 1.3894  decode.d5.loss_cls: 1.2778  decode.d5.loss_mask: 0.8022  decode.d5.loss_dice: 1.4097  decode.d6.loss_cls: 1.3431  decode.d6.loss_mask: 0.7869  decode.d6.loss_dice: 1.3736  decode.d7.loss_cls: 1.3020  decode.d7.loss_mask: 0.7704  decode.d7.loss_dice: 1.3997  decode.d8.loss_cls: 1.3024  decode.d8.loss_mask: 0.7513  decode.d8.loss_dice: 1.3787
2023/05/23 23:16:03 - mmengine - INFO - Iter(train) [ 40550/160000]  lr: 7.6871e-06  eta: 14:10:41  time: 0.4222  data_time: 0.0098  memory: 4831  grad_norm: 104.1134  loss: 30.3101  decode.loss_cls: 0.9232  decode.loss_mask: 0.8079  decode.loss_dice: 1.0520  decode.d0.loss_cls: 2.7795  decode.d0.loss_mask: 0.8568  decode.d0.loss_dice: 1.2359  decode.d1.loss_cls: 0.9668  decode.d1.loss_mask: 0.8511  decode.d1.loss_dice: 1.1916  decode.d2.loss_cls: 0.9196  decode.d2.loss_mask: 0.8436  decode.d2.loss_dice: 1.1258  decode.d3.loss_cls: 0.8758  decode.d3.loss_mask: 0.7956  decode.d3.loss_dice: 1.0934  decode.d4.loss_cls: 0.8533  decode.d4.loss_mask: 0.8286  decode.d4.loss_dice: 1.1001  decode.d5.loss_cls: 0.8673  decode.d5.loss_mask: 0.8508  decode.d5.loss_dice: 1.1116  decode.d6.loss_cls: 0.8926  decode.d6.loss_mask: 0.8332  decode.d6.loss_dice: 1.0933  decode.d7.loss_cls: 0.8712  decode.d7.loss_mask: 0.8062  decode.d7.loss_dice: 1.1031  decode.d8.loss_cls: 0.9226  decode.d8.loss_mask: 0.7976  decode.d8.loss_dice: 1.0598
2023/05/23 23:16:23 - mmengine - INFO - Iter(train) [ 40600/160000]  lr: 7.6842e-06  eta: 14:10:18  time: 0.4126  data_time: 0.0099  memory: 4823  grad_norm: 109.1335  loss: 40.0068  decode.loss_cls: 1.3166  decode.loss_mask: 0.8517  decode.loss_dice: 1.5392  decode.d0.loss_cls: 3.1667  decode.d0.loss_mask: 0.9218  decode.d0.loss_dice: 1.7683  decode.d1.loss_cls: 1.4936  decode.d1.loss_mask: 0.9196  decode.d1.loss_dice: 1.6532  decode.d2.loss_cls: 1.4116  decode.d2.loss_mask: 0.9087  decode.d2.loss_dice: 1.6187  decode.d3.loss_cls: 1.3065  decode.d3.loss_mask: 0.8639  decode.d3.loss_dice: 1.5809  decode.d4.loss_cls: 1.3356  decode.d4.loss_mask: 0.8566  decode.d4.loss_dice: 1.5932  decode.d5.loss_cls: 1.3014  decode.d5.loss_mask: 0.8635  decode.d5.loss_dice: 1.6016  decode.d6.loss_cls: 1.2545  decode.d6.loss_mask: 0.8565  decode.d6.loss_dice: 1.5729  decode.d7.loss_cls: 1.3269  decode.d7.loss_mask: 0.8544  decode.d7.loss_dice: 1.5541  decode.d8.loss_cls: 1.3247  decode.d8.loss_mask: 0.8494  decode.d8.loss_dice: 1.5407
2023/05/23 23:16:44 - mmengine - INFO - Iter(train) [ 40650/160000]  lr: 7.6813e-06  eta: 14:09:54  time: 0.4126  data_time: 0.0101  memory: 4869  grad_norm: 92.5736  loss: 38.2262  decode.loss_cls: 1.2479  decode.loss_mask: 0.8797  decode.loss_dice: 1.3511  decode.d0.loss_cls: 3.2112  decode.d0.loss_mask: 0.9464  decode.d0.loss_dice: 1.6703  decode.d1.loss_cls: 1.4676  decode.d1.loss_mask: 0.9001  decode.d1.loss_dice: 1.5374  decode.d2.loss_cls: 1.3295  decode.d2.loss_mask: 0.8927  decode.d2.loss_dice: 1.4262  decode.d3.loss_cls: 1.2538  decode.d3.loss_mask: 0.8927  decode.d3.loss_dice: 1.4002  decode.d4.loss_cls: 1.2489  decode.d4.loss_mask: 0.8705  decode.d4.loss_dice: 1.3988  decode.d5.loss_cls: 1.2524  decode.d5.loss_mask: 0.9056  decode.d5.loss_dice: 1.4541  decode.d6.loss_cls: 1.2435  decode.d6.loss_mask: 0.8737  decode.d6.loss_dice: 1.4100  decode.d7.loss_cls: 1.2966  decode.d7.loss_mask: 0.9024  decode.d7.loss_dice: 1.4041  decode.d8.loss_cls: 1.2790  decode.d8.loss_mask: 0.8990  decode.d8.loss_dice: 1.3809
2023/05/23 23:17:05 - mmengine - INFO - Iter(train) [ 40700/160000]  lr: 7.6784e-06  eta: 14:09:32  time: 0.4146  data_time: 0.0100  memory: 4918  grad_norm: 96.0212  loss: 38.9599  decode.loss_cls: 1.3861  decode.loss_mask: 0.8120  decode.loss_dice: 1.4013  decode.d0.loss_cls: 3.1616  decode.d0.loss_mask: 0.9336  decode.d0.loss_dice: 1.6572  decode.d1.loss_cls: 1.6510  decode.d1.loss_mask: 0.8405  decode.d1.loss_dice: 1.4848  decode.d2.loss_cls: 1.5026  decode.d2.loss_mask: 0.7962  decode.d2.loss_dice: 1.4633  decode.d3.loss_cls: 1.4731  decode.d3.loss_mask: 0.7816  decode.d3.loss_dice: 1.3964  decode.d4.loss_cls: 1.4230  decode.d4.loss_mask: 0.8137  decode.d4.loss_dice: 1.4400  decode.d5.loss_cls: 1.4217  decode.d5.loss_mask: 0.8051  decode.d5.loss_dice: 1.4255  decode.d6.loss_cls: 1.4235  decode.d6.loss_mask: 0.8234  decode.d6.loss_dice: 1.3739  decode.d7.loss_cls: 1.4168  decode.d7.loss_mask: 0.8308  decode.d7.loss_dice: 1.4038  decode.d8.loss_cls: 1.4198  decode.d8.loss_mask: 0.8127  decode.d8.loss_dice: 1.3852
2023/05/23 23:17:28 - mmengine - INFO - Iter(train) [ 40750/160000]  lr: 7.6755e-06  eta: 14:09:15  time: 0.4668  data_time: 0.0095  memory: 4830  grad_norm: 92.6825  loss: 27.8009  decode.loss_cls: 0.9432  decode.loss_mask: 0.7428  decode.loss_dice: 0.9102  decode.d0.loss_cls: 2.7760  decode.d0.loss_mask: 0.6744  decode.d0.loss_dice: 0.9959  decode.d1.loss_cls: 1.0260  decode.d1.loss_mask: 0.7179  decode.d1.loss_dice: 0.9971  decode.d2.loss_cls: 1.0487  decode.d2.loss_mask: 0.6628  decode.d2.loss_dice: 0.9311  decode.d3.loss_cls: 0.9462  decode.d3.loss_mask: 0.7569  decode.d3.loss_dice: 0.9052  decode.d4.loss_cls: 0.9608  decode.d4.loss_mask: 0.6813  decode.d4.loss_dice: 0.9092  decode.d5.loss_cls: 0.9357  decode.d5.loss_mask: 0.7083  decode.d5.loss_dice: 0.9195  decode.d6.loss_cls: 0.9073  decode.d6.loss_mask: 0.6927  decode.d6.loss_dice: 0.9143  decode.d7.loss_cls: 0.9205  decode.d7.loss_mask: 0.7221  decode.d7.loss_dice: 0.9198  decode.d8.loss_cls: 0.9071  decode.d8.loss_mask: 0.7402  decode.d8.loss_dice: 0.9275
2023/05/23 23:17:49 - mmengine - INFO - Iter(train) [ 40800/160000]  lr: 7.6726e-06  eta: 14:08:54  time: 0.4129  data_time: 0.0098  memory: 4942  grad_norm: 89.7330  loss: 35.6168  decode.loss_cls: 1.2141  decode.loss_mask: 0.8966  decode.loss_dice: 1.1506  decode.d0.loss_cls: 3.2651  decode.d0.loss_mask: 0.9446  decode.d0.loss_dice: 1.3651  decode.d1.loss_cls: 1.4000  decode.d1.loss_mask: 0.8912  decode.d1.loss_dice: 1.2357  decode.d2.loss_cls: 1.3603  decode.d2.loss_mask: 0.9011  decode.d2.loss_dice: 1.1795  decode.d3.loss_cls: 1.3074  decode.d3.loss_mask: 0.8867  decode.d3.loss_dice: 1.1731  decode.d4.loss_cls: 1.2789  decode.d4.loss_mask: 0.8651  decode.d4.loss_dice: 1.1925  decode.d5.loss_cls: 1.3473  decode.d5.loss_mask: 0.8365  decode.d5.loss_dice: 1.1814  decode.d6.loss_cls: 1.2375  decode.d6.loss_mask: 0.8969  decode.d6.loss_dice: 1.1650  decode.d7.loss_cls: 1.1795  decode.d7.loss_mask: 0.8702  decode.d7.loss_dice: 1.1739  decode.d8.loss_cls: 1.2102  decode.d8.loss_mask: 0.8728  decode.d8.loss_dice: 1.1379
2023/05/23 23:18:10 - mmengine - INFO - Iter(train) [ 40850/160000]  lr: 7.6697e-06  eta: 14:08:30  time: 0.4177  data_time: 0.0096  memory: 4844  grad_norm: 104.4974  loss: 39.7297  decode.loss_cls: 1.3125  decode.loss_mask: 0.9307  decode.loss_dice: 1.4250  decode.d0.loss_cls: 3.2807  decode.d0.loss_mask: 0.9941  decode.d0.loss_dice: 1.6274  decode.d1.loss_cls: 1.4039  decode.d1.loss_mask: 1.0330  decode.d1.loss_dice: 1.5465  decode.d2.loss_cls: 1.3942  decode.d2.loss_mask: 0.9796  decode.d2.loss_dice: 1.4912  decode.d3.loss_cls: 1.3279  decode.d3.loss_mask: 0.9545  decode.d3.loss_dice: 1.5066  decode.d4.loss_cls: 1.2730  decode.d4.loss_mask: 0.9407  decode.d4.loss_dice: 1.5300  decode.d5.loss_cls: 1.2617  decode.d5.loss_mask: 0.9586  decode.d5.loss_dice: 1.5212  decode.d6.loss_cls: 1.2640  decode.d6.loss_mask: 0.9319  decode.d6.loss_dice: 1.5075  decode.d7.loss_cls: 1.2620  decode.d7.loss_mask: 0.9494  decode.d7.loss_dice: 1.4464  decode.d8.loss_cls: 1.2936  decode.d8.loss_mask: 0.9344  decode.d8.loss_dice: 1.4474
2023/05/23 23:18:31 - mmengine - INFO - Iter(train) [ 40900/160000]  lr: 7.6668e-06  eta: 14:08:08  time: 0.4153  data_time: 0.0098  memory: 4859  grad_norm: 105.7327  loss: 46.4833  decode.loss_cls: 1.5516  decode.loss_mask: 0.9653  decode.loss_dice: 1.8161  decode.d0.loss_cls: 3.6315  decode.d0.loss_mask: 0.9500  decode.d0.loss_dice: 2.1126  decode.d1.loss_cls: 1.6212  decode.d1.loss_mask: 1.0238  decode.d1.loss_dice: 1.9796  decode.d2.loss_cls: 1.5450  decode.d2.loss_mask: 0.9655  decode.d2.loss_dice: 1.8918  decode.d3.loss_cls: 1.6050  decode.d3.loss_mask: 0.9666  decode.d3.loss_dice: 1.8732  decode.d4.loss_cls: 1.5621  decode.d4.loss_mask: 1.0091  decode.d4.loss_dice: 1.8816  decode.d5.loss_cls: 1.6035  decode.d5.loss_mask: 0.9258  decode.d5.loss_dice: 1.8544  decode.d6.loss_cls: 1.6120  decode.d6.loss_mask: 0.9722  decode.d6.loss_dice: 1.8321  decode.d7.loss_cls: 1.5406  decode.d7.loss_mask: 0.9776  decode.d7.loss_dice: 1.8338  decode.d8.loss_cls: 1.5780  decode.d8.loss_mask: 0.9716  decode.d8.loss_dice: 1.8303
2023/05/23 23:18:51 - mmengine - INFO - Iter(train) [ 40950/160000]  lr: 7.6639e-06  eta: 14:07:44  time: 0.4117  data_time: 0.0099  memory: 4866  grad_norm: 97.4083  loss: 34.9432  decode.loss_cls: 1.5221  decode.loss_mask: 0.6754  decode.loss_dice: 1.0193  decode.d0.loss_cls: 3.4364  decode.d0.loss_mask: 0.7722  decode.d0.loss_dice: 1.2644  decode.d1.loss_cls: 1.6456  decode.d1.loss_mask: 0.7325  decode.d1.loss_dice: 1.1627  decode.d2.loss_cls: 1.5126  decode.d2.loss_mask: 0.7115  decode.d2.loss_dice: 1.1049  decode.d3.loss_cls: 1.6252  decode.d3.loss_mask: 0.6865  decode.d3.loss_dice: 0.9978  decode.d4.loss_cls: 1.5298  decode.d4.loss_mask: 0.6881  decode.d4.loss_dice: 1.0109  decode.d5.loss_cls: 1.5428  decode.d5.loss_mask: 0.6673  decode.d5.loss_dice: 1.0137  decode.d6.loss_cls: 1.5771  decode.d6.loss_mask: 0.6719  decode.d6.loss_dice: 0.9907  decode.d7.loss_cls: 1.5226  decode.d7.loss_mask: 0.6816  decode.d7.loss_dice: 0.9929  decode.d8.loss_cls: 1.5127  decode.d8.loss_mask: 0.6778  decode.d8.loss_dice: 0.9942
2023/05/23 23:19:13 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 23:19:13 - mmengine - INFO - Iter(train) [ 41000/160000]  lr: 7.6610e-06  eta: 14:07:23  time: 0.4125  data_time: 0.0096  memory: 4804  grad_norm: 74.1243  loss: 26.4961  decode.loss_cls: 1.0282  decode.loss_mask: 0.5782  decode.loss_dice: 0.8661  decode.d0.loss_cls: 2.7424  decode.d0.loss_mask: 0.5983  decode.d0.loss_dice: 0.9453  decode.d1.loss_cls: 1.1406  decode.d1.loss_mask: 0.5772  decode.d1.loss_dice: 0.8835  decode.d2.loss_cls: 1.0755  decode.d2.loss_mask: 0.5738  decode.d2.loss_dice: 0.8781  decode.d3.loss_cls: 1.0247  decode.d3.loss_mask: 0.5726  decode.d3.loss_dice: 0.8837  decode.d4.loss_cls: 1.0134  decode.d4.loss_mask: 0.5697  decode.d4.loss_dice: 0.8782  decode.d5.loss_cls: 0.9316  decode.d5.loss_mask: 0.5743  decode.d5.loss_dice: 0.9110  decode.d6.loss_cls: 1.0042  decode.d6.loss_mask: 0.5685  decode.d6.loss_dice: 0.8245  decode.d7.loss_cls: 0.9975  decode.d7.loss_mask: 0.5614  decode.d7.loss_dice: 0.8658  decode.d8.loss_cls: 0.9932  decode.d8.loss_mask: 0.5691  decode.d8.loss_dice: 0.8656
2023/05/23 23:19:13 - mmengine - INFO - Saving checkpoint at 41000 iterations
2023/05/23 23:19:39 - mmengine - INFO - Iter(train) [ 41050/160000]  lr: 7.6581e-06  eta: 14:07:17  time: 0.4205  data_time: 0.0098  memory: 4837  grad_norm: 86.7345  loss: 42.7624  decode.loss_cls: 1.4949  decode.loss_mask: 0.8618  decode.loss_dice: 1.6084  decode.d0.loss_cls: 3.4658  decode.d0.loss_mask: 0.9390  decode.d0.loss_dice: 1.8028  decode.d1.loss_cls: 1.5561  decode.d1.loss_mask: 0.9141  decode.d1.loss_dice: 1.7007  decode.d2.loss_cls: 1.5329  decode.d2.loss_mask: 0.9054  decode.d2.loss_dice: 1.6951  decode.d3.loss_cls: 1.5660  decode.d3.loss_mask: 0.8989  decode.d3.loss_dice: 1.6288  decode.d4.loss_cls: 1.4608  decode.d4.loss_mask: 0.9065  decode.d4.loss_dice: 1.6293  decode.d5.loss_cls: 1.5100  decode.d5.loss_mask: 0.9456  decode.d5.loss_dice: 1.6679  decode.d6.loss_cls: 1.4750  decode.d6.loss_mask: 0.9103  decode.d6.loss_dice: 1.6142  decode.d7.loss_cls: 1.4752  decode.d7.loss_mask: 0.9101  decode.d7.loss_dice: 1.6404  decode.d8.loss_cls: 1.4775  decode.d8.loss_mask: 0.9386  decode.d8.loss_dice: 1.6305
2023/05/23 23:20:00 - mmengine - INFO - Iter(train) [ 41100/160000]  lr: 7.6552e-06  eta: 14:06:52  time: 0.4027  data_time: 0.0097  memory: 4791  grad_norm: 104.2873  loss: 35.2269  decode.loss_cls: 1.0885  decode.loss_mask: 0.9936  decode.loss_dice: 1.0870  decode.d0.loss_cls: 3.1589  decode.d0.loss_mask: 1.0452  decode.d0.loss_dice: 1.2474  decode.d1.loss_cls: 1.2666  decode.d1.loss_mask: 1.0596  decode.d1.loss_dice: 1.1777  decode.d2.loss_cls: 1.1667  decode.d2.loss_mask: 1.0765  decode.d2.loss_dice: 1.1325  decode.d3.loss_cls: 1.2052  decode.d3.loss_mask: 1.0555  decode.d3.loss_dice: 1.0947  decode.d4.loss_cls: 1.1860  decode.d4.loss_mask: 1.0397  decode.d4.loss_dice: 1.1093  decode.d5.loss_cls: 1.1454  decode.d5.loss_mask: 1.0227  decode.d5.loss_dice: 1.1035  decode.d6.loss_cls: 1.1781  decode.d6.loss_mask: 1.0109  decode.d6.loss_dice: 1.0837  decode.d7.loss_cls: 1.1693  decode.d7.loss_mask: 1.0003  decode.d7.loss_dice: 1.0914  decode.d8.loss_cls: 1.1453  decode.d8.loss_mask: 1.0096  decode.d8.loss_dice: 1.0760
2023/05/23 23:20:20 - mmengine - INFO - Iter(train) [ 41150/160000]  lr: 7.6523e-06  eta: 14:06:28  time: 0.4091  data_time: 0.0097  memory: 4871  grad_norm: 101.1428  loss: 35.5673  decode.loss_cls: 1.2989  decode.loss_mask: 0.7088  decode.loss_dice: 1.1649  decode.d0.loss_cls: 3.5554  decode.d0.loss_mask: 0.8255  decode.d0.loss_dice: 1.4471  decode.d1.loss_cls: 1.4178  decode.d1.loss_mask: 0.8569  decode.d1.loss_dice: 1.3762  decode.d2.loss_cls: 1.4130  decode.d2.loss_mask: 0.7761  decode.d2.loss_dice: 1.2674  decode.d3.loss_cls: 1.3754  decode.d3.loss_mask: 0.7510  decode.d3.loss_dice: 1.2168  decode.d4.loss_cls: 1.3595  decode.d4.loss_mask: 0.7314  decode.d4.loss_dice: 1.2119  decode.d5.loss_cls: 1.2997  decode.d5.loss_mask: 0.7693  decode.d5.loss_dice: 1.2248  decode.d6.loss_cls: 1.3187  decode.d6.loss_mask: 0.7119  decode.d6.loss_dice: 1.1523  decode.d7.loss_cls: 1.2921  decode.d7.loss_mask: 0.7136  decode.d7.loss_dice: 1.1914  decode.d8.loss_cls: 1.2610  decode.d8.loss_mask: 0.6959  decode.d8.loss_dice: 1.1827
2023/05/23 23:20:40 - mmengine - INFO - Iter(train) [ 41200/160000]  lr: 7.6494e-06  eta: 14:06:04  time: 0.4187  data_time: 0.0103  memory: 4845  grad_norm: 99.7466  loss: 33.0835  decode.loss_cls: 1.1547  decode.loss_mask: 0.8085  decode.loss_dice: 1.0952  decode.d0.loss_cls: 3.1769  decode.d0.loss_mask: 0.8489  decode.d0.loss_dice: 1.2012  decode.d1.loss_cls: 1.2478  decode.d1.loss_mask: 0.8115  decode.d1.loss_dice: 1.1180  decode.d2.loss_cls: 1.1394  decode.d2.loss_mask: 0.7805  decode.d2.loss_dice: 1.1087  decode.d3.loss_cls: 1.1615  decode.d3.loss_mask: 0.8399  decode.d3.loss_dice: 1.1052  decode.d4.loss_cls: 1.1503  decode.d4.loss_mask: 0.8148  decode.d4.loss_dice: 1.1134  decode.d5.loss_cls: 1.1748  decode.d5.loss_mask: 0.8271  decode.d5.loss_dice: 1.1258  decode.d6.loss_cls: 1.1933  decode.d6.loss_mask: 0.8058  decode.d6.loss_dice: 1.1140  decode.d7.loss_cls: 1.1902  decode.d7.loss_mask: 0.8123  decode.d7.loss_dice: 1.1103  decode.d8.loss_cls: 1.1474  decode.d8.loss_mask: 0.8063  decode.d8.loss_dice: 1.0999
2023/05/23 23:21:01 - mmengine - INFO - Iter(train) [ 41250/160000]  lr: 7.6465e-06  eta: 14:05:40  time: 0.4150  data_time: 0.0103  memory: 4865  grad_norm: 83.2065  loss: 39.8495  decode.loss_cls: 1.5126  decode.loss_mask: 0.9458  decode.loss_dice: 1.2402  decode.d0.loss_cls: 3.4790  decode.d0.loss_mask: 1.0548  decode.d0.loss_dice: 1.4381  decode.d1.loss_cls: 1.5649  decode.d1.loss_mask: 0.9972  decode.d1.loss_dice: 1.4297  decode.d2.loss_cls: 1.5667  decode.d2.loss_mask: 0.9397  decode.d2.loss_dice: 1.3679  decode.d3.loss_cls: 1.4963  decode.d3.loss_mask: 0.9165  decode.d3.loss_dice: 1.2823  decode.d4.loss_cls: 1.5557  decode.d4.loss_mask: 0.8990  decode.d4.loss_dice: 1.3049  decode.d5.loss_cls: 1.4641  decode.d5.loss_mask: 0.9086  decode.d5.loss_dice: 1.2781  decode.d6.loss_cls: 1.5781  decode.d6.loss_mask: 0.8945  decode.d6.loss_dice: 1.2590  decode.d7.loss_cls: 1.5304  decode.d7.loss_mask: 0.9194  decode.d7.loss_dice: 1.2499  decode.d8.loss_cls: 1.4984  decode.d8.loss_mask: 0.9739  decode.d8.loss_dice: 1.3037
2023/05/23 23:21:22 - mmengine - INFO - Iter(train) [ 41300/160000]  lr: 7.6436e-06  eta: 14:05:17  time: 0.4118  data_time: 0.0098  memory: 4857  grad_norm: 88.4967  loss: 32.1288  decode.loss_cls: 1.0293  decode.loss_mask: 0.7387  decode.loss_dice: 1.0827  decode.d0.loss_cls: 3.3719  decode.d0.loss_mask: 0.8225  decode.d0.loss_dice: 1.3073  decode.d1.loss_cls: 1.3168  decode.d1.loss_mask: 0.7625  decode.d1.loss_dice: 1.2011  decode.d2.loss_cls: 1.1558  decode.d2.loss_mask: 0.7682  decode.d2.loss_dice: 1.1303  decode.d3.loss_cls: 1.0858  decode.d3.loss_mask: 0.7741  decode.d3.loss_dice: 1.0973  decode.d4.loss_cls: 1.0904  decode.d4.loss_mask: 0.7562  decode.d4.loss_dice: 1.1011  decode.d5.loss_cls: 1.0343  decode.d5.loss_mask: 0.7377  decode.d5.loss_dice: 1.0899  decode.d6.loss_cls: 1.0468  decode.d6.loss_mask: 0.7372  decode.d6.loss_dice: 1.0712  decode.d7.loss_cls: 1.0615  decode.d7.loss_mask: 0.7547  decode.d7.loss_dice: 1.1040  decode.d8.loss_cls: 1.0299  decode.d8.loss_mask: 0.7449  decode.d8.loss_dice: 1.1248
2023/05/23 23:21:43 - mmengine - INFO - Iter(train) [ 41350/160000]  lr: 7.6407e-06  eta: 14:04:55  time: 0.4238  data_time: 0.0098  memory: 4844  grad_norm: 88.6805  loss: 33.2694  decode.loss_cls: 1.1317  decode.loss_mask: 0.7010  decode.loss_dice: 1.2498  decode.d0.loss_cls: 3.0915  decode.d0.loss_mask: 0.7082  decode.d0.loss_dice: 1.4338  decode.d1.loss_cls: 1.2537  decode.d1.loss_mask: 0.7191  decode.d1.loss_dice: 1.2856  decode.d2.loss_cls: 1.2189  decode.d2.loss_mask: 0.7001  decode.d2.loss_dice: 1.3009  decode.d3.loss_cls: 1.1926  decode.d3.loss_mask: 0.6894  decode.d3.loss_dice: 1.2814  decode.d4.loss_cls: 1.1153  decode.d4.loss_mask: 0.7127  decode.d4.loss_dice: 1.2812  decode.d5.loss_cls: 1.1199  decode.d5.loss_mask: 0.7042  decode.d5.loss_dice: 1.2745  decode.d6.loss_cls: 1.0994  decode.d6.loss_mask: 0.6932  decode.d6.loss_dice: 1.2249  decode.d7.loss_cls: 1.1323  decode.d7.loss_mask: 0.6800  decode.d7.loss_dice: 1.2312  decode.d8.loss_cls: 1.1005  decode.d8.loss_mask: 0.6872  decode.d8.loss_dice: 1.2554
2023/05/23 23:22:04 - mmengine - INFO - Iter(train) [ 41400/160000]  lr: 7.6378e-06  eta: 14:04:33  time: 0.4183  data_time: 0.0097  memory: 4829  grad_norm: 103.2347  loss: 47.9368  decode.loss_cls: 1.9223  decode.loss_mask: 0.8662  decode.loss_dice: 1.5725  decode.d0.loss_cls: 3.9346  decode.d0.loss_mask: 0.9563  decode.d0.loss_dice: 1.9295  decode.d1.loss_cls: 2.2582  decode.d1.loss_mask: 0.8981  decode.d1.loss_dice: 1.7570  decode.d2.loss_cls: 2.0928  decode.d2.loss_mask: 0.8799  decode.d2.loss_dice: 1.7063  decode.d3.loss_cls: 2.0734  decode.d3.loss_mask: 0.8781  decode.d3.loss_dice: 1.5891  decode.d4.loss_cls: 2.1350  decode.d4.loss_mask: 0.8548  decode.d4.loss_dice: 1.6165  decode.d5.loss_cls: 2.1289  decode.d5.loss_mask: 0.8625  decode.d5.loss_dice: 1.6274  decode.d6.loss_cls: 2.1258  decode.d6.loss_mask: 0.8370  decode.d6.loss_dice: 1.5398  decode.d7.loss_cls: 2.0409  decode.d7.loss_mask: 0.8675  decode.d7.loss_dice: 1.5665  decode.d8.loss_cls: 2.0569  decode.d8.loss_mask: 0.8136  decode.d8.loss_dice: 1.5493
2023/05/23 23:22:25 - mmengine - INFO - Iter(train) [ 41450/160000]  lr: 7.6349e-06  eta: 14:04:11  time: 0.4677  data_time: 0.0101  memory: 4815  grad_norm: 79.8317  loss: 39.4148  decode.loss_cls: 1.2967  decode.loss_mask: 0.7675  decode.loss_dice: 1.5871  decode.d0.loss_cls: 3.5123  decode.d0.loss_mask: 0.7325  decode.d0.loss_dice: 1.8201  decode.d1.loss_cls: 1.4523  decode.d1.loss_mask: 0.7506  decode.d1.loss_dice: 1.6266  decode.d2.loss_cls: 1.3642  decode.d2.loss_mask: 0.7473  decode.d2.loss_dice: 1.6059  decode.d3.loss_cls: 1.3925  decode.d3.loss_mask: 0.7667  decode.d3.loss_dice: 1.5758  decode.d4.loss_cls: 1.4546  decode.d4.loss_mask: 0.7238  decode.d4.loss_dice: 1.5845  decode.d5.loss_cls: 1.3208  decode.d5.loss_mask: 0.7489  decode.d5.loss_dice: 1.5838  decode.d6.loss_cls: 1.3462  decode.d6.loss_mask: 0.7811  decode.d6.loss_dice: 1.5622  decode.d7.loss_cls: 1.2944  decode.d7.loss_mask: 0.7613  decode.d7.loss_dice: 1.5911  decode.d8.loss_cls: 1.3039  decode.d8.loss_mask: 0.7685  decode.d8.loss_dice: 1.5915
2023/05/23 23:22:48 - mmengine - INFO - Iter(train) [ 41500/160000]  lr: 7.6320e-06  eta: 14:03:53  time: 0.4139  data_time: 0.0101  memory: 4824  grad_norm: 88.0010  loss: 49.4354  decode.loss_cls: 1.8946  decode.loss_mask: 0.8747  decode.loss_dice: 1.8787  decode.d0.loss_cls: 3.8279  decode.d0.loss_mask: 0.9131  decode.d0.loss_dice: 2.2377  decode.d1.loss_cls: 1.9830  decode.d1.loss_mask: 0.9180  decode.d1.loss_dice: 2.0816  decode.d2.loss_cls: 1.9252  decode.d2.loss_mask: 0.9334  decode.d2.loss_dice: 2.0419  decode.d3.loss_cls: 1.9708  decode.d3.loss_mask: 0.9134  decode.d3.loss_dice: 1.9515  decode.d4.loss_cls: 1.9115  decode.d4.loss_mask: 0.8961  decode.d4.loss_dice: 1.9002  decode.d5.loss_cls: 1.8583  decode.d5.loss_mask: 0.8575  decode.d5.loss_dice: 1.9059  decode.d6.loss_cls: 1.8864  decode.d6.loss_mask: 0.8357  decode.d6.loss_dice: 1.8907  decode.d7.loss_cls: 1.9002  decode.d7.loss_mask: 0.8395  decode.d7.loss_dice: 1.8749  decode.d8.loss_cls: 1.7932  decode.d8.loss_mask: 0.8640  decode.d8.loss_dice: 1.8763
2023/05/23 23:23:08 - mmengine - INFO - Iter(train) [ 41550/160000]  lr: 7.6291e-06  eta: 14:03:30  time: 0.4142  data_time: 0.0097  memory: 4876  grad_norm: 136.5866  loss: 35.9070  decode.loss_cls: 1.4183  decode.loss_mask: 0.7218  decode.loss_dice: 1.1692  decode.d0.loss_cls: 2.9354  decode.d0.loss_mask: 0.7618  decode.d0.loss_dice: 1.4783  decode.d1.loss_cls: 1.5830  decode.d1.loss_mask: 0.7136  decode.d1.loss_dice: 1.3884  decode.d2.loss_cls: 1.5537  decode.d2.loss_mask: 0.6752  decode.d2.loss_dice: 1.2833  decode.d3.loss_cls: 1.4213  decode.d3.loss_mask: 0.7261  decode.d3.loss_dice: 1.2513  decode.d4.loss_cls: 1.4887  decode.d4.loss_mask: 0.7129  decode.d4.loss_dice: 1.2316  decode.d5.loss_cls: 1.4504  decode.d5.loss_mask: 0.7226  decode.d5.loss_dice: 1.2510  decode.d6.loss_cls: 1.4018  decode.d6.loss_mask: 0.7256  decode.d6.loss_dice: 1.2121  decode.d7.loss_cls: 1.3806  decode.d7.loss_mask: 0.7121  decode.d7.loss_dice: 1.2044  decode.d8.loss_cls: 1.4076  decode.d8.loss_mask: 0.7326  decode.d8.loss_dice: 1.1924
2023/05/23 23:23:29 - mmengine - INFO - Iter(train) [ 41600/160000]  lr: 7.6262e-06  eta: 14:03:07  time: 0.4176  data_time: 0.0100  memory: 4899  grad_norm: 92.7865  loss: 39.9061  decode.loss_cls: 1.2674  decode.loss_mask: 0.8729  decode.loss_dice: 1.4933  decode.d0.loss_cls: 3.3188  decode.d0.loss_mask: 0.8760  decode.d0.loss_dice: 1.7467  decode.d1.loss_cls: 1.5302  decode.d1.loss_mask: 0.8640  decode.d1.loss_dice: 1.6770  decode.d2.loss_cls: 1.2896  decode.d2.loss_mask: 0.9275  decode.d2.loss_dice: 1.6477  decode.d3.loss_cls: 1.2994  decode.d3.loss_mask: 0.8883  decode.d3.loss_dice: 1.5908  decode.d4.loss_cls: 1.3162  decode.d4.loss_mask: 0.8743  decode.d4.loss_dice: 1.5504  decode.d5.loss_cls: 1.3210  decode.d5.loss_mask: 0.8817  decode.d5.loss_dice: 1.5888  decode.d6.loss_cls: 1.3521  decode.d6.loss_mask: 0.8408  decode.d6.loss_dice: 1.5287  decode.d7.loss_cls: 1.3369  decode.d7.loss_mask: 0.8145  decode.d7.loss_dice: 1.5325  decode.d8.loss_cls: 1.3024  decode.d8.loss_mask: 0.8504  decode.d8.loss_dice: 1.5256
2023/05/23 23:23:50 - mmengine - INFO - Iter(train) [ 41650/160000]  lr: 7.6234e-06  eta: 14:02:44  time: 0.4221  data_time: 0.0100  memory: 4829  grad_norm: 115.8912  loss: 31.4055  decode.loss_cls: 1.0653  decode.loss_mask: 0.7675  decode.loss_dice: 0.9827  decode.d0.loss_cls: 3.1386  decode.d0.loss_mask: 0.8206  decode.d0.loss_dice: 1.2222  decode.d1.loss_cls: 1.3282  decode.d1.loss_mask: 0.8511  decode.d1.loss_dice: 1.1165  decode.d2.loss_cls: 1.1609  decode.d2.loss_mask: 0.7844  decode.d2.loss_dice: 1.0668  decode.d3.loss_cls: 1.1917  decode.d3.loss_mask: 0.7325  decode.d3.loss_dice: 0.9942  decode.d4.loss_cls: 1.2086  decode.d4.loss_mask: 0.7380  decode.d4.loss_dice: 0.9947  decode.d5.loss_cls: 1.1277  decode.d5.loss_mask: 0.7378  decode.d5.loss_dice: 0.9716  decode.d6.loss_cls: 1.0587  decode.d6.loss_mask: 0.7698  decode.d6.loss_dice: 0.9609  decode.d7.loss_cls: 1.0683  decode.d7.loss_mask: 0.7813  decode.d7.loss_dice: 0.9666  decode.d8.loss_cls: 1.0751  decode.d8.loss_mask: 0.7796  decode.d8.loss_dice: 0.9436
2023/05/23 23:24:11 - mmengine - INFO - Iter(train) [ 41700/160000]  lr: 7.6205e-06  eta: 14:02:22  time: 0.4535  data_time: 0.0100  memory: 4836  grad_norm: 112.3178  loss: 32.2777  decode.loss_cls: 1.2657  decode.loss_mask: 0.7580  decode.loss_dice: 0.9520  decode.d0.loss_cls: 3.1669  decode.d0.loss_mask: 0.7998  decode.d0.loss_dice: 1.1380  decode.d1.loss_cls: 1.3868  decode.d1.loss_mask: 0.7973  decode.d1.loss_dice: 1.0153  decode.d2.loss_cls: 1.3681  decode.d2.loss_mask: 0.7628  decode.d2.loss_dice: 0.9381  decode.d3.loss_cls: 1.3454  decode.d3.loss_mask: 0.7531  decode.d3.loss_dice: 0.9439  decode.d4.loss_cls: 1.2574  decode.d4.loss_mask: 0.7627  decode.d4.loss_dice: 0.9638  decode.d5.loss_cls: 1.3593  decode.d5.loss_mask: 0.7932  decode.d5.loss_dice: 0.9158  decode.d6.loss_cls: 1.2376  decode.d6.loss_mask: 0.8219  decode.d6.loss_dice: 0.9122  decode.d7.loss_cls: 1.2531  decode.d7.loss_mask: 0.7657  decode.d7.loss_dice: 0.9436  decode.d8.loss_cls: 1.2186  decode.d8.loss_mask: 0.7591  decode.d8.loss_dice: 0.9225
2023/05/23 23:24:32 - mmengine - INFO - Iter(train) [ 41750/160000]  lr: 7.6176e-06  eta: 14:01:59  time: 0.4220  data_time: 0.0102  memory: 4848  grad_norm: 99.5329  loss: 29.0620  decode.loss_cls: 1.1483  decode.loss_mask: 0.5799  decode.loss_dice: 0.9690  decode.d0.loss_cls: 2.7239  decode.d0.loss_mask: 0.6327  decode.d0.loss_dice: 1.1215  decode.d1.loss_cls: 1.2105  decode.d1.loss_mask: 0.6334  decode.d1.loss_dice: 1.0208  decode.d2.loss_cls: 1.1222  decode.d2.loss_mask: 0.6337  decode.d2.loss_dice: 1.0195  decode.d3.loss_cls: 1.1298  decode.d3.loss_mask: 0.6051  decode.d3.loss_dice: 0.9745  decode.d4.loss_cls: 1.0770  decode.d4.loss_mask: 0.6068  decode.d4.loss_dice: 0.9879  decode.d5.loss_cls: 1.1428  decode.d5.loss_mask: 0.5903  decode.d5.loss_dice: 0.9856  decode.d6.loss_cls: 1.1730  decode.d6.loss_mask: 0.6043  decode.d6.loss_dice: 0.9493  decode.d7.loss_cls: 1.1326  decode.d7.loss_mask: 0.6137  decode.d7.loss_dice: 0.9756  decode.d8.loss_cls: 1.1176  decode.d8.loss_mask: 0.5968  decode.d8.loss_dice: 0.9840
2023/05/23 23:24:53 - mmengine - INFO - Iter(train) [ 41800/160000]  lr: 7.6147e-06  eta: 14:01:37  time: 0.4213  data_time: 0.0104  memory: 4857  grad_norm: 90.8076  loss: 28.5176  decode.loss_cls: 0.9405  decode.loss_mask: 0.7106  decode.loss_dice: 0.9725  decode.d0.loss_cls: 2.6867  decode.d0.loss_mask: 0.7628  decode.d0.loss_dice: 1.1592  decode.d1.loss_cls: 0.9663  decode.d1.loss_mask: 0.7725  decode.d1.loss_dice: 0.9974  decode.d2.loss_cls: 0.9955  decode.d2.loss_mask: 0.7515  decode.d2.loss_dice: 0.9928  decode.d3.loss_cls: 0.9317  decode.d3.loss_mask: 0.7297  decode.d3.loss_dice: 0.9861  decode.d4.loss_cls: 0.9351  decode.d4.loss_mask: 0.7170  decode.d4.loss_dice: 0.9939  decode.d5.loss_cls: 0.9287  decode.d5.loss_mask: 0.7294  decode.d5.loss_dice: 0.9677  decode.d6.loss_cls: 0.9336  decode.d6.loss_mask: 0.7420  decode.d6.loss_dice: 0.9644  decode.d7.loss_cls: 0.9078  decode.d7.loss_mask: 0.7320  decode.d7.loss_dice: 0.9908  decode.d8.loss_cls: 0.9203  decode.d8.loss_mask: 0.7121  decode.d8.loss_dice: 0.9868
2023/05/23 23:25:14 - mmengine - INFO - Iter(train) [ 41850/160000]  lr: 7.6118e-06  eta: 14:01:15  time: 0.4297  data_time: 0.0098  memory: 4859  grad_norm: 84.2380  loss: 38.9543  decode.loss_cls: 1.3567  decode.loss_mask: 0.8919  decode.loss_dice: 1.4365  decode.d0.loss_cls: 3.1888  decode.d0.loss_mask: 0.9780  decode.d0.loss_dice: 1.5624  decode.d1.loss_cls: 1.4320  decode.d1.loss_mask: 0.9769  decode.d1.loss_dice: 1.5367  decode.d2.loss_cls: 1.4626  decode.d2.loss_mask: 0.8844  decode.d2.loss_dice: 1.4160  decode.d3.loss_cls: 1.3627  decode.d3.loss_mask: 0.8908  decode.d3.loss_dice: 1.4032  decode.d4.loss_cls: 1.3475  decode.d4.loss_mask: 0.8778  decode.d4.loss_dice: 1.4248  decode.d5.loss_cls: 1.3049  decode.d5.loss_mask: 0.8969  decode.d5.loss_dice: 1.4288  decode.d6.loss_cls: 1.3390  decode.d6.loss_mask: 0.8928  decode.d6.loss_dice: 1.4417  decode.d7.loss_cls: 1.3252  decode.d7.loss_mask: 0.8764  decode.d7.loss_dice: 1.4492  decode.d8.loss_cls: 1.3046  decode.d8.loss_mask: 0.8901  decode.d8.loss_dice: 1.3749
2023/05/23 23:25:35 - mmengine - INFO - Iter(train) [ 41900/160000]  lr: 7.6089e-06  eta: 14:00:52  time: 0.4257  data_time: 0.0098  memory: 4896  grad_norm: 92.5707  loss: 34.7599  decode.loss_cls: 1.2488  decode.loss_mask: 0.6748  decode.loss_dice: 1.2292  decode.d0.loss_cls: 3.2415  decode.d0.loss_mask: 0.7539  decode.d0.loss_dice: 1.4930  decode.d1.loss_cls: 1.4819  decode.d1.loss_mask: 0.7906  decode.d1.loss_dice: 1.3652  decode.d2.loss_cls: 1.3321  decode.d2.loss_mask: 0.6913  decode.d2.loss_dice: 1.2823  decode.d3.loss_cls: 1.3193  decode.d3.loss_mask: 0.6786  decode.d3.loss_dice: 1.2369  decode.d4.loss_cls: 1.3057  decode.d4.loss_mask: 0.6721  decode.d4.loss_dice: 1.2429  decode.d5.loss_cls: 1.2762  decode.d5.loss_mask: 0.6736  decode.d5.loss_dice: 1.2591  decode.d6.loss_cls: 1.2548  decode.d6.loss_mask: 0.6666  decode.d6.loss_dice: 1.2307  decode.d7.loss_cls: 1.2758  decode.d7.loss_mask: 0.6711  decode.d7.loss_dice: 1.2482  decode.d8.loss_cls: 1.2517  decode.d8.loss_mask: 0.6755  decode.d8.loss_dice: 1.2365
2023/05/23 23:25:58 - mmengine - INFO - Iter(train) [ 41950/160000]  lr: 7.6060e-06  eta: 14:00:36  time: 0.4669  data_time: 0.0100  memory: 4906  grad_norm: 93.7394  loss: 44.6911  decode.loss_cls: 1.7218  decode.loss_mask: 0.7902  decode.loss_dice: 1.6757  decode.d0.loss_cls: 3.6564  decode.d0.loss_mask: 0.8115  decode.d0.loss_dice: 1.9414  decode.d1.loss_cls: 1.8278  decode.d1.loss_mask: 0.8405  decode.d1.loss_dice: 1.8224  decode.d2.loss_cls: 1.8529  decode.d2.loss_mask: 0.7757  decode.d2.loss_dice: 1.7593  decode.d3.loss_cls: 1.6824  decode.d3.loss_mask: 0.7618  decode.d3.loss_dice: 1.7511  decode.d4.loss_cls: 1.6829  decode.d4.loss_mask: 0.7951  decode.d4.loss_dice: 1.7473  decode.d5.loss_cls: 1.7129  decode.d5.loss_mask: 0.7828  decode.d5.loss_dice: 1.7270  decode.d6.loss_cls: 1.7020  decode.d6.loss_mask: 0.7673  decode.d6.loss_dice: 1.7091  decode.d7.loss_cls: 1.6709  decode.d7.loss_mask: 0.7796  decode.d7.loss_dice: 1.7248  decode.d8.loss_cls: 1.7192  decode.d8.loss_mask: 0.7892  decode.d8.loss_dice: 1.7103
2023/05/23 23:26:20 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 23:26:20 - mmengine - INFO - Iter(train) [ 42000/160000]  lr: 7.6031e-06  eta: 14:00:17  time: 0.4672  data_time: 0.0104  memory: 4846  grad_norm: 93.0849  loss: 45.7058  decode.loss_cls: 1.6188  decode.loss_mask: 0.9436  decode.loss_dice: 1.6867  decode.d0.loss_cls: 3.5794  decode.d0.loss_mask: 1.0317  decode.d0.loss_dice: 1.8814  decode.d1.loss_cls: 1.8058  decode.d1.loss_mask: 0.9531  decode.d1.loss_dice: 1.7626  decode.d2.loss_cls: 1.7357  decode.d2.loss_mask: 0.9588  decode.d2.loss_dice: 1.7030  decode.d3.loss_cls: 1.7772  decode.d3.loss_mask: 0.9755  decode.d3.loss_dice: 1.7310  decode.d4.loss_cls: 1.7765  decode.d4.loss_mask: 0.9548  decode.d4.loss_dice: 1.7094  decode.d5.loss_cls: 1.7014  decode.d5.loss_mask: 0.9603  decode.d5.loss_dice: 1.6887  decode.d6.loss_cls: 1.7130  decode.d6.loss_mask: 0.9354  decode.d6.loss_dice: 1.6818  decode.d7.loss_cls: 1.6145  decode.d7.loss_mask: 0.9583  decode.d7.loss_dice: 1.6871  decode.d8.loss_cls: 1.6025  decode.d8.loss_mask: 0.9395  decode.d8.loss_dice: 1.6383
2023/05/23 23:26:20 - mmengine - INFO - Saving checkpoint at 42000 iterations
2023/05/23 23:26:47 - mmengine - INFO - Iter(train) [ 42050/160000]  lr: 7.6002e-06  eta: 14:00:10  time: 0.4218  data_time: 0.0100  memory: 4847  grad_norm: 87.2797  loss: 36.4987  decode.loss_cls: 1.2759  decode.loss_mask: 0.8016  decode.loss_dice: 1.2714  decode.d0.loss_cls: 3.2471  decode.d0.loss_mask: 0.8905  decode.d0.loss_dice: 1.4685  decode.d1.loss_cls: 1.5353  decode.d1.loss_mask: 0.8763  decode.d1.loss_dice: 1.3435  decode.d2.loss_cls: 1.4050  decode.d2.loss_mask: 0.8176  decode.d2.loss_dice: 1.3003  decode.d3.loss_cls: 1.3619  decode.d3.loss_mask: 0.7953  decode.d3.loss_dice: 1.2563  decode.d4.loss_cls: 1.3167  decode.d4.loss_mask: 0.7962  decode.d4.loss_dice: 1.2656  decode.d5.loss_cls: 1.3106  decode.d5.loss_mask: 0.8279  decode.d5.loss_dice: 1.2609  decode.d6.loss_cls: 1.3130  decode.d6.loss_mask: 0.8106  decode.d6.loss_dice: 1.2566  decode.d7.loss_cls: 1.2794  decode.d7.loss_mask: 0.8120  decode.d7.loss_dice: 1.2701  decode.d8.loss_cls: 1.2144  decode.d8.loss_mask: 0.8155  decode.d8.loss_dice: 1.3026
2023/05/23 23:27:08 - mmengine - INFO - Iter(train) [ 42100/160000]  lr: 7.5973e-06  eta: 13:59:47  time: 0.4193  data_time: 0.0100  memory: 4823  grad_norm: 90.9292  loss: 37.2798  decode.loss_cls: 1.2178  decode.loss_mask: 0.8638  decode.loss_dice: 1.3782  decode.d0.loss_cls: 3.0811  decode.d0.loss_mask: 0.9826  decode.d0.loss_dice: 1.5948  decode.d1.loss_cls: 1.3501  decode.d1.loss_mask: 0.9356  decode.d1.loss_dice: 1.5158  decode.d2.loss_cls: 1.2651  decode.d2.loss_mask: 0.8869  decode.d2.loss_dice: 1.4344  decode.d3.loss_cls: 1.2202  decode.d3.loss_mask: 0.8934  decode.d3.loss_dice: 1.4009  decode.d4.loss_cls: 1.1561  decode.d4.loss_mask: 0.9022  decode.d4.loss_dice: 1.3930  decode.d5.loss_cls: 1.1593  decode.d5.loss_mask: 0.8796  decode.d5.loss_dice: 1.3939  decode.d6.loss_cls: 1.1793  decode.d6.loss_mask: 0.8580  decode.d6.loss_dice: 1.3928  decode.d7.loss_cls: 1.1627  decode.d7.loss_mask: 0.9277  decode.d7.loss_dice: 1.4051  decode.d8.loss_cls: 1.1874  decode.d8.loss_mask: 0.8706  decode.d8.loss_dice: 1.3913
2023/05/23 23:27:29 - mmengine - INFO - Iter(train) [ 42150/160000]  lr: 7.5944e-06  eta: 13:59:25  time: 0.4298  data_time: 0.0101  memory: 4947  grad_norm: 89.1496  loss: 37.0807  decode.loss_cls: 1.1726  decode.loss_mask: 0.7539  decode.loss_dice: 1.4641  decode.d0.loss_cls: 3.2188  decode.d0.loss_mask: 0.8411  decode.d0.loss_dice: 1.6342  decode.d1.loss_cls: 1.3364  decode.d1.loss_mask: 0.8826  decode.d1.loss_dice: 1.5470  decode.d2.loss_cls: 1.2062  decode.d2.loss_mask: 0.8116  decode.d2.loss_dice: 1.5258  decode.d3.loss_cls: 1.2155  decode.d3.loss_mask: 0.8035  decode.d3.loss_dice: 1.4699  decode.d4.loss_cls: 1.2627  decode.d4.loss_mask: 0.7394  decode.d4.loss_dice: 1.4631  decode.d5.loss_cls: 1.1952  decode.d5.loss_mask: 0.7416  decode.d5.loss_dice: 1.4754  decode.d6.loss_cls: 1.3025  decode.d6.loss_mask: 0.7397  decode.d6.loss_dice: 1.4293  decode.d7.loss_cls: 1.2441  decode.d7.loss_mask: 0.7445  decode.d7.loss_dice: 1.4500  decode.d8.loss_cls: 1.2028  decode.d8.loss_mask: 0.7591  decode.d8.loss_dice: 1.4482
2023/05/23 23:27:50 - mmengine - INFO - Iter(train) [ 42200/160000]  lr: 7.5915e-06  eta: 13:59:02  time: 0.4177  data_time: 0.0101  memory: 4920  grad_norm: 91.9024  loss: 38.8600  decode.loss_cls: 1.3537  decode.loss_mask: 0.9176  decode.loss_dice: 1.3608  decode.d0.loss_cls: 3.1913  decode.d0.loss_mask: 0.9874  decode.d0.loss_dice: 1.5687  decode.d1.loss_cls: 1.3891  decode.d1.loss_mask: 1.0062  decode.d1.loss_dice: 1.4811  decode.d2.loss_cls: 1.2768  decode.d2.loss_mask: 1.0181  decode.d2.loss_dice: 1.4709  decode.d3.loss_cls: 1.2955  decode.d3.loss_mask: 0.9393  decode.d3.loss_dice: 1.4323  decode.d4.loss_cls: 1.2515  decode.d4.loss_mask: 0.9363  decode.d4.loss_dice: 1.3704  decode.d5.loss_cls: 1.3528  decode.d5.loss_mask: 0.9308  decode.d5.loss_dice: 1.3551  decode.d6.loss_cls: 1.3748  decode.d6.loss_mask: 0.9186  decode.d6.loss_dice: 1.3464  decode.d7.loss_cls: 1.3820  decode.d7.loss_mask: 0.9159  decode.d7.loss_dice: 1.3763  decode.d8.loss_cls: 1.4001  decode.d8.loss_mask: 0.9160  decode.d8.loss_dice: 1.3442
2023/05/23 23:28:11 - mmengine - INFO - Iter(train) [ 42250/160000]  lr: 7.5886e-06  eta: 13:58:39  time: 0.4229  data_time: 0.0099  memory: 4878  grad_norm: 96.5564  loss: 35.3210  decode.loss_cls: 1.4573  decode.loss_mask: 0.7554  decode.loss_dice: 1.1059  decode.d0.loss_cls: 3.3824  decode.d0.loss_mask: 0.8058  decode.d0.loss_dice: 1.2807  decode.d1.loss_cls: 1.6418  decode.d1.loss_mask: 0.7790  decode.d1.loss_dice: 1.1689  decode.d2.loss_cls: 1.4936  decode.d2.loss_mask: 0.7743  decode.d2.loss_dice: 1.1234  decode.d3.loss_cls: 1.4609  decode.d3.loss_mask: 0.7229  decode.d3.loss_dice: 1.0864  decode.d4.loss_cls: 1.4125  decode.d4.loss_mask: 0.7401  decode.d4.loss_dice: 1.0910  decode.d5.loss_cls: 1.4417  decode.d5.loss_mask: 0.7373  decode.d5.loss_dice: 1.0934  decode.d6.loss_cls: 1.4914  decode.d6.loss_mask: 0.7122  decode.d6.loss_dice: 1.0466  decode.d7.loss_cls: 1.5333  decode.d7.loss_mask: 0.7115  decode.d7.loss_dice: 1.0217  decode.d8.loss_cls: 1.4391  decode.d8.loss_mask: 0.7365  decode.d8.loss_dice: 1.0743
2023/05/23 23:28:31 - mmengine - INFO - Iter(train) [ 42300/160000]  lr: 7.5857e-06  eta: 13:58:15  time: 0.4049  data_time: 0.0099  memory: 4952  grad_norm: 112.0586  loss: 38.9671  decode.loss_cls: 1.3731  decode.loss_mask: 0.9452  decode.loss_dice: 1.3968  decode.d0.loss_cls: 3.0510  decode.d0.loss_mask: 0.9736  decode.d0.loss_dice: 1.5805  decode.d1.loss_cls: 1.5218  decode.d1.loss_mask: 0.9224  decode.d1.loss_dice: 1.4682  decode.d2.loss_cls: 1.3990  decode.d2.loss_mask: 0.9317  decode.d2.loss_dice: 1.3974  decode.d3.loss_cls: 1.2960  decode.d3.loss_mask: 0.9220  decode.d3.loss_dice: 1.3875  decode.d4.loss_cls: 1.2953  decode.d4.loss_mask: 0.9518  decode.d4.loss_dice: 1.4169  decode.d5.loss_cls: 1.3196  decode.d5.loss_mask: 0.9430  decode.d5.loss_dice: 1.4089  decode.d6.loss_cls: 1.3582  decode.d6.loss_mask: 0.9260  decode.d6.loss_dice: 1.3747  decode.d7.loss_cls: 1.3405  decode.d7.loss_mask: 0.9335  decode.d7.loss_dice: 1.4209  decode.d8.loss_cls: 1.3717  decode.d8.loss_mask: 0.9425  decode.d8.loss_dice: 1.3977
2023/05/23 23:28:52 - mmengine - INFO - Iter(train) [ 42350/160000]  lr: 7.5828e-06  eta: 13:57:52  time: 0.4187  data_time: 0.0098  memory: 4917  grad_norm: 84.4086  loss: 39.1816  decode.loss_cls: 1.3979  decode.loss_mask: 0.7412  decode.loss_dice: 1.4833  decode.d0.loss_cls: 3.1079  decode.d0.loss_mask: 0.8472  decode.d0.loss_dice: 1.7967  decode.d1.loss_cls: 1.5108  decode.d1.loss_mask: 0.8082  decode.d1.loss_dice: 1.7057  decode.d2.loss_cls: 1.3713  decode.d2.loss_mask: 0.7817  decode.d2.loss_dice: 1.6332  decode.d3.loss_cls: 1.3386  decode.d3.loss_mask: 0.7871  decode.d3.loss_dice: 1.5850  decode.d4.loss_cls: 1.2949  decode.d4.loss_mask: 0.7848  decode.d4.loss_dice: 1.5953  decode.d5.loss_cls: 1.3228  decode.d5.loss_mask: 0.7744  decode.d5.loss_dice: 1.5628  decode.d6.loss_cls: 1.3082  decode.d6.loss_mask: 0.7859  decode.d6.loss_dice: 1.5518  decode.d7.loss_cls: 1.3640  decode.d7.loss_mask: 0.7706  decode.d7.loss_dice: 1.5589  decode.d8.loss_cls: 1.2917  decode.d8.loss_mask: 0.7737  decode.d8.loss_dice: 1.5459
2023/05/23 23:29:14 - mmengine - INFO - Iter(train) [ 42400/160000]  lr: 7.5799e-06  eta: 13:57:33  time: 0.4244  data_time: 0.0097  memory: 4804  grad_norm: 131.9500  loss: 41.3653  decode.loss_cls: 1.3439  decode.loss_mask: 0.8066  decode.loss_dice: 1.7133  decode.d0.loss_cls: 3.2643  decode.d0.loss_mask: 0.7835  decode.d0.loss_dice: 1.8755  decode.d1.loss_cls: 1.7038  decode.d1.loss_mask: 0.7725  decode.d1.loss_dice: 1.7727  decode.d2.loss_cls: 1.5739  decode.d2.loss_mask: 0.7724  decode.d2.loss_dice: 1.7548  decode.d3.loss_cls: 1.4538  decode.d3.loss_mask: 0.8111  decode.d3.loss_dice: 1.7114  decode.d4.loss_cls: 1.4044  decode.d4.loss_mask: 0.7971  decode.d4.loss_dice: 1.6971  decode.d5.loss_cls: 1.3843  decode.d5.loss_mask: 0.7934  decode.d5.loss_dice: 1.6561  decode.d6.loss_cls: 1.4823  decode.d6.loss_mask: 0.7637  decode.d6.loss_dice: 1.6384  decode.d7.loss_cls: 1.4011  decode.d7.loss_mask: 0.7700  decode.d7.loss_dice: 1.6282  decode.d8.loss_cls: 1.4019  decode.d8.loss_mask: 0.7782  decode.d8.loss_dice: 1.6554
2023/05/23 23:29:35 - mmengine - INFO - Iter(train) [ 42450/160000]  lr: 7.5770e-06  eta: 13:57:11  time: 0.4097  data_time: 0.0099  memory: 4876  grad_norm: 88.2663  loss: 30.0389  decode.loss_cls: 0.9309  decode.loss_mask: 0.7675  decode.loss_dice: 1.0493  decode.d0.loss_cls: 2.9997  decode.d0.loss_mask: 0.7645  decode.d0.loss_dice: 1.1750  decode.d1.loss_cls: 1.1104  decode.d1.loss_mask: 0.7712  decode.d1.loss_dice: 1.0689  decode.d2.loss_cls: 0.9670  decode.d2.loss_mask: 0.7444  decode.d2.loss_dice: 1.0770  decode.d3.loss_cls: 0.9905  decode.d3.loss_mask: 0.7676  decode.d3.loss_dice: 1.0342  decode.d4.loss_cls: 0.9487  decode.d4.loss_mask: 0.7487  decode.d4.loss_dice: 1.0466  decode.d5.loss_cls: 0.9680  decode.d5.loss_mask: 0.7738  decode.d5.loss_dice: 1.0363  decode.d6.loss_cls: 0.9511  decode.d6.loss_mask: 0.7440  decode.d6.loss_dice: 1.0789  decode.d7.loss_cls: 0.9823  decode.d7.loss_mask: 0.7439  decode.d7.loss_dice: 1.0370  decode.d8.loss_cls: 0.9303  decode.d8.loss_mask: 0.7728  decode.d8.loss_dice: 1.0584
2023/05/23 23:29:56 - mmengine - INFO - Iter(train) [ 42500/160000]  lr: 7.5741e-06  eta: 13:56:49  time: 0.4421  data_time: 0.0109  memory: 4928  grad_norm: 94.2132  loss: 43.1295  decode.loss_cls: 1.5667  decode.loss_mask: 0.8312  decode.loss_dice: 1.6194  decode.d0.loss_cls: 3.5779  decode.d0.loss_mask: 0.8667  decode.d0.loss_dice: 1.7962  decode.d1.loss_cls: 1.7405  decode.d1.loss_mask: 0.8360  decode.d1.loss_dice: 1.7121  decode.d2.loss_cls: 1.7109  decode.d2.loss_mask: 0.8588  decode.d2.loss_dice: 1.6802  decode.d3.loss_cls: 1.5746  decode.d3.loss_mask: 0.8717  decode.d3.loss_dice: 1.6492  decode.d4.loss_cls: 1.5538  decode.d4.loss_mask: 0.8765  decode.d4.loss_dice: 1.6475  decode.d5.loss_cls: 1.5509  decode.d5.loss_mask: 0.8552  decode.d5.loss_dice: 1.6230  decode.d6.loss_cls: 1.6605  decode.d6.loss_mask: 0.8130  decode.d6.loss_dice: 1.5926  decode.d7.loss_cls: 1.5977  decode.d7.loss_mask: 0.8248  decode.d7.loss_dice: 1.6478  decode.d8.loss_cls: 1.5809  decode.d8.loss_mask: 0.8055  decode.d8.loss_dice: 1.6078
2023/05/23 23:30:17 - mmengine - INFO - Iter(train) [ 42550/160000]  lr: 7.5712e-06  eta: 13:56:26  time: 0.4106  data_time: 0.0102  memory: 4882  grad_norm: 92.6324  loss: 31.1927  decode.loss_cls: 1.1144  decode.loss_mask: 0.7875  decode.loss_dice: 0.9255  decode.d0.loss_cls: 3.2742  decode.d0.loss_mask: 0.7638  decode.d0.loss_dice: 1.0297  decode.d1.loss_cls: 1.2517  decode.d1.loss_mask: 0.8171  decode.d1.loss_dice: 1.0532  decode.d2.loss_cls: 1.2562  decode.d2.loss_mask: 0.7916  decode.d2.loss_dice: 0.9668  decode.d3.loss_cls: 1.2308  decode.d3.loss_mask: 0.7769  decode.d3.loss_dice: 0.9321  decode.d4.loss_cls: 1.1989  decode.d4.loss_mask: 0.7735  decode.d4.loss_dice: 0.9392  decode.d5.loss_cls: 1.1372  decode.d5.loss_mask: 0.7940  decode.d5.loss_dice: 0.9105  decode.d6.loss_cls: 1.1047  decode.d6.loss_mask: 0.8093  decode.d6.loss_dice: 0.9526  decode.d7.loss_cls: 1.1115  decode.d7.loss_mask: 0.7814  decode.d7.loss_dice: 0.9332  decode.d8.loss_cls: 1.0790  decode.d8.loss_mask: 0.7808  decode.d8.loss_dice: 0.9155
2023/05/23 23:30:38 - mmengine - INFO - Iter(train) [ 42600/160000]  lr: 7.5683e-06  eta: 13:56:02  time: 0.4031  data_time: 0.0096  memory: 4908  grad_norm: 84.8931  loss: 47.5477  decode.loss_cls: 1.4372  decode.loss_mask: 1.0334  decode.loss_dice: 1.8850  decode.d0.loss_cls: 3.5750  decode.d0.loss_mask: 1.1083  decode.d0.loss_dice: 2.2295  decode.d1.loss_cls: 1.7377  decode.d1.loss_mask: 1.0239  decode.d1.loss_dice: 2.1538  decode.d2.loss_cls: 1.5549  decode.d2.loss_mask: 1.0665  decode.d2.loss_dice: 2.0600  decode.d3.loss_cls: 1.5754  decode.d3.loss_mask: 1.0342  decode.d3.loss_dice: 1.9526  decode.d4.loss_cls: 1.5133  decode.d4.loss_mask: 1.0478  decode.d4.loss_dice: 1.9546  decode.d5.loss_cls: 1.5141  decode.d5.loss_mask: 1.0115  decode.d5.loss_dice: 1.9493  decode.d6.loss_cls: 1.4664  decode.d6.loss_mask: 1.0097  decode.d6.loss_dice: 1.9166  decode.d7.loss_cls: 1.4617  decode.d7.loss_mask: 1.0029  decode.d7.loss_dice: 1.9057  decode.d8.loss_cls: 1.4343  decode.d8.loss_mask: 1.0256  decode.d8.loss_dice: 1.9069
2023/05/23 23:30:58 - mmengine - INFO - Iter(train) [ 42650/160000]  lr: 7.5654e-06  eta: 13:55:39  time: 0.4109  data_time: 0.0099  memory: 4885  grad_norm: 93.2463  loss: 39.8320  decode.loss_cls: 1.3553  decode.loss_mask: 0.9541  decode.loss_dice: 1.3618  decode.d0.loss_cls: 3.3347  decode.d0.loss_mask: 1.0426  decode.d0.loss_dice: 1.5750  decode.d1.loss_cls: 1.5402  decode.d1.loss_mask: 1.0294  decode.d1.loss_dice: 1.5146  decode.d2.loss_cls: 1.4071  decode.d2.loss_mask: 0.9945  decode.d2.loss_dice: 1.4218  decode.d3.loss_cls: 1.3800  decode.d3.loss_mask: 1.0056  decode.d3.loss_dice: 1.3914  decode.d4.loss_cls: 1.3957  decode.d4.loss_mask: 0.9876  decode.d4.loss_dice: 1.4019  decode.d5.loss_cls: 1.3555  decode.d5.loss_mask: 0.9648  decode.d5.loss_dice: 1.4119  decode.d6.loss_cls: 1.3247  decode.d6.loss_mask: 0.9482  decode.d6.loss_dice: 1.3856  decode.d7.loss_cls: 1.3313  decode.d7.loss_mask: 0.9594  decode.d7.loss_dice: 1.3815  decode.d8.loss_cls: 1.3775  decode.d8.loss_mask: 0.9471  decode.d8.loss_dice: 1.3510
2023/05/23 23:31:19 - mmengine - INFO - Iter(train) [ 42700/160000]  lr: 7.5625e-06  eta: 13:55:15  time: 0.4091  data_time: 0.0099  memory: 4822  grad_norm: 108.9124  loss: 38.1795  decode.loss_cls: 1.3388  decode.loss_mask: 0.9675  decode.loss_dice: 1.2836  decode.d0.loss_cls: 3.2065  decode.d0.loss_mask: 0.8858  decode.d0.loss_dice: 1.4491  decode.d1.loss_cls: 1.5212  decode.d1.loss_mask: 0.9150  decode.d1.loss_dice: 1.3989  decode.d2.loss_cls: 1.4391  decode.d2.loss_mask: 0.9003  decode.d2.loss_dice: 1.3519  decode.d3.loss_cls: 1.3643  decode.d3.loss_mask: 0.9182  decode.d3.loss_dice: 1.3358  decode.d4.loss_cls: 1.3399  decode.d4.loss_mask: 0.8995  decode.d4.loss_dice: 1.2896  decode.d5.loss_cls: 1.3242  decode.d5.loss_mask: 0.9139  decode.d5.loss_dice: 1.3141  decode.d6.loss_cls: 1.3826  decode.d6.loss_mask: 0.9007  decode.d6.loss_dice: 1.3105  decode.d7.loss_cls: 1.3800  decode.d7.loss_mask: 0.9398  decode.d7.loss_dice: 1.2771  decode.d8.loss_cls: 1.4191  decode.d8.loss_mask: 0.9361  decode.d8.loss_dice: 1.2766
2023/05/23 23:31:42 - mmengine - INFO - Iter(train) [ 42750/160000]  lr: 7.5596e-06  eta: 13:54:59  time: 0.4701  data_time: 0.0094  memory: 4867  grad_norm: 125.7425  loss: 38.4777  decode.loss_cls: 1.4577  decode.loss_mask: 0.6816  decode.loss_dice: 1.4527  decode.d0.loss_cls: 3.1163  decode.d0.loss_mask: 0.7021  decode.d0.loss_dice: 1.5779  decode.d1.loss_cls: 1.6341  decode.d1.loss_mask: 0.7379  decode.d1.loss_dice: 1.5357  decode.d2.loss_cls: 1.5779  decode.d2.loss_mask: 0.7113  decode.d2.loss_dice: 1.4533  decode.d3.loss_cls: 1.5287  decode.d3.loss_mask: 0.6846  decode.d3.loss_dice: 1.4356  decode.d4.loss_cls: 1.5179  decode.d4.loss_mask: 0.6836  decode.d4.loss_dice: 1.4705  decode.d5.loss_cls: 1.4484  decode.d5.loss_mask: 0.6930  decode.d5.loss_dice: 1.4879  decode.d6.loss_cls: 1.5004  decode.d6.loss_mask: 0.6802  decode.d6.loss_dice: 1.4440  decode.d7.loss_cls: 1.4973  decode.d7.loss_mask: 0.6948  decode.d7.loss_dice: 1.4154  decode.d8.loss_cls: 1.5179  decode.d8.loss_mask: 0.6934  decode.d8.loss_dice: 1.4456
2023/05/23 23:32:04 - mmengine - INFO - Iter(train) [ 42800/160000]  lr: 7.5567e-06  eta: 13:54:39  time: 0.4317  data_time: 0.0099  memory: 4827  grad_norm: 116.0089  loss: 35.1298  decode.loss_cls: 1.4870  decode.loss_mask: 0.7114  decode.loss_dice: 1.0452  decode.d0.loss_cls: 3.2563  decode.d0.loss_mask: 0.8064  decode.d0.loss_dice: 1.2562  decode.d1.loss_cls: 1.6957  decode.d1.loss_mask: 0.7296  decode.d1.loss_dice: 1.1670  decode.d2.loss_cls: 1.5433  decode.d2.loss_mask: 0.7457  decode.d2.loss_dice: 1.1824  decode.d3.loss_cls: 1.5079  decode.d3.loss_mask: 0.7046  decode.d3.loss_dice: 1.0664  decode.d4.loss_cls: 1.4593  decode.d4.loss_mask: 0.6998  decode.d4.loss_dice: 1.0469  decode.d5.loss_cls: 1.4439  decode.d5.loss_mask: 0.7178  decode.d5.loss_dice: 1.0410  decode.d6.loss_cls: 1.4926  decode.d6.loss_mask: 0.7540  decode.d6.loss_dice: 1.0726  decode.d7.loss_cls: 1.4057  decode.d7.loss_mask: 0.7449  decode.d7.loss_dice: 1.0962  decode.d8.loss_cls: 1.4527  decode.d8.loss_mask: 0.7274  decode.d8.loss_dice: 1.0699
2023/05/23 23:32:26 - mmengine - INFO - Iter(train) [ 42850/160000]  lr: 7.5537e-06  eta: 13:54:19  time: 0.4124  data_time: 0.0099  memory: 4865  grad_norm: 95.8383  loss: 44.2137  decode.loss_cls: 1.6937  decode.loss_mask: 0.8995  decode.loss_dice: 1.5561  decode.d0.loss_cls: 3.6577  decode.d0.loss_mask: 1.0066  decode.d0.loss_dice: 1.7839  decode.d1.loss_cls: 1.9087  decode.d1.loss_mask: 0.9536  decode.d1.loss_dice: 1.6794  decode.d2.loss_cls: 1.7779  decode.d2.loss_mask: 0.9228  decode.d2.loss_dice: 1.6534  decode.d3.loss_cls: 1.7341  decode.d3.loss_mask: 0.8877  decode.d3.loss_dice: 1.5866  decode.d4.loss_cls: 1.7177  decode.d4.loss_mask: 0.8876  decode.d4.loss_dice: 1.5738  decode.d5.loss_cls: 1.6836  decode.d5.loss_mask: 0.8635  decode.d5.loss_dice: 1.5479  decode.d6.loss_cls: 1.6474  decode.d6.loss_mask: 0.8554  decode.d6.loss_dice: 1.5446  decode.d7.loss_cls: 1.6532  decode.d7.loss_mask: 0.8674  decode.d7.loss_dice: 1.5688  decode.d8.loss_cls: 1.6790  decode.d8.loss_mask: 0.8572  decode.d8.loss_dice: 1.5650
2023/05/23 23:32:46 - mmengine - INFO - Iter(train) [ 42900/160000]  lr: 7.5508e-06  eta: 13:53:55  time: 0.4121  data_time: 0.0098  memory: 4927  grad_norm: 112.6228  loss: 36.6913  decode.loss_cls: 1.2753  decode.loss_mask: 0.7718  decode.loss_dice: 1.3381  decode.d0.loss_cls: 3.0372  decode.d0.loss_mask: 0.9131  decode.d0.loss_dice: 1.5462  decode.d1.loss_cls: 1.3693  decode.d1.loss_mask: 0.8094  decode.d1.loss_dice: 1.3813  decode.d2.loss_cls: 1.2513  decode.d2.loss_mask: 0.8364  decode.d2.loss_dice: 1.4103  decode.d3.loss_cls: 1.2905  decode.d3.loss_mask: 0.7957  decode.d3.loss_dice: 1.4067  decode.d4.loss_cls: 1.2673  decode.d4.loss_mask: 0.8020  decode.d4.loss_dice: 1.4068  decode.d5.loss_cls: 1.2655  decode.d5.loss_mask: 0.7865  decode.d5.loss_dice: 1.4025  decode.d6.loss_cls: 1.3386  decode.d6.loss_mask: 0.7672  decode.d6.loss_dice: 1.3535  decode.d7.loss_cls: 1.2736  decode.d7.loss_mask: 0.7907  decode.d7.loss_dice: 1.3911  decode.d8.loss_cls: 1.2996  decode.d8.loss_mask: 0.7794  decode.d8.loss_dice: 1.3343
2023/05/23 23:33:07 - mmengine - INFO - Iter(train) [ 42950/160000]  lr: 7.5479e-06  eta: 13:53:32  time: 0.4067  data_time: 0.0097  memory: 4886  grad_norm: 136.6706  loss: 26.3977  decode.loss_cls: 1.0025  decode.loss_mask: 0.5520  decode.loss_dice: 0.7827  decode.d0.loss_cls: 2.7494  decode.d0.loss_mask: 0.5945  decode.d0.loss_dice: 1.0006  decode.d1.loss_cls: 1.1481  decode.d1.loss_mask: 0.6118  decode.d1.loss_dice: 0.9219  decode.d2.loss_cls: 1.0567  decode.d2.loss_mask: 0.6046  decode.d2.loss_dice: 0.8839  decode.d3.loss_cls: 1.0006  decode.d3.loss_mask: 0.5639  decode.d3.loss_dice: 0.8460  decode.d4.loss_cls: 1.0607  decode.d4.loss_mask: 0.5829  decode.d4.loss_dice: 0.8568  decode.d5.loss_cls: 1.0147  decode.d5.loss_mask: 0.5844  decode.d5.loss_dice: 0.8729  decode.d6.loss_cls: 1.0446  decode.d6.loss_mask: 0.5937  decode.d6.loss_dice: 0.7951  decode.d7.loss_cls: 0.9894  decode.d7.loss_mask: 0.5587  decode.d7.loss_dice: 0.7994  decode.d8.loss_cls: 0.9775  decode.d8.loss_mask: 0.5572  decode.d8.loss_dice: 0.7905
2023/05/23 23:33:27 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 23:33:27 - mmengine - INFO - Iter(train) [ 43000/160000]  lr: 7.5450e-06  eta: 13:53:08  time: 0.4153  data_time: 0.0104  memory: 4821  grad_norm: 89.7040  loss: 44.3805  decode.loss_cls: 1.7021  decode.loss_mask: 0.8130  decode.loss_dice: 1.5787  decode.d0.loss_cls: 3.6249  decode.d0.loss_mask: 0.9213  decode.d0.loss_dice: 1.9134  decode.d1.loss_cls: 1.8594  decode.d1.loss_mask: 0.8778  decode.d1.loss_dice: 1.7556  decode.d2.loss_cls: 1.6929  decode.d2.loss_mask: 0.8875  decode.d2.loss_dice: 1.7533  decode.d3.loss_cls: 1.7423  decode.d3.loss_mask: 0.8361  decode.d3.loss_dice: 1.6639  decode.d4.loss_cls: 1.6895  decode.d4.loss_mask: 0.8332  decode.d4.loss_dice: 1.6231  decode.d5.loss_cls: 1.7219  decode.d5.loss_mask: 0.8078  decode.d5.loss_dice: 1.6438  decode.d6.loss_cls: 1.6702  decode.d6.loss_mask: 0.8566  decode.d6.loss_dice: 1.6223  decode.d7.loss_cls: 1.6358  decode.d7.loss_mask: 0.8763  decode.d7.loss_dice: 1.6532  decode.d8.loss_cls: 1.7217  decode.d8.loss_mask: 0.8519  decode.d8.loss_dice: 1.5509
2023/05/23 23:33:27 - mmengine - INFO - Saving checkpoint at 43000 iterations
2023/05/23 23:33:55 - mmengine - INFO - Iter(train) [ 43050/160000]  lr: 7.5421e-06  eta: 13:53:04  time: 0.4410  data_time: 0.0099  memory: 4829  grad_norm: 116.8446  loss: 31.5426  decode.loss_cls: 1.0914  decode.loss_mask: 0.6085  decode.loss_dice: 1.1646  decode.d0.loss_cls: 2.8281  decode.d0.loss_mask: 0.7146  decode.d0.loss_dice: 1.4457  decode.d1.loss_cls: 1.3054  decode.d1.loss_mask: 0.6958  decode.d1.loss_dice: 1.2840  decode.d2.loss_cls: 1.1439  decode.d2.loss_mask: 0.6625  decode.d2.loss_dice: 1.1928  decode.d3.loss_cls: 1.1138  decode.d3.loss_mask: 0.6580  decode.d3.loss_dice: 1.1863  decode.d4.loss_cls: 1.1200  decode.d4.loss_mask: 0.6440  decode.d4.loss_dice: 1.1797  decode.d5.loss_cls: 1.0483  decode.d5.loss_mask: 0.6751  decode.d5.loss_dice: 1.1645  decode.d6.loss_cls: 1.0169  decode.d6.loss_mask: 0.6458  decode.d6.loss_dice: 1.1921  decode.d7.loss_cls: 1.0458  decode.d7.loss_mask: 0.6520  decode.d7.loss_dice: 1.2010  decode.d8.loss_cls: 1.0753  decode.d8.loss_mask: 0.6143  decode.d8.loss_dice: 1.1721
2023/05/23 23:34:16 - mmengine - INFO - Iter(train) [ 43100/160000]  lr: 7.5392e-06  eta: 13:52:40  time: 0.4130  data_time: 0.0097  memory: 4816  grad_norm: 88.8854  loss: 38.5815  decode.loss_cls: 1.3592  decode.loss_mask: 0.8702  decode.loss_dice: 1.3328  decode.d0.loss_cls: 3.1965  decode.d0.loss_mask: 0.8854  decode.d0.loss_dice: 1.6445  decode.d1.loss_cls: 1.4854  decode.d1.loss_mask: 0.8507  decode.d1.loss_dice: 1.4327  decode.d2.loss_cls: 1.5015  decode.d2.loss_mask: 0.8365  decode.d2.loss_dice: 1.3699  decode.d3.loss_cls: 1.4558  decode.d3.loss_mask: 0.8882  decode.d3.loss_dice: 1.3584  decode.d4.loss_cls: 1.4781  decode.d4.loss_mask: 0.8454  decode.d4.loss_dice: 1.3385  decode.d5.loss_cls: 1.4446  decode.d5.loss_mask: 0.8563  decode.d5.loss_dice: 1.3373  decode.d6.loss_cls: 1.4030  decode.d6.loss_mask: 0.8447  decode.d6.loss_dice: 1.3545  decode.d7.loss_cls: 1.3995  decode.d7.loss_mask: 0.8724  decode.d7.loss_dice: 1.3576  decode.d8.loss_cls: 1.3966  decode.d8.loss_mask: 0.8383  decode.d8.loss_dice: 1.3469
2023/05/23 23:34:36 - mmengine - INFO - Iter(train) [ 43150/160000]  lr: 7.5363e-06  eta: 13:52:17  time: 0.4169  data_time: 0.0099  memory: 4865  grad_norm: 93.9401  loss: 37.6629  decode.loss_cls: 1.4654  decode.loss_mask: 0.8489  decode.loss_dice: 1.1525  decode.d0.loss_cls: 3.3308  decode.d0.loss_mask: 0.9636  decode.d0.loss_dice: 1.3644  decode.d1.loss_cls: 1.5421  decode.d1.loss_mask: 0.9656  decode.d1.loss_dice: 1.2717  decode.d2.loss_cls: 1.4962  decode.d2.loss_mask: 0.9090  decode.d2.loss_dice: 1.2364  decode.d3.loss_cls: 1.4989  decode.d3.loss_mask: 0.8854  decode.d3.loss_dice: 1.1857  decode.d4.loss_cls: 1.4784  decode.d4.loss_mask: 0.8754  decode.d4.loss_dice: 1.1971  decode.d5.loss_cls: 1.5364  decode.d5.loss_mask: 0.8645  decode.d5.loss_dice: 1.1160  decode.d6.loss_cls: 1.4904  decode.d6.loss_mask: 0.8632  decode.d6.loss_dice: 1.1774  decode.d7.loss_cls: 1.4251  decode.d7.loss_mask: 0.8840  decode.d7.loss_dice: 1.1719  decode.d8.loss_cls: 1.4441  decode.d8.loss_mask: 0.8453  decode.d8.loss_dice: 1.1773
2023/05/23 23:34:57 - mmengine - INFO - Iter(train) [ 43200/160000]  lr: 7.5334e-06  eta: 13:51:55  time: 0.4111  data_time: 0.0099  memory: 5041  grad_norm: 99.4897  loss: 30.6003  decode.loss_cls: 0.9783  decode.loss_mask: 0.7469  decode.loss_dice: 1.0892  decode.d0.loss_cls: 2.9279  decode.d0.loss_mask: 0.8159  decode.d0.loss_dice: 1.1608  decode.d1.loss_cls: 1.1260  decode.d1.loss_mask: 0.7488  decode.d1.loss_dice: 1.1230  decode.d2.loss_cls: 1.0485  decode.d2.loss_mask: 0.7668  decode.d2.loss_dice: 1.1028  decode.d3.loss_cls: 1.0382  decode.d3.loss_mask: 0.7573  decode.d3.loss_dice: 1.0706  decode.d4.loss_cls: 0.9695  decode.d4.loss_mask: 0.7896  decode.d4.loss_dice: 1.0815  decode.d5.loss_cls: 0.9558  decode.d5.loss_mask: 0.7791  decode.d5.loss_dice: 1.0871  decode.d6.loss_cls: 0.9274  decode.d6.loss_mask: 0.8077  decode.d6.loss_dice: 1.0858  decode.d7.loss_cls: 0.9453  decode.d7.loss_mask: 0.7723  decode.d7.loss_dice: 1.0966  decode.d8.loss_cls: 0.9783  decode.d8.loss_mask: 0.7490  decode.d8.loss_dice: 1.0743
2023/05/23 23:35:18 - mmengine - INFO - Iter(train) [ 43250/160000]  lr: 7.5305e-06  eta: 13:51:32  time: 0.4192  data_time: 0.0097  memory: 4846  grad_norm: 120.9784  loss: 43.7014  decode.loss_cls: 1.5610  decode.loss_mask: 0.8467  decode.loss_dice: 1.7330  decode.d0.loss_cls: 3.5453  decode.d0.loss_mask: 0.8363  decode.d0.loss_dice: 1.8633  decode.d1.loss_cls: 1.6427  decode.d1.loss_mask: 0.9354  decode.d1.loss_dice: 1.8665  decode.d2.loss_cls: 1.5646  decode.d2.loss_mask: 0.8856  decode.d2.loss_dice: 1.8258  decode.d3.loss_cls: 1.4284  decode.d3.loss_mask: 0.9192  decode.d3.loss_dice: 1.7790  decode.d4.loss_cls: 1.5182  decode.d4.loss_mask: 0.8847  decode.d4.loss_dice: 1.7575  decode.d5.loss_cls: 1.4822  decode.d5.loss_mask: 0.8389  decode.d5.loss_dice: 1.7649  decode.d6.loss_cls: 1.4883  decode.d6.loss_mask: 0.8550  decode.d6.loss_dice: 1.7316  decode.d7.loss_cls: 1.5337  decode.d7.loss_mask: 0.8323  decode.d7.loss_dice: 1.7403  decode.d8.loss_cls: 1.5060  decode.d8.loss_mask: 0.8285  decode.d8.loss_dice: 1.7063
2023/05/23 23:35:40 - mmengine - INFO - Iter(train) [ 43300/160000]  lr: 7.5276e-06  eta: 13:51:12  time: 0.4710  data_time: 0.0095  memory: 4860  grad_norm: 90.3571  loss: 34.7115  decode.loss_cls: 1.2421  decode.loss_mask: 0.7950  decode.loss_dice: 1.1277  decode.d0.loss_cls: 2.9588  decode.d0.loss_mask: 0.7803  decode.d0.loss_dice: 1.2988  decode.d1.loss_cls: 1.5379  decode.d1.loss_mask: 0.7949  decode.d1.loss_dice: 1.2259  decode.d2.loss_cls: 1.3802  decode.d2.loss_mask: 0.8162  decode.d2.loss_dice: 1.1871  decode.d3.loss_cls: 1.3367  decode.d3.loss_mask: 0.7966  decode.d3.loss_dice: 1.1707  decode.d4.loss_cls: 1.3224  decode.d4.loss_mask: 0.8277  decode.d4.loss_dice: 1.1337  decode.d5.loss_cls: 1.2982  decode.d5.loss_mask: 0.8301  decode.d5.loss_dice: 1.1523  decode.d6.loss_cls: 1.2825  decode.d6.loss_mask: 0.8032  decode.d6.loss_dice: 1.1651  decode.d7.loss_cls: 1.2860  decode.d7.loss_mask: 0.8013  decode.d7.loss_dice: 1.1547  decode.d8.loss_cls: 1.2736  decode.d8.loss_mask: 0.8030  decode.d8.loss_dice: 1.1288
2023/05/23 23:36:02 - mmengine - INFO - Iter(train) [ 43350/160000]  lr: 7.5247e-06  eta: 13:50:53  time: 0.4213  data_time: 0.0100  memory: 4887  grad_norm: 96.3151  loss: 43.0179  decode.loss_cls: 1.7322  decode.loss_mask: 0.7663  decode.loss_dice: 1.5363  decode.d0.loss_cls: 3.5109  decode.d0.loss_mask: 0.8351  decode.d0.loss_dice: 1.8106  decode.d1.loss_cls: 1.8346  decode.d1.loss_mask: 0.7948  decode.d1.loss_dice: 1.6129  decode.d2.loss_cls: 1.7275  decode.d2.loss_mask: 0.7959  decode.d2.loss_dice: 1.6610  decode.d3.loss_cls: 1.7291  decode.d3.loss_mask: 0.8121  decode.d3.loss_dice: 1.5602  decode.d4.loss_cls: 1.6791  decode.d4.loss_mask: 0.7946  decode.d4.loss_dice: 1.5642  decode.d5.loss_cls: 1.6893  decode.d5.loss_mask: 0.8209  decode.d5.loss_dice: 1.5835  decode.d6.loss_cls: 1.7132  decode.d6.loss_mask: 0.7979  decode.d6.loss_dice: 1.5539  decode.d7.loss_cls: 1.7073  decode.d7.loss_mask: 0.7970  decode.d7.loss_dice: 1.5821  decode.d8.loss_cls: 1.6790  decode.d8.loss_mask: 0.7854  decode.d8.loss_dice: 1.5511
2023/05/23 23:36:24 - mmengine - INFO - Iter(train) [ 43400/160000]  lr: 7.5218e-06  eta: 13:50:32  time: 0.4524  data_time: 0.0103  memory: 4910  grad_norm: 95.5552  loss: 48.4335  decode.loss_cls: 1.7869  decode.loss_mask: 0.9972  decode.loss_dice: 1.6628  decode.d0.loss_cls: 3.9251  decode.d0.loss_mask: 1.1050  decode.d0.loss_dice: 2.0412  decode.d1.loss_cls: 1.8973  decode.d1.loss_mask: 1.0612  decode.d1.loss_dice: 1.8468  decode.d2.loss_cls: 1.9101  decode.d2.loss_mask: 1.0805  decode.d2.loss_dice: 1.7911  decode.d3.loss_cls: 1.8798  decode.d3.loss_mask: 1.0201  decode.d3.loss_dice: 1.7545  decode.d4.loss_cls: 1.8141  decode.d4.loss_mask: 1.0175  decode.d4.loss_dice: 1.7448  decode.d5.loss_cls: 1.7864  decode.d5.loss_mask: 1.0096  decode.d5.loss_dice: 1.7231  decode.d6.loss_cls: 1.8026  decode.d6.loss_mask: 1.0071  decode.d6.loss_dice: 1.7288  decode.d7.loss_cls: 1.7933  decode.d7.loss_mask: 0.9813  decode.d7.loss_dice: 1.7223  decode.d8.loss_cls: 1.8066  decode.d8.loss_mask: 1.0062  decode.d8.loss_dice: 1.7302
2023/05/23 23:36:47 - mmengine - INFO - Iter(train) [ 43450/160000]  lr: 7.5189e-06  eta: 13:50:16  time: 0.4683  data_time: 0.0095  memory: 4997  grad_norm: 103.0090  loss: 41.2746  decode.loss_cls: 1.3577  decode.loss_mask: 0.9353  decode.loss_dice: 1.6208  decode.d0.loss_cls: 3.4199  decode.d0.loss_mask: 0.8474  decode.d0.loss_dice: 1.7768  decode.d1.loss_cls: 1.5674  decode.d1.loss_mask: 0.8930  decode.d1.loss_dice: 1.7255  decode.d2.loss_cls: 1.4384  decode.d2.loss_mask: 0.9006  decode.d2.loss_dice: 1.6435  decode.d3.loss_cls: 1.3241  decode.d3.loss_mask: 0.8974  decode.d3.loss_dice: 1.6387  decode.d4.loss_cls: 1.3918  decode.d4.loss_mask: 0.9139  decode.d4.loss_dice: 1.6149  decode.d5.loss_cls: 1.3322  decode.d5.loss_mask: 0.9129  decode.d5.loss_dice: 1.6472  decode.d6.loss_cls: 1.3170  decode.d6.loss_mask: 0.9051  decode.d6.loss_dice: 1.6324  decode.d7.loss_cls: 1.3292  decode.d7.loss_mask: 0.8923  decode.d7.loss_dice: 1.5826  decode.d8.loss_cls: 1.2800  decode.d8.loss_mask: 0.9094  decode.d8.loss_dice: 1.6270
2023/05/23 23:37:09 - mmengine - INFO - Iter(train) [ 43500/160000]  lr: 7.5160e-06  eta: 13:49:56  time: 0.4477  data_time: 0.0102  memory: 4840  grad_norm: 95.8515  loss: 40.1436  decode.loss_cls: 1.5243  decode.loss_mask: 0.8583  decode.loss_dice: 1.3118  decode.d0.loss_cls: 3.5357  decode.d0.loss_mask: 0.9472  decode.d0.loss_dice: 1.6035  decode.d1.loss_cls: 1.6676  decode.d1.loss_mask: 0.9378  decode.d1.loss_dice: 1.5026  decode.d2.loss_cls: 1.5725  decode.d2.loss_mask: 0.9233  decode.d2.loss_dice: 1.4585  decode.d3.loss_cls: 1.5630  decode.d3.loss_mask: 0.8862  decode.d3.loss_dice: 1.3724  decode.d4.loss_cls: 1.5367  decode.d4.loss_mask: 0.8885  decode.d4.loss_dice: 1.3641  decode.d5.loss_cls: 1.4863  decode.d5.loss_mask: 0.8633  decode.d5.loss_dice: 1.3015  decode.d6.loss_cls: 1.5388  decode.d6.loss_mask: 0.8562  decode.d6.loss_dice: 1.2885  decode.d7.loss_cls: 1.5243  decode.d7.loss_mask: 0.8559  decode.d7.loss_dice: 1.3089  decode.d8.loss_cls: 1.5227  decode.d8.loss_mask: 0.8438  decode.d8.loss_dice: 1.2994
2023/05/23 23:37:30 - mmengine - INFO - Iter(train) [ 43550/160000]  lr: 7.5131e-06  eta: 13:49:34  time: 0.4241  data_time: 0.0100  memory: 4831  grad_norm: 110.1309  loss: 39.9989  decode.loss_cls: 1.3548  decode.loss_mask: 0.8915  decode.loss_dice: 1.4536  decode.d0.loss_cls: 3.3033  decode.d0.loss_mask: 0.9323  decode.d0.loss_dice: 1.6358  decode.d1.loss_cls: 1.4588  decode.d1.loss_mask: 0.9359  decode.d1.loss_dice: 1.5868  decode.d2.loss_cls: 1.5008  decode.d2.loss_mask: 0.9044  decode.d2.loss_dice: 1.4995  decode.d3.loss_cls: 1.4590  decode.d3.loss_mask: 0.8990  decode.d3.loss_dice: 1.4843  decode.d4.loss_cls: 1.3703  decode.d4.loss_mask: 0.9165  decode.d4.loss_dice: 1.5061  decode.d5.loss_cls: 1.3703  decode.d5.loss_mask: 0.8842  decode.d5.loss_dice: 1.4677  decode.d6.loss_cls: 1.4024  decode.d6.loss_mask: 0.8798  decode.d6.loss_dice: 1.4316  decode.d7.loss_cls: 1.4306  decode.d7.loss_mask: 0.8870  decode.d7.loss_dice: 1.4550  decode.d8.loss_cls: 1.3545  decode.d8.loss_mask: 0.8863  decode.d8.loss_dice: 1.4569
2023/05/23 23:37:51 - mmengine - INFO - Iter(train) [ 43600/160000]  lr: 7.5102e-06  eta: 13:49:10  time: 0.4086  data_time: 0.0101  memory: 4875  grad_norm: 91.2751  loss: 35.6772  decode.loss_cls: 1.1780  decode.loss_mask: 0.8934  decode.loss_dice: 1.2405  decode.d0.loss_cls: 3.1299  decode.d0.loss_mask: 0.9049  decode.d0.loss_dice: 1.3386  decode.d1.loss_cls: 1.2962  decode.d1.loss_mask: 0.8704  decode.d1.loss_dice: 1.3414  decode.d2.loss_cls: 1.2040  decode.d2.loss_mask: 0.8749  decode.d2.loss_dice: 1.3161  decode.d3.loss_cls: 1.1503  decode.d3.loss_mask: 0.8972  decode.d3.loss_dice: 1.2824  decode.d4.loss_cls: 1.1863  decode.d4.loss_mask: 0.9352  decode.d4.loss_dice: 1.2795  decode.d5.loss_cls: 1.1455  decode.d5.loss_mask: 0.8965  decode.d5.loss_dice: 1.3027  decode.d6.loss_cls: 1.1669  decode.d6.loss_mask: 0.9137  decode.d6.loss_dice: 1.2804  decode.d7.loss_cls: 1.1377  decode.d7.loss_mask: 0.9119  decode.d7.loss_dice: 1.2550  decode.d8.loss_cls: 1.1822  decode.d8.loss_mask: 0.8884  decode.d8.loss_dice: 1.2770
2023/05/23 23:38:12 - mmengine - INFO - Iter(train) [ 43650/160000]  lr: 7.5073e-06  eta: 13:48:48  time: 0.4632  data_time: 0.0096  memory: 4875  grad_norm: 86.2411  loss: 42.5001  decode.loss_cls: 1.4206  decode.loss_mask: 0.9111  decode.loss_dice: 1.5956  decode.d0.loss_cls: 3.3175  decode.d0.loss_mask: 1.0638  decode.d0.loss_dice: 1.9003  decode.d1.loss_cls: 1.6162  decode.d1.loss_mask: 0.9610  decode.d1.loss_dice: 1.7251  decode.d2.loss_cls: 1.5106  decode.d2.loss_mask: 0.9425  decode.d2.loss_dice: 1.6930  decode.d3.loss_cls: 1.4848  decode.d3.loss_mask: 0.9167  decode.d3.loss_dice: 1.6208  decode.d4.loss_cls: 1.5064  decode.d4.loss_mask: 0.9095  decode.d4.loss_dice: 1.6166  decode.d5.loss_cls: 1.4843  decode.d5.loss_mask: 0.9176  decode.d5.loss_dice: 1.5818  decode.d6.loss_cls: 1.4869  decode.d6.loss_mask: 0.8708  decode.d6.loss_dice: 1.5790  decode.d7.loss_cls: 1.4516  decode.d7.loss_mask: 0.8636  decode.d7.loss_dice: 1.5794  decode.d8.loss_cls: 1.4478  decode.d8.loss_mask: 0.9008  decode.d8.loss_dice: 1.6245
2023/05/23 23:38:33 - mmengine - INFO - Iter(train) [ 43700/160000]  lr: 7.5044e-06  eta: 13:48:27  time: 0.4139  data_time: 0.0097  memory: 4836  grad_norm: 104.5911  loss: 38.2248  decode.loss_cls: 1.5850  decode.loss_mask: 0.7275  decode.loss_dice: 1.2538  decode.d0.loss_cls: 3.4881  decode.d0.loss_mask: 0.8062  decode.d0.loss_dice: 1.4841  decode.d1.loss_cls: 1.6649  decode.d1.loss_mask: 0.7879  decode.d1.loss_dice: 1.4045  decode.d2.loss_cls: 1.6170  decode.d2.loss_mask: 0.7572  decode.d2.loss_dice: 1.2822  decode.d3.loss_cls: 1.5402  decode.d3.loss_mask: 0.7300  decode.d3.loss_dice: 1.2540  decode.d4.loss_cls: 1.5444  decode.d4.loss_mask: 0.7154  decode.d4.loss_dice: 1.2833  decode.d5.loss_cls: 1.5890  decode.d5.loss_mask: 0.7541  decode.d5.loss_dice: 1.3136  decode.d6.loss_cls: 1.6140  decode.d6.loss_mask: 0.7010  decode.d6.loss_dice: 1.2640  decode.d7.loss_cls: 1.6185  decode.d7.loss_mask: 0.6751  decode.d7.loss_dice: 1.2251  decode.d8.loss_cls: 1.5729  decode.d8.loss_mask: 0.7205  decode.d8.loss_dice: 1.2514
2023/05/23 23:38:55 - mmengine - INFO - Iter(train) [ 43750/160000]  lr: 7.5015e-06  eta: 13:48:06  time: 0.4525  data_time: 0.0097  memory: 4851  grad_norm: 86.9389  loss: 31.0464  decode.loss_cls: 1.0237  decode.loss_mask: 0.6685  decode.loss_dice: 1.1054  decode.d0.loss_cls: 3.1244  decode.d0.loss_mask: 0.7480  decode.d0.loss_dice: 1.2814  decode.d1.loss_cls: 1.2409  decode.d1.loss_mask: 0.7196  decode.d1.loss_dice: 1.1616  decode.d2.loss_cls: 1.0878  decode.d2.loss_mask: 0.7200  decode.d2.loss_dice: 1.1422  decode.d3.loss_cls: 1.0530  decode.d3.loss_mask: 0.6952  decode.d3.loss_dice: 1.1080  decode.d4.loss_cls: 1.0398  decode.d4.loss_mask: 0.6761  decode.d4.loss_dice: 1.1249  decode.d5.loss_cls: 1.0481  decode.d5.loss_mask: 0.6768  decode.d5.loss_dice: 1.1136  decode.d6.loss_cls: 1.0459  decode.d6.loss_mask: 0.6830  decode.d6.loss_dice: 1.0834  decode.d7.loss_cls: 1.0065  decode.d7.loss_mask: 0.6842  decode.d7.loss_dice: 1.1026  decode.d8.loss_cls: 1.0834  decode.d8.loss_mask: 0.6829  decode.d8.loss_dice: 1.1156
2023/05/23 23:39:16 - mmengine - INFO - Iter(train) [ 43800/160000]  lr: 7.4986e-06  eta: 13:47:43  time: 0.4133  data_time: 0.0098  memory: 4831  grad_norm: 91.3862  loss: 47.0150  decode.loss_cls: 1.6228  decode.loss_mask: 1.0395  decode.loss_dice: 1.7081  decode.d0.loss_cls: 3.4786  decode.d0.loss_mask: 1.0003  decode.d0.loss_dice: 2.0054  decode.d1.loss_cls: 1.9035  decode.d1.loss_mask: 1.0586  decode.d1.loss_dice: 1.8974  decode.d2.loss_cls: 1.7054  decode.d2.loss_mask: 1.0262  decode.d2.loss_dice: 1.8311  decode.d3.loss_cls: 1.6546  decode.d3.loss_mask: 0.9882  decode.d3.loss_dice: 1.7960  decode.d4.loss_cls: 1.7154  decode.d4.loss_mask: 1.0172  decode.d4.loss_dice: 1.8444  decode.d5.loss_cls: 1.6787  decode.d5.loss_mask: 0.9975  decode.d5.loss_dice: 1.7899  decode.d6.loss_cls: 1.6796  decode.d6.loss_mask: 0.9831  decode.d6.loss_dice: 1.7635  decode.d7.loss_cls: 1.6445  decode.d7.loss_mask: 1.0015  decode.d7.loss_dice: 1.7798  decode.d8.loss_cls: 1.6202  decode.d8.loss_mask: 1.0451  decode.d8.loss_dice: 1.7391
2023/05/23 23:39:38 - mmengine - INFO - Iter(train) [ 43850/160000]  lr: 7.4957e-06  eta: 13:47:23  time: 0.4082  data_time: 0.0101  memory: 4847  grad_norm: 115.5185  loss: 38.1326  decode.loss_cls: 1.3810  decode.loss_mask: 0.7650  decode.loss_dice: 1.4033  decode.d0.loss_cls: 3.2153  decode.d0.loss_mask: 0.8635  decode.d0.loss_dice: 1.5657  decode.d1.loss_cls: 1.4392  decode.d1.loss_mask: 0.9084  decode.d1.loss_dice: 1.5743  decode.d2.loss_cls: 1.3713  decode.d2.loss_mask: 0.8595  decode.d2.loss_dice: 1.4922  decode.d3.loss_cls: 1.3834  decode.d3.loss_mask: 0.7805  decode.d3.loss_dice: 1.4614  decode.d4.loss_cls: 1.3520  decode.d4.loss_mask: 0.7742  decode.d4.loss_dice: 1.4643  decode.d5.loss_cls: 1.3225  decode.d5.loss_mask: 0.7652  decode.d5.loss_dice: 1.4515  decode.d6.loss_cls: 1.2578  decode.d6.loss_mask: 0.7757  decode.d6.loss_dice: 1.4560  decode.d7.loss_cls: 1.3118  decode.d7.loss_mask: 0.7530  decode.d7.loss_dice: 1.4446  decode.d8.loss_cls: 1.3181  decode.d8.loss_mask: 0.7633  decode.d8.loss_dice: 1.4584
2023/05/23 23:39:59 - mmengine - INFO - Iter(train) [ 43900/160000]  lr: 7.4928e-06  eta: 13:47:02  time: 0.4145  data_time: 0.0105  memory: 4855  grad_norm: 100.1342  loss: 44.4442  decode.loss_cls: 1.4570  decode.loss_mask: 0.9730  decode.loss_dice: 1.6955  decode.d0.loss_cls: 3.7389  decode.d0.loss_mask: 0.9626  decode.d0.loss_dice: 1.9142  decode.d1.loss_cls: 1.7174  decode.d1.loss_mask: 0.9955  decode.d1.loss_dice: 1.8105  decode.d2.loss_cls: 1.6270  decode.d2.loss_mask: 0.9777  decode.d2.loss_dice: 1.7361  decode.d3.loss_cls: 1.5342  decode.d3.loss_mask: 0.9424  decode.d3.loss_dice: 1.7292  decode.d4.loss_cls: 1.4701  decode.d4.loss_mask: 0.9572  decode.d4.loss_dice: 1.7236  decode.d5.loss_cls: 1.4682  decode.d5.loss_mask: 0.9453  decode.d5.loss_dice: 1.7052  decode.d6.loss_cls: 1.4869  decode.d6.loss_mask: 0.9484  decode.d6.loss_dice: 1.7081  decode.d7.loss_cls: 1.4503  decode.d7.loss_mask: 0.9416  decode.d7.loss_dice: 1.6922  decode.d8.loss_cls: 1.4543  decode.d8.loss_mask: 0.9698  decode.d8.loss_dice: 1.7117
2023/05/23 23:40:20 - mmengine - INFO - Iter(train) [ 43950/160000]  lr: 7.4899e-06  eta: 13:46:39  time: 0.4107  data_time: 0.0103  memory: 4829  grad_norm: 97.5290  loss: 39.7079  decode.loss_cls: 1.3903  decode.loss_mask: 0.9537  decode.loss_dice: 1.3734  decode.d0.loss_cls: 3.2343  decode.d0.loss_mask: 1.0478  decode.d0.loss_dice: 1.6067  decode.d1.loss_cls: 1.4098  decode.d1.loss_mask: 0.9980  decode.d1.loss_dice: 1.5382  decode.d2.loss_cls: 1.4206  decode.d2.loss_mask: 0.9575  decode.d2.loss_dice: 1.4455  decode.d3.loss_cls: 1.3868  decode.d3.loss_mask: 0.9689  decode.d3.loss_dice: 1.3746  decode.d4.loss_cls: 1.3524  decode.d4.loss_mask: 0.9803  decode.d4.loss_dice: 1.4025  decode.d5.loss_cls: 1.3781  decode.d5.loss_mask: 0.9688  decode.d5.loss_dice: 1.3884  decode.d6.loss_cls: 1.3814  decode.d6.loss_mask: 0.9756  decode.d6.loss_dice: 1.3614  decode.d7.loss_cls: 1.3296  decode.d7.loss_mask: 0.9956  decode.d7.loss_dice: 1.3849  decode.d8.loss_cls: 1.3510  decode.d8.loss_mask: 0.9767  decode.d8.loss_dice: 1.3752
2023/05/23 23:40:41 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 23:40:41 - mmengine - INFO - Iter(train) [ 44000/160000]  lr: 7.4870e-06  eta: 13:46:16  time: 0.4263  data_time: 0.0102  memory: 4866  grad_norm: 107.2967  loss: 37.6229  decode.loss_cls: 1.0655  decode.loss_mask: 0.8116  decode.loss_dice: 1.5437  decode.d0.loss_cls: 3.2386  decode.d0.loss_mask: 0.8642  decode.d0.loss_dice: 1.7467  decode.d1.loss_cls: 1.3060  decode.d1.loss_mask: 0.8594  decode.d1.loss_dice: 1.7055  decode.d2.loss_cls: 1.1691  decode.d2.loss_mask: 0.8521  decode.d2.loss_dice: 1.6454  decode.d3.loss_cls: 1.1154  decode.d3.loss_mask: 0.8277  decode.d3.loss_dice: 1.5493  decode.d4.loss_cls: 1.1003  decode.d4.loss_mask: 0.7986  decode.d4.loss_dice: 1.5892  decode.d5.loss_cls: 1.1215  decode.d5.loss_mask: 0.7754  decode.d5.loss_dice: 1.5396  decode.d6.loss_cls: 1.1624  decode.d6.loss_mask: 0.7876  decode.d6.loss_dice: 1.5150  decode.d7.loss_cls: 1.1090  decode.d7.loss_mask: 0.7965  decode.d7.loss_dice: 1.5492  decode.d8.loss_cls: 1.0682  decode.d8.loss_mask: 0.8091  decode.d8.loss_dice: 1.6010
2023/05/23 23:40:41 - mmengine - INFO - Saving checkpoint at 44000 iterations
2023/05/23 23:41:07 - mmengine - INFO - Iter(train) [ 44050/160000]  lr: 7.4841e-06  eta: 13:46:08  time: 0.4153  data_time: 0.0099  memory: 4945  grad_norm: 97.6653  loss: 35.8978  decode.loss_cls: 1.3606  decode.loss_mask: 0.8352  decode.loss_dice: 1.1378  decode.d0.loss_cls: 3.2000  decode.d0.loss_mask: 0.8373  decode.d0.loss_dice: 1.3381  decode.d1.loss_cls: 1.5092  decode.d1.loss_mask: 0.8411  decode.d1.loss_dice: 1.2321  decode.d2.loss_cls: 1.4783  decode.d2.loss_mask: 0.7968  decode.d2.loss_dice: 1.1731  decode.d3.loss_cls: 1.4405  decode.d3.loss_mask: 0.7846  decode.d3.loss_dice: 1.1506  decode.d4.loss_cls: 1.3792  decode.d4.loss_mask: 0.8239  decode.d4.loss_dice: 1.1798  decode.d5.loss_cls: 1.3752  decode.d5.loss_mask: 0.8116  decode.d5.loss_dice: 1.1765  decode.d6.loss_cls: 1.3530  decode.d6.loss_mask: 0.8222  decode.d6.loss_dice: 1.1442  decode.d7.loss_cls: 1.3413  decode.d7.loss_mask: 0.8337  decode.d7.loss_dice: 1.1642  decode.d8.loss_cls: 1.3979  decode.d8.loss_mask: 0.8211  decode.d8.loss_dice: 1.1588
2023/05/23 23:41:30 - mmengine - INFO - Iter(train) [ 44100/160000]  lr: 7.4812e-06  eta: 13:45:50  time: 0.4679  data_time: 0.0097  memory: 4821  grad_norm: 85.5869  loss: 45.6875  decode.loss_cls: 1.4942  decode.loss_mask: 1.0414  decode.loss_dice: 1.7687  decode.d0.loss_cls: 3.3494  decode.d0.loss_mask: 1.1226  decode.d0.loss_dice: 2.0390  decode.d1.loss_cls: 1.6438  decode.d1.loss_mask: 1.1034  decode.d1.loss_dice: 1.9149  decode.d2.loss_cls: 1.5184  decode.d2.loss_mask: 1.0490  decode.d2.loss_dice: 1.8317  decode.d3.loss_cls: 1.4453  decode.d3.loss_mask: 1.0224  decode.d3.loss_dice: 1.7875  decode.d4.loss_cls: 1.4212  decode.d4.loss_mask: 1.0814  decode.d4.loss_dice: 1.8132  decode.d5.loss_cls: 1.4239  decode.d5.loss_mask: 1.0525  decode.d5.loss_dice: 1.8102  decode.d6.loss_cls: 1.4372  decode.d6.loss_mask: 1.0887  decode.d6.loss_dice: 1.7835  decode.d7.loss_cls: 1.4280  decode.d7.loss_mask: 1.0760  decode.d7.loss_dice: 1.7843  decode.d8.loss_cls: 1.4658  decode.d8.loss_mask: 1.0675  decode.d8.loss_dice: 1.8224
2023/05/23 23:41:52 - mmengine - INFO - Iter(train) [ 44150/160000]  lr: 7.4783e-06  eta: 13:45:32  time: 0.4593  data_time: 0.0101  memory: 4844  grad_norm: 117.8807  loss: 46.0146  decode.loss_cls: 1.7487  decode.loss_mask: 0.9965  decode.loss_dice: 1.5974  decode.d0.loss_cls: 3.4278  decode.d0.loss_mask: 1.0281  decode.d0.loss_dice: 1.7754  decode.d1.loss_cls: 1.8130  decode.d1.loss_mask: 1.0726  decode.d1.loss_dice: 1.7418  decode.d2.loss_cls: 1.8794  decode.d2.loss_mask: 1.0311  decode.d2.loss_dice: 1.6866  decode.d3.loss_cls: 1.7205  decode.d3.loss_mask: 1.0582  decode.d3.loss_dice: 1.6563  decode.d4.loss_cls: 1.7290  decode.d4.loss_mask: 1.0387  decode.d4.loss_dice: 1.6267  decode.d5.loss_cls: 1.7274  decode.d5.loss_mask: 1.0064  decode.d5.loss_dice: 1.6231  decode.d6.loss_cls: 1.6619  decode.d6.loss_mask: 1.0422  decode.d6.loss_dice: 1.6745  decode.d7.loss_cls: 1.7007  decode.d7.loss_mask: 1.0120  decode.d7.loss_dice: 1.6278  decode.d8.loss_cls: 1.7179  decode.d8.loss_mask: 0.9999  decode.d8.loss_dice: 1.5932
2023/05/23 23:42:14 - mmengine - INFO - Iter(train) [ 44200/160000]  lr: 7.4754e-06  eta: 13:45:12  time: 0.4330  data_time: 0.0099  memory: 4807  grad_norm: 100.6023  loss: 33.2420  decode.loss_cls: 1.2214  decode.loss_mask: 0.6440  decode.loss_dice: 1.1454  decode.d0.loss_cls: 3.0967  decode.d0.loss_mask: 0.7181  decode.d0.loss_dice: 1.2401  decode.d1.loss_cls: 1.2878  decode.d1.loss_mask: 0.6947  decode.d1.loss_dice: 1.2307  decode.d2.loss_cls: 1.2335  decode.d2.loss_mask: 0.6970  decode.d2.loss_dice: 1.2183  decode.d3.loss_cls: 1.2958  decode.d3.loss_mask: 0.6665  decode.d3.loss_dice: 1.1587  decode.d4.loss_cls: 1.3171  decode.d4.loss_mask: 0.6542  decode.d4.loss_dice: 1.1534  decode.d5.loss_cls: 1.3201  decode.d5.loss_mask: 0.6457  decode.d5.loss_dice: 1.1807  decode.d6.loss_cls: 1.3677  decode.d6.loss_mask: 0.6690  decode.d6.loss_dice: 1.1775  decode.d7.loss_cls: 1.3286  decode.d7.loss_mask: 0.6424  decode.d7.loss_dice: 1.1522  decode.d8.loss_cls: 1.2566  decode.d8.loss_mask: 0.6497  decode.d8.loss_dice: 1.1786
2023/05/23 23:42:37 - mmengine - INFO - Iter(train) [ 44250/160000]  lr: 7.4725e-06  eta: 13:44:55  time: 0.4293  data_time: 0.0098  memory: 4802  grad_norm: 87.4420  loss: 40.0817  decode.loss_cls: 1.3363  decode.loss_mask: 0.9536  decode.loss_dice: 1.4535  decode.d0.loss_cls: 3.2779  decode.d0.loss_mask: 0.9377  decode.d0.loss_dice: 1.6371  decode.d1.loss_cls: 1.4865  decode.d1.loss_mask: 0.9657  decode.d1.loss_dice: 1.5770  decode.d2.loss_cls: 1.3992  decode.d2.loss_mask: 0.9029  decode.d2.loss_dice: 1.5265  decode.d3.loss_cls: 1.3941  decode.d3.loss_mask: 0.9269  decode.d3.loss_dice: 1.5027  decode.d4.loss_cls: 1.3708  decode.d4.loss_mask: 0.9070  decode.d4.loss_dice: 1.5154  decode.d5.loss_cls: 1.3303  decode.d5.loss_mask: 0.9274  decode.d5.loss_dice: 1.5033  decode.d6.loss_cls: 1.3301  decode.d6.loss_mask: 0.9336  decode.d6.loss_dice: 1.4871  decode.d7.loss_cls: 1.3148  decode.d7.loss_mask: 0.9736  decode.d7.loss_dice: 1.4975  decode.d8.loss_cls: 1.3436  decode.d8.loss_mask: 0.9162  decode.d8.loss_dice: 1.4533
2023/05/23 23:42:58 - mmengine - INFO - Iter(train) [ 44300/160000]  lr: 7.4696e-06  eta: 13:44:32  time: 0.4262  data_time: 0.0102  memory: 4840  grad_norm: 88.9418  loss: 38.0532  decode.loss_cls: 1.5023  decode.loss_mask: 0.8057  decode.loss_dice: 1.2052  decode.d0.loss_cls: 3.4788  decode.d0.loss_mask: 0.9049  decode.d0.loss_dice: 1.3763  decode.d1.loss_cls: 1.7241  decode.d1.loss_mask: 0.8942  decode.d1.loss_dice: 1.3333  decode.d2.loss_cls: 1.5884  decode.d2.loss_mask: 0.8270  decode.d2.loss_dice: 1.2377  decode.d3.loss_cls: 1.5278  decode.d3.loss_mask: 0.7965  decode.d3.loss_dice: 1.1956  decode.d4.loss_cls: 1.4947  decode.d4.loss_mask: 0.8137  decode.d4.loss_dice: 1.2256  decode.d5.loss_cls: 1.4982  decode.d5.loss_mask: 0.8066  decode.d5.loss_dice: 1.2297  decode.d6.loss_cls: 1.5055  decode.d6.loss_mask: 0.8070  decode.d6.loss_dice: 1.1798  decode.d7.loss_cls: 1.4918  decode.d7.loss_mask: 0.8234  decode.d7.loss_dice: 1.2426  decode.d8.loss_cls: 1.5193  decode.d8.loss_mask: 0.8156  decode.d8.loss_dice: 1.2019
2023/05/23 23:43:19 - mmengine - INFO - Iter(train) [ 44350/160000]  lr: 7.4666e-06  eta: 13:44:09  time: 0.4051  data_time: 0.0104  memory: 4916  grad_norm: 86.3394  loss: 34.7466  decode.loss_cls: 1.3600  decode.loss_mask: 0.6853  decode.loss_dice: 1.1485  decode.d0.loss_cls: 3.2450  decode.d0.loss_mask: 0.7485  decode.d0.loss_dice: 1.3364  decode.d1.loss_cls: 1.3662  decode.d1.loss_mask: 0.7854  decode.d1.loss_dice: 1.2803  decode.d2.loss_cls: 1.3337  decode.d2.loss_mask: 0.7297  decode.d2.loss_dice: 1.2435  decode.d3.loss_cls: 1.3749  decode.d3.loss_mask: 0.7095  decode.d3.loss_dice: 1.2556  decode.d4.loss_cls: 1.3497  decode.d4.loss_mask: 0.7103  decode.d4.loss_dice: 1.2148  decode.d5.loss_cls: 1.3980  decode.d5.loss_mask: 0.7021  decode.d5.loss_dice: 1.2071  decode.d6.loss_cls: 1.3225  decode.d6.loss_mask: 0.6912  decode.d6.loss_dice: 1.1901  decode.d7.loss_cls: 1.3898  decode.d7.loss_mask: 0.6964  decode.d7.loss_dice: 1.1281  decode.d8.loss_cls: 1.3500  decode.d8.loss_mask: 0.6652  decode.d8.loss_dice: 1.1288
2023/05/23 23:43:39 - mmengine - INFO - Iter(train) [ 44400/160000]  lr: 7.4637e-06  eta: 13:43:45  time: 0.4143  data_time: 0.0104  memory: 4834  grad_norm: 91.8668  loss: 31.9201  decode.loss_cls: 1.3343  decode.loss_mask: 0.7024  decode.loss_dice: 0.9150  decode.d0.loss_cls: 3.2051  decode.d0.loss_mask: 0.8199  decode.d0.loss_dice: 1.0642  decode.d1.loss_cls: 1.3825  decode.d1.loss_mask: 0.7047  decode.d1.loss_dice: 1.0022  decode.d2.loss_cls: 1.4303  decode.d2.loss_mask: 0.6867  decode.d2.loss_dice: 0.9002  decode.d3.loss_cls: 1.3662  decode.d3.loss_mask: 0.6857  decode.d3.loss_dice: 0.8963  decode.d4.loss_cls: 1.3225  decode.d4.loss_mask: 0.6941  decode.d4.loss_dice: 0.9356  decode.d5.loss_cls: 1.3644  decode.d5.loss_mask: 0.7038  decode.d5.loss_dice: 0.8993  decode.d6.loss_cls: 1.3868  decode.d6.loss_mask: 0.6712  decode.d6.loss_dice: 0.8888  decode.d7.loss_cls: 1.3763  decode.d7.loss_mask: 0.6806  decode.d7.loss_dice: 0.8912  decode.d8.loss_cls: 1.4094  decode.d8.loss_mask: 0.6841  decode.d8.loss_dice: 0.9161
2023/05/23 23:44:01 - mmengine - INFO - Iter(train) [ 44450/160000]  lr: 7.4608e-06  eta: 13:43:26  time: 0.4094  data_time: 0.0098  memory: 4877  grad_norm: 102.0954  loss: 31.1604  decode.loss_cls: 0.9772  decode.loss_mask: 0.7546  decode.loss_dice: 1.1093  decode.d0.loss_cls: 3.1222  decode.d0.loss_mask: 0.7609  decode.d0.loss_dice: 1.2715  decode.d1.loss_cls: 1.1488  decode.d1.loss_mask: 0.7638  decode.d1.loss_dice: 1.2614  decode.d2.loss_cls: 1.0842  decode.d2.loss_mask: 0.7402  decode.d2.loss_dice: 1.1537  decode.d3.loss_cls: 1.0667  decode.d3.loss_mask: 0.7021  decode.d3.loss_dice: 1.0962  decode.d4.loss_cls: 1.0395  decode.d4.loss_mask: 0.7105  decode.d4.loss_dice: 1.0881  decode.d5.loss_cls: 1.0012  decode.d5.loss_mask: 0.7133  decode.d5.loss_dice: 1.1238  decode.d6.loss_cls: 0.9491  decode.d6.loss_mask: 0.7426  decode.d6.loss_dice: 1.1103  decode.d7.loss_cls: 0.9780  decode.d7.loss_mask: 0.7242  decode.d7.loss_dice: 1.1180  decode.d8.loss_cls: 0.9875  decode.d8.loss_mask: 0.7433  decode.d8.loss_dice: 1.1184
2023/05/23 23:44:22 - mmengine - INFO - Iter(train) [ 44500/160000]  lr: 7.4579e-06  eta: 13:43:02  time: 0.4055  data_time: 0.0100  memory: 4869  grad_norm: 83.7875  loss: 26.5644  decode.loss_cls: 0.9350  decode.loss_mask: 0.6008  decode.loss_dice: 0.8386  decode.d0.loss_cls: 2.7293  decode.d0.loss_mask: 0.6753  decode.d0.loss_dice: 1.0076  decode.d1.loss_cls: 1.1590  decode.d1.loss_mask: 0.5947  decode.d1.loss_dice: 0.9110  decode.d2.loss_cls: 1.0137  decode.d2.loss_mask: 0.6253  decode.d2.loss_dice: 0.9014  decode.d3.loss_cls: 1.0459  decode.d3.loss_mask: 0.6280  decode.d3.loss_dice: 0.8977  decode.d4.loss_cls: 0.9765  decode.d4.loss_mask: 0.6371  decode.d4.loss_dice: 0.8731  decode.d5.loss_cls: 0.9139  decode.d5.loss_mask: 0.6099  decode.d5.loss_dice: 0.8843  decode.d6.loss_cls: 0.9230  decode.d6.loss_mask: 0.6110  decode.d6.loss_dice: 0.8324  decode.d7.loss_cls: 0.9258  decode.d7.loss_mask: 0.5973  decode.d7.loss_dice: 0.8386  decode.d8.loss_cls: 0.9073  decode.d8.loss_mask: 0.5978  decode.d8.loss_dice: 0.8730
2023/05/23 23:44:43 - mmengine - INFO - Iter(train) [ 44550/160000]  lr: 7.4550e-06  eta: 13:42:39  time: 0.4087  data_time: 0.0098  memory: 4822  grad_norm: 91.3619  loss: 41.4365  decode.loss_cls: 1.5343  decode.loss_mask: 0.8977  decode.loss_dice: 1.4221  decode.d0.loss_cls: 3.2917  decode.d0.loss_mask: 0.9755  decode.d0.loss_dice: 1.6042  decode.d1.loss_cls: 1.6447  decode.d1.loss_mask: 0.9508  decode.d1.loss_dice: 1.5673  decode.d2.loss_cls: 1.5798  decode.d2.loss_mask: 0.9045  decode.d2.loss_dice: 1.5384  decode.d3.loss_cls: 1.6043  decode.d3.loss_mask: 0.8910  decode.d3.loss_dice: 1.4589  decode.d4.loss_cls: 1.5450  decode.d4.loss_mask: 0.9186  decode.d4.loss_dice: 1.4864  decode.d5.loss_cls: 1.5468  decode.d5.loss_mask: 0.8976  decode.d5.loss_dice: 1.4850  decode.d6.loss_cls: 1.5576  decode.d6.loss_mask: 0.8713  decode.d6.loss_dice: 1.4845  decode.d7.loss_cls: 1.5854  decode.d7.loss_mask: 0.8789  decode.d7.loss_dice: 1.4041  decode.d8.loss_cls: 1.5731  decode.d8.loss_mask: 0.8812  decode.d8.loss_dice: 1.4559
2023/05/23 23:45:04 - mmengine - INFO - Iter(train) [ 44600/160000]  lr: 7.4521e-06  eta: 13:42:17  time: 0.4092  data_time: 0.0102  memory: 4829  grad_norm: 100.5657  loss: 41.1212  decode.loss_cls: 1.3022  decode.loss_mask: 0.9328  decode.loss_dice: 1.5301  decode.d0.loss_cls: 3.2776  decode.d0.loss_mask: 1.0147  decode.d0.loss_dice: 1.8385  decode.d1.loss_cls: 1.5405  decode.d1.loss_mask: 1.0322  decode.d1.loss_dice: 1.7408  decode.d2.loss_cls: 1.3721  decode.d2.loss_mask: 0.9925  decode.d2.loss_dice: 1.6497  decode.d3.loss_cls: 1.3820  decode.d3.loss_mask: 0.9612  decode.d3.loss_dice: 1.6070  decode.d4.loss_cls: 1.3477  decode.d4.loss_mask: 0.9885  decode.d4.loss_dice: 1.5687  decode.d5.loss_cls: 1.3768  decode.d5.loss_mask: 0.9200  decode.d5.loss_dice: 1.5400  decode.d6.loss_cls: 1.3641  decode.d6.loss_mask: 0.9523  decode.d6.loss_dice: 1.4886  decode.d7.loss_cls: 1.2229  decode.d7.loss_mask: 0.9260  decode.d7.loss_dice: 1.5293  decode.d8.loss_cls: 1.2514  decode.d8.loss_mask: 0.9472  decode.d8.loss_dice: 1.5236
2023/05/23 23:45:25 - mmengine - INFO - Iter(train) [ 44650/160000]  lr: 7.4492e-06  eta: 13:41:55  time: 0.4137  data_time: 0.0097  memory: 4878  grad_norm: 104.9144  loss: 37.4486  decode.loss_cls: 1.3835  decode.loss_mask: 0.7600  decode.loss_dice: 1.3786  decode.d0.loss_cls: 3.1049  decode.d0.loss_mask: 0.8221  decode.d0.loss_dice: 1.5299  decode.d1.loss_cls: 1.4676  decode.d1.loss_mask: 0.7867  decode.d1.loss_dice: 1.4183  decode.d2.loss_cls: 1.3653  decode.d2.loss_mask: 0.7772  decode.d2.loss_dice: 1.4548  decode.d3.loss_cls: 1.3303  decode.d3.loss_mask: 0.7820  decode.d3.loss_dice: 1.4370  decode.d4.loss_cls: 1.3697  decode.d4.loss_mask: 0.7607  decode.d4.loss_dice: 1.4198  decode.d5.loss_cls: 1.3968  decode.d5.loss_mask: 0.7493  decode.d5.loss_dice: 1.4125  decode.d6.loss_cls: 1.4008  decode.d6.loss_mask: 0.7490  decode.d6.loss_dice: 1.3724  decode.d7.loss_cls: 1.3803  decode.d7.loss_mask: 0.7579  decode.d7.loss_dice: 1.3923  decode.d8.loss_cls: 1.3620  decode.d8.loss_mask: 0.7484  decode.d8.loss_dice: 1.3785
2023/05/23 23:45:45 - mmengine - INFO - Iter(train) [ 44700/160000]  lr: 7.4463e-06  eta: 13:41:32  time: 0.4153  data_time: 0.0111  memory: 4824  grad_norm: 95.2228  loss: 38.2789  decode.loss_cls: 1.3564  decode.loss_mask: 0.8059  decode.loss_dice: 1.4539  decode.d0.loss_cls: 3.2170  decode.d0.loss_mask: 0.8451  decode.d0.loss_dice: 1.5983  decode.d1.loss_cls: 1.4982  decode.d1.loss_mask: 0.7949  decode.d1.loss_dice: 1.5189  decode.d2.loss_cls: 1.4084  decode.d2.loss_mask: 0.8323  decode.d2.loss_dice: 1.4359  decode.d3.loss_cls: 1.3330  decode.d3.loss_mask: 0.8164  decode.d3.loss_dice: 1.4572  decode.d4.loss_cls: 1.3187  decode.d4.loss_mask: 0.7940  decode.d4.loss_dice: 1.4260  decode.d5.loss_cls: 1.3645  decode.d5.loss_mask: 0.8106  decode.d5.loss_dice: 1.4495  decode.d6.loss_cls: 1.3873  decode.d6.loss_mask: 0.8163  decode.d6.loss_dice: 1.3897  decode.d7.loss_cls: 1.3725  decode.d7.loss_mask: 0.7923  decode.d7.loss_dice: 1.4218  decode.d8.loss_cls: 1.3700  decode.d8.loss_mask: 0.7921  decode.d8.loss_dice: 1.4019
2023/05/23 23:46:07 - mmengine - INFO - Iter(train) [ 44750/160000]  lr: 7.4434e-06  eta: 13:41:10  time: 0.4582  data_time: 0.0097  memory: 4829  grad_norm: 93.0848  loss: 40.3173  decode.loss_cls: 1.3370  decode.loss_mask: 1.0109  decode.loss_dice: 1.3744  decode.d0.loss_cls: 3.4778  decode.d0.loss_mask: 1.1649  decode.d0.loss_dice: 1.5831  decode.d1.loss_cls: 1.4326  decode.d1.loss_mask: 1.0429  decode.d1.loss_dice: 1.5130  decode.d2.loss_cls: 1.4228  decode.d2.loss_mask: 1.0512  decode.d2.loss_dice: 1.3857  decode.d3.loss_cls: 1.4335  decode.d3.loss_mask: 1.0234  decode.d3.loss_dice: 1.4031  decode.d4.loss_cls: 1.3794  decode.d4.loss_mask: 1.0455  decode.d4.loss_dice: 1.4255  decode.d5.loss_cls: 1.3072  decode.d5.loss_mask: 1.0342  decode.d5.loss_dice: 1.3531  decode.d6.loss_cls: 1.3252  decode.d6.loss_mask: 1.0228  decode.d6.loss_dice: 1.3935  decode.d7.loss_cls: 1.3164  decode.d7.loss_mask: 1.0178  decode.d7.loss_dice: 1.3653  decode.d8.loss_cls: 1.2936  decode.d8.loss_mask: 1.0402  decode.d8.loss_dice: 1.3414
2023/05/23 23:46:27 - mmengine - INFO - Iter(train) [ 44800/160000]  lr: 7.4405e-06  eta: 13:40:47  time: 0.4180  data_time: 0.0101  memory: 4856  grad_norm: 90.7815  loss: 35.5000  decode.loss_cls: 1.1133  decode.loss_mask: 0.7194  decode.loss_dice: 1.4565  decode.d0.loss_cls: 2.9130  decode.d0.loss_mask: 0.7762  decode.d0.loss_dice: 1.6339  decode.d1.loss_cls: 1.2665  decode.d1.loss_mask: 0.7698  decode.d1.loss_dice: 1.5698  decode.d2.loss_cls: 1.3179  decode.d2.loss_mask: 0.7137  decode.d2.loss_dice: 1.5138  decode.d3.loss_cls: 1.2013  decode.d3.loss_mask: 0.7109  decode.d3.loss_dice: 1.4231  decode.d4.loss_cls: 1.1453  decode.d4.loss_mask: 0.7207  decode.d4.loss_dice: 1.4930  decode.d5.loss_cls: 1.1145  decode.d5.loss_mask: 0.7124  decode.d5.loss_dice: 1.4542  decode.d6.loss_cls: 1.1013  decode.d6.loss_mask: 0.7151  decode.d6.loss_dice: 1.4345  decode.d7.loss_cls: 1.1141  decode.d7.loss_mask: 0.7040  decode.d7.loss_dice: 1.4168  decode.d8.loss_cls: 1.1740  decode.d8.loss_mask: 0.6897  decode.d8.loss_dice: 1.4112
2023/05/23 23:46:48 - mmengine - INFO - Iter(train) [ 44850/160000]  lr: 7.4376e-06  eta: 13:40:24  time: 0.4120  data_time: 0.0106  memory: 4877  grad_norm: 94.5639  loss: 29.5709  decode.loss_cls: 0.9622  decode.loss_mask: 0.6880  decode.loss_dice: 1.0643  decode.d0.loss_cls: 2.8486  decode.d0.loss_mask: 0.7178  decode.d0.loss_dice: 1.2145  decode.d1.loss_cls: 1.1456  decode.d1.loss_mask: 0.6728  decode.d1.loss_dice: 1.0818  decode.d2.loss_cls: 1.0140  decode.d2.loss_mask: 0.6797  decode.d2.loss_dice: 1.0497  decode.d3.loss_cls: 0.9904  decode.d3.loss_mask: 0.7056  decode.d3.loss_dice: 1.0667  decode.d4.loss_cls: 0.9861  decode.d4.loss_mask: 0.6933  decode.d4.loss_dice: 1.0693  decode.d5.loss_cls: 0.9629  decode.d5.loss_mask: 0.7224  decode.d5.loss_dice: 1.0916  decode.d6.loss_cls: 0.9586  decode.d6.loss_mask: 0.7172  decode.d6.loss_dice: 1.0647  decode.d7.loss_cls: 0.9358  decode.d7.loss_mask: 0.6940  decode.d7.loss_dice: 1.0551  decode.d8.loss_cls: 0.9642  decode.d8.loss_mask: 0.6845  decode.d8.loss_dice: 1.0695
2023/05/23 23:47:10 - mmengine - INFO - Iter(train) [ 44900/160000]  lr: 7.4347e-06  eta: 13:40:03  time: 0.4112  data_time: 0.0097  memory: 4890  grad_norm: 96.0227  loss: 38.1693  decode.loss_cls: 1.2701  decode.loss_mask: 0.7660  decode.loss_dice: 1.4389  decode.d0.loss_cls: 3.3961  decode.d0.loss_mask: 0.7992  decode.d0.loss_dice: 1.6916  decode.d1.loss_cls: 1.3864  decode.d1.loss_mask: 0.9024  decode.d1.loss_dice: 1.6272  decode.d2.loss_cls: 1.2810  decode.d2.loss_mask: 0.8337  decode.d2.loss_dice: 1.5696  decode.d3.loss_cls: 1.3293  decode.d3.loss_mask: 0.8071  decode.d3.loss_dice: 1.4796  decode.d4.loss_cls: 1.2956  decode.d4.loss_mask: 0.7986  decode.d4.loss_dice: 1.4918  decode.d5.loss_cls: 1.2721  decode.d5.loss_mask: 0.7716  decode.d5.loss_dice: 1.4813  decode.d6.loss_cls: 1.2608  decode.d6.loss_mask: 0.7642  decode.d6.loss_dice: 1.4644  decode.d7.loss_cls: 1.2400  decode.d7.loss_mask: 0.7595  decode.d7.loss_dice: 1.4621  decode.d8.loss_cls: 1.3249  decode.d8.loss_mask: 0.7554  decode.d8.loss_dice: 1.4489
2023/05/23 23:47:31 - mmengine - INFO - Iter(train) [ 44950/160000]  lr: 7.4318e-06  eta: 13:39:41  time: 0.4184  data_time: 0.0103  memory: 4823  grad_norm: 92.5352  loss: 50.3759  decode.loss_cls: 1.7791  decode.loss_mask: 0.9807  decode.loss_dice: 1.9426  decode.d0.loss_cls: 3.8514  decode.d0.loss_mask: 1.0393  decode.d0.loss_dice: 2.2340  decode.d1.loss_cls: 2.0694  decode.d1.loss_mask: 1.0085  decode.d1.loss_dice: 2.1220  decode.d2.loss_cls: 1.8497  decode.d2.loss_mask: 1.0027  decode.d2.loss_dice: 2.0735  decode.d3.loss_cls: 1.8297  decode.d3.loss_mask: 0.9898  decode.d3.loss_dice: 1.9851  decode.d4.loss_cls: 1.8291  decode.d4.loss_mask: 0.9674  decode.d4.loss_dice: 1.9855  decode.d5.loss_cls: 1.7801  decode.d5.loss_mask: 0.9688  decode.d5.loss_dice: 1.9782  decode.d6.loss_cls: 1.7652  decode.d6.loss_mask: 0.9658  decode.d6.loss_dice: 1.9704  decode.d7.loss_cls: 1.7620  decode.d7.loss_mask: 0.9705  decode.d7.loss_dice: 1.9924  decode.d8.loss_cls: 1.8026  decode.d8.loss_mask: 0.9268  decode.d8.loss_dice: 1.9534
2023/05/23 23:47:52 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 23:47:52 - mmengine - INFO - Iter(train) [ 45000/160000]  lr: 7.4289e-06  eta: 13:39:18  time: 0.4201  data_time: 0.0100  memory: 4846  grad_norm: 104.5581  loss: 41.7219  decode.loss_cls: 1.5641  decode.loss_mask: 0.8580  decode.loss_dice: 1.4157  decode.d0.loss_cls: 3.6173  decode.d0.loss_mask: 0.9355  decode.d0.loss_dice: 1.7150  decode.d1.loss_cls: 1.6504  decode.d1.loss_mask: 0.9432  decode.d1.loss_dice: 1.5913  decode.d2.loss_cls: 1.6334  decode.d2.loss_mask: 0.8795  decode.d2.loss_dice: 1.5104  decode.d3.loss_cls: 1.6072  decode.d3.loss_mask: 0.9195  decode.d3.loss_dice: 1.4346  decode.d4.loss_cls: 1.5527  decode.d4.loss_mask: 0.9263  decode.d4.loss_dice: 1.4499  decode.d5.loss_cls: 1.5601  decode.d5.loss_mask: 0.8814  decode.d5.loss_dice: 1.4549  decode.d6.loss_cls: 1.5355  decode.d6.loss_mask: 0.8840  decode.d6.loss_dice: 1.4592  decode.d7.loss_cls: 1.5763  decode.d7.loss_mask: 0.8699  decode.d7.loss_dice: 1.4279  decode.d8.loss_cls: 1.6011  decode.d8.loss_mask: 0.8504  decode.d8.loss_dice: 1.4170
2023/05/23 23:47:52 - mmengine - INFO - Saving checkpoint at 45000 iterations
2023/05/23 23:48:02 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:48  time: 0.0795  data_time: 0.0020  memory: 2167  
2023/05/23 23:48:06 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:47  time: 0.0954  data_time: 0.0018  memory: 2216  
2023/05/23 23:48:11 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:42  time: 0.0795  data_time: 0.0018  memory: 2167  
2023/05/23 23:48:15 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:37  time: 0.0787  data_time: 0.0018  memory: 2104  
2023/05/23 23:48:19 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:32  time: 0.0797  data_time: 0.0022  memory: 2831  
2023/05/23 23:48:23 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:27  time: 0.0794  data_time: 0.0018  memory: 2167  
2023/05/23 23:48:27 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:23  time: 0.0794  data_time: 0.0018  memory: 2167  
2023/05/23 23:48:31 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0795  data_time: 0.0019  memory: 2167  
2023/05/23 23:48:35 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0965  data_time: 0.0020  memory: 2944  
2023/05/23 23:48:42 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:11  time: 0.0818  data_time: 0.0018  memory: 2356  
2023/05/23 23:48:46 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0780  data_time: 0.0016  memory: 2217  
2023/05/23 23:48:50 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0781  data_time: 0.0017  memory: 2328  
2023/05/23 23:48:54 - mmengine - INFO - per class results:
2023/05/23 23:48:54 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.36 | 92.49 |
|     bicycle      | 66.04 | 81.52 |
|       car        | 57.56 | 88.36 |
|    motorcycle    | 82.47 | 90.36 |
|     airplane     | 82.98 | 91.37 |
|       bus        |  78.1 | 87.41 |
|      train       | 82.39 | 93.85 |
|      truck       | 50.67 | 64.37 |
|       boat       | 59.11 | 73.33 |
|  traffic light   | 66.71 | 81.47 |
|   fire hydrant   | 82.64 | 94.84 |
|    stop sign     | 91.33 | 96.53 |
|  parking meter   | 81.17 | 85.78 |
|      bench       |  42.8 | 69.38 |
|       bird       | 81.23 | 90.52 |
|       cat        | 83.49 | 89.14 |
|       dog        | 73.95 |  82.5 |
|      horse       |  76.7 | 89.64 |
|      sheep       | 85.53 | 92.69 |
|       cow        | 79.44 | 87.39 |
|     elephant     |  89.8 | 94.72 |
|       bear       | 92.07 | 94.79 |
|      zebra       | 90.11 |  93.4 |
|     giraffe      | 87.04 | 92.92 |
|     backpack     |  29.6 | 54.33 |
|     umbrella     | 76.36 | 87.33 |
|     handbag      |  30.4 | 54.83 |
|       tie        | 10.15 | 11.92 |
|     suitcase     | 70.65 | 93.68 |
|     frisbee      | 71.25 |  88.8 |
|       skis       | 37.18 | 51.04 |
|    snowboard     | 41.96 | 61.37 |
|   sports ball    | 45.11 | 74.68 |
|       kite       | 51.94 | 62.35 |
|   baseball bat   | 45.91 | 74.49 |
|  baseball glove  | 66.51 | 87.69 |
|    skateboard    | 68.62 | 86.88 |
|    surfboard     | 74.14 | 86.07 |
|  tennis racket   | 82.49 | 89.62 |
|      bottle      | 51.44 | 74.55 |
|    wine glass    | 53.66 | 79.15 |
|       cup        | 53.69 | 75.03 |
|       fork       | 28.99 | 36.03 |
|      knife       | 24.43 | 35.25 |
|      spoon       | 24.82 | 30.53 |
|       bowl       | 45.97 | 62.88 |
|      banana      | 68.75 | 89.14 |
|      apple       | 50.19 | 69.48 |
|     sandwich     | 42.41 | 65.05 |
|      orange      | 72.38 | 84.82 |
|     broccoli     | 52.39 | 64.42 |
|      carrot      | 49.01 | 55.99 |
|     hot dog      | 47.94 | 62.42 |
|      pizza       | 69.81 | 84.56 |
|      donut       | 66.16 | 80.88 |
|       cake       | 58.28 | 73.61 |
|      chair       | 39.45 | 53.88 |
|      couch       | 46.32 | 85.65 |
|   potted plant   |  32.3 | 59.37 |
|       bed        |  60.0 | 82.37 |
|   dining table   | 40.51 | 74.91 |
|      toilet      | 78.37 | 92.34 |
|        tv        | 70.84 | 81.38 |
|      laptop      | 71.97 |  90.7 |
|      mouse       | 63.83 | 89.65 |
|      remote      | 60.37 | 71.57 |
|     keyboard     | 58.07 | 68.03 |
|    cell phone    | 70.52 | 89.11 |
|    microwave     |  65.4 | 75.94 |
|       oven       | 51.08 | 79.44 |
|     toaster      | 23.68 | 30.17 |
|       sink       | 58.91 | 77.84 |
|   refrigerator   | 77.02 | 89.24 |
|       book       | 46.34 | 62.77 |
|      clock       | 71.93 | 80.57 |
|       vase       | 57.31 | 81.14 |
|     scissors     | 59.08 |  68.0 |
|    teddy bear    |  73.5 | 85.44 |
|    hair drier    | 41.63 | 42.43 |
|    toothbrush    | 15.48 | 68.72 |
|      banner      | 34.91 | 65.43 |
|     blanket      |  0.24 |  0.26 |
|      branch      | 18.63 | 25.78 |
|      bridge      | 31.16 | 46.07 |
|  building-other  | 50.94 | 65.02 |
|       bush       | 33.33 | 47.41 |
|     cabinet      | 49.94 | 71.44 |
|       cage       | 16.86 |  29.3 |
|    cardboard     |  37.7 | 47.32 |
|      carpet      | 52.03 | 71.82 |
|  ceiling-other   |  62.8 |  83.9 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 18.83 | 29.73 |
|      clouds      | 42.33 | 54.76 |
|     counter      |  27.9 | 42.75 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 60.97 | 78.32 |
|    desk-stuff    | 47.29 | 64.25 |
|       dirt       | 41.53 | 65.97 |
|    door-stuff    | 34.57 | 59.35 |
|      fence       | 27.73 | 47.37 |
|   floor-marble   |  5.76 |  6.42 |
|   floor-other    | 20.09 | 26.52 |
|   floor-stone    |  4.76 |  6.73 |
|    floor-tile    | 59.56 | 70.03 |
|    floor-wood    | 57.09 | 75.27 |
|      flower      | 40.68 | 53.99 |
|       fog        |  0.04 |  0.04 |
|    food-other    | 25.95 | 34.54 |
|      fruit       | 33.38 | 49.86 |
| furniture-other  | 16.01 | 24.66 |
|      grass       | 69.02 | 83.37 |
|      gravel      | 27.29 | 38.64 |
|   ground-other   |  1.67 |  1.81 |
|       hill       | 19.37 | 28.76 |
|      house       | 23.83 | 30.04 |
|      leaves      | 28.43 |  40.0 |
|      light       | 35.75 | 50.78 |
|       mat        |  0.0  |  0.0  |
|      metal       |  31.6 | 44.45 |
|   mirror-stuff   | 43.77 | 54.63 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 48.04 |  64.4 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  3.65 |  3.82 |
|       net        | 42.05 |  63.3 |
|      paper       | 28.75 | 39.22 |
|     pavement     | 49.86 | 70.06 |
|      pillow      |  6.0  |  7.26 |
|   plant-other    | 17.93 | 23.32 |
|     plastic      | 15.91 | 21.45 |
|     platform     | 26.78 | 44.78 |
|   playingfield   | 69.07 |  90.3 |
|     railing      |  2.47 |  3.71 |
|     railroad     | 60.53 | 77.98 |
|      river       | 31.64 | 34.91 |
|       road       | 63.65 |  79.3 |
|       rock       |  36.7 | 55.52 |
|       roof       | 15.97 | 21.17 |
|       rug        | 33.23 | 45.49 |
|      salad       |  0.0  |  0.0  |
|       sand       |  59.0 | 65.43 |
|       sea        | 84.75 |  92.2 |
|      shelf       | 28.82 | 36.32 |
|    sky-other     | 69.04 |  88.1 |
|    skyscraper    | 35.24 | 43.77 |
|       snow       | 88.82 | 91.69 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      |  20.3 |  36.2 |
|      stone       | 15.06 | 31.06 |
|      straw       | 25.41 | 31.29 |
| structural-other |  0.0  |  0.0  |
|      table       | 14.58 |  17.1 |
|       tent       |  6.96 |  8.49 |
|  textile-other   | 10.86 | 20.32 |
|      towel       | 29.34 | 41.28 |
|       tree       | 73.29 | 87.46 |
|    vegetable     | 33.11 | 45.27 |
|    wall-brick    | 41.13 | 62.47 |
|  wall-concrete   | 58.04 | 81.21 |
|    wall-other    | 16.35 |  23.3 |
|    wall-panel    |  2.74 |  2.98 |
|    wall-stone    | 28.82 | 39.49 |
|    wall-tile     | 64.42 | 81.16 |
|    wall-wood     | 38.06 | 54.85 |
|   water-other    |  33.2 | 63.57 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 48.12 | 57.88 |
|   window-other   | 44.74 | 67.72 |
|       wood       | 26.24 | 38.04 |
+------------------+-------+-------+
2023/05/23 23:48:54 - mmengine - INFO - Iter(val) [625/625]    aAcc: 69.8700  mIoU: 44.6100  mAcc: 57.5400  data_time: 0.0021  time: 0.0873
2023/05/23 23:48:54 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_35000.pth is removed
2023/05/23 23:48:57 - mmengine - INFO - The best checkpoint with 44.6100 mIoU at 45000 iter is saved to best_mIoU_iter_45000.pth.
2023/05/23 23:49:18 - mmengine - INFO - Iter(train) [ 45050/160000]  lr: 7.4260e-06  eta: 13:39:09  time: 0.4215  data_time: 0.0104  memory: 4837  grad_norm: 111.9621  loss: 43.6982  decode.loss_cls: 1.6195  decode.loss_mask: 0.9210  decode.loss_dice: 1.4481  decode.d0.loss_cls: 3.5539  decode.d0.loss_mask: 1.0946  decode.d0.loss_dice: 1.8109  decode.d1.loss_cls: 1.7767  decode.d1.loss_mask: 1.0758  decode.d1.loss_dice: 1.6667  decode.d2.loss_cls: 1.5865  decode.d2.loss_mask: 1.0732  decode.d2.loss_dice: 1.5924  decode.d3.loss_cls: 1.6257  decode.d3.loss_mask: 0.9864  decode.d3.loss_dice: 1.4994  decode.d4.loss_cls: 1.6310  decode.d4.loss_mask: 1.0158  decode.d4.loss_dice: 1.5170  decode.d5.loss_cls: 1.5909  decode.d5.loss_mask: 0.9764  decode.d5.loss_dice: 1.5037  decode.d6.loss_cls: 1.6470  decode.d6.loss_mask: 0.9237  decode.d6.loss_dice: 1.4394  decode.d7.loss_cls: 1.6014  decode.d7.loss_mask: 0.9640  decode.d7.loss_dice: 1.4781  decode.d8.loss_cls: 1.6729  decode.d8.loss_mask: 0.9472  decode.d8.loss_dice: 1.4588
2023/05/23 23:49:39 - mmengine - INFO - Iter(train) [ 45100/160000]  lr: 7.4231e-06  eta: 13:38:46  time: 0.4188  data_time: 0.0100  memory: 4940  grad_norm: 119.7437  loss: 33.5625  decode.loss_cls: 1.1668  decode.loss_mask: 0.8024  decode.loss_dice: 1.2074  decode.d0.loss_cls: 3.0029  decode.d0.loss_mask: 0.7854  decode.d0.loss_dice: 1.3006  decode.d1.loss_cls: 1.2397  decode.d1.loss_mask: 0.7641  decode.d1.loss_dice: 1.2455  decode.d2.loss_cls: 1.2443  decode.d2.loss_mask: 0.7728  decode.d2.loss_dice: 1.2524  decode.d3.loss_cls: 1.2497  decode.d3.loss_mask: 0.7413  decode.d3.loss_dice: 1.1677  decode.d4.loss_cls: 1.1943  decode.d4.loss_mask: 0.7590  decode.d4.loss_dice: 1.1767  decode.d5.loss_cls: 1.1608  decode.d5.loss_mask: 0.7794  decode.d5.loss_dice: 1.2101  decode.d6.loss_cls: 1.1344  decode.d6.loss_mask: 0.7691  decode.d6.loss_dice: 1.2009  decode.d7.loss_cls: 1.1714  decode.d7.loss_mask: 0.7456  decode.d7.loss_dice: 1.2012  decode.d8.loss_cls: 1.1278  decode.d8.loss_mask: 0.7729  decode.d8.loss_dice: 1.2156
2023/05/23 23:50:00 - mmengine - INFO - Iter(train) [ 45150/160000]  lr: 7.4201e-06  eta: 13:38:23  time: 0.4259  data_time: 0.0100  memory: 4919  grad_norm: 105.1500  loss: 38.4590  decode.loss_cls: 1.3767  decode.loss_mask: 0.7984  decode.loss_dice: 1.3819  decode.d0.loss_cls: 3.4015  decode.d0.loss_mask: 0.8999  decode.d0.loss_dice: 1.7558  decode.d1.loss_cls: 1.5707  decode.d1.loss_mask: 0.8166  decode.d1.loss_dice: 1.5341  decode.d2.loss_cls: 1.4185  decode.d2.loss_mask: 0.8058  decode.d2.loss_dice: 1.4205  decode.d3.loss_cls: 1.3946  decode.d3.loss_mask: 0.7893  decode.d3.loss_dice: 1.3851  decode.d4.loss_cls: 1.3207  decode.d4.loss_mask: 0.8259  decode.d4.loss_dice: 1.3800  decode.d5.loss_cls: 1.3498  decode.d5.loss_mask: 0.8091  decode.d5.loss_dice: 1.3947  decode.d6.loss_cls: 1.3405  decode.d6.loss_mask: 0.8016  decode.d6.loss_dice: 1.3900  decode.d7.loss_cls: 1.3220  decode.d7.loss_mask: 0.8349  decode.d7.loss_dice: 1.3956  decode.d8.loss_cls: 1.3643  decode.d8.loss_mask: 0.7999  decode.d8.loss_dice: 1.3806
2023/05/23 23:50:21 - mmengine - INFO - Iter(train) [ 45200/160000]  lr: 7.4172e-06  eta: 13:38:02  time: 0.4502  data_time: 0.0100  memory: 4837  grad_norm: 104.1207  loss: 38.1262  decode.loss_cls: 1.2315  decode.loss_mask: 0.9857  decode.loss_dice: 1.3158  decode.d0.loss_cls: 3.2293  decode.d0.loss_mask: 1.0623  decode.d0.loss_dice: 1.5117  decode.d1.loss_cls: 1.3533  decode.d1.loss_mask: 1.0485  decode.d1.loss_dice: 1.4439  decode.d2.loss_cls: 1.2696  decode.d2.loss_mask: 1.0470  decode.d2.loss_dice: 1.3886  decode.d3.loss_cls: 1.2589  decode.d3.loss_mask: 0.9645  decode.d3.loss_dice: 1.3368  decode.d4.loss_cls: 1.1783  decode.d4.loss_mask: 0.9974  decode.d4.loss_dice: 1.3816  decode.d5.loss_cls: 1.2137  decode.d5.loss_mask: 0.9653  decode.d5.loss_dice: 1.3345  decode.d6.loss_cls: 1.2201  decode.d6.loss_mask: 0.9895  decode.d6.loss_dice: 1.3086  decode.d7.loss_cls: 1.1880  decode.d7.loss_mask: 1.0207  decode.d7.loss_dice: 1.3473  decode.d8.loss_cls: 1.2136  decode.d8.loss_mask: 0.9959  decode.d8.loss_dice: 1.3242
2023/05/23 23:50:44 - mmengine - INFO - Iter(train) [ 45250/160000]  lr: 7.4143e-06  eta: 13:37:44  time: 0.4686  data_time: 0.0095  memory: 4804  grad_norm: 141.6957  loss: 38.4095  decode.loss_cls: 1.3656  decode.loss_mask: 0.8609  decode.loss_dice: 1.3735  decode.d0.loss_cls: 3.0240  decode.d0.loss_mask: 0.8847  decode.d0.loss_dice: 1.5504  decode.d1.loss_cls: 1.6055  decode.d1.loss_mask: 0.9130  decode.d1.loss_dice: 1.4467  decode.d2.loss_cls: 1.4417  decode.d2.loss_mask: 0.8760  decode.d2.loss_dice: 1.4103  decode.d3.loss_cls: 1.4259  decode.d3.loss_mask: 0.8560  decode.d3.loss_dice: 1.3795  decode.d4.loss_cls: 1.3567  decode.d4.loss_mask: 0.8788  decode.d4.loss_dice: 1.3722  decode.d5.loss_cls: 1.3292  decode.d5.loss_mask: 0.8852  decode.d5.loss_dice: 1.3834  decode.d6.loss_cls: 1.3023  decode.d6.loss_mask: 0.9224  decode.d6.loss_dice: 1.3818  decode.d7.loss_cls: 1.3329  decode.d7.loss_mask: 0.8649  decode.d7.loss_dice: 1.4023  decode.d8.loss_cls: 1.3406  decode.d8.loss_mask: 0.8563  decode.d8.loss_dice: 1.3869
2023/05/23 23:51:05 - mmengine - INFO - Iter(train) [ 45300/160000]  lr: 7.4114e-06  eta: 13:37:22  time: 0.4202  data_time: 0.0102  memory: 4948  grad_norm: 81.7989  loss: 50.1151  decode.loss_cls: 1.7995  decode.loss_mask: 0.8206  decode.loss_dice: 2.0229  decode.d0.loss_cls: 3.8076  decode.d0.loss_mask: 0.8437  decode.d0.loss_dice: 2.3123  decode.d1.loss_cls: 1.8978  decode.d1.loss_mask: 0.8727  decode.d1.loss_dice: 2.2734  decode.d2.loss_cls: 1.8632  decode.d2.loss_mask: 0.8375  decode.d2.loss_dice: 2.1378  decode.d3.loss_cls: 1.8396  decode.d3.loss_mask: 0.8511  decode.d3.loss_dice: 2.0770  decode.d4.loss_cls: 1.8584  decode.d4.loss_mask: 0.8784  decode.d4.loss_dice: 2.1092  decode.d5.loss_cls: 1.7953  decode.d5.loss_mask: 0.8695  decode.d5.loss_dice: 2.0967  decode.d6.loss_cls: 1.8467  decode.d6.loss_mask: 0.8514  decode.d6.loss_dice: 2.0644  decode.d7.loss_cls: 1.8253  decode.d7.loss_mask: 0.8639  decode.d7.loss_dice: 2.0854  decode.d8.loss_cls: 1.8219  decode.d8.loss_mask: 0.8618  decode.d8.loss_dice: 2.0301
2023/05/23 23:51:27 - mmengine - INFO - Iter(train) [ 45350/160000]  lr: 7.4085e-06  eta: 13:37:01  time: 0.4187  data_time: 0.0099  memory: 4822  grad_norm: 97.0811  loss: 29.6733  decode.loss_cls: 0.9180  decode.loss_mask: 0.6873  decode.loss_dice: 1.1021  decode.d0.loss_cls: 2.5990  decode.d0.loss_mask: 0.7146  decode.d0.loss_dice: 1.3327  decode.d1.loss_cls: 1.0707  decode.d1.loss_mask: 0.7257  decode.d1.loss_dice: 1.1925  decode.d2.loss_cls: 0.9605  decode.d2.loss_mask: 0.7318  decode.d2.loss_dice: 1.1261  decode.d3.loss_cls: 0.9563  decode.d3.loss_mask: 0.7122  decode.d3.loss_dice: 1.1004  decode.d4.loss_cls: 1.0026  decode.d4.loss_mask: 0.7145  decode.d4.loss_dice: 1.1125  decode.d5.loss_cls: 0.8763  decode.d5.loss_mask: 0.7164  decode.d5.loss_dice: 1.1073  decode.d6.loss_cls: 0.9285  decode.d6.loss_mask: 0.6971  decode.d6.loss_dice: 1.1138  decode.d7.loss_cls: 0.9199  decode.d7.loss_mask: 0.6976  decode.d7.loss_dice: 1.1289  decode.d8.loss_cls: 0.9139  decode.d8.loss_mask: 0.6889  decode.d8.loss_dice: 1.1252
2023/05/23 23:51:48 - mmengine - INFO - Iter(train) [ 45400/160000]  lr: 7.4056e-06  eta: 13:36:39  time: 0.4196  data_time: 0.0101  memory: 4890  grad_norm: 130.5428  loss: 38.7798  decode.loss_cls: 1.4896  decode.loss_mask: 0.8075  decode.loss_dice: 1.3373  decode.d0.loss_cls: 3.6254  decode.d0.loss_mask: 0.7968  decode.d0.loss_dice: 1.5496  decode.d1.loss_cls: 1.7922  decode.d1.loss_mask: 0.8034  decode.d1.loss_dice: 1.4078  decode.d2.loss_cls: 1.4863  decode.d2.loss_mask: 0.7813  decode.d2.loss_dice: 1.3572  decode.d3.loss_cls: 1.5344  decode.d3.loss_mask: 0.7655  decode.d3.loss_dice: 1.2983  decode.d4.loss_cls: 1.4644  decode.d4.loss_mask: 0.7981  decode.d4.loss_dice: 1.3250  decode.d5.loss_cls: 1.4101  decode.d5.loss_mask: 0.8155  decode.d5.loss_dice: 1.3325  decode.d6.loss_cls: 1.5882  decode.d6.loss_mask: 0.7973  decode.d6.loss_dice: 1.2988  decode.d7.loss_cls: 1.4130  decode.d7.loss_mask: 0.8282  decode.d7.loss_dice: 1.3195  decode.d8.loss_cls: 1.4586  decode.d8.loss_mask: 0.7798  decode.d8.loss_dice: 1.3181
2023/05/23 23:52:09 - mmengine - INFO - Iter(train) [ 45450/160000]  lr: 7.4027e-06  eta: 13:36:17  time: 0.4149  data_time: 0.0100  memory: 4890  grad_norm: 95.3487  loss: 32.0582  decode.loss_cls: 1.0730  decode.loss_mask: 0.6870  decode.loss_dice: 1.1928  decode.d0.loss_cls: 3.1345  decode.d0.loss_mask: 0.6979  decode.d0.loss_dice: 1.3165  decode.d1.loss_cls: 1.1531  decode.d1.loss_mask: 0.7166  decode.d1.loss_dice: 1.2770  decode.d2.loss_cls: 1.1442  decode.d2.loss_mask: 0.6995  decode.d2.loss_dice: 1.2250  decode.d3.loss_cls: 1.0649  decode.d3.loss_mask: 0.6986  decode.d3.loss_dice: 1.1973  decode.d4.loss_cls: 1.1163  decode.d4.loss_mask: 0.6901  decode.d4.loss_dice: 1.1840  decode.d5.loss_cls: 1.1001  decode.d5.loss_mask: 0.6969  decode.d5.loss_dice: 1.1509  decode.d6.loss_cls: 1.0896  decode.d6.loss_mask: 0.6810  decode.d6.loss_dice: 1.1605  decode.d7.loss_cls: 1.0681  decode.d7.loss_mask: 0.7012  decode.d7.loss_dice: 1.1662  decode.d8.loss_cls: 1.0936  decode.d8.loss_mask: 0.7001  decode.d8.loss_dice: 1.1815
2023/05/23 23:52:31 - mmengine - INFO - Iter(train) [ 45500/160000]  lr: 7.3998e-06  eta: 13:35:58  time: 0.4393  data_time: 0.0100  memory: 4816  grad_norm: 113.6087  loss: 40.2778  decode.loss_cls: 1.3470  decode.loss_mask: 0.8205  decode.loss_dice: 1.5733  decode.d0.loss_cls: 3.3676  decode.d0.loss_mask: 0.8226  decode.d0.loss_dice: 1.7444  decode.d1.loss_cls: 1.4845  decode.d1.loss_mask: 0.8358  decode.d1.loss_dice: 1.6589  decode.d2.loss_cls: 1.4144  decode.d2.loss_mask: 0.8452  decode.d2.loss_dice: 1.6173  decode.d3.loss_cls: 1.4405  decode.d3.loss_mask: 0.8501  decode.d3.loss_dice: 1.5335  decode.d4.loss_cls: 1.3909  decode.d4.loss_mask: 0.8260  decode.d4.loss_dice: 1.5650  decode.d5.loss_cls: 1.4118  decode.d5.loss_mask: 0.8417  decode.d5.loss_dice: 1.5445  decode.d6.loss_cls: 1.4789  decode.d6.loss_mask: 0.8011  decode.d6.loss_dice: 1.5095  decode.d7.loss_cls: 1.4254  decode.d7.loss_mask: 0.8197  decode.d7.loss_dice: 1.5364  decode.d8.loss_cls: 1.3568  decode.d8.loss_mask: 0.8626  decode.d8.loss_dice: 1.5520
2023/05/23 23:52:52 - mmengine - INFO - Iter(train) [ 45550/160000]  lr: 7.3969e-06  eta: 13:35:35  time: 0.4102  data_time: 0.0098  memory: 4849  grad_norm: 95.0501  loss: 28.3163  decode.loss_cls: 0.9720  decode.loss_mask: 0.6114  decode.loss_dice: 1.0993  decode.d0.loss_cls: 2.4414  decode.d0.loss_mask: 0.5942  decode.d0.loss_dice: 1.2124  decode.d1.loss_cls: 0.9851  decode.d1.loss_mask: 0.5962  decode.d1.loss_dice: 1.1659  decode.d2.loss_cls: 0.9936  decode.d2.loss_mask: 0.5924  decode.d2.loss_dice: 1.1181  decode.d3.loss_cls: 0.9646  decode.d3.loss_mask: 0.6172  decode.d3.loss_dice: 1.0780  decode.d4.loss_cls: 0.9190  decode.d4.loss_mask: 0.5977  decode.d4.loss_dice: 1.1075  decode.d5.loss_cls: 0.9801  decode.d5.loss_mask: 0.5747  decode.d5.loss_dice: 1.0903  decode.d6.loss_cls: 0.9456  decode.d6.loss_mask: 0.6192  decode.d6.loss_dice: 1.1023  decode.d7.loss_cls: 0.9502  decode.d7.loss_mask: 0.6169  decode.d7.loss_dice: 1.1106  decode.d8.loss_cls: 0.9804  decode.d8.loss_mask: 0.6048  decode.d8.loss_dice: 1.0753
2023/05/23 23:53:13 - mmengine - INFO - Iter(train) [ 45600/160000]  lr: 7.3940e-06  eta: 13:35:13  time: 0.4194  data_time: 0.0096  memory: 4846  grad_norm: 85.4316  loss: 38.6242  decode.loss_cls: 1.4942  decode.loss_mask: 0.8264  decode.loss_dice: 1.3016  decode.d0.loss_cls: 3.3878  decode.d0.loss_mask: 0.8401  decode.d0.loss_dice: 1.4226  decode.d1.loss_cls: 1.6792  decode.d1.loss_mask: 0.8260  decode.d1.loss_dice: 1.3479  decode.d2.loss_cls: 1.5704  decode.d2.loss_mask: 0.8281  decode.d2.loss_dice: 1.3353  decode.d3.loss_cls: 1.5191  decode.d3.loss_mask: 0.8309  decode.d3.loss_dice: 1.2993  decode.d4.loss_cls: 1.4989  decode.d4.loss_mask: 0.8430  decode.d4.loss_dice: 1.3151  decode.d5.loss_cls: 1.4959  decode.d5.loss_mask: 0.8404  decode.d5.loss_dice: 1.3102  decode.d6.loss_cls: 1.4816  decode.d6.loss_mask: 0.8329  decode.d6.loss_dice: 1.2999  decode.d7.loss_cls: 1.4934  decode.d7.loss_mask: 0.8285  decode.d7.loss_dice: 1.2961  decode.d8.loss_cls: 1.4490  decode.d8.loss_mask: 0.8213  decode.d8.loss_dice: 1.3089
2023/05/23 23:53:34 - mmengine - INFO - Iter(train) [ 45650/160000]  lr: 7.3911e-06  eta: 13:34:51  time: 0.4202  data_time: 0.0100  memory: 4863  grad_norm: 92.5249  loss: 37.0819  decode.loss_cls: 1.1602  decode.loss_mask: 0.9550  decode.loss_dice: 1.3407  decode.d0.loss_cls: 2.8448  decode.d0.loss_mask: 1.0356  decode.d0.loss_dice: 1.4715  decode.d1.loss_cls: 1.3643  decode.d1.loss_mask: 0.9676  decode.d1.loss_dice: 1.4259  decode.d2.loss_cls: 1.3276  decode.d2.loss_mask: 0.9875  decode.d2.loss_dice: 1.3691  decode.d3.loss_cls: 1.3142  decode.d3.loss_mask: 0.9792  decode.d3.loss_dice: 1.3387  decode.d4.loss_cls: 1.1894  decode.d4.loss_mask: 0.9900  decode.d4.loss_dice: 1.3570  decode.d5.loss_cls: 1.1540  decode.d5.loss_mask: 0.9467  decode.d5.loss_dice: 1.3474  decode.d6.loss_cls: 1.1276  decode.d6.loss_mask: 0.9589  decode.d6.loss_dice: 1.3495  decode.d7.loss_cls: 1.1213  decode.d7.loss_mask: 0.9447  decode.d7.loss_dice: 1.3350  decode.d8.loss_cls: 1.0849  decode.d8.loss_mask: 0.9476  decode.d8.loss_dice: 1.3460
2023/05/23 23:53:55 - mmengine - INFO - Iter(train) [ 45700/160000]  lr: 7.3882e-06  eta: 13:34:29  time: 0.4201  data_time: 0.0100  memory: 4865  grad_norm: 99.3653  loss: 43.0842  decode.loss_cls: 1.4464  decode.loss_mask: 0.8969  decode.loss_dice: 1.6961  decode.d0.loss_cls: 3.2884  decode.d0.loss_mask: 0.9815  decode.d0.loss_dice: 1.9462  decode.d1.loss_cls: 1.4141  decode.d1.loss_mask: 0.9550  decode.d1.loss_dice: 1.8554  decode.d2.loss_cls: 1.5029  decode.d2.loss_mask: 0.9231  decode.d2.loss_dice: 1.7351  decode.d3.loss_cls: 1.4403  decode.d3.loss_mask: 0.9212  decode.d3.loss_dice: 1.7609  decode.d4.loss_cls: 1.4023  decode.d4.loss_mask: 0.9353  decode.d4.loss_dice: 1.7644  decode.d5.loss_cls: 1.4130  decode.d5.loss_mask: 0.9157  decode.d5.loss_dice: 1.7183  decode.d6.loss_cls: 1.4004  decode.d6.loss_mask: 0.9413  decode.d6.loss_dice: 1.7286  decode.d7.loss_cls: 1.4206  decode.d7.loss_mask: 0.9110  decode.d7.loss_dice: 1.7344  decode.d8.loss_cls: 1.4293  decode.d8.loss_mask: 0.9069  decode.d8.loss_dice: 1.6991
2023/05/23 23:54:16 - mmengine - INFO - Iter(train) [ 45750/160000]  lr: 7.3852e-06  eta: 13:34:06  time: 0.4094  data_time: 0.0098  memory: 4908  grad_norm: 98.4439  loss: 37.3498  decode.loss_cls: 1.4270  decode.loss_mask: 0.7888  decode.loss_dice: 1.1985  decode.d0.loss_cls: 3.3525  decode.d0.loss_mask: 0.8771  decode.d0.loss_dice: 1.4550  decode.d1.loss_cls: 1.5254  decode.d1.loss_mask: 0.8327  decode.d1.loss_dice: 1.4148  decode.d2.loss_cls: 1.4686  decode.d2.loss_mask: 0.7984  decode.d2.loss_dice: 1.3673  decode.d3.loss_cls: 1.4395  decode.d3.loss_mask: 0.7681  decode.d3.loss_dice: 1.3083  decode.d4.loss_cls: 1.4052  decode.d4.loss_mask: 0.7708  decode.d4.loss_dice: 1.3184  decode.d5.loss_cls: 1.3830  decode.d5.loss_mask: 0.7639  decode.d5.loss_dice: 1.2976  decode.d6.loss_cls: 1.3293  decode.d6.loss_mask: 0.7860  decode.d6.loss_dice: 1.2785  decode.d7.loss_cls: 1.4028  decode.d7.loss_mask: 0.8030  decode.d7.loss_dice: 1.2980  decode.d8.loss_cls: 1.4012  decode.d8.loss_mask: 0.7913  decode.d8.loss_dice: 1.2987
2023/05/23 23:54:37 - mmengine - INFO - Iter(train) [ 45800/160000]  lr: 7.3823e-06  eta: 13:33:42  time: 0.4162  data_time: 0.0098  memory: 4837  grad_norm: 112.2190  loss: 32.9721  decode.loss_cls: 1.0264  decode.loss_mask: 0.7330  decode.loss_dice: 1.2578  decode.d0.loss_cls: 2.9517  decode.d0.loss_mask: 0.8127  decode.d0.loss_dice: 1.4618  decode.d1.loss_cls: 1.1376  decode.d1.loss_mask: 0.7751  decode.d1.loss_dice: 1.3658  decode.d2.loss_cls: 1.0274  decode.d2.loss_mask: 0.7564  decode.d2.loss_dice: 1.3231  decode.d3.loss_cls: 1.0822  decode.d3.loss_mask: 0.7256  decode.d3.loss_dice: 1.2820  decode.d4.loss_cls: 1.0152  decode.d4.loss_mask: 0.7321  decode.d4.loss_dice: 1.3002  decode.d5.loss_cls: 1.0022  decode.d5.loss_mask: 0.7255  decode.d5.loss_dice: 1.3055  decode.d6.loss_cls: 1.0588  decode.d6.loss_mask: 0.7111  decode.d6.loss_dice: 1.2658  decode.d7.loss_cls: 1.0567  decode.d7.loss_mask: 0.7432  decode.d7.loss_dice: 1.2983  decode.d8.loss_cls: 1.0594  decode.d8.loss_mask: 0.7095  decode.d8.loss_dice: 1.2700
2023/05/23 23:54:58 - mmengine - INFO - Iter(train) [ 45850/160000]  lr: 7.3794e-06  eta: 13:33:20  time: 0.4311  data_time: 0.0103  memory: 4886  grad_norm: 107.0238  loss: 44.2142  decode.loss_cls: 1.4155  decode.loss_mask: 0.9390  decode.loss_dice: 1.7365  decode.d0.loss_cls: 3.8301  decode.d0.loss_mask: 0.9015  decode.d0.loss_dice: 1.9414  decode.d1.loss_cls: 1.6694  decode.d1.loss_mask: 0.9172  decode.d1.loss_dice: 1.7945  decode.d2.loss_cls: 1.5079  decode.d2.loss_mask: 0.9422  decode.d2.loss_dice: 1.7581  decode.d3.loss_cls: 1.4814  decode.d3.loss_mask: 0.9407  decode.d3.loss_dice: 1.7314  decode.d4.loss_cls: 1.4549  decode.d4.loss_mask: 0.9468  decode.d4.loss_dice: 1.7247  decode.d5.loss_cls: 1.4678  decode.d5.loss_mask: 0.9163  decode.d5.loss_dice: 1.7371  decode.d6.loss_cls: 1.4618  decode.d6.loss_mask: 0.9144  decode.d6.loss_dice: 1.7215  decode.d7.loss_cls: 1.5055  decode.d7.loss_mask: 0.9343  decode.d7.loss_dice: 1.7589  decode.d8.loss_cls: 1.4944  decode.d8.loss_mask: 0.9249  decode.d8.loss_dice: 1.7440
2023/05/23 23:55:19 - mmengine - INFO - Iter(train) [ 45900/160000]  lr: 7.3765e-06  eta: 13:32:58  time: 0.4175  data_time: 0.0102  memory: 4888  grad_norm: 96.9375  loss: 39.9734  decode.loss_cls: 1.4561  decode.loss_mask: 0.9196  decode.loss_dice: 1.3064  decode.d0.loss_cls: 3.2223  decode.d0.loss_mask: 1.0271  decode.d0.loss_dice: 1.5354  decode.d1.loss_cls: 1.6054  decode.d1.loss_mask: 0.9983  decode.d1.loss_dice: 1.4909  decode.d2.loss_cls: 1.4893  decode.d2.loss_mask: 0.9501  decode.d2.loss_dice: 1.3989  decode.d3.loss_cls: 1.5575  decode.d3.loss_mask: 0.9151  decode.d3.loss_dice: 1.3345  decode.d4.loss_cls: 1.5307  decode.d4.loss_mask: 0.9037  decode.d4.loss_dice: 1.3270  decode.d5.loss_cls: 1.4976  decode.d5.loss_mask: 0.9254  decode.d5.loss_dice: 1.3143  decode.d6.loss_cls: 1.4514  decode.d6.loss_mask: 0.9537  decode.d6.loss_dice: 1.3175  decode.d7.loss_cls: 1.5192  decode.d7.loss_mask: 0.9385  decode.d7.loss_dice: 1.2994  decode.d8.loss_cls: 1.5823  decode.d8.loss_mask: 0.9197  decode.d8.loss_dice: 1.2862
2023/05/23 23:55:40 - mmengine - INFO - Iter(train) [ 45950/160000]  lr: 7.3736e-06  eta: 13:32:35  time: 0.4229  data_time: 0.0097  memory: 4904  grad_norm: 91.9697  loss: 29.2235  decode.loss_cls: 1.0596  decode.loss_mask: 0.6044  decode.loss_dice: 0.9448  decode.d0.loss_cls: 2.9031  decode.d0.loss_mask: 0.6854  decode.d0.loss_dice: 1.1165  decode.d1.loss_cls: 1.2905  decode.d1.loss_mask: 0.6826  decode.d1.loss_dice: 1.0185  decode.d2.loss_cls: 1.2164  decode.d2.loss_mask: 0.6798  decode.d2.loss_dice: 0.9931  decode.d3.loss_cls: 1.1399  decode.d3.loss_mask: 0.6758  decode.d3.loss_dice: 0.9739  decode.d4.loss_cls: 1.0606  decode.d4.loss_mask: 0.6483  decode.d4.loss_dice: 0.9727  decode.d5.loss_cls: 1.0954  decode.d5.loss_mask: 0.6215  decode.d5.loss_dice: 1.0186  decode.d6.loss_cls: 1.0142  decode.d6.loss_mask: 0.6386  decode.d6.loss_dice: 0.9676  decode.d7.loss_cls: 1.0358  decode.d7.loss_mask: 0.6149  decode.d7.loss_dice: 0.9630  decode.d8.loss_cls: 1.0203  decode.d8.loss_mask: 0.6198  decode.d8.loss_dice: 0.9476
2023/05/23 23:56:00 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/23 23:56:00 - mmengine - INFO - Iter(train) [ 46000/160000]  lr: 7.3707e-06  eta: 13:32:12  time: 0.4124  data_time: 0.0106  memory: 4893  grad_norm: 103.0966  loss: 42.1251  decode.loss_cls: 1.6542  decode.loss_mask: 0.8013  decode.loss_dice: 1.3942  decode.d0.loss_cls: 3.6612  decode.d0.loss_mask: 0.9303  decode.d0.loss_dice: 1.7151  decode.d1.loss_cls: 1.8099  decode.d1.loss_mask: 0.8769  decode.d1.loss_dice: 1.5774  decode.d2.loss_cls: 1.7745  decode.d2.loss_mask: 0.8350  decode.d2.loss_dice: 1.5247  decode.d3.loss_cls: 1.7884  decode.d3.loss_mask: 0.8293  decode.d3.loss_dice: 1.4303  decode.d4.loss_cls: 1.7286  decode.d4.loss_mask: 0.8294  decode.d4.loss_dice: 1.4446  decode.d5.loss_cls: 1.6827  decode.d5.loss_mask: 0.8279  decode.d5.loss_dice: 1.4012  decode.d6.loss_cls: 1.6931  decode.d6.loss_mask: 0.8052  decode.d6.loss_dice: 1.4124  decode.d7.loss_cls: 1.6187  decode.d7.loss_mask: 0.8200  decode.d7.loss_dice: 1.4202  decode.d8.loss_cls: 1.6104  decode.d8.loss_mask: 0.8057  decode.d8.loss_dice: 1.4223
2023/05/23 23:56:00 - mmengine - INFO - Saving checkpoint at 46000 iterations
2023/05/23 23:56:28 - mmengine - INFO - Iter(train) [ 46050/160000]  lr: 7.3678e-06  eta: 13:32:06  time: 0.4663  data_time: 0.0097  memory: 4845  grad_norm: 111.2250  loss: 33.8879  decode.loss_cls: 1.2403  decode.loss_mask: 0.7469  decode.loss_dice: 1.0972  decode.d0.loss_cls: 3.0748  decode.d0.loss_mask: 0.8358  decode.d0.loss_dice: 1.3457  decode.d1.loss_cls: 1.3841  decode.d1.loss_mask: 0.7882  decode.d1.loss_dice: 1.2256  decode.d2.loss_cls: 1.3096  decode.d2.loss_mask: 0.7451  decode.d2.loss_dice: 1.1465  decode.d3.loss_cls: 1.2609  decode.d3.loss_mask: 0.7476  decode.d3.loss_dice: 1.0863  decode.d4.loss_cls: 1.2932  decode.d4.loss_mask: 0.7543  decode.d4.loss_dice: 1.1329  decode.d5.loss_cls: 1.2918  decode.d5.loss_mask: 0.7439  decode.d5.loss_dice: 1.1376  decode.d6.loss_cls: 1.2955  decode.d6.loss_mask: 0.7536  decode.d6.loss_dice: 1.1520  decode.d7.loss_cls: 1.2829  decode.d7.loss_mask: 0.7488  decode.d7.loss_dice: 1.1439  decode.d8.loss_cls: 1.2476  decode.d8.loss_mask: 0.7488  decode.d8.loss_dice: 1.1267
2023/05/23 23:56:51 - mmengine - INFO - Iter(train) [ 46100/160000]  lr: 7.3649e-06  eta: 13:31:49  time: 0.4652  data_time: 0.0099  memory: 4899  grad_norm: 130.2669  loss: 37.7136  decode.loss_cls: 1.2615  decode.loss_mask: 0.8630  decode.loss_dice: 1.3462  decode.d0.loss_cls: 3.0880  decode.d0.loss_mask: 0.9024  decode.d0.loss_dice: 1.5313  decode.d1.loss_cls: 1.3092  decode.d1.loss_mask: 0.9875  decode.d1.loss_dice: 1.5422  decode.d2.loss_cls: 1.3555  decode.d2.loss_mask: 0.9316  decode.d2.loss_dice: 1.4225  decode.d3.loss_cls: 1.3047  decode.d3.loss_mask: 0.9066  decode.d3.loss_dice: 1.3540  decode.d4.loss_cls: 1.2599  decode.d4.loss_mask: 0.8908  decode.d4.loss_dice: 1.3644  decode.d5.loss_cls: 1.2797  decode.d5.loss_mask: 0.9009  decode.d5.loss_dice: 1.3745  decode.d6.loss_cls: 1.2576  decode.d6.loss_mask: 0.9075  decode.d6.loss_dice: 1.3376  decode.d7.loss_cls: 1.2845  decode.d7.loss_mask: 0.9135  decode.d7.loss_dice: 1.3603  decode.d8.loss_cls: 1.2673  decode.d8.loss_mask: 0.8761  decode.d8.loss_dice: 1.3327
2023/05/23 23:57:12 - mmengine - INFO - Iter(train) [ 46150/160000]  lr: 7.3620e-06  eta: 13:31:28  time: 0.4623  data_time: 0.0096  memory: 4836  grad_norm: 98.1213  loss: 36.3825  decode.loss_cls: 1.2630  decode.loss_mask: 0.8121  decode.loss_dice: 1.2694  decode.d0.loss_cls: 2.9311  decode.d0.loss_mask: 0.8964  decode.d0.loss_dice: 1.5130  decode.d1.loss_cls: 1.3423  decode.d1.loss_mask: 0.9211  decode.d1.loss_dice: 1.4469  decode.d2.loss_cls: 1.3093  decode.d2.loss_mask: 0.8896  decode.d2.loss_dice: 1.3485  decode.d3.loss_cls: 1.2709  decode.d3.loss_mask: 0.8322  decode.d3.loss_dice: 1.2973  decode.d4.loss_cls: 1.2645  decode.d4.loss_mask: 0.8382  decode.d4.loss_dice: 1.3345  decode.d5.loss_cls: 1.2780  decode.d5.loss_mask: 0.8122  decode.d5.loss_dice: 1.3055  decode.d6.loss_cls: 1.2936  decode.d6.loss_mask: 0.8152  decode.d6.loss_dice: 1.3039  decode.d7.loss_cls: 1.3090  decode.d7.loss_mask: 0.8242  decode.d7.loss_dice: 1.2570  decode.d8.loss_cls: 1.2538  decode.d8.loss_mask: 0.8330  decode.d8.loss_dice: 1.3167
2023/05/23 23:57:36 - mmengine - INFO - Iter(train) [ 46200/160000]  lr: 7.3591e-06  eta: 13:31:12  time: 0.4676  data_time: 0.0101  memory: 4829  grad_norm: 110.9998  loss: 36.0868  decode.loss_cls: 1.2650  decode.loss_mask: 0.8108  decode.loss_dice: 1.2392  decode.d0.loss_cls: 3.2367  decode.d0.loss_mask: 0.8868  decode.d0.loss_dice: 1.4019  decode.d1.loss_cls: 1.4051  decode.d1.loss_mask: 0.8605  decode.d1.loss_dice: 1.3470  decode.d2.loss_cls: 1.3687  decode.d2.loss_mask: 0.8736  decode.d2.loss_dice: 1.2852  decode.d3.loss_cls: 1.2660  decode.d3.loss_mask: 0.8137  decode.d3.loss_dice: 1.2741  decode.d4.loss_cls: 1.2583  decode.d4.loss_mask: 0.8088  decode.d4.loss_dice: 1.2489  decode.d5.loss_cls: 1.3016  decode.d5.loss_mask: 0.8026  decode.d5.loss_dice: 1.2347  decode.d6.loss_cls: 1.2910  decode.d6.loss_mask: 0.8194  decode.d6.loss_dice: 1.2553  decode.d7.loss_cls: 1.3450  decode.d7.loss_mask: 0.8081  decode.d7.loss_dice: 1.2447  decode.d8.loss_cls: 1.3047  decode.d8.loss_mask: 0.8010  decode.d8.loss_dice: 1.2283
2023/05/23 23:57:59 - mmengine - INFO - Iter(train) [ 46250/160000]  lr: 7.3562e-06  eta: 13:30:55  time: 0.4701  data_time: 0.0097  memory: 4837  grad_norm: 109.8747  loss: 31.4705  decode.loss_cls: 1.1613  decode.loss_mask: 0.7542  decode.loss_dice: 0.9832  decode.d0.loss_cls: 3.0171  decode.d0.loss_mask: 0.7952  decode.d0.loss_dice: 1.1109  decode.d1.loss_cls: 1.3225  decode.d1.loss_mask: 0.7735  decode.d1.loss_dice: 1.0580  decode.d2.loss_cls: 1.1650  decode.d2.loss_mask: 0.7886  decode.d2.loss_dice: 1.0459  decode.d3.loss_cls: 1.1900  decode.d3.loss_mask: 0.7647  decode.d3.loss_dice: 0.9936  decode.d4.loss_cls: 1.1505  decode.d4.loss_mask: 0.7681  decode.d4.loss_dice: 0.9879  decode.d5.loss_cls: 1.1701  decode.d5.loss_mask: 0.7535  decode.d5.loss_dice: 1.0016  decode.d6.loss_cls: 1.1534  decode.d6.loss_mask: 0.7508  decode.d6.loss_dice: 1.0007  decode.d7.loss_cls: 1.1830  decode.d7.loss_mask: 0.7433  decode.d7.loss_dice: 0.9997  decode.d8.loss_cls: 1.1477  decode.d8.loss_mask: 0.7389  decode.d8.loss_dice: 0.9974
2023/05/23 23:58:21 - mmengine - INFO - Iter(train) [ 46300/160000]  lr: 7.3532e-06  eta: 13:30:34  time: 0.4071  data_time: 0.0103  memory: 4845  grad_norm: 89.9905  loss: 42.6999  decode.loss_cls: 1.5248  decode.loss_mask: 0.8112  decode.loss_dice: 1.5984  decode.d0.loss_cls: 3.4438  decode.d0.loss_mask: 0.8964  decode.d0.loss_dice: 1.8865  decode.d1.loss_cls: 1.6844  decode.d1.loss_mask: 0.8543  decode.d1.loss_dice: 1.7352  decode.d2.loss_cls: 1.5844  decode.d2.loss_mask: 0.8318  decode.d2.loss_dice: 1.6917  decode.d3.loss_cls: 1.5720  decode.d3.loss_mask: 0.8417  decode.d3.loss_dice: 1.6547  decode.d4.loss_cls: 1.5858  decode.d4.loss_mask: 0.8472  decode.d4.loss_dice: 1.6867  decode.d5.loss_cls: 1.5370  decode.d5.loss_mask: 0.8320  decode.d5.loss_dice: 1.6837  decode.d6.loss_cls: 1.5213  decode.d6.loss_mask: 0.7999  decode.d6.loss_dice: 1.6362  decode.d7.loss_cls: 1.5450  decode.d7.loss_mask: 0.8089  decode.d7.loss_dice: 1.6362  decode.d8.loss_cls: 1.5392  decode.d8.loss_mask: 0.8087  decode.d8.loss_dice: 1.6209
2023/05/23 23:58:42 - mmengine - INFO - Iter(train) [ 46350/160000]  lr: 7.3503e-06  eta: 13:30:12  time: 0.4157  data_time: 0.0103  memory: 4888  grad_norm: 86.7225  loss: 34.4972  decode.loss_cls: 1.2375  decode.loss_mask: 0.7367  decode.loss_dice: 1.1477  decode.d0.loss_cls: 3.2483  decode.d0.loss_mask: 0.8125  decode.d0.loss_dice: 1.3712  decode.d1.loss_cls: 1.4633  decode.d1.loss_mask: 0.8460  decode.d1.loss_dice: 1.3068  decode.d2.loss_cls: 1.3044  decode.d2.loss_mask: 0.7785  decode.d2.loss_dice: 1.2550  decode.d3.loss_cls: 1.2625  decode.d3.loss_mask: 0.7579  decode.d3.loss_dice: 1.1945  decode.d4.loss_cls: 1.2346  decode.d4.loss_mask: 0.7699  decode.d4.loss_dice: 1.1727  decode.d5.loss_cls: 1.2874  decode.d5.loss_mask: 0.7467  decode.d5.loss_dice: 1.1754  decode.d6.loss_cls: 1.2833  decode.d6.loss_mask: 0.7251  decode.d6.loss_dice: 1.1318  decode.d7.loss_cls: 1.2455  decode.d7.loss_mask: 0.7309  decode.d7.loss_dice: 1.1471  decode.d8.loss_cls: 1.2408  decode.d8.loss_mask: 0.7401  decode.d8.loss_dice: 1.1430
2023/05/23 23:59:02 - mmengine - INFO - Iter(train) [ 46400/160000]  lr: 7.3474e-06  eta: 13:29:48  time: 0.4123  data_time: 0.0104  memory: 4844  grad_norm: 104.9617  loss: 28.1806  decode.loss_cls: 1.1373  decode.loss_mask: 0.6278  decode.loss_dice: 0.8828  decode.d0.loss_cls: 2.7078  decode.d0.loss_mask: 0.6734  decode.d0.loss_dice: 1.0569  decode.d1.loss_cls: 1.1459  decode.d1.loss_mask: 0.6916  decode.d1.loss_dice: 0.9353  decode.d2.loss_cls: 1.0160  decode.d2.loss_mask: 0.6746  decode.d2.loss_dice: 0.9744  decode.d3.loss_cls: 1.0477  decode.d3.loss_mask: 0.6501  decode.d3.loss_dice: 0.9218  decode.d4.loss_cls: 1.0568  decode.d4.loss_mask: 0.6480  decode.d4.loss_dice: 0.9170  decode.d5.loss_cls: 1.0193  decode.d5.loss_mask: 0.6321  decode.d5.loss_dice: 0.9179  decode.d6.loss_cls: 1.0629  decode.d6.loss_mask: 0.6423  decode.d6.loss_dice: 0.9139  decode.d7.loss_cls: 1.0615  decode.d7.loss_mask: 0.6387  decode.d7.loss_dice: 0.9140  decode.d8.loss_cls: 1.0722  decode.d8.loss_mask: 0.6316  decode.d8.loss_dice: 0.9087
2023/05/23 23:59:23 - mmengine - INFO - Iter(train) [ 46450/160000]  lr: 7.3445e-06  eta: 13:29:25  time: 0.4087  data_time: 0.0098  memory: 4857  grad_norm: 101.5899  loss: 43.1064  decode.loss_cls: 1.5214  decode.loss_mask: 0.8723  decode.loss_dice: 1.6379  decode.d0.loss_cls: 3.4082  decode.d0.loss_mask: 1.0132  decode.d0.loss_dice: 1.8183  decode.d1.loss_cls: 1.6275  decode.d1.loss_mask: 0.9345  decode.d1.loss_dice: 1.7340  decode.d2.loss_cls: 1.6008  decode.d2.loss_mask: 0.9116  decode.d2.loss_dice: 1.7026  decode.d3.loss_cls: 1.5826  decode.d3.loss_mask: 0.8921  decode.d3.loss_dice: 1.6358  decode.d4.loss_cls: 1.5309  decode.d4.loss_mask: 0.8910  decode.d4.loss_dice: 1.6307  decode.d5.loss_cls: 1.5011  decode.d5.loss_mask: 0.9213  decode.d5.loss_dice: 1.6573  decode.d6.loss_cls: 1.5154  decode.d6.loss_mask: 0.8966  decode.d6.loss_dice: 1.6460  decode.d7.loss_cls: 1.4515  decode.d7.loss_mask: 0.8855  decode.d7.loss_dice: 1.6562  decode.d8.loss_cls: 1.5189  decode.d8.loss_mask: 0.8710  decode.d8.loss_dice: 1.6404
2023/05/23 23:59:44 - mmengine - INFO - Iter(train) [ 46500/160000]  lr: 7.3416e-06  eta: 13:29:03  time: 0.4376  data_time: 0.0101  memory: 4845  grad_norm: 111.4581  loss: 31.6228  decode.loss_cls: 1.1126  decode.loss_mask: 0.7072  decode.loss_dice: 1.0762  decode.d0.loss_cls: 2.7633  decode.d0.loss_mask: 0.8693  decode.d0.loss_dice: 1.2662  decode.d1.loss_cls: 1.2903  decode.d1.loss_mask: 0.7906  decode.d1.loss_dice: 1.2121  decode.d2.loss_cls: 1.1970  decode.d2.loss_mask: 0.7494  decode.d2.loss_dice: 1.1092  decode.d3.loss_cls: 1.1608  decode.d3.loss_mask: 0.7436  decode.d3.loss_dice: 1.1161  decode.d4.loss_cls: 1.1695  decode.d4.loss_mask: 0.7073  decode.d4.loss_dice: 1.0726  decode.d5.loss_cls: 1.0724  decode.d5.loss_mask: 0.7146  decode.d5.loss_dice: 1.1058  decode.d6.loss_cls: 1.0984  decode.d6.loss_mask: 0.7079  decode.d6.loss_dice: 1.0408  decode.d7.loss_cls: 1.1067  decode.d7.loss_mask: 0.7029  decode.d7.loss_dice: 1.0605  decode.d8.loss_cls: 1.1307  decode.d8.loss_mask: 0.6929  decode.d8.loss_dice: 1.0757
2023/05/24 00:00:05 - mmengine - INFO - Iter(train) [ 46550/160000]  lr: 7.3387e-06  eta: 13:28:40  time: 0.4126  data_time: 0.0099  memory: 4907  grad_norm: 111.9279  loss: 44.3250  decode.loss_cls: 1.5363  decode.loss_mask: 0.9018  decode.loss_dice: 1.6202  decode.d0.loss_cls: 3.5861  decode.d0.loss_mask: 1.0915  decode.d0.loss_dice: 1.9894  decode.d1.loss_cls: 1.6365  decode.d1.loss_mask: 0.9777  decode.d1.loss_dice: 1.8014  decode.d2.loss_cls: 1.5881  decode.d2.loss_mask: 0.9880  decode.d2.loss_dice: 1.7241  decode.d3.loss_cls: 1.6934  decode.d3.loss_mask: 0.9132  decode.d3.loss_dice: 1.6046  decode.d4.loss_cls: 1.6138  decode.d4.loss_mask: 0.9572  decode.d4.loss_dice: 1.6257  decode.d5.loss_cls: 1.5228  decode.d5.loss_mask: 0.9520  decode.d5.loss_dice: 1.6438  decode.d6.loss_cls: 1.5064  decode.d6.loss_mask: 0.9489  decode.d6.loss_dice: 1.6149  decode.d7.loss_cls: 1.5528  decode.d7.loss_mask: 0.9496  decode.d7.loss_dice: 1.6549  decode.d8.loss_cls: 1.5430  decode.d8.loss_mask: 0.9421  decode.d8.loss_dice: 1.6450
2023/05/24 00:00:25 - mmengine - INFO - Iter(train) [ 46600/160000]  lr: 7.3358e-06  eta: 13:28:17  time: 0.4099  data_time: 0.0101  memory: 4903  grad_norm: 99.4512  loss: 31.6786  decode.loss_cls: 1.3014  decode.loss_mask: 0.5998  decode.loss_dice: 1.0362  decode.d0.loss_cls: 3.2009  decode.d0.loss_mask: 0.6225  decode.d0.loss_dice: 1.2349  decode.d1.loss_cls: 1.3984  decode.d1.loss_mask: 0.6339  decode.d1.loss_dice: 1.0892  decode.d2.loss_cls: 1.2909  decode.d2.loss_mask: 0.6560  decode.d2.loss_dice: 1.0638  decode.d3.loss_cls: 1.2866  decode.d3.loss_mask: 0.6179  decode.d3.loss_dice: 1.0273  decode.d4.loss_cls: 1.3224  decode.d4.loss_mask: 0.6217  decode.d4.loss_dice: 1.0421  decode.d5.loss_cls: 1.2867  decode.d5.loss_mask: 0.6182  decode.d5.loss_dice: 1.0186  decode.d6.loss_cls: 1.2871  decode.d6.loss_mask: 0.6327  decode.d6.loss_dice: 1.0002  decode.d7.loss_cls: 1.3001  decode.d7.loss_mask: 0.6015  decode.d7.loss_dice: 1.0178  decode.d8.loss_cls: 1.2030  decode.d8.loss_mask: 0.6254  decode.d8.loss_dice: 1.0412
2023/05/24 00:00:46 - mmengine - INFO - Iter(train) [ 46650/160000]  lr: 7.3329e-06  eta: 13:27:54  time: 0.4105  data_time: 0.0098  memory: 4866  grad_norm: 91.2075  loss: 31.3867  decode.loss_cls: 1.2883  decode.loss_mask: 0.6612  decode.loss_dice: 0.9452  decode.d0.loss_cls: 3.1518  decode.d0.loss_mask: 0.7046  decode.d0.loss_dice: 1.1335  decode.d1.loss_cls: 1.3015  decode.d1.loss_mask: 0.6890  decode.d1.loss_dice: 1.0807  decode.d2.loss_cls: 1.2811  decode.d2.loss_mask: 0.6401  decode.d2.loss_dice: 1.0018  decode.d3.loss_cls: 1.2497  decode.d3.loss_mask: 0.6235  decode.d3.loss_dice: 1.0107  decode.d4.loss_cls: 1.3049  decode.d4.loss_mask: 0.6428  decode.d4.loss_dice: 0.9983  decode.d5.loss_cls: 1.2699  decode.d5.loss_mask: 0.6546  decode.d5.loss_dice: 1.0037  decode.d6.loss_cls: 1.2682  decode.d6.loss_mask: 0.6584  decode.d6.loss_dice: 0.9912  decode.d7.loss_cls: 1.2841  decode.d7.loss_mask: 0.6603  decode.d7.loss_dice: 0.9727  decode.d8.loss_cls: 1.2340  decode.d8.loss_mask: 0.6925  decode.d8.loss_dice: 0.9883
2023/05/24 00:01:07 - mmengine - INFO - Iter(train) [ 46700/160000]  lr: 7.3300e-06  eta: 13:27:31  time: 0.4223  data_time: 0.0099  memory: 4903  grad_norm: 120.7633  loss: 40.4223  decode.loss_cls: 1.4330  decode.loss_mask: 0.7978  decode.loss_dice: 1.5428  decode.d0.loss_cls: 3.3656  decode.d0.loss_mask: 0.8506  decode.d0.loss_dice: 1.7420  decode.d1.loss_cls: 1.5150  decode.d1.loss_mask: 0.8419  decode.d1.loss_dice: 1.5942  decode.d2.loss_cls: 1.4972  decode.d2.loss_mask: 0.8114  decode.d2.loss_dice: 1.5787  decode.d3.loss_cls: 1.4758  decode.d3.loss_mask: 0.8253  decode.d3.loss_dice: 1.5296  decode.d4.loss_cls: 1.4553  decode.d4.loss_mask: 0.8171  decode.d4.loss_dice: 1.5198  decode.d5.loss_cls: 1.4743  decode.d5.loss_mask: 0.8175  decode.d5.loss_dice: 1.5335  decode.d6.loss_cls: 1.4857  decode.d6.loss_mask: 0.7890  decode.d6.loss_dice: 1.5489  decode.d7.loss_cls: 1.4470  decode.d7.loss_mask: 0.7963  decode.d7.loss_dice: 1.5539  decode.d8.loss_cls: 1.4749  decode.d8.loss_mask: 0.7903  decode.d8.loss_dice: 1.5179
2023/05/24 00:01:28 - mmengine - INFO - Iter(train) [ 46750/160000]  lr: 7.3270e-06  eta: 13:27:08  time: 0.4108  data_time: 0.0103  memory: 4868  grad_norm: 93.5270  loss: 31.0854  decode.loss_cls: 1.1986  decode.loss_mask: 0.6422  decode.loss_dice: 1.0022  decode.d0.loss_cls: 3.1975  decode.d0.loss_mask: 0.7004  decode.d0.loss_dice: 1.1446  decode.d1.loss_cls: 1.3398  decode.d1.loss_mask: 0.6833  decode.d1.loss_dice: 1.0884  decode.d2.loss_cls: 1.1851  decode.d2.loss_mask: 0.6592  decode.d2.loss_dice: 1.0803  decode.d3.loss_cls: 1.2057  decode.d3.loss_mask: 0.6572  decode.d3.loss_dice: 1.0294  decode.d4.loss_cls: 1.1861  decode.d4.loss_mask: 0.6517  decode.d4.loss_dice: 1.0292  decode.d5.loss_cls: 1.2078  decode.d5.loss_mask: 0.6495  decode.d5.loss_dice: 1.0306  decode.d6.loss_cls: 1.1705  decode.d6.loss_mask: 0.6685  decode.d6.loss_dice: 1.0138  decode.d7.loss_cls: 1.1429  decode.d7.loss_mask: 0.6696  decode.d7.loss_dice: 1.0139  decode.d8.loss_cls: 1.1679  decode.d8.loss_mask: 0.6577  decode.d8.loss_dice: 1.0114
2023/05/24 00:01:49 - mmengine - INFO - Iter(train) [ 46800/160000]  lr: 7.3241e-06  eta: 13:26:45  time: 0.4208  data_time: 0.0098  memory: 4846  grad_norm: 113.1191  loss: 34.8792  decode.loss_cls: 1.0399  decode.loss_mask: 0.8424  decode.loss_dice: 1.2862  decode.d0.loss_cls: 2.7980  decode.d0.loss_mask: 0.9472  decode.d0.loss_dice: 1.4941  decode.d1.loss_cls: 1.2266  decode.d1.loss_mask: 0.9370  decode.d1.loss_dice: 1.4302  decode.d2.loss_cls: 1.1257  decode.d2.loss_mask: 0.8946  decode.d2.loss_dice: 1.3915  decode.d3.loss_cls: 1.1579  decode.d3.loss_mask: 0.8440  decode.d3.loss_dice: 1.3291  decode.d4.loss_cls: 1.0903  decode.d4.loss_mask: 0.8517  decode.d4.loss_dice: 1.3017  decode.d5.loss_cls: 1.1022  decode.d5.loss_mask: 0.8387  decode.d5.loss_dice: 1.3067  decode.d6.loss_cls: 1.1471  decode.d6.loss_mask: 0.8180  decode.d6.loss_dice: 1.2860  decode.d7.loss_cls: 1.0541  decode.d7.loss_mask: 0.8317  decode.d7.loss_dice: 1.3074  decode.d8.loss_cls: 1.0649  decode.d8.loss_mask: 0.8380  decode.d8.loss_dice: 1.2965
2023/05/24 00:02:10 - mmengine - INFO - Iter(train) [ 46850/160000]  lr: 7.3212e-06  eta: 13:26:23  time: 0.4261  data_time: 0.0100  memory: 4865  grad_norm: 96.1486  loss: 37.3804  decode.loss_cls: 1.5787  decode.loss_mask: 0.7059  decode.loss_dice: 1.1350  decode.d0.loss_cls: 3.3099  decode.d0.loss_mask: 0.8654  decode.d0.loss_dice: 1.4036  decode.d1.loss_cls: 1.8130  decode.d1.loss_mask: 0.8010  decode.d1.loss_dice: 1.3520  decode.d2.loss_cls: 1.5717  decode.d2.loss_mask: 0.7625  decode.d2.loss_dice: 1.2336  decode.d3.loss_cls: 1.6145  decode.d3.loss_mask: 0.7458  decode.d3.loss_dice: 1.2287  decode.d4.loss_cls: 1.5963  decode.d4.loss_mask: 0.7397  decode.d4.loss_dice: 1.2088  decode.d5.loss_cls: 1.5599  decode.d5.loss_mask: 0.7176  decode.d5.loss_dice: 1.1699  decode.d6.loss_cls: 1.5933  decode.d6.loss_mask: 0.7155  decode.d6.loss_dice: 1.1490  decode.d7.loss_cls: 1.5642  decode.d7.loss_mask: 0.7077  decode.d7.loss_dice: 1.1454  decode.d8.loss_cls: 1.5102  decode.d8.loss_mask: 0.7253  decode.d8.loss_dice: 1.1561
2023/05/24 00:02:32 - mmengine - INFO - Iter(train) [ 46900/160000]  lr: 7.3183e-06  eta: 13:26:03  time: 0.4710  data_time: 0.0102  memory: 4867  grad_norm: 119.6421  loss: 36.0648  decode.loss_cls: 1.1867  decode.loss_mask: 0.8739  decode.loss_dice: 1.1957  decode.d0.loss_cls: 3.3716  decode.d0.loss_mask: 0.9374  decode.d0.loss_dice: 1.4457  decode.d1.loss_cls: 1.4023  decode.d1.loss_mask: 0.9435  decode.d1.loss_dice: 1.3230  decode.d2.loss_cls: 1.3423  decode.d2.loss_mask: 0.9094  decode.d2.loss_dice: 1.3133  decode.d3.loss_cls: 1.2821  decode.d3.loss_mask: 0.9003  decode.d3.loss_dice: 1.2302  decode.d4.loss_cls: 1.2650  decode.d4.loss_mask: 0.8434  decode.d4.loss_dice: 1.1972  decode.d5.loss_cls: 1.2608  decode.d5.loss_mask: 0.8402  decode.d5.loss_dice: 1.1736  decode.d6.loss_cls: 1.2211  decode.d6.loss_mask: 0.8554  decode.d6.loss_dice: 1.2166  decode.d7.loss_cls: 1.1838  decode.d7.loss_mask: 0.8833  decode.d7.loss_dice: 1.1935  decode.d8.loss_cls: 1.1835  decode.d8.loss_mask: 0.8879  decode.d8.loss_dice: 1.2022
2023/05/24 00:02:53 - mmengine - INFO - Iter(train) [ 46950/160000]  lr: 7.3154e-06  eta: 13:25:41  time: 0.4216  data_time: 0.0105  memory: 4955  grad_norm: 105.8260  loss: 44.3500  decode.loss_cls: 1.8978  decode.loss_mask: 0.7773  decode.loss_dice: 1.5436  decode.d0.loss_cls: 3.7617  decode.d0.loss_mask: 0.9180  decode.d0.loss_dice: 1.7855  decode.d1.loss_cls: 1.9550  decode.d1.loss_mask: 0.8065  decode.d1.loss_dice: 1.6965  decode.d2.loss_cls: 1.8306  decode.d2.loss_mask: 0.8052  decode.d2.loss_dice: 1.6226  decode.d3.loss_cls: 1.8759  decode.d3.loss_mask: 0.8116  decode.d3.loss_dice: 1.5493  decode.d4.loss_cls: 1.8607  decode.d4.loss_mask: 0.7929  decode.d4.loss_dice: 1.5618  decode.d5.loss_cls: 1.8560  decode.d5.loss_mask: 0.7601  decode.d5.loss_dice: 1.5157  decode.d6.loss_cls: 1.7763  decode.d6.loss_mask: 0.7977  decode.d6.loss_dice: 1.5551  decode.d7.loss_cls: 1.7864  decode.d7.loss_mask: 0.7905  decode.d7.loss_dice: 1.5745  decode.d8.loss_cls: 1.7872  decode.d8.loss_mask: 0.7708  decode.d8.loss_dice: 1.5272
2023/05/24 00:03:13 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 00:03:13 - mmengine - INFO - Iter(train) [ 47000/160000]  lr: 7.3125e-06  eta: 13:25:17  time: 0.4035  data_time: 0.0097  memory: 4845  grad_norm: 110.7849  loss: 40.5249  decode.loss_cls: 1.5237  decode.loss_mask: 0.7623  decode.loss_dice: 1.3886  decode.d0.loss_cls: 3.7821  decode.d0.loss_mask: 0.8636  decode.d0.loss_dice: 1.7540  decode.d1.loss_cls: 1.6552  decode.d1.loss_mask: 0.8448  decode.d1.loss_dice: 1.6243  decode.d2.loss_cls: 1.5931  decode.d2.loss_mask: 0.7861  decode.d2.loss_dice: 1.5374  decode.d3.loss_cls: 1.5847  decode.d3.loss_mask: 0.7482  decode.d3.loss_dice: 1.4465  decode.d4.loss_cls: 1.5334  decode.d4.loss_mask: 0.7651  decode.d4.loss_dice: 1.4608  decode.d5.loss_cls: 1.5007  decode.d5.loss_mask: 0.7606  decode.d5.loss_dice: 1.4615  decode.d6.loss_cls: 1.5963  decode.d6.loss_mask: 0.7506  decode.d6.loss_dice: 1.4356  decode.d7.loss_cls: 1.4907  decode.d7.loss_mask: 0.7602  decode.d7.loss_dice: 1.4500  decode.d8.loss_cls: 1.4789  decode.d8.loss_mask: 0.7554  decode.d8.loss_dice: 1.4307
2023/05/24 00:03:13 - mmengine - INFO - Saving checkpoint at 47000 iterations
2023/05/24 00:03:38 - mmengine - INFO - Iter(train) [ 47050/160000]  lr: 7.3096e-06  eta: 13:25:05  time: 0.4112  data_time: 0.0100  memory: 4838  grad_norm: 85.8005  loss: 42.4327  decode.loss_cls: 1.4156  decode.loss_mask: 0.9258  decode.loss_dice: 1.6151  decode.d0.loss_cls: 3.2475  decode.d0.loss_mask: 1.0156  decode.d0.loss_dice: 1.8705  decode.d1.loss_cls: 1.5763  decode.d1.loss_mask: 0.9861  decode.d1.loss_dice: 1.7056  decode.d2.loss_cls: 1.4322  decode.d2.loss_mask: 1.0263  decode.d2.loss_dice: 1.7075  decode.d3.loss_cls: 1.4626  decode.d3.loss_mask: 0.9428  decode.d3.loss_dice: 1.6441  decode.d4.loss_cls: 1.3992  decode.d4.loss_mask: 0.9510  decode.d4.loss_dice: 1.6269  decode.d5.loss_cls: 1.3747  decode.d5.loss_mask: 0.9811  decode.d5.loss_dice: 1.6027  decode.d6.loss_cls: 1.4188  decode.d6.loss_mask: 0.9669  decode.d6.loss_dice: 1.6008  decode.d7.loss_cls: 1.3591  decode.d7.loss_mask: 0.9840  decode.d7.loss_dice: 1.6145  decode.d8.loss_cls: 1.4125  decode.d8.loss_mask: 0.9401  decode.d8.loss_dice: 1.6268
2023/05/24 00:04:00 - mmengine - INFO - Iter(train) [ 47100/160000]  lr: 7.3067e-06  eta: 13:24:44  time: 0.4652  data_time: 0.0100  memory: 4867  grad_norm: 94.9212  loss: 41.5515  decode.loss_cls: 1.5755  decode.loss_mask: 0.9068  decode.loss_dice: 1.4560  decode.d0.loss_cls: 3.5507  decode.d0.loss_mask: 0.9307  decode.d0.loss_dice: 1.6170  decode.d1.loss_cls: 1.6887  decode.d1.loss_mask: 0.8667  decode.d1.loss_dice: 1.5723  decode.d2.loss_cls: 1.6253  decode.d2.loss_mask: 0.9080  decode.d2.loss_dice: 1.5097  decode.d3.loss_cls: 1.5714  decode.d3.loss_mask: 0.8816  decode.d3.loss_dice: 1.4919  decode.d4.loss_cls: 1.5211  decode.d4.loss_mask: 0.8543  decode.d4.loss_dice: 1.4754  decode.d5.loss_cls: 1.5149  decode.d5.loss_mask: 0.9091  decode.d5.loss_dice: 1.4483  decode.d6.loss_cls: 1.5500  decode.d6.loss_mask: 0.8950  decode.d6.loss_dice: 1.4530  decode.d7.loss_cls: 1.5634  decode.d7.loss_mask: 0.8928  decode.d7.loss_dice: 1.4465  decode.d8.loss_cls: 1.5627  decode.d8.loss_mask: 0.8753  decode.d8.loss_dice: 1.4374
2023/05/24 00:04:23 - mmengine - INFO - Iter(train) [ 47150/160000]  lr: 7.3037e-06  eta: 13:24:27  time: 0.4288  data_time: 0.0100  memory: 4835  grad_norm: 109.1152  loss: 41.8512  decode.loss_cls: 1.3979  decode.loss_mask: 0.9983  decode.loss_dice: 1.4874  decode.d0.loss_cls: 3.3977  decode.d0.loss_mask: 1.0008  decode.d0.loss_dice: 1.6876  decode.d1.loss_cls: 1.6297  decode.d1.loss_mask: 1.0186  decode.d1.loss_dice: 1.6240  decode.d2.loss_cls: 1.5469  decode.d2.loss_mask: 0.9884  decode.d2.loss_dice: 1.5663  decode.d3.loss_cls: 1.4439  decode.d3.loss_mask: 0.9840  decode.d3.loss_dice: 1.4571  decode.d4.loss_cls: 1.4326  decode.d4.loss_mask: 0.9732  decode.d4.loss_dice: 1.4865  decode.d5.loss_cls: 1.4345  decode.d5.loss_mask: 1.0075  decode.d5.loss_dice: 1.5108  decode.d6.loss_cls: 1.4950  decode.d6.loss_mask: 0.9920  decode.d6.loss_dice: 1.4687  decode.d7.loss_cls: 1.4825  decode.d7.loss_mask: 0.9920  decode.d7.loss_dice: 1.4696  decode.d8.loss_cls: 1.4317  decode.d8.loss_mask: 0.9735  decode.d8.loss_dice: 1.4725
2023/05/24 00:04:44 - mmengine - INFO - Iter(train) [ 47200/160000]  lr: 7.3008e-06  eta: 13:24:03  time: 0.4125  data_time: 0.0100  memory: 4871  grad_norm: 122.7062  loss: 34.6754  decode.loss_cls: 1.0287  decode.loss_mask: 0.7983  decode.loss_dice: 1.3575  decode.d0.loss_cls: 3.0574  decode.d0.loss_mask: 0.8060  decode.d0.loss_dice: 1.5856  decode.d1.loss_cls: 1.1481  decode.d1.loss_mask: 0.8306  decode.d1.loss_dice: 1.4517  decode.d2.loss_cls: 1.0944  decode.d2.loss_mask: 0.7984  decode.d2.loss_dice: 1.4168  decode.d3.loss_cls: 1.1172  decode.d3.loss_mask: 0.7689  decode.d3.loss_dice: 1.3893  decode.d4.loss_cls: 1.0874  decode.d4.loss_mask: 0.7899  decode.d4.loss_dice: 1.3637  decode.d5.loss_cls: 1.0746  decode.d5.loss_mask: 0.7946  decode.d5.loss_dice: 1.3579  decode.d6.loss_cls: 1.0549  decode.d6.loss_mask: 0.8018  decode.d6.loss_dice: 1.3360  decode.d7.loss_cls: 1.0801  decode.d7.loss_mask: 0.7899  decode.d7.loss_dice: 1.3495  decode.d8.loss_cls: 1.0556  decode.d8.loss_mask: 0.7794  decode.d8.loss_dice: 1.3113
2023/05/24 00:05:04 - mmengine - INFO - Iter(train) [ 47250/160000]  lr: 7.2979e-06  eta: 13:23:40  time: 0.4120  data_time: 0.0098  memory: 4835  grad_norm: 101.3713  loss: 37.1494  decode.loss_cls: 1.1326  decode.loss_mask: 0.8734  decode.loss_dice: 1.4669  decode.d0.loss_cls: 3.1168  decode.d0.loss_mask: 0.9478  decode.d0.loss_dice: 1.6553  decode.d1.loss_cls: 1.1984  decode.d1.loss_mask: 0.9086  decode.d1.loss_dice: 1.5010  decode.d2.loss_cls: 1.1285  decode.d2.loss_mask: 0.9368  decode.d2.loss_dice: 1.4582  decode.d3.loss_cls: 1.1800  decode.d3.loss_mask: 0.8772  decode.d3.loss_dice: 1.4370  decode.d4.loss_cls: 1.1167  decode.d4.loss_mask: 0.9225  decode.d4.loss_dice: 1.4446  decode.d5.loss_cls: 1.1519  decode.d5.loss_mask: 0.8993  decode.d5.loss_dice: 1.4303  decode.d6.loss_cls: 1.1557  decode.d6.loss_mask: 0.8804  decode.d6.loss_dice: 1.4463  decode.d7.loss_cls: 1.1438  decode.d7.loss_mask: 0.8685  decode.d7.loss_dice: 1.4294  decode.d8.loss_cls: 1.1581  decode.d8.loss_mask: 0.8692  decode.d8.loss_dice: 1.4144
2023/05/24 00:05:26 - mmengine - INFO - Iter(train) [ 47300/160000]  lr: 7.2950e-06  eta: 13:23:19  time: 0.4105  data_time: 0.0107  memory: 4919  grad_norm: 95.9493  loss: 36.5250  decode.loss_cls: 1.2066  decode.loss_mask: 0.7941  decode.loss_dice: 1.3631  decode.d0.loss_cls: 3.1204  decode.d0.loss_mask: 0.8235  decode.d0.loss_dice: 1.5424  decode.d1.loss_cls: 1.3975  decode.d1.loss_mask: 0.7915  decode.d1.loss_dice: 1.4405  decode.d2.loss_cls: 1.3574  decode.d2.loss_mask: 0.7693  decode.d2.loss_dice: 1.3973  decode.d3.loss_cls: 1.3198  decode.d3.loss_mask: 0.7605  decode.d3.loss_dice: 1.3863  decode.d4.loss_cls: 1.2523  decode.d4.loss_mask: 0.7884  decode.d4.loss_dice: 1.3874  decode.d5.loss_cls: 1.3026  decode.d5.loss_mask: 0.7839  decode.d5.loss_dice: 1.3526  decode.d6.loss_cls: 1.2657  decode.d6.loss_mask: 0.7778  decode.d6.loss_dice: 1.3472  decode.d7.loss_cls: 1.2845  decode.d7.loss_mask: 0.7761  decode.d7.loss_dice: 1.3507  decode.d8.loss_cls: 1.2317  decode.d8.loss_mask: 0.7864  decode.d8.loss_dice: 1.3674
2023/05/24 00:05:46 - mmengine - INFO - Iter(train) [ 47350/160000]  lr: 7.2921e-06  eta: 13:22:56  time: 0.4124  data_time: 0.0098  memory: 4803  grad_norm: 125.1185  loss: 38.0401  decode.loss_cls: 1.2627  decode.loss_mask: 0.9265  decode.loss_dice: 1.3584  decode.d0.loss_cls: 3.1084  decode.d0.loss_mask: 1.0088  decode.d0.loss_dice: 1.5196  decode.d1.loss_cls: 1.3621  decode.d1.loss_mask: 0.9592  decode.d1.loss_dice: 1.4425  decode.d2.loss_cls: 1.3044  decode.d2.loss_mask: 0.9426  decode.d2.loss_dice: 1.4269  decode.d3.loss_cls: 1.2526  decode.d3.loss_mask: 0.9568  decode.d3.loss_dice: 1.3601  decode.d4.loss_cls: 1.2400  decode.d4.loss_mask: 0.9454  decode.d4.loss_dice: 1.3947  decode.d5.loss_cls: 1.2355  decode.d5.loss_mask: 0.9547  decode.d5.loss_dice: 1.3824  decode.d6.loss_cls: 1.2186  decode.d6.loss_mask: 0.9582  decode.d6.loss_dice: 1.3567  decode.d7.loss_cls: 1.2501  decode.d7.loss_mask: 0.9469  decode.d7.loss_dice: 1.4256  decode.d8.loss_cls: 1.2547  decode.d8.loss_mask: 0.9298  decode.d8.loss_dice: 1.3554
2023/05/24 00:06:07 - mmengine - INFO - Iter(train) [ 47400/160000]  lr: 7.2892e-06  eta: 13:22:33  time: 0.4184  data_time: 0.0096  memory: 4871  grad_norm: 119.1481  loss: 41.8100  decode.loss_cls: 1.4749  decode.loss_mask: 0.9501  decode.loss_dice: 1.4695  decode.d0.loss_cls: 3.5714  decode.d0.loss_mask: 1.0342  decode.d0.loss_dice: 1.6989  decode.d1.loss_cls: 1.4547  decode.d1.loss_mask: 0.9460  decode.d1.loss_dice: 1.5948  decode.d2.loss_cls: 1.4804  decode.d2.loss_mask: 0.9563  decode.d2.loss_dice: 1.5699  decode.d3.loss_cls: 1.4933  decode.d3.loss_mask: 0.9590  decode.d3.loss_dice: 1.5207  decode.d4.loss_cls: 1.5095  decode.d4.loss_mask: 0.9535  decode.d4.loss_dice: 1.5203  decode.d5.loss_cls: 1.4472  decode.d5.loss_mask: 0.9565  decode.d5.loss_dice: 1.5231  decode.d6.loss_cls: 1.4543  decode.d6.loss_mask: 0.9421  decode.d6.loss_dice: 1.5095  decode.d7.loss_cls: 1.4640  decode.d7.loss_mask: 0.9512  decode.d7.loss_dice: 1.5036  decode.d8.loss_cls: 1.4450  decode.d8.loss_mask: 0.9462  decode.d8.loss_dice: 1.5097
2023/05/24 00:06:28 - mmengine - INFO - Iter(train) [ 47450/160000]  lr: 7.2863e-06  eta: 13:22:11  time: 0.4224  data_time: 0.0104  memory: 4865  grad_norm: 104.4783  loss: 36.4633  decode.loss_cls: 1.1748  decode.loss_mask: 0.8983  decode.loss_dice: 1.2488  decode.d0.loss_cls: 3.2843  decode.d0.loss_mask: 0.9124  decode.d0.loss_dice: 1.4765  decode.d1.loss_cls: 1.3949  decode.d1.loss_mask: 0.9306  decode.d1.loss_dice: 1.3657  decode.d2.loss_cls: 1.1857  decode.d2.loss_mask: 0.9437  decode.d2.loss_dice: 1.3240  decode.d3.loss_cls: 1.1587  decode.d3.loss_mask: 0.8597  decode.d3.loss_dice: 1.3151  decode.d4.loss_cls: 1.1951  decode.d4.loss_mask: 0.9233  decode.d4.loss_dice: 1.3183  decode.d5.loss_cls: 1.2058  decode.d5.loss_mask: 0.9330  decode.d5.loss_dice: 1.2990  decode.d6.loss_cls: 1.1495  decode.d6.loss_mask: 0.9073  decode.d6.loss_dice: 1.2816  decode.d7.loss_cls: 1.2415  decode.d7.loss_mask: 0.8760  decode.d7.loss_dice: 1.2902  decode.d8.loss_cls: 1.2081  decode.d8.loss_mask: 0.8670  decode.d8.loss_dice: 1.2944
2023/05/24 00:06:49 - mmengine - INFO - Iter(train) [ 47500/160000]  lr: 7.2834e-06  eta: 13:21:48  time: 0.4098  data_time: 0.0102  memory: 4890  grad_norm: 122.1816  loss: 34.2662  decode.loss_cls: 1.0409  decode.loss_mask: 0.8566  decode.loss_dice: 1.2298  decode.d0.loss_cls: 2.9345  decode.d0.loss_mask: 0.9639  decode.d0.loss_dice: 1.4437  decode.d1.loss_cls: 1.2541  decode.d1.loss_mask: 0.8940  decode.d1.loss_dice: 1.3212  decode.d2.loss_cls: 1.1119  decode.d2.loss_mask: 0.8939  decode.d2.loss_dice: 1.2472  decode.d3.loss_cls: 1.1264  decode.d3.loss_mask: 0.8770  decode.d3.loss_dice: 1.2390  decode.d4.loss_cls: 1.0815  decode.d4.loss_mask: 0.8768  decode.d4.loss_dice: 1.2271  decode.d5.loss_cls: 1.1563  decode.d5.loss_mask: 0.8556  decode.d5.loss_dice: 1.2410  decode.d6.loss_cls: 1.0544  decode.d6.loss_mask: 0.8594  decode.d6.loss_dice: 1.2016  decode.d7.loss_cls: 1.0571  decode.d7.loss_mask: 0.8695  decode.d7.loss_dice: 1.2260  decode.d8.loss_cls: 1.0530  decode.d8.loss_mask: 0.8586  decode.d8.loss_dice: 1.2142
2023/05/24 00:07:09 - mmengine - INFO - Iter(train) [ 47550/160000]  lr: 7.2804e-06  eta: 13:21:24  time: 0.4085  data_time: 0.0097  memory: 4846  grad_norm: 112.6927  loss: 29.2931  decode.loss_cls: 1.3041  decode.loss_mask: 0.6199  decode.loss_dice: 0.7471  decode.d0.loss_cls: 3.0357  decode.d0.loss_mask: 0.7048  decode.d0.loss_dice: 0.8428  decode.d1.loss_cls: 1.3722  decode.d1.loss_mask: 0.7151  decode.d1.loss_dice: 0.8344  decode.d2.loss_cls: 1.2470  decode.d2.loss_mask: 0.7497  decode.d2.loss_dice: 0.8056  decode.d3.loss_cls: 1.2856  decode.d3.loss_mask: 0.6943  decode.d3.loss_dice: 0.7746  decode.d4.loss_cls: 1.2713  decode.d4.loss_mask: 0.6976  decode.d4.loss_dice: 0.7589  decode.d5.loss_cls: 1.3272  decode.d5.loss_mask: 0.6325  decode.d5.loss_dice: 0.7490  decode.d6.loss_cls: 1.3628  decode.d6.loss_mask: 0.6080  decode.d6.loss_dice: 0.7404  decode.d7.loss_cls: 1.3931  decode.d7.loss_mask: 0.6212  decode.d7.loss_dice: 0.7347  decode.d8.loss_cls: 1.3308  decode.d8.loss_mask: 0.6003  decode.d8.loss_dice: 0.7326
2023/05/24 00:07:31 - mmengine - INFO - Iter(train) [ 47600/160000]  lr: 7.2775e-06  eta: 13:21:03  time: 0.4123  data_time: 0.0106  memory: 4845  grad_norm: 112.5703  loss: 42.1081  decode.loss_cls: 1.6962  decode.loss_mask: 0.7955  decode.loss_dice: 1.4653  decode.d0.loss_cls: 3.6384  decode.d0.loss_mask: 0.8672  decode.d0.loss_dice: 1.7462  decode.d1.loss_cls: 1.7314  decode.d1.loss_mask: 0.8578  decode.d1.loss_dice: 1.6774  decode.d2.loss_cls: 1.6728  decode.d2.loss_mask: 0.8159  decode.d2.loss_dice: 1.5500  decode.d3.loss_cls: 1.5722  decode.d3.loss_mask: 0.8468  decode.d3.loss_dice: 1.5196  decode.d4.loss_cls: 1.6416  decode.d4.loss_mask: 0.8368  decode.d4.loss_dice: 1.4871  decode.d5.loss_cls: 1.6058  decode.d5.loss_mask: 0.8359  decode.d5.loss_dice: 1.4897  decode.d6.loss_cls: 1.6813  decode.d6.loss_mask: 0.8057  decode.d6.loss_dice: 1.4655  decode.d7.loss_cls: 1.6322  decode.d7.loss_mask: 0.8161  decode.d7.loss_dice: 1.4981  decode.d8.loss_cls: 1.5682  decode.d8.loss_mask: 0.8243  decode.d8.loss_dice: 1.4669
2023/05/24 00:07:52 - mmengine - INFO - Iter(train) [ 47650/160000]  lr: 7.2746e-06  eta: 13:20:41  time: 0.4400  data_time: 0.0099  memory: 4816  grad_norm: 115.2720  loss: 37.8366  decode.loss_cls: 1.3625  decode.loss_mask: 0.9548  decode.loss_dice: 1.2274  decode.d0.loss_cls: 3.2053  decode.d0.loss_mask: 0.9528  decode.d0.loss_dice: 1.4103  decode.d1.loss_cls: 1.4141  decode.d1.loss_mask: 0.9817  decode.d1.loss_dice: 1.3606  decode.d2.loss_cls: 1.3395  decode.d2.loss_mask: 0.9771  decode.d2.loss_dice: 1.2700  decode.d3.loss_cls: 1.2626  decode.d3.loss_mask: 1.0187  decode.d3.loss_dice: 1.3287  decode.d4.loss_cls: 1.3577  decode.d4.loss_mask: 0.9673  decode.d4.loss_dice: 1.3071  decode.d5.loss_cls: 1.3791  decode.d5.loss_mask: 0.9438  decode.d5.loss_dice: 1.2587  decode.d6.loss_cls: 1.3283  decode.d6.loss_mask: 0.9571  decode.d6.loss_dice: 1.2363  decode.d7.loss_cls: 1.3171  decode.d7.loss_mask: 0.9426  decode.d7.loss_dice: 1.2197  decode.d8.loss_cls: 1.2759  decode.d8.loss_mask: 1.0031  decode.d8.loss_dice: 1.2767
2023/05/24 00:08:13 - mmengine - INFO - Iter(train) [ 47700/160000]  lr: 7.2717e-06  eta: 13:20:19  time: 0.4229  data_time: 0.0103  memory: 4844  grad_norm: 100.1214  loss: 39.9043  decode.loss_cls: 1.6393  decode.loss_mask: 0.8831  decode.loss_dice: 1.1889  decode.d0.loss_cls: 3.1823  decode.d0.loss_mask: 1.0849  decode.d0.loss_dice: 1.4873  decode.d1.loss_cls: 1.8409  decode.d1.loss_mask: 0.9308  decode.d1.loss_dice: 1.3372  decode.d2.loss_cls: 1.7012  decode.d2.loss_mask: 0.9136  decode.d2.loss_dice: 1.2970  decode.d3.loss_cls: 1.6232  decode.d3.loss_mask: 0.9149  decode.d3.loss_dice: 1.2511  decode.d4.loss_cls: 1.6240  decode.d4.loss_mask: 0.9095  decode.d4.loss_dice: 1.2296  decode.d5.loss_cls: 1.5691  decode.d5.loss_mask: 0.8883  decode.d5.loss_dice: 1.2007  decode.d6.loss_cls: 1.6281  decode.d6.loss_mask: 0.9036  decode.d6.loss_dice: 1.2447  decode.d7.loss_cls: 1.5971  decode.d7.loss_mask: 0.8877  decode.d7.loss_dice: 1.2391  decode.d8.loss_cls: 1.5808  decode.d8.loss_mask: 0.9037  decode.d8.loss_dice: 1.2225
2023/05/24 00:08:34 - mmengine - INFO - Iter(train) [ 47750/160000]  lr: 7.2688e-06  eta: 13:19:57  time: 0.4174  data_time: 0.0100  memory: 4845  grad_norm: 98.0957  loss: 35.5801  decode.loss_cls: 1.1283  decode.loss_mask: 0.8927  decode.loss_dice: 1.2554  decode.d0.loss_cls: 2.9904  decode.d0.loss_mask: 0.9646  decode.d0.loss_dice: 1.4683  decode.d1.loss_cls: 1.2090  decode.d1.loss_mask: 0.9466  decode.d1.loss_dice: 1.3921  decode.d2.loss_cls: 1.1603  decode.d2.loss_mask: 0.8923  decode.d2.loss_dice: 1.3415  decode.d3.loss_cls: 1.1561  decode.d3.loss_mask: 0.8872  decode.d3.loss_dice: 1.3063  decode.d4.loss_cls: 1.1573  decode.d4.loss_mask: 0.8742  decode.d4.loss_dice: 1.3334  decode.d5.loss_cls: 1.0816  decode.d5.loss_mask: 0.9206  decode.d5.loss_dice: 1.3041  decode.d6.loss_cls: 1.1360  decode.d6.loss_mask: 0.9247  decode.d6.loss_dice: 1.2556  decode.d7.loss_cls: 1.1344  decode.d7.loss_mask: 0.9336  decode.d7.loss_dice: 1.2461  decode.d8.loss_cls: 1.1430  decode.d8.loss_mask: 0.9234  decode.d8.loss_dice: 1.2210
2023/05/24 00:08:55 - mmengine - INFO - Iter(train) [ 47800/160000]  lr: 7.2659e-06  eta: 13:19:35  time: 0.4233  data_time: 0.0101  memory: 4833  grad_norm: 98.9794  loss: 39.1328  decode.loss_cls: 1.3611  decode.loss_mask: 0.8243  decode.loss_dice: 1.4445  decode.d0.loss_cls: 3.3608  decode.d0.loss_mask: 0.9487  decode.d0.loss_dice: 1.6409  decode.d1.loss_cls: 1.5109  decode.d1.loss_mask: 0.8686  decode.d1.loss_dice: 1.5112  decode.d2.loss_cls: 1.3534  decode.d2.loss_mask: 0.8647  decode.d2.loss_dice: 1.4959  decode.d3.loss_cls: 1.3393  decode.d3.loss_mask: 0.8903  decode.d3.loss_dice: 1.4942  decode.d4.loss_cls: 1.3098  decode.d4.loss_mask: 0.8574  decode.d4.loss_dice: 1.4808  decode.d5.loss_cls: 1.3222  decode.d5.loss_mask: 0.8326  decode.d5.loss_dice: 1.4794  decode.d6.loss_cls: 1.3502  decode.d6.loss_mask: 0.8454  decode.d6.loss_dice: 1.4921  decode.d7.loss_cls: 1.3527  decode.d7.loss_mask: 0.8343  decode.d7.loss_dice: 1.4530  decode.d8.loss_cls: 1.3472  decode.d8.loss_mask: 0.8206  decode.d8.loss_dice: 1.4462
2023/05/24 00:09:16 - mmengine - INFO - Iter(train) [ 47850/160000]  lr: 7.2630e-06  eta: 13:19:12  time: 0.4131  data_time: 0.0097  memory: 4865  grad_norm: 84.0045  loss: 42.1263  decode.loss_cls: 1.5143  decode.loss_mask: 0.9166  decode.loss_dice: 1.5078  decode.d0.loss_cls: 3.2369  decode.d0.loss_mask: 0.9455  decode.d0.loss_dice: 1.6879  decode.d1.loss_cls: 1.7593  decode.d1.loss_mask: 0.9018  decode.d1.loss_dice: 1.6326  decode.d2.loss_cls: 1.5951  decode.d2.loss_mask: 0.9436  decode.d2.loss_dice: 1.5767  decode.d3.loss_cls: 1.5031  decode.d3.loss_mask: 0.9344  decode.d3.loss_dice: 1.5802  decode.d4.loss_cls: 1.5091  decode.d4.loss_mask: 0.9178  decode.d4.loss_dice: 1.5772  decode.d5.loss_cls: 1.5331  decode.d5.loss_mask: 0.9076  decode.d5.loss_dice: 1.5759  decode.d6.loss_cls: 1.5240  decode.d6.loss_mask: 0.9140  decode.d6.loss_dice: 1.5330  decode.d7.loss_cls: 1.5260  decode.d7.loss_mask: 0.9091  decode.d7.loss_dice: 1.5300  decode.d8.loss_cls: 1.4756  decode.d8.loss_mask: 0.9047  decode.d8.loss_dice: 1.5535
2023/05/24 00:09:38 - mmengine - INFO - Iter(train) [ 47900/160000]  lr: 7.2600e-06  eta: 13:18:52  time: 0.4727  data_time: 0.0097  memory: 4858  grad_norm: 90.9224  loss: 37.8734  decode.loss_cls: 1.2327  decode.loss_mask: 0.7938  decode.loss_dice: 1.5147  decode.d0.loss_cls: 3.2239  decode.d0.loss_mask: 0.7352  decode.d0.loss_dice: 1.6568  decode.d1.loss_cls: 1.4233  decode.d1.loss_mask: 0.8110  decode.d1.loss_dice: 1.5452  decode.d2.loss_cls: 1.3449  decode.d2.loss_mask: 0.8202  decode.d2.loss_dice: 1.4918  decode.d3.loss_cls: 1.2704  decode.d3.loss_mask: 0.8252  decode.d3.loss_dice: 1.4754  decode.d4.loss_cls: 1.2711  decode.d4.loss_mask: 0.8114  decode.d4.loss_dice: 1.4939  decode.d5.loss_cls: 1.2400  decode.d5.loss_mask: 0.7917  decode.d5.loss_dice: 1.5171  decode.d6.loss_cls: 1.2251  decode.d6.loss_mask: 0.8160  decode.d6.loss_dice: 1.4759  decode.d7.loss_cls: 1.2456  decode.d7.loss_mask: 0.7939  decode.d7.loss_dice: 1.4766  decode.d8.loss_cls: 1.2823  decode.d8.loss_mask: 0.7965  decode.d8.loss_dice: 1.4721
2023/05/24 00:09:59 - mmengine - INFO - Iter(train) [ 47950/160000]  lr: 7.2571e-06  eta: 13:18:31  time: 0.4121  data_time: 0.0102  memory: 4832  grad_norm: 86.4380  loss: 34.6761  decode.loss_cls: 1.0529  decode.loss_mask: 0.8756  decode.loss_dice: 1.2363  decode.d0.loss_cls: 2.9864  decode.d0.loss_mask: 0.9510  decode.d0.loss_dice: 1.4117  decode.d1.loss_cls: 1.2103  decode.d1.loss_mask: 0.9657  decode.d1.loss_dice: 1.3024  decode.d2.loss_cls: 1.1053  decode.d2.loss_mask: 0.9463  decode.d2.loss_dice: 1.2533  decode.d3.loss_cls: 1.1245  decode.d3.loss_mask: 0.9176  decode.d3.loss_dice: 1.2376  decode.d4.loss_cls: 1.0953  decode.d4.loss_mask: 0.9161  decode.d4.loss_dice: 1.2843  decode.d5.loss_cls: 1.0194  decode.d5.loss_mask: 0.9515  decode.d5.loss_dice: 1.2521  decode.d6.loss_cls: 1.0455  decode.d6.loss_mask: 0.9238  decode.d6.loss_dice: 1.2463  decode.d7.loss_cls: 1.0106  decode.d7.loss_mask: 0.9214  decode.d7.loss_dice: 1.2453  decode.d8.loss_cls: 1.0197  decode.d8.loss_mask: 0.9173  decode.d8.loss_dice: 1.2506
2023/05/24 00:10:20 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 00:10:20 - mmengine - INFO - Iter(train) [ 48000/160000]  lr: 7.2542e-06  eta: 13:18:08  time: 0.4121  data_time: 0.0097  memory: 4839  grad_norm: 81.2876  loss: 32.9698  decode.loss_cls: 1.0438  decode.loss_mask: 0.7357  decode.loss_dice: 1.2226  decode.d0.loss_cls: 3.1367  decode.d0.loss_mask: 0.7719  decode.d0.loss_dice: 1.4505  decode.d1.loss_cls: 1.1732  decode.d1.loss_mask: 0.7697  decode.d1.loss_dice: 1.3248  decode.d2.loss_cls: 1.0086  decode.d2.loss_mask: 0.7521  decode.d2.loss_dice: 1.2757  decode.d3.loss_cls: 1.0281  decode.d3.loss_mask: 0.7475  decode.d3.loss_dice: 1.2526  decode.d4.loss_cls: 1.0426  decode.d4.loss_mask: 0.7541  decode.d4.loss_dice: 1.2291  decode.d5.loss_cls: 1.0194  decode.d5.loss_mask: 0.7503  decode.d5.loss_dice: 1.2722  decode.d6.loss_cls: 1.0569  decode.d6.loss_mask: 0.7673  decode.d6.loss_dice: 1.2533  decode.d7.loss_cls: 1.0895  decode.d7.loss_mask: 0.7425  decode.d7.loss_dice: 1.2218  decode.d8.loss_cls: 1.1262  decode.d8.loss_mask: 0.7370  decode.d8.loss_dice: 1.2141
2023/05/24 00:10:20 - mmengine - INFO - Saving checkpoint at 48000 iterations
2023/05/24 00:10:47 - mmengine - INFO - Iter(train) [ 48050/160000]  lr: 7.2513e-06  eta: 13:17:59  time: 0.4123  data_time: 0.0099  memory: 4807  grad_norm: 85.8135  loss: 29.9683  decode.loss_cls: 1.1138  decode.loss_mask: 0.5721  decode.loss_dice: 1.0663  decode.d0.loss_cls: 2.8561  decode.d0.loss_mask: 0.5996  decode.d0.loss_dice: 1.2378  decode.d1.loss_cls: 1.2267  decode.d1.loss_mask: 0.5865  decode.d1.loss_dice: 1.2492  decode.d2.loss_cls: 1.1686  decode.d2.loss_mask: 0.5568  decode.d2.loss_dice: 1.1546  decode.d3.loss_cls: 1.1323  decode.d3.loss_mask: 0.5349  decode.d3.loss_dice: 1.0976  decode.d4.loss_cls: 1.1183  decode.d4.loss_mask: 0.5364  decode.d4.loss_dice: 1.1126  decode.d5.loss_cls: 1.1114  decode.d5.loss_mask: 0.5348  decode.d5.loss_dice: 1.1022  decode.d6.loss_cls: 1.1656  decode.d6.loss_mask: 0.5203  decode.d6.loss_dice: 1.0677  decode.d7.loss_cls: 1.1661  decode.d7.loss_mask: 0.5223  decode.d7.loss_dice: 1.0930  decode.d8.loss_cls: 1.1442  decode.d8.loss_mask: 0.5382  decode.d8.loss_dice: 1.0823
2023/05/24 00:11:08 - mmengine - INFO - Iter(train) [ 48100/160000]  lr: 7.2484e-06  eta: 13:17:36  time: 0.4169  data_time: 0.0109  memory: 4889  grad_norm: 106.8747  loss: 37.5352  decode.loss_cls: 1.5457  decode.loss_mask: 0.7849  decode.loss_dice: 1.1821  decode.d0.loss_cls: 3.1221  decode.d0.loss_mask: 0.8353  decode.d0.loss_dice: 1.4294  decode.d1.loss_cls: 1.6444  decode.d1.loss_mask: 0.8171  decode.d1.loss_dice: 1.2780  decode.d2.loss_cls: 1.6380  decode.d2.loss_mask: 0.8560  decode.d2.loss_dice: 1.2173  decode.d3.loss_cls: 1.6059  decode.d3.loss_mask: 0.8211  decode.d3.loss_dice: 1.2012  decode.d4.loss_cls: 1.5608  decode.d4.loss_mask: 0.8030  decode.d4.loss_dice: 1.1910  decode.d5.loss_cls: 1.5791  decode.d5.loss_mask: 0.7877  decode.d5.loss_dice: 1.1694  decode.d6.loss_cls: 1.5731  decode.d6.loss_mask: 0.7953  decode.d6.loss_dice: 1.1411  decode.d7.loss_cls: 1.5549  decode.d7.loss_mask: 0.7736  decode.d7.loss_dice: 1.1528  decode.d8.loss_cls: 1.5138  decode.d8.loss_mask: 0.7979  decode.d8.loss_dice: 1.1632
2023/05/24 00:11:30 - mmengine - INFO - Iter(train) [ 48150/160000]  lr: 7.2455e-06  eta: 13:17:17  time: 0.4670  data_time: 0.0098  memory: 4877  grad_norm: 90.1179  loss: 35.8876  decode.loss_cls: 1.2329  decode.loss_mask: 0.7506  decode.loss_dice: 1.2506  decode.d0.loss_cls: 3.4453  decode.d0.loss_mask: 0.7811  decode.d0.loss_dice: 1.4836  decode.d1.loss_cls: 1.5206  decode.d1.loss_mask: 0.8062  decode.d1.loss_dice: 1.3886  decode.d2.loss_cls: 1.4065  decode.d2.loss_mask: 0.7726  decode.d2.loss_dice: 1.3079  decode.d3.loss_cls: 1.3227  decode.d3.loss_mask: 0.7606  decode.d3.loss_dice: 1.2457  decode.d4.loss_cls: 1.2649  decode.d4.loss_mask: 0.7900  decode.d4.loss_dice: 1.2915  decode.d5.loss_cls: 1.2604  decode.d5.loss_mask: 0.7663  decode.d5.loss_dice: 1.2575  decode.d6.loss_cls: 1.2539  decode.d6.loss_mask: 0.7454  decode.d6.loss_dice: 1.2751  decode.d7.loss_cls: 1.2064  decode.d7.loss_mask: 0.7662  decode.d7.loss_dice: 1.2911  decode.d8.loss_cls: 1.2488  decode.d8.loss_mask: 0.7555  decode.d8.loss_dice: 1.2389
2023/05/24 00:11:51 - mmengine - INFO - Iter(train) [ 48200/160000]  lr: 7.2426e-06  eta: 13:16:56  time: 0.4116  data_time: 0.0098  memory: 4846  grad_norm: 97.7677  loss: 44.3378  decode.loss_cls: 1.3634  decode.loss_mask: 0.9531  decode.loss_dice: 1.7544  decode.d0.loss_cls: 3.6842  decode.d0.loss_mask: 0.9974  decode.d0.loss_dice: 1.9921  decode.d1.loss_cls: 1.5949  decode.d1.loss_mask: 0.9924  decode.d1.loss_dice: 1.9014  decode.d2.loss_cls: 1.4688  decode.d2.loss_mask: 1.0350  decode.d2.loss_dice: 1.8603  decode.d3.loss_cls: 1.3834  decode.d3.loss_mask: 0.9716  decode.d3.loss_dice: 1.7720  decode.d4.loss_cls: 1.4317  decode.d4.loss_mask: 0.9826  decode.d4.loss_dice: 1.8049  decode.d5.loss_cls: 1.3795  decode.d5.loss_mask: 0.9510  decode.d5.loss_dice: 1.7942  decode.d6.loss_cls: 1.3840  decode.d6.loss_mask: 0.9424  decode.d6.loss_dice: 1.7592  decode.d7.loss_cls: 1.3886  decode.d7.loss_mask: 0.9488  decode.d7.loss_dice: 1.7730  decode.d8.loss_cls: 1.4106  decode.d8.loss_mask: 0.9239  decode.d8.loss_dice: 1.7389
2023/05/24 00:12:14 - mmengine - INFO - Iter(train) [ 48250/160000]  lr: 7.2396e-06  eta: 13:16:36  time: 0.4650  data_time: 0.0097  memory: 4878  grad_norm: 98.7839  loss: 38.5024  decode.loss_cls: 1.3814  decode.loss_mask: 0.9211  decode.loss_dice: 1.2909  decode.d0.loss_cls: 3.2741  decode.d0.loss_mask: 0.9110  decode.d0.loss_dice: 1.5089  decode.d1.loss_cls: 1.4916  decode.d1.loss_mask: 0.9521  decode.d1.loss_dice: 1.4142  decode.d2.loss_cls: 1.4706  decode.d2.loss_mask: 0.9022  decode.d2.loss_dice: 1.3626  decode.d3.loss_cls: 1.4141  decode.d3.loss_mask: 0.9272  decode.d3.loss_dice: 1.2941  decode.d4.loss_cls: 1.3770  decode.d4.loss_mask: 0.9294  decode.d4.loss_dice: 1.2909  decode.d5.loss_cls: 1.3919  decode.d5.loss_mask: 0.9228  decode.d5.loss_dice: 1.3101  decode.d6.loss_cls: 1.4036  decode.d6.loss_mask: 0.8864  decode.d6.loss_dice: 1.2858  decode.d7.loss_cls: 1.3183  decode.d7.loss_mask: 0.9096  decode.d7.loss_dice: 1.3121  decode.d8.loss_cls: 1.4496  decode.d8.loss_mask: 0.8949  decode.d8.loss_dice: 1.3039
2023/05/24 00:12:36 - mmengine - INFO - Iter(train) [ 48300/160000]  lr: 7.2367e-06  eta: 13:16:17  time: 0.4198  data_time: 0.0100  memory: 4871  grad_norm: 108.3315  loss: 39.2262  decode.loss_cls: 1.2760  decode.loss_mask: 0.8838  decode.loss_dice: 1.4319  decode.d0.loss_cls: 3.1622  decode.d0.loss_mask: 0.9673  decode.d0.loss_dice: 1.6938  decode.d1.loss_cls: 1.3789  decode.d1.loss_mask: 0.9577  decode.d1.loss_dice: 1.6385  decode.d2.loss_cls: 1.3466  decode.d2.loss_mask: 0.9201  decode.d2.loss_dice: 1.5566  decode.d3.loss_cls: 1.3064  decode.d3.loss_mask: 0.9266  decode.d3.loss_dice: 1.5032  decode.d4.loss_cls: 1.3075  decode.d4.loss_mask: 0.8969  decode.d4.loss_dice: 1.4804  decode.d5.loss_cls: 1.3136  decode.d5.loss_mask: 0.8778  decode.d5.loss_dice: 1.4943  decode.d6.loss_cls: 1.2967  decode.d6.loss_mask: 0.9208  decode.d6.loss_dice: 1.4354  decode.d7.loss_cls: 1.2921  decode.d7.loss_mask: 0.9118  decode.d7.loss_dice: 1.4219  decode.d8.loss_cls: 1.3008  decode.d8.loss_mask: 0.8760  decode.d8.loss_dice: 1.4506
2023/05/24 00:12:57 - mmengine - INFO - Iter(train) [ 48350/160000]  lr: 7.2338e-06  eta: 13:15:55  time: 0.4379  data_time: 0.0098  memory: 4859  grad_norm: 87.0770  loss: 41.3995  decode.loss_cls: 1.3790  decode.loss_mask: 0.8034  decode.loss_dice: 1.6914  decode.d0.loss_cls: 3.1627  decode.d0.loss_mask: 0.8385  decode.d0.loss_dice: 1.9301  decode.d1.loss_cls: 1.4653  decode.d1.loss_mask: 0.8298  decode.d1.loss_dice: 1.8031  decode.d2.loss_cls: 1.4643  decode.d2.loss_mask: 0.8121  decode.d2.loss_dice: 1.7642  decode.d3.loss_cls: 1.4243  decode.d3.loss_mask: 0.8015  decode.d3.loss_dice: 1.7169  decode.d4.loss_cls: 1.4367  decode.d4.loss_mask: 0.7835  decode.d4.loss_dice: 1.7247  decode.d5.loss_cls: 1.3635  decode.d5.loss_mask: 0.7812  decode.d5.loss_dice: 1.7208  decode.d6.loss_cls: 1.4490  decode.d6.loss_mask: 0.7727  decode.d6.loss_dice: 1.6941  decode.d7.loss_cls: 1.4026  decode.d7.loss_mask: 0.8091  decode.d7.loss_dice: 1.7049  decode.d8.loss_cls: 1.3588  decode.d8.loss_mask: 0.8092  decode.d8.loss_dice: 1.7020
2023/05/24 00:13:20 - mmengine - INFO - Iter(train) [ 48400/160000]  lr: 7.2309e-06  eta: 13:15:38  time: 0.4647  data_time: 0.0100  memory: 4829  grad_norm: 84.9857  loss: 36.8759  decode.loss_cls: 1.3195  decode.loss_mask: 0.8173  decode.loss_dice: 1.2782  decode.d0.loss_cls: 3.0715  decode.d0.loss_mask: 0.8995  decode.d0.loss_dice: 1.5483  decode.d1.loss_cls: 1.3822  decode.d1.loss_mask: 0.8589  decode.d1.loss_dice: 1.4476  decode.d2.loss_cls: 1.4171  decode.d2.loss_mask: 0.8176  decode.d2.loss_dice: 1.3919  decode.d3.loss_cls: 1.3485  decode.d3.loss_mask: 0.8343  decode.d3.loss_dice: 1.3307  decode.d4.loss_cls: 1.3172  decode.d4.loss_mask: 0.8261  decode.d4.loss_dice: 1.3110  decode.d5.loss_cls: 1.3217  decode.d5.loss_mask: 0.8239  decode.d5.loss_dice: 1.3339  decode.d6.loss_cls: 1.3273  decode.d6.loss_mask: 0.7983  decode.d6.loss_dice: 1.2812  decode.d7.loss_cls: 1.3130  decode.d7.loss_mask: 0.8044  decode.d7.loss_dice: 1.2628  decode.d8.loss_cls: 1.3093  decode.d8.loss_mask: 0.8102  decode.d8.loss_dice: 1.2724
2023/05/24 00:13:43 - mmengine - INFO - Iter(train) [ 48450/160000]  lr: 7.2280e-06  eta: 13:15:20  time: 0.4235  data_time: 0.0101  memory: 4961  grad_norm: 93.1193  loss: 39.3964  decode.loss_cls: 1.2213  decode.loss_mask: 0.8914  decode.loss_dice: 1.4855  decode.d0.loss_cls: 3.3040  decode.d0.loss_mask: 0.9291  decode.d0.loss_dice: 1.6667  decode.d1.loss_cls: 1.4415  decode.d1.loss_mask: 0.9114  decode.d1.loss_dice: 1.5955  decode.d2.loss_cls: 1.2844  decode.d2.loss_mask: 0.9072  decode.d2.loss_dice: 1.5304  decode.d3.loss_cls: 1.3549  decode.d3.loss_mask: 0.9116  decode.d3.loss_dice: 1.4839  decode.d4.loss_cls: 1.2614  decode.d4.loss_mask: 0.9226  decode.d4.loss_dice: 1.5110  decode.d5.loss_cls: 1.3184  decode.d5.loss_mask: 0.9226  decode.d5.loss_dice: 1.4975  decode.d6.loss_cls: 1.3403  decode.d6.loss_mask: 0.8798  decode.d6.loss_dice: 1.4661  decode.d7.loss_cls: 1.3019  decode.d7.loss_mask: 0.9081  decode.d7.loss_dice: 1.4932  decode.d8.loss_cls: 1.3021  decode.d8.loss_mask: 0.8953  decode.d8.loss_dice: 1.4575
2023/05/24 00:14:04 - mmengine - INFO - Iter(train) [ 48500/160000]  lr: 7.2251e-06  eta: 13:14:57  time: 0.4110  data_time: 0.0101  memory: 4891  grad_norm: 98.1115  loss: 40.6457  decode.loss_cls: 1.5492  decode.loss_mask: 0.8717  decode.loss_dice: 1.3238  decode.d0.loss_cls: 3.6083  decode.d0.loss_mask: 0.9378  decode.d0.loss_dice: 1.6867  decode.d1.loss_cls: 1.6905  decode.d1.loss_mask: 0.8979  decode.d1.loss_dice: 1.4535  decode.d2.loss_cls: 1.5869  decode.d2.loss_mask: 0.8927  decode.d2.loss_dice: 1.4303  decode.d3.loss_cls: 1.6268  decode.d3.loss_mask: 0.8467  decode.d3.loss_dice: 1.3499  decode.d4.loss_cls: 1.5973  decode.d4.loss_mask: 0.8275  decode.d4.loss_dice: 1.3486  decode.d5.loss_cls: 1.6703  decode.d5.loss_mask: 0.8268  decode.d5.loss_dice: 1.3477  decode.d6.loss_cls: 1.6343  decode.d6.loss_mask: 0.8269  decode.d6.loss_dice: 1.3097  decode.d7.loss_cls: 1.6075  decode.d7.loss_mask: 0.8263  decode.d7.loss_dice: 1.3079  decode.d8.loss_cls: 1.5770  decode.d8.loss_mask: 0.8765  decode.d8.loss_dice: 1.3088
2023/05/24 00:14:25 - mmengine - INFO - Iter(train) [ 48550/160000]  lr: 7.2222e-06  eta: 13:14:35  time: 0.4714  data_time: 0.0096  memory: 4960  grad_norm: 103.8050  loss: 47.1661  decode.loss_cls: 1.4055  decode.loss_mask: 0.8833  decode.loss_dice: 1.9809  decode.d0.loss_cls: 3.5963  decode.d0.loss_mask: 0.9886  decode.d0.loss_dice: 2.3105  decode.d1.loss_cls: 1.7160  decode.d1.loss_mask: 1.0893  decode.d1.loss_dice: 2.1882  decode.d2.loss_cls: 1.5903  decode.d2.loss_mask: 1.0272  decode.d2.loss_dice: 2.0610  decode.d3.loss_cls: 1.5062  decode.d3.loss_mask: 0.9751  decode.d3.loss_dice: 2.0186  decode.d4.loss_cls: 1.4810  decode.d4.loss_mask: 0.9290  decode.d4.loss_dice: 2.0260  decode.d5.loss_cls: 1.5047  decode.d5.loss_mask: 0.9026  decode.d5.loss_dice: 1.9670  decode.d6.loss_cls: 1.4782  decode.d6.loss_mask: 0.9027  decode.d6.loss_dice: 1.9510  decode.d7.loss_cls: 1.4644  decode.d7.loss_mask: 0.9356  decode.d7.loss_dice: 1.9588  decode.d8.loss_cls: 1.4369  decode.d8.loss_mask: 0.8944  decode.d8.loss_dice: 1.9966
2023/05/24 00:14:49 - mmengine - INFO - Iter(train) [ 48600/160000]  lr: 7.2192e-06  eta: 13:14:19  time: 0.4674  data_time: 0.0100  memory: 4854  grad_norm: 100.6766  loss: 37.9329  decode.loss_cls: 1.2920  decode.loss_mask: 0.8303  decode.loss_dice: 1.3639  decode.d0.loss_cls: 3.4045  decode.d0.loss_mask: 0.8962  decode.d0.loss_dice: 1.6351  decode.d1.loss_cls: 1.5634  decode.d1.loss_mask: 0.8617  decode.d1.loss_dice: 1.4500  decode.d2.loss_cls: 1.3286  decode.d2.loss_mask: 0.8660  decode.d2.loss_dice: 1.4137  decode.d3.loss_cls: 1.3012  decode.d3.loss_mask: 0.8453  decode.d3.loss_dice: 1.4090  decode.d4.loss_cls: 1.2851  decode.d4.loss_mask: 0.8420  decode.d4.loss_dice: 1.4028  decode.d5.loss_cls: 1.2701  decode.d5.loss_mask: 0.8448  decode.d5.loss_dice: 1.3780  decode.d6.loss_cls: 1.1988  decode.d6.loss_mask: 0.8491  decode.d6.loss_dice: 1.4047  decode.d7.loss_cls: 1.2578  decode.d7.loss_mask: 0.8493  decode.d7.loss_dice: 1.3822  decode.d8.loss_cls: 1.2536  decode.d8.loss_mask: 0.8521  decode.d8.loss_dice: 1.4013
2023/05/24 00:15:10 - mmengine - INFO - Iter(train) [ 48650/160000]  lr: 7.2163e-06  eta: 13:13:56  time: 0.4138  data_time: 0.0100  memory: 4898  grad_norm: 88.5712  loss: 36.8473  decode.loss_cls: 1.1931  decode.loss_mask: 0.9445  decode.loss_dice: 1.2491  decode.d0.loss_cls: 3.1446  decode.d0.loss_mask: 1.0247  decode.d0.loss_dice: 1.5050  decode.d1.loss_cls: 1.3991  decode.d1.loss_mask: 0.8805  decode.d1.loss_dice: 1.3620  decode.d2.loss_cls: 1.2429  decode.d2.loss_mask: 0.8874  decode.d2.loss_dice: 1.3577  decode.d3.loss_cls: 1.2330  decode.d3.loss_mask: 0.9125  decode.d3.loss_dice: 1.3399  decode.d4.loss_cls: 1.2511  decode.d4.loss_mask: 0.9095  decode.d4.loss_dice: 1.2776  decode.d5.loss_cls: 1.2939  decode.d5.loss_mask: 0.9068  decode.d5.loss_dice: 1.2614  decode.d6.loss_cls: 1.2255  decode.d6.loss_mask: 0.9183  decode.d6.loss_dice: 1.3022  decode.d7.loss_cls: 1.2610  decode.d7.loss_mask: 0.8810  decode.d7.loss_dice: 1.2639  decode.d8.loss_cls: 1.2822  decode.d8.loss_mask: 0.8702  decode.d8.loss_dice: 1.2666
2023/05/24 00:15:30 - mmengine - INFO - Iter(train) [ 48700/160000]  lr: 7.2134e-06  eta: 13:13:33  time: 0.4117  data_time: 0.0101  memory: 4824  grad_norm: 124.4235  loss: 43.2335  decode.loss_cls: 1.3616  decode.loss_mask: 0.9025  decode.loss_dice: 1.7595  decode.d0.loss_cls: 3.4840  decode.d0.loss_mask: 0.9433  decode.d0.loss_dice: 1.9703  decode.d1.loss_cls: 1.5424  decode.d1.loss_mask: 0.9057  decode.d1.loss_dice: 1.8477  decode.d2.loss_cls: 1.4976  decode.d2.loss_mask: 0.9034  decode.d2.loss_dice: 1.7883  decode.d3.loss_cls: 1.4277  decode.d3.loss_mask: 0.9005  decode.d3.loss_dice: 1.7772  decode.d4.loss_cls: 1.4029  decode.d4.loss_mask: 0.8768  decode.d4.loss_dice: 1.7404  decode.d5.loss_cls: 1.5277  decode.d5.loss_mask: 0.8731  decode.d5.loss_dice: 1.7299  decode.d6.loss_cls: 1.4934  decode.d6.loss_mask: 0.8837  decode.d6.loss_dice: 1.6886  decode.d7.loss_cls: 1.3880  decode.d7.loss_mask: 0.8910  decode.d7.loss_dice: 1.7169  decode.d8.loss_cls: 1.3912  decode.d8.loss_mask: 0.9001  decode.d8.loss_dice: 1.7180
2023/05/24 00:15:51 - mmengine - INFO - Iter(train) [ 48750/160000]  lr: 7.2105e-06  eta: 13:13:10  time: 0.4170  data_time: 0.0101  memory: 4846  grad_norm: 93.3779  loss: 35.4508  decode.loss_cls: 1.3736  decode.loss_mask: 0.7302  decode.loss_dice: 1.1406  decode.d0.loss_cls: 3.0934  decode.d0.loss_mask: 0.8327  decode.d0.loss_dice: 1.4223  decode.d1.loss_cls: 1.4629  decode.d1.loss_mask: 0.7858  decode.d1.loss_dice: 1.2967  decode.d2.loss_cls: 1.4794  decode.d2.loss_mask: 0.7768  decode.d2.loss_dice: 1.2312  decode.d3.loss_cls: 1.3804  decode.d3.loss_mask: 0.7681  decode.d3.loss_dice: 1.2069  decode.d4.loss_cls: 1.3919  decode.d4.loss_mask: 0.7505  decode.d4.loss_dice: 1.2064  decode.d5.loss_cls: 1.3916  decode.d5.loss_mask: 0.7384  decode.d5.loss_dice: 1.1945  decode.d6.loss_cls: 1.3878  decode.d6.loss_mask: 0.7490  decode.d6.loss_dice: 1.1339  decode.d7.loss_cls: 1.3244  decode.d7.loss_mask: 0.7497  decode.d7.loss_dice: 1.1830  decode.d8.loss_cls: 1.3504  decode.d8.loss_mask: 0.7364  decode.d8.loss_dice: 1.1817
2023/05/24 00:16:12 - mmengine - INFO - Iter(train) [ 48800/160000]  lr: 7.2076e-06  eta: 13:12:47  time: 0.4131  data_time: 0.0099  memory: 4824  grad_norm: 138.5581  loss: 35.6364  decode.loss_cls: 1.1368  decode.loss_mask: 0.8566  decode.loss_dice: 1.1565  decode.d0.loss_cls: 3.3093  decode.d0.loss_mask: 0.9585  decode.d0.loss_dice: 1.4020  decode.d1.loss_cls: 1.3494  decode.d1.loss_mask: 0.9627  decode.d1.loss_dice: 1.3001  decode.d2.loss_cls: 1.3024  decode.d2.loss_mask: 0.9560  decode.d2.loss_dice: 1.2313  decode.d3.loss_cls: 1.3289  decode.d3.loss_mask: 0.8603  decode.d3.loss_dice: 1.1537  decode.d4.loss_cls: 1.2264  decode.d4.loss_mask: 0.8551  decode.d4.loss_dice: 1.2144  decode.d5.loss_cls: 1.1500  decode.d5.loss_mask: 0.8991  decode.d5.loss_dice: 1.2063  decode.d6.loss_cls: 1.2134  decode.d6.loss_mask: 0.8716  decode.d6.loss_dice: 1.1991  decode.d7.loss_cls: 1.2107  decode.d7.loss_mask: 0.8800  decode.d7.loss_dice: 1.1816  decode.d8.loss_cls: 1.1987  decode.d8.loss_mask: 0.8749  decode.d8.loss_dice: 1.1905
2023/05/24 00:16:32 - mmengine - INFO - Iter(train) [ 48850/160000]  lr: 7.2047e-06  eta: 13:12:24  time: 0.4061  data_time: 0.0099  memory: 4885  grad_norm: 95.8206  loss: 41.6417  decode.loss_cls: 1.3249  decode.loss_mask: 0.9428  decode.loss_dice: 1.5685  decode.d0.loss_cls: 3.2451  decode.d0.loss_mask: 0.9988  decode.d0.loss_dice: 1.7694  decode.d1.loss_cls: 1.4923  decode.d1.loss_mask: 0.9570  decode.d1.loss_dice: 1.6889  decode.d2.loss_cls: 1.4310  decode.d2.loss_mask: 0.9519  decode.d2.loss_dice: 1.6044  decode.d3.loss_cls: 1.4011  decode.d3.loss_mask: 0.9951  decode.d3.loss_dice: 1.6113  decode.d4.loss_cls: 1.3436  decode.d4.loss_mask: 1.0053  decode.d4.loss_dice: 1.6325  decode.d5.loss_cls: 1.3741  decode.d5.loss_mask: 0.9842  decode.d5.loss_dice: 1.5853  decode.d6.loss_cls: 1.3825  decode.d6.loss_mask: 0.9709  decode.d6.loss_dice: 1.6126  decode.d7.loss_cls: 1.3549  decode.d7.loss_mask: 0.9484  decode.d7.loss_dice: 1.5950  decode.d8.loss_cls: 1.3378  decode.d8.loss_mask: 0.9209  decode.d8.loss_dice: 1.6110
2023/05/24 00:16:53 - mmengine - INFO - Iter(train) [ 48900/160000]  lr: 7.2017e-06  eta: 13:12:01  time: 0.4128  data_time: 0.0098  memory: 4836  grad_norm: 147.4620  loss: 36.2802  decode.loss_cls: 1.2564  decode.loss_mask: 0.8566  decode.loss_dice: 1.2712  decode.d0.loss_cls: 3.1075  decode.d0.loss_mask: 0.8210  decode.d0.loss_dice: 1.4237  decode.d1.loss_cls: 1.4215  decode.d1.loss_mask: 0.9073  decode.d1.loss_dice: 1.3106  decode.d2.loss_cls: 1.3265  decode.d2.loss_mask: 0.8921  decode.d2.loss_dice: 1.2684  decode.d3.loss_cls: 1.3013  decode.d3.loss_mask: 0.8647  decode.d3.loss_dice: 1.3027  decode.d4.loss_cls: 1.2553  decode.d4.loss_mask: 0.8446  decode.d4.loss_dice: 1.3166  decode.d5.loss_cls: 1.3455  decode.d5.loss_mask: 0.8196  decode.d5.loss_dice: 1.2290  decode.d6.loss_cls: 1.2621  decode.d6.loss_mask: 0.8416  decode.d6.loss_dice: 1.2690  decode.d7.loss_cls: 1.2737  decode.d7.loss_mask: 0.8486  decode.d7.loss_dice: 1.2418  decode.d8.loss_cls: 1.2612  decode.d8.loss_mask: 0.8627  decode.d8.loss_dice: 1.2773
2023/05/24 00:17:13 - mmengine - INFO - Iter(train) [ 48950/160000]  lr: 7.1988e-06  eta: 13:11:38  time: 0.4159  data_time: 0.0097  memory: 4831  grad_norm: 134.5725  loss: 36.8597  decode.loss_cls: 1.0509  decode.loss_mask: 0.8551  decode.loss_dice: 1.5020  decode.d0.loss_cls: 3.0482  decode.d0.loss_mask: 0.8870  decode.d0.loss_dice: 1.6331  decode.d1.loss_cls: 1.2246  decode.d1.loss_mask: 0.8857  decode.d1.loss_dice: 1.6341  decode.d2.loss_cls: 1.0662  decode.d2.loss_mask: 0.8685  decode.d2.loss_dice: 1.5292  decode.d3.loss_cls: 1.1563  decode.d3.loss_mask: 0.8522  decode.d3.loss_dice: 1.5264  decode.d4.loss_cls: 1.0632  decode.d4.loss_mask: 0.8772  decode.d4.loss_dice: 1.5598  decode.d5.loss_cls: 1.0803  decode.d5.loss_mask: 0.8554  decode.d5.loss_dice: 1.4885  decode.d6.loss_cls: 1.1264  decode.d6.loss_mask: 0.8284  decode.d6.loss_dice: 1.4864  decode.d7.loss_cls: 1.0824  decode.d7.loss_mask: 0.8263  decode.d7.loss_dice: 1.4852  decode.d8.loss_cls: 1.0477  decode.d8.loss_mask: 0.8453  decode.d8.loss_dice: 1.4877
2023/05/24 00:17:35 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 00:17:35 - mmengine - INFO - Iter(train) [ 49000/160000]  lr: 7.1959e-06  eta: 13:11:16  time: 0.4101  data_time: 0.0102  memory: 4928  grad_norm: 109.7942  loss: 36.8795  decode.loss_cls: 1.4564  decode.loss_mask: 0.7138  decode.loss_dice: 1.0786  decode.d0.loss_cls: 3.3212  decode.d0.loss_mask: 0.8829  decode.d0.loss_dice: 1.4364  decode.d1.loss_cls: 1.6519  decode.d1.loss_mask: 0.8934  decode.d1.loss_dice: 1.2691  decode.d2.loss_cls: 1.6858  decode.d2.loss_mask: 0.8194  decode.d2.loss_dice: 1.1742  decode.d3.loss_cls: 1.6264  decode.d3.loss_mask: 0.8208  decode.d3.loss_dice: 1.1352  decode.d4.loss_cls: 1.5474  decode.d4.loss_mask: 0.8175  decode.d4.loss_dice: 1.1245  decode.d5.loss_cls: 1.5554  decode.d5.loss_mask: 0.7725  decode.d5.loss_dice: 1.1000  decode.d6.loss_cls: 1.5542  decode.d6.loss_mask: 0.7428  decode.d6.loss_dice: 1.0804  decode.d7.loss_cls: 1.5185  decode.d7.loss_mask: 0.7228  decode.d7.loss_dice: 1.0704  decode.d8.loss_cls: 1.4706  decode.d8.loss_mask: 0.7328  decode.d8.loss_dice: 1.1043
2023/05/24 00:17:35 - mmengine - INFO - Saving checkpoint at 49000 iterations
2023/05/24 00:18:01 - mmengine - INFO - Iter(train) [ 49050/160000]  lr: 7.1930e-06  eta: 13:11:06  time: 0.4093  data_time: 0.0099  memory: 4871  grad_norm: 107.7937  loss: 39.9679  decode.loss_cls: 1.4254  decode.loss_mask: 0.9844  decode.loss_dice: 1.3222  decode.d0.loss_cls: 3.0695  decode.d0.loss_mask: 1.1618  decode.d0.loss_dice: 1.5884  decode.d1.loss_cls: 1.4831  decode.d1.loss_mask: 1.0542  decode.d1.loss_dice: 1.4394  decode.d2.loss_cls: 1.4603  decode.d2.loss_mask: 1.0276  decode.d2.loss_dice: 1.4200  decode.d3.loss_cls: 1.4105  decode.d3.loss_mask: 1.0053  decode.d3.loss_dice: 1.3292  decode.d4.loss_cls: 1.4221  decode.d4.loss_mask: 1.0038  decode.d4.loss_dice: 1.3666  decode.d5.loss_cls: 1.3936  decode.d5.loss_mask: 1.0200  decode.d5.loss_dice: 1.3694  decode.d6.loss_cls: 1.3759  decode.d6.loss_mask: 1.0019  decode.d6.loss_dice: 1.3506  decode.d7.loss_cls: 1.3675  decode.d7.loss_mask: 1.0007  decode.d7.loss_dice: 1.3617  decode.d8.loss_cls: 1.3852  decode.d8.loss_mask: 1.0057  decode.d8.loss_dice: 1.3615
2023/05/24 00:18:23 - mmengine - INFO - Iter(train) [ 49100/160000]  lr: 7.1901e-06  eta: 13:10:45  time: 0.4724  data_time: 0.0098  memory: 4857  grad_norm: 127.2512  loss: 31.5715  decode.loss_cls: 1.1956  decode.loss_mask: 0.6292  decode.loss_dice: 1.0943  decode.d0.loss_cls: 2.9597  decode.d0.loss_mask: 0.7682  decode.d0.loss_dice: 1.2835  decode.d1.loss_cls: 1.1731  decode.d1.loss_mask: 0.6953  decode.d1.loss_dice: 1.1772  decode.d2.loss_cls: 1.2459  decode.d2.loss_mask: 0.6633  decode.d2.loss_dice: 1.1476  decode.d3.loss_cls: 1.1929  decode.d3.loss_mask: 0.6411  decode.d3.loss_dice: 1.0812  decode.d4.loss_cls: 1.1611  decode.d4.loss_mask: 0.6587  decode.d4.loss_dice: 1.0964  decode.d5.loss_cls: 1.1688  decode.d5.loss_mask: 0.6569  decode.d5.loss_dice: 1.0945  decode.d6.loss_cls: 1.1621  decode.d6.loss_mask: 0.6554  decode.d6.loss_dice: 1.0743  decode.d7.loss_cls: 1.1472  decode.d7.loss_mask: 0.6692  decode.d7.loss_dice: 1.1216  decode.d8.loss_cls: 1.1932  decode.d8.loss_mask: 0.6700  decode.d8.loss_dice: 1.0940
2023/05/24 00:18:44 - mmengine - INFO - Iter(train) [ 49150/160000]  lr: 7.1871e-06  eta: 13:10:24  time: 0.4112  data_time: 0.0099  memory: 4829  grad_norm: 98.6720  loss: 50.9590  decode.loss_cls: 1.8230  decode.loss_mask: 0.9740  decode.loss_dice: 1.9358  decode.d0.loss_cls: 4.0311  decode.d0.loss_mask: 1.0596  decode.d0.loss_dice: 2.3337  decode.d1.loss_cls: 2.0675  decode.d1.loss_mask: 0.9984  decode.d1.loss_dice: 2.0415  decode.d2.loss_cls: 1.9104  decode.d2.loss_mask: 0.9976  decode.d2.loss_dice: 2.0238  decode.d3.loss_cls: 1.8714  decode.d3.loss_mask: 0.9671  decode.d3.loss_dice: 1.9817  decode.d4.loss_cls: 1.8241  decode.d4.loss_mask: 0.9573  decode.d4.loss_dice: 2.0194  decode.d5.loss_cls: 1.8671  decode.d5.loss_mask: 0.9957  decode.d5.loss_dice: 1.9493  decode.d6.loss_cls: 1.8354  decode.d6.loss_mask: 0.9992  decode.d6.loss_dice: 1.9643  decode.d7.loss_cls: 1.8244  decode.d7.loss_mask: 0.9819  decode.d7.loss_dice: 1.9756  decode.d8.loss_cls: 1.8415  decode.d8.loss_mask: 0.9513  decode.d8.loss_dice: 1.9558
2023/05/24 00:19:06 - mmengine - INFO - Iter(train) [ 49200/160000]  lr: 7.1842e-06  eta: 13:10:03  time: 0.4176  data_time: 0.0098  memory: 4803  grad_norm: 99.9081  loss: 32.7712  decode.loss_cls: 1.0842  decode.loss_mask: 0.6903  decode.loss_dice: 1.2221  decode.d0.loss_cls: 2.8253  decode.d0.loss_mask: 0.7441  decode.d0.loss_dice: 1.4039  decode.d1.loss_cls: 1.2631  decode.d1.loss_mask: 0.7085  decode.d1.loss_dice: 1.3056  decode.d2.loss_cls: 1.1733  decode.d2.loss_mask: 0.7313  decode.d2.loss_dice: 1.2890  decode.d3.loss_cls: 1.1832  decode.d3.loss_mask: 0.7156  decode.d3.loss_dice: 1.2465  decode.d4.loss_cls: 1.1138  decode.d4.loss_mask: 0.7059  decode.d4.loss_dice: 1.2620  decode.d5.loss_cls: 1.1217  decode.d5.loss_mask: 0.6903  decode.d5.loss_dice: 1.2222  decode.d6.loss_cls: 1.1123  decode.d6.loss_mask: 0.6807  decode.d6.loss_dice: 1.2187  decode.d7.loss_cls: 1.0873  decode.d7.loss_mask: 0.6963  decode.d7.loss_dice: 1.2487  decode.d8.loss_cls: 1.0808  decode.d8.loss_mask: 0.6810  decode.d8.loss_dice: 1.2637
2023/05/24 00:19:27 - mmengine - INFO - Iter(train) [ 49250/160000]  lr: 7.1813e-06  eta: 13:09:40  time: 0.4244  data_time: 0.0105  memory: 4862  grad_norm: 91.7889  loss: 36.4746  decode.loss_cls: 1.1334  decode.loss_mask: 0.9198  decode.loss_dice: 1.3479  decode.d0.loss_cls: 3.0470  decode.d0.loss_mask: 0.9885  decode.d0.loss_dice: 1.4918  decode.d1.loss_cls: 1.2821  decode.d1.loss_mask: 0.9771  decode.d1.loss_dice: 1.3894  decode.d2.loss_cls: 1.2007  decode.d2.loss_mask: 0.8961  decode.d2.loss_dice: 1.3192  decode.d3.loss_cls: 1.2422  decode.d3.loss_mask: 0.9047  decode.d3.loss_dice: 1.3070  decode.d4.loss_cls: 1.2082  decode.d4.loss_mask: 0.9271  decode.d4.loss_dice: 1.3119  decode.d5.loss_cls: 1.2713  decode.d5.loss_mask: 0.8932  decode.d5.loss_dice: 1.2827  decode.d6.loss_cls: 1.1944  decode.d6.loss_mask: 0.8908  decode.d6.loss_dice: 1.2983  decode.d7.loss_cls: 1.1788  decode.d7.loss_mask: 0.8977  decode.d7.loss_dice: 1.3041  decode.d8.loss_cls: 1.1785  decode.d8.loss_mask: 0.9052  decode.d8.loss_dice: 1.2856
2023/05/24 00:19:47 - mmengine - INFO - Iter(train) [ 49300/160000]  lr: 7.1784e-06  eta: 13:09:17  time: 0.4111  data_time: 0.0102  memory: 4847  grad_norm: 106.6831  loss: 43.1387  decode.loss_cls: 1.5351  decode.loss_mask: 0.9297  decode.loss_dice: 1.4674  decode.d0.loss_cls: 3.3435  decode.d0.loss_mask: 1.0947  decode.d0.loss_dice: 1.8830  decode.d1.loss_cls: 1.6792  decode.d1.loss_mask: 0.9770  decode.d1.loss_dice: 1.6884  decode.d2.loss_cls: 1.5266  decode.d2.loss_mask: 0.9800  decode.d2.loss_dice: 1.6061  decode.d3.loss_cls: 1.5506  decode.d3.loss_mask: 0.9627  decode.d3.loss_dice: 1.5734  decode.d4.loss_cls: 1.5548  decode.d4.loss_mask: 0.9629  decode.d4.loss_dice: 1.5967  decode.d5.loss_cls: 1.5202  decode.d5.loss_mask: 0.9909  decode.d5.loss_dice: 1.5515  decode.d6.loss_cls: 1.5494  decode.d6.loss_mask: 0.9968  decode.d6.loss_dice: 1.5367  decode.d7.loss_cls: 1.4843  decode.d7.loss_mask: 0.9896  decode.d7.loss_dice: 1.5975  decode.d8.loss_cls: 1.5220  decode.d8.loss_mask: 0.9550  decode.d8.loss_dice: 1.5331
2023/05/24 00:20:08 - mmengine - INFO - Iter(train) [ 49350/160000]  lr: 7.1755e-06  eta: 13:08:55  time: 0.4084  data_time: 0.0103  memory: 4857  grad_norm: 97.7083  loss: 30.6993  decode.loss_cls: 1.1510  decode.loss_mask: 0.7538  decode.loss_dice: 0.9397  decode.d0.loss_cls: 2.7903  decode.d0.loss_mask: 0.8193  decode.d0.loss_dice: 1.1570  decode.d1.loss_cls: 1.2456  decode.d1.loss_mask: 0.7742  decode.d1.loss_dice: 1.0576  decode.d2.loss_cls: 1.1360  decode.d2.loss_mask: 0.7558  decode.d2.loss_dice: 1.0007  decode.d3.loss_cls: 1.0997  decode.d3.loss_mask: 0.7949  decode.d3.loss_dice: 0.9825  decode.d4.loss_cls: 1.0775  decode.d4.loss_mask: 0.7938  decode.d4.loss_dice: 0.9805  decode.d5.loss_cls: 1.0427  decode.d5.loss_mask: 0.8378  decode.d5.loss_dice: 0.9627  decode.d6.loss_cls: 1.1379  decode.d6.loss_mask: 0.7780  decode.d6.loss_dice: 0.9344  decode.d7.loss_cls: 1.1405  decode.d7.loss_mask: 0.7660  decode.d7.loss_dice: 0.9356  decode.d8.loss_cls: 1.1500  decode.d8.loss_mask: 0.7682  decode.d8.loss_dice: 0.9355
2023/05/24 00:20:29 - mmengine - INFO - Iter(train) [ 49400/160000]  lr: 7.1726e-06  eta: 13:08:32  time: 0.4240  data_time: 0.0099  memory: 4841  grad_norm: 99.7594  loss: 31.8065  decode.loss_cls: 0.9920  decode.loss_mask: 0.8263  decode.loss_dice: 1.1037  decode.d0.loss_cls: 2.9733  decode.d0.loss_mask: 0.8119  decode.d0.loss_dice: 1.1316  decode.d1.loss_cls: 1.2142  decode.d1.loss_mask: 0.7844  decode.d1.loss_dice: 1.1133  decode.d2.loss_cls: 1.0384  decode.d2.loss_mask: 0.8789  decode.d2.loss_dice: 1.1679  decode.d3.loss_cls: 1.0733  decode.d3.loss_mask: 0.8409  decode.d3.loss_dice: 1.1189  decode.d4.loss_cls: 1.0763  decode.d4.loss_mask: 0.8422  decode.d4.loss_dice: 1.1182  decode.d5.loss_cls: 0.9800  decode.d5.loss_mask: 0.8107  decode.d5.loss_dice: 1.1006  decode.d6.loss_cls: 0.9730  decode.d6.loss_mask: 0.8347  decode.d6.loss_dice: 1.1214  decode.d7.loss_cls: 1.0307  decode.d7.loss_mask: 0.8388  decode.d7.loss_dice: 1.0946  decode.d8.loss_cls: 0.9943  decode.d8.loss_mask: 0.8275  decode.d8.loss_dice: 1.0945
2023/05/24 00:20:50 - mmengine - INFO - Iter(train) [ 49450/160000]  lr: 7.1696e-06  eta: 13:08:10  time: 0.4224  data_time: 0.0102  memory: 4857  grad_norm: 91.0556  loss: 45.0439  decode.loss_cls: 1.5806  decode.loss_mask: 0.9938  decode.loss_dice: 1.5955  decode.d0.loss_cls: 3.5553  decode.d0.loss_mask: 1.1103  decode.d0.loss_dice: 1.9359  decode.d1.loss_cls: 1.6812  decode.d1.loss_mask: 1.1072  decode.d1.loss_dice: 1.8038  decode.d2.loss_cls: 1.6481  decode.d2.loss_mask: 1.0765  decode.d2.loss_dice: 1.7088  decode.d3.loss_cls: 1.6509  decode.d3.loss_mask: 0.9794  decode.d3.loss_dice: 1.6331  decode.d4.loss_cls: 1.5498  decode.d4.loss_mask: 0.9779  decode.d4.loss_dice: 1.6312  decode.d5.loss_cls: 1.5890  decode.d5.loss_mask: 1.0096  decode.d5.loss_dice: 1.6609  decode.d6.loss_cls: 1.5243  decode.d6.loss_mask: 1.0032  decode.d6.loss_dice: 1.6320  decode.d7.loss_cls: 1.5621  decode.d7.loss_mask: 1.0413  decode.d7.loss_dice: 1.5739  decode.d8.loss_cls: 1.5959  decode.d8.loss_mask: 0.9923  decode.d8.loss_dice: 1.6400
2023/05/24 00:21:11 - mmengine - INFO - Iter(train) [ 49500/160000]  lr: 7.1667e-06  eta: 13:07:47  time: 0.4127  data_time: 0.0097  memory: 4930  grad_norm: 99.2967  loss: 31.7474  decode.loss_cls: 1.2919  decode.loss_mask: 0.6325  decode.loss_dice: 1.0080  decode.d0.loss_cls: 2.9326  decode.d0.loss_mask: 0.7374  decode.d0.loss_dice: 1.1322  decode.d1.loss_cls: 1.4340  decode.d1.loss_mask: 0.7421  decode.d1.loss_dice: 1.1208  decode.d2.loss_cls: 1.3024  decode.d2.loss_mask: 0.6701  decode.d2.loss_dice: 1.0493  decode.d3.loss_cls: 1.3443  decode.d3.loss_mask: 0.6486  decode.d3.loss_dice: 1.0287  decode.d4.loss_cls: 1.2620  decode.d4.loss_mask: 0.6551  decode.d4.loss_dice: 1.0030  decode.d5.loss_cls: 1.2839  decode.d5.loss_mask: 0.6460  decode.d5.loss_dice: 1.0186  decode.d6.loss_cls: 1.2433  decode.d6.loss_mask: 0.6447  decode.d6.loss_dice: 1.0062  decode.d7.loss_cls: 1.2643  decode.d7.loss_mask: 0.6501  decode.d7.loss_dice: 1.0042  decode.d8.loss_cls: 1.3059  decode.d8.loss_mask: 0.6706  decode.d8.loss_dice: 1.0147
2023/05/24 00:21:33 - mmengine - INFO - Iter(train) [ 49550/160000]  lr: 7.1638e-06  eta: 13:07:27  time: 0.4174  data_time: 0.0098  memory: 4826  grad_norm: 90.6541  loss: 28.4412  decode.loss_cls: 0.9905  decode.loss_mask: 0.7195  decode.loss_dice: 0.8796  decode.d0.loss_cls: 2.6874  decode.d0.loss_mask: 0.7674  decode.d0.loss_dice: 1.0104  decode.d1.loss_cls: 1.1765  decode.d1.loss_mask: 0.7567  decode.d1.loss_dice: 0.9574  decode.d2.loss_cls: 1.0842  decode.d2.loss_mask: 0.7332  decode.d2.loss_dice: 0.9458  decode.d3.loss_cls: 1.0570  decode.d3.loss_mask: 0.7169  decode.d3.loss_dice: 0.8925  decode.d4.loss_cls: 1.0095  decode.d4.loss_mask: 0.7004  decode.d4.loss_dice: 0.8969  decode.d5.loss_cls: 1.0467  decode.d5.loss_mask: 0.7269  decode.d5.loss_dice: 0.9069  decode.d6.loss_cls: 0.9791  decode.d6.loss_mask: 0.7154  decode.d6.loss_dice: 0.8895  decode.d7.loss_cls: 1.0025  decode.d7.loss_mask: 0.7004  decode.d7.loss_dice: 0.8763  decode.d8.loss_cls: 1.0006  decode.d8.loss_mask: 0.7201  decode.d8.loss_dice: 0.8948
2023/05/24 00:21:54 - mmengine - INFO - Iter(train) [ 49600/160000]  lr: 7.1609e-06  eta: 13:07:05  time: 0.4244  data_time: 0.0101  memory: 4829  grad_norm: 98.3613  loss: 40.9750  decode.loss_cls: 1.3590  decode.loss_mask: 0.7982  decode.loss_dice: 1.5959  decode.d0.loss_cls: 3.2828  decode.d0.loss_mask: 0.8754  decode.d0.loss_dice: 1.8952  decode.d1.loss_cls: 1.5127  decode.d1.loss_mask: 0.8843  decode.d1.loss_dice: 1.7179  decode.d2.loss_cls: 1.4311  decode.d2.loss_mask: 0.8739  decode.d2.loss_dice: 1.6917  decode.d3.loss_cls: 1.4339  decode.d3.loss_mask: 0.8189  decode.d3.loss_dice: 1.6632  decode.d4.loss_cls: 1.4036  decode.d4.loss_mask: 0.8022  decode.d4.loss_dice: 1.6696  decode.d5.loss_cls: 1.3814  decode.d5.loss_mask: 0.8354  decode.d5.loss_dice: 1.6731  decode.d6.loss_cls: 1.3786  decode.d6.loss_mask: 0.8012  decode.d6.loss_dice: 1.6114  decode.d7.loss_cls: 1.4165  decode.d7.loss_mask: 0.7675  decode.d7.loss_dice: 1.6152  decode.d8.loss_cls: 1.3638  decode.d8.loss_mask: 0.7988  decode.d8.loss_dice: 1.6225
2023/05/24 00:22:15 - mmengine - INFO - Iter(train) [ 49650/160000]  lr: 7.1580e-06  eta: 13:06:42  time: 0.4122  data_time: 0.0099  memory: 4811  grad_norm: 94.9733  loss: 36.8757  decode.loss_cls: 1.3396  decode.loss_mask: 0.7763  decode.loss_dice: 1.2643  decode.d0.loss_cls: 3.3658  decode.d0.loss_mask: 0.7579  decode.d0.loss_dice: 1.4194  decode.d1.loss_cls: 1.4049  decode.d1.loss_mask: 0.7980  decode.d1.loss_dice: 1.3811  decode.d2.loss_cls: 1.4699  decode.d2.loss_mask: 0.7895  decode.d2.loss_dice: 1.3901  decode.d3.loss_cls: 1.5089  decode.d3.loss_mask: 0.7671  decode.d3.loss_dice: 1.2990  decode.d4.loss_cls: 1.4551  decode.d4.loss_mask: 0.7818  decode.d4.loss_dice: 1.3040  decode.d5.loss_cls: 1.4209  decode.d5.loss_mask: 0.7594  decode.d5.loss_dice: 1.3111  decode.d6.loss_cls: 1.4136  decode.d6.loss_mask: 0.7358  decode.d6.loss_dice: 1.2837  decode.d7.loss_cls: 1.3019  decode.d7.loss_mask: 0.7512  decode.d7.loss_dice: 1.2821  decode.d8.loss_cls: 1.3129  decode.d8.loss_mask: 0.7474  decode.d8.loss_dice: 1.2829
2023/05/24 00:22:35 - mmengine - INFO - Iter(train) [ 49700/160000]  lr: 7.1550e-06  eta: 13:06:19  time: 0.4163  data_time: 0.0104  memory: 4887  grad_norm: 89.4064  loss: 36.9628  decode.loss_cls: 1.2835  decode.loss_mask: 0.8281  decode.loss_dice: 1.3263  decode.d0.loss_cls: 2.9473  decode.d0.loss_mask: 0.9605  decode.d0.loss_dice: 1.5984  decode.d1.loss_cls: 1.3758  decode.d1.loss_mask: 0.8711  decode.d1.loss_dice: 1.4398  decode.d2.loss_cls: 1.3489  decode.d2.loss_mask: 0.8239  decode.d2.loss_dice: 1.3708  decode.d3.loss_cls: 1.3622  decode.d3.loss_mask: 0.7930  decode.d3.loss_dice: 1.3428  decode.d4.loss_cls: 1.3376  decode.d4.loss_mask: 0.7768  decode.d4.loss_dice: 1.3486  decode.d5.loss_cls: 1.2927  decode.d5.loss_mask: 0.7885  decode.d5.loss_dice: 1.3529  decode.d6.loss_cls: 1.3211  decode.d6.loss_mask: 0.8080  decode.d6.loss_dice: 1.3542  decode.d7.loss_cls: 1.2885  decode.d7.loss_mask: 0.8116  decode.d7.loss_dice: 1.3413  decode.d8.loss_cls: 1.3342  decode.d8.loss_mask: 0.7970  decode.d8.loss_dice: 1.3374
2023/05/24 00:22:59 - mmengine - INFO - Iter(train) [ 49750/160000]  lr: 7.1521e-06  eta: 13:06:02  time: 0.4730  data_time: 0.0100  memory: 4852  grad_norm: 99.0263  loss: 39.3377  decode.loss_cls: 1.2696  decode.loss_mask: 0.8970  decode.loss_dice: 1.4552  decode.d0.loss_cls: 3.2510  decode.d0.loss_mask: 1.0140  decode.d0.loss_dice: 1.7145  decode.d1.loss_cls: 1.4625  decode.d1.loss_mask: 0.9576  decode.d1.loss_dice: 1.6029  decode.d2.loss_cls: 1.2951  decode.d2.loss_mask: 0.9004  decode.d2.loss_dice: 1.6036  decode.d3.loss_cls: 1.3205  decode.d3.loss_mask: 0.8780  decode.d3.loss_dice: 1.5241  decode.d4.loss_cls: 1.3361  decode.d4.loss_mask: 0.9001  decode.d4.loss_dice: 1.4922  decode.d5.loss_cls: 1.2770  decode.d5.loss_mask: 0.8688  decode.d5.loss_dice: 1.4639  decode.d6.loss_cls: 1.2941  decode.d6.loss_mask: 0.8725  decode.d6.loss_dice: 1.4922  decode.d7.loss_cls: 1.2574  decode.d7.loss_mask: 0.8627  decode.d7.loss_dice: 1.5035  decode.d8.loss_cls: 1.2244  decode.d8.loss_mask: 0.8843  decode.d8.loss_dice: 1.4624
2023/05/24 00:23:20 - mmengine - INFO - Iter(train) [ 49800/160000]  lr: 7.1492e-06  eta: 13:05:41  time: 0.4196  data_time: 0.0102  memory: 4846  grad_norm: 90.3918  loss: 47.6563  decode.loss_cls: 1.5226  decode.loss_mask: 1.0795  decode.loss_dice: 1.8474  decode.d0.loss_cls: 3.6020  decode.d0.loss_mask: 1.2359  decode.d0.loss_dice: 2.1714  decode.d1.loss_cls: 1.5868  decode.d1.loss_mask: 1.1000  decode.d1.loss_dice: 2.0317  decode.d2.loss_cls: 1.5470  decode.d2.loss_mask: 1.1201  decode.d2.loss_dice: 1.9784  decode.d3.loss_cls: 1.5562  decode.d3.loss_mask: 1.0656  decode.d3.loss_dice: 1.8683  decode.d4.loss_cls: 1.5086  decode.d4.loss_mask: 1.0810  decode.d4.loss_dice: 1.8916  decode.d5.loss_cls: 1.4681  decode.d5.loss_mask: 1.1084  decode.d5.loss_dice: 1.9077  decode.d6.loss_cls: 1.5461  decode.d6.loss_mask: 1.0668  decode.d6.loss_dice: 1.8462  decode.d7.loss_cls: 1.4877  decode.d7.loss_mask: 1.0898  decode.d7.loss_dice: 1.8787  decode.d8.loss_cls: 1.4843  decode.d8.loss_mask: 1.0768  decode.d8.loss_dice: 1.9017
2023/05/24 00:23:41 - mmengine - INFO - Iter(train) [ 49850/160000]  lr: 7.1463e-06  eta: 13:05:19  time: 0.4192  data_time: 0.0101  memory: 4845  grad_norm: 86.6989  loss: 42.2621  decode.loss_cls: 1.5120  decode.loss_mask: 0.8139  decode.loss_dice: 1.6298  decode.d0.loss_cls: 3.1551  decode.d0.loss_mask: 0.9377  decode.d0.loss_dice: 1.8288  decode.d1.loss_cls: 1.6557  decode.d1.loss_mask: 0.8770  decode.d1.loss_dice: 1.6622  decode.d2.loss_cls: 1.5415  decode.d2.loss_mask: 0.8856  decode.d2.loss_dice: 1.7165  decode.d3.loss_cls: 1.5839  decode.d3.loss_mask: 0.8404  decode.d3.loss_dice: 1.6149  decode.d4.loss_cls: 1.5868  decode.d4.loss_mask: 0.8432  decode.d4.loss_dice: 1.6519  decode.d5.loss_cls: 1.5337  decode.d5.loss_mask: 0.8281  decode.d5.loss_dice: 1.6321  decode.d6.loss_cls: 1.5619  decode.d6.loss_mask: 0.8279  decode.d6.loss_dice: 1.5985  decode.d7.loss_cls: 1.5330  decode.d7.loss_mask: 0.8209  decode.d7.loss_dice: 1.6178  decode.d8.loss_cls: 1.5338  decode.d8.loss_mask: 0.8214  decode.d8.loss_dice: 1.6161
2023/05/24 00:24:02 - mmengine - INFO - Iter(train) [ 49900/160000]  lr: 7.1434e-06  eta: 13:04:57  time: 0.4135  data_time: 0.0099  memory: 4857  grad_norm: 88.2710  loss: 43.0078  decode.loss_cls: 1.3603  decode.loss_mask: 0.7926  decode.loss_dice: 1.7225  decode.d0.loss_cls: 3.5368  decode.d0.loss_mask: 0.8724  decode.d0.loss_dice: 1.9913  decode.d1.loss_cls: 1.5454  decode.d1.loss_mask: 0.8529  decode.d1.loss_dice: 1.9412  decode.d2.loss_cls: 1.5384  decode.d2.loss_mask: 0.8839  decode.d2.loss_dice: 1.8332  decode.d3.loss_cls: 1.4880  decode.d3.loss_mask: 0.8180  decode.d3.loss_dice: 1.8030  decode.d4.loss_cls: 1.4781  decode.d4.loss_mask: 0.8277  decode.d4.loss_dice: 1.8331  decode.d5.loss_cls: 1.3901  decode.d5.loss_mask: 0.8382  decode.d5.loss_dice: 1.7946  decode.d6.loss_cls: 1.4090  decode.d6.loss_mask: 0.8262  decode.d6.loss_dice: 1.7506  decode.d7.loss_cls: 1.4018  decode.d7.loss_mask: 0.7996  decode.d7.loss_dice: 1.7305  decode.d8.loss_cls: 1.4024  decode.d8.loss_mask: 0.7994  decode.d8.loss_dice: 1.7467
2023/05/24 00:24:23 - mmengine - INFO - Iter(train) [ 49950/160000]  lr: 7.1404e-06  eta: 13:04:34  time: 0.4056  data_time: 0.0098  memory: 4874  grad_norm: 99.2727  loss: 41.5333  decode.loss_cls: 1.4107  decode.loss_mask: 0.7809  decode.loss_dice: 1.5275  decode.d0.loss_cls: 3.4756  decode.d0.loss_mask: 0.8566  decode.d0.loss_dice: 1.7628  decode.d1.loss_cls: 1.5975  decode.d1.loss_mask: 0.8700  decode.d1.loss_dice: 1.6775  decode.d2.loss_cls: 1.4974  decode.d2.loss_mask: 0.8775  decode.d2.loss_dice: 1.6571  decode.d3.loss_cls: 1.5609  decode.d3.loss_mask: 0.8590  decode.d3.loss_dice: 1.5945  decode.d4.loss_cls: 1.5482  decode.d4.loss_mask: 0.8498  decode.d4.loss_dice: 1.6217  decode.d5.loss_cls: 1.5142  decode.d5.loss_mask: 0.8441  decode.d5.loss_dice: 1.6044  decode.d6.loss_cls: 1.4488  decode.d6.loss_mask: 0.8691  decode.d6.loss_dice: 1.5879  decode.d7.loss_cls: 1.4432  decode.d7.loss_mask: 0.8246  decode.d7.loss_dice: 1.5546  decode.d8.loss_cls: 1.4052  decode.d8.loss_mask: 0.8423  decode.d8.loss_dice: 1.5696
2023/05/24 00:24:44 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 00:24:44 - mmengine - INFO - Iter(train) [ 50000/160000]  lr: 7.1375e-06  eta: 13:04:11  time: 0.4176  data_time: 0.0098  memory: 4861  grad_norm: 83.7800  loss: 31.6218  decode.loss_cls: 1.0540  decode.loss_mask: 0.6800  decode.loss_dice: 1.1232  decode.d0.loss_cls: 3.0999  decode.d0.loss_mask: 0.6919  decode.d0.loss_dice: 1.3101  decode.d1.loss_cls: 1.2284  decode.d1.loss_mask: 0.7561  decode.d1.loss_dice: 1.2048  decode.d2.loss_cls: 1.0920  decode.d2.loss_mask: 0.7226  decode.d2.loss_dice: 1.2021  decode.d3.loss_cls: 1.1278  decode.d3.loss_mask: 0.7045  decode.d3.loss_dice: 1.1541  decode.d4.loss_cls: 1.1307  decode.d4.loss_mask: 0.7013  decode.d4.loss_dice: 1.1706  decode.d5.loss_cls: 1.0573  decode.d5.loss_mask: 0.7104  decode.d5.loss_dice: 1.1381  decode.d6.loss_cls: 1.0411  decode.d6.loss_mask: 0.7012  decode.d6.loss_dice: 1.1123  decode.d7.loss_cls: 1.0289  decode.d7.loss_mask: 0.7059  decode.d7.loss_dice: 1.1106  decode.d8.loss_cls: 1.0290  decode.d8.loss_mask: 0.7096  decode.d8.loss_dice: 1.1232
2023/05/24 00:24:44 - mmengine - INFO - Saving checkpoint at 50000 iterations
2023/05/24 00:24:53 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:45  time: 0.0784  data_time: 0.0018  memory: 2167  
2023/05/24 00:24:57 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:42  time: 0.0829  data_time: 0.0020  memory: 2216  
2023/05/24 00:25:02 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:38  time: 0.0809  data_time: 0.0017  memory: 2167  
2023/05/24 00:25:06 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0936  data_time: 0.0018  memory: 2104  
2023/05/24 00:25:10 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0783  data_time: 0.0017  memory: 2831  
2023/05/24 00:25:14 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:27  time: 0.0786  data_time: 0.0017  memory: 2167  
2023/05/24 00:25:19 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0800  data_time: 0.0018  memory: 2167  
2023/05/24 00:25:23 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0809  data_time: 0.0018  memory: 2167  
2023/05/24 00:25:27 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0789  data_time: 0.0018  memory: 2944  
2023/05/24 00:25:31 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0782  data_time: 0.0018  memory: 2356  
2023/05/24 00:25:35 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0777  data_time: 0.0017  memory: 2217  
2023/05/24 00:25:41 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.3346  data_time: 0.0019  memory: 2328  
2023/05/24 00:25:45 - mmengine - INFO - per class results:
2023/05/24 00:25:45 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.09 |  92.6 |
|     bicycle      | 67.19 | 82.05 |
|       car        | 56.07 | 78.62 |
|    motorcycle    | 82.51 | 90.52 |
|     airplane     | 83.96 |  91.5 |
|       bus        | 78.22 | 82.73 |
|      train       | 82.24 |  92.5 |
|      truck       | 49.62 | 72.02 |
|       boat       | 56.47 |  82.9 |
|  traffic light   | 64.49 | 82.43 |
|   fire hydrant   | 84.81 | 95.32 |
|    stop sign     | 91.88 | 96.55 |
|  parking meter   | 76.59 | 86.64 |
|      bench       | 46.72 | 64.11 |
|       bird       | 80.95 | 90.85 |
|       cat        | 87.33 | 95.06 |
|       dog        | 80.17 | 88.14 |
|      horse       | 77.95 | 89.05 |
|      sheep       | 85.28 | 92.08 |
|       cow        | 80.15 | 88.89 |
|     elephant     |  88.9 | 93.77 |
|       bear       | 92.49 | 95.18 |
|      zebra       | 90.02 | 93.01 |
|     giraffe      | 86.85 | 92.42 |
|     backpack     | 28.57 | 55.23 |
|     umbrella     | 79.88 | 86.92 |
|     handbag      | 32.59 |  51.1 |
|       tie        |  9.08 | 14.72 |
|     suitcase     | 74.25 | 90.99 |
|     frisbee      | 63.44 |  91.1 |
|       skis       | 39.86 | 55.77 |
|    snowboard     |  45.4 | 73.54 |
|   sports ball    | 43.47 | 73.93 |
|       kite       | 49.22 | 57.71 |
|   baseball bat   | 49.36 | 62.55 |
|  baseball glove  | 66.65 | 84.14 |
|    skateboard    | 55.41 | 69.53 |
|    surfboard     | 59.28 | 88.28 |
|  tennis racket   | 82.67 | 89.02 |
|      bottle      | 42.62 | 56.36 |
|    wine glass    | 56.49 | 77.25 |
|       cup        | 49.91 | 75.54 |
|       fork       | 25.43 | 32.02 |
|      knife       | 20.98 | 28.34 |
|      spoon       |  34.6 | 61.87 |
|       bowl       | 44.52 | 62.43 |
|      banana      | 66.89 | 86.85 |
|      apple       | 49.86 | 72.09 |
|     sandwich     | 44.36 | 64.85 |
|      orange      | 66.17 | 82.34 |
|     broccoli     | 56.49 | 72.78 |
|      carrot      | 52.01 | 61.55 |
|     hot dog      | 49.22 | 58.65 |
|      pizza       | 69.64 | 86.13 |
|      donut       | 62.86 | 77.97 |
|       cake       | 56.26 | 73.84 |
|      chair       | 42.33 | 54.61 |
|      couch       | 54.39 | 78.71 |
|   potted plant   | 31.21 | 46.01 |
|       bed        | 60.79 | 76.76 |
|   dining table   | 40.87 | 79.92 |
|      toilet      | 78.73 | 94.11 |
|        tv        | 73.51 | 84.23 |
|      laptop      | 68.12 | 84.11 |
|      mouse       | 68.52 | 85.17 |
|      remote      | 59.14 | 71.53 |
|     keyboard     | 56.53 |  68.4 |
|    cell phone    | 66.53 | 90.05 |
|    microwave     | 60.48 | 76.54 |
|       oven       | 54.33 | 71.08 |
|     toaster      | 19.75 | 22.32 |
|       sink       |  57.7 | 77.18 |
|   refrigerator   |  76.4 | 90.87 |
|       book       | 45.55 | 62.07 |
|      clock       | 71.17 | 86.55 |
|       vase       | 52.42 | 82.13 |
|     scissors     | 59.29 | 69.38 |
|    teddy bear    | 75.75 | 88.24 |
|    hair drier    | 37.62 | 38.69 |
|    toothbrush    | 14.88 | 65.93 |
|      banner      | 30.45 | 69.82 |
|     blanket      |  0.83 |  0.84 |
|      branch      | 17.73 | 20.98 |
|      bridge      | 30.36 | 51.35 |
|  building-other  | 47.48 | 66.77 |
|       bush       | 31.94 | 43.78 |
|     cabinet      |  50.3 | 70.96 |
|       cage       | 19.09 | 33.56 |
|    cardboard     |  38.1 | 44.89 |
|      carpet      | 51.84 | 66.16 |
|  ceiling-other   |  62.1 | 79.93 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 17.36 | 26.12 |
|      clouds      | 43.72 | 54.24 |
|     counter      | 25.91 | 45.45 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 62.16 |  74.2 |
|    desk-stuff    | 43.08 | 59.31 |
|       dirt       | 37.85 |  58.4 |
|    door-stuff    | 35.07 | 46.33 |
|      fence       | 29.13 |  54.5 |
|   floor-marble   |  3.95 |  4.02 |
|   floor-other    | 24.58 | 38.38 |
|   floor-stone    |  3.43 |  3.69 |
|    floor-tile    | 59.14 | 69.75 |
|    floor-wood    | 63.17 | 73.64 |
|      flower      | 45.34 | 65.49 |
|       fog        |  1.7  |  1.71 |
|    food-other    | 20.23 | 23.12 |
|      fruit       | 34.75 | 51.66 |
| furniture-other  | 14.33 | 18.72 |
|      grass       |  69.1 | 79.67 |
|      gravel      | 25.42 | 36.75 |
|   ground-other   |  3.49 |  5.14 |
|       hill       | 14.53 | 18.17 |
|      house       | 25.54 | 37.93 |
|      leaves      |  29.0 | 49.27 |
|      light       | 34.63 | 52.56 |
|       mat        |  0.0  |  0.0  |
|      metal       | 30.56 | 46.93 |
|   mirror-stuff   | 41.95 | 59.08 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 50.44 | 68.04 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  0.4  |  0.4  |
|       net        |  37.1 | 64.17 |
|      paper       | 26.89 | 36.27 |
|     pavement     | 48.45 | 68.76 |
|      pillow      | 10.66 | 13.05 |
|   plant-other    | 16.69 | 24.31 |
|     plastic      | 15.45 | 19.83 |
|     platform     | 27.38 | 41.89 |
|   playingfield   | 68.32 | 89.95 |
|     railing      |  1.21 |  1.4  |
|     railroad     |  59.8 | 79.06 |
|      river       | 40.08 |  47.8 |
|       road       | 63.77 | 79.31 |
|       rock       | 40.82 | 65.96 |
|       roof       | 11.68 | 14.37 |
|       rug        | 32.16 | 49.09 |
|      salad       |  0.0  |  0.0  |
|       sand       | 61.47 | 71.05 |
|       sea        | 85.34 | 91.95 |
|      shelf       | 29.29 | 41.16 |
|    sky-other     | 70.17 | 90.11 |
|    skyscraper    | 32.56 | 46.49 |
|       snow       |  87.5 | 92.53 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      |  15.4 |  25.2 |
|      stone       |  9.88 | 13.01 |
|      straw       |  29.6 | 40.46 |
| structural-other |  0.0  |  0.0  |
|      table       | 13.87 | 16.32 |
|       tent       |  6.35 |  8.97 |
|  textile-other   |  9.99 | 14.88 |
|      towel       | 30.97 | 43.49 |
|       tree       |  73.3 | 85.97 |
|    vegetable     | 28.84 | 38.73 |
|    wall-brick    | 43.94 | 63.16 |
|  wall-concrete   | 58.31 | 80.89 |
|    wall-other    | 17.91 | 28.96 |
|    wall-panel    |  2.39 |  2.5  |
|    wall-stone    | 29.32 |  32.8 |
|    wall-tile     | 60.65 |  85.2 |
|    wall-wood     | 37.78 | 52.43 |
|   water-other    | 29.79 | 54.17 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 48.33 | 58.61 |
|   window-other   | 42.19 | 64.77 |
|       wood       | 23.51 | 33.79 |
+------------------+-------+-------+
2023/05/24 00:25:45 - mmengine - INFO - Iter(val) [625/625]    aAcc: 69.7000  mIoU: 44.2000  mAcc: 57.1500  data_time: 0.0020  time: 0.0863
2023/05/24 00:26:09 - mmengine - INFO - Iter(train) [ 50050/160000]  lr: 7.1346e-06  eta: 13:03:58  time: 0.4711  data_time: 0.0095  memory: 4866  grad_norm: 108.7270  loss: 39.6852  decode.loss_cls: 1.4652  decode.loss_mask: 0.7842  decode.loss_dice: 1.4429  decode.d0.loss_cls: 3.3126  decode.d0.loss_mask: 0.8333  decode.d0.loss_dice: 1.5856  decode.d1.loss_cls: 1.6118  decode.d1.loss_mask: 0.8447  decode.d1.loss_dice: 1.5260  decode.d2.loss_cls: 1.5665  decode.d2.loss_mask: 0.8422  decode.d2.loss_dice: 1.4646  decode.d3.loss_cls: 1.5364  decode.d3.loss_mask: 0.7967  decode.d3.loss_dice: 1.4739  decode.d4.loss_cls: 1.5257  decode.d4.loss_mask: 0.7820  decode.d4.loss_dice: 1.4643  decode.d5.loss_cls: 1.5110  decode.d5.loss_mask: 0.7855  decode.d5.loss_dice: 1.4260  decode.d6.loss_cls: 1.4225  decode.d6.loss_mask: 0.7890  decode.d6.loss_dice: 1.4575  decode.d7.loss_cls: 1.5219  decode.d7.loss_mask: 0.7675  decode.d7.loss_dice: 1.4353  decode.d8.loss_cls: 1.5108  decode.d8.loss_mask: 0.7849  decode.d8.loss_dice: 1.4147
2023/05/24 00:26:32 - mmengine - INFO - Iter(train) [ 50100/160000]  lr: 7.1317e-06  eta: 13:03:41  time: 0.4691  data_time: 0.0100  memory: 4804  grad_norm: 91.4600  loss: 36.2861  decode.loss_cls: 1.1559  decode.loss_mask: 0.8745  decode.loss_dice: 1.2720  decode.d0.loss_cls: 2.8410  decode.d0.loss_mask: 0.8517  decode.d0.loss_dice: 1.4811  decode.d1.loss_cls: 1.3132  decode.d1.loss_mask: 0.9741  decode.d1.loss_dice: 1.4557  decode.d2.loss_cls: 1.2290  decode.d2.loss_mask: 0.9461  decode.d2.loss_dice: 1.4223  decode.d3.loss_cls: 1.1934  decode.d3.loss_mask: 0.8912  decode.d3.loss_dice: 1.3272  decode.d4.loss_cls: 1.3199  decode.d4.loss_mask: 0.8266  decode.d4.loss_dice: 1.3442  decode.d5.loss_cls: 1.2304  decode.d5.loss_mask: 0.8488  decode.d5.loss_dice: 1.3180  decode.d6.loss_cls: 1.2753  decode.d6.loss_mask: 0.8322  decode.d6.loss_dice: 1.3061  decode.d7.loss_cls: 1.2315  decode.d7.loss_mask: 0.8360  decode.d7.loss_dice: 1.3143  decode.d8.loss_cls: 1.2203  decode.d8.loss_mask: 0.8426  decode.d8.loss_dice: 1.3114
2023/05/24 00:26:55 - mmengine - INFO - Iter(train) [ 50150/160000]  lr: 7.1288e-06  eta: 13:03:24  time: 0.4647  data_time: 0.0104  memory: 4858  grad_norm: 86.0795  loss: 39.8003  decode.loss_cls: 1.3303  decode.loss_mask: 0.8881  decode.loss_dice: 1.4258  decode.d0.loss_cls: 3.2782  decode.d0.loss_mask: 1.0401  decode.d0.loss_dice: 1.7374  decode.d1.loss_cls: 1.4472  decode.d1.loss_mask: 0.9415  decode.d1.loss_dice: 1.5443  decode.d2.loss_cls: 1.4871  decode.d2.loss_mask: 0.9269  decode.d2.loss_dice: 1.4853  decode.d3.loss_cls: 1.4640  decode.d3.loss_mask: 0.9203  decode.d3.loss_dice: 1.4125  decode.d4.loss_cls: 1.4498  decode.d4.loss_mask: 0.9078  decode.d4.loss_dice: 1.4079  decode.d5.loss_cls: 1.4201  decode.d5.loss_mask: 0.8750  decode.d5.loss_dice: 1.3982  decode.d6.loss_cls: 1.3786  decode.d6.loss_mask: 0.9024  decode.d6.loss_dice: 1.4257  decode.d7.loss_cls: 1.4142  decode.d7.loss_mask: 0.8906  decode.d7.loss_dice: 1.3786  decode.d8.loss_cls: 1.3382  decode.d8.loss_mask: 0.8864  decode.d8.loss_dice: 1.3978
2023/05/24 00:27:17 - mmengine - INFO - Iter(train) [ 50200/160000]  lr: 7.1258e-06  eta: 13:03:02  time: 0.4068  data_time: 0.0097  memory: 4832  grad_norm: 92.2737  loss: 27.4201  decode.loss_cls: 0.9765  decode.loss_mask: 0.5177  decode.loss_dice: 0.9707  decode.d0.loss_cls: 2.9494  decode.d0.loss_mask: 0.5793  decode.d0.loss_dice: 1.2337  decode.d1.loss_cls: 1.1343  decode.d1.loss_mask: 0.5997  decode.d1.loss_dice: 1.0422  decode.d2.loss_cls: 1.0563  decode.d2.loss_mask: 0.5532  decode.d2.loss_dice: 1.0567  decode.d3.loss_cls: 0.9844  decode.d3.loss_mask: 0.5436  decode.d3.loss_dice: 0.9922  decode.d4.loss_cls: 0.9937  decode.d4.loss_mask: 0.5328  decode.d4.loss_dice: 0.9728  decode.d5.loss_cls: 0.9267  decode.d5.loss_mask: 0.5313  decode.d5.loss_dice: 0.9678  decode.d6.loss_cls: 0.9368  decode.d6.loss_mask: 0.5058  decode.d6.loss_dice: 0.9652  decode.d7.loss_cls: 0.9812  decode.d7.loss_mask: 0.5149  decode.d7.loss_dice: 0.9849  decode.d8.loss_cls: 0.9355  decode.d8.loss_mask: 0.5176  decode.d8.loss_dice: 0.9634
2023/05/24 00:27:38 - mmengine - INFO - Iter(train) [ 50250/160000]  lr: 7.1229e-06  eta: 13:02:40  time: 0.4111  data_time: 0.0097  memory: 4815  grad_norm: 95.8155  loss: 32.8237  decode.loss_cls: 1.0542  decode.loss_mask: 0.8629  decode.loss_dice: 1.0938  decode.d0.loss_cls: 2.9178  decode.d0.loss_mask: 0.8645  decode.d0.loss_dice: 1.2421  decode.d1.loss_cls: 1.2696  decode.d1.loss_mask: 0.8860  decode.d1.loss_dice: 1.1965  decode.d2.loss_cls: 1.1179  decode.d2.loss_mask: 0.9036  decode.d2.loss_dice: 1.1717  decode.d3.loss_cls: 1.1420  decode.d3.loss_mask: 0.8627  decode.d3.loss_dice: 1.1250  decode.d4.loss_cls: 1.0972  decode.d4.loss_mask: 0.8732  decode.d4.loss_dice: 1.1050  decode.d5.loss_cls: 1.0787  decode.d5.loss_mask: 0.8697  decode.d5.loss_dice: 1.0804  decode.d6.loss_cls: 1.0665  decode.d6.loss_mask: 0.8463  decode.d6.loss_dice: 1.0857  decode.d7.loss_cls: 1.0770  decode.d7.loss_mask: 0.8461  decode.d7.loss_dice: 1.1073  decode.d8.loss_cls: 1.0474  decode.d8.loss_mask: 0.8562  decode.d8.loss_dice: 1.0767
2023/05/24 00:27:59 - mmengine - INFO - Iter(train) [ 50300/160000]  lr: 7.1200e-06  eta: 13:02:18  time: 0.4145  data_time: 0.0102  memory: 4857  grad_norm: 86.2740  loss: 45.9506  decode.loss_cls: 1.5735  decode.loss_mask: 1.1027  decode.loss_dice: 1.6246  decode.d0.loss_cls: 3.5788  decode.d0.loss_mask: 1.1657  decode.d0.loss_dice: 1.8838  decode.d1.loss_cls: 1.7112  decode.d1.loss_mask: 1.2012  decode.d1.loss_dice: 1.7905  decode.d2.loss_cls: 1.7142  decode.d2.loss_mask: 1.0840  decode.d2.loss_dice: 1.6337  decode.d3.loss_cls: 1.7113  decode.d3.loss_mask: 1.0826  decode.d3.loss_dice: 1.6022  decode.d4.loss_cls: 1.6064  decode.d4.loss_mask: 1.0767  decode.d4.loss_dice: 1.6306  decode.d5.loss_cls: 1.5973  decode.d5.loss_mask: 1.0991  decode.d5.loss_dice: 1.6122  decode.d6.loss_cls: 1.5468  decode.d6.loss_mask: 1.1079  decode.d6.loss_dice: 1.5981  decode.d7.loss_cls: 1.5572  decode.d7.loss_mask: 1.1202  decode.d7.loss_dice: 1.6373  decode.d8.loss_cls: 1.5414  decode.d8.loss_mask: 1.1296  decode.d8.loss_dice: 1.6297
2023/05/24 00:28:20 - mmengine - INFO - Iter(train) [ 50350/160000]  lr: 7.1171e-06  eta: 13:01:56  time: 0.4144  data_time: 0.0099  memory: 4837  grad_norm: 150.5102  loss: 34.5064  decode.loss_cls: 1.2146  decode.loss_mask: 0.6027  decode.loss_dice: 1.3298  decode.d0.loss_cls: 3.4508  decode.d0.loss_mask: 0.6733  decode.d0.loss_dice: 1.5640  decode.d1.loss_cls: 1.3313  decode.d1.loss_mask: 0.6128  decode.d1.loss_dice: 1.4319  decode.d2.loss_cls: 1.2319  decode.d2.loss_mask: 0.6069  decode.d2.loss_dice: 1.4158  decode.d3.loss_cls: 1.1949  decode.d3.loss_mask: 0.6132  decode.d3.loss_dice: 1.3774  decode.d4.loss_cls: 1.1897  decode.d4.loss_mask: 0.6005  decode.d4.loss_dice: 1.3942  decode.d5.loss_cls: 1.1854  decode.d5.loss_mask: 0.6088  decode.d5.loss_dice: 1.3756  decode.d6.loss_cls: 1.2383  decode.d6.loss_mask: 0.5895  decode.d6.loss_dice: 1.3566  decode.d7.loss_cls: 1.2232  decode.d7.loss_mask: 0.5994  decode.d7.loss_dice: 1.3417  decode.d8.loss_cls: 1.2242  decode.d8.loss_mask: 0.6024  decode.d8.loss_dice: 1.3254
2023/05/24 00:28:41 - mmengine - INFO - Iter(train) [ 50400/160000]  lr: 7.1142e-06  eta: 13:01:33  time: 0.4084  data_time: 0.0098  memory: 4959  grad_norm: 92.9197  loss: 47.2904  decode.loss_cls: 1.7317  decode.loss_mask: 0.8805  decode.loss_dice: 1.8028  decode.d0.loss_cls: 3.4642  decode.d0.loss_mask: 0.9847  decode.d0.loss_dice: 2.1019  decode.d1.loss_cls: 1.9083  decode.d1.loss_mask: 0.9812  decode.d1.loss_dice: 2.0484  decode.d2.loss_cls: 1.8758  decode.d2.loss_mask: 0.9163  decode.d2.loss_dice: 1.9193  decode.d3.loss_cls: 1.7252  decode.d3.loss_mask: 0.9008  decode.d3.loss_dice: 1.8121  decode.d4.loss_cls: 1.7877  decode.d4.loss_mask: 0.8951  decode.d4.loss_dice: 1.7882  decode.d5.loss_cls: 1.7015  decode.d5.loss_mask: 0.8942  decode.d5.loss_dice: 1.8376  decode.d6.loss_cls: 1.7162  decode.d6.loss_mask: 0.9005  decode.d6.loss_dice: 1.8165  decode.d7.loss_cls: 1.7213  decode.d7.loss_mask: 0.8977  decode.d7.loss_dice: 1.8330  decode.d8.loss_cls: 1.7380  decode.d8.loss_mask: 0.8863  decode.d8.loss_dice: 1.8236
2023/05/24 00:29:01 - mmengine - INFO - Iter(train) [ 50450/160000]  lr: 7.1112e-06  eta: 13:01:10  time: 0.4062  data_time: 0.0099  memory: 4839  grad_norm: 124.3368  loss: 34.8997  decode.loss_cls: 1.2650  decode.loss_mask: 0.6755  decode.loss_dice: 1.1666  decode.d0.loss_cls: 3.2415  decode.d0.loss_mask: 0.7800  decode.d0.loss_dice: 1.4888  decode.d1.loss_cls: 1.5244  decode.d1.loss_mask: 0.7666  decode.d1.loss_dice: 1.3663  decode.d2.loss_cls: 1.4110  decode.d2.loss_mask: 0.7523  decode.d2.loss_dice: 1.2423  decode.d3.loss_cls: 1.2977  decode.d3.loss_mask: 0.7205  decode.d3.loss_dice: 1.2073  decode.d4.loss_cls: 1.3720  decode.d4.loss_mask: 0.6911  decode.d4.loss_dice: 1.1878  decode.d5.loss_cls: 1.3502  decode.d5.loss_mask: 0.6790  decode.d5.loss_dice: 1.2202  decode.d6.loss_cls: 1.2953  decode.d6.loss_mask: 0.6903  decode.d6.loss_dice: 1.2080  decode.d7.loss_cls: 1.3015  decode.d7.loss_mask: 0.6816  decode.d7.loss_dice: 1.1635  decode.d8.loss_cls: 1.2995  decode.d8.loss_mask: 0.6845  decode.d8.loss_dice: 1.1697
2023/05/24 00:29:22 - mmengine - INFO - Iter(train) [ 50500/160000]  lr: 7.1083e-06  eta: 13:00:47  time: 0.4207  data_time: 0.0100  memory: 4817  grad_norm: 125.4939  loss: 38.9942  decode.loss_cls: 1.3276  decode.loss_mask: 0.9785  decode.loss_dice: 1.2863  decode.d0.loss_cls: 3.4696  decode.d0.loss_mask: 1.0243  decode.d0.loss_dice: 1.4578  decode.d1.loss_cls: 1.5055  decode.d1.loss_mask: 1.0460  decode.d1.loss_dice: 1.3915  decode.d2.loss_cls: 1.3288  decode.d2.loss_mask: 0.9883  decode.d2.loss_dice: 1.3237  decode.d3.loss_cls: 1.3962  decode.d3.loss_mask: 0.9845  decode.d3.loss_dice: 1.3132  decode.d4.loss_cls: 1.2900  decode.d4.loss_mask: 1.0055  decode.d4.loss_dice: 1.3219  decode.d5.loss_cls: 1.3111  decode.d5.loss_mask: 0.9876  decode.d5.loss_dice: 1.3287  decode.d6.loss_cls: 1.3207  decode.d6.loss_mask: 1.0034  decode.d6.loss_dice: 1.2968  decode.d7.loss_cls: 1.4132  decode.d7.loss_mask: 0.9657  decode.d7.loss_dice: 1.2779  decode.d8.loss_cls: 1.3676  decode.d8.loss_mask: 0.9971  decode.d8.loss_dice: 1.2854
2023/05/24 00:29:43 - mmengine - INFO - Iter(train) [ 50550/160000]  lr: 7.1054e-06  eta: 13:00:24  time: 0.4104  data_time: 0.0099  memory: 4874  grad_norm: 101.7958  loss: 43.7757  decode.loss_cls: 1.5317  decode.loss_mask: 0.9139  decode.loss_dice: 1.6258  decode.d0.loss_cls: 3.4332  decode.d0.loss_mask: 1.0276  decode.d0.loss_dice: 1.7902  decode.d1.loss_cls: 1.6241  decode.d1.loss_mask: 1.0289  decode.d1.loss_dice: 1.7703  decode.d2.loss_cls: 1.5671  decode.d2.loss_mask: 0.9914  decode.d2.loss_dice: 1.7270  decode.d3.loss_cls: 1.4944  decode.d3.loss_mask: 0.9992  decode.d3.loss_dice: 1.6989  decode.d4.loss_cls: 1.3813  decode.d4.loss_mask: 0.9966  decode.d4.loss_dice: 1.7009  decode.d5.loss_cls: 1.4773  decode.d5.loss_mask: 0.9796  decode.d5.loss_dice: 1.7093  decode.d6.loss_cls: 1.4708  decode.d6.loss_mask: 0.9450  decode.d6.loss_dice: 1.6704  decode.d7.loss_cls: 1.4810  decode.d7.loss_mask: 0.9583  decode.d7.loss_dice: 1.6706  decode.d8.loss_cls: 1.5717  decode.d8.loss_mask: 0.9002  decode.d8.loss_dice: 1.6392
2023/05/24 00:30:06 - mmengine - INFO - Iter(train) [ 50600/160000]  lr: 7.1025e-06  eta: 13:00:07  time: 0.4441  data_time: 0.0099  memory: 4847  grad_norm: 109.4085  loss: 37.6211  decode.loss_cls: 1.3142  decode.loss_mask: 0.8676  decode.loss_dice: 1.3268  decode.d0.loss_cls: 2.9814  decode.d0.loss_mask: 0.8889  decode.d0.loss_dice: 1.5731  decode.d1.loss_cls: 1.5220  decode.d1.loss_mask: 0.8533  decode.d1.loss_dice: 1.4000  decode.d2.loss_cls: 1.3860  decode.d2.loss_mask: 0.8473  decode.d2.loss_dice: 1.3521  decode.d3.loss_cls: 1.3950  decode.d3.loss_mask: 0.8673  decode.d3.loss_dice: 1.3537  decode.d4.loss_cls: 1.4115  decode.d4.loss_mask: 0.8375  decode.d4.loss_dice: 1.3621  decode.d5.loss_cls: 1.3888  decode.d5.loss_mask: 0.8762  decode.d5.loss_dice: 1.3325  decode.d6.loss_cls: 1.3233  decode.d6.loss_mask: 0.8593  decode.d6.loss_dice: 1.3263  decode.d7.loss_cls: 1.3086  decode.d7.loss_mask: 0.8514  decode.d7.loss_dice: 1.3339  decode.d8.loss_cls: 1.2964  decode.d8.loss_mask: 0.8370  decode.d8.loss_dice: 1.3476
2023/05/24 00:30:27 - mmengine - INFO - Iter(train) [ 50650/160000]  lr: 7.0996e-06  eta: 12:59:44  time: 0.4098  data_time: 0.0102  memory: 4838  grad_norm: 121.9996  loss: 36.9416  decode.loss_cls: 1.3461  decode.loss_mask: 0.7779  decode.loss_dice: 1.3686  decode.d0.loss_cls: 3.1574  decode.d0.loss_mask: 0.7543  decode.d0.loss_dice: 1.5388  decode.d1.loss_cls: 1.4524  decode.d1.loss_mask: 0.7839  decode.d1.loss_dice: 1.4119  decode.d2.loss_cls: 1.4194  decode.d2.loss_mask: 0.7694  decode.d2.loss_dice: 1.3392  decode.d3.loss_cls: 1.3903  decode.d3.loss_mask: 0.7556  decode.d3.loss_dice: 1.3305  decode.d4.loss_cls: 1.3621  decode.d4.loss_mask: 0.7727  decode.d4.loss_dice: 1.3458  decode.d5.loss_cls: 1.3430  decode.d5.loss_mask: 0.7801  decode.d5.loss_dice: 1.3356  decode.d6.loss_cls: 1.3981  decode.d6.loss_mask: 0.7976  decode.d6.loss_dice: 1.3188  decode.d7.loss_cls: 1.3617  decode.d7.loss_mask: 0.7493  decode.d7.loss_dice: 1.3429  decode.d8.loss_cls: 1.2607  decode.d8.loss_mask: 0.8121  decode.d8.loss_dice: 1.3652
2023/05/24 00:30:48 - mmengine - INFO - Iter(train) [ 50700/160000]  lr: 7.0966e-06  eta: 12:59:21  time: 0.4114  data_time: 0.0102  memory: 4876  grad_norm: 93.1890  loss: 33.1507  decode.loss_cls: 1.4047  decode.loss_mask: 0.6729  decode.loss_dice: 0.9443  decode.d0.loss_cls: 3.1788  decode.d0.loss_mask: 0.7155  decode.d0.loss_dice: 1.1122  decode.d1.loss_cls: 1.4960  decode.d1.loss_mask: 0.7016  decode.d1.loss_dice: 1.0065  decode.d2.loss_cls: 1.4667  decode.d2.loss_mask: 0.6622  decode.d2.loss_dice: 1.0101  decode.d3.loss_cls: 1.5416  decode.d3.loss_mask: 0.6791  decode.d3.loss_dice: 0.9613  decode.d4.loss_cls: 1.4841  decode.d4.loss_mask: 0.6981  decode.d4.loss_dice: 0.9774  decode.d5.loss_cls: 1.5037  decode.d5.loss_mask: 0.6641  decode.d5.loss_dice: 0.9944  decode.d6.loss_cls: 1.4521  decode.d6.loss_mask: 0.6725  decode.d6.loss_dice: 0.9658  decode.d7.loss_cls: 1.4835  decode.d7.loss_mask: 0.6675  decode.d7.loss_dice: 0.9477  decode.d8.loss_cls: 1.4574  decode.d8.loss_mask: 0.6678  decode.d8.loss_dice: 0.9611
2023/05/24 00:31:10 - mmengine - INFO - Iter(train) [ 50750/160000]  lr: 7.0937e-06  eta: 12:59:03  time: 0.4662  data_time: 0.0097  memory: 4832  grad_norm: 110.0886  loss: 34.1474  decode.loss_cls: 1.1352  decode.loss_mask: 0.8265  decode.loss_dice: 1.2183  decode.d0.loss_cls: 3.0296  decode.d0.loss_mask: 0.8697  decode.d0.loss_dice: 1.3881  decode.d1.loss_cls: 1.2626  decode.d1.loss_mask: 0.8159  decode.d1.loss_dice: 1.3302  decode.d2.loss_cls: 1.2411  decode.d2.loss_mask: 0.7961  decode.d2.loss_dice: 1.2687  decode.d3.loss_cls: 1.2442  decode.d3.loss_mask: 0.7525  decode.d3.loss_dice: 1.2313  decode.d4.loss_cls: 1.1474  decode.d4.loss_mask: 0.7643  decode.d4.loss_dice: 1.2216  decode.d5.loss_cls: 1.1648  decode.d5.loss_mask: 0.7894  decode.d5.loss_dice: 1.1884  decode.d6.loss_cls: 1.2024  decode.d6.loss_mask: 0.7873  decode.d6.loss_dice: 1.1778  decode.d7.loss_cls: 1.1234  decode.d7.loss_mask: 0.7912  decode.d7.loss_dice: 1.2067  decode.d8.loss_cls: 1.1467  decode.d8.loss_mask: 0.8160  decode.d8.loss_dice: 1.2098
2023/05/24 00:31:34 - mmengine - INFO - Iter(train) [ 50800/160000]  lr: 7.0908e-06  eta: 12:58:46  time: 0.4677  data_time: 0.0103  memory: 4886  grad_norm: 94.9426  loss: 30.0992  decode.loss_cls: 1.2598  decode.loss_mask: 0.6104  decode.loss_dice: 0.8267  decode.d0.loss_cls: 3.0469  decode.d0.loss_mask: 0.7058  decode.d0.loss_dice: 1.0067  decode.d1.loss_cls: 1.4623  decode.d1.loss_mask: 0.6349  decode.d1.loss_dice: 0.8637  decode.d2.loss_cls: 1.3812  decode.d2.loss_mask: 0.6697  decode.d2.loss_dice: 0.8689  decode.d3.loss_cls: 1.3411  decode.d3.loss_mask: 0.6440  decode.d3.loss_dice: 0.9070  decode.d4.loss_cls: 1.2951  decode.d4.loss_mask: 0.6770  decode.d4.loss_dice: 0.8445  decode.d5.loss_cls: 1.3068  decode.d5.loss_mask: 0.6202  decode.d5.loss_dice: 0.8603  decode.d6.loss_cls: 1.2380  decode.d6.loss_mask: 0.6743  decode.d6.loss_dice: 0.8659  decode.d7.loss_cls: 1.2189  decode.d7.loss_mask: 0.6642  decode.d7.loss_dice: 0.8663  decode.d8.loss_cls: 1.2498  decode.d8.loss_mask: 0.6370  decode.d8.loss_dice: 0.8520
2023/05/24 00:31:55 - mmengine - INFO - Iter(train) [ 50850/160000]  lr: 7.0879e-06  eta: 12:58:23  time: 0.4167  data_time: 0.0100  memory: 4887  grad_norm: 115.2070  loss: 41.1891  decode.loss_cls: 1.2535  decode.loss_mask: 1.0143  decode.loss_dice: 1.5102  decode.d0.loss_cls: 3.5178  decode.d0.loss_mask: 1.1148  decode.d0.loss_dice: 1.7569  decode.d1.loss_cls: 1.4278  decode.d1.loss_mask: 1.0266  decode.d1.loss_dice: 1.6134  decode.d2.loss_cls: 1.3307  decode.d2.loss_mask: 1.0737  decode.d2.loss_dice: 1.5756  decode.d3.loss_cls: 1.3062  decode.d3.loss_mask: 1.0464  decode.d3.loss_dice: 1.5319  decode.d4.loss_cls: 1.2019  decode.d4.loss_mask: 1.0516  decode.d4.loss_dice: 1.5550  decode.d5.loss_cls: 1.2722  decode.d5.loss_mask: 1.0369  decode.d5.loss_dice: 1.5440  decode.d6.loss_cls: 1.2885  decode.d6.loss_mask: 1.0324  decode.d6.loss_dice: 1.5142  decode.d7.loss_cls: 1.2497  decode.d7.loss_mask: 1.0289  decode.d7.loss_dice: 1.5247  decode.d8.loss_cls: 1.2331  decode.d8.loss_mask: 1.0235  decode.d8.loss_dice: 1.5325
2023/05/24 00:32:15 - mmengine - INFO - Iter(train) [ 50900/160000]  lr: 7.0849e-06  eta: 12:58:01  time: 0.4170  data_time: 0.0100  memory: 4871  grad_norm: 105.0653  loss: 45.0114  decode.loss_cls: 1.5217  decode.loss_mask: 1.0287  decode.loss_dice: 1.6367  decode.d0.loss_cls: 3.4854  decode.d0.loss_mask: 1.0960  decode.d0.loss_dice: 2.0389  decode.d1.loss_cls: 1.6147  decode.d1.loss_mask: 1.0686  decode.d1.loss_dice: 1.8439  decode.d2.loss_cls: 1.5352  decode.d2.loss_mask: 1.0536  decode.d2.loss_dice: 1.7784  decode.d3.loss_cls: 1.4913  decode.d3.loss_mask: 1.0371  decode.d3.loss_dice: 1.7031  decode.d4.loss_cls: 1.5118  decode.d4.loss_mask: 1.0273  decode.d4.loss_dice: 1.6836  decode.d5.loss_cls: 1.4776  decode.d5.loss_mask: 1.0320  decode.d5.loss_dice: 1.6791  decode.d6.loss_cls: 1.5363  decode.d6.loss_mask: 1.0187  decode.d6.loss_dice: 1.6436  decode.d7.loss_cls: 1.4998  decode.d7.loss_mask: 1.0015  decode.d7.loss_dice: 1.7460  decode.d8.loss_cls: 1.4843  decode.d8.loss_mask: 1.0367  decode.d8.loss_dice: 1.6998
2023/05/24 00:32:38 - mmengine - INFO - Iter(train) [ 50950/160000]  lr: 7.0820e-06  eta: 12:57:42  time: 0.4287  data_time: 0.0102  memory: 4893  grad_norm: 96.9248  loss: 41.4468  decode.loss_cls: 1.3098  decode.loss_mask: 0.8795  decode.loss_dice: 1.5810  decode.d0.loss_cls: 3.4788  decode.d0.loss_mask: 0.9326  decode.d0.loss_dice: 1.8810  decode.d1.loss_cls: 1.6029  decode.d1.loss_mask: 0.9308  decode.d1.loss_dice: 1.7593  decode.d2.loss_cls: 1.4904  decode.d2.loss_mask: 0.8828  decode.d2.loss_dice: 1.6690  decode.d3.loss_cls: 1.4758  decode.d3.loss_mask: 0.8622  decode.d3.loss_dice: 1.5913  decode.d4.loss_cls: 1.4325  decode.d4.loss_mask: 0.8416  decode.d4.loss_dice: 1.5993  decode.d5.loss_cls: 1.3906  decode.d5.loss_mask: 0.8540  decode.d5.loss_dice: 1.6114  decode.d6.loss_cls: 1.2985  decode.d6.loss_mask: 0.8691  decode.d6.loss_dice: 1.6114  decode.d7.loss_cls: 1.3850  decode.d7.loss_mask: 0.8567  decode.d7.loss_dice: 1.6076  decode.d8.loss_cls: 1.2902  decode.d8.loss_mask: 0.8575  decode.d8.loss_dice: 1.6142
2023/05/24 00:33:00 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 00:33:00 - mmengine - INFO - Iter(train) [ 51000/160000]  lr: 7.0791e-06  eta: 12:57:22  time: 0.4139  data_time: 0.0104  memory: 4846  grad_norm: 108.7843  loss: 38.8225  decode.loss_cls: 1.3272  decode.loss_mask: 0.9243  decode.loss_dice: 1.3561  decode.d0.loss_cls: 3.3198  decode.d0.loss_mask: 0.8702  decode.d0.loss_dice: 1.5437  decode.d1.loss_cls: 1.4598  decode.d1.loss_mask: 0.9253  decode.d1.loss_dice: 1.4417  decode.d2.loss_cls: 1.4089  decode.d2.loss_mask: 0.8559  decode.d2.loss_dice: 1.4093  decode.d3.loss_cls: 1.4503  decode.d3.loss_mask: 0.9040  decode.d3.loss_dice: 1.3477  decode.d4.loss_cls: 1.4135  decode.d4.loss_mask: 0.9111  decode.d4.loss_dice: 1.3696  decode.d5.loss_cls: 1.3615  decode.d5.loss_mask: 0.9102  decode.d5.loss_dice: 1.3921  decode.d6.loss_cls: 1.3612  decode.d6.loss_mask: 0.8793  decode.d6.loss_dice: 1.3776  decode.d7.loss_cls: 1.3511  decode.d7.loss_mask: 0.8993  decode.d7.loss_dice: 1.4036  decode.d8.loss_cls: 1.3272  decode.d8.loss_mask: 0.9265  decode.d8.loss_dice: 1.3944
2023/05/24 00:33:00 - mmengine - INFO - Saving checkpoint at 51000 iterations
2023/05/24 00:33:26 - mmengine - INFO - Iter(train) [ 51050/160000]  lr: 7.0762e-06  eta: 12:57:10  time: 0.4109  data_time: 0.0100  memory: 4873  grad_norm: 101.2865  loss: 29.6020  decode.loss_cls: 0.9738  decode.loss_mask: 0.8501  decode.loss_dice: 0.9133  decode.d0.loss_cls: 2.7376  decode.d0.loss_mask: 0.9139  decode.d0.loss_dice: 1.0547  decode.d1.loss_cls: 1.1004  decode.d1.loss_mask: 0.9027  decode.d1.loss_dice: 1.0169  decode.d2.loss_cls: 0.9843  decode.d2.loss_mask: 0.8815  decode.d2.loss_dice: 0.9351  decode.d3.loss_cls: 0.9799  decode.d3.loss_mask: 0.8432  decode.d3.loss_dice: 0.9057  decode.d4.loss_cls: 0.9827  decode.d4.loss_mask: 0.8798  decode.d4.loss_dice: 0.9226  decode.d5.loss_cls: 0.9448  decode.d5.loss_mask: 0.8319  decode.d5.loss_dice: 0.9129  decode.d6.loss_cls: 0.9983  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 0.8994  decode.d7.loss_cls: 0.9871  decode.d7.loss_mask: 0.8072  decode.d7.loss_dice: 0.9056  decode.d8.loss_cls: 0.9598  decode.d8.loss_mask: 0.8312  decode.d8.loss_dice: 0.9371
2023/05/24 00:33:47 - mmengine - INFO - Iter(train) [ 51100/160000]  lr: 7.0733e-06  eta: 12:56:48  time: 0.4226  data_time: 0.0100  memory: 4858  grad_norm: 100.3972  loss: 54.8253  decode.loss_cls: 2.0017  decode.loss_mask: 1.1052  decode.loss_dice: 2.0821  decode.d0.loss_cls: 4.0313  decode.d0.loss_mask: 1.1720  decode.d0.loss_dice: 2.4031  decode.d1.loss_cls: 2.0904  decode.d1.loss_mask: 1.1752  decode.d1.loss_dice: 2.3197  decode.d2.loss_cls: 2.0468  decode.d2.loss_mask: 1.0928  decode.d2.loss_dice: 2.2067  decode.d3.loss_cls: 2.0236  decode.d3.loss_mask: 1.0778  decode.d3.loss_dice: 2.1116  decode.d4.loss_cls: 2.0119  decode.d4.loss_mask: 1.0794  decode.d4.loss_dice: 2.1882  decode.d5.loss_cls: 1.9883  decode.d5.loss_mask: 1.0441  decode.d5.loss_dice: 2.1533  decode.d6.loss_cls: 1.9275  decode.d6.loss_mask: 1.0384  decode.d6.loss_dice: 2.1033  decode.d7.loss_cls: 2.0341  decode.d7.loss_mask: 1.0598  decode.d7.loss_dice: 2.1221  decode.d8.loss_cls: 1.9826  decode.d8.loss_mask: 1.0842  decode.d8.loss_dice: 2.0681
2023/05/24 00:34:08 - mmengine - INFO - Iter(train) [ 51150/160000]  lr: 7.0703e-06  eta: 12:56:26  time: 0.4072  data_time: 0.0098  memory: 4839  grad_norm: 93.9948  loss: 33.2543  decode.loss_cls: 1.2626  decode.loss_mask: 0.7676  decode.loss_dice: 1.0712  decode.d0.loss_cls: 3.1028  decode.d0.loss_mask: 0.8251  decode.d0.loss_dice: 1.2510  decode.d1.loss_cls: 1.2806  decode.d1.loss_mask: 0.8242  decode.d1.loss_dice: 1.1706  decode.d2.loss_cls: 1.1984  decode.d2.loss_mask: 0.7966  decode.d2.loss_dice: 1.1148  decode.d3.loss_cls: 1.2550  decode.d3.loss_mask: 0.7942  decode.d3.loss_dice: 1.0793  decode.d4.loss_cls: 1.2239  decode.d4.loss_mask: 0.7996  decode.d4.loss_dice: 1.0941  decode.d5.loss_cls: 1.2047  decode.d5.loss_mask: 0.8020  decode.d5.loss_dice: 1.0746  decode.d6.loss_cls: 1.2313  decode.d6.loss_mask: 0.7987  decode.d6.loss_dice: 1.0891  decode.d7.loss_cls: 1.1919  decode.d7.loss_mask: 0.7954  decode.d7.loss_dice: 1.1043  decode.d8.loss_cls: 1.1660  decode.d8.loss_mask: 0.7871  decode.d8.loss_dice: 1.0976
2023/05/24 00:34:29 - mmengine - INFO - Iter(train) [ 51200/160000]  lr: 7.0674e-06  eta: 12:56:02  time: 0.4100  data_time: 0.0105  memory: 4845  grad_norm: 108.3896  loss: 33.3180  decode.loss_cls: 1.2232  decode.loss_mask: 0.7794  decode.loss_dice: 1.0109  decode.d0.loss_cls: 3.1186  decode.d0.loss_mask: 0.8081  decode.d0.loss_dice: 1.2335  decode.d1.loss_cls: 1.4024  decode.d1.loss_mask: 0.8429  decode.d1.loss_dice: 1.1424  decode.d2.loss_cls: 1.3946  decode.d2.loss_mask: 0.8224  decode.d2.loss_dice: 1.0952  decode.d3.loss_cls: 1.2836  decode.d3.loss_mask: 0.8087  decode.d3.loss_dice: 1.0529  decode.d4.loss_cls: 1.2595  decode.d4.loss_mask: 0.7815  decode.d4.loss_dice: 1.0489  decode.d5.loss_cls: 1.2380  decode.d5.loss_mask: 0.7910  decode.d5.loss_dice: 1.0276  decode.d6.loss_cls: 1.2439  decode.d6.loss_mask: 0.8215  decode.d6.loss_dice: 1.0392  decode.d7.loss_cls: 1.2185  decode.d7.loss_mask: 0.7822  decode.d7.loss_dice: 1.0210  decode.d8.loss_cls: 1.2200  decode.d8.loss_mask: 0.7901  decode.d8.loss_dice: 1.0162
2023/05/24 00:34:50 - mmengine - INFO - Iter(train) [ 51250/160000]  lr: 7.0645e-06  eta: 12:55:40  time: 0.4089  data_time: 0.0102  memory: 4900  grad_norm: 102.2001  loss: 36.6764  decode.loss_cls: 1.4399  decode.loss_mask: 0.7100  decode.loss_dice: 1.1702  decode.d0.loss_cls: 3.3905  decode.d0.loss_mask: 0.8025  decode.d0.loss_dice: 1.4298  decode.d1.loss_cls: 1.5953  decode.d1.loss_mask: 0.8748  decode.d1.loss_dice: 1.2427  decode.d2.loss_cls: 1.5187  decode.d2.loss_mask: 0.7459  decode.d2.loss_dice: 1.2435  decode.d3.loss_cls: 1.4635  decode.d3.loss_mask: 0.8045  decode.d3.loss_dice: 1.2519  decode.d4.loss_cls: 1.4439  decode.d4.loss_mask: 0.7857  decode.d4.loss_dice: 1.2453  decode.d5.loss_cls: 1.4516  decode.d5.loss_mask: 0.7507  decode.d5.loss_dice: 1.2148  decode.d6.loss_cls: 1.3905  decode.d6.loss_mask: 0.7624  decode.d6.loss_dice: 1.1991  decode.d7.loss_cls: 1.5263  decode.d7.loss_mask: 0.6846  decode.d7.loss_dice: 1.1974  decode.d8.loss_cls: 1.4473  decode.d8.loss_mask: 0.7300  decode.d8.loss_dice: 1.1633
2023/05/24 00:35:10 - mmengine - INFO - Iter(train) [ 51300/160000]  lr: 7.0616e-06  eta: 12:55:17  time: 0.4216  data_time: 0.0098  memory: 4874  grad_norm: 81.4653  loss: 43.8806  decode.loss_cls: 1.4784  decode.loss_mask: 0.8911  decode.loss_dice: 1.6788  decode.d0.loss_cls: 3.4052  decode.d0.loss_mask: 0.9273  decode.d0.loss_dice: 1.8993  decode.d1.loss_cls: 1.7261  decode.d1.loss_mask: 0.9314  decode.d1.loss_dice: 1.8294  decode.d2.loss_cls: 1.6652  decode.d2.loss_mask: 0.8949  decode.d2.loss_dice: 1.6879  decode.d3.loss_cls: 1.5978  decode.d3.loss_mask: 0.8988  decode.d3.loss_dice: 1.7301  decode.d4.loss_cls: 1.5468  decode.d4.loss_mask: 0.8871  decode.d4.loss_dice: 1.6885  decode.d5.loss_cls: 1.5274  decode.d5.loss_mask: 0.8966  decode.d5.loss_dice: 1.6992  decode.d6.loss_cls: 1.5448  decode.d6.loss_mask: 0.9332  decode.d6.loss_dice: 1.6900  decode.d7.loss_cls: 1.4791  decode.d7.loss_mask: 0.9313  decode.d7.loss_dice: 1.7247  decode.d8.loss_cls: 1.4465  decode.d8.loss_mask: 0.9260  decode.d8.loss_dice: 1.7178
2023/05/24 00:35:31 - mmengine - INFO - Iter(train) [ 51350/160000]  lr: 7.0586e-06  eta: 12:54:54  time: 0.4190  data_time: 0.0101  memory: 4785  grad_norm: 98.0291  loss: 34.6682  decode.loss_cls: 1.1927  decode.loss_mask: 0.8003  decode.loss_dice: 1.2044  decode.d0.loss_cls: 2.9700  decode.d0.loss_mask: 0.8853  decode.d0.loss_dice: 1.4569  decode.d1.loss_cls: 1.3794  decode.d1.loss_mask: 0.8431  decode.d1.loss_dice: 1.3172  decode.d2.loss_cls: 1.2663  decode.d2.loss_mask: 0.8115  decode.d2.loss_dice: 1.2797  decode.d3.loss_cls: 1.1510  decode.d3.loss_mask: 0.8343  decode.d3.loss_dice: 1.2384  decode.d4.loss_cls: 1.1853  decode.d4.loss_mask: 0.8253  decode.d4.loss_dice: 1.2193  decode.d5.loss_cls: 1.2053  decode.d5.loss_mask: 0.7995  decode.d5.loss_dice: 1.2124  decode.d6.loss_cls: 1.1794  decode.d6.loss_mask: 0.8227  decode.d6.loss_dice: 1.2210  decode.d7.loss_cls: 1.1816  decode.d7.loss_mask: 0.7850  decode.d7.loss_dice: 1.1958  decode.d8.loss_cls: 1.1607  decode.d8.loss_mask: 0.8408  decode.d8.loss_dice: 1.2034
2023/05/24 00:35:53 - mmengine - INFO - Iter(train) [ 51400/160000]  lr: 7.0557e-06  eta: 12:54:34  time: 0.4690  data_time: 0.0103  memory: 4829  grad_norm: 79.6696  loss: 32.2426  decode.loss_cls: 1.2528  decode.loss_mask: 0.6310  decode.loss_dice: 1.0629  decode.d0.loss_cls: 3.2500  decode.d0.loss_mask: 0.6824  decode.d0.loss_dice: 1.2873  decode.d1.loss_cls: 1.4004  decode.d1.loss_mask: 0.6695  decode.d1.loss_dice: 1.1977  decode.d2.loss_cls: 1.3168  decode.d2.loss_mask: 0.6590  decode.d2.loss_dice: 1.1509  decode.d3.loss_cls: 1.2236  decode.d3.loss_mask: 0.6452  decode.d3.loss_dice: 1.1295  decode.d4.loss_cls: 1.2440  decode.d4.loss_mask: 0.6265  decode.d4.loss_dice: 1.1119  decode.d5.loss_cls: 1.2127  decode.d5.loss_mask: 0.6312  decode.d5.loss_dice: 1.0923  decode.d6.loss_cls: 1.2022  decode.d6.loss_mask: 0.6341  decode.d6.loss_dice: 1.0767  decode.d7.loss_cls: 1.2234  decode.d7.loss_mask: 0.6381  decode.d7.loss_dice: 1.0708  decode.d8.loss_cls: 1.2133  decode.d8.loss_mask: 0.6325  decode.d8.loss_dice: 1.0740
2023/05/24 00:36:16 - mmengine - INFO - Iter(train) [ 51450/160000]  lr: 7.0528e-06  eta: 12:54:16  time: 0.4391  data_time: 0.0099  memory: 4805  grad_norm: 83.7162  loss: 39.5487  decode.loss_cls: 1.3480  decode.loss_mask: 0.8183  decode.loss_dice: 1.4234  decode.d0.loss_cls: 3.4901  decode.d0.loss_mask: 0.8396  decode.d0.loss_dice: 1.6934  decode.d1.loss_cls: 1.5126  decode.d1.loss_mask: 0.8110  decode.d1.loss_dice: 1.5978  decode.d2.loss_cls: 1.4982  decode.d2.loss_mask: 0.8223  decode.d2.loss_dice: 1.5214  decode.d3.loss_cls: 1.4185  decode.d3.loss_mask: 0.8996  decode.d3.loss_dice: 1.4814  decode.d4.loss_cls: 1.3912  decode.d4.loss_mask: 0.8547  decode.d4.loss_dice: 1.4767  decode.d5.loss_cls: 1.4848  decode.d5.loss_mask: 0.7965  decode.d5.loss_dice: 1.4571  decode.d6.loss_cls: 1.3834  decode.d6.loss_mask: 0.8288  decode.d6.loss_dice: 1.4504  decode.d7.loss_cls: 1.4139  decode.d7.loss_mask: 0.8233  decode.d7.loss_dice: 1.4178  decode.d8.loss_cls: 1.3656  decode.d8.loss_mask: 0.8258  decode.d8.loss_dice: 1.4030
2023/05/24 00:36:37 - mmengine - INFO - Iter(train) [ 51500/160000]  lr: 7.0499e-06  eta: 12:53:53  time: 0.4112  data_time: 0.0098  memory: 4885  grad_norm: 116.6023  loss: 39.1038  decode.loss_cls: 1.5051  decode.loss_mask: 0.8720  decode.loss_dice: 1.2134  decode.d0.loss_cls: 3.6283  decode.d0.loss_mask: 0.9682  decode.d0.loss_dice: 1.4590  decode.d1.loss_cls: 1.5708  decode.d1.loss_mask: 0.9129  decode.d1.loss_dice: 1.3710  decode.d2.loss_cls: 1.5244  decode.d2.loss_mask: 0.9792  decode.d2.loss_dice: 1.3450  decode.d3.loss_cls: 1.5057  decode.d3.loss_mask: 0.9259  decode.d3.loss_dice: 1.3189  decode.d4.loss_cls: 1.5076  decode.d4.loss_mask: 0.8991  decode.d4.loss_dice: 1.2562  decode.d5.loss_cls: 1.5029  decode.d5.loss_mask: 0.8907  decode.d5.loss_dice: 1.2653  decode.d6.loss_cls: 1.4319  decode.d6.loss_mask: 0.8891  decode.d6.loss_dice: 1.2416  decode.d7.loss_cls: 1.4501  decode.d7.loss_mask: 0.8880  decode.d7.loss_dice: 1.2236  decode.d8.loss_cls: 1.4570  decode.d8.loss_mask: 0.8778  decode.d8.loss_dice: 1.2234
2023/05/24 00:36:58 - mmengine - INFO - Iter(train) [ 51550/160000]  lr: 7.0469e-06  eta: 12:53:31  time: 0.4163  data_time: 0.0101  memory: 4937  grad_norm: 91.7905  loss: 41.6238  decode.loss_cls: 1.5215  decode.loss_mask: 0.8871  decode.loss_dice: 1.4666  decode.d0.loss_cls: 3.3495  decode.d0.loss_mask: 1.1010  decode.d0.loss_dice: 1.7168  decode.d1.loss_cls: 1.6602  decode.d1.loss_mask: 0.9380  decode.d1.loss_dice: 1.5774  decode.d2.loss_cls: 1.5563  decode.d2.loss_mask: 0.9453  decode.d2.loss_dice: 1.5256  decode.d3.loss_cls: 1.5012  decode.d3.loss_mask: 0.9219  decode.d3.loss_dice: 1.4933  decode.d4.loss_cls: 1.4961  decode.d4.loss_mask: 0.9143  decode.d4.loss_dice: 1.4522  decode.d5.loss_cls: 1.5314  decode.d5.loss_mask: 0.9111  decode.d5.loss_dice: 1.5195  decode.d6.loss_cls: 1.5159  decode.d6.loss_mask: 0.8892  decode.d6.loss_dice: 1.4562  decode.d7.loss_cls: 1.4745  decode.d7.loss_mask: 0.9120  decode.d7.loss_dice: 1.4937  decode.d8.loss_cls: 1.4893  decode.d8.loss_mask: 0.9019  decode.d8.loss_dice: 1.5048
2023/05/24 00:37:19 - mmengine - INFO - Iter(train) [ 51600/160000]  lr: 7.0440e-06  eta: 12:53:08  time: 0.4262  data_time: 0.0101  memory: 4857  grad_norm: 103.8464  loss: 33.8433  decode.loss_cls: 1.2661  decode.loss_mask: 0.6354  decode.loss_dice: 1.2095  decode.d0.loss_cls: 3.0852  decode.d0.loss_mask: 0.7122  decode.d0.loss_dice: 1.3964  decode.d1.loss_cls: 1.4018  decode.d1.loss_mask: 0.7199  decode.d1.loss_dice: 1.2999  decode.d2.loss_cls: 1.3149  decode.d2.loss_mask: 0.6945  decode.d2.loss_dice: 1.2586  decode.d3.loss_cls: 1.3782  decode.d3.loss_mask: 0.6593  decode.d3.loss_dice: 1.2274  decode.d4.loss_cls: 1.3307  decode.d4.loss_mask: 0.6720  decode.d4.loss_dice: 1.2242  decode.d5.loss_cls: 1.3093  decode.d5.loss_mask: 0.6606  decode.d5.loss_dice: 1.2060  decode.d6.loss_cls: 1.2222  decode.d6.loss_mask: 0.6404  decode.d6.loss_dice: 1.2043  decode.d7.loss_cls: 1.2074  decode.d7.loss_mask: 0.6316  decode.d7.loss_dice: 1.2015  decode.d8.loss_cls: 1.2061  decode.d8.loss_mask: 0.6471  decode.d8.loss_dice: 1.2205
2023/05/24 00:37:40 - mmengine - INFO - Iter(train) [ 51650/160000]  lr: 7.0411e-06  eta: 12:52:46  time: 0.4161  data_time: 0.0105  memory: 4883  grad_norm: 149.7746  loss: 43.7018  decode.loss_cls: 1.4858  decode.loss_mask: 0.9048  decode.loss_dice: 1.5833  decode.d0.loss_cls: 3.6827  decode.d0.loss_mask: 0.9630  decode.d0.loss_dice: 1.9125  decode.d1.loss_cls: 1.6883  decode.d1.loss_mask: 0.9019  decode.d1.loss_dice: 1.7706  decode.d2.loss_cls: 1.6661  decode.d2.loss_mask: 0.9375  decode.d2.loss_dice: 1.7304  decode.d3.loss_cls: 1.5858  decode.d3.loss_mask: 0.9148  decode.d3.loss_dice: 1.6529  decode.d4.loss_cls: 1.5255  decode.d4.loss_mask: 0.8980  decode.d4.loss_dice: 1.6698  decode.d5.loss_cls: 1.5652  decode.d5.loss_mask: 0.9089  decode.d5.loss_dice: 1.6335  decode.d6.loss_cls: 1.5593  decode.d6.loss_mask: 0.9187  decode.d6.loss_dice: 1.6164  decode.d7.loss_cls: 1.5154  decode.d7.loss_mask: 0.8909  decode.d7.loss_dice: 1.6149  decode.d8.loss_cls: 1.5146  decode.d8.loss_mask: 0.8913  decode.d8.loss_dice: 1.5992
2023/05/24 00:38:00 - mmengine - INFO - Iter(train) [ 51700/160000]  lr: 7.0382e-06  eta: 12:52:23  time: 0.4134  data_time: 0.0107  memory: 4875  grad_norm: 109.8754  loss: 40.7011  decode.loss_cls: 1.5251  decode.loss_mask: 0.8610  decode.loss_dice: 1.4441  decode.d0.loss_cls: 3.5645  decode.d0.loss_mask: 0.8834  decode.d0.loss_dice: 1.5644  decode.d1.loss_cls: 1.6380  decode.d1.loss_mask: 0.8665  decode.d1.loss_dice: 1.5329  decode.d2.loss_cls: 1.5534  decode.d2.loss_mask: 0.8371  decode.d2.loss_dice: 1.5007  decode.d3.loss_cls: 1.5192  decode.d3.loss_mask: 0.8310  decode.d3.loss_dice: 1.4173  decode.d4.loss_cls: 1.5389  decode.d4.loss_mask: 0.8602  decode.d4.loss_dice: 1.4641  decode.d5.loss_cls: 1.5413  decode.d5.loss_mask: 0.8617  decode.d5.loss_dice: 1.4271  decode.d6.loss_cls: 1.5576  decode.d6.loss_mask: 0.8362  decode.d6.loss_dice: 1.4222  decode.d7.loss_cls: 1.5934  decode.d7.loss_mask: 0.8223  decode.d7.loss_dice: 1.4223  decode.d8.loss_cls: 1.5531  decode.d8.loss_mask: 0.8625  decode.d8.loss_dice: 1.3998
2023/05/24 00:38:21 - mmengine - INFO - Iter(train) [ 51750/160000]  lr: 7.0353e-06  eta: 12:52:01  time: 0.4246  data_time: 0.0103  memory: 4907  grad_norm: 92.8176  loss: 27.1198  decode.loss_cls: 0.9511  decode.loss_mask: 0.5988  decode.loss_dice: 0.8908  decode.d0.loss_cls: 2.6608  decode.d0.loss_mask: 0.6853  decode.d0.loss_dice: 1.0687  decode.d1.loss_cls: 1.0752  decode.d1.loss_mask: 0.6678  decode.d1.loss_dice: 0.9888  decode.d2.loss_cls: 1.0918  decode.d2.loss_mask: 0.6317  decode.d2.loss_dice: 0.9209  decode.d3.loss_cls: 1.0053  decode.d3.loss_mask: 0.6369  decode.d3.loss_dice: 0.9054  decode.d4.loss_cls: 1.0028  decode.d4.loss_mask: 0.6140  decode.d4.loss_dice: 0.8927  decode.d5.loss_cls: 0.9853  decode.d5.loss_mask: 0.6132  decode.d5.loss_dice: 0.9022  decode.d6.loss_cls: 0.9336  decode.d6.loss_mask: 0.6017  decode.d6.loss_dice: 0.9210  decode.d7.loss_cls: 0.9216  decode.d7.loss_mask: 0.5942  decode.d7.loss_dice: 0.8840  decode.d8.loss_cls: 0.9470  decode.d8.loss_mask: 0.6020  decode.d8.loss_dice: 0.9257
2023/05/24 00:38:42 - mmengine - INFO - Iter(train) [ 51800/160000]  lr: 7.0323e-06  eta: 12:51:38  time: 0.4088  data_time: 0.0097  memory: 4864  grad_norm: 91.1136  loss: 37.5234  decode.loss_cls: 1.4187  decode.loss_mask: 0.6216  decode.loss_dice: 1.4213  decode.d0.loss_cls: 3.2829  decode.d0.loss_mask: 0.6300  decode.d0.loss_dice: 1.5994  decode.d1.loss_cls: 1.6339  decode.d1.loss_mask: 0.6790  decode.d1.loss_dice: 1.5621  decode.d2.loss_cls: 1.5515  decode.d2.loss_mask: 0.6130  decode.d2.loss_dice: 1.4763  decode.d3.loss_cls: 1.4363  decode.d3.loss_mask: 0.6436  decode.d3.loss_dice: 1.4492  decode.d4.loss_cls: 1.4034  decode.d4.loss_mask: 0.6541  decode.d4.loss_dice: 1.4643  decode.d5.loss_cls: 1.4205  decode.d5.loss_mask: 0.6348  decode.d5.loss_dice: 1.4333  decode.d6.loss_cls: 1.4310  decode.d6.loss_mask: 0.6386  decode.d6.loss_dice: 1.4122  decode.d7.loss_cls: 1.3887  decode.d7.loss_mask: 0.6366  decode.d7.loss_dice: 1.4498  decode.d8.loss_cls: 1.4548  decode.d8.loss_mask: 0.6445  decode.d8.loss_dice: 1.4381
2023/05/24 00:39:05 - mmengine - INFO - Iter(train) [ 51850/160000]  lr: 7.0294e-06  eta: 12:51:19  time: 0.4098  data_time: 0.0100  memory: 4890  grad_norm: 108.1193  loss: 33.2861  decode.loss_cls: 1.2355  decode.loss_mask: 0.6304  decode.loss_dice: 1.2464  decode.d0.loss_cls: 3.0490  decode.d0.loss_mask: 0.6662  decode.d0.loss_dice: 1.3969  decode.d1.loss_cls: 1.4225  decode.d1.loss_mask: 0.6121  decode.d1.loss_dice: 1.3060  decode.d2.loss_cls: 1.3168  decode.d2.loss_mask: 0.5884  decode.d2.loss_dice: 1.2603  decode.d3.loss_cls: 1.2139  decode.d3.loss_mask: 0.6161  decode.d3.loss_dice: 1.2658  decode.d4.loss_cls: 1.1762  decode.d4.loss_mask: 0.6114  decode.d4.loss_dice: 1.2610  decode.d5.loss_cls: 1.2187  decode.d5.loss_mask: 0.6259  decode.d5.loss_dice: 1.2672  decode.d6.loss_cls: 1.1842  decode.d6.loss_mask: 0.6258  decode.d6.loss_dice: 1.2783  decode.d7.loss_cls: 1.2318  decode.d7.loss_mask: 0.6185  decode.d7.loss_dice: 1.2682  decode.d8.loss_cls: 1.2118  decode.d8.loss_mask: 0.6229  decode.d8.loss_dice: 1.2582
2023/05/24 00:39:25 - mmengine - INFO - Iter(train) [ 51900/160000]  lr: 7.0265e-06  eta: 12:50:56  time: 0.4055  data_time: 0.0101  memory: 4890  grad_norm: 103.5374  loss: 29.4941  decode.loss_cls: 1.1598  decode.loss_mask: 0.6044  decode.loss_dice: 1.0219  decode.d0.loss_cls: 2.6724  decode.d0.loss_mask: 0.7536  decode.d0.loss_dice: 1.1753  decode.d1.loss_cls: 1.2301  decode.d1.loss_mask: 0.6562  decode.d1.loss_dice: 1.1049  decode.d2.loss_cls: 1.2048  decode.d2.loss_mask: 0.6074  decode.d2.loss_dice: 0.9742  decode.d3.loss_cls: 1.1208  decode.d3.loss_mask: 0.6101  decode.d3.loss_dice: 0.9828  decode.d4.loss_cls: 1.1273  decode.d4.loss_mask: 0.5577  decode.d4.loss_dice: 0.9892  decode.d5.loss_cls: 1.1036  decode.d5.loss_mask: 0.5916  decode.d5.loss_dice: 1.0050  decode.d6.loss_cls: 1.1142  decode.d6.loss_mask: 0.6051  decode.d6.loss_dice: 1.0230  decode.d7.loss_cls: 1.0955  decode.d7.loss_mask: 0.5756  decode.d7.loss_dice: 1.0209  decode.d8.loss_cls: 1.1624  decode.d8.loss_mask: 0.6098  decode.d8.loss_dice: 1.0349
2023/05/24 00:39:46 - mmengine - INFO - Iter(train) [ 51950/160000]  lr: 7.0236e-06  eta: 12:50:34  time: 0.4571  data_time: 0.0097  memory: 4895  grad_norm: 101.9932  loss: 35.9276  decode.loss_cls: 1.1730  decode.loss_mask: 0.8105  decode.loss_dice: 1.3885  decode.d0.loss_cls: 3.1564  decode.d0.loss_mask: 0.8263  decode.d0.loss_dice: 1.5703  decode.d1.loss_cls: 1.2625  decode.d1.loss_mask: 0.8098  decode.d1.loss_dice: 1.4266  decode.d2.loss_cls: 1.2100  decode.d2.loss_mask: 0.7764  decode.d2.loss_dice: 1.4585  decode.d3.loss_cls: 1.1997  decode.d3.loss_mask: 0.7668  decode.d3.loss_dice: 1.4041  decode.d4.loss_cls: 1.1607  decode.d4.loss_mask: 0.7680  decode.d4.loss_dice: 1.4098  decode.d5.loss_cls: 1.1322  decode.d5.loss_mask: 0.7636  decode.d5.loss_dice: 1.4171  decode.d6.loss_cls: 1.1698  decode.d6.loss_mask: 0.7858  decode.d6.loss_dice: 1.4029  decode.d7.loss_cls: 1.1689  decode.d7.loss_mask: 0.7916  decode.d7.loss_dice: 1.3560  decode.d8.loss_cls: 1.2021  decode.d8.loss_mask: 0.7916  decode.d8.loss_dice: 1.3682
2023/05/24 00:40:09 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 00:40:09 - mmengine - INFO - Iter(train) [ 52000/160000]  lr: 7.0206e-06  eta: 12:50:15  time: 0.4162  data_time: 0.0104  memory: 4835  grad_norm: 91.5849  loss: 38.2815  decode.loss_cls: 1.2741  decode.loss_mask: 0.8049  decode.loss_dice: 1.4994  decode.d0.loss_cls: 2.9392  decode.d0.loss_mask: 0.8485  decode.d0.loss_dice: 1.7304  decode.d1.loss_cls: 1.4150  decode.d1.loss_mask: 0.8263  decode.d1.loss_dice: 1.5957  decode.d2.loss_cls: 1.3560  decode.d2.loss_mask: 0.8238  decode.d2.loss_dice: 1.5430  decode.d3.loss_cls: 1.3234  decode.d3.loss_mask: 0.8128  decode.d3.loss_dice: 1.5014  decode.d4.loss_cls: 1.2901  decode.d4.loss_mask: 0.8070  decode.d4.loss_dice: 1.5221  decode.d5.loss_cls: 1.3218  decode.d5.loss_mask: 0.8323  decode.d5.loss_dice: 1.4790  decode.d6.loss_cls: 1.3064  decode.d6.loss_mask: 0.8089  decode.d6.loss_dice: 1.4371  decode.d7.loss_cls: 1.3027  decode.d7.loss_mask: 0.8064  decode.d7.loss_dice: 1.4957  decode.d8.loss_cls: 1.2745  decode.d8.loss_mask: 0.8147  decode.d8.loss_dice: 1.4890
2023/05/24 00:40:09 - mmengine - INFO - Saving checkpoint at 52000 iterations
2023/05/24 00:40:35 - mmengine - INFO - Iter(train) [ 52050/160000]  lr: 7.0177e-06  eta: 12:50:03  time: 0.4103  data_time: 0.0100  memory: 4781  grad_norm: 98.6469  loss: 42.8535  decode.loss_cls: 1.3403  decode.loss_mask: 1.0211  decode.loss_dice: 1.6950  decode.d0.loss_cls: 3.2459  decode.d0.loss_mask: 0.9808  decode.d0.loss_dice: 1.8759  decode.d1.loss_cls: 1.3881  decode.d1.loss_mask: 1.0201  decode.d1.loss_dice: 1.7764  decode.d2.loss_cls: 1.3699  decode.d2.loss_mask: 1.0144  decode.d2.loss_dice: 1.7651  decode.d3.loss_cls: 1.3492  decode.d3.loss_mask: 0.9797  decode.d3.loss_dice: 1.6461  decode.d4.loss_cls: 1.3293  decode.d4.loss_mask: 0.9783  decode.d4.loss_dice: 1.7147  decode.d5.loss_cls: 1.4000  decode.d5.loss_mask: 0.9948  decode.d5.loss_dice: 1.7202  decode.d6.loss_cls: 1.2664  decode.d6.loss_mask: 1.0010  decode.d6.loss_dice: 1.7633  decode.d7.loss_cls: 1.3965  decode.d7.loss_mask: 1.0090  decode.d7.loss_dice: 1.6850  decode.d8.loss_cls: 1.4018  decode.d8.loss_mask: 1.0154  decode.d8.loss_dice: 1.7100
2023/05/24 00:40:55 - mmengine - INFO - Iter(train) [ 52100/160000]  lr: 7.0148e-06  eta: 12:49:40  time: 0.4269  data_time: 0.0100  memory: 4901  grad_norm: 136.5500  loss: 37.8090  decode.loss_cls: 1.3661  decode.loss_mask: 0.7529  decode.loss_dice: 1.3491  decode.d0.loss_cls: 3.1919  decode.d0.loss_mask: 0.8675  decode.d0.loss_dice: 1.6071  decode.d1.loss_cls: 1.4966  decode.d1.loss_mask: 0.7638  decode.d1.loss_dice: 1.4677  decode.d2.loss_cls: 1.4565  decode.d2.loss_mask: 0.7858  decode.d2.loss_dice: 1.4173  decode.d3.loss_cls: 1.3678  decode.d3.loss_mask: 0.7742  decode.d3.loss_dice: 1.3910  decode.d4.loss_cls: 1.3669  decode.d4.loss_mask: 0.7840  decode.d4.loss_dice: 1.3775  decode.d5.loss_cls: 1.3861  decode.d5.loss_mask: 0.7957  decode.d5.loss_dice: 1.4097  decode.d6.loss_cls: 1.3550  decode.d6.loss_mask: 0.7914  decode.d6.loss_dice: 1.3784  decode.d7.loss_cls: 1.3484  decode.d7.loss_mask: 0.7807  decode.d7.loss_dice: 1.3876  decode.d8.loss_cls: 1.4079  decode.d8.loss_mask: 0.7682  decode.d8.loss_dice: 1.4164
2023/05/24 00:41:16 - mmengine - INFO - Iter(train) [ 52150/160000]  lr: 7.0118e-06  eta: 12:49:17  time: 0.4195  data_time: 0.0099  memory: 4840  grad_norm: 82.3229  loss: 46.9076  decode.loss_cls: 1.5571  decode.loss_mask: 1.0156  decode.loss_dice: 1.8332  decode.d0.loss_cls: 3.5895  decode.d0.loss_mask: 1.0999  decode.d0.loss_dice: 2.1062  decode.d1.loss_cls: 1.7560  decode.d1.loss_mask: 1.0437  decode.d1.loss_dice: 1.9512  decode.d2.loss_cls: 1.6702  decode.d2.loss_mask: 1.0209  decode.d2.loss_dice: 1.8701  decode.d3.loss_cls: 1.6324  decode.d3.loss_mask: 1.0189  decode.d3.loss_dice: 1.8151  decode.d4.loss_cls: 1.6142  decode.d4.loss_mask: 1.0077  decode.d4.loss_dice: 1.8197  decode.d5.loss_cls: 1.5853  decode.d5.loss_mask: 1.0140  decode.d5.loss_dice: 1.8305  decode.d6.loss_cls: 1.5123  decode.d6.loss_mask: 1.0338  decode.d6.loss_dice: 1.7921  decode.d7.loss_cls: 1.5129  decode.d7.loss_mask: 1.0136  decode.d7.loss_dice: 1.8134  decode.d8.loss_cls: 1.5284  decode.d8.loss_mask: 1.0206  decode.d8.loss_dice: 1.8291
2023/05/24 00:41:37 - mmengine - INFO - Iter(train) [ 52200/160000]  lr: 7.0089e-06  eta: 12:48:55  time: 0.4205  data_time: 0.0101  memory: 4890  grad_norm: 203.3292  loss: 39.7386  decode.loss_cls: 1.3504  decode.loss_mask: 0.9890  decode.loss_dice: 1.4368  decode.d0.loss_cls: 3.0627  decode.d0.loss_mask: 1.0783  decode.d0.loss_dice: 1.6196  decode.d1.loss_cls: 1.4404  decode.d1.loss_mask: 0.9740  decode.d1.loss_dice: 1.5592  decode.d2.loss_cls: 1.3590  decode.d2.loss_mask: 0.9872  decode.d2.loss_dice: 1.4786  decode.d3.loss_cls: 1.3224  decode.d3.loss_mask: 0.9674  decode.d3.loss_dice: 1.4569  decode.d4.loss_cls: 1.3136  decode.d4.loss_mask: 0.9695  decode.d4.loss_dice: 1.4604  decode.d5.loss_cls: 1.2703  decode.d5.loss_mask: 0.9719  decode.d5.loss_dice: 1.4596  decode.d6.loss_cls: 1.2922  decode.d6.loss_mask: 0.9936  decode.d6.loss_dice: 1.4377  decode.d7.loss_cls: 1.3371  decode.d7.loss_mask: 0.9865  decode.d7.loss_dice: 1.4223  decode.d8.loss_cls: 1.3088  decode.d8.loss_mask: 1.0011  decode.d8.loss_dice: 1.4318
2023/05/24 00:41:57 - mmengine - INFO - Iter(train) [ 52250/160000]  lr: 7.0060e-06  eta: 12:48:31  time: 0.4176  data_time: 0.0098  memory: 4905  grad_norm: 93.5700  loss: 41.4620  decode.loss_cls: 1.5498  decode.loss_mask: 0.7071  decode.loss_dice: 1.6403  decode.d0.loss_cls: 3.4655  decode.d0.loss_mask: 0.7841  decode.d0.loss_dice: 1.8972  decode.d1.loss_cls: 1.6112  decode.d1.loss_mask: 0.7226  decode.d1.loss_dice: 1.6934  decode.d2.loss_cls: 1.6154  decode.d2.loss_mask: 0.7070  decode.d2.loss_dice: 1.6969  decode.d3.loss_cls: 1.5608  decode.d3.loss_mask: 0.6911  decode.d3.loss_dice: 1.6770  decode.d4.loss_cls: 1.5293  decode.d4.loss_mask: 0.6858  decode.d4.loss_dice: 1.7014  decode.d5.loss_cls: 1.4809  decode.d5.loss_mask: 0.6799  decode.d5.loss_dice: 1.7159  decode.d6.loss_cls: 1.4468  decode.d6.loss_mask: 0.7076  decode.d6.loss_dice: 1.6870  decode.d7.loss_cls: 1.4632  decode.d7.loss_mask: 0.7103  decode.d7.loss_dice: 1.6741  decode.d8.loss_cls: 1.5976  decode.d8.loss_mask: 0.6996  decode.d8.loss_dice: 1.6629
2023/05/24 00:42:18 - mmengine - INFO - Iter(train) [ 52300/160000]  lr: 7.0031e-06  eta: 12:48:09  time: 0.4123  data_time: 0.0101  memory: 4895  grad_norm: 108.3882  loss: 31.5918  decode.loss_cls: 1.0971  decode.loss_mask: 0.7375  decode.loss_dice: 1.0202  decode.d0.loss_cls: 3.0036  decode.d0.loss_mask: 0.7447  decode.d0.loss_dice: 1.2181  decode.d1.loss_cls: 1.2848  decode.d1.loss_mask: 0.7733  decode.d1.loss_dice: 1.1417  decode.d2.loss_cls: 1.2423  decode.d2.loss_mask: 0.7250  decode.d2.loss_dice: 1.1233  decode.d3.loss_cls: 1.1794  decode.d3.loss_mask: 0.7222  decode.d3.loss_dice: 1.0466  decode.d4.loss_cls: 1.2065  decode.d4.loss_mask: 0.7346  decode.d4.loss_dice: 1.0525  decode.d5.loss_cls: 1.1802  decode.d5.loss_mask: 0.7102  decode.d5.loss_dice: 1.0376  decode.d6.loss_cls: 1.1865  decode.d6.loss_mask: 0.7022  decode.d6.loss_dice: 1.0068  decode.d7.loss_cls: 1.0843  decode.d7.loss_mask: 0.7279  decode.d7.loss_dice: 1.0237  decode.d8.loss_cls: 1.1149  decode.d8.loss_mask: 0.7340  decode.d8.loss_dice: 1.0302
2023/05/24 00:42:39 - mmengine - INFO - Iter(train) [ 52350/160000]  lr: 7.0001e-06  eta: 12:47:46  time: 0.4082  data_time: 0.0104  memory: 4866  grad_norm: 115.8512  loss: 34.9221  decode.loss_cls: 1.0175  decode.loss_mask: 0.9125  decode.loss_dice: 1.2024  decode.d0.loss_cls: 3.2321  decode.d0.loss_mask: 1.0081  decode.d0.loss_dice: 1.4435  decode.d1.loss_cls: 1.2598  decode.d1.loss_mask: 0.9543  decode.d1.loss_dice: 1.3428  decode.d2.loss_cls: 1.1736  decode.d2.loss_mask: 0.9246  decode.d2.loss_dice: 1.2551  decode.d3.loss_cls: 1.1261  decode.d3.loss_mask: 0.8749  decode.d3.loss_dice: 1.2484  decode.d4.loss_cls: 1.1008  decode.d4.loss_mask: 0.8858  decode.d4.loss_dice: 1.2431  decode.d5.loss_cls: 1.0474  decode.d5.loss_mask: 0.8952  decode.d5.loss_dice: 1.2222  decode.d6.loss_cls: 1.0000  decode.d6.loss_mask: 0.9209  decode.d6.loss_dice: 1.2323  decode.d7.loss_cls: 1.0610  decode.d7.loss_mask: 0.9225  decode.d7.loss_dice: 1.2291  decode.d8.loss_cls: 1.0480  decode.d8.loss_mask: 0.9192  decode.d8.loss_dice: 1.2190
2023/05/24 00:42:59 - mmengine - INFO - Iter(train) [ 52400/160000]  lr: 6.9972e-06  eta: 12:47:23  time: 0.4084  data_time: 0.0100  memory: 4846  grad_norm: 119.8906  loss: 51.2096  decode.loss_cls: 1.7976  decode.loss_mask: 1.0482  decode.loss_dice: 1.9391  decode.d0.loss_cls: 3.7279  decode.d0.loss_mask: 1.0713  decode.d0.loss_dice: 2.2931  decode.d1.loss_cls: 1.9493  decode.d1.loss_mask: 1.0508  decode.d1.loss_dice: 2.1667  decode.d2.loss_cls: 1.9163  decode.d2.loss_mask: 1.0717  decode.d2.loss_dice: 2.0609  decode.d3.loss_cls: 1.7513  decode.d3.loss_mask: 1.0759  decode.d3.loss_dice: 2.0533  decode.d4.loss_cls: 1.8306  decode.d4.loss_mask: 1.0568  decode.d4.loss_dice: 1.9828  decode.d5.loss_cls: 1.8622  decode.d5.loss_mask: 1.0517  decode.d5.loss_dice: 1.9869  decode.d6.loss_cls: 1.8402  decode.d6.loss_mask: 1.0679  decode.d6.loss_dice: 1.9804  decode.d7.loss_cls: 1.7697  decode.d7.loss_mask: 1.0288  decode.d7.loss_dice: 1.9409  decode.d8.loss_cls: 1.7895  decode.d8.loss_mask: 1.0535  decode.d8.loss_dice: 1.9942
2023/05/24 00:43:21 - mmengine - INFO - Iter(train) [ 52450/160000]  lr: 6.9943e-06  eta: 12:47:02  time: 0.4293  data_time: 0.0100  memory: 4803  grad_norm: 88.3922  loss: 39.0339  decode.loss_cls: 1.4100  decode.loss_mask: 0.7821  decode.loss_dice: 1.3970  decode.d0.loss_cls: 3.1711  decode.d0.loss_mask: 0.8575  decode.d0.loss_dice: 1.6214  decode.d1.loss_cls: 1.6467  decode.d1.loss_mask: 0.8318  decode.d1.loss_dice: 1.4749  decode.d2.loss_cls: 1.5725  decode.d2.loss_mask: 0.8142  decode.d2.loss_dice: 1.4527  decode.d3.loss_cls: 1.4794  decode.d3.loss_mask: 0.8060  decode.d3.loss_dice: 1.4178  decode.d4.loss_cls: 1.5114  decode.d4.loss_mask: 0.7973  decode.d4.loss_dice: 1.4118  decode.d5.loss_cls: 1.4626  decode.d5.loss_mask: 0.7786  decode.d5.loss_dice: 1.3866  decode.d6.loss_cls: 1.4818  decode.d6.loss_mask: 0.7938  decode.d6.loss_dice: 1.3757  decode.d7.loss_cls: 1.4752  decode.d7.loss_mask: 0.8107  decode.d7.loss_dice: 1.4115  decode.d8.loss_cls: 1.3893  decode.d8.loss_mask: 0.8022  decode.d8.loss_dice: 1.4104
2023/05/24 00:43:44 - mmengine - INFO - Iter(train) [ 52500/160000]  lr: 6.9914e-06  eta: 12:46:43  time: 0.4691  data_time: 0.0098  memory: 4823  grad_norm: 93.7172  loss: 33.6957  decode.loss_cls: 1.2185  decode.loss_mask: 0.7437  decode.loss_dice: 1.1066  decode.d0.loss_cls: 2.8998  decode.d0.loss_mask: 0.9127  decode.d0.loss_dice: 1.4359  decode.d1.loss_cls: 1.3921  decode.d1.loss_mask: 0.8065  decode.d1.loss_dice: 1.2309  decode.d2.loss_cls: 1.2954  decode.d2.loss_mask: 0.7988  decode.d2.loss_dice: 1.1637  decode.d3.loss_cls: 1.1757  decode.d3.loss_mask: 0.8078  decode.d3.loss_dice: 1.1764  decode.d4.loss_cls: 1.1555  decode.d4.loss_mask: 0.8085  decode.d4.loss_dice: 1.1279  decode.d5.loss_cls: 1.2092  decode.d5.loss_mask: 0.7673  decode.d5.loss_dice: 1.1695  decode.d6.loss_cls: 1.2336  decode.d6.loss_mask: 0.7618  decode.d6.loss_dice: 1.1206  decode.d7.loss_cls: 1.2143  decode.d7.loss_mask: 0.7431  decode.d7.loss_dice: 1.1177  decode.d8.loss_cls: 1.2319  decode.d8.loss_mask: 0.7379  decode.d8.loss_dice: 1.1324
2023/05/24 00:44:04 - mmengine - INFO - Iter(train) [ 52550/160000]  lr: 6.9884e-06  eta: 12:46:20  time: 0.4097  data_time: 0.0100  memory: 4846  grad_norm: 107.1204  loss: 41.7934  decode.loss_cls: 1.4154  decode.loss_mask: 1.0868  decode.loss_dice: 1.4738  decode.d0.loss_cls: 3.2334  decode.d0.loss_mask: 1.0007  decode.d0.loss_dice: 1.7173  decode.d1.loss_cls: 1.6457  decode.d1.loss_mask: 1.0121  decode.d1.loss_dice: 1.6386  decode.d2.loss_cls: 1.5270  decode.d2.loss_mask: 1.0033  decode.d2.loss_dice: 1.5242  decode.d3.loss_cls: 1.4415  decode.d3.loss_mask: 1.0106  decode.d3.loss_dice: 1.4472  decode.d4.loss_cls: 1.5234  decode.d4.loss_mask: 0.9820  decode.d4.loss_dice: 1.4201  decode.d5.loss_cls: 1.4708  decode.d5.loss_mask: 1.0024  decode.d5.loss_dice: 1.4805  decode.d6.loss_cls: 1.4104  decode.d6.loss_mask: 1.0238  decode.d6.loss_dice: 1.4535  decode.d7.loss_cls: 1.4440  decode.d7.loss_mask: 1.0356  decode.d7.loss_dice: 1.4782  decode.d8.loss_cls: 1.4314  decode.d8.loss_mask: 0.9977  decode.d8.loss_dice: 1.4623
2023/05/24 00:44:27 - mmengine - INFO - Iter(train) [ 52600/160000]  lr: 6.9855e-06  eta: 12:46:02  time: 0.4751  data_time: 0.0102  memory: 4874  grad_norm: 92.6853  loss: 36.1807  decode.loss_cls: 1.3375  decode.loss_mask: 0.7628  decode.loss_dice: 1.2421  decode.d0.loss_cls: 3.1749  decode.d0.loss_mask: 0.8847  decode.d0.loss_dice: 1.4702  decode.d1.loss_cls: 1.4729  decode.d1.loss_mask: 0.8282  decode.d1.loss_dice: 1.4085  decode.d2.loss_cls: 1.3292  decode.d2.loss_mask: 0.7800  decode.d2.loss_dice: 1.2659  decode.d3.loss_cls: 1.3723  decode.d3.loss_mask: 0.7699  decode.d3.loss_dice: 1.2659  decode.d4.loss_cls: 1.3203  decode.d4.loss_mask: 0.7714  decode.d4.loss_dice: 1.2639  decode.d5.loss_cls: 1.3829  decode.d5.loss_mask: 0.7688  decode.d5.loss_dice: 1.2545  decode.d6.loss_cls: 1.4073  decode.d6.loss_mask: 0.7789  decode.d6.loss_dice: 1.2259  decode.d7.loss_cls: 1.3326  decode.d7.loss_mask: 0.7657  decode.d7.loss_dice: 1.2385  decode.d8.loss_cls: 1.3293  decode.d8.loss_mask: 0.7627  decode.d8.loss_dice: 1.2131
2023/05/24 00:44:49 - mmengine - INFO - Iter(train) [ 52650/160000]  lr: 6.9826e-06  eta: 12:45:41  time: 0.4629  data_time: 0.0102  memory: 4885  grad_norm: 126.4232  loss: 41.3977  decode.loss_cls: 1.4071  decode.loss_mask: 0.9113  decode.loss_dice: 1.4966  decode.d0.loss_cls: 3.5286  decode.d0.loss_mask: 0.9686  decode.d0.loss_dice: 1.8154  decode.d1.loss_cls: 1.5751  decode.d1.loss_mask: 0.9727  decode.d1.loss_dice: 1.6469  decode.d2.loss_cls: 1.4991  decode.d2.loss_mask: 0.9256  decode.d2.loss_dice: 1.5669  decode.d3.loss_cls: 1.4289  decode.d3.loss_mask: 0.9111  decode.d3.loss_dice: 1.5405  decode.d4.loss_cls: 1.4785  decode.d4.loss_mask: 0.8889  decode.d4.loss_dice: 1.5525  decode.d5.loss_cls: 1.4085  decode.d5.loss_mask: 0.9431  decode.d5.loss_dice: 1.5441  decode.d6.loss_cls: 1.3956  decode.d6.loss_mask: 0.9211  decode.d6.loss_dice: 1.5179  decode.d7.loss_cls: 1.3932  decode.d7.loss_mask: 0.9087  decode.d7.loss_dice: 1.4868  decode.d8.loss_cls: 1.3675  decode.d8.loss_mask: 0.9037  decode.d8.loss_dice: 1.4937
2023/05/24 00:45:12 - mmengine - INFO - Iter(train) [ 52700/160000]  lr: 6.9797e-06  eta: 12:45:23  time: 0.4132  data_time: 0.0101  memory: 4838  grad_norm: 95.3943  loss: 29.3923  decode.loss_cls: 0.9128  decode.loss_mask: 0.6920  decode.loss_dice: 1.0195  decode.d0.loss_cls: 3.1174  decode.d0.loss_mask: 0.7334  decode.d0.loss_dice: 1.1567  decode.d1.loss_cls: 1.1250  decode.d1.loss_mask: 0.7101  decode.d1.loss_dice: 1.1175  decode.d2.loss_cls: 1.0774  decode.d2.loss_mask: 0.6892  decode.d2.loss_dice: 1.0785  decode.d3.loss_cls: 1.0269  decode.d3.loss_mask: 0.7072  decode.d3.loss_dice: 1.0635  decode.d4.loss_cls: 0.9098  decode.d4.loss_mask: 0.7042  decode.d4.loss_dice: 1.0652  decode.d5.loss_cls: 0.9124  decode.d5.loss_mask: 0.6875  decode.d5.loss_dice: 1.0226  decode.d6.loss_cls: 0.9403  decode.d6.loss_mask: 0.6822  decode.d6.loss_dice: 1.0176  decode.d7.loss_cls: 0.9122  decode.d7.loss_mask: 0.6919  decode.d7.loss_dice: 1.0161  decode.d8.loss_cls: 0.8852  decode.d8.loss_mask: 0.6985  decode.d8.loss_dice: 1.0195
2023/05/24 00:45:35 - mmengine - INFO - Iter(train) [ 52750/160000]  lr: 6.9767e-06  eta: 12:45:04  time: 0.4262  data_time: 0.0102  memory: 4805  grad_norm: 119.6764  loss: 29.1802  decode.loss_cls: 1.2673  decode.loss_mask: 0.6078  decode.loss_dice: 0.8705  decode.d0.loss_cls: 2.7277  decode.d0.loss_mask: 0.6722  decode.d0.loss_dice: 1.0118  decode.d1.loss_cls: 1.2740  decode.d1.loss_mask: 0.6604  decode.d1.loss_dice: 0.9476  decode.d2.loss_cls: 1.2169  decode.d2.loss_mask: 0.6352  decode.d2.loss_dice: 0.8987  decode.d3.loss_cls: 1.2262  decode.d3.loss_mask: 0.6182  decode.d3.loss_dice: 0.9078  decode.d4.loss_cls: 1.2608  decode.d4.loss_mask: 0.6072  decode.d4.loss_dice: 0.8846  decode.d5.loss_cls: 1.2133  decode.d5.loss_mask: 0.6060  decode.d5.loss_dice: 0.8891  decode.d6.loss_cls: 1.2192  decode.d6.loss_mask: 0.5924  decode.d6.loss_dice: 0.8882  decode.d7.loss_cls: 1.2276  decode.d7.loss_mask: 0.6116  decode.d7.loss_dice: 0.8915  decode.d8.loss_cls: 1.2566  decode.d8.loss_mask: 0.6056  decode.d8.loss_dice: 0.8840
2023/05/24 00:45:56 - mmengine - INFO - Iter(train) [ 52800/160000]  lr: 6.9738e-06  eta: 12:44:42  time: 0.4382  data_time: 0.0101  memory: 4897  grad_norm: 98.8692  loss: 41.3654  decode.loss_cls: 1.6469  decode.loss_mask: 0.7669  decode.loss_dice: 1.4511  decode.d0.loss_cls: 3.2079  decode.d0.loss_mask: 0.7977  decode.d0.loss_dice: 1.7417  decode.d1.loss_cls: 1.8140  decode.d1.loss_mask: 0.7931  decode.d1.loss_dice: 1.5798  decode.d2.loss_cls: 1.7796  decode.d2.loss_mask: 0.7906  decode.d2.loss_dice: 1.5042  decode.d3.loss_cls: 1.7338  decode.d3.loss_mask: 0.7728  decode.d3.loss_dice: 1.4703  decode.d4.loss_cls: 1.6633  decode.d4.loss_mask: 0.7896  decode.d4.loss_dice: 1.4867  decode.d5.loss_cls: 1.6792  decode.d5.loss_mask: 0.7911  decode.d5.loss_dice: 1.4558  decode.d6.loss_cls: 1.6538  decode.d6.loss_mask: 0.7733  decode.d6.loss_dice: 1.4446  decode.d7.loss_cls: 1.6374  decode.d7.loss_mask: 0.7870  decode.d7.loss_dice: 1.4822  decode.d8.loss_cls: 1.6458  decode.d8.loss_mask: 0.7610  decode.d8.loss_dice: 1.4641
2023/05/24 00:46:17 - mmengine - INFO - Iter(train) [ 52850/160000]  lr: 6.9709e-06  eta: 12:44:20  time: 0.4080  data_time: 0.0101  memory: 4890  grad_norm: 91.2300  loss: 30.6523  decode.loss_cls: 1.0855  decode.loss_mask: 0.8087  decode.loss_dice: 0.8494  decode.d0.loss_cls: 3.0442  decode.d0.loss_mask: 0.9079  decode.d0.loss_dice: 1.0443  decode.d1.loss_cls: 1.1993  decode.d1.loss_mask: 0.9094  decode.d1.loss_dice: 0.9926  decode.d2.loss_cls: 1.2271  decode.d2.loss_mask: 0.8246  decode.d2.loss_dice: 0.8963  decode.d3.loss_cls: 1.2072  decode.d3.loss_mask: 0.7926  decode.d3.loss_dice: 0.8861  decode.d4.loss_cls: 1.1633  decode.d4.loss_mask: 0.8255  decode.d4.loss_dice: 0.8835  decode.d5.loss_cls: 1.1556  decode.d5.loss_mask: 0.8182  decode.d5.loss_dice: 0.8697  decode.d6.loss_cls: 1.1236  decode.d6.loss_mask: 0.8044  decode.d6.loss_dice: 0.8383  decode.d7.loss_cls: 1.1073  decode.d7.loss_mask: 0.7993  decode.d7.loss_dice: 0.8515  decode.d8.loss_cls: 1.0857  decode.d8.loss_mask: 0.8021  decode.d8.loss_dice: 0.8492
2023/05/24 00:46:39 - mmengine - INFO - Iter(train) [ 52900/160000]  lr: 6.9679e-06  eta: 12:43:59  time: 0.4645  data_time: 0.0099  memory: 4904  grad_norm: 209.3470  loss: 50.6269  decode.loss_cls: 1.5337  decode.loss_mask: 1.1128  decode.loss_dice: 2.0634  decode.d0.loss_cls: 3.6599  decode.d0.loss_mask: 1.2296  decode.d0.loss_dice: 2.4288  decode.d1.loss_cls: 1.6767  decode.d1.loss_mask: 1.1060  decode.d1.loss_dice: 2.2233  decode.d2.loss_cls: 1.6782  decode.d2.loss_mask: 1.1262  decode.d2.loss_dice: 2.1315  decode.d3.loss_cls: 1.6125  decode.d3.loss_mask: 1.1212  decode.d3.loss_dice: 2.0958  decode.d4.loss_cls: 1.5387  decode.d4.loss_mask: 1.1266  decode.d4.loss_dice: 2.1467  decode.d5.loss_cls: 1.4897  decode.d5.loss_mask: 1.1603  decode.d5.loss_dice: 2.1301  decode.d6.loss_cls: 1.5002  decode.d6.loss_mask: 1.1409  decode.d6.loss_dice: 2.0959  decode.d7.loss_cls: 1.5073  decode.d7.loss_mask: 1.1497  decode.d7.loss_dice: 2.1132  decode.d8.loss_cls: 1.5076  decode.d8.loss_mask: 1.1347  decode.d8.loss_dice: 2.0859
2023/05/24 00:47:00 - mmengine - INFO - Iter(train) [ 52950/160000]  lr: 6.9650e-06  eta: 12:43:38  time: 0.4088  data_time: 0.0100  memory: 4811  grad_norm: 109.3146  loss: 39.6771  decode.loss_cls: 1.4596  decode.loss_mask: 0.9119  decode.loss_dice: 1.3060  decode.d0.loss_cls: 3.4336  decode.d0.loss_mask: 0.9569  decode.d0.loss_dice: 1.6429  decode.d1.loss_cls: 1.5212  decode.d1.loss_mask: 0.9153  decode.d1.loss_dice: 1.5112  decode.d2.loss_cls: 1.4677  decode.d2.loss_mask: 0.9264  decode.d2.loss_dice: 1.4207  decode.d3.loss_cls: 1.4664  decode.d3.loss_mask: 0.8928  decode.d3.loss_dice: 1.3839  decode.d4.loss_cls: 1.4585  decode.d4.loss_mask: 0.9099  decode.d4.loss_dice: 1.3698  decode.d5.loss_cls: 1.4453  decode.d5.loss_mask: 0.8781  decode.d5.loss_dice: 1.3439  decode.d6.loss_cls: 1.4729  decode.d6.loss_mask: 0.8947  decode.d6.loss_dice: 1.3005  decode.d7.loss_cls: 1.4332  decode.d7.loss_mask: 0.9071  decode.d7.loss_dice: 1.3515  decode.d8.loss_cls: 1.4376  decode.d8.loss_mask: 0.9197  decode.d8.loss_dice: 1.3376
2023/05/24 00:47:21 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 00:47:21 - mmengine - INFO - Iter(train) [ 53000/160000]  lr: 6.9621e-06  eta: 12:43:15  time: 0.4133  data_time: 0.0105  memory: 4864  grad_norm: 91.5201  loss: 37.8403  decode.loss_cls: 1.2728  decode.loss_mask: 0.8481  decode.loss_dice: 1.3618  decode.d0.loss_cls: 3.1329  decode.d0.loss_mask: 0.9578  decode.d0.loss_dice: 1.6068  decode.d1.loss_cls: 1.4152  decode.d1.loss_mask: 0.9278  decode.d1.loss_dice: 1.4602  decode.d2.loss_cls: 1.2826  decode.d2.loss_mask: 0.9085  decode.d2.loss_dice: 1.4222  decode.d3.loss_cls: 1.2679  decode.d3.loss_mask: 0.8750  decode.d3.loss_dice: 1.3893  decode.d4.loss_cls: 1.3341  decode.d4.loss_mask: 0.8539  decode.d4.loss_dice: 1.4073  decode.d5.loss_cls: 1.2533  decode.d5.loss_mask: 0.8877  decode.d5.loss_dice: 1.4186  decode.d6.loss_cls: 1.2971  decode.d6.loss_mask: 0.8672  decode.d6.loss_dice: 1.3798  decode.d7.loss_cls: 1.2623  decode.d7.loss_mask: 0.8562  decode.d7.loss_dice: 1.4149  decode.d8.loss_cls: 1.2498  decode.d8.loss_mask: 0.8494  decode.d8.loss_dice: 1.3800
2023/05/24 00:47:21 - mmengine - INFO - Saving checkpoint at 53000 iterations
2023/05/24 00:47:47 - mmengine - INFO - Iter(train) [ 53050/160000]  lr: 6.9592e-06  eta: 12:43:03  time: 0.4091  data_time: 0.0101  memory: 4935  grad_norm: 98.7217  loss: 40.8337  decode.loss_cls: 1.4245  decode.loss_mask: 0.9009  decode.loss_dice: 1.4861  decode.d0.loss_cls: 3.2037  decode.d0.loss_mask: 0.9889  decode.d0.loss_dice: 1.7270  decode.d1.loss_cls: 1.5681  decode.d1.loss_mask: 0.9791  decode.d1.loss_dice: 1.6512  decode.d2.loss_cls: 1.5010  decode.d2.loss_mask: 0.8546  decode.d2.loss_dice: 1.5287  decode.d3.loss_cls: 1.4406  decode.d3.loss_mask: 0.8498  decode.d3.loss_dice: 1.5250  decode.d4.loss_cls: 1.3957  decode.d4.loss_mask: 0.8645  decode.d4.loss_dice: 1.5038  decode.d5.loss_cls: 1.4315  decode.d5.loss_mask: 0.8639  decode.d5.loss_dice: 1.5154  decode.d6.loss_cls: 1.4391  decode.d6.loss_mask: 0.8896  decode.d6.loss_dice: 1.5363  decode.d7.loss_cls: 1.4729  decode.d7.loss_mask: 0.8892  decode.d7.loss_dice: 1.5208  decode.d8.loss_cls: 1.4402  decode.d8.loss_mask: 0.8916  decode.d8.loss_dice: 1.5498
2023/05/24 00:48:09 - mmengine - INFO - Iter(train) [ 53100/160000]  lr: 6.9562e-06  eta: 12:42:43  time: 0.4344  data_time: 0.0100  memory: 4835  grad_norm: 90.0737  loss: 37.5831  decode.loss_cls: 1.2311  decode.loss_mask: 0.8779  decode.loss_dice: 1.3035  decode.d0.loss_cls: 3.2708  decode.d0.loss_mask: 0.9416  decode.d0.loss_dice: 1.6405  decode.d1.loss_cls: 1.3870  decode.d1.loss_mask: 0.9270  decode.d1.loss_dice: 1.4606  decode.d2.loss_cls: 1.3312  decode.d2.loss_mask: 0.9052  decode.d2.loss_dice: 1.4191  decode.d3.loss_cls: 1.3207  decode.d3.loss_mask: 0.8425  decode.d3.loss_dice: 1.3222  decode.d4.loss_cls: 1.3165  decode.d4.loss_mask: 0.8383  decode.d4.loss_dice: 1.3376  decode.d5.loss_cls: 1.2909  decode.d5.loss_mask: 0.8445  decode.d5.loss_dice: 1.3403  decode.d6.loss_cls: 1.2980  decode.d6.loss_mask: 0.8629  decode.d6.loss_dice: 1.3299  decode.d7.loss_cls: 1.2891  decode.d7.loss_mask: 0.8692  decode.d7.loss_dice: 1.3043  decode.d8.loss_cls: 1.2621  decode.d8.loss_mask: 0.8675  decode.d8.loss_dice: 1.3511
2023/05/24 00:48:29 - mmengine - INFO - Iter(train) [ 53150/160000]  lr: 6.9533e-06  eta: 12:42:20  time: 0.4078  data_time: 0.0099  memory: 4844  grad_norm: 91.6841  loss: 33.0031  decode.loss_cls: 1.3272  decode.loss_mask: 0.6299  decode.loss_dice: 1.1152  decode.d0.loss_cls: 3.1500  decode.d0.loss_mask: 0.6818  decode.d0.loss_dice: 1.2765  decode.d1.loss_cls: 1.4036  decode.d1.loss_mask: 0.6773  decode.d1.loss_dice: 1.1787  decode.d2.loss_cls: 1.3357  decode.d2.loss_mask: 0.6368  decode.d2.loss_dice: 1.1464  decode.d3.loss_cls: 1.3331  decode.d3.loss_mask: 0.6129  decode.d3.loss_dice: 1.1320  decode.d4.loss_cls: 1.3411  decode.d4.loss_mask: 0.6291  decode.d4.loss_dice: 1.1495  decode.d5.loss_cls: 1.3183  decode.d5.loss_mask: 0.6447  decode.d5.loss_dice: 1.1390  decode.d6.loss_cls: 1.2932  decode.d6.loss_mask: 0.6245  decode.d6.loss_dice: 1.1388  decode.d7.loss_cls: 1.2500  decode.d7.loss_mask: 0.6547  decode.d7.loss_dice: 1.1393  decode.d8.loss_cls: 1.2690  decode.d8.loss_mask: 0.6400  decode.d8.loss_dice: 1.1346
2023/05/24 00:48:50 - mmengine - INFO - Iter(train) [ 53200/160000]  lr: 6.9504e-06  eta: 12:41:57  time: 0.4131  data_time: 0.0103  memory: 4855  grad_norm: 87.1289  loss: 41.0172  decode.loss_cls: 1.4326  decode.loss_mask: 0.8343  decode.loss_dice: 1.5870  decode.d0.loss_cls: 3.1933  decode.d0.loss_mask: 0.8577  decode.d0.loss_dice: 1.8086  decode.d1.loss_cls: 1.5043  decode.d1.loss_mask: 0.8768  decode.d1.loss_dice: 1.6758  decode.d2.loss_cls: 1.4419  decode.d2.loss_mask: 0.8737  decode.d2.loss_dice: 1.6653  decode.d3.loss_cls: 1.4178  decode.d3.loss_mask: 0.8278  decode.d3.loss_dice: 1.6347  decode.d4.loss_cls: 1.3886  decode.d4.loss_mask: 0.8540  decode.d4.loss_dice: 1.6201  decode.d5.loss_cls: 1.4025  decode.d5.loss_mask: 0.8533  decode.d5.loss_dice: 1.6238  decode.d6.loss_cls: 1.4585  decode.d6.loss_mask: 0.8556  decode.d6.loss_dice: 1.6022  decode.d7.loss_cls: 1.4366  decode.d7.loss_mask: 0.8337  decode.d7.loss_dice: 1.5807  decode.d8.loss_cls: 1.4526  decode.d8.loss_mask: 0.8311  decode.d8.loss_dice: 1.5922
2023/05/24 00:49:11 - mmengine - INFO - Iter(train) [ 53250/160000]  lr: 6.9475e-06  eta: 12:41:34  time: 0.4149  data_time: 0.0099  memory: 4848  grad_norm: 105.9662  loss: 49.2701  decode.loss_cls: 1.5739  decode.loss_mask: 0.9698  decode.loss_dice: 2.1368  decode.d0.loss_cls: 3.5055  decode.d0.loss_mask: 0.9557  decode.d0.loss_dice: 2.3462  decode.d1.loss_cls: 1.7741  decode.d1.loss_mask: 0.9107  decode.d1.loss_dice: 2.2269  decode.d2.loss_cls: 1.5566  decode.d2.loss_mask: 0.9783  decode.d2.loss_dice: 2.2141  decode.d3.loss_cls: 1.6110  decode.d3.loss_mask: 0.9579  decode.d3.loss_dice: 2.1975  decode.d4.loss_cls: 1.6106  decode.d4.loss_mask: 0.9309  decode.d4.loss_dice: 2.1611  decode.d5.loss_cls: 1.6215  decode.d5.loss_mask: 0.9220  decode.d5.loss_dice: 2.1978  decode.d6.loss_cls: 1.5758  decode.d6.loss_mask: 0.9316  decode.d6.loss_dice: 2.1599  decode.d7.loss_cls: 1.5761  decode.d7.loss_mask: 0.9337  decode.d7.loss_dice: 2.1068  decode.d8.loss_cls: 1.5328  decode.d8.loss_mask: 0.9881  decode.d8.loss_dice: 2.1065
2023/05/24 00:49:33 - mmengine - INFO - Iter(train) [ 53300/160000]  lr: 6.9445e-06  eta: 12:41:13  time: 0.4554  data_time: 0.0105  memory: 4836  grad_norm: 91.5768  loss: 37.0451  decode.loss_cls: 1.3360  decode.loss_mask: 0.8224  decode.loss_dice: 1.2792  decode.d0.loss_cls: 3.1699  decode.d0.loss_mask: 0.8359  decode.d0.loss_dice: 1.4790  decode.d1.loss_cls: 1.5342  decode.d1.loss_mask: 0.8632  decode.d1.loss_dice: 1.4009  decode.d2.loss_cls: 1.4818  decode.d2.loss_mask: 0.7867  decode.d2.loss_dice: 1.3236  decode.d3.loss_cls: 1.3855  decode.d3.loss_mask: 0.7849  decode.d3.loss_dice: 1.3341  decode.d4.loss_cls: 1.3495  decode.d4.loss_mask: 0.7965  decode.d4.loss_dice: 1.2838  decode.d5.loss_cls: 1.3484  decode.d5.loss_mask: 0.7950  decode.d5.loss_dice: 1.3197  decode.d6.loss_cls: 1.3431  decode.d6.loss_mask: 0.8166  decode.d6.loss_dice: 1.2776  decode.d7.loss_cls: 1.3586  decode.d7.loss_mask: 0.7941  decode.d7.loss_dice: 1.2722  decode.d8.loss_cls: 1.3892  decode.d8.loss_mask: 0.8075  decode.d8.loss_dice: 1.2759
2023/05/24 00:49:54 - mmengine - INFO - Iter(train) [ 53350/160000]  lr: 6.9416e-06  eta: 12:40:51  time: 0.4256  data_time: 0.0107  memory: 4946  grad_norm: 169.8903  loss: 28.8213  decode.loss_cls: 0.9421  decode.loss_mask: 0.6984  decode.loss_dice: 0.9771  decode.d0.loss_cls: 2.7665  decode.d0.loss_mask: 0.7133  decode.d0.loss_dice: 1.1620  decode.d1.loss_cls: 1.0786  decode.d1.loss_mask: 0.6596  decode.d1.loss_dice: 1.0691  decode.d2.loss_cls: 1.0315  decode.d2.loss_mask: 0.6741  decode.d2.loss_dice: 1.0057  decode.d3.loss_cls: 1.0472  decode.d3.loss_mask: 0.7073  decode.d3.loss_dice: 1.0578  decode.d4.loss_cls: 0.9673  decode.d4.loss_mask: 0.6956  decode.d4.loss_dice: 0.9902  decode.d5.loss_cls: 0.9562  decode.d5.loss_mask: 0.7050  decode.d5.loss_dice: 0.9869  decode.d6.loss_cls: 0.9565  decode.d6.loss_mask: 0.7285  decode.d6.loss_dice: 0.9797  decode.d7.loss_cls: 0.9512  decode.d7.loss_mask: 0.7060  decode.d7.loss_dice: 0.9781  decode.d8.loss_cls: 0.9448  decode.d8.loss_mask: 0.7105  decode.d8.loss_dice: 0.9746
2023/05/24 00:50:15 - mmengine - INFO - Iter(train) [ 53400/160000]  lr: 6.9387e-06  eta: 12:40:29  time: 0.4089  data_time: 0.0100  memory: 4921  grad_norm: 89.3244  loss: 39.4496  decode.loss_cls: 1.5891  decode.loss_mask: 0.7693  decode.loss_dice: 1.3545  decode.d0.loss_cls: 3.3764  decode.d0.loss_mask: 0.8514  decode.d0.loss_dice: 1.5878  decode.d1.loss_cls: 1.6048  decode.d1.loss_mask: 0.8281  decode.d1.loss_dice: 1.4700  decode.d2.loss_cls: 1.6482  decode.d2.loss_mask: 0.7720  decode.d2.loss_dice: 1.4012  decode.d3.loss_cls: 1.6071  decode.d3.loss_mask: 0.7463  decode.d3.loss_dice: 1.3655  decode.d4.loss_cls: 1.5895  decode.d4.loss_mask: 0.7723  decode.d4.loss_dice: 1.3443  decode.d5.loss_cls: 1.6052  decode.d5.loss_mask: 0.7713  decode.d5.loss_dice: 1.3871  decode.d6.loss_cls: 1.5616  decode.d6.loss_mask: 0.7529  decode.d6.loss_dice: 1.3620  decode.d7.loss_cls: 1.5145  decode.d7.loss_mask: 0.7744  decode.d7.loss_dice: 1.3465  decode.d8.loss_cls: 1.5391  decode.d8.loss_mask: 0.7827  decode.d8.loss_dice: 1.3742
2023/05/24 00:50:35 - mmengine - INFO - Iter(train) [ 53450/160000]  lr: 6.9357e-06  eta: 12:40:06  time: 0.4107  data_time: 0.0101  memory: 4845  grad_norm: 126.0561  loss: 40.6320  decode.loss_cls: 1.6832  decode.loss_mask: 0.6916  decode.loss_dice: 1.4200  decode.d0.loss_cls: 3.4918  decode.d0.loss_mask: 0.8379  decode.d0.loss_dice: 1.7103  decode.d1.loss_cls: 1.6761  decode.d1.loss_mask: 0.7852  decode.d1.loss_dice: 1.6369  decode.d2.loss_cls: 1.7224  decode.d2.loss_mask: 0.7139  decode.d2.loss_dice: 1.5152  decode.d3.loss_cls: 1.6752  decode.d3.loss_mask: 0.6911  decode.d3.loss_dice: 1.4357  decode.d4.loss_cls: 1.6714  decode.d4.loss_mask: 0.7028  decode.d4.loss_dice: 1.4319  decode.d5.loss_cls: 1.6287  decode.d5.loss_mask: 0.7107  decode.d5.loss_dice: 1.4069  decode.d6.loss_cls: 1.6903  decode.d6.loss_mask: 0.7132  decode.d6.loss_dice: 1.4301  decode.d7.loss_cls: 1.6276  decode.d7.loss_mask: 0.6931  decode.d7.loss_dice: 1.4254  decode.d8.loss_cls: 1.6331  decode.d8.loss_mask: 0.7170  decode.d8.loss_dice: 1.4632
2023/05/24 00:50:56 - mmengine - INFO - Iter(train) [ 53500/160000]  lr: 6.9328e-06  eta: 12:39:44  time: 0.4296  data_time: 0.0102  memory: 4906  grad_norm: 92.1784  loss: 31.6446  decode.loss_cls: 1.0555  decode.loss_mask: 0.8102  decode.loss_dice: 1.0690  decode.d0.loss_cls: 3.0600  decode.d0.loss_mask: 0.8278  decode.d0.loss_dice: 1.2525  decode.d1.loss_cls: 1.2485  decode.d1.loss_mask: 0.7884  decode.d1.loss_dice: 1.1132  decode.d2.loss_cls: 1.1570  decode.d2.loss_mask: 0.7799  decode.d2.loss_dice: 1.0491  decode.d3.loss_cls: 1.1260  decode.d3.loss_mask: 0.7793  decode.d3.loss_dice: 1.0198  decode.d4.loss_cls: 1.0591  decode.d4.loss_mask: 0.7875  decode.d4.loss_dice: 1.0365  decode.d5.loss_cls: 1.0808  decode.d5.loss_mask: 0.7789  decode.d5.loss_dice: 1.0374  decode.d6.loss_cls: 1.0938  decode.d6.loss_mask: 0.7926  decode.d6.loss_dice: 1.0529  decode.d7.loss_cls: 1.0312  decode.d7.loss_mask: 0.7963  decode.d7.loss_dice: 1.0737  decode.d8.loss_cls: 1.0150  decode.d8.loss_mask: 0.7940  decode.d8.loss_dice: 1.0788
2023/05/24 00:51:17 - mmengine - INFO - Iter(train) [ 53550/160000]  lr: 6.9299e-06  eta: 12:39:21  time: 0.4154  data_time: 0.0104  memory: 4991  grad_norm: 92.6331  loss: 45.5394  decode.loss_cls: 1.5081  decode.loss_mask: 0.8982  decode.loss_dice: 1.7987  decode.d0.loss_cls: 3.7152  decode.d0.loss_mask: 1.0005  decode.d0.loss_dice: 2.0285  decode.d1.loss_cls: 1.6092  decode.d1.loss_mask: 0.9969  decode.d1.loss_dice: 1.8904  decode.d2.loss_cls: 1.5679  decode.d2.loss_mask: 0.9818  decode.d2.loss_dice: 1.8920  decode.d3.loss_cls: 1.5660  decode.d3.loss_mask: 0.9680  decode.d3.loss_dice: 1.8931  decode.d4.loss_cls: 1.4612  decode.d4.loss_mask: 0.9619  decode.d4.loss_dice: 1.8463  decode.d5.loss_cls: 1.5259  decode.d5.loss_mask: 0.9526  decode.d5.loss_dice: 1.8649  decode.d6.loss_cls: 1.4978  decode.d6.loss_mask: 0.9239  decode.d6.loss_dice: 1.8060  decode.d7.loss_cls: 1.5110  decode.d7.loss_mask: 0.9135  decode.d7.loss_dice: 1.7999  decode.d8.loss_cls: 1.4714  decode.d8.loss_mask: 0.9071  decode.d8.loss_dice: 1.7814
2023/05/24 00:51:40 - mmengine - INFO - Iter(train) [ 53600/160000]  lr: 6.9269e-06  eta: 12:39:02  time: 0.4733  data_time: 0.0105  memory: 4800  grad_norm: 88.0369  loss: 38.6230  decode.loss_cls: 1.4870  decode.loss_mask: 0.7848  decode.loss_dice: 1.2701  decode.d0.loss_cls: 3.3469  decode.d0.loss_mask: 0.7591  decode.d0.loss_dice: 1.5473  decode.d1.loss_cls: 1.6677  decode.d1.loss_mask: 0.7874  decode.d1.loss_dice: 1.3955  decode.d2.loss_cls: 1.6231  decode.d2.loss_mask: 0.7982  decode.d2.loss_dice: 1.3821  decode.d3.loss_cls: 1.5494  decode.d3.loss_mask: 0.8001  decode.d3.loss_dice: 1.3704  decode.d4.loss_cls: 1.5424  decode.d4.loss_mask: 0.7806  decode.d4.loss_dice: 1.3528  decode.d5.loss_cls: 1.5139  decode.d5.loss_mask: 0.7827  decode.d5.loss_dice: 1.3279  decode.d6.loss_cls: 1.5313  decode.d6.loss_mask: 0.8015  decode.d6.loss_dice: 1.2946  decode.d7.loss_cls: 1.4761  decode.d7.loss_mask: 0.8002  decode.d7.loss_dice: 1.2621  decode.d8.loss_cls: 1.4974  decode.d8.loss_mask: 0.7794  decode.d8.loss_dice: 1.3111
2023/05/24 00:52:00 - mmengine - INFO - Iter(train) [ 53650/160000]  lr: 6.9240e-06  eta: 12:38:40  time: 0.4127  data_time: 0.0099  memory: 4879  grad_norm: 95.5972  loss: 34.4108  decode.loss_cls: 1.4255  decode.loss_mask: 0.6694  decode.loss_dice: 1.1302  decode.d0.loss_cls: 3.2386  decode.d0.loss_mask: 0.7338  decode.d0.loss_dice: 1.2704  decode.d1.loss_cls: 1.6215  decode.d1.loss_mask: 0.7143  decode.d1.loss_dice: 1.2137  decode.d2.loss_cls: 1.5121  decode.d2.loss_mask: 0.7002  decode.d2.loss_dice: 1.1687  decode.d3.loss_cls: 1.4508  decode.d3.loss_mask: 0.6476  decode.d3.loss_dice: 1.0899  decode.d4.loss_cls: 1.4033  decode.d4.loss_mask: 0.6585  decode.d4.loss_dice: 1.1174  decode.d5.loss_cls: 1.4378  decode.d5.loss_mask: 0.6500  decode.d5.loss_dice: 1.0958  decode.d6.loss_cls: 1.4106  decode.d6.loss_mask: 0.6364  decode.d6.loss_dice: 1.1104  decode.d7.loss_cls: 1.3734  decode.d7.loss_mask: 0.6600  decode.d7.loss_dice: 1.0629  decode.d8.loss_cls: 1.4409  decode.d8.loss_mask: 0.6618  decode.d8.loss_dice: 1.1047
2023/05/24 00:52:22 - mmengine - INFO - Iter(train) [ 53700/160000]  lr: 6.9211e-06  eta: 12:38:18  time: 0.4245  data_time: 0.0099  memory: 4816  grad_norm: 104.4449  loss: 38.4602  decode.loss_cls: 1.1613  decode.loss_mask: 0.9433  decode.loss_dice: 1.4412  decode.d0.loss_cls: 3.2268  decode.d0.loss_mask: 0.9089  decode.d0.loss_dice: 1.6034  decode.d1.loss_cls: 1.4213  decode.d1.loss_mask: 0.8848  decode.d1.loss_dice: 1.5460  decode.d2.loss_cls: 1.3246  decode.d2.loss_mask: 0.9263  decode.d2.loss_dice: 1.5016  decode.d3.loss_cls: 1.2800  decode.d3.loss_mask: 0.9516  decode.d3.loss_dice: 1.4626  decode.d4.loss_cls: 1.2621  decode.d4.loss_mask: 0.8813  decode.d4.loss_dice: 1.4405  decode.d5.loss_cls: 1.1915  decode.d5.loss_mask: 0.8884  decode.d5.loss_dice: 1.4852  decode.d6.loss_cls: 1.2636  decode.d6.loss_mask: 0.9277  decode.d6.loss_dice: 1.4510  decode.d7.loss_cls: 1.2273  decode.d7.loss_mask: 0.8999  decode.d7.loss_dice: 1.4217  decode.d8.loss_cls: 1.1442  decode.d8.loss_mask: 0.9289  decode.d8.loss_dice: 1.4635
2023/05/24 00:52:43 - mmengine - INFO - Iter(train) [ 53750/160000]  lr: 6.9182e-06  eta: 12:37:57  time: 0.4657  data_time: 0.0100  memory: 4847  grad_norm: 111.9935  loss: 39.5364  decode.loss_cls: 1.3576  decode.loss_mask: 0.8692  decode.loss_dice: 1.3936  decode.d0.loss_cls: 3.2896  decode.d0.loss_mask: 0.9414  decode.d0.loss_dice: 1.6103  decode.d1.loss_cls: 1.5470  decode.d1.loss_mask: 0.8985  decode.d1.loss_dice: 1.5156  decode.d2.loss_cls: 1.4907  decode.d2.loss_mask: 0.8975  decode.d2.loss_dice: 1.4245  decode.d3.loss_cls: 1.4383  decode.d3.loss_mask: 0.9031  decode.d3.loss_dice: 1.4566  decode.d4.loss_cls: 1.4268  decode.d4.loss_mask: 0.9042  decode.d4.loss_dice: 1.4496  decode.d5.loss_cls: 1.4143  decode.d5.loss_mask: 0.8840  decode.d5.loss_dice: 1.4116  decode.d6.loss_cls: 1.4437  decode.d6.loss_mask: 0.8920  decode.d6.loss_dice: 1.3973  decode.d7.loss_cls: 1.4215  decode.d7.loss_mask: 0.8648  decode.d7.loss_dice: 1.3934  decode.d8.loss_cls: 1.3849  decode.d8.loss_mask: 0.8594  decode.d8.loss_dice: 1.3551
2023/05/24 00:53:05 - mmengine - INFO - Iter(train) [ 53800/160000]  lr: 6.9152e-06  eta: 12:37:36  time: 0.4268  data_time: 0.0099  memory: 4802  grad_norm: 99.2317  loss: 38.0733  decode.loss_cls: 1.3392  decode.loss_mask: 0.9295  decode.loss_dice: 1.2577  decode.d0.loss_cls: 3.3889  decode.d0.loss_mask: 0.9204  decode.d0.loss_dice: 1.4014  decode.d1.loss_cls: 1.5110  decode.d1.loss_mask: 0.9029  decode.d1.loss_dice: 1.3413  decode.d2.loss_cls: 1.3993  decode.d2.loss_mask: 0.9281  decode.d2.loss_dice: 1.3226  decode.d3.loss_cls: 1.4385  decode.d3.loss_mask: 0.9533  decode.d3.loss_dice: 1.2877  decode.d4.loss_cls: 1.4071  decode.d4.loss_mask: 0.9506  decode.d4.loss_dice: 1.2835  decode.d5.loss_cls: 1.3470  decode.d5.loss_mask: 0.9494  decode.d5.loss_dice: 1.2942  decode.d6.loss_cls: 1.3284  decode.d6.loss_mask: 0.9417  decode.d6.loss_dice: 1.2471  decode.d7.loss_cls: 1.3110  decode.d7.loss_mask: 0.9308  decode.d7.loss_dice: 1.2566  decode.d8.loss_cls: 1.3123  decode.d8.loss_mask: 0.9475  decode.d8.loss_dice: 1.2444
2023/05/24 00:53:26 - mmengine - INFO - Iter(train) [ 53850/160000]  lr: 6.9123e-06  eta: 12:37:14  time: 0.4166  data_time: 0.0102  memory: 4929  grad_norm: 119.6705  loss: 38.7546  decode.loss_cls: 1.2124  decode.loss_mask: 0.8609  decode.loss_dice: 1.4391  decode.d0.loss_cls: 3.3824  decode.d0.loss_mask: 0.9101  decode.d0.loss_dice: 1.7362  decode.d1.loss_cls: 1.4358  decode.d1.loss_mask: 0.9223  decode.d1.loss_dice: 1.6540  decode.d2.loss_cls: 1.3400  decode.d2.loss_mask: 0.9439  decode.d2.loss_dice: 1.5451  decode.d3.loss_cls: 1.2400  decode.d3.loss_mask: 0.8780  decode.d3.loss_dice: 1.5118  decode.d4.loss_cls: 1.2346  decode.d4.loss_mask: 0.8543  decode.d4.loss_dice: 1.4747  decode.d5.loss_cls: 1.1939  decode.d5.loss_mask: 0.8679  decode.d5.loss_dice: 1.4962  decode.d6.loss_cls: 1.2505  decode.d6.loss_mask: 0.8525  decode.d6.loss_dice: 1.4392  decode.d7.loss_cls: 1.1803  decode.d7.loss_mask: 0.8561  decode.d7.loss_dice: 1.4895  decode.d8.loss_cls: 1.1763  decode.d8.loss_mask: 0.8864  decode.d8.loss_dice: 1.4901
2023/05/24 00:53:47 - mmengine - INFO - Iter(train) [ 53900/160000]  lr: 6.9094e-06  eta: 12:36:52  time: 0.4152  data_time: 0.0105  memory: 4836  grad_norm: 104.8298  loss: 25.2515  decode.loss_cls: 0.9947  decode.loss_mask: 0.4658  decode.loss_dice: 0.7823  decode.d0.loss_cls: 2.9079  decode.d0.loss_mask: 0.5434  decode.d0.loss_dice: 0.9826  decode.d1.loss_cls: 1.1450  decode.d1.loss_mask: 0.5136  decode.d1.loss_dice: 0.9071  decode.d2.loss_cls: 1.0376  decode.d2.loss_mask: 0.4675  decode.d2.loss_dice: 0.8464  decode.d3.loss_cls: 0.9967  decode.d3.loss_mask: 0.4792  decode.d3.loss_dice: 0.8017  decode.d4.loss_cls: 0.9792  decode.d4.loss_mask: 0.4834  decode.d4.loss_dice: 0.8590  decode.d5.loss_cls: 0.9376  decode.d5.loss_mask: 0.4784  decode.d5.loss_dice: 0.8467  decode.d6.loss_cls: 0.9753  decode.d6.loss_mask: 0.4776  decode.d6.loss_dice: 0.8182  decode.d7.loss_cls: 0.9849  decode.d7.loss_mask: 0.4740  decode.d7.loss_dice: 0.8034  decode.d8.loss_cls: 0.9573  decode.d8.loss_mask: 0.4792  decode.d8.loss_dice: 0.8259
2023/05/24 00:54:09 - mmengine - INFO - Iter(train) [ 53950/160000]  lr: 6.9064e-06  eta: 12:36:31  time: 0.4227  data_time: 0.0101  memory: 4855  grad_norm: 100.5370  loss: 30.0451  decode.loss_cls: 0.9731  decode.loss_mask: 0.6939  decode.loss_dice: 1.0351  decode.d0.loss_cls: 3.0138  decode.d0.loss_mask: 0.7637  decode.d0.loss_dice: 1.3061  decode.d1.loss_cls: 1.1082  decode.d1.loss_mask: 0.7125  decode.d1.loss_dice: 1.1349  decode.d2.loss_cls: 0.9933  decode.d2.loss_mask: 0.7069  decode.d2.loss_dice: 1.1490  decode.d3.loss_cls: 0.9815  decode.d3.loss_mask: 0.7197  decode.d3.loss_dice: 1.0791  decode.d4.loss_cls: 0.9850  decode.d4.loss_mask: 0.7204  decode.d4.loss_dice: 1.0771  decode.d5.loss_cls: 0.9544  decode.d5.loss_mask: 0.7416  decode.d5.loss_dice: 1.0847  decode.d6.loss_cls: 0.9416  decode.d6.loss_mask: 0.6847  decode.d6.loss_dice: 1.0744  decode.d7.loss_cls: 0.9728  decode.d7.loss_mask: 0.6940  decode.d7.loss_dice: 1.0494  decode.d8.loss_cls: 0.9721  decode.d8.loss_mask: 0.6785  decode.d8.loss_dice: 1.0437
2023/05/24 00:54:30 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 00:54:30 - mmengine - INFO - Iter(train) [ 54000/160000]  lr: 6.9035e-06  eta: 12:36:08  time: 0.4089  data_time: 0.0099  memory: 4900  grad_norm: 107.9069  loss: 39.9572  decode.loss_cls: 1.4142  decode.loss_mask: 0.7487  decode.loss_dice: 1.5178  decode.d0.loss_cls: 3.5466  decode.d0.loss_mask: 0.7659  decode.d0.loss_dice: 1.6878  decode.d1.loss_cls: 1.6310  decode.d1.loss_mask: 0.8378  decode.d1.loss_dice: 1.6200  decode.d2.loss_cls: 1.4586  decode.d2.loss_mask: 0.7651  decode.d2.loss_dice: 1.5792  decode.d3.loss_cls: 1.5263  decode.d3.loss_mask: 0.7552  decode.d3.loss_dice: 1.5452  decode.d4.loss_cls: 1.4642  decode.d4.loss_mask: 0.7452  decode.d4.loss_dice: 1.5641  decode.d5.loss_cls: 1.4197  decode.d5.loss_mask: 0.7501  decode.d5.loss_dice: 1.5653  decode.d6.loss_cls: 1.4263  decode.d6.loss_mask: 0.7472  decode.d6.loss_dice: 1.4992  decode.d7.loss_cls: 1.4129  decode.d7.loss_mask: 0.7712  decode.d7.loss_dice: 1.5458  decode.d8.loss_cls: 1.3767  decode.d8.loss_mask: 0.7586  decode.d8.loss_dice: 1.5110
2023/05/24 00:54:30 - mmengine - INFO - Saving checkpoint at 54000 iterations
2023/05/24 00:54:55 - mmengine - INFO - Iter(train) [ 54050/160000]  lr: 6.9006e-06  eta: 12:35:55  time: 0.4191  data_time: 0.0100  memory: 4831  grad_norm: 112.7795  loss: 40.7756  decode.loss_cls: 1.3078  decode.loss_mask: 0.8956  decode.loss_dice: 1.6081  decode.d0.loss_cls: 3.2223  decode.d0.loss_mask: 0.8890  decode.d0.loss_dice: 1.8405  decode.d1.loss_cls: 1.5740  decode.d1.loss_mask: 0.8670  decode.d1.loss_dice: 1.7000  decode.d2.loss_cls: 1.4576  decode.d2.loss_mask: 0.8879  decode.d2.loss_dice: 1.6599  decode.d3.loss_cls: 1.2789  decode.d3.loss_mask: 0.8849  decode.d3.loss_dice: 1.6341  decode.d4.loss_cls: 1.3673  decode.d4.loss_mask: 0.8804  decode.d4.loss_dice: 1.6068  decode.d5.loss_cls: 1.2906  decode.d5.loss_mask: 0.8639  decode.d5.loss_dice: 1.6193  decode.d6.loss_cls: 1.3259  decode.d6.loss_mask: 0.8908  decode.d6.loss_dice: 1.6041  decode.d7.loss_cls: 1.2598  decode.d7.loss_mask: 0.9113  decode.d7.loss_dice: 1.6354  decode.d8.loss_cls: 1.2860  decode.d8.loss_mask: 0.9080  decode.d8.loss_dice: 1.6184
2023/05/24 00:55:16 - mmengine - INFO - Iter(train) [ 54100/160000]  lr: 6.8976e-06  eta: 12:35:33  time: 0.4147  data_time: 0.0102  memory: 4801  grad_norm: 91.9447  loss: 29.7800  decode.loss_cls: 0.9930  decode.loss_mask: 0.7858  decode.loss_dice: 0.9134  decode.d0.loss_cls: 2.8956  decode.d0.loss_mask: 0.8310  decode.d0.loss_dice: 1.0326  decode.d1.loss_cls: 1.1606  decode.d1.loss_mask: 0.8159  decode.d1.loss_dice: 1.0223  decode.d2.loss_cls: 1.1332  decode.d2.loss_mask: 0.7808  decode.d2.loss_dice: 0.9476  decode.d3.loss_cls: 1.0479  decode.d3.loss_mask: 0.7947  decode.d3.loss_dice: 0.9348  decode.d4.loss_cls: 1.0526  decode.d4.loss_mask: 0.7746  decode.d4.loss_dice: 0.9453  decode.d5.loss_cls: 1.0656  decode.d5.loss_mask: 0.7738  decode.d5.loss_dice: 0.9324  decode.d6.loss_cls: 1.0157  decode.d6.loss_mask: 0.7712  decode.d6.loss_dice: 0.9218  decode.d7.loss_cls: 0.9971  decode.d7.loss_mask: 0.7695  decode.d7.loss_dice: 0.9220  decode.d8.loss_cls: 1.0443  decode.d8.loss_mask: 0.7686  decode.d8.loss_dice: 0.9360
2023/05/24 00:55:37 - mmengine - INFO - Iter(train) [ 54150/160000]  lr: 6.8947e-06  eta: 12:35:09  time: 0.4040  data_time: 0.0100  memory: 4901  grad_norm: 98.9747  loss: 39.3974  decode.loss_cls: 1.5568  decode.loss_mask: 0.7955  decode.loss_dice: 1.3495  decode.d0.loss_cls: 3.3295  decode.d0.loss_mask: 0.8902  decode.d0.loss_dice: 1.6957  decode.d1.loss_cls: 1.6368  decode.d1.loss_mask: 0.8272  decode.d1.loss_dice: 1.4663  decode.d2.loss_cls: 1.6063  decode.d2.loss_mask: 0.7558  decode.d2.loss_dice: 1.4233  decode.d3.loss_cls: 1.5340  decode.d3.loss_mask: 0.7668  decode.d3.loss_dice: 1.3607  decode.d4.loss_cls: 1.5529  decode.d4.loss_mask: 0.7789  decode.d4.loss_dice: 1.3829  decode.d5.loss_cls: 1.5478  decode.d5.loss_mask: 0.7848  decode.d5.loss_dice: 1.3698  decode.d6.loss_cls: 1.5491  decode.d6.loss_mask: 0.7705  decode.d6.loss_dice: 1.3587  decode.d7.loss_cls: 1.5130  decode.d7.loss_mask: 0.7815  decode.d7.loss_dice: 1.3303  decode.d8.loss_cls: 1.5327  decode.d8.loss_mask: 0.7906  decode.d8.loss_dice: 1.3592
2023/05/24 00:55:57 - mmengine - INFO - Iter(train) [ 54200/160000]  lr: 6.8918e-06  eta: 12:34:47  time: 0.4144  data_time: 0.0102  memory: 4836  grad_norm: 143.4480  loss: 36.5484  decode.loss_cls: 1.3014  decode.loss_mask: 0.7914  decode.loss_dice: 1.3123  decode.d0.loss_cls: 3.1938  decode.d0.loss_mask: 0.8243  decode.d0.loss_dice: 1.4259  decode.d1.loss_cls: 1.4490  decode.d1.loss_mask: 0.7899  decode.d1.loss_dice: 1.3892  decode.d2.loss_cls: 1.5562  decode.d2.loss_mask: 0.7628  decode.d2.loss_dice: 1.3415  decode.d3.loss_cls: 1.4191  decode.d3.loss_mask: 0.7409  decode.d3.loss_dice: 1.2815  decode.d4.loss_cls: 1.3865  decode.d4.loss_mask: 0.7536  decode.d4.loss_dice: 1.3076  decode.d5.loss_cls: 1.3022  decode.d5.loss_mask: 0.7646  decode.d5.loss_dice: 1.3292  decode.d6.loss_cls: 1.3112  decode.d6.loss_mask: 0.7815  decode.d6.loss_dice: 1.2939  decode.d7.loss_cls: 1.2776  decode.d7.loss_mask: 0.7734  decode.d7.loss_dice: 1.3012  decode.d8.loss_cls: 1.3081  decode.d8.loss_mask: 0.7746  decode.d8.loss_dice: 1.3040
2023/05/24 00:56:18 - mmengine - INFO - Iter(train) [ 54250/160000]  lr: 6.8889e-06  eta: 12:34:24  time: 0.4191  data_time: 0.0106  memory: 4886  grad_norm: 96.4864  loss: 44.5601  decode.loss_cls: 1.5161  decode.loss_mask: 0.8122  decode.loss_dice: 1.7878  decode.d0.loss_cls: 3.7106  decode.d0.loss_mask: 0.9558  decode.d0.loss_dice: 2.1740  decode.d1.loss_cls: 1.6786  decode.d1.loss_mask: 0.8287  decode.d1.loss_dice: 1.9622  decode.d2.loss_cls: 1.5986  decode.d2.loss_mask: 0.8150  decode.d2.loss_dice: 1.8630  decode.d3.loss_cls: 1.5384  decode.d3.loss_mask: 0.8072  decode.d3.loss_dice: 1.8231  decode.d4.loss_cls: 1.4979  decode.d4.loss_mask: 0.8190  decode.d4.loss_dice: 1.8382  decode.d5.loss_cls: 1.4976  decode.d5.loss_mask: 0.8248  decode.d5.loss_dice: 1.7933  decode.d6.loss_cls: 1.4893  decode.d6.loss_mask: 0.8203  decode.d6.loss_dice: 1.7944  decode.d7.loss_cls: 1.5246  decode.d7.loss_mask: 0.8238  decode.d7.loss_dice: 1.8408  decode.d8.loss_cls: 1.5004  decode.d8.loss_mask: 0.8041  decode.d8.loss_dice: 1.8202
2023/05/24 00:56:40 - mmengine - INFO - Iter(train) [ 54300/160000]  lr: 6.8859e-06  eta: 12:34:03  time: 0.4162  data_time: 0.0100  memory: 4857  grad_norm: 100.9696  loss: 37.9426  decode.loss_cls: 1.3003  decode.loss_mask: 0.7817  decode.loss_dice: 1.3536  decode.d0.loss_cls: 3.3572  decode.d0.loss_mask: 0.8885  decode.d0.loss_dice: 1.6030  decode.d1.loss_cls: 1.5386  decode.d1.loss_mask: 0.8589  decode.d1.loss_dice: 1.5030  decode.d2.loss_cls: 1.3507  decode.d2.loss_mask: 0.8699  decode.d2.loss_dice: 1.4445  decode.d3.loss_cls: 1.3082  decode.d3.loss_mask: 0.8464  decode.d3.loss_dice: 1.3516  decode.d4.loss_cls: 1.3463  decode.d4.loss_mask: 0.8301  decode.d4.loss_dice: 1.3869  decode.d5.loss_cls: 1.2660  decode.d5.loss_mask: 0.8410  decode.d5.loss_dice: 1.4092  decode.d6.loss_cls: 1.3214  decode.d6.loss_mask: 0.8271  decode.d6.loss_dice: 1.3782  decode.d7.loss_cls: 1.2879  decode.d7.loss_mask: 0.8138  decode.d7.loss_dice: 1.3566  decode.d8.loss_cls: 1.3579  decode.d8.loss_mask: 0.8083  decode.d8.loss_dice: 1.3559
2023/05/24 00:57:01 - mmengine - INFO - Iter(train) [ 54350/160000]  lr: 6.8830e-06  eta: 12:33:42  time: 0.4157  data_time: 0.0102  memory: 4929  grad_norm: 95.8613  loss: 39.4951  decode.loss_cls: 1.4670  decode.loss_mask: 0.9038  decode.loss_dice: 1.2721  decode.d0.loss_cls: 3.4612  decode.d0.loss_mask: 1.0435  decode.d0.loss_dice: 1.6043  decode.d1.loss_cls: 1.5798  decode.d1.loss_mask: 0.9792  decode.d1.loss_dice: 1.3828  decode.d2.loss_cls: 1.5943  decode.d2.loss_mask: 0.9262  decode.d2.loss_dice: 1.3464  decode.d3.loss_cls: 1.4775  decode.d3.loss_mask: 0.9083  decode.d3.loss_dice: 1.2704  decode.d4.loss_cls: 1.5274  decode.d4.loss_mask: 0.9291  decode.d4.loss_dice: 1.2710  decode.d5.loss_cls: 1.4145  decode.d5.loss_mask: 0.9414  decode.d5.loss_dice: 1.2654  decode.d6.loss_cls: 1.4766  decode.d6.loss_mask: 0.9162  decode.d6.loss_dice: 1.2920  decode.d7.loss_cls: 1.4333  decode.d7.loss_mask: 0.9138  decode.d7.loss_dice: 1.2782  decode.d8.loss_cls: 1.4280  decode.d8.loss_mask: 0.9114  decode.d8.loss_dice: 1.2801
2023/05/24 00:57:22 - mmengine - INFO - Iter(train) [ 54400/160000]  lr: 6.8801e-06  eta: 12:33:20  time: 0.4105  data_time: 0.0101  memory: 4836  grad_norm: 105.5940  loss: 37.8211  decode.loss_cls: 1.3799  decode.loss_mask: 0.8185  decode.loss_dice: 1.2439  decode.d0.loss_cls: 3.5211  decode.d0.loss_mask: 0.9152  decode.d0.loss_dice: 1.4862  decode.d1.loss_cls: 1.5495  decode.d1.loss_mask: 0.8378  decode.d1.loss_dice: 1.3817  decode.d2.loss_cls: 1.5116  decode.d2.loss_mask: 0.8317  decode.d2.loss_dice: 1.3202  decode.d3.loss_cls: 1.4670  decode.d3.loss_mask: 0.8260  decode.d3.loss_dice: 1.2817  decode.d4.loss_cls: 1.4259  decode.d4.loss_mask: 0.8003  decode.d4.loss_dice: 1.2665  decode.d5.loss_cls: 1.4437  decode.d5.loss_mask: 0.7960  decode.d5.loss_dice: 1.2430  decode.d6.loss_cls: 1.4342  decode.d6.loss_mask: 0.7917  decode.d6.loss_dice: 1.2317  decode.d7.loss_cls: 1.4254  decode.d7.loss_mask: 0.8288  decode.d7.loss_dice: 1.2338  decode.d8.loss_cls: 1.4162  decode.d8.loss_mask: 0.8490  decode.d8.loss_dice: 1.2630
2023/05/24 00:57:43 - mmengine - INFO - Iter(train) [ 54450/160000]  lr: 6.8771e-06  eta: 12:32:57  time: 0.4116  data_time: 0.0098  memory: 4902  grad_norm: 90.9906  loss: 39.9856  decode.loss_cls: 1.4471  decode.loss_mask: 0.9013  decode.loss_dice: 1.3880  decode.d0.loss_cls: 3.1774  decode.d0.loss_mask: 1.0422  decode.d0.loss_dice: 1.5936  decode.d1.loss_cls: 1.6053  decode.d1.loss_mask: 0.9926  decode.d1.loss_dice: 1.5472  decode.d2.loss_cls: 1.5048  decode.d2.loss_mask: 0.9497  decode.d2.loss_dice: 1.4340  decode.d3.loss_cls: 1.4287  decode.d3.loss_mask: 0.8977  decode.d3.loss_dice: 1.4265  decode.d4.loss_cls: 1.4154  decode.d4.loss_mask: 0.9119  decode.d4.loss_dice: 1.4244  decode.d5.loss_cls: 1.4263  decode.d5.loss_mask: 0.8771  decode.d5.loss_dice: 1.4356  decode.d6.loss_cls: 1.4677  decode.d6.loss_mask: 0.8716  decode.d6.loss_dice: 1.3902  decode.d7.loss_cls: 1.4592  decode.d7.loss_mask: 0.8561  decode.d7.loss_dice: 1.4042  decode.d8.loss_cls: 1.4529  decode.d8.loss_mask: 0.8801  decode.d8.loss_dice: 1.3766
2023/05/24 00:58:04 - mmengine - INFO - Iter(train) [ 54500/160000]  lr: 6.8742e-06  eta: 12:32:34  time: 0.4095  data_time: 0.0102  memory: 4890  grad_norm: 93.5925  loss: 34.0549  decode.loss_cls: 1.1920  decode.loss_mask: 0.8345  decode.loss_dice: 1.0548  decode.d0.loss_cls: 3.3794  decode.d0.loss_mask: 0.9408  decode.d0.loss_dice: 1.3448  decode.d1.loss_cls: 1.2926  decode.d1.loss_mask: 0.9141  decode.d1.loss_dice: 1.1927  decode.d2.loss_cls: 1.2771  decode.d2.loss_mask: 0.8737  decode.d2.loss_dice: 1.1225  decode.d3.loss_cls: 1.2275  decode.d3.loss_mask: 0.8580  decode.d3.loss_dice: 1.1027  decode.d4.loss_cls: 1.2191  decode.d4.loss_mask: 0.8557  decode.d4.loss_dice: 1.1014  decode.d5.loss_cls: 1.2207  decode.d5.loss_mask: 0.8192  decode.d5.loss_dice: 1.1031  decode.d6.loss_cls: 1.1735  decode.d6.loss_mask: 0.8007  decode.d6.loss_dice: 1.0427  decode.d7.loss_cls: 1.1416  decode.d7.loss_mask: 0.8286  decode.d7.loss_dice: 1.0611  decode.d8.loss_cls: 1.1613  decode.d8.loss_mask: 0.8511  decode.d8.loss_dice: 1.0677
2023/05/24 00:58:24 - mmengine - INFO - Iter(train) [ 54550/160000]  lr: 6.8713e-06  eta: 12:32:11  time: 0.4182  data_time: 0.0104  memory: 4897  grad_norm: 114.9795  loss: 40.6075  decode.loss_cls: 1.2342  decode.loss_mask: 0.8809  decode.loss_dice: 1.5639  decode.d0.loss_cls: 3.3584  decode.d0.loss_mask: 0.9679  decode.d0.loss_dice: 1.7716  decode.d1.loss_cls: 1.4176  decode.d1.loss_mask: 0.9672  decode.d1.loss_dice: 1.6738  decode.d2.loss_cls: 1.3353  decode.d2.loss_mask: 0.9510  decode.d2.loss_dice: 1.6617  decode.d3.loss_cls: 1.2470  decode.d3.loss_mask: 0.9431  decode.d3.loss_dice: 1.6500  decode.d4.loss_cls: 1.3090  decode.d4.loss_mask: 0.9094  decode.d4.loss_dice: 1.6118  decode.d5.loss_cls: 1.3772  decode.d5.loss_mask: 0.9195  decode.d5.loss_dice: 1.5532  decode.d6.loss_cls: 1.2621  decode.d6.loss_mask: 0.9219  decode.d6.loss_dice: 1.5748  decode.d7.loss_cls: 1.2722  decode.d7.loss_mask: 0.9016  decode.d7.loss_dice: 1.6063  decode.d8.loss_cls: 1.2707  decode.d8.loss_mask: 0.9110  decode.d8.loss_dice: 1.5831
2023/05/24 00:58:45 - mmengine - INFO - Iter(train) [ 54600/160000]  lr: 6.8683e-06  eta: 12:31:49  time: 0.4138  data_time: 0.0099  memory: 4821  grad_norm: 88.9926  loss: 44.1804  decode.loss_cls: 1.5459  decode.loss_mask: 0.9732  decode.loss_dice: 1.5787  decode.d0.loss_cls: 3.4005  decode.d0.loss_mask: 0.9967  decode.d0.loss_dice: 1.8553  decode.d1.loss_cls: 1.6265  decode.d1.loss_mask: 1.0736  decode.d1.loss_dice: 1.8036  decode.d2.loss_cls: 1.5673  decode.d2.loss_mask: 1.0397  decode.d2.loss_dice: 1.7086  decode.d3.loss_cls: 1.5722  decode.d3.loss_mask: 1.0045  decode.d3.loss_dice: 1.6884  decode.d4.loss_cls: 1.5392  decode.d4.loss_mask: 1.0393  decode.d4.loss_dice: 1.6766  decode.d5.loss_cls: 1.5346  decode.d5.loss_mask: 1.0181  decode.d5.loss_dice: 1.6494  decode.d6.loss_cls: 1.5496  decode.d6.loss_mask: 0.9872  decode.d6.loss_dice: 1.5900  decode.d7.loss_cls: 1.5146  decode.d7.loss_mask: 0.9622  decode.d7.loss_dice: 1.6223  decode.d8.loss_cls: 1.5180  decode.d8.loss_mask: 0.9526  decode.d8.loss_dice: 1.5920
2023/05/24 00:59:06 - mmengine - INFO - Iter(train) [ 54650/160000]  lr: 6.8654e-06  eta: 12:31:27  time: 0.4187  data_time: 0.0099  memory: 4844  grad_norm: 93.7099  loss: 32.0159  decode.loss_cls: 0.9311  decode.loss_mask: 0.7827  decode.loss_dice: 1.2446  decode.d0.loss_cls: 2.8479  decode.d0.loss_mask: 0.7575  decode.d0.loss_dice: 1.3920  decode.d1.loss_cls: 1.1440  decode.d1.loss_mask: 0.7726  decode.d1.loss_dice: 1.2833  decode.d2.loss_cls: 1.0332  decode.d2.loss_mask: 0.7413  decode.d2.loss_dice: 1.2432  decode.d3.loss_cls: 1.0209  decode.d3.loss_mask: 0.7689  decode.d3.loss_dice: 1.2357  decode.d4.loss_cls: 0.9800  decode.d4.loss_mask: 0.8002  decode.d4.loss_dice: 1.2223  decode.d5.loss_cls: 0.9209  decode.d5.loss_mask: 0.7929  decode.d5.loss_dice: 1.2243  decode.d6.loss_cls: 0.9685  decode.d6.loss_mask: 0.7872  decode.d6.loss_dice: 1.1965  decode.d7.loss_cls: 0.9847  decode.d7.loss_mask: 0.7742  decode.d7.loss_dice: 1.2140  decode.d8.loss_cls: 0.9544  decode.d8.loss_mask: 0.7743  decode.d8.loss_dice: 1.2228
2023/05/24 00:59:27 - mmengine - INFO - Iter(train) [ 54700/160000]  lr: 6.8625e-06  eta: 12:31:05  time: 0.4207  data_time: 0.0100  memory: 4840  grad_norm: 99.2742  loss: 38.5991  decode.loss_cls: 1.6665  decode.loss_mask: 0.7511  decode.loss_dice: 1.2284  decode.d0.loss_cls: 3.2062  decode.d0.loss_mask: 0.9007  decode.d0.loss_dice: 1.4450  decode.d1.loss_cls: 1.6185  decode.d1.loss_mask: 0.8595  decode.d1.loss_dice: 1.3776  decode.d2.loss_cls: 1.6585  decode.d2.loss_mask: 0.8516  decode.d2.loss_dice: 1.3305  decode.d3.loss_cls: 1.6758  decode.d3.loss_mask: 0.8063  decode.d3.loss_dice: 1.2698  decode.d4.loss_cls: 1.5498  decode.d4.loss_mask: 0.7820  decode.d4.loss_dice: 1.2504  decode.d5.loss_cls: 1.5496  decode.d5.loss_mask: 0.7818  decode.d5.loss_dice: 1.3088  decode.d6.loss_cls: 1.5987  decode.d6.loss_mask: 0.7519  decode.d6.loss_dice: 1.2405  decode.d7.loss_cls: 1.5612  decode.d7.loss_mask: 0.7440  decode.d7.loss_dice: 1.2403  decode.d8.loss_cls: 1.5737  decode.d8.loss_mask: 0.7608  decode.d8.loss_dice: 1.2594
2023/05/24 00:59:48 - mmengine - INFO - Iter(train) [ 54750/160000]  lr: 6.8595e-06  eta: 12:30:42  time: 0.4096  data_time: 0.0100  memory: 4829  grad_norm: 125.9754  loss: 30.9969  decode.loss_cls: 0.9804  decode.loss_mask: 0.7178  decode.loss_dice: 1.0962  decode.d0.loss_cls: 3.1250  decode.d0.loss_mask: 0.7731  decode.d0.loss_dice: 1.2940  decode.d1.loss_cls: 1.2739  decode.d1.loss_mask: 0.7173  decode.d1.loss_dice: 1.1716  decode.d2.loss_cls: 1.1300  decode.d2.loss_mask: 0.7446  decode.d2.loss_dice: 1.1628  decode.d3.loss_cls: 1.1099  decode.d3.loss_mask: 0.6638  decode.d3.loss_dice: 1.0592  decode.d4.loss_cls: 1.0486  decode.d4.loss_mask: 0.6729  decode.d4.loss_dice: 1.1191  decode.d5.loss_cls: 1.0522  decode.d5.loss_mask: 0.6822  decode.d5.loss_dice: 1.0513  decode.d6.loss_cls: 1.0066  decode.d6.loss_mask: 0.6809  decode.d6.loss_dice: 1.0830  decode.d7.loss_cls: 0.9958  decode.d7.loss_mask: 0.7006  decode.d7.loss_dice: 1.0843  decode.d8.loss_cls: 0.9833  decode.d8.loss_mask: 0.7099  decode.d8.loss_dice: 1.1067
2023/05/24 01:00:09 - mmengine - INFO - Iter(train) [ 54800/160000]  lr: 6.8566e-06  eta: 12:30:20  time: 0.4159  data_time: 0.0098  memory: 4864  grad_norm: 116.5221  loss: 40.6442  decode.loss_cls: 1.3299  decode.loss_mask: 0.8631  decode.loss_dice: 1.5459  decode.d0.loss_cls: 3.1999  decode.d0.loss_mask: 0.8457  decode.d0.loss_dice: 1.7816  decode.d1.loss_cls: 1.5766  decode.d1.loss_mask: 0.9143  decode.d1.loss_dice: 1.6939  decode.d2.loss_cls: 1.4101  decode.d2.loss_mask: 0.9369  decode.d2.loss_dice: 1.6355  decode.d3.loss_cls: 1.4349  decode.d3.loss_mask: 0.8891  decode.d3.loss_dice: 1.5577  decode.d4.loss_cls: 1.3670  decode.d4.loss_mask: 0.8726  decode.d4.loss_dice: 1.5706  decode.d5.loss_cls: 1.3799  decode.d5.loss_mask: 0.8722  decode.d5.loss_dice: 1.5583  decode.d6.loss_cls: 1.4586  decode.d6.loss_mask: 0.8711  decode.d6.loss_dice: 1.5357  decode.d7.loss_cls: 1.3457  decode.d7.loss_mask: 0.8782  decode.d7.loss_dice: 1.5391  decode.d8.loss_cls: 1.3408  decode.d8.loss_mask: 0.8853  decode.d8.loss_dice: 1.5541
2023/05/24 01:00:30 - mmengine - INFO - Iter(train) [ 54850/160000]  lr: 6.8537e-06  eta: 12:29:58  time: 0.4220  data_time: 0.0100  memory: 4857  grad_norm: 99.4844  loss: 26.9700  decode.loss_cls: 0.9626  decode.loss_mask: 0.6967  decode.loss_dice: 0.7436  decode.d0.loss_cls: 2.8544  decode.d0.loss_mask: 0.7800  decode.d0.loss_dice: 0.9018  decode.d1.loss_cls: 1.1609  decode.d1.loss_mask: 0.7068  decode.d1.loss_dice: 0.8151  decode.d2.loss_cls: 1.1383  decode.d2.loss_mask: 0.6956  decode.d2.loss_dice: 0.7842  decode.d3.loss_cls: 1.0178  decode.d3.loss_mask: 0.6910  decode.d3.loss_dice: 0.7903  decode.d4.loss_cls: 1.0216  decode.d4.loss_mask: 0.7045  decode.d4.loss_dice: 0.7807  decode.d5.loss_cls: 0.9965  decode.d5.loss_mask: 0.7282  decode.d5.loss_dice: 0.7757  decode.d6.loss_cls: 1.0099  decode.d6.loss_mask: 0.6896  decode.d6.loss_dice: 0.7488  decode.d7.loss_cls: 1.0057  decode.d7.loss_mask: 0.6751  decode.d7.loss_dice: 0.7242  decode.d8.loss_cls: 0.9442  decode.d8.loss_mask: 0.6879  decode.d8.loss_dice: 0.7383
2023/05/24 01:00:51 - mmengine - INFO - Iter(train) [ 54900/160000]  lr: 6.8507e-06  eta: 12:29:36  time: 0.4130  data_time: 0.0104  memory: 4859  grad_norm: 94.4261  loss: 32.6144  decode.loss_cls: 1.0033  decode.loss_mask: 0.8573  decode.loss_dice: 1.1799  decode.d0.loss_cls: 2.9552  decode.d0.loss_mask: 0.9720  decode.d0.loss_dice: 1.3224  decode.d1.loss_cls: 1.1007  decode.d1.loss_mask: 0.8857  decode.d1.loss_dice: 1.1396  decode.d2.loss_cls: 1.0630  decode.d2.loss_mask: 0.8600  decode.d2.loss_dice: 1.1653  decode.d3.loss_cls: 1.0066  decode.d3.loss_mask: 0.8998  decode.d3.loss_dice: 1.1539  decode.d4.loss_cls: 1.0129  decode.d4.loss_mask: 0.8358  decode.d4.loss_dice: 1.1364  decode.d5.loss_cls: 1.0330  decode.d5.loss_mask: 0.8488  decode.d5.loss_dice: 1.1003  decode.d6.loss_cls: 1.0529  decode.d6.loss_mask: 0.8423  decode.d6.loss_dice: 1.1406  decode.d7.loss_cls: 1.0261  decode.d7.loss_mask: 0.8515  decode.d7.loss_dice: 1.1621  decode.d8.loss_cls: 1.0051  decode.d8.loss_mask: 0.8467  decode.d8.loss_dice: 1.1555
2023/05/24 01:01:12 - mmengine - INFO - Iter(train) [ 54950/160000]  lr: 6.8478e-06  eta: 12:29:13  time: 0.4071  data_time: 0.0100  memory: 4858  grad_norm: 100.1716  loss: 38.2379  decode.loss_cls: 1.2772  decode.loss_mask: 0.8261  decode.loss_dice: 1.4205  decode.d0.loss_cls: 3.0228  decode.d0.loss_mask: 0.9240  decode.d0.loss_dice: 1.5921  decode.d1.loss_cls: 1.5263  decode.d1.loss_mask: 0.8329  decode.d1.loss_dice: 1.5525  decode.d2.loss_cls: 1.3647  decode.d2.loss_mask: 0.8260  decode.d2.loss_dice: 1.5117  decode.d3.loss_cls: 1.3794  decode.d3.loss_mask: 0.8297  decode.d3.loss_dice: 1.4964  decode.d4.loss_cls: 1.3252  decode.d4.loss_mask: 0.8153  decode.d4.loss_dice: 1.4363  decode.d5.loss_cls: 1.3546  decode.d5.loss_mask: 0.8335  decode.d5.loss_dice: 1.4019  decode.d6.loss_cls: 1.3137  decode.d6.loss_mask: 0.8348  decode.d6.loss_dice: 1.4118  decode.d7.loss_cls: 1.3316  decode.d7.loss_mask: 0.8267  decode.d7.loss_dice: 1.4157  decode.d8.loss_cls: 1.3414  decode.d8.loss_mask: 0.8277  decode.d8.loss_dice: 1.3856
2023/05/24 01:01:33 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 01:01:33 - mmengine - INFO - Iter(train) [ 55000/160000]  lr: 6.8449e-06  eta: 12:28:50  time: 0.4148  data_time: 0.0100  memory: 4819  grad_norm: 91.9464  loss: 39.0108  decode.loss_cls: 1.3055  decode.loss_mask: 0.8805  decode.loss_dice: 1.4126  decode.d0.loss_cls: 3.0838  decode.d0.loss_mask: 0.9749  decode.d0.loss_dice: 1.6795  decode.d1.loss_cls: 1.4699  decode.d1.loss_mask: 0.8958  decode.d1.loss_dice: 1.5687  decode.d2.loss_cls: 1.3997  decode.d2.loss_mask: 0.8780  decode.d2.loss_dice: 1.4969  decode.d3.loss_cls: 1.4759  decode.d3.loss_mask: 0.8517  decode.d3.loss_dice: 1.4243  decode.d4.loss_cls: 1.3679  decode.d4.loss_mask: 0.8568  decode.d4.loss_dice: 1.4478  decode.d5.loss_cls: 1.3752  decode.d5.loss_mask: 0.8542  decode.d5.loss_dice: 1.4429  decode.d6.loss_cls: 1.3019  decode.d6.loss_mask: 0.8904  decode.d6.loss_dice: 1.4170  decode.d7.loss_cls: 1.3332  decode.d7.loss_mask: 0.8702  decode.d7.loss_dice: 1.4337  decode.d8.loss_cls: 1.3190  decode.d8.loss_mask: 0.8842  decode.d8.loss_dice: 1.4185
2023/05/24 01:01:33 - mmengine - INFO - Saving checkpoint at 55000 iterations
2023/05/24 01:01:45 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:01:17  time: 0.0866  data_time: 0.0020  memory: 2167  
2023/05/24 01:01:49 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:57  time: 0.0836  data_time: 0.0019  memory: 2216  
2023/05/24 01:01:53 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:47  time: 0.0795  data_time: 0.0019  memory: 2167  
2023/05/24 01:01:57 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:40  time: 0.0821  data_time: 0.0019  memory: 2104  
2023/05/24 01:02:01 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:34  time: 0.0856  data_time: 0.0019  memory: 2831  
2023/05/24 01:02:05 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0791  data_time: 0.0017  memory: 2167  
2023/05/24 01:02:10 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0813  data_time: 0.0018  memory: 2167  
2023/05/24 01:02:14 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:20  time: 0.0802  data_time: 0.0018  memory: 2167  
2023/05/24 01:02:18 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0843  data_time: 0.0021  memory: 2944  
2023/05/24 01:02:22 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:11  time: 0.0887  data_time: 0.0019  memory: 2356  
2023/05/24 01:02:27 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0795  data_time: 0.0018  memory: 2217  
2023/05/24 01:02:31 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0797  data_time: 0.0018  memory: 2328  
2023/05/24 01:02:35 - mmengine - INFO - per class results:
2023/05/24 01:02:35 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.56 | 93.01 |
|     bicycle      | 68.04 | 83.33 |
|       car        | 57.55 | 76.47 |
|    motorcycle    | 82.57 | 88.99 |
|     airplane     | 85.25 | 91.01 |
|       bus        | 79.33 | 85.45 |
|      train       | 82.36 | 91.09 |
|      truck       |  54.3 | 68.16 |
|       boat       | 61.18 | 78.96 |
|  traffic light   | 65.76 | 79.15 |
|   fire hydrant   | 80.51 |  94.5 |
|    stop sign     | 90.13 | 96.13 |
|  parking meter   | 80.95 | 84.89 |
|      bench       |  50.1 | 66.17 |
|       bird       | 81.35 |  90.5 |
|       cat        | 85.43 | 92.96 |
|       dog        | 79.95 | 89.55 |
|      horse       | 78.26 | 89.57 |
|      sheep       | 86.82 | 93.59 |
|       cow        | 82.61 | 88.42 |
|     elephant     | 89.05 | 94.75 |
|       bear       | 92.12 | 94.92 |
|      zebra       | 89.99 | 92.67 |
|     giraffe      | 86.94 | 92.85 |
|     backpack     | 31.92 | 61.52 |
|     umbrella     | 79.55 | 87.72 |
|     handbag      | 32.21 | 48.85 |
|       tie        |  9.8  | 11.46 |
|     suitcase     | 78.41 | 88.82 |
|     frisbee      | 63.87 | 89.25 |
|       skis       | 37.15 | 48.73 |
|    snowboard     | 51.38 | 71.44 |
|   sports ball    | 57.46 | 73.07 |
|       kite       | 51.83 | 59.21 |
|   baseball bat   | 49.34 | 64.42 |
|  baseball glove  | 72.45 | 84.68 |
|    skateboard    | 55.23 | 67.33 |
|    surfboard     | 65.89 | 85.99 |
|  tennis racket   | 81.56 | 87.62 |
|      bottle      | 43.25 | 53.47 |
|    wine glass    | 56.62 | 78.55 |
|       cup        |  55.4 | 71.57 |
|       fork       |  29.1 | 36.18 |
|      knife       |  29.4 | 43.55 |
|      spoon       | 33.56 | 53.82 |
|       bowl       | 42.04 | 57.16 |
|      banana      |  67.0 | 83.38 |
|      apple       | 48.15 | 71.17 |
|     sandwich     | 38.84 | 48.98 |
|      orange      | 64.66 | 70.94 |
|     broccoli     |  56.9 | 72.12 |
|      carrot      | 50.53 | 61.91 |
|     hot dog      | 43.46 | 51.22 |
|      pizza       | 70.37 | 80.87 |
|      donut       | 64.73 | 75.46 |
|       cake       | 60.99 | 77.09 |
|      chair       | 42.77 | 61.38 |
|      couch       |  49.5 | 76.99 |
|   potted plant   | 31.14 | 53.88 |
|       bed        | 60.44 | 73.81 |
|   dining table   | 40.96 | 80.49 |
|      toilet      | 79.39 | 93.75 |
|        tv        | 70.11 | 80.52 |
|      laptop      | 71.19 | 85.66 |
|      mouse       | 77.15 |  88.0 |
|      remote      | 50.03 | 70.81 |
|     keyboard     | 60.72 | 72.06 |
|    cell phone    |  70.4 | 85.08 |
|    microwave     | 66.07 | 74.17 |
|       oven       | 55.04 | 74.17 |
|     toaster      | 30.12 | 48.38 |
|       sink       | 60.09 | 76.16 |
|   refrigerator   | 74.53 | 88.71 |
|       book       | 47.78 | 69.62 |
|      clock       | 71.58 | 78.25 |
|       vase       | 57.29 | 82.83 |
|     scissors     | 76.41 | 89.04 |
|    teddy bear    |  73.3 | 85.63 |
|    hair drier    | 43.51 | 44.33 |
|    toothbrush    | 21.12 |  68.2 |
|      banner      | 31.46 | 67.73 |
|     blanket      |  1.37 |  1.59 |
|      branch      | 24.27 |  38.5 |
|      bridge      |  29.1 | 40.93 |
|  building-other  | 51.06 | 68.57 |
|       bush       | 31.24 |  42.7 |
|     cabinet      | 50.94 | 70.01 |
|       cage       | 16.99 | 28.04 |
|    cardboard     | 41.34 | 45.83 |
|      carpet      | 46.54 | 59.45 |
|  ceiling-other   | 62.48 | 79.68 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 16.72 | 22.81 |
|      clouds      | 47.21 | 61.69 |
|     counter      | 27.04 | 43.33 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 60.81 | 79.79 |
|    desk-stuff    | 37.45 | 46.16 |
|       dirt       | 37.99 | 54.55 |
|    door-stuff    | 34.98 | 53.11 |
|      fence       | 29.02 | 50.82 |
|   floor-marble   |  8.61 | 11.69 |
|   floor-other    | 18.81 | 24.15 |
|   floor-stone    |  0.64 |  0.67 |
|    floor-tile    | 56.34 |  64.0 |
|    floor-wood    | 58.81 | 78.87 |
|      flower      | 37.95 | 54.64 |
|       fog        |  7.35 |  7.76 |
|    food-other    | 25.23 | 31.08 |
|      fruit       | 39.25 | 58.72 |
| furniture-other  | 16.29 | 22.68 |
|      grass       | 68.48 | 86.08 |
|      gravel      | 31.46 | 46.15 |
|   ground-other   |  0.24 |  0.29 |
|       hill       | 22.81 | 34.68 |
|      house       | 24.13 | 30.24 |
|      leaves      | 27.56 | 41.68 |
|      light       |  35.8 | 50.81 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.29 | 47.23 |
|   mirror-stuff   | 38.21 | 67.99 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 49.66 | 66.01 |
|       mud        |  0.0  |  0.0  |
|      napkin      | 11.91 | 12.55 |
|       net        | 42.28 | 58.28 |
|      paper       |  30.0 | 43.07 |
|     pavement     | 49.86 | 70.95 |
|      pillow      |  9.84 | 11.84 |
|   plant-other    | 18.24 | 29.65 |
|     plastic      | 18.78 |  25.4 |
|     platform     | 27.73 | 38.05 |
|   playingfield   | 68.61 | 89.29 |
|     railing      |  3.49 |  4.96 |
|     railroad     | 56.36 | 68.25 |
|      river       | 48.13 | 64.76 |
|       road       | 63.68 | 80.06 |
|       rock       | 42.25 | 60.43 |
|       roof       | 13.02 | 16.07 |
|       rug        | 31.84 | 56.44 |
|      salad       |  0.0  |  0.0  |
|       sand       | 60.92 | 69.65 |
|       sea        | 83.55 | 93.15 |
|      shelf       | 33.27 | 45.26 |
|    sky-other     | 70.35 | 87.32 |
|    skyscraper    | 33.68 |  54.9 |
|       snow       | 88.38 | 92.28 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 16.99 | 28.97 |
|      stone       | 13.03 | 19.97 |
|      straw       | 28.49 | 39.41 |
| structural-other |  0.27 |  0.29 |
|      table       |  17.3 | 23.05 |
|       tent       |  7.56 | 10.58 |
|  textile-other   |  9.67 | 16.19 |
|      towel       | 29.03 | 43.46 |
|       tree       | 73.25 | 85.24 |
|    vegetable     | 33.35 | 51.16 |
|    wall-brick    | 43.28 | 62.15 |
|  wall-concrete   | 57.87 | 80.76 |
|    wall-other    | 15.83 | 22.59 |
|    wall-panel    |  1.58 |  1.72 |
|    wall-stone    | 27.82 | 44.05 |
|    wall-tile     | 62.54 | 81.01 |
|    wall-wood     | 38.07 | 58.45 |
|   water-other    | 21.56 | 31.05 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 48.12 | 62.65 |
|   window-other   | 42.22 | 71.89 |
|       wood       | 27.65 | 40.54 |
+------------------+-------+-------+
2023/05/24 01:02:35 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.0000  mIoU: 45.2000  mAcc: 57.5700  data_time: 0.0021  time: 0.0869
2023/05/24 01:02:35 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_45000.pth is removed
2023/05/24 01:02:38 - mmengine - INFO - The best checkpoint with 45.2000 mIoU at 55000 iter is saved to best_mIoU_iter_55000.pth.
2023/05/24 01:02:59 - mmengine - INFO - Iter(train) [ 55050/160000]  lr: 6.8419e-06  eta: 12:28:38  time: 0.4085  data_time: 0.0100  memory: 4888  grad_norm: 92.0710  loss: 38.4986  decode.loss_cls: 1.2443  decode.loss_mask: 0.8991  decode.loss_dice: 1.3833  decode.d0.loss_cls: 3.3328  decode.d0.loss_mask: 1.0357  decode.d0.loss_dice: 1.6108  decode.d1.loss_cls: 1.3404  decode.d1.loss_mask: 0.9754  decode.d1.loss_dice: 1.4703  decode.d2.loss_cls: 1.2445  decode.d2.loss_mask: 0.9427  decode.d2.loss_dice: 1.4717  decode.d3.loss_cls: 1.2507  decode.d3.loss_mask: 0.9474  decode.d3.loss_dice: 1.4495  decode.d4.loss_cls: 1.2377  decode.d4.loss_mask: 0.9281  decode.d4.loss_dice: 1.4369  decode.d5.loss_cls: 1.2512  decode.d5.loss_mask: 0.9742  decode.d5.loss_dice: 1.3993  decode.d6.loss_cls: 1.2121  decode.d6.loss_mask: 0.9800  decode.d6.loss_dice: 1.4105  decode.d7.loss_cls: 1.1857  decode.d7.loss_mask: 0.9508  decode.d7.loss_dice: 1.4022  decode.d8.loss_cls: 1.1826  decode.d8.loss_mask: 0.9587  decode.d8.loss_dice: 1.3901
2023/05/24 01:03:20 - mmengine - INFO - Iter(train) [ 55100/160000]  lr: 6.8390e-06  eta: 12:28:16  time: 0.4188  data_time: 0.0106  memory: 4867  grad_norm: 101.6364  loss: 32.1818  decode.loss_cls: 0.9904  decode.loss_mask: 0.7216  decode.loss_dice: 1.2326  decode.d0.loss_cls: 2.8725  decode.d0.loss_mask: 0.7896  decode.d0.loss_dice: 1.4227  decode.d1.loss_cls: 1.1202  decode.d1.loss_mask: 0.7849  decode.d1.loss_dice: 1.3553  decode.d2.loss_cls: 1.0546  decode.d2.loss_mask: 0.7622  decode.d2.loss_dice: 1.2799  decode.d3.loss_cls: 1.0097  decode.d3.loss_mask: 0.7436  decode.d3.loss_dice: 1.2648  decode.d4.loss_cls: 0.9814  decode.d4.loss_mask: 0.7438  decode.d4.loss_dice: 1.2667  decode.d5.loss_cls: 0.9399  decode.d5.loss_mask: 0.7638  decode.d5.loss_dice: 1.2551  decode.d6.loss_cls: 0.9896  decode.d6.loss_mask: 0.7241  decode.d6.loss_dice: 1.2454  decode.d7.loss_cls: 0.9876  decode.d7.loss_mask: 0.7171  decode.d7.loss_dice: 1.2321  decode.d8.loss_cls: 0.9410  decode.d8.loss_mask: 0.7350  decode.d8.loss_dice: 1.2544
2023/05/24 01:03:41 - mmengine - INFO - Iter(train) [ 55150/160000]  lr: 6.8361e-06  eta: 12:27:54  time: 0.4202  data_time: 0.0102  memory: 4825  grad_norm: 102.9620  loss: 32.5879  decode.loss_cls: 1.3393  decode.loss_mask: 0.7408  decode.loss_dice: 0.9468  decode.d0.loss_cls: 3.0882  decode.d0.loss_mask: 0.8308  decode.d0.loss_dice: 1.0929  decode.d1.loss_cls: 1.3134  decode.d1.loss_mask: 0.8077  decode.d1.loss_dice: 0.9967  decode.d2.loss_cls: 1.3143  decode.d2.loss_mask: 0.7492  decode.d2.loss_dice: 1.0046  decode.d3.loss_cls: 1.3578  decode.d3.loss_mask: 0.7570  decode.d3.loss_dice: 0.9865  decode.d4.loss_cls: 1.4071  decode.d4.loss_mask: 0.7220  decode.d4.loss_dice: 0.9756  decode.d5.loss_cls: 1.3417  decode.d5.loss_mask: 0.7417  decode.d5.loss_dice: 0.9789  decode.d6.loss_cls: 1.3390  decode.d6.loss_mask: 0.7492  decode.d6.loss_dice: 0.9586  decode.d7.loss_cls: 1.2587  decode.d7.loss_mask: 0.7550  decode.d7.loss_dice: 0.9844  decode.d8.loss_cls: 1.3088  decode.d8.loss_mask: 0.7530  decode.d8.loss_dice: 0.9883
2023/05/24 01:04:02 - mmengine - INFO - Iter(train) [ 55200/160000]  lr: 6.8331e-06  eta: 12:27:32  time: 0.4226  data_time: 0.0101  memory: 4886  grad_norm: 128.9465  loss: 46.9141  decode.loss_cls: 1.5908  decode.loss_mask: 1.0078  decode.loss_dice: 1.7616  decode.d0.loss_cls: 3.4201  decode.d0.loss_mask: 1.1382  decode.d0.loss_dice: 2.1465  decode.d1.loss_cls: 1.5973  decode.d1.loss_mask: 1.0582  decode.d1.loss_dice: 2.0580  decode.d2.loss_cls: 1.5813  decode.d2.loss_mask: 0.9822  decode.d2.loss_dice: 1.9142  decode.d3.loss_cls: 1.6403  decode.d3.loss_mask: 1.0028  decode.d3.loss_dice: 1.8401  decode.d4.loss_cls: 1.5926  decode.d4.loss_mask: 1.0003  decode.d4.loss_dice: 1.8742  decode.d5.loss_cls: 1.5950  decode.d5.loss_mask: 0.9934  decode.d5.loss_dice: 1.8789  decode.d6.loss_cls: 1.5762  decode.d6.loss_mask: 1.0038  decode.d6.loss_dice: 1.8420  decode.d7.loss_cls: 1.6403  decode.d7.loss_mask: 1.0238  decode.d7.loss_dice: 1.7993  decode.d8.loss_cls: 1.5844  decode.d8.loss_mask: 1.0010  decode.d8.loss_dice: 1.7693
2023/05/24 01:04:24 - mmengine - INFO - Iter(train) [ 55250/160000]  lr: 6.8302e-06  eta: 12:27:11  time: 0.4698  data_time: 0.0106  memory: 4823  grad_norm: 114.3509  loss: 34.7388  decode.loss_cls: 1.3617  decode.loss_mask: 0.8223  decode.loss_dice: 1.0294  decode.d0.loss_cls: 3.1154  decode.d0.loss_mask: 0.9237  decode.d0.loss_dice: 1.2314  decode.d1.loss_cls: 1.4698  decode.d1.loss_mask: 0.9216  decode.d1.loss_dice: 1.1270  decode.d2.loss_cls: 1.4131  decode.d2.loss_mask: 0.8757  decode.d2.loss_dice: 1.0684  decode.d3.loss_cls: 1.3997  decode.d3.loss_mask: 0.8387  decode.d3.loss_dice: 1.0352  decode.d4.loss_cls: 1.3625  decode.d4.loss_mask: 0.8341  decode.d4.loss_dice: 1.0102  decode.d5.loss_cls: 1.4262  decode.d5.loss_mask: 0.8202  decode.d5.loss_dice: 1.0313  decode.d6.loss_cls: 1.3716  decode.d6.loss_mask: 0.8166  decode.d6.loss_dice: 1.0194  decode.d7.loss_cls: 1.3408  decode.d7.loss_mask: 0.8122  decode.d7.loss_dice: 0.9939  decode.d8.loss_cls: 1.3902  decode.d8.loss_mask: 0.8215  decode.d8.loss_dice: 1.0551
2023/05/24 01:04:45 - mmengine - INFO - Iter(train) [ 55300/160000]  lr: 6.8273e-06  eta: 12:26:50  time: 0.4125  data_time: 0.0098  memory: 4869  grad_norm: 113.1238  loss: 37.8032  decode.loss_cls: 1.1343  decode.loss_mask: 0.9631  decode.loss_dice: 1.3584  decode.d0.loss_cls: 3.0255  decode.d0.loss_mask: 0.9591  decode.d0.loss_dice: 1.5216  decode.d1.loss_cls: 1.3817  decode.d1.loss_mask: 1.0334  decode.d1.loss_dice: 1.4549  decode.d2.loss_cls: 1.2683  decode.d2.loss_mask: 1.0809  decode.d2.loss_dice: 1.4110  decode.d3.loss_cls: 1.1521  decode.d3.loss_mask: 1.0649  decode.d3.loss_dice: 1.3952  decode.d4.loss_cls: 1.1727  decode.d4.loss_mask: 1.0223  decode.d4.loss_dice: 1.3789  decode.d5.loss_cls: 1.2087  decode.d5.loss_mask: 0.9805  decode.d5.loss_dice: 1.3636  decode.d6.loss_cls: 1.1811  decode.d6.loss_mask: 0.9702  decode.d6.loss_dice: 1.3309  decode.d7.loss_cls: 1.1353  decode.d7.loss_mask: 1.0017  decode.d7.loss_dice: 1.3746  decode.d8.loss_cls: 1.1353  decode.d8.loss_mask: 0.9886  decode.d8.loss_dice: 1.3542
2023/05/24 01:05:06 - mmengine - INFO - Iter(train) [ 55350/160000]  lr: 6.8243e-06  eta: 12:26:27  time: 0.4118  data_time: 0.0099  memory: 4858  grad_norm: 110.7957  loss: 42.5137  decode.loss_cls: 1.4818  decode.loss_mask: 0.8368  decode.loss_dice: 1.5507  decode.d0.loss_cls: 3.3629  decode.d0.loss_mask: 0.9608  decode.d0.loss_dice: 1.8236  decode.d1.loss_cls: 1.5961  decode.d1.loss_mask: 0.9502  decode.d1.loss_dice: 1.7290  decode.d2.loss_cls: 1.5209  decode.d2.loss_mask: 0.9299  decode.d2.loss_dice: 1.7049  decode.d3.loss_cls: 1.6083  decode.d3.loss_mask: 0.8503  decode.d3.loss_dice: 1.6301  decode.d4.loss_cls: 1.5362  decode.d4.loss_mask: 0.9048  decode.d4.loss_dice: 1.6371  decode.d5.loss_cls: 1.5262  decode.d5.loss_mask: 0.8942  decode.d5.loss_dice: 1.6009  decode.d6.loss_cls: 1.5341  decode.d6.loss_mask: 0.8766  decode.d6.loss_dice: 1.5675  decode.d7.loss_cls: 1.5118  decode.d7.loss_mask: 0.8598  decode.d7.loss_dice: 1.5848  decode.d8.loss_cls: 1.4545  decode.d8.loss_mask: 0.8845  decode.d8.loss_dice: 1.6043
2023/05/24 01:05:27 - mmengine - INFO - Iter(train) [ 55400/160000]  lr: 6.8214e-06  eta: 12:26:05  time: 0.4180  data_time: 0.0101  memory: 4808  grad_norm: 96.6000  loss: 37.1846  decode.loss_cls: 1.3212  decode.loss_mask: 0.8051  decode.loss_dice: 1.2772  decode.d0.loss_cls: 3.1421  decode.d0.loss_mask: 0.8665  decode.d0.loss_dice: 1.5060  decode.d1.loss_cls: 1.5109  decode.d1.loss_mask: 0.8604  decode.d1.loss_dice: 1.3896  decode.d2.loss_cls: 1.4597  decode.d2.loss_mask: 0.8349  decode.d2.loss_dice: 1.3140  decode.d3.loss_cls: 1.4271  decode.d3.loss_mask: 0.8459  decode.d3.loss_dice: 1.3410  decode.d4.loss_cls: 1.4281  decode.d4.loss_mask: 0.8274  decode.d4.loss_dice: 1.3141  decode.d5.loss_cls: 1.3756  decode.d5.loss_mask: 0.8286  decode.d5.loss_dice: 1.3033  decode.d6.loss_cls: 1.3292  decode.d6.loss_mask: 0.8212  decode.d6.loss_dice: 1.2773  decode.d7.loss_cls: 1.3531  decode.d7.loss_mask: 0.8009  decode.d7.loss_dice: 1.2514  decode.d8.loss_cls: 1.3347  decode.d8.loss_mask: 0.7933  decode.d8.loss_dice: 1.2450
2023/05/24 01:05:48 - mmengine - INFO - Iter(train) [ 55450/160000]  lr: 6.8185e-06  eta: 12:25:42  time: 0.4196  data_time: 0.0100  memory: 4836  grad_norm: 91.6992  loss: 35.8830  decode.loss_cls: 1.2440  decode.loss_mask: 0.6920  decode.loss_dice: 1.3562  decode.d0.loss_cls: 3.2685  decode.d0.loss_mask: 0.8044  decode.d0.loss_dice: 1.5957  decode.d1.loss_cls: 1.3841  decode.d1.loss_mask: 0.7439  decode.d1.loss_dice: 1.5052  decode.d2.loss_cls: 1.3124  decode.d2.loss_mask: 0.7174  decode.d2.loss_dice: 1.4232  decode.d3.loss_cls: 1.2781  decode.d3.loss_mask: 0.7224  decode.d3.loss_dice: 1.3713  decode.d4.loss_cls: 1.2661  decode.d4.loss_mask: 0.7173  decode.d4.loss_dice: 1.3753  decode.d5.loss_cls: 1.2263  decode.d5.loss_mask: 0.7019  decode.d5.loss_dice: 1.4201  decode.d6.loss_cls: 1.2067  decode.d6.loss_mask: 0.7040  decode.d6.loss_dice: 1.3481  decode.d7.loss_cls: 1.2669  decode.d7.loss_mask: 0.6951  decode.d7.loss_dice: 1.3089  decode.d8.loss_cls: 1.2264  decode.d8.loss_mask: 0.6900  decode.d8.loss_dice: 1.3114
2023/05/24 01:06:09 - mmengine - INFO - Iter(train) [ 55500/160000]  lr: 6.8155e-06  eta: 12:25:21  time: 0.4186  data_time: 0.0098  memory: 4876  grad_norm: 103.7361  loss: 42.1630  decode.loss_cls: 1.4150  decode.loss_mask: 0.9217  decode.loss_dice: 1.5890  decode.d0.loss_cls: 3.3079  decode.d0.loss_mask: 1.0146  decode.d0.loss_dice: 1.8183  decode.d1.loss_cls: 1.4945  decode.d1.loss_mask: 1.0163  decode.d1.loss_dice: 1.7260  decode.d2.loss_cls: 1.5094  decode.d2.loss_mask: 0.9632  decode.d2.loss_dice: 1.6203  decode.d3.loss_cls: 1.4545  decode.d3.loss_mask: 0.9367  decode.d3.loss_dice: 1.6280  decode.d4.loss_cls: 1.3869  decode.d4.loss_mask: 0.9319  decode.d4.loss_dice: 1.6124  decode.d5.loss_cls: 1.4216  decode.d5.loss_mask: 0.9618  decode.d5.loss_dice: 1.6073  decode.d6.loss_cls: 1.4122  decode.d6.loss_mask: 0.9324  decode.d6.loss_dice: 1.5989  decode.d7.loss_cls: 1.4299  decode.d7.loss_mask: 0.9298  decode.d7.loss_dice: 1.5997  decode.d8.loss_cls: 1.3969  decode.d8.loss_mask: 0.9331  decode.d8.loss_dice: 1.5927
2023/05/24 01:06:31 - mmengine - INFO - Iter(train) [ 55550/160000]  lr: 6.8126e-06  eta: 12:25:00  time: 0.4813  data_time: 0.0115  memory: 4820  grad_norm: 105.1618  loss: 40.1199  decode.loss_cls: 1.5177  decode.loss_mask: 0.7407  decode.loss_dice: 1.4406  decode.d0.loss_cls: 3.3499  decode.d0.loss_mask: 0.8746  decode.d0.loss_dice: 1.7284  decode.d1.loss_cls: 1.6641  decode.d1.loss_mask: 0.8255  decode.d1.loss_dice: 1.6145  decode.d2.loss_cls: 1.5489  decode.d2.loss_mask: 0.8307  decode.d2.loss_dice: 1.5567  decode.d3.loss_cls: 1.5873  decode.d3.loss_mask: 0.7811  decode.d3.loss_dice: 1.4556  decode.d4.loss_cls: 1.5243  decode.d4.loss_mask: 0.7565  decode.d4.loss_dice: 1.4536  decode.d5.loss_cls: 1.5549  decode.d5.loss_mask: 0.7660  decode.d5.loss_dice: 1.4341  decode.d6.loss_cls: 1.4961  decode.d6.loss_mask: 0.7697  decode.d6.loss_dice: 1.4882  decode.d7.loss_cls: 1.5380  decode.d7.loss_mask: 0.7310  decode.d7.loss_dice: 1.4280  decode.d8.loss_cls: 1.4897  decode.d8.loss_mask: 0.7262  decode.d8.loss_dice: 1.4472
2023/05/24 01:06:54 - mmengine - INFO - Iter(train) [ 55600/160000]  lr: 6.8097e-06  eta: 12:24:43  time: 0.4701  data_time: 0.0102  memory: 4850  grad_norm: 98.7985  loss: 29.7205  decode.loss_cls: 0.9553  decode.loss_mask: 0.6211  decode.loss_dice: 1.1040  decode.d0.loss_cls: 3.0932  decode.d0.loss_mask: 0.6818  decode.d0.loss_dice: 1.3148  decode.d1.loss_cls: 1.1653  decode.d1.loss_mask: 0.6302  decode.d1.loss_dice: 1.1810  decode.d2.loss_cls: 1.0373  decode.d2.loss_mask: 0.6103  decode.d2.loss_dice: 1.1282  decode.d3.loss_cls: 1.0058  decode.d3.loss_mask: 0.6113  decode.d3.loss_dice: 1.1083  decode.d4.loss_cls: 0.9694  decode.d4.loss_mask: 0.6243  decode.d4.loss_dice: 1.1488  decode.d5.loss_cls: 0.9516  decode.d5.loss_mask: 0.6176  decode.d5.loss_dice: 1.1301  decode.d6.loss_cls: 0.9714  decode.d6.loss_mask: 0.5938  decode.d6.loss_dice: 1.0881  decode.d7.loss_cls: 1.0134  decode.d7.loss_mask: 0.5911  decode.d7.loss_dice: 1.0679  decode.d8.loss_cls: 1.0045  decode.d8.loss_mask: 0.6105  decode.d8.loss_dice: 1.0902
2023/05/24 01:07:18 - mmengine - INFO - Iter(train) [ 55650/160000]  lr: 6.8067e-06  eta: 12:24:26  time: 0.4720  data_time: 0.0102  memory: 4877  grad_norm: 128.0079  loss: 27.1846  decode.loss_cls: 0.8754  decode.loss_mask: 0.7046  decode.loss_dice: 0.8998  decode.d0.loss_cls: 2.6768  decode.d0.loss_mask: 0.7650  decode.d0.loss_dice: 1.0561  decode.d1.loss_cls: 0.9361  decode.d1.loss_mask: 0.7416  decode.d1.loss_dice: 1.0025  decode.d2.loss_cls: 0.9405  decode.d2.loss_mask: 0.7126  decode.d2.loss_dice: 0.9422  decode.d3.loss_cls: 0.9132  decode.d3.loss_mask: 0.7079  decode.d3.loss_dice: 0.9317  decode.d4.loss_cls: 0.8999  decode.d4.loss_mask: 0.7064  decode.d4.loss_dice: 0.9050  decode.d5.loss_cls: 0.8674  decode.d5.loss_mask: 0.6879  decode.d5.loss_dice: 0.8998  decode.d6.loss_cls: 0.9016  decode.d6.loss_mask: 0.6901  decode.d6.loss_dice: 0.8922  decode.d7.loss_cls: 0.8850  decode.d7.loss_mask: 0.7002  decode.d7.loss_dice: 0.8938  decode.d8.loss_cls: 0.8551  decode.d8.loss_mask: 0.7042  decode.d8.loss_dice: 0.8901
2023/05/24 01:07:41 - mmengine - INFO - Iter(train) [ 55700/160000]  lr: 6.8038e-06  eta: 12:24:07  time: 0.4297  data_time: 0.0099  memory: 4765  grad_norm: 100.7205  loss: 35.7526  decode.loss_cls: 1.4455  decode.loss_mask: 0.7222  decode.loss_dice: 1.1786  decode.d0.loss_cls: 3.3123  decode.d0.loss_mask: 0.7490  decode.d0.loss_dice: 1.3576  decode.d1.loss_cls: 1.4317  decode.d1.loss_mask: 0.7828  decode.d1.loss_dice: 1.2983  decode.d2.loss_cls: 1.5436  decode.d2.loss_mask: 0.7294  decode.d2.loss_dice: 1.2326  decode.d3.loss_cls: 1.4066  decode.d3.loss_mask: 0.7231  decode.d3.loss_dice: 1.1565  decode.d4.loss_cls: 1.4387  decode.d4.loss_mask: 0.7105  decode.d4.loss_dice: 1.1721  decode.d5.loss_cls: 1.4312  decode.d5.loss_mask: 0.7389  decode.d5.loss_dice: 1.1938  decode.d6.loss_cls: 1.4744  decode.d6.loss_mask: 0.6964  decode.d6.loss_dice: 1.1524  decode.d7.loss_cls: 1.4362  decode.d7.loss_mask: 0.7393  decode.d7.loss_dice: 1.1674  decode.d8.loss_cls: 1.4606  decode.d8.loss_mask: 0.7283  decode.d8.loss_dice: 1.1425
2023/05/24 01:08:02 - mmengine - INFO - Iter(train) [ 55750/160000]  lr: 6.8008e-06  eta: 12:23:46  time: 0.4240  data_time: 0.0099  memory: 4904  grad_norm: 89.4731  loss: 41.2741  decode.loss_cls: 1.4854  decode.loss_mask: 0.8402  decode.loss_dice: 1.4356  decode.d0.loss_cls: 3.7337  decode.d0.loss_mask: 0.9369  decode.d0.loss_dice: 1.7364  decode.d1.loss_cls: 1.7264  decode.d1.loss_mask: 0.8469  decode.d1.loss_dice: 1.5464  decode.d2.loss_cls: 1.6048  decode.d2.loss_mask: 0.8961  decode.d2.loss_dice: 1.5063  decode.d3.loss_cls: 1.5436  decode.d3.loss_mask: 0.8634  decode.d3.loss_dice: 1.4638  decode.d4.loss_cls: 1.5238  decode.d4.loss_mask: 0.8623  decode.d4.loss_dice: 1.4533  decode.d5.loss_cls: 1.5151  decode.d5.loss_mask: 0.8808  decode.d5.loss_dice: 1.4973  decode.d6.loss_cls: 1.4571  decode.d6.loss_mask: 0.8454  decode.d6.loss_dice: 1.4802  decode.d7.loss_cls: 1.5187  decode.d7.loss_mask: 0.8513  decode.d7.loss_dice: 1.4595  decode.d8.loss_cls: 1.4436  decode.d8.loss_mask: 0.8826  decode.d8.loss_dice: 1.4372
2023/05/24 01:08:23 - mmengine - INFO - Iter(train) [ 55800/160000]  lr: 6.7979e-06  eta: 12:23:23  time: 0.4156  data_time: 0.0101  memory: 4811  grad_norm: 81.4282  loss: 34.1335  decode.loss_cls: 1.1249  decode.loss_mask: 0.8477  decode.loss_dice: 1.1231  decode.d0.loss_cls: 3.0784  decode.d0.loss_mask: 0.9756  decode.d0.loss_dice: 1.4448  decode.d1.loss_cls: 1.2537  decode.d1.loss_mask: 0.9505  decode.d1.loss_dice: 1.2484  decode.d2.loss_cls: 1.1314  decode.d2.loss_mask: 0.9041  decode.d2.loss_dice: 1.2116  decode.d3.loss_cls: 1.1419  decode.d3.loss_mask: 0.8962  decode.d3.loss_dice: 1.1276  decode.d4.loss_cls: 1.1526  decode.d4.loss_mask: 0.8895  decode.d4.loss_dice: 1.1350  decode.d5.loss_cls: 1.0775  decode.d5.loss_mask: 0.8973  decode.d5.loss_dice: 1.1462  decode.d6.loss_cls: 1.1230  decode.d6.loss_mask: 0.8810  decode.d6.loss_dice: 1.1103  decode.d7.loss_cls: 1.0969  decode.d7.loss_mask: 0.9076  decode.d7.loss_dice: 1.1331  decode.d8.loss_cls: 1.1084  decode.d8.loss_mask: 0.8853  decode.d8.loss_dice: 1.1300
2023/05/24 01:08:46 - mmengine - INFO - Iter(train) [ 55850/160000]  lr: 6.7950e-06  eta: 12:23:04  time: 0.4733  data_time: 0.0110  memory: 4836  grad_norm: 94.0574  loss: 31.6005  decode.loss_cls: 0.9106  decode.loss_mask: 0.7361  decode.loss_dice: 1.1896  decode.d0.loss_cls: 3.0274  decode.d0.loss_mask: 0.8291  decode.d0.loss_dice: 1.4114  decode.d1.loss_cls: 1.0996  decode.d1.loss_mask: 0.7697  decode.d1.loss_dice: 1.2364  decode.d2.loss_cls: 1.0116  decode.d2.loss_mask: 0.7455  decode.d2.loss_dice: 1.1993  decode.d3.loss_cls: 0.9931  decode.d3.loss_mask: 0.7582  decode.d3.loss_dice: 1.2523  decode.d4.loss_cls: 1.0126  decode.d4.loss_mask: 0.7357  decode.d4.loss_dice: 1.2382  decode.d5.loss_cls: 0.9907  decode.d5.loss_mask: 0.7256  decode.d5.loss_dice: 1.1972  decode.d6.loss_cls: 0.9336  decode.d6.loss_mask: 0.7314  decode.d6.loss_dice: 1.1892  decode.d7.loss_cls: 0.9299  decode.d7.loss_mask: 0.7178  decode.d7.loss_dice: 1.1535  decode.d8.loss_cls: 0.9522  decode.d8.loss_mask: 0.7237  decode.d8.loss_dice: 1.1993
2023/05/24 01:09:09 - mmengine - INFO - Iter(train) [ 55900/160000]  lr: 6.7920e-06  eta: 12:22:47  time: 0.4681  data_time: 0.0099  memory: 4844  grad_norm: 110.8235  loss: 40.1248  decode.loss_cls: 1.5065  decode.loss_mask: 0.9109  decode.loss_dice: 1.3514  decode.d0.loss_cls: 3.0322  decode.d0.loss_mask: 0.9362  decode.d0.loss_dice: 1.6290  decode.d1.loss_cls: 1.6521  decode.d1.loss_mask: 0.9303  decode.d1.loss_dice: 1.4479  decode.d2.loss_cls: 1.5702  decode.d2.loss_mask: 0.8794  decode.d2.loss_dice: 1.3976  decode.d3.loss_cls: 1.5435  decode.d3.loss_mask: 0.8763  decode.d3.loss_dice: 1.3660  decode.d4.loss_cls: 1.5653  decode.d4.loss_mask: 0.8834  decode.d4.loss_dice: 1.3885  decode.d5.loss_cls: 1.5151  decode.d5.loss_mask: 0.8987  decode.d5.loss_dice: 1.3692  decode.d6.loss_cls: 1.5738  decode.d6.loss_mask: 0.9291  decode.d6.loss_dice: 1.3656  decode.d7.loss_cls: 1.5012  decode.d7.loss_mask: 0.9527  decode.d7.loss_dice: 1.3719  decode.d8.loss_cls: 1.5051  decode.d8.loss_mask: 0.9262  decode.d8.loss_dice: 1.3495
2023/05/24 01:09:33 - mmengine - INFO - Iter(train) [ 55950/160000]  lr: 6.7891e-06  eta: 12:22:29  time: 0.4664  data_time: 0.0099  memory: 4817  grad_norm: 114.0158  loss: 41.2535  decode.loss_cls: 1.4648  decode.loss_mask: 0.8352  decode.loss_dice: 1.4792  decode.d0.loss_cls: 3.2654  decode.d0.loss_mask: 1.0363  decode.d0.loss_dice: 1.7148  decode.d1.loss_cls: 1.5871  decode.d1.loss_mask: 1.0126  decode.d1.loss_dice: 1.6058  decode.d2.loss_cls: 1.5336  decode.d2.loss_mask: 0.9529  decode.d2.loss_dice: 1.5690  decode.d3.loss_cls: 1.4714  decode.d3.loss_mask: 0.9697  decode.d3.loss_dice: 1.4966  decode.d4.loss_cls: 1.4667  decode.d4.loss_mask: 0.9274  decode.d4.loss_dice: 1.4626  decode.d5.loss_cls: 1.5130  decode.d5.loss_mask: 0.9139  decode.d5.loss_dice: 1.4999  decode.d6.loss_cls: 1.5269  decode.d6.loss_mask: 0.8991  decode.d6.loss_dice: 1.4821  decode.d7.loss_cls: 1.4481  decode.d7.loss_mask: 0.8917  decode.d7.loss_dice: 1.4533  decode.d8.loss_cls: 1.5076  decode.d8.loss_mask: 0.8349  decode.d8.loss_dice: 1.4319
2023/05/24 01:09:56 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 01:09:56 - mmengine - INFO - Iter(train) [ 56000/160000]  lr: 6.7862e-06  eta: 12:22:11  time: 0.4684  data_time: 0.0099  memory: 4846  grad_norm: 81.0409  loss: 32.1801  decode.loss_cls: 1.0781  decode.loss_mask: 0.7506  decode.loss_dice: 1.1704  decode.d0.loss_cls: 2.9593  decode.d0.loss_mask: 0.7881  decode.d0.loss_dice: 1.2114  decode.d1.loss_cls: 1.2354  decode.d1.loss_mask: 0.7603  decode.d1.loss_dice: 1.2107  decode.d2.loss_cls: 1.1468  decode.d2.loss_mask: 0.7644  decode.d2.loss_dice: 1.1829  decode.d3.loss_cls: 1.1266  decode.d3.loss_mask: 0.7088  decode.d3.loss_dice: 1.1114  decode.d4.loss_cls: 1.0680  decode.d4.loss_mask: 0.7358  decode.d4.loss_dice: 1.1362  decode.d5.loss_cls: 1.0818  decode.d5.loss_mask: 0.7360  decode.d5.loss_dice: 1.1432  decode.d6.loss_cls: 1.1060  decode.d6.loss_mask: 0.7401  decode.d6.loss_dice: 1.1687  decode.d7.loss_cls: 1.0901  decode.d7.loss_mask: 0.7448  decode.d7.loss_dice: 1.1932  decode.d8.loss_cls: 1.0673  decode.d8.loss_mask: 0.7562  decode.d8.loss_dice: 1.2079
2023/05/24 01:09:56 - mmengine - INFO - Saving checkpoint at 56000 iterations
2023/05/24 01:10:24 - mmengine - INFO - Iter(train) [ 56050/160000]  lr: 6.7832e-06  eta: 12:22:01  time: 0.4290  data_time: 0.0110  memory: 4802  grad_norm: 90.8956  loss: 27.6354  decode.loss_cls: 1.0880  decode.loss_mask: 0.5834  decode.loss_dice: 0.8480  decode.d0.loss_cls: 2.7364  decode.d0.loss_mask: 0.6030  decode.d0.loss_dice: 1.0006  decode.d1.loss_cls: 1.1530  decode.d1.loss_mask: 0.6241  decode.d1.loss_dice: 0.9405  decode.d2.loss_cls: 1.1582  decode.d2.loss_mask: 0.5812  decode.d2.loss_dice: 0.9199  decode.d3.loss_cls: 1.2247  decode.d3.loss_mask: 0.6022  decode.d3.loss_dice: 0.8826  decode.d4.loss_cls: 1.1451  decode.d4.loss_mask: 0.5780  decode.d4.loss_dice: 0.8483  decode.d5.loss_cls: 1.1083  decode.d5.loss_mask: 0.5642  decode.d5.loss_dice: 0.8761  decode.d6.loss_cls: 1.1189  decode.d6.loss_mask: 0.5605  decode.d6.loss_dice: 0.8774  decode.d7.loss_cls: 1.0757  decode.d7.loss_mask: 0.5605  decode.d7.loss_dice: 0.8591  decode.d8.loss_cls: 1.0300  decode.d8.loss_mask: 0.5887  decode.d8.loss_dice: 0.8988
2023/05/24 01:10:45 - mmengine - INFO - Iter(train) [ 56100/160000]  lr: 6.7803e-06  eta: 12:21:39  time: 0.4079  data_time: 0.0103  memory: 4885  grad_norm: 82.0846  loss: 34.3904  decode.loss_cls: 1.0287  decode.loss_mask: 0.8144  decode.loss_dice: 1.3094  decode.d0.loss_cls: 2.9591  decode.d0.loss_mask: 0.8191  decode.d0.loss_dice: 1.5085  decode.d1.loss_cls: 1.1874  decode.d1.loss_mask: 0.8272  decode.d1.loss_dice: 1.4461  decode.d2.loss_cls: 1.0881  decode.d2.loss_mask: 0.8083  decode.d2.loss_dice: 1.3745  decode.d3.loss_cls: 1.0578  decode.d3.loss_mask: 0.8044  decode.d3.loss_dice: 1.3375  decode.d4.loss_cls: 1.0621  decode.d4.loss_mask: 0.8110  decode.d4.loss_dice: 1.3411  decode.d5.loss_cls: 1.0712  decode.d5.loss_mask: 0.8073  decode.d5.loss_dice: 1.3437  decode.d6.loss_cls: 1.0610  decode.d6.loss_mask: 0.8070  decode.d6.loss_dice: 1.3251  decode.d7.loss_cls: 1.0669  decode.d7.loss_mask: 0.8028  decode.d7.loss_dice: 1.3322  decode.d8.loss_cls: 1.0241  decode.d8.loss_mask: 0.8127  decode.d8.loss_dice: 1.3520
2023/05/24 01:11:06 - mmengine - INFO - Iter(train) [ 56150/160000]  lr: 6.7774e-06  eta: 12:21:17  time: 0.4137  data_time: 0.0101  memory: 4836  grad_norm: 101.4116  loss: 31.6961  decode.loss_cls: 1.2000  decode.loss_mask: 0.5849  decode.loss_dice: 1.1456  decode.d0.loss_cls: 3.0881  decode.d0.loss_mask: 0.6916  decode.d0.loss_dice: 1.3067  decode.d1.loss_cls: 1.2852  decode.d1.loss_mask: 0.6561  decode.d1.loss_dice: 1.2225  decode.d2.loss_cls: 1.2340  decode.d2.loss_mask: 0.6194  decode.d2.loss_dice: 1.1701  decode.d3.loss_cls: 1.1250  decode.d3.loss_mask: 0.6459  decode.d3.loss_dice: 1.1628  decode.d4.loss_cls: 1.1591  decode.d4.loss_mask: 0.5905  decode.d4.loss_dice: 1.1584  decode.d5.loss_cls: 1.1123  decode.d5.loss_mask: 0.6463  decode.d5.loss_dice: 1.1362  decode.d6.loss_cls: 1.1171  decode.d6.loss_mask: 0.6408  decode.d6.loss_dice: 1.1554  decode.d7.loss_cls: 1.1897  decode.d7.loss_mask: 0.5945  decode.d7.loss_dice: 1.1543  decode.d8.loss_cls: 1.1297  decode.d8.loss_mask: 0.6259  decode.d8.loss_dice: 1.1483
2023/05/24 01:11:27 - mmengine - INFO - Iter(train) [ 56200/160000]  lr: 6.7744e-06  eta: 12:20:55  time: 0.4245  data_time: 0.0100  memory: 4891  grad_norm: 87.7872  loss: 36.4612  decode.loss_cls: 1.4119  decode.loss_mask: 0.6729  decode.loss_dice: 1.3322  decode.d0.loss_cls: 3.1041  decode.d0.loss_mask: 0.7544  decode.d0.loss_dice: 1.6064  decode.d1.loss_cls: 1.4848  decode.d1.loss_mask: 0.7049  decode.d1.loss_dice: 1.4442  decode.d2.loss_cls: 1.4104  decode.d2.loss_mask: 0.7205  decode.d2.loss_dice: 1.3748  decode.d3.loss_cls: 1.3681  decode.d3.loss_mask: 0.7155  decode.d3.loss_dice: 1.3764  decode.d4.loss_cls: 1.3370  decode.d4.loss_mask: 0.7093  decode.d4.loss_dice: 1.3801  decode.d5.loss_cls: 1.3658  decode.d5.loss_mask: 0.7029  decode.d5.loss_dice: 1.3834  decode.d6.loss_cls: 1.3063  decode.d6.loss_mask: 0.7004  decode.d6.loss_dice: 1.3759  decode.d7.loss_cls: 1.3248  decode.d7.loss_mask: 0.6855  decode.d7.loss_dice: 1.3668  decode.d8.loss_cls: 1.3188  decode.d8.loss_mask: 0.6906  decode.d8.loss_dice: 1.3322
2023/05/24 01:11:49 - mmengine - INFO - Iter(train) [ 56250/160000]  lr: 6.7715e-06  eta: 12:20:35  time: 0.4129  data_time: 0.0100  memory: 4826  grad_norm: 87.8248  loss: 36.5519  decode.loss_cls: 1.2807  decode.loss_mask: 0.7880  decode.loss_dice: 1.3015  decode.d0.loss_cls: 3.2032  decode.d0.loss_mask: 0.8723  decode.d0.loss_dice: 1.5419  decode.d1.loss_cls: 1.3822  decode.d1.loss_mask: 0.8678  decode.d1.loss_dice: 1.4521  decode.d2.loss_cls: 1.2842  decode.d2.loss_mask: 0.8115  decode.d2.loss_dice: 1.3730  decode.d3.loss_cls: 1.2872  decode.d3.loss_mask: 0.7875  decode.d3.loss_dice: 1.3288  decode.d4.loss_cls: 1.2871  decode.d4.loss_mask: 0.7823  decode.d4.loss_dice: 1.3266  decode.d5.loss_cls: 1.3060  decode.d5.loss_mask: 0.7932  decode.d5.loss_dice: 1.3083  decode.d6.loss_cls: 1.2739  decode.d6.loss_mask: 0.8165  decode.d6.loss_dice: 1.3067  decode.d7.loss_cls: 1.3304  decode.d7.loss_mask: 0.7995  decode.d7.loss_dice: 1.2986  decode.d8.loss_cls: 1.2674  decode.d8.loss_mask: 0.7830  decode.d8.loss_dice: 1.3106
2023/05/24 01:12:10 - mmengine - INFO - Iter(train) [ 56300/160000]  lr: 6.7685e-06  eta: 12:20:14  time: 0.4199  data_time: 0.0100  memory: 4916  grad_norm: 85.3415  loss: 27.0012  decode.loss_cls: 0.9334  decode.loss_mask: 0.5129  decode.loss_dice: 0.9637  decode.d0.loss_cls: 2.8643  decode.d0.loss_mask: 0.5953  decode.d0.loss_dice: 1.1937  decode.d1.loss_cls: 1.0317  decode.d1.loss_mask: 0.5793  decode.d1.loss_dice: 1.0772  decode.d2.loss_cls: 0.9477  decode.d2.loss_mask: 0.5396  decode.d2.loss_dice: 1.0386  decode.d3.loss_cls: 1.0389  decode.d3.loss_mask: 0.5035  decode.d3.loss_dice: 0.9729  decode.d4.loss_cls: 0.9922  decode.d4.loss_mask: 0.5054  decode.d4.loss_dice: 0.9711  decode.d5.loss_cls: 0.9617  decode.d5.loss_mask: 0.5152  decode.d5.loss_dice: 0.9860  decode.d6.loss_cls: 0.9520  decode.d6.loss_mask: 0.5261  decode.d6.loss_dice: 0.9608  decode.d7.loss_cls: 0.9259  decode.d7.loss_mask: 0.5211  decode.d7.loss_dice: 0.9704  decode.d8.loss_cls: 0.9268  decode.d8.loss_mask: 0.5186  decode.d8.loss_dice: 0.9751
2023/05/24 01:12:31 - mmengine - INFO - Iter(train) [ 56350/160000]  lr: 6.7656e-06  eta: 12:19:51  time: 0.4144  data_time: 0.0101  memory: 4875  grad_norm: 121.6706  loss: 42.3908  decode.loss_cls: 1.4901  decode.loss_mask: 0.8329  decode.loss_dice: 1.5664  decode.d0.loss_cls: 3.3523  decode.d0.loss_mask: 0.9208  decode.d0.loss_dice: 1.8869  decode.d1.loss_cls: 1.6279  decode.d1.loss_mask: 0.8784  decode.d1.loss_dice: 1.7584  decode.d2.loss_cls: 1.5727  decode.d2.loss_mask: 0.8951  decode.d2.loss_dice: 1.7180  decode.d3.loss_cls: 1.5098  decode.d3.loss_mask: 0.8426  decode.d3.loss_dice: 1.6949  decode.d4.loss_cls: 1.5029  decode.d4.loss_mask: 0.8840  decode.d4.loss_dice: 1.6437  decode.d5.loss_cls: 1.5020  decode.d5.loss_mask: 0.8568  decode.d5.loss_dice: 1.5916  decode.d6.loss_cls: 1.5119  decode.d6.loss_mask: 0.8430  decode.d6.loss_dice: 1.5429  decode.d7.loss_cls: 1.5281  decode.d7.loss_mask: 0.8508  decode.d7.loss_dice: 1.5832  decode.d8.loss_cls: 1.5761  decode.d8.loss_mask: 0.8487  decode.d8.loss_dice: 1.5776
2023/05/24 01:12:53 - mmengine - INFO - Iter(train) [ 56400/160000]  lr: 6.7627e-06  eta: 12:19:29  time: 0.4149  data_time: 0.0100  memory: 4820  grad_norm: 88.8592  loss: 38.9128  decode.loss_cls: 1.4314  decode.loss_mask: 0.7561  decode.loss_dice: 1.4089  decode.d0.loss_cls: 3.3744  decode.d0.loss_mask: 0.7587  decode.d0.loss_dice: 1.5804  decode.d1.loss_cls: 1.6736  decode.d1.loss_mask: 0.8086  decode.d1.loss_dice: 1.4895  decode.d2.loss_cls: 1.5828  decode.d2.loss_mask: 0.7542  decode.d2.loss_dice: 1.4517  decode.d3.loss_cls: 1.5648  decode.d3.loss_mask: 0.7273  decode.d3.loss_dice: 1.4371  decode.d4.loss_cls: 1.4933  decode.d4.loss_mask: 0.7474  decode.d4.loss_dice: 1.4327  decode.d5.loss_cls: 1.5099  decode.d5.loss_mask: 0.7591  decode.d5.loss_dice: 1.4174  decode.d6.loss_cls: 1.4215  decode.d6.loss_mask: 0.7634  decode.d6.loss_dice: 1.4093  decode.d7.loss_cls: 1.3728  decode.d7.loss_mask: 0.7787  decode.d7.loss_dice: 1.4032  decode.d8.loss_cls: 1.4293  decode.d8.loss_mask: 0.7744  decode.d8.loss_dice: 1.4007
2023/05/24 01:13:14 - mmengine - INFO - Iter(train) [ 56450/160000]  lr: 6.7597e-06  eta: 12:19:07  time: 0.4252  data_time: 0.0102  memory: 4925  grad_norm: 86.0276  loss: 37.8082  decode.loss_cls: 1.1934  decode.loss_mask: 0.8472  decode.loss_dice: 1.4216  decode.d0.loss_cls: 3.0314  decode.d0.loss_mask: 0.9778  decode.d0.loss_dice: 1.6635  decode.d1.loss_cls: 1.3723  decode.d1.loss_mask: 0.9134  decode.d1.loss_dice: 1.4980  decode.d2.loss_cls: 1.3062  decode.d2.loss_mask: 0.8810  decode.d2.loss_dice: 1.4923  decode.d3.loss_cls: 1.2657  decode.d3.loss_mask: 0.8525  decode.d3.loss_dice: 1.4367  decode.d4.loss_cls: 1.2305  decode.d4.loss_mask: 0.8510  decode.d4.loss_dice: 1.4816  decode.d5.loss_cls: 1.2417  decode.d5.loss_mask: 0.8353  decode.d5.loss_dice: 1.4657  decode.d6.loss_cls: 1.2035  decode.d6.loss_mask: 0.8506  decode.d6.loss_dice: 1.4368  decode.d7.loss_cls: 1.2164  decode.d7.loss_mask: 0.8601  decode.d7.loss_dice: 1.4657  decode.d8.loss_cls: 1.2443  decode.d8.loss_mask: 0.8414  decode.d8.loss_dice: 1.4305
2023/05/24 01:13:35 - mmengine - INFO - Iter(train) [ 56500/160000]  lr: 6.7568e-06  eta: 12:18:47  time: 0.4125  data_time: 0.0100  memory: 4919  grad_norm: 91.3659  loss: 43.6580  decode.loss_cls: 1.5495  decode.loss_mask: 0.8812  decode.loss_dice: 1.6517  decode.d0.loss_cls: 3.4297  decode.d0.loss_mask: 0.9713  decode.d0.loss_dice: 1.8986  decode.d1.loss_cls: 1.7025  decode.d1.loss_mask: 0.9498  decode.d1.loss_dice: 1.7870  decode.d2.loss_cls: 1.5969  decode.d2.loss_mask: 0.9269  decode.d2.loss_dice: 1.7476  decode.d3.loss_cls: 1.6264  decode.d3.loss_mask: 0.9004  decode.d3.loss_dice: 1.6462  decode.d4.loss_cls: 1.5295  decode.d4.loss_mask: 0.9165  decode.d4.loss_dice: 1.6485  decode.d5.loss_cls: 1.6062  decode.d5.loss_mask: 0.8937  decode.d5.loss_dice: 1.6433  decode.d6.loss_cls: 1.5470  decode.d6.loss_mask: 0.8634  decode.d6.loss_dice: 1.6162  decode.d7.loss_cls: 1.5240  decode.d7.loss_mask: 0.8833  decode.d7.loss_dice: 1.6610  decode.d8.loss_cls: 1.4991  decode.d8.loss_mask: 0.8869  decode.d8.loss_dice: 1.6738
2023/05/24 01:13:57 - mmengine - INFO - Iter(train) [ 56550/160000]  lr: 6.7539e-06  eta: 12:18:26  time: 0.4132  data_time: 0.0105  memory: 4906  grad_norm: 94.3885  loss: 38.1449  decode.loss_cls: 1.4855  decode.loss_mask: 0.7567  decode.loss_dice: 1.3337  decode.d0.loss_cls: 3.4897  decode.d0.loss_mask: 0.7731  decode.d0.loss_dice: 1.5447  decode.d1.loss_cls: 1.4275  decode.d1.loss_mask: 0.8152  decode.d1.loss_dice: 1.5182  decode.d2.loss_cls: 1.4510  decode.d2.loss_mask: 0.7922  decode.d2.loss_dice: 1.4511  decode.d3.loss_cls: 1.4805  decode.d3.loss_mask: 0.7502  decode.d3.loss_dice: 1.3439  decode.d4.loss_cls: 1.4809  decode.d4.loss_mask: 0.7273  decode.d4.loss_dice: 1.3677  decode.d5.loss_cls: 1.5098  decode.d5.loss_mask: 0.7175  decode.d5.loss_dice: 1.3301  decode.d6.loss_cls: 1.4273  decode.d6.loss_mask: 0.7607  decode.d6.loss_dice: 1.3313  decode.d7.loss_cls: 1.4290  decode.d7.loss_mask: 0.7472  decode.d7.loss_dice: 1.3271  decode.d8.loss_cls: 1.5175  decode.d8.loss_mask: 0.7444  decode.d8.loss_dice: 1.3138
2023/05/24 01:14:18 - mmengine - INFO - Iter(train) [ 56600/160000]  lr: 6.7509e-06  eta: 12:18:03  time: 0.4199  data_time: 0.0102  memory: 4843  grad_norm: 123.4824  loss: 38.7009  decode.loss_cls: 1.4280  decode.loss_mask: 0.8213  decode.loss_dice: 1.3565  decode.d0.loss_cls: 3.1785  decode.d0.loss_mask: 0.8913  decode.d0.loss_dice: 1.6240  decode.d1.loss_cls: 1.4898  decode.d1.loss_mask: 0.8697  decode.d1.loss_dice: 1.5154  decode.d2.loss_cls: 1.3659  decode.d2.loss_mask: 0.8579  decode.d2.loss_dice: 1.4820  decode.d3.loss_cls: 1.4251  decode.d3.loss_mask: 0.8355  decode.d3.loss_dice: 1.4518  decode.d4.loss_cls: 1.4124  decode.d4.loss_mask: 0.8314  decode.d4.loss_dice: 1.4084  decode.d5.loss_cls: 1.4199  decode.d5.loss_mask: 0.8160  decode.d5.loss_dice: 1.3802  decode.d6.loss_cls: 1.4126  decode.d6.loss_mask: 0.8258  decode.d6.loss_dice: 1.3807  decode.d7.loss_cls: 1.4289  decode.d7.loss_mask: 0.8179  decode.d7.loss_dice: 1.4120  decode.d8.loss_cls: 1.4015  decode.d8.loss_mask: 0.8197  decode.d8.loss_dice: 1.3410
2023/05/24 01:14:39 - mmengine - INFO - Iter(train) [ 56650/160000]  lr: 6.7480e-06  eta: 12:17:41  time: 0.4213  data_time: 0.0102  memory: 4847  grad_norm: 91.4786  loss: 35.8943  decode.loss_cls: 1.2171  decode.loss_mask: 0.8057  decode.loss_dice: 1.2174  decode.d0.loss_cls: 3.2365  decode.d0.loss_mask: 0.8785  decode.d0.loss_dice: 1.4431  decode.d1.loss_cls: 1.3128  decode.d1.loss_mask: 0.9165  decode.d1.loss_dice: 1.3623  decode.d2.loss_cls: 1.2700  decode.d2.loss_mask: 0.8742  decode.d2.loss_dice: 1.3410  decode.d3.loss_cls: 1.3182  decode.d3.loss_mask: 0.8646  decode.d3.loss_dice: 1.2647  decode.d4.loss_cls: 1.2780  decode.d4.loss_mask: 0.8232  decode.d4.loss_dice: 1.2675  decode.d5.loss_cls: 1.2522  decode.d5.loss_mask: 0.8418  decode.d5.loss_dice: 1.2440  decode.d6.loss_cls: 1.2389  decode.d6.loss_mask: 0.8212  decode.d6.loss_dice: 1.2183  decode.d7.loss_cls: 1.2518  decode.d7.loss_mask: 0.8268  decode.d7.loss_dice: 1.2071  decode.d8.loss_cls: 1.2197  decode.d8.loss_mask: 0.8185  decode.d8.loss_dice: 1.2626
2023/05/24 01:15:00 - mmengine - INFO - Iter(train) [ 56700/160000]  lr: 6.7450e-06  eta: 12:17:18  time: 0.4146  data_time: 0.0108  memory: 4896  grad_norm: 104.9382  loss: 28.7431  decode.loss_cls: 0.9655  decode.loss_mask: 0.7025  decode.loss_dice: 0.9555  decode.d0.loss_cls: 2.6661  decode.d0.loss_mask: 0.7598  decode.d0.loss_dice: 1.1118  decode.d1.loss_cls: 1.1199  decode.d1.loss_mask: 0.7477  decode.d1.loss_dice: 1.0675  decode.d2.loss_cls: 1.0296  decode.d2.loss_mask: 0.7381  decode.d2.loss_dice: 1.0203  decode.d3.loss_cls: 1.0074  decode.d3.loss_mask: 0.7437  decode.d3.loss_dice: 1.0120  decode.d4.loss_cls: 0.9999  decode.d4.loss_mask: 0.7170  decode.d4.loss_dice: 0.9958  decode.d5.loss_cls: 0.9642  decode.d5.loss_mask: 0.6932  decode.d5.loss_dice: 0.9951  decode.d6.loss_cls: 0.9233  decode.d6.loss_mask: 0.6821  decode.d6.loss_dice: 0.9842  decode.d7.loss_cls: 0.8903  decode.d7.loss_mask: 0.6811  decode.d7.loss_dice: 0.9672  decode.d8.loss_cls: 0.9056  decode.d8.loss_mask: 0.7130  decode.d8.loss_dice: 0.9838
2023/05/24 01:15:21 - mmengine - INFO - Iter(train) [ 56750/160000]  lr: 6.7421e-06  eta: 12:16:56  time: 0.4223  data_time: 0.0101  memory: 4836  grad_norm: 104.0276  loss: 30.9683  decode.loss_cls: 0.9881  decode.loss_mask: 0.6886  decode.loss_dice: 1.1827  decode.d0.loss_cls: 2.7901  decode.d0.loss_mask: 0.7742  decode.d0.loss_dice: 1.3265  decode.d1.loss_cls: 1.1389  decode.d1.loss_mask: 0.7010  decode.d1.loss_dice: 1.2831  decode.d2.loss_cls: 0.9524  decode.d2.loss_mask: 0.7361  decode.d2.loss_dice: 1.2448  decode.d3.loss_cls: 1.0063  decode.d3.loss_mask: 0.6900  decode.d3.loss_dice: 1.1967  decode.d4.loss_cls: 0.9852  decode.d4.loss_mask: 0.6884  decode.d4.loss_dice: 1.2097  decode.d5.loss_cls: 0.9674  decode.d5.loss_mask: 0.6969  decode.d5.loss_dice: 1.1734  decode.d6.loss_cls: 0.9785  decode.d6.loss_mask: 0.6806  decode.d6.loss_dice: 1.2154  decode.d7.loss_cls: 0.9439  decode.d7.loss_mask: 0.6852  decode.d7.loss_dice: 1.2000  decode.d8.loss_cls: 0.9673  decode.d8.loss_mask: 0.6880  decode.d8.loss_dice: 1.1887
2023/05/24 01:15:41 - mmengine - INFO - Iter(train) [ 56800/160000]  lr: 6.7392e-06  eta: 12:16:34  time: 0.4099  data_time: 0.0101  memory: 4908  grad_norm: 87.8951  loss: 41.1925  decode.loss_cls: 1.6022  decode.loss_mask: 0.8018  decode.loss_dice: 1.3790  decode.d0.loss_cls: 3.4513  decode.d0.loss_mask: 0.9550  decode.d0.loss_dice: 1.7850  decode.d1.loss_cls: 1.6503  decode.d1.loss_mask: 0.9314  decode.d1.loss_dice: 1.6152  decode.d2.loss_cls: 1.7228  decode.d2.loss_mask: 0.8540  decode.d2.loss_dice: 1.5044  decode.d3.loss_cls: 1.6143  decode.d3.loss_mask: 0.8345  decode.d3.loss_dice: 1.4797  decode.d4.loss_cls: 1.5655  decode.d4.loss_mask: 0.8128  decode.d4.loss_dice: 1.4692  decode.d5.loss_cls: 1.5336  decode.d5.loss_mask: 0.7890  decode.d5.loss_dice: 1.4045  decode.d6.loss_cls: 1.5945  decode.d6.loss_mask: 0.8192  decode.d6.loss_dice: 1.3976  decode.d7.loss_cls: 1.5973  decode.d7.loss_mask: 0.8162  decode.d7.loss_dice: 1.4038  decode.d8.loss_cls: 1.5562  decode.d8.loss_mask: 0.8621  decode.d8.loss_dice: 1.3900
2023/05/24 01:16:02 - mmengine - INFO - Iter(train) [ 56850/160000]  lr: 6.7362e-06  eta: 12:16:11  time: 0.4177  data_time: 0.0101  memory: 4804  grad_norm: 88.7091  loss: 26.2420  decode.loss_cls: 0.8980  decode.loss_mask: 0.6840  decode.loss_dice: 0.7873  decode.d0.loss_cls: 2.7950  decode.d0.loss_mask: 0.7370  decode.d0.loss_dice: 0.8942  decode.d1.loss_cls: 1.0315  decode.d1.loss_mask: 0.7632  decode.d1.loss_dice: 0.8371  decode.d2.loss_cls: 0.9752  decode.d2.loss_mask: 0.7286  decode.d2.loss_dice: 0.8101  decode.d3.loss_cls: 0.9633  decode.d3.loss_mask: 0.7017  decode.d3.loss_dice: 0.7723  decode.d4.loss_cls: 0.9411  decode.d4.loss_mask: 0.6863  decode.d4.loss_dice: 0.7736  decode.d5.loss_cls: 0.8835  decode.d5.loss_mask: 0.7159  decode.d5.loss_dice: 0.8014  decode.d6.loss_cls: 0.8813  decode.d6.loss_mask: 0.7045  decode.d6.loss_dice: 0.7853  decode.d7.loss_cls: 0.8766  decode.d7.loss_mask: 0.7005  decode.d7.loss_dice: 0.7823  decode.d8.loss_cls: 0.8596  decode.d8.loss_mask: 0.6814  decode.d8.loss_dice: 0.7901
2023/05/24 01:16:25 - mmengine - INFO - Iter(train) [ 56900/160000]  lr: 6.7333e-06  eta: 12:15:52  time: 0.4758  data_time: 0.0108  memory: 4819  grad_norm: 100.1016  loss: 31.2089  decode.loss_cls: 1.0674  decode.loss_mask: 0.7524  decode.loss_dice: 1.0431  decode.d0.loss_cls: 2.9908  decode.d0.loss_mask: 0.7208  decode.d0.loss_dice: 1.1400  decode.d1.loss_cls: 1.1548  decode.d1.loss_mask: 0.7514  decode.d1.loss_dice: 1.1620  decode.d2.loss_cls: 1.0680  decode.d2.loss_mask: 0.7404  decode.d2.loss_dice: 1.1392  decode.d3.loss_cls: 1.1446  decode.d3.loss_mask: 0.7350  decode.d3.loss_dice: 1.0687  decode.d4.loss_cls: 1.1097  decode.d4.loss_mask: 0.7237  decode.d4.loss_dice: 1.0654  decode.d5.loss_cls: 1.0991  decode.d5.loss_mask: 0.7398  decode.d5.loss_dice: 1.0732  decode.d6.loss_cls: 1.1145  decode.d6.loss_mask: 0.7527  decode.d6.loss_dice: 1.0543  decode.d7.loss_cls: 1.1164  decode.d7.loss_mask: 0.7383  decode.d7.loss_dice: 1.0518  decode.d8.loss_cls: 1.0716  decode.d8.loss_mask: 0.7410  decode.d8.loss_dice: 1.0786
2023/05/24 01:16:47 - mmengine - INFO - Iter(train) [ 56950/160000]  lr: 6.7304e-06  eta: 12:15:32  time: 0.4166  data_time: 0.0104  memory: 4847  grad_norm: 101.7381  loss: 37.2856  decode.loss_cls: 1.2535  decode.loss_mask: 0.7086  decode.loss_dice: 1.3685  decode.d0.loss_cls: 3.3867  decode.d0.loss_mask: 0.8067  decode.d0.loss_dice: 1.5992  decode.d1.loss_cls: 1.5135  decode.d1.loss_mask: 0.7615  decode.d1.loss_dice: 1.5051  decode.d2.loss_cls: 1.5053  decode.d2.loss_mask: 0.7300  decode.d2.loss_dice: 1.4191  decode.d3.loss_cls: 1.3871  decode.d3.loss_mask: 0.7279  decode.d3.loss_dice: 1.4079  decode.d4.loss_cls: 1.4099  decode.d4.loss_mask: 0.7260  decode.d4.loss_dice: 1.3874  decode.d5.loss_cls: 1.3433  decode.d5.loss_mask: 0.7356  decode.d5.loss_dice: 1.3878  decode.d6.loss_cls: 1.3556  decode.d6.loss_mask: 0.7108  decode.d6.loss_dice: 1.3481  decode.d7.loss_cls: 1.3426  decode.d7.loss_mask: 0.7118  decode.d7.loss_dice: 1.3674  decode.d8.loss_cls: 1.3042  decode.d8.loss_mask: 0.7055  decode.d8.loss_dice: 1.3687
2023/05/24 01:17:10 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 01:17:10 - mmengine - INFO - Iter(train) [ 57000/160000]  lr: 6.7274e-06  eta: 12:15:12  time: 0.4112  data_time: 0.0105  memory: 4857  grad_norm: 98.9947  loss: 32.7038  decode.loss_cls: 1.1761  decode.loss_mask: 0.6698  decode.loss_dice: 1.1179  decode.d0.loss_cls: 2.9745  decode.d0.loss_mask: 0.8161  decode.d0.loss_dice: 1.2884  decode.d1.loss_cls: 1.2933  decode.d1.loss_mask: 0.7852  decode.d1.loss_dice: 1.1758  decode.d2.loss_cls: 1.2888  decode.d2.loss_mask: 0.6910  decode.d2.loss_dice: 1.1483  decode.d3.loss_cls: 1.2062  decode.d3.loss_mask: 0.6956  decode.d3.loss_dice: 1.1535  decode.d4.loss_cls: 1.1668  decode.d4.loss_mask: 0.7147  decode.d4.loss_dice: 1.1502  decode.d5.loss_cls: 1.2002  decode.d5.loss_mask: 0.7103  decode.d5.loss_dice: 1.1017  decode.d6.loss_cls: 1.2511  decode.d6.loss_mask: 0.6848  decode.d6.loss_dice: 1.1265  decode.d7.loss_cls: 1.2902  decode.d7.loss_mask: 0.6938  decode.d7.loss_dice: 1.1281  decode.d8.loss_cls: 1.1714  decode.d8.loss_mask: 0.6884  decode.d8.loss_dice: 1.1454
2023/05/24 01:17:10 - mmengine - INFO - Saving checkpoint at 57000 iterations
2023/05/24 01:17:37 - mmengine - INFO - Iter(train) [ 57050/160000]  lr: 6.7245e-06  eta: 12:15:02  time: 0.4298  data_time: 0.0101  memory: 4898  grad_norm: 81.4557  loss: 31.9435  decode.loss_cls: 1.2358  decode.loss_mask: 0.7089  decode.loss_dice: 1.0347  decode.d0.loss_cls: 2.8980  decode.d0.loss_mask: 0.7526  decode.d0.loss_dice: 1.1384  decode.d1.loss_cls: 1.2183  decode.d1.loss_mask: 0.7750  decode.d1.loss_dice: 1.0741  decode.d2.loss_cls: 1.2913  decode.d2.loss_mask: 0.7263  decode.d2.loss_dice: 1.0853  decode.d3.loss_cls: 1.2406  decode.d3.loss_mask: 0.7554  decode.d3.loss_dice: 1.0332  decode.d4.loss_cls: 1.2621  decode.d4.loss_mask: 0.7656  decode.d4.loss_dice: 1.0379  decode.d5.loss_cls: 1.2203  decode.d5.loss_mask: 0.7347  decode.d5.loss_dice: 1.0292  decode.d6.loss_cls: 1.2416  decode.d6.loss_mask: 0.7202  decode.d6.loss_dice: 1.0139  decode.d7.loss_cls: 1.2419  decode.d7.loss_mask: 0.7180  decode.d7.loss_dice: 1.0138  decode.d8.loss_cls: 1.2421  decode.d8.loss_mask: 0.7199  decode.d8.loss_dice: 1.0143
2023/05/24 01:17:58 - mmengine - INFO - Iter(train) [ 57100/160000]  lr: 6.7215e-06  eta: 12:14:40  time: 0.4503  data_time: 0.0104  memory: 4895  grad_norm: 113.8082  loss: 26.6627  decode.loss_cls: 1.0131  decode.loss_mask: 0.5859  decode.loss_dice: 0.8664  decode.d0.loss_cls: 2.9208  decode.d0.loss_mask: 0.5759  decode.d0.loss_dice: 1.0482  decode.d1.loss_cls: 1.1234  decode.d1.loss_mask: 0.5488  decode.d1.loss_dice: 0.9333  decode.d2.loss_cls: 1.0211  decode.d2.loss_mask: 0.5532  decode.d2.loss_dice: 0.8971  decode.d3.loss_cls: 1.0283  decode.d3.loss_mask: 0.5326  decode.d3.loss_dice: 0.8438  decode.d4.loss_cls: 1.0644  decode.d4.loss_mask: 0.5211  decode.d4.loss_dice: 0.8468  decode.d5.loss_cls: 1.0085  decode.d5.loss_mask: 0.5370  decode.d5.loss_dice: 0.8857  decode.d6.loss_cls: 1.0864  decode.d6.loss_mask: 0.5247  decode.d6.loss_dice: 0.8897  decode.d7.loss_cls: 1.0267  decode.d7.loss_mask: 0.5371  decode.d7.loss_dice: 0.8687  decode.d8.loss_cls: 0.9945  decode.d8.loss_mask: 0.5299  decode.d8.loss_dice: 0.8495
2023/05/24 01:18:20 - mmengine - INFO - Iter(train) [ 57150/160000]  lr: 6.7186e-06  eta: 12:14:19  time: 0.4165  data_time: 0.0103  memory: 4836  grad_norm: 96.6030  loss: 37.0265  decode.loss_cls: 1.1978  decode.loss_mask: 0.7883  decode.loss_dice: 1.3864  decode.d0.loss_cls: 3.4472  decode.d0.loss_mask: 0.8426  decode.d0.loss_dice: 1.5529  decode.d1.loss_cls: 1.4568  decode.d1.loss_mask: 0.8162  decode.d1.loss_dice: 1.5192  decode.d2.loss_cls: 1.3246  decode.d2.loss_mask: 0.8051  decode.d2.loss_dice: 1.4595  decode.d3.loss_cls: 1.2630  decode.d3.loss_mask: 0.7896  decode.d3.loss_dice: 1.3896  decode.d4.loss_cls: 1.2049  decode.d4.loss_mask: 0.7719  decode.d4.loss_dice: 1.4060  decode.d5.loss_cls: 1.2007  decode.d5.loss_mask: 0.7860  decode.d5.loss_dice: 1.3800  decode.d6.loss_cls: 1.2514  decode.d6.loss_mask: 0.7957  decode.d6.loss_dice: 1.3859  decode.d7.loss_cls: 1.1746  decode.d7.loss_mask: 0.7837  decode.d7.loss_dice: 1.4261  decode.d8.loss_cls: 1.2137  decode.d8.loss_mask: 0.8031  decode.d8.loss_dice: 1.4043
2023/05/24 01:18:40 - mmengine - INFO - Iter(train) [ 57200/160000]  lr: 6.7157e-06  eta: 12:13:56  time: 0.4120  data_time: 0.0099  memory: 4917  grad_norm: 109.8549  loss: 31.7265  decode.loss_cls: 1.1093  decode.loss_mask: 0.7639  decode.loss_dice: 1.0837  decode.d0.loss_cls: 2.6631  decode.d0.loss_mask: 0.7860  decode.d0.loss_dice: 1.2751  decode.d1.loss_cls: 1.1761  decode.d1.loss_mask: 0.8018  decode.d1.loss_dice: 1.2372  decode.d2.loss_cls: 1.1110  decode.d2.loss_mask: 0.8012  decode.d2.loss_dice: 1.1839  decode.d3.loss_cls: 1.1620  decode.d3.loss_mask: 0.7816  decode.d3.loss_dice: 1.0722  decode.d4.loss_cls: 1.1070  decode.d4.loss_mask: 0.7860  decode.d4.loss_dice: 1.1174  decode.d5.loss_cls: 1.1157  decode.d5.loss_mask: 0.7465  decode.d5.loss_dice: 1.0768  decode.d6.loss_cls: 1.1099  decode.d6.loss_mask: 0.7450  decode.d6.loss_dice: 1.0947  decode.d7.loss_cls: 1.0812  decode.d7.loss_mask: 0.7570  decode.d7.loss_dice: 1.0730  decode.d8.loss_cls: 1.0443  decode.d8.loss_mask: 0.7638  decode.d8.loss_dice: 1.1002
2023/05/24 01:19:02 - mmengine - INFO - Iter(train) [ 57250/160000]  lr: 6.7127e-06  eta: 12:13:34  time: 0.4270  data_time: 0.0101  memory: 4845  grad_norm: 131.6805  loss: 30.2073  decode.loss_cls: 1.0410  decode.loss_mask: 0.7367  decode.loss_dice: 0.9908  decode.d0.loss_cls: 3.0494  decode.d0.loss_mask: 0.7881  decode.d0.loss_dice: 1.1742  decode.d1.loss_cls: 1.0819  decode.d1.loss_mask: 0.7225  decode.d1.loss_dice: 1.0514  decode.d2.loss_cls: 1.0622  decode.d2.loss_mask: 0.7143  decode.d2.loss_dice: 1.0126  decode.d3.loss_cls: 1.0791  decode.d3.loss_mask: 0.7327  decode.d3.loss_dice: 1.0035  decode.d4.loss_cls: 1.0593  decode.d4.loss_mask: 0.7420  decode.d4.loss_dice: 1.0217  decode.d5.loss_cls: 1.0677  decode.d5.loss_mask: 0.7341  decode.d5.loss_dice: 0.9986  decode.d6.loss_cls: 1.0945  decode.d6.loss_mask: 0.7283  decode.d6.loss_dice: 0.9962  decode.d7.loss_cls: 1.0778  decode.d7.loss_mask: 0.7150  decode.d7.loss_dice: 0.9783  decode.d8.loss_cls: 1.0526  decode.d8.loss_mask: 0.7243  decode.d8.loss_dice: 0.9765
2023/05/24 01:19:25 - mmengine - INFO - Iter(train) [ 57300/160000]  lr: 6.7098e-06  eta: 12:13:16  time: 0.4768  data_time: 0.0098  memory: 4877  grad_norm: 81.4435  loss: 50.4124  decode.loss_cls: 1.7619  decode.loss_mask: 0.8963  decode.loss_dice: 1.9761  decode.d0.loss_cls: 3.7283  decode.d0.loss_mask: 0.9811  decode.d0.loss_dice: 2.3681  decode.d1.loss_cls: 1.9489  decode.d1.loss_mask: 1.0004  decode.d1.loss_dice: 2.2330  decode.d2.loss_cls: 1.8834  decode.d2.loss_mask: 0.9771  decode.d2.loss_dice: 2.1415  decode.d3.loss_cls: 1.8491  decode.d3.loss_mask: 0.9326  decode.d3.loss_dice: 2.0949  decode.d4.loss_cls: 1.8049  decode.d4.loss_mask: 0.9430  decode.d4.loss_dice: 2.0364  decode.d5.loss_cls: 1.8442  decode.d5.loss_mask: 0.9553  decode.d5.loss_dice: 2.0344  decode.d6.loss_cls: 1.7865  decode.d6.loss_mask: 0.9153  decode.d6.loss_dice: 1.9762  decode.d7.loss_cls: 1.8212  decode.d7.loss_mask: 0.9023  decode.d7.loss_dice: 1.9740  decode.d8.loss_cls: 1.7839  decode.d8.loss_mask: 0.8956  decode.d8.loss_dice: 1.9664
2023/05/24 01:19:48 - mmengine - INFO - Iter(train) [ 57350/160000]  lr: 6.7068e-06  eta: 12:12:58  time: 0.4695  data_time: 0.0102  memory: 4821  grad_norm: 100.0764  loss: 33.1769  decode.loss_cls: 1.0527  decode.loss_mask: 0.7242  decode.loss_dice: 1.2741  decode.d0.loss_cls: 3.0665  decode.d0.loss_mask: 0.7205  decode.d0.loss_dice: 1.4215  decode.d1.loss_cls: 1.2013  decode.d1.loss_mask: 0.7474  decode.d1.loss_dice: 1.3481  decode.d2.loss_cls: 1.1320  decode.d2.loss_mask: 0.7267  decode.d2.loss_dice: 1.3035  decode.d3.loss_cls: 1.1392  decode.d3.loss_mask: 0.7472  decode.d3.loss_dice: 1.2906  decode.d4.loss_cls: 1.0619  decode.d4.loss_mask: 0.7633  decode.d4.loss_dice: 1.2848  decode.d5.loss_cls: 1.0584  decode.d5.loss_mask: 0.7134  decode.d5.loss_dice: 1.2692  decode.d6.loss_cls: 1.0464  decode.d6.loss_mask: 0.7304  decode.d6.loss_dice: 1.2972  decode.d7.loss_cls: 1.0552  decode.d7.loss_mask: 0.7252  decode.d7.loss_dice: 1.2420  decode.d8.loss_cls: 1.0202  decode.d8.loss_mask: 0.7198  decode.d8.loss_dice: 1.2940
2023/05/24 01:20:10 - mmengine - INFO - Iter(train) [ 57400/160000]  lr: 6.7039e-06  eta: 12:12:37  time: 0.4194  data_time: 0.0100  memory: 4824  grad_norm: 99.5350  loss: 45.2826  decode.loss_cls: 1.5703  decode.loss_mask: 1.0347  decode.loss_dice: 1.6261  decode.d0.loss_cls: 3.6102  decode.d0.loss_mask: 0.9986  decode.d0.loss_dice: 1.8849  decode.d1.loss_cls: 1.6222  decode.d1.loss_mask: 1.0900  decode.d1.loss_dice: 1.7651  decode.d2.loss_cls: 1.6125  decode.d2.loss_mask: 1.0028  decode.d2.loss_dice: 1.7255  decode.d3.loss_cls: 1.7456  decode.d3.loss_mask: 0.9814  decode.d3.loss_dice: 1.6899  decode.d4.loss_cls: 1.6451  decode.d4.loss_mask: 1.0383  decode.d4.loss_dice: 1.6669  decode.d5.loss_cls: 1.6106  decode.d5.loss_mask: 1.0162  decode.d5.loss_dice: 1.6510  decode.d6.loss_cls: 1.6306  decode.d6.loss_mask: 0.9800  decode.d6.loss_dice: 1.6018  decode.d7.loss_cls: 1.6509  decode.d7.loss_mask: 0.9934  decode.d7.loss_dice: 1.5889  decode.d8.loss_cls: 1.6059  decode.d8.loss_mask: 1.0195  decode.d8.loss_dice: 1.6238
2023/05/24 01:20:31 - mmengine - INFO - Iter(train) [ 57450/160000]  lr: 6.7010e-06  eta: 12:12:14  time: 0.4110  data_time: 0.0101  memory: 4865  grad_norm: 85.4066  loss: 35.6759  decode.loss_cls: 1.2686  decode.loss_mask: 0.6072  decode.loss_dice: 1.3966  decode.d0.loss_cls: 3.0001  decode.d0.loss_mask: 0.6371  decode.d0.loss_dice: 1.5945  decode.d1.loss_cls: 1.5186  decode.d1.loss_mask: 0.6551  decode.d1.loss_dice: 1.5089  decode.d2.loss_cls: 1.4822  decode.d2.loss_mask: 0.6166  decode.d2.loss_dice: 1.4539  decode.d3.loss_cls: 1.3654  decode.d3.loss_mask: 0.6360  decode.d3.loss_dice: 1.4095  decode.d4.loss_cls: 1.3641  decode.d4.loss_mask: 0.6469  decode.d4.loss_dice: 1.4469  decode.d5.loss_cls: 1.2596  decode.d5.loss_mask: 0.6442  decode.d5.loss_dice: 1.3964  decode.d6.loss_cls: 1.2622  decode.d6.loss_mask: 0.6086  decode.d6.loss_dice: 1.3754  decode.d7.loss_cls: 1.2891  decode.d7.loss_mask: 0.6083  decode.d7.loss_dice: 1.3837  decode.d8.loss_cls: 1.2334  decode.d8.loss_mask: 0.6157  decode.d8.loss_dice: 1.3914
2023/05/24 01:20:51 - mmengine - INFO - Iter(train) [ 57500/160000]  lr: 6.6980e-06  eta: 12:11:51  time: 0.4206  data_time: 0.0106  memory: 4859  grad_norm: 89.4508  loss: 33.1952  decode.loss_cls: 1.1323  decode.loss_mask: 0.7224  decode.loss_dice: 1.2044  decode.d0.loss_cls: 3.0424  decode.d0.loss_mask: 0.7511  decode.d0.loss_dice: 1.2851  decode.d1.loss_cls: 1.2976  decode.d1.loss_mask: 0.7150  decode.d1.loss_dice: 1.2725  decode.d2.loss_cls: 1.2618  decode.d2.loss_mask: 0.7621  decode.d2.loss_dice: 1.2320  decode.d3.loss_cls: 1.1895  decode.d3.loss_mask: 0.7695  decode.d3.loss_dice: 1.1781  decode.d4.loss_cls: 1.1677  decode.d4.loss_mask: 0.7457  decode.d4.loss_dice: 1.2015  decode.d5.loss_cls: 1.1970  decode.d5.loss_mask: 0.7595  decode.d5.loss_dice: 1.1572  decode.d6.loss_cls: 1.1345  decode.d6.loss_mask: 0.7808  decode.d6.loss_dice: 1.1717  decode.d7.loss_cls: 1.1775  decode.d7.loss_mask: 0.7513  decode.d7.loss_dice: 1.1114  decode.d8.loss_cls: 1.1612  decode.d8.loss_mask: 0.7175  decode.d8.loss_dice: 1.1448
2023/05/24 01:21:14 - mmengine - INFO - Iter(train) [ 57550/160000]  lr: 6.6951e-06  eta: 12:11:32  time: 0.4725  data_time: 0.0110  memory: 4838  grad_norm: 98.6473  loss: 36.0850  decode.loss_cls: 1.2854  decode.loss_mask: 0.7606  decode.loss_dice: 1.2719  decode.d0.loss_cls: 2.9621  decode.d0.loss_mask: 0.8417  decode.d0.loss_dice: 1.5550  decode.d1.loss_cls: 1.4772  decode.d1.loss_mask: 0.7811  decode.d1.loss_dice: 1.4014  decode.d2.loss_cls: 1.3801  decode.d2.loss_mask: 0.7478  decode.d2.loss_dice: 1.3311  decode.d3.loss_cls: 1.4302  decode.d3.loss_mask: 0.7168  decode.d3.loss_dice: 1.3124  decode.d4.loss_cls: 1.3097  decode.d4.loss_mask: 0.7950  decode.d4.loss_dice: 1.3480  decode.d5.loss_cls: 1.3707  decode.d5.loss_mask: 0.7410  decode.d5.loss_dice: 1.2502  decode.d6.loss_cls: 1.2647  decode.d6.loss_mask: 0.7838  decode.d6.loss_dice: 1.3087  decode.d7.loss_cls: 1.2867  decode.d7.loss_mask: 0.7626  decode.d7.loss_dice: 1.2898  decode.d8.loss_cls: 1.2730  decode.d8.loss_mask: 0.7508  decode.d8.loss_dice: 1.2956
2023/05/24 01:21:35 - mmengine - INFO - Iter(train) [ 57600/160000]  lr: 6.6921e-06  eta: 12:11:11  time: 0.4144  data_time: 0.0099  memory: 4846  grad_norm: 97.2378  loss: 39.6873  decode.loss_cls: 1.4463  decode.loss_mask: 0.7089  decode.loss_dice: 1.5504  decode.d0.loss_cls: 3.3562  decode.d0.loss_mask: 0.7322  decode.d0.loss_dice: 1.7146  decode.d1.loss_cls: 1.6741  decode.d1.loss_mask: 0.7802  decode.d1.loss_dice: 1.5769  decode.d2.loss_cls: 1.5640  decode.d2.loss_mask: 0.7192  decode.d2.loss_dice: 1.5481  decode.d3.loss_cls: 1.5306  decode.d3.loss_mask: 0.7060  decode.d3.loss_dice: 1.4952  decode.d4.loss_cls: 1.5695  decode.d4.loss_mask: 0.6763  decode.d4.loss_dice: 1.4893  decode.d5.loss_cls: 1.5036  decode.d5.loss_mask: 0.6972  decode.d5.loss_dice: 1.4998  decode.d6.loss_cls: 1.4716  decode.d6.loss_mask: 0.7305  decode.d6.loss_dice: 1.5242  decode.d7.loss_cls: 1.4595  decode.d7.loss_mask: 0.7373  decode.d7.loss_dice: 1.4619  decode.d8.loss_cls: 1.4969  decode.d8.loss_mask: 0.7255  decode.d8.loss_dice: 1.5415
2023/05/24 01:21:57 - mmengine - INFO - Iter(train) [ 57650/160000]  lr: 6.6892e-06  eta: 12:10:50  time: 0.4693  data_time: 0.0100  memory: 4907  grad_norm: 89.4954  loss: 35.3856  decode.loss_cls: 1.3554  decode.loss_mask: 0.6298  decode.loss_dice: 1.3082  decode.d0.loss_cls: 3.3155  decode.d0.loss_mask: 0.6243  decode.d0.loss_dice: 1.6178  decode.d1.loss_cls: 1.5337  decode.d1.loss_mask: 0.5916  decode.d1.loss_dice: 1.3909  decode.d2.loss_cls: 1.4201  decode.d2.loss_mask: 0.5650  decode.d2.loss_dice: 1.3917  decode.d3.loss_cls: 1.3961  decode.d3.loss_mask: 0.6005  decode.d3.loss_dice: 1.3192  decode.d4.loss_cls: 1.3872  decode.d4.loss_mask: 0.6132  decode.d4.loss_dice: 1.3241  decode.d5.loss_cls: 1.3704  decode.d5.loss_mask: 0.6199  decode.d5.loss_dice: 1.3135  decode.d6.loss_cls: 1.2651  decode.d6.loss_mask: 0.6229  decode.d6.loss_dice: 1.3196  decode.d7.loss_cls: 1.2714  decode.d7.loss_mask: 0.6244  decode.d7.loss_dice: 1.3350  decode.d8.loss_cls: 1.3064  decode.d8.loss_mask: 0.6155  decode.d8.loss_dice: 1.3371
2023/05/24 01:22:21 - mmengine - INFO - Iter(train) [ 57700/160000]  lr: 6.6862e-06  eta: 12:10:32  time: 0.4690  data_time: 0.0098  memory: 4804  grad_norm: 207.5651  loss: 28.1612  decode.loss_cls: 1.1264  decode.loss_mask: 0.5666  decode.loss_dice: 0.9198  decode.d0.loss_cls: 2.7555  decode.d0.loss_mask: 0.6180  decode.d0.loss_dice: 1.0725  decode.d1.loss_cls: 1.1778  decode.d1.loss_mask: 0.5640  decode.d1.loss_dice: 1.0119  decode.d2.loss_cls: 1.1574  decode.d2.loss_mask: 0.5532  decode.d2.loss_dice: 0.9775  decode.d3.loss_cls: 1.0973  decode.d3.loss_mask: 0.5751  decode.d3.loss_dice: 0.9564  decode.d4.loss_cls: 1.0653  decode.d4.loss_mask: 0.5838  decode.d4.loss_dice: 0.9797  decode.d5.loss_cls: 1.0607  decode.d5.loss_mask: 0.5698  decode.d5.loss_dice: 0.9785  decode.d6.loss_cls: 1.1080  decode.d6.loss_mask: 0.6004  decode.d6.loss_dice: 0.9256  decode.d7.loss_cls: 1.0212  decode.d7.loss_mask: 0.5973  decode.d7.loss_dice: 0.9484  decode.d8.loss_cls: 1.1027  decode.d8.loss_mask: 0.5686  decode.d8.loss_dice: 0.9219
2023/05/24 01:22:42 - mmengine - INFO - Iter(train) [ 57750/160000]  lr: 6.6833e-06  eta: 12:10:11  time: 0.4122  data_time: 0.0098  memory: 4899  grad_norm: 102.4122  loss: 33.8380  decode.loss_cls: 0.9794  decode.loss_mask: 0.8664  decode.loss_dice: 1.2114  decode.d0.loss_cls: 3.1762  decode.d0.loss_mask: 0.8978  decode.d0.loss_dice: 1.3720  decode.d1.loss_cls: 1.1785  decode.d1.loss_mask: 0.8069  decode.d1.loss_dice: 1.2686  decode.d2.loss_cls: 1.1478  decode.d2.loss_mask: 0.8301  decode.d2.loss_dice: 1.2447  decode.d3.loss_cls: 1.1453  decode.d3.loss_mask: 0.8377  decode.d3.loss_dice: 1.2403  decode.d4.loss_cls: 1.1144  decode.d4.loss_mask: 0.8378  decode.d4.loss_dice: 1.2445  decode.d5.loss_cls: 1.0046  decode.d5.loss_mask: 0.8777  decode.d5.loss_dice: 1.2168  decode.d6.loss_cls: 1.0337  decode.d6.loss_mask: 0.8789  decode.d6.loss_dice: 1.2167  decode.d7.loss_cls: 1.0094  decode.d7.loss_mask: 0.8799  decode.d7.loss_dice: 1.2205  decode.d8.loss_cls: 0.9972  decode.d8.loss_mask: 0.8841  decode.d8.loss_dice: 1.2184
2023/05/24 01:23:03 - mmengine - INFO - Iter(train) [ 57800/160000]  lr: 6.6804e-06  eta: 12:09:49  time: 0.4149  data_time: 0.0103  memory: 4804  grad_norm: 93.1470  loss: 38.2411  decode.loss_cls: 1.4935  decode.loss_mask: 0.7856  decode.loss_dice: 1.3044  decode.d0.loss_cls: 3.1565  decode.d0.loss_mask: 0.8530  decode.d0.loss_dice: 1.5355  decode.d1.loss_cls: 1.6608  decode.d1.loss_mask: 0.8076  decode.d1.loss_dice: 1.3877  decode.d2.loss_cls: 1.5551  decode.d2.loss_mask: 0.7847  decode.d2.loss_dice: 1.2931  decode.d3.loss_cls: 1.5734  decode.d3.loss_mask: 0.7848  decode.d3.loss_dice: 1.2964  decode.d4.loss_cls: 1.5624  decode.d4.loss_mask: 0.7938  decode.d4.loss_dice: 1.2982  decode.d5.loss_cls: 1.4942  decode.d5.loss_mask: 0.7960  decode.d5.loss_dice: 1.2831  decode.d6.loss_cls: 1.4579  decode.d6.loss_mask: 0.8240  decode.d6.loss_dice: 1.3031  decode.d7.loss_cls: 1.4843  decode.d7.loss_mask: 0.7922  decode.d7.loss_dice: 1.3045  decode.d8.loss_cls: 1.5138  decode.d8.loss_mask: 0.7731  decode.d8.loss_dice: 1.2884
2023/05/24 01:23:25 - mmengine - INFO - Iter(train) [ 57850/160000]  lr: 6.6774e-06  eta: 12:09:28  time: 0.4227  data_time: 0.0104  memory: 4865  grad_norm: 90.0365  loss: 47.2376  decode.loss_cls: 1.6628  decode.loss_mask: 1.1475  decode.loss_dice: 1.6758  decode.d0.loss_cls: 3.5325  decode.d0.loss_mask: 1.0906  decode.d0.loss_dice: 1.9346  decode.d1.loss_cls: 1.7077  decode.d1.loss_mask: 1.1019  decode.d1.loss_dice: 1.7493  decode.d2.loss_cls: 1.7349  decode.d2.loss_mask: 1.1771  decode.d2.loss_dice: 1.7480  decode.d3.loss_cls: 1.7523  decode.d3.loss_mask: 1.0776  decode.d3.loss_dice: 1.6676  decode.d4.loss_cls: 1.7616  decode.d4.loss_mask: 1.0563  decode.d4.loss_dice: 1.7102  decode.d5.loss_cls: 1.7311  decode.d5.loss_mask: 1.0935  decode.d5.loss_dice: 1.7171  decode.d6.loss_cls: 1.7606  decode.d6.loss_mask: 1.0879  decode.d6.loss_dice: 1.6714  decode.d7.loss_cls: 1.7104  decode.d7.loss_mask: 1.0314  decode.d7.loss_dice: 1.6598  decode.d8.loss_cls: 1.6925  decode.d8.loss_mask: 1.1124  decode.d8.loss_dice: 1.6812
2023/05/24 01:23:45 - mmengine - INFO - Iter(train) [ 57900/160000]  lr: 6.6745e-06  eta: 12:09:05  time: 0.4175  data_time: 0.0105  memory: 4836  grad_norm: 87.5099  loss: 35.1843  decode.loss_cls: 1.3553  decode.loss_mask: 0.6645  decode.loss_dice: 1.2688  decode.d0.loss_cls: 3.1863  decode.d0.loss_mask: 0.7187  decode.d0.loss_dice: 1.4497  decode.d1.loss_cls: 1.5514  decode.d1.loss_mask: 0.7110  decode.d1.loss_dice: 1.4171  decode.d2.loss_cls: 1.4072  decode.d2.loss_mask: 0.7018  decode.d2.loss_dice: 1.3524  decode.d3.loss_cls: 1.3365  decode.d3.loss_mask: 0.6905  decode.d3.loss_dice: 1.2749  decode.d4.loss_cls: 1.3422  decode.d4.loss_mask: 0.6784  decode.d4.loss_dice: 1.2773  decode.d5.loss_cls: 1.3161  decode.d5.loss_mask: 0.6772  decode.d5.loss_dice: 1.2353  decode.d6.loss_cls: 1.2626  decode.d6.loss_mask: 0.6687  decode.d6.loss_dice: 1.2308  decode.d7.loss_cls: 1.3454  decode.d7.loss_mask: 0.6383  decode.d7.loss_dice: 1.2142  decode.d8.loss_cls: 1.2962  decode.d8.loss_mask: 0.6842  decode.d8.loss_dice: 1.2311
2023/05/24 01:24:06 - mmengine - INFO - Iter(train) [ 57950/160000]  lr: 6.6715e-06  eta: 12:08:42  time: 0.4114  data_time: 0.0100  memory: 4830  grad_norm: 102.1678  loss: 40.0929  decode.loss_cls: 1.2891  decode.loss_mask: 0.9161  decode.loss_dice: 1.4445  decode.d0.loss_cls: 3.2806  decode.d0.loss_mask: 0.8773  decode.d0.loss_dice: 1.5618  decode.d1.loss_cls: 1.4915  decode.d1.loss_mask: 0.9072  decode.d1.loss_dice: 1.6396  decode.d2.loss_cls: 1.4491  decode.d2.loss_mask: 0.9127  decode.d2.loss_dice: 1.5509  decode.d3.loss_cls: 1.4148  decode.d3.loss_mask: 0.8984  decode.d3.loss_dice: 1.5350  decode.d4.loss_cls: 1.3660  decode.d4.loss_mask: 0.9007  decode.d4.loss_dice: 1.5519  decode.d5.loss_cls: 1.3887  decode.d5.loss_mask: 0.9076  decode.d5.loss_dice: 1.5003  decode.d6.loss_cls: 1.4184  decode.d6.loss_mask: 0.9276  decode.d6.loss_dice: 1.5212  decode.d7.loss_cls: 1.3331  decode.d7.loss_mask: 0.9076  decode.d7.loss_dice: 1.4861  decode.d8.loss_cls: 1.2999  decode.d8.loss_mask: 0.9271  decode.d8.loss_dice: 1.4878
2023/05/24 01:24:28 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 01:24:28 - mmengine - INFO - Iter(train) [ 58000/160000]  lr: 6.6686e-06  eta: 12:08:21  time: 0.4112  data_time: 0.0111  memory: 4835  grad_norm: 96.6229  loss: 36.0577  decode.loss_cls: 1.1743  decode.loss_mask: 0.8303  decode.loss_dice: 1.3416  decode.d0.loss_cls: 3.1194  decode.d0.loss_mask: 0.8655  decode.d0.loss_dice: 1.4981  decode.d1.loss_cls: 1.3262  decode.d1.loss_mask: 0.8699  decode.d1.loss_dice: 1.4108  decode.d2.loss_cls: 1.2411  decode.d2.loss_mask: 0.8272  decode.d2.loss_dice: 1.3657  decode.d3.loss_cls: 1.1814  decode.d3.loss_mask: 0.8635  decode.d3.loss_dice: 1.3375  decode.d4.loss_cls: 1.1743  decode.d4.loss_mask: 0.8595  decode.d4.loss_dice: 1.3510  decode.d5.loss_cls: 1.1843  decode.d5.loss_mask: 0.8626  decode.d5.loss_dice: 1.3340  decode.d6.loss_cls: 1.1637  decode.d6.loss_mask: 0.8364  decode.d6.loss_dice: 1.3479  decode.d7.loss_cls: 1.1571  decode.d7.loss_mask: 0.8375  decode.d7.loss_dice: 1.3306  decode.d8.loss_cls: 1.1963  decode.d8.loss_mask: 0.8370  decode.d8.loss_dice: 1.3330
2023/05/24 01:24:28 - mmengine - INFO - Saving checkpoint at 58000 iterations
2023/05/24 01:24:54 - mmengine - INFO - Iter(train) [ 58050/160000]  lr: 6.6657e-06  eta: 12:08:08  time: 0.4115  data_time: 0.0106  memory: 4838  grad_norm: 105.2488  loss: 38.5475  decode.loss_cls: 1.1530  decode.loss_mask: 0.8707  decode.loss_dice: 1.4839  decode.d0.loss_cls: 3.2663  decode.d0.loss_mask: 0.9544  decode.d0.loss_dice: 1.8058  decode.d1.loss_cls: 1.4436  decode.d1.loss_mask: 0.8706  decode.d1.loss_dice: 1.6054  decode.d2.loss_cls: 1.2912  decode.d2.loss_mask: 0.8979  decode.d2.loss_dice: 1.5935  decode.d3.loss_cls: 1.2381  decode.d3.loss_mask: 0.8741  decode.d3.loss_dice: 1.5307  decode.d4.loss_cls: 1.2882  decode.d4.loss_mask: 0.8297  decode.d4.loss_dice: 1.4919  decode.d5.loss_cls: 1.2099  decode.d5.loss_mask: 0.8374  decode.d5.loss_dice: 1.4870  decode.d6.loss_cls: 1.1939  decode.d6.loss_mask: 0.8384  decode.d6.loss_dice: 1.4812  decode.d7.loss_cls: 1.1712  decode.d7.loss_mask: 0.8668  decode.d7.loss_dice: 1.4744  decode.d8.loss_cls: 1.1717  decode.d8.loss_mask: 0.8712  decode.d8.loss_dice: 1.4552
2023/05/24 01:25:15 - mmengine - INFO - Iter(train) [ 58100/160000]  lr: 6.6627e-06  eta: 12:07:46  time: 0.4063  data_time: 0.0100  memory: 4905  grad_norm: 96.8489  loss: 37.7057  decode.loss_cls: 1.1247  decode.loss_mask: 0.8726  decode.loss_dice: 1.5142  decode.d0.loss_cls: 3.1640  decode.d0.loss_mask: 0.8689  decode.d0.loss_dice: 1.7030  decode.d1.loss_cls: 1.3190  decode.d1.loss_mask: 0.8721  decode.d1.loss_dice: 1.5764  decode.d2.loss_cls: 1.2464  decode.d2.loss_mask: 0.8304  decode.d2.loss_dice: 1.5600  decode.d3.loss_cls: 1.2163  decode.d3.loss_mask: 0.8526  decode.d3.loss_dice: 1.5032  decode.d4.loss_cls: 1.1795  decode.d4.loss_mask: 0.8541  decode.d4.loss_dice: 1.5039  decode.d5.loss_cls: 1.1691  decode.d5.loss_mask: 0.8455  decode.d5.loss_dice: 1.4711  decode.d6.loss_cls: 1.1501  decode.d6.loss_mask: 0.8597  decode.d6.loss_dice: 1.4928  decode.d7.loss_cls: 1.0975  decode.d7.loss_mask: 0.8555  decode.d7.loss_dice: 1.4943  decode.d8.loss_cls: 1.1420  decode.d8.loss_mask: 0.8759  decode.d8.loss_dice: 1.4912
2023/05/24 01:25:36 - mmengine - INFO - Iter(train) [ 58150/160000]  lr: 6.6598e-06  eta: 12:07:23  time: 0.4320  data_time: 0.0103  memory: 4830  grad_norm: 92.4726  loss: 28.5172  decode.loss_cls: 1.0916  decode.loss_mask: 0.6423  decode.loss_dice: 0.8634  decode.d0.loss_cls: 2.7877  decode.d0.loss_mask: 0.6770  decode.d0.loss_dice: 0.9830  decode.d1.loss_cls: 1.2404  decode.d1.loss_mask: 0.6579  decode.d1.loss_dice: 0.9403  decode.d2.loss_cls: 1.1378  decode.d2.loss_mask: 0.6504  decode.d2.loss_dice: 0.8898  decode.d3.loss_cls: 1.1552  decode.d3.loss_mask: 0.6723  decode.d3.loss_dice: 0.8791  decode.d4.loss_cls: 1.1400  decode.d4.loss_mask: 0.6854  decode.d4.loss_dice: 0.8759  decode.d5.loss_cls: 1.1402  decode.d5.loss_mask: 0.6510  decode.d5.loss_dice: 0.8865  decode.d6.loss_cls: 1.1225  decode.d6.loss_mask: 0.6395  decode.d6.loss_dice: 0.8921  decode.d7.loss_cls: 1.0829  decode.d7.loss_mask: 0.6568  decode.d7.loss_dice: 0.8736  decode.d8.loss_cls: 1.1037  decode.d8.loss_mask: 0.6455  decode.d8.loss_dice: 0.8533
2023/05/24 01:25:58 - mmengine - INFO - Iter(train) [ 58200/160000]  lr: 6.6568e-06  eta: 12:07:03  time: 0.4311  data_time: 0.0101  memory: 4821  grad_norm: 100.2322  loss: 42.7699  decode.loss_cls: 1.7416  decode.loss_mask: 0.9148  decode.loss_dice: 1.3538  decode.d0.loss_cls: 3.6227  decode.d0.loss_mask: 1.0154  decode.d0.loss_dice: 1.5626  decode.d1.loss_cls: 1.7582  decode.d1.loss_mask: 0.9707  decode.d1.loss_dice: 1.4950  decode.d2.loss_cls: 1.7773  decode.d2.loss_mask: 0.9212  decode.d2.loss_dice: 1.4079  decode.d3.loss_cls: 1.7323  decode.d3.loss_mask: 0.9327  decode.d3.loss_dice: 1.3868  decode.d4.loss_cls: 1.7502  decode.d4.loss_mask: 0.9347  decode.d4.loss_dice: 1.3966  decode.d5.loss_cls: 1.8050  decode.d5.loss_mask: 0.9287  decode.d5.loss_dice: 1.3707  decode.d6.loss_cls: 1.7004  decode.d6.loss_mask: 0.9581  decode.d6.loss_dice: 1.3694  decode.d7.loss_cls: 1.6950  decode.d7.loss_mask: 0.9544  decode.d7.loss_dice: 1.3480  decode.d8.loss_cls: 1.7157  decode.d8.loss_mask: 0.9171  decode.d8.loss_dice: 1.3327
2023/05/24 01:26:19 - mmengine - INFO - Iter(train) [ 58250/160000]  lr: 6.6539e-06  eta: 12:06:41  time: 0.4158  data_time: 0.0108  memory: 4865  grad_norm: 101.8202  loss: 36.6342  decode.loss_cls: 1.1663  decode.loss_mask: 0.9320  decode.loss_dice: 1.3256  decode.d0.loss_cls: 2.9992  decode.d0.loss_mask: 0.9314  decode.d0.loss_dice: 1.4835  decode.d1.loss_cls: 1.2380  decode.d1.loss_mask: 0.9782  decode.d1.loss_dice: 1.4202  decode.d2.loss_cls: 1.2025  decode.d2.loss_mask: 0.9521  decode.d2.loss_dice: 1.3517  decode.d3.loss_cls: 1.1979  decode.d3.loss_mask: 0.9287  decode.d3.loss_dice: 1.3165  decode.d4.loss_cls: 1.1876  decode.d4.loss_mask: 0.9398  decode.d4.loss_dice: 1.3385  decode.d5.loss_cls: 1.1651  decode.d5.loss_mask: 0.9447  decode.d5.loss_dice: 1.3361  decode.d6.loss_cls: 1.1964  decode.d6.loss_mask: 0.9483  decode.d6.loss_dice: 1.3177  decode.d7.loss_cls: 1.1668  decode.d7.loss_mask: 0.9570  decode.d7.loss_dice: 1.2993  decode.d8.loss_cls: 1.1252  decode.d8.loss_mask: 0.9598  decode.d8.loss_dice: 1.3280
2023/05/24 01:26:39 - mmengine - INFO - Iter(train) [ 58300/160000]  lr: 6.6509e-06  eta: 12:06:18  time: 0.4124  data_time: 0.0101  memory: 4845  grad_norm: 98.5128  loss: 33.8085  decode.loss_cls: 1.1528  decode.loss_mask: 0.7092  decode.loss_dice: 1.2652  decode.d0.loss_cls: 2.8573  decode.d0.loss_mask: 0.7724  decode.d0.loss_dice: 1.5033  decode.d1.loss_cls: 1.1625  decode.d1.loss_mask: 0.7698  decode.d1.loss_dice: 1.3941  decode.d2.loss_cls: 1.1501  decode.d2.loss_mask: 0.7834  decode.d2.loss_dice: 1.3239  decode.d3.loss_cls: 1.1703  decode.d3.loss_mask: 0.7615  decode.d3.loss_dice: 1.3149  decode.d4.loss_cls: 1.1177  decode.d4.loss_mask: 0.7528  decode.d4.loss_dice: 1.3121  decode.d5.loss_cls: 1.1370  decode.d5.loss_mask: 0.7401  decode.d5.loss_dice: 1.2687  decode.d6.loss_cls: 1.1471  decode.d6.loss_mask: 0.7447  decode.d6.loss_dice: 1.2650  decode.d7.loss_cls: 1.1274  decode.d7.loss_mask: 0.7383  decode.d7.loss_dice: 1.2721  decode.d8.loss_cls: 1.0754  decode.d8.loss_mask: 0.7362  decode.d8.loss_dice: 1.2832
2023/05/24 01:27:00 - mmengine - INFO - Iter(train) [ 58350/160000]  lr: 6.6480e-06  eta: 12:05:55  time: 0.4099  data_time: 0.0104  memory: 4857  grad_norm: 102.4018  loss: 39.0456  decode.loss_cls: 1.1982  decode.loss_mask: 0.9131  decode.loss_dice: 1.4889  decode.d0.loss_cls: 3.2635  decode.d0.loss_mask: 0.8726  decode.d0.loss_dice: 1.7655  decode.d1.loss_cls: 1.3820  decode.d1.loss_mask: 0.9332  decode.d1.loss_dice: 1.7230  decode.d2.loss_cls: 1.3038  decode.d2.loss_mask: 0.9147  decode.d2.loss_dice: 1.5797  decode.d3.loss_cls: 1.2854  decode.d3.loss_mask: 0.8978  decode.d3.loss_dice: 1.5116  decode.d4.loss_cls: 1.2542  decode.d4.loss_mask: 0.9336  decode.d4.loss_dice: 1.4873  decode.d5.loss_cls: 1.1777  decode.d5.loss_mask: 0.8908  decode.d5.loss_dice: 1.5092  decode.d6.loss_cls: 1.2111  decode.d6.loss_mask: 0.9096  decode.d6.loss_dice: 1.4741  decode.d7.loss_cls: 1.2234  decode.d7.loss_mask: 0.8807  decode.d7.loss_dice: 1.4896  decode.d8.loss_cls: 1.2180  decode.d8.loss_mask: 0.8849  decode.d8.loss_dice: 1.4682
2023/05/24 01:27:21 - mmengine - INFO - Iter(train) [ 58400/160000]  lr: 6.6451e-06  eta: 12:05:33  time: 0.4163  data_time: 0.0102  memory: 4805  grad_norm: 87.6098  loss: 35.5987  decode.loss_cls: 1.3211  decode.loss_mask: 0.8919  decode.loss_dice: 1.1211  decode.d0.loss_cls: 3.3090  decode.d0.loss_mask: 0.8208  decode.d0.loss_dice: 1.2877  decode.d1.loss_cls: 1.2948  decode.d1.loss_mask: 0.9399  decode.d1.loss_dice: 1.2473  decode.d2.loss_cls: 1.2731  decode.d2.loss_mask: 0.8571  decode.d2.loss_dice: 1.1631  decode.d3.loss_cls: 1.3191  decode.d3.loss_mask: 0.8352  decode.d3.loss_dice: 1.1168  decode.d4.loss_cls: 1.3030  decode.d4.loss_mask: 0.8358  decode.d4.loss_dice: 1.1180  decode.d5.loss_cls: 1.3277  decode.d5.loss_mask: 0.8568  decode.d5.loss_dice: 1.1435  decode.d6.loss_cls: 1.3633  decode.d6.loss_mask: 0.8891  decode.d6.loss_dice: 1.1405  decode.d7.loss_cls: 1.3109  decode.d7.loss_mask: 0.8999  decode.d7.loss_dice: 1.1552  decode.d8.loss_cls: 1.4003  decode.d8.loss_mask: 0.8926  decode.d8.loss_dice: 1.1641
2023/05/24 01:27:42 - mmengine - INFO - Iter(train) [ 58450/160000]  lr: 6.6421e-06  eta: 12:05:11  time: 0.4128  data_time: 0.0101  memory: 4906  grad_norm: 100.2671  loss: 38.3124  decode.loss_cls: 1.3979  decode.loss_mask: 0.8561  decode.loss_dice: 1.3193  decode.d0.loss_cls: 3.3615  decode.d0.loss_mask: 0.8811  decode.d0.loss_dice: 1.5764  decode.d1.loss_cls: 1.4854  decode.d1.loss_mask: 0.9176  decode.d1.loss_dice: 1.4254  decode.d2.loss_cls: 1.4103  decode.d2.loss_mask: 0.8801  decode.d2.loss_dice: 1.3926  decode.d3.loss_cls: 1.3863  decode.d3.loss_mask: 0.8742  decode.d3.loss_dice: 1.3546  decode.d4.loss_cls: 1.3931  decode.d4.loss_mask: 0.8785  decode.d4.loss_dice: 1.3517  decode.d5.loss_cls: 1.3738  decode.d5.loss_mask: 0.8725  decode.d5.loss_dice: 1.3372  decode.d6.loss_cls: 1.3310  decode.d6.loss_mask: 0.8621  decode.d6.loss_dice: 1.3204  decode.d7.loss_cls: 1.3562  decode.d7.loss_mask: 0.8426  decode.d7.loss_dice: 1.3123  decode.d8.loss_cls: 1.3984  decode.d8.loss_mask: 0.8496  decode.d8.loss_dice: 1.3144
2023/05/24 01:28:03 - mmengine - INFO - Iter(train) [ 58500/160000]  lr: 6.6392e-06  eta: 12:04:49  time: 0.4117  data_time: 0.0101  memory: 4836  grad_norm: 101.1535  loss: 35.3126  decode.loss_cls: 1.2188  decode.loss_mask: 0.9332  decode.loss_dice: 1.0740  decode.d0.loss_cls: 3.1498  decode.d0.loss_mask: 0.9992  decode.d0.loss_dice: 1.2667  decode.d1.loss_cls: 1.4011  decode.d1.loss_mask: 0.9886  decode.d1.loss_dice: 1.1393  decode.d2.loss_cls: 1.3339  decode.d2.loss_mask: 0.9686  decode.d2.loss_dice: 1.1227  decode.d3.loss_cls: 1.2473  decode.d3.loss_mask: 0.9637  decode.d3.loss_dice: 1.1097  decode.d4.loss_cls: 1.2572  decode.d4.loss_mask: 0.9482  decode.d4.loss_dice: 1.0999  decode.d5.loss_cls: 1.2717  decode.d5.loss_mask: 0.9245  decode.d5.loss_dice: 1.0961  decode.d6.loss_cls: 1.2516  decode.d6.loss_mask: 0.9118  decode.d6.loss_dice: 1.0714  decode.d7.loss_cls: 1.2804  decode.d7.loss_mask: 0.9157  decode.d7.loss_dice: 1.0738  decode.d8.loss_cls: 1.2596  decode.d8.loss_mask: 0.9411  decode.d8.loss_dice: 1.0931
2023/05/24 01:28:24 - mmengine - INFO - Iter(train) [ 58550/160000]  lr: 6.6362e-06  eta: 12:04:26  time: 0.4134  data_time: 0.0100  memory: 4979  grad_norm: 97.0326  loss: 34.1587  decode.loss_cls: 1.0250  decode.loss_mask: 0.8673  decode.loss_dice: 1.1836  decode.d0.loss_cls: 3.0757  decode.d0.loss_mask: 0.9839  decode.d0.loss_dice: 1.4074  decode.d1.loss_cls: 1.1112  decode.d1.loss_mask: 0.9860  decode.d1.loss_dice: 1.3756  decode.d2.loss_cls: 1.0568  decode.d2.loss_mask: 0.9648  decode.d2.loss_dice: 1.2636  decode.d3.loss_cls: 1.0329  decode.d3.loss_mask: 0.9224  decode.d3.loss_dice: 1.2422  decode.d4.loss_cls: 1.0455  decode.d4.loss_mask: 0.9027  decode.d4.loss_dice: 1.2496  decode.d5.loss_cls: 1.0206  decode.d5.loss_mask: 0.8897  decode.d5.loss_dice: 1.2451  decode.d6.loss_cls: 1.0209  decode.d6.loss_mask: 0.9012  decode.d6.loss_dice: 1.1672  decode.d7.loss_cls: 1.0270  decode.d7.loss_mask: 0.9001  decode.d7.loss_dice: 1.1976  decode.d8.loss_cls: 1.0229  decode.d8.loss_mask: 0.9037  decode.d8.loss_dice: 1.1665
2023/05/24 01:28:44 - mmengine - INFO - Iter(train) [ 58600/160000]  lr: 6.6333e-06  eta: 12:04:03  time: 0.4130  data_time: 0.0103  memory: 4821  grad_norm: 92.5643  loss: 28.2142  decode.loss_cls: 0.9451  decode.loss_mask: 0.6918  decode.loss_dice: 0.8906  decode.d0.loss_cls: 2.8254  decode.d0.loss_mask: 0.7794  decode.d0.loss_dice: 1.0179  decode.d1.loss_cls: 1.0693  decode.d1.loss_mask: 0.7172  decode.d1.loss_dice: 0.9741  decode.d2.loss_cls: 1.0498  decode.d2.loss_mask: 0.6982  decode.d2.loss_dice: 0.9623  decode.d3.loss_cls: 0.9985  decode.d3.loss_mask: 0.7127  decode.d3.loss_dice: 0.9288  decode.d4.loss_cls: 0.9824  decode.d4.loss_mask: 0.7119  decode.d4.loss_dice: 0.9656  decode.d5.loss_cls: 0.9625  decode.d5.loss_mask: 0.6986  decode.d5.loss_dice: 0.9572  decode.d6.loss_cls: 0.9641  decode.d6.loss_mask: 0.6820  decode.d6.loss_dice: 0.9022  decode.d7.loss_cls: 0.9908  decode.d7.loss_mask: 0.6819  decode.d7.loss_dice: 0.9031  decode.d8.loss_cls: 0.9574  decode.d8.loss_mask: 0.6850  decode.d8.loss_dice: 0.9083
2023/05/24 01:29:05 - mmengine - INFO - Iter(train) [ 58650/160000]  lr: 6.6303e-06  eta: 12:03:41  time: 0.4291  data_time: 0.0105  memory: 4829  grad_norm: 118.0486  loss: 31.9259  decode.loss_cls: 1.1463  decode.loss_mask: 0.7110  decode.loss_dice: 1.0091  decode.d0.loss_cls: 3.1479  decode.d0.loss_mask: 0.7900  decode.d0.loss_dice: 1.2692  decode.d1.loss_cls: 1.3523  decode.d1.loss_mask: 0.7811  decode.d1.loss_dice: 1.1850  decode.d2.loss_cls: 1.2108  decode.d2.loss_mask: 0.7151  decode.d2.loss_dice: 1.0718  decode.d3.loss_cls: 1.1657  decode.d3.loss_mask: 0.7342  decode.d3.loss_dice: 1.0675  decode.d4.loss_cls: 1.1473  decode.d4.loss_mask: 0.7371  decode.d4.loss_dice: 1.0786  decode.d5.loss_cls: 1.1462  decode.d5.loss_mask: 0.7231  decode.d5.loss_dice: 1.0640  decode.d6.loss_cls: 1.1446  decode.d6.loss_mask: 0.7092  decode.d6.loss_dice: 1.0556  decode.d7.loss_cls: 1.1418  decode.d7.loss_mask: 0.7189  decode.d7.loss_dice: 1.0360  decode.d8.loss_cls: 1.0899  decode.d8.loss_mask: 0.7183  decode.d8.loss_dice: 1.0583
2023/05/24 01:29:27 - mmengine - INFO - Iter(train) [ 58700/160000]  lr: 6.6274e-06  eta: 12:03:21  time: 0.4814  data_time: 0.0124  memory: 4837  grad_norm: 91.3659  loss: 45.9466  decode.loss_cls: 1.6610  decode.loss_mask: 0.9781  decode.loss_dice: 1.6543  decode.d0.loss_cls: 3.7618  decode.d0.loss_mask: 1.0609  decode.d0.loss_dice: 1.9093  decode.d1.loss_cls: 1.8136  decode.d1.loss_mask: 1.0323  decode.d1.loss_dice: 1.8052  decode.d2.loss_cls: 1.7505  decode.d2.loss_mask: 0.9696  decode.d2.loss_dice: 1.7619  decode.d3.loss_cls: 1.7065  decode.d3.loss_mask: 0.9343  decode.d3.loss_dice: 1.6929  decode.d4.loss_cls: 1.6752  decode.d4.loss_mask: 0.9453  decode.d4.loss_dice: 1.6449  decode.d5.loss_cls: 1.6841  decode.d5.loss_mask: 0.9556  decode.d5.loss_dice: 1.6232  decode.d6.loss_cls: 1.6791  decode.d6.loss_mask: 0.9813  decode.d6.loss_dice: 1.6331  decode.d7.loss_cls: 1.6309  decode.d7.loss_mask: 0.9965  decode.d7.loss_dice: 1.6829  decode.d8.loss_cls: 1.6496  decode.d8.loss_mask: 0.9976  decode.d8.loss_dice: 1.6752
2023/05/24 01:29:50 - mmengine - INFO - Iter(train) [ 58750/160000]  lr: 6.6245e-06  eta: 12:03:01  time: 0.4108  data_time: 0.0100  memory: 4836  grad_norm: 100.3391  loss: 33.7070  decode.loss_cls: 1.1949  decode.loss_mask: 0.6910  decode.loss_dice: 1.2130  decode.d0.loss_cls: 3.0539  decode.d0.loss_mask: 0.7194  decode.d0.loss_dice: 1.3860  decode.d1.loss_cls: 1.2709  decode.d1.loss_mask: 0.7292  decode.d1.loss_dice: 1.3133  decode.d2.loss_cls: 1.2900  decode.d2.loss_mask: 0.6961  decode.d2.loss_dice: 1.2611  decode.d3.loss_cls: 1.2612  decode.d3.loss_mask: 0.6874  decode.d3.loss_dice: 1.2297  decode.d4.loss_cls: 1.2249  decode.d4.loss_mask: 0.6868  decode.d4.loss_dice: 1.2700  decode.d5.loss_cls: 1.2298  decode.d5.loss_mask: 0.6873  decode.d5.loss_dice: 1.2524  decode.d6.loss_cls: 1.2084  decode.d6.loss_mask: 0.6996  decode.d6.loss_dice: 1.2139  decode.d7.loss_cls: 1.2119  decode.d7.loss_mask: 0.6939  decode.d7.loss_dice: 1.2257  decode.d8.loss_cls: 1.1702  decode.d8.loss_mask: 0.7061  decode.d8.loss_dice: 1.2290
2023/05/24 01:30:11 - mmengine - INFO - Iter(train) [ 58800/160000]  lr: 6.6215e-06  eta: 12:02:39  time: 0.4112  data_time: 0.0101  memory: 4857  grad_norm: 89.5990  loss: 32.3521  decode.loss_cls: 1.2605  decode.loss_mask: 0.7103  decode.loss_dice: 1.0210  decode.d0.loss_cls: 3.0381  decode.d0.loss_mask: 0.8677  decode.d0.loss_dice: 1.2395  decode.d1.loss_cls: 1.3010  decode.d1.loss_mask: 0.7924  decode.d1.loss_dice: 1.1622  decode.d2.loss_cls: 1.1812  decode.d2.loss_mask: 0.7792  decode.d2.loss_dice: 1.1186  decode.d3.loss_cls: 1.2172  decode.d3.loss_mask: 0.7448  decode.d3.loss_dice: 1.0405  decode.d4.loss_cls: 1.2309  decode.d4.loss_mask: 0.7572  decode.d4.loss_dice: 1.0476  decode.d5.loss_cls: 1.1919  decode.d5.loss_mask: 0.7445  decode.d5.loss_dice: 1.0652  decode.d6.loss_cls: 1.1854  decode.d6.loss_mask: 0.7299  decode.d6.loss_dice: 1.0208  decode.d7.loss_cls: 1.2070  decode.d7.loss_mask: 0.7271  decode.d7.loss_dice: 1.0399  decode.d8.loss_cls: 1.1716  decode.d8.loss_mask: 0.7107  decode.d8.loss_dice: 1.0482
2023/05/24 01:30:32 - mmengine - INFO - Iter(train) [ 58850/160000]  lr: 6.6186e-06  eta: 12:02:16  time: 0.4265  data_time: 0.0101  memory: 4788  grad_norm: 100.6598  loss: 33.2427  decode.loss_cls: 1.0715  decode.loss_mask: 0.7245  decode.loss_dice: 1.2659  decode.d0.loss_cls: 3.0579  decode.d0.loss_mask: 0.6991  decode.d0.loss_dice: 1.3389  decode.d1.loss_cls: 1.2098  decode.d1.loss_mask: 0.7732  decode.d1.loss_dice: 1.3497  decode.d2.loss_cls: 1.1820  decode.d2.loss_mask: 0.7451  decode.d2.loss_dice: 1.3067  decode.d3.loss_cls: 1.0690  decode.d3.loss_mask: 0.7360  decode.d3.loss_dice: 1.2800  decode.d4.loss_cls: 1.0234  decode.d4.loss_mask: 0.7440  decode.d4.loss_dice: 1.3096  decode.d5.loss_cls: 1.0886  decode.d5.loss_mask: 0.7285  decode.d5.loss_dice: 1.3066  decode.d6.loss_cls: 1.1166  decode.d6.loss_mask: 0.7210  decode.d6.loss_dice: 1.2412  decode.d7.loss_cls: 1.0737  decode.d7.loss_mask: 0.7248  decode.d7.loss_dice: 1.2207  decode.d8.loss_cls: 1.1282  decode.d8.loss_mask: 0.7294  decode.d8.loss_dice: 1.2771
2023/05/24 01:30:53 - mmengine - INFO - Iter(train) [ 58900/160000]  lr: 6.6156e-06  eta: 12:01:55  time: 0.4236  data_time: 0.0100  memory: 4822  grad_norm: 84.8707  loss: 28.8167  decode.loss_cls: 0.9561  decode.loss_mask: 0.6475  decode.loss_dice: 1.0234  decode.d0.loss_cls: 3.0720  decode.d0.loss_mask: 0.6179  decode.d0.loss_dice: 1.1826  decode.d1.loss_cls: 1.0516  decode.d1.loss_mask: 0.7021  decode.d1.loss_dice: 1.1038  decode.d2.loss_cls: 1.0476  decode.d2.loss_mask: 0.6159  decode.d2.loss_dice: 1.0615  decode.d3.loss_cls: 1.0462  decode.d3.loss_mask: 0.6252  decode.d3.loss_dice: 1.0031  decode.d4.loss_cls: 1.0418  decode.d4.loss_mask: 0.6185  decode.d4.loss_dice: 0.9949  decode.d5.loss_cls: 1.0099  decode.d5.loss_mask: 0.6044  decode.d5.loss_dice: 0.9872  decode.d6.loss_cls: 0.9547  decode.d6.loss_mask: 0.6236  decode.d6.loss_dice: 1.0071  decode.d7.loss_cls: 0.9783  decode.d7.loss_mask: 0.6167  decode.d7.loss_dice: 1.0085  decode.d8.loss_cls: 0.9756  decode.d8.loss_mask: 0.6222  decode.d8.loss_dice: 1.0169
2023/05/24 01:31:15 - mmengine - INFO - Iter(train) [ 58950/160000]  lr: 6.6127e-06  eta: 12:01:33  time: 0.4198  data_time: 0.0102  memory: 4863  grad_norm: 103.2163  loss: 36.3111  decode.loss_cls: 1.3507  decode.loss_mask: 0.7119  decode.loss_dice: 1.3350  decode.d0.loss_cls: 3.4088  decode.d0.loss_mask: 0.7409  decode.d0.loss_dice: 1.5886  decode.d1.loss_cls: 1.4767  decode.d1.loss_mask: 0.7086  decode.d1.loss_dice: 1.4283  decode.d2.loss_cls: 1.3387  decode.d2.loss_mask: 0.7349  decode.d2.loss_dice: 1.3496  decode.d3.loss_cls: 1.3329  decode.d3.loss_mask: 0.7044  decode.d3.loss_dice: 1.3272  decode.d4.loss_cls: 1.3346  decode.d4.loss_mask: 0.7049  decode.d4.loss_dice: 1.2932  decode.d5.loss_cls: 1.3836  decode.d5.loss_mask: 0.7186  decode.d5.loss_dice: 1.3275  decode.d6.loss_cls: 1.3249  decode.d6.loss_mask: 0.7087  decode.d6.loss_dice: 1.3014  decode.d7.loss_cls: 1.3369  decode.d7.loss_mask: 0.7063  decode.d7.loss_dice: 1.3082  decode.d8.loss_cls: 1.3020  decode.d8.loss_mask: 0.7124  decode.d8.loss_dice: 1.3108
2023/05/24 01:31:35 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 01:31:35 - mmengine - INFO - Iter(train) [ 59000/160000]  lr: 6.6097e-06  eta: 12:01:11  time: 0.4133  data_time: 0.0100  memory: 4869  grad_norm: 93.5337  loss: 45.7853  decode.loss_cls: 1.5209  decode.loss_mask: 1.0194  decode.loss_dice: 1.6819  decode.d0.loss_cls: 3.7166  decode.d0.loss_mask: 1.0348  decode.d0.loss_dice: 1.9872  decode.d1.loss_cls: 1.7484  decode.d1.loss_mask: 1.0663  decode.d1.loss_dice: 1.8396  decode.d2.loss_cls: 1.6355  decode.d2.loss_mask: 1.1277  decode.d2.loss_dice: 1.7823  decode.d3.loss_cls: 1.5831  decode.d3.loss_mask: 1.0465  decode.d3.loss_dice: 1.7189  decode.d4.loss_cls: 1.4712  decode.d4.loss_mask: 1.0495  decode.d4.loss_dice: 1.6981  decode.d5.loss_cls: 1.6373  decode.d5.loss_mask: 1.0274  decode.d5.loss_dice: 1.6586  decode.d6.loss_cls: 1.5694  decode.d6.loss_mask: 1.0434  decode.d6.loss_dice: 1.6697  decode.d7.loss_cls: 1.5293  decode.d7.loss_mask: 1.0201  decode.d7.loss_dice: 1.6697  decode.d8.loss_cls: 1.5533  decode.d8.loss_mask: 1.0118  decode.d8.loss_dice: 1.6672
2023/05/24 01:31:35 - mmengine - INFO - Saving checkpoint at 59000 iterations
2023/05/24 01:32:02 - mmengine - INFO - Iter(train) [ 59050/160000]  lr: 6.6068e-06  eta: 12:00:58  time: 0.4134  data_time: 0.0104  memory: 4816  grad_norm: 89.7806  loss: 32.8190  decode.loss_cls: 1.0971  decode.loss_mask: 0.7536  decode.loss_dice: 1.2262  decode.d0.loss_cls: 2.7872  decode.d0.loss_mask: 0.7129  decode.d0.loss_dice: 1.3399  decode.d1.loss_cls: 1.2210  decode.d1.loss_mask: 0.7328  decode.d1.loss_dice: 1.2871  decode.d2.loss_cls: 1.1242  decode.d2.loss_mask: 0.7486  decode.d2.loss_dice: 1.2296  decode.d3.loss_cls: 1.0922  decode.d3.loss_mask: 0.7324  decode.d3.loss_dice: 1.2510  decode.d4.loss_cls: 1.1098  decode.d4.loss_mask: 0.7331  decode.d4.loss_dice: 1.2389  decode.d5.loss_cls: 1.1143  decode.d5.loss_mask: 0.7412  decode.d5.loss_dice: 1.2190  decode.d6.loss_cls: 1.0910  decode.d6.loss_mask: 0.7712  decode.d6.loss_dice: 1.2489  decode.d7.loss_cls: 1.0750  decode.d7.loss_mask: 0.7309  decode.d7.loss_dice: 1.2624  decode.d8.loss_cls: 1.1490  decode.d8.loss_mask: 0.7498  decode.d8.loss_dice: 1.2487
2023/05/24 01:32:23 - mmengine - INFO - Iter(train) [ 59100/160000]  lr: 6.6038e-06  eta: 12:00:35  time: 0.4138  data_time: 0.0102  memory: 4838  grad_norm: 86.7724  loss: 30.6258  decode.loss_cls: 1.0813  decode.loss_mask: 0.6176  decode.loss_dice: 1.0980  decode.d0.loss_cls: 2.9812  decode.d0.loss_mask: 0.6747  decode.d0.loss_dice: 1.2545  decode.d1.loss_cls: 1.1930  decode.d1.loss_mask: 0.6749  decode.d1.loss_dice: 1.2170  decode.d2.loss_cls: 1.2086  decode.d2.loss_mask: 0.6061  decode.d2.loss_dice: 1.1544  decode.d3.loss_cls: 1.0630  decode.d3.loss_mask: 0.6577  decode.d3.loss_dice: 1.1572  decode.d4.loss_cls: 1.0277  decode.d4.loss_mask: 0.6453  decode.d4.loss_dice: 1.1475  decode.d5.loss_cls: 0.9686  decode.d5.loss_mask: 0.6665  decode.d5.loss_dice: 1.1635  decode.d6.loss_cls: 1.0522  decode.d6.loss_mask: 0.6353  decode.d6.loss_dice: 1.0844  decode.d7.loss_cls: 1.1233  decode.d7.loss_mask: 0.6209  decode.d7.loss_dice: 1.0963  decode.d8.loss_cls: 1.0439  decode.d8.loss_mask: 0.6163  decode.d8.loss_dice: 1.0948
2023/05/24 01:32:43 - mmengine - INFO - Iter(train) [ 59150/160000]  lr: 6.6009e-06  eta: 12:00:13  time: 0.4166  data_time: 0.0104  memory: 4836  grad_norm: 93.2545  loss: 32.6242  decode.loss_cls: 1.2567  decode.loss_mask: 0.7239  decode.loss_dice: 1.0431  decode.d0.loss_cls: 2.8689  decode.d0.loss_mask: 0.7456  decode.d0.loss_dice: 1.2427  decode.d1.loss_cls: 1.3779  decode.d1.loss_mask: 0.7553  decode.d1.loss_dice: 1.1121  decode.d2.loss_cls: 1.2389  decode.d2.loss_mask: 0.7762  decode.d2.loss_dice: 1.0919  decode.d3.loss_cls: 1.3058  decode.d3.loss_mask: 0.7730  decode.d3.loss_dice: 1.0429  decode.d4.loss_cls: 1.2755  decode.d4.loss_mask: 0.7345  decode.d4.loss_dice: 1.0661  decode.d5.loss_cls: 1.2967  decode.d5.loss_mask: 0.7389  decode.d5.loss_dice: 1.0751  decode.d6.loss_cls: 1.2340  decode.d6.loss_mask: 0.7297  decode.d6.loss_dice: 1.0697  decode.d7.loss_cls: 1.2675  decode.d7.loss_mask: 0.7275  decode.d7.loss_dice: 1.0317  decode.d8.loss_cls: 1.1982  decode.d8.loss_mask: 0.7525  decode.d8.loss_dice: 1.0718
2023/05/24 01:33:04 - mmengine - INFO - Iter(train) [ 59200/160000]  lr: 6.5979e-06  eta: 11:59:50  time: 0.4125  data_time: 0.0105  memory: 4846  grad_norm: 91.3443  loss: 35.1290  decode.loss_cls: 1.2253  decode.loss_mask: 0.7391  decode.loss_dice: 1.2946  decode.d0.loss_cls: 3.0795  decode.d0.loss_mask: 0.7331  decode.d0.loss_dice: 1.4482  decode.d1.loss_cls: 1.3379  decode.d1.loss_mask: 0.7544  decode.d1.loss_dice: 1.3895  decode.d2.loss_cls: 1.2588  decode.d2.loss_mask: 0.7473  decode.d2.loss_dice: 1.3038  decode.d3.loss_cls: 1.3093  decode.d3.loss_mask: 0.7507  decode.d3.loss_dice: 1.3149  decode.d4.loss_cls: 1.2728  decode.d4.loss_mask: 0.7479  decode.d4.loss_dice: 1.3002  decode.d5.loss_cls: 1.2247  decode.d5.loss_mask: 0.7492  decode.d5.loss_dice: 1.3108  decode.d6.loss_cls: 1.2269  decode.d6.loss_mask: 0.7441  decode.d6.loss_dice: 1.3044  decode.d7.loss_cls: 1.2367  decode.d7.loss_mask: 0.7424  decode.d7.loss_dice: 1.2908  decode.d8.loss_cls: 1.2793  decode.d8.loss_mask: 0.7214  decode.d8.loss_dice: 1.2911
2023/05/24 01:33:25 - mmengine - INFO - Iter(train) [ 59250/160000]  lr: 6.5950e-06  eta: 11:59:27  time: 0.4136  data_time: 0.0101  memory: 4884  grad_norm: 84.0587  loss: 37.8835  decode.loss_cls: 1.3275  decode.loss_mask: 0.8853  decode.loss_dice: 1.2556  decode.d0.loss_cls: 3.3638  decode.d0.loss_mask: 0.9049  decode.d0.loss_dice: 1.4165  decode.d1.loss_cls: 1.5168  decode.d1.loss_mask: 0.9468  decode.d1.loss_dice: 1.3978  decode.d2.loss_cls: 1.4775  decode.d2.loss_mask: 0.9142  decode.d2.loss_dice: 1.3577  decode.d3.loss_cls: 1.4327  decode.d3.loss_mask: 0.8731  decode.d3.loss_dice: 1.2610  decode.d4.loss_cls: 1.3875  decode.d4.loss_mask: 0.8941  decode.d4.loss_dice: 1.2686  decode.d5.loss_cls: 1.3959  decode.d5.loss_mask: 0.8925  decode.d5.loss_dice: 1.2320  decode.d6.loss_cls: 1.4055  decode.d6.loss_mask: 0.8694  decode.d6.loss_dice: 1.2409  decode.d7.loss_cls: 1.4098  decode.d7.loss_mask: 0.8653  decode.d7.loss_dice: 1.2198  decode.d8.loss_cls: 1.3425  decode.d8.loss_mask: 0.8886  decode.d8.loss_dice: 1.2399
2023/05/24 01:33:45 - mmengine - INFO - Iter(train) [ 59300/160000]  lr: 6.5921e-06  eta: 11:59:05  time: 0.4148  data_time: 0.0101  memory: 4847  grad_norm: 256.7243  loss: 47.1176  decode.loss_cls: 1.6347  decode.loss_mask: 0.8059  decode.loss_dice: 1.9585  decode.d0.loss_cls: 3.7318  decode.d0.loss_mask: 0.8756  decode.d0.loss_dice: 2.2615  decode.d1.loss_cls: 1.8616  decode.d1.loss_mask: 0.8616  decode.d1.loss_dice: 2.0325  decode.d2.loss_cls: 1.7454  decode.d2.loss_mask: 0.8005  decode.d2.loss_dice: 1.9712  decode.d3.loss_cls: 1.7246  decode.d3.loss_mask: 0.7903  decode.d3.loss_dice: 1.9034  decode.d4.loss_cls: 1.6482  decode.d4.loss_mask: 0.8157  decode.d4.loss_dice: 1.9882  decode.d5.loss_cls: 1.6548  decode.d5.loss_mask: 0.8083  decode.d5.loss_dice: 1.9992  decode.d6.loss_cls: 1.6280  decode.d6.loss_mask: 0.7961  decode.d6.loss_dice: 1.9980  decode.d7.loss_cls: 1.6181  decode.d7.loss_mask: 0.8136  decode.d7.loss_dice: 1.9608  decode.d8.loss_cls: 1.6289  decode.d8.loss_mask: 0.8015  decode.d8.loss_dice: 1.9989
2023/05/24 01:34:07 - mmengine - INFO - Iter(train) [ 59350/160000]  lr: 6.5891e-06  eta: 11:58:43  time: 0.4580  data_time: 0.0103  memory: 4856  grad_norm: 102.0166  loss: 33.5079  decode.loss_cls: 1.1992  decode.loss_mask: 0.7873  decode.loss_dice: 1.0522  decode.d0.loss_cls: 3.2753  decode.d0.loss_mask: 0.8210  decode.d0.loss_dice: 1.2407  decode.d1.loss_cls: 1.3262  decode.d1.loss_mask: 0.8263  decode.d1.loss_dice: 1.1639  decode.d2.loss_cls: 1.2671  decode.d2.loss_mask: 0.8232  decode.d2.loss_dice: 1.1125  decode.d3.loss_cls: 1.3089  decode.d3.loss_mask: 0.8014  decode.d3.loss_dice: 1.0741  decode.d4.loss_cls: 1.2577  decode.d4.loss_mask: 0.7932  decode.d4.loss_dice: 1.0954  decode.d5.loss_cls: 1.1951  decode.d5.loss_mask: 0.7917  decode.d5.loss_dice: 1.0880  decode.d6.loss_cls: 1.1940  decode.d6.loss_mask: 0.7839  decode.d6.loss_dice: 1.0748  decode.d7.loss_cls: 1.2140  decode.d7.loss_mask: 0.7881  decode.d7.loss_dice: 1.0697  decode.d8.loss_cls: 1.2239  decode.d8.loss_mask: 0.7929  decode.d8.loss_dice: 1.0663
2023/05/24 01:34:29 - mmengine - INFO - Iter(train) [ 59400/160000]  lr: 6.5862e-06  eta: 11:58:22  time: 0.4669  data_time: 0.0099  memory: 4884  grad_norm: 98.5450  loss: 30.9359  decode.loss_cls: 1.0835  decode.loss_mask: 0.7070  decode.loss_dice: 1.0696  decode.d0.loss_cls: 2.8804  decode.d0.loss_mask: 0.7493  decode.d0.loss_dice: 1.2135  decode.d1.loss_cls: 1.1267  decode.d1.loss_mask: 0.7425  decode.d1.loss_dice: 1.1820  decode.d2.loss_cls: 1.1374  decode.d2.loss_mask: 0.6901  decode.d2.loss_dice: 1.1073  decode.d3.loss_cls: 1.1217  decode.d3.loss_mask: 0.6928  decode.d3.loss_dice: 1.0961  decode.d4.loss_cls: 1.0974  decode.d4.loss_mask: 0.6734  decode.d4.loss_dice: 1.0656  decode.d5.loss_cls: 1.1207  decode.d5.loss_mask: 0.6985  decode.d5.loss_dice: 1.0723  decode.d6.loss_cls: 1.1265  decode.d6.loss_mask: 0.6676  decode.d6.loss_dice: 1.0846  decode.d7.loss_cls: 1.1085  decode.d7.loss_mask: 0.6833  decode.d7.loss_dice: 1.0876  decode.d8.loss_cls: 1.0951  decode.d8.loss_mask: 0.6837  decode.d8.loss_dice: 1.0711
2023/05/24 01:34:50 - mmengine - INFO - Iter(train) [ 59450/160000]  lr: 6.5832e-06  eta: 11:58:02  time: 0.4201  data_time: 0.0102  memory: 4867  grad_norm: 79.4622  loss: 53.8842  decode.loss_cls: 1.7610  decode.loss_mask: 1.0591  decode.loss_dice: 2.2243  decode.d0.loss_cls: 3.6699  decode.d0.loss_mask: 1.1733  decode.d0.loss_dice: 2.5497  decode.d1.loss_cls: 1.8732  decode.d1.loss_mask: 1.1914  decode.d1.loss_dice: 2.3898  decode.d2.loss_cls: 1.9341  decode.d2.loss_mask: 1.1060  decode.d2.loss_dice: 2.2888  decode.d3.loss_cls: 1.8851  decode.d3.loss_mask: 1.0889  decode.d3.loss_dice: 2.2052  decode.d4.loss_cls: 1.8164  decode.d4.loss_mask: 1.0816  decode.d4.loss_dice: 2.2631  decode.d5.loss_cls: 1.8039  decode.d5.loss_mask: 1.0744  decode.d5.loss_dice: 2.1838  decode.d6.loss_cls: 1.8168  decode.d6.loss_mask: 1.0909  decode.d6.loss_dice: 2.2031  decode.d7.loss_cls: 1.7391  decode.d7.loss_mask: 1.0947  decode.d7.loss_dice: 2.2391  decode.d8.loss_cls: 1.8443  decode.d8.loss_mask: 1.0320  decode.d8.loss_dice: 2.2012
2023/05/24 01:35:11 - mmengine - INFO - Iter(train) [ 59500/160000]  lr: 6.5803e-06  eta: 11:57:39  time: 0.4106  data_time: 0.0102  memory: 4840  grad_norm: 104.1996  loss: 44.9670  decode.loss_cls: 1.5171  decode.loss_mask: 0.9645  decode.loss_dice: 1.6765  decode.d0.loss_cls: 3.4135  decode.d0.loss_mask: 1.1561  decode.d0.loss_dice: 1.9561  decode.d1.loss_cls: 1.6993  decode.d1.loss_mask: 1.0383  decode.d1.loss_dice: 1.8440  decode.d2.loss_cls: 1.5889  decode.d2.loss_mask: 0.9969  decode.d2.loss_dice: 1.7367  decode.d3.loss_cls: 1.6030  decode.d3.loss_mask: 0.9893  decode.d3.loss_dice: 1.7219  decode.d4.loss_cls: 1.5283  decode.d4.loss_mask: 0.9896  decode.d4.loss_dice: 1.7087  decode.d5.loss_cls: 1.5981  decode.d5.loss_mask: 0.9731  decode.d5.loss_dice: 1.7128  decode.d6.loss_cls: 1.5403  decode.d6.loss_mask: 0.9644  decode.d6.loss_dice: 1.6768  decode.d7.loss_cls: 1.5336  decode.d7.loss_mask: 0.9556  decode.d7.loss_dice: 1.6998  decode.d8.loss_cls: 1.5678  decode.d8.loss_mask: 0.9579  decode.d8.loss_dice: 1.6582
2023/05/24 01:35:32 - mmengine - INFO - Iter(train) [ 59550/160000]  lr: 6.5773e-06  eta: 11:57:17  time: 0.4239  data_time: 0.0106  memory: 4835  grad_norm: 173.7756  loss: 38.3162  decode.loss_cls: 1.2280  decode.loss_mask: 0.8978  decode.loss_dice: 1.4079  decode.d0.loss_cls: 3.0775  decode.d0.loss_mask: 1.0591  decode.d0.loss_dice: 1.6054  decode.d1.loss_cls: 1.3326  decode.d1.loss_mask: 0.9205  decode.d1.loss_dice: 1.5130  decode.d2.loss_cls: 1.2787  decode.d2.loss_mask: 0.9592  decode.d2.loss_dice: 1.4951  decode.d3.loss_cls: 1.2249  decode.d3.loss_mask: 0.9287  decode.d3.loss_dice: 1.4500  decode.d4.loss_cls: 1.2007  decode.d4.loss_mask: 0.9604  decode.d4.loss_dice: 1.4913  decode.d5.loss_cls: 1.2200  decode.d5.loss_mask: 0.9425  decode.d5.loss_dice: 1.4487  decode.d6.loss_cls: 1.2631  decode.d6.loss_mask: 0.8795  decode.d6.loss_dice: 1.4033  decode.d7.loss_cls: 1.2520  decode.d7.loss_mask: 0.8841  decode.d7.loss_dice: 1.4416  decode.d8.loss_cls: 1.2575  decode.d8.loss_mask: 0.8966  decode.d8.loss_dice: 1.3965
2023/05/24 01:35:53 - mmengine - INFO - Iter(train) [ 59600/160000]  lr: 6.5744e-06  eta: 11:56:55  time: 0.4253  data_time: 0.0101  memory: 4837  grad_norm: 86.0137  loss: 28.8464  decode.loss_cls: 1.1849  decode.loss_mask: 0.6063  decode.loss_dice: 0.8933  decode.d0.loss_cls: 3.0261  decode.d0.loss_mask: 0.7366  decode.d0.loss_dice: 1.0526  decode.d1.loss_cls: 1.3176  decode.d1.loss_mask: 0.6564  decode.d1.loss_dice: 0.9754  decode.d2.loss_cls: 1.1955  decode.d2.loss_mask: 0.6085  decode.d2.loss_dice: 0.9052  decode.d3.loss_cls: 1.2416  decode.d3.loss_mask: 0.5790  decode.d3.loss_dice: 0.8267  decode.d4.loss_cls: 1.2167  decode.d4.loss_mask: 0.5740  decode.d4.loss_dice: 0.8075  decode.d5.loss_cls: 1.1530  decode.d5.loss_mask: 0.5803  decode.d5.loss_dice: 0.8468  decode.d6.loss_cls: 1.0782  decode.d6.loss_mask: 0.6037  decode.d6.loss_dice: 0.8795  decode.d7.loss_cls: 1.1623  decode.d7.loss_mask: 0.6000  decode.d7.loss_dice: 0.8784  decode.d8.loss_cls: 1.1516  decode.d8.loss_mask: 0.6116  decode.d8.loss_dice: 0.8972
2023/05/24 01:36:16 - mmengine - INFO - Iter(train) [ 59650/160000]  lr: 6.5714e-06  eta: 11:56:36  time: 0.4716  data_time: 0.0097  memory: 4812  grad_norm: 94.8833  loss: 35.6796  decode.loss_cls: 1.1462  decode.loss_mask: 0.7611  decode.loss_dice: 1.3275  decode.d0.loss_cls: 3.1946  decode.d0.loss_mask: 0.8290  decode.d0.loss_dice: 1.5450  decode.d1.loss_cls: 1.3729  decode.d1.loss_mask: 0.8108  decode.d1.loss_dice: 1.4708  decode.d2.loss_cls: 1.2612  decode.d2.loss_mask: 0.8200  decode.d2.loss_dice: 1.4050  decode.d3.loss_cls: 1.2237  decode.d3.loss_mask: 0.7827  decode.d3.loss_dice: 1.3654  decode.d4.loss_cls: 1.2357  decode.d4.loss_mask: 0.7757  decode.d4.loss_dice: 1.3551  decode.d5.loss_cls: 1.1716  decode.d5.loss_mask: 0.7691  decode.d5.loss_dice: 1.3184  decode.d6.loss_cls: 1.1470  decode.d6.loss_mask: 0.7618  decode.d6.loss_dice: 1.3383  decode.d7.loss_cls: 1.1343  decode.d7.loss_mask: 0.7689  decode.d7.loss_dice: 1.3448  decode.d8.loss_cls: 1.1398  decode.d8.loss_mask: 0.7746  decode.d8.loss_dice: 1.3285
2023/05/24 01:36:37 - mmengine - INFO - Iter(train) [ 59700/160000]  lr: 6.5685e-06  eta: 11:56:14  time: 0.4193  data_time: 0.0101  memory: 4808  grad_norm: 155.5964  loss: 32.1659  decode.loss_cls: 1.0705  decode.loss_mask: 0.6912  decode.loss_dice: 1.1405  decode.d0.loss_cls: 3.1388  decode.d0.loss_mask: 0.7520  decode.d0.loss_dice: 1.3177  decode.d1.loss_cls: 1.2617  decode.d1.loss_mask: 0.7278  decode.d1.loss_dice: 1.2517  decode.d2.loss_cls: 1.2624  decode.d2.loss_mask: 0.6814  decode.d2.loss_dice: 1.1763  decode.d3.loss_cls: 1.2007  decode.d3.loss_mask: 0.6990  decode.d3.loss_dice: 1.1570  decode.d4.loss_cls: 1.1154  decode.d4.loss_mask: 0.6918  decode.d4.loss_dice: 1.1698  decode.d5.loss_cls: 1.1404  decode.d5.loss_mask: 0.6763  decode.d5.loss_dice: 1.1675  decode.d6.loss_cls: 1.0436  decode.d6.loss_mask: 0.6969  decode.d6.loss_dice: 1.1611  decode.d7.loss_cls: 1.0748  decode.d7.loss_mask: 0.6883  decode.d7.loss_dice: 1.1288  decode.d8.loss_cls: 1.0660  decode.d8.loss_mask: 0.6768  decode.d8.loss_dice: 1.1397
2023/05/24 01:36:58 - mmengine - INFO - Iter(train) [ 59750/160000]  lr: 6.5655e-06  eta: 11:55:52  time: 0.4222  data_time: 0.0102  memory: 4821  grad_norm: 98.6102  loss: 37.5680  decode.loss_cls: 1.5160  decode.loss_mask: 0.7565  decode.loss_dice: 1.2496  decode.d0.loss_cls: 3.2810  decode.d0.loss_mask: 0.8432  decode.d0.loss_dice: 1.4191  decode.d1.loss_cls: 1.5806  decode.d1.loss_mask: 0.8099  decode.d1.loss_dice: 1.3497  decode.d2.loss_cls: 1.4175  decode.d2.loss_mask: 0.7993  decode.d2.loss_dice: 1.3431  decode.d3.loss_cls: 1.4549  decode.d3.loss_mask: 0.7923  decode.d3.loss_dice: 1.3092  decode.d4.loss_cls: 1.4167  decode.d4.loss_mask: 0.7864  decode.d4.loss_dice: 1.3242  decode.d5.loss_cls: 1.4691  decode.d5.loss_mask: 0.7771  decode.d5.loss_dice: 1.2801  decode.d6.loss_cls: 1.5229  decode.d6.loss_mask: 0.7854  decode.d6.loss_dice: 1.2656  decode.d7.loss_cls: 1.4926  decode.d7.loss_mask: 0.7611  decode.d7.loss_dice: 1.2757  decode.d8.loss_cls: 1.4369  decode.d8.loss_mask: 0.7754  decode.d8.loss_dice: 1.2767
2023/05/24 01:37:19 - mmengine - INFO - Iter(train) [ 59800/160000]  lr: 6.5626e-06  eta: 11:55:29  time: 0.4115  data_time: 0.0105  memory: 4868  grad_norm: 120.4067  loss: 36.9217  decode.loss_cls: 1.2231  decode.loss_mask: 0.8399  decode.loss_dice: 1.3515  decode.d0.loss_cls: 3.1641  decode.d0.loss_mask: 0.9328  decode.d0.loss_dice: 1.5938  decode.d1.loss_cls: 1.3457  decode.d1.loss_mask: 0.8960  decode.d1.loss_dice: 1.4908  decode.d2.loss_cls: 1.2090  decode.d2.loss_mask: 0.8713  decode.d2.loss_dice: 1.4355  decode.d3.loss_cls: 1.2651  decode.d3.loss_mask: 0.8520  decode.d3.loss_dice: 1.3753  decode.d4.loss_cls: 1.2736  decode.d4.loss_mask: 0.8310  decode.d4.loss_dice: 1.3260  decode.d5.loss_cls: 1.1905  decode.d5.loss_mask: 0.8148  decode.d5.loss_dice: 1.3717  decode.d6.loss_cls: 1.2366  decode.d6.loss_mask: 0.8430  decode.d6.loss_dice: 1.3541  decode.d7.loss_cls: 1.2215  decode.d7.loss_mask: 0.8368  decode.d7.loss_dice: 1.3735  decode.d8.loss_cls: 1.2164  decode.d8.loss_mask: 0.8468  decode.d8.loss_dice: 1.3394
2023/05/24 01:37:40 - mmengine - INFO - Iter(train) [ 59850/160000]  lr: 6.5596e-06  eta: 11:55:07  time: 0.4171  data_time: 0.0100  memory: 4804  grad_norm: 92.4933  loss: 32.9608  decode.loss_cls: 1.1076  decode.loss_mask: 0.7427  decode.loss_dice: 1.1403  decode.d0.loss_cls: 2.8740  decode.d0.loss_mask: 0.8289  decode.d0.loss_dice: 1.4321  decode.d1.loss_cls: 1.3670  decode.d1.loss_mask: 0.7837  decode.d1.loss_dice: 1.2746  decode.d2.loss_cls: 1.2472  decode.d2.loss_mask: 0.7511  decode.d2.loss_dice: 1.2082  decode.d3.loss_cls: 1.1031  decode.d3.loss_mask: 0.7778  decode.d3.loss_dice: 1.1372  decode.d4.loss_cls: 1.0891  decode.d4.loss_mask: 0.7676  decode.d4.loss_dice: 1.1738  decode.d5.loss_cls: 1.1469  decode.d5.loss_mask: 0.7288  decode.d5.loss_dice: 1.1786  decode.d6.loss_cls: 1.1373  decode.d6.loss_mask: 0.7416  decode.d6.loss_dice: 1.1599  decode.d7.loss_cls: 1.1130  decode.d7.loss_mask: 0.7293  decode.d7.loss_dice: 1.1570  decode.d8.loss_cls: 1.1246  decode.d8.loss_mask: 0.7711  decode.d8.loss_dice: 1.1668
2023/05/24 01:38:02 - mmengine - INFO - Iter(train) [ 59900/160000]  lr: 6.5567e-06  eta: 11:54:47  time: 0.4714  data_time: 0.0104  memory: 4835  grad_norm: 114.6432  loss: 41.1494  decode.loss_cls: 1.3376  decode.loss_mask: 1.0077  decode.loss_dice: 1.4908  decode.d0.loss_cls: 3.3189  decode.d0.loss_mask: 1.1705  decode.d0.loss_dice: 1.7941  decode.d1.loss_cls: 1.3928  decode.d1.loss_mask: 1.0589  decode.d1.loss_dice: 1.5972  decode.d2.loss_cls: 1.3926  decode.d2.loss_mask: 1.0099  decode.d2.loss_dice: 1.5357  decode.d3.loss_cls: 1.3989  decode.d3.loss_mask: 1.0011  decode.d3.loss_dice: 1.5134  decode.d4.loss_cls: 1.3659  decode.d4.loss_mask: 0.9786  decode.d4.loss_dice: 1.5000  decode.d5.loss_cls: 1.3102  decode.d5.loss_mask: 1.0017  decode.d5.loss_dice: 1.5364  decode.d6.loss_cls: 1.3114  decode.d6.loss_mask: 0.9959  decode.d6.loss_dice: 1.4382  decode.d7.loss_cls: 1.3022  decode.d7.loss_mask: 1.0142  decode.d7.loss_dice: 1.5143  decode.d8.loss_cls: 1.3329  decode.d8.loss_mask: 1.0136  decode.d8.loss_dice: 1.5138
2023/05/24 01:38:25 - mmengine - INFO - Iter(train) [ 59950/160000]  lr: 6.5537e-06  eta: 11:54:28  time: 0.4260  data_time: 0.0103  memory: 4847  grad_norm: 101.0307  loss: 33.3999  decode.loss_cls: 1.4687  decode.loss_mask: 0.6686  decode.loss_dice: 0.9485  decode.d0.loss_cls: 3.4555  decode.d0.loss_mask: 0.7149  decode.d0.loss_dice: 1.1930  decode.d1.loss_cls: 1.5825  decode.d1.loss_mask: 0.6960  decode.d1.loss_dice: 0.9998  decode.d2.loss_cls: 1.5003  decode.d2.loss_mask: 0.6860  decode.d2.loss_dice: 0.9692  decode.d3.loss_cls: 1.4672  decode.d3.loss_mask: 0.6708  decode.d3.loss_dice: 0.9507  decode.d4.loss_cls: 1.4684  decode.d4.loss_mask: 0.6727  decode.d4.loss_dice: 0.9605  decode.d5.loss_cls: 1.4653  decode.d5.loss_mask: 0.6625  decode.d5.loss_dice: 0.9336  decode.d6.loss_cls: 1.4871  decode.d6.loss_mask: 0.6691  decode.d6.loss_dice: 0.9268  decode.d7.loss_cls: 1.4646  decode.d7.loss_mask: 0.6775  decode.d7.loss_dice: 0.9593  decode.d8.loss_cls: 1.4807  decode.d8.loss_mask: 0.6672  decode.d8.loss_dice: 0.9329
2023/05/24 01:38:46 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 01:38:46 - mmengine - INFO - Iter(train) [ 60000/160000]  lr: 6.5508e-06  eta: 11:54:05  time: 0.4170  data_time: 0.0100  memory: 4891  grad_norm: 84.8537  loss: 41.5843  decode.loss_cls: 1.5001  decode.loss_mask: 0.8031  decode.loss_dice: 1.5733  decode.d0.loss_cls: 3.2913  decode.d0.loss_mask: 0.8922  decode.d0.loss_dice: 1.7755  decode.d1.loss_cls: 1.6086  decode.d1.loss_mask: 0.8726  decode.d1.loss_dice: 1.7525  decode.d2.loss_cls: 1.5199  decode.d2.loss_mask: 0.8459  decode.d2.loss_dice: 1.6059  decode.d3.loss_cls: 1.5285  decode.d3.loss_mask: 0.8245  decode.d3.loss_dice: 1.6274  decode.d4.loss_cls: 1.4807  decode.d4.loss_mask: 0.8109  decode.d4.loss_dice: 1.6110  decode.d5.loss_cls: 1.5021  decode.d5.loss_mask: 0.8015  decode.d5.loss_dice: 1.5904  decode.d6.loss_cls: 1.4798  decode.d6.loss_mask: 0.8605  decode.d6.loss_dice: 1.5982  decode.d7.loss_cls: 1.4578  decode.d7.loss_mask: 0.8540  decode.d7.loss_dice: 1.6105  decode.d8.loss_cls: 1.4168  decode.d8.loss_mask: 0.8593  decode.d8.loss_dice: 1.6295
2023/05/24 01:38:46 - mmengine - INFO - Saving checkpoint at 60000 iterations
2023/05/24 01:38:56 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0799  data_time: 0.0019  memory: 2167  
2023/05/24 01:39:00 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0854  data_time: 0.0019  memory: 2216  
2023/05/24 01:39:04 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:39  time: 0.0789  data_time: 0.0017  memory: 2167  
2023/05/24 01:39:08 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0792  data_time: 0.0018  memory: 2104  
2023/05/24 01:39:12 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0804  data_time: 0.0018  memory: 2831  
2023/05/24 01:39:16 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0807  data_time: 0.0019  memory: 2167  
2023/05/24 01:39:20 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0841  data_time: 0.0019  memory: 2167  
2023/05/24 01:39:25 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0796  data_time: 0.0019  memory: 2167  
2023/05/24 01:39:29 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0786  data_time: 0.0018  memory: 2944  
2023/05/24 01:39:33 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0794  data_time: 0.0019  memory: 2356  
2023/05/24 01:39:37 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0787  data_time: 0.0018  memory: 2217  
2023/05/24 01:39:43 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.1750  data_time: 0.0021  memory: 2328  
2023/05/24 01:39:47 - mmengine - INFO - per class results:
2023/05/24 01:39:47 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.69 | 93.79 |
|     bicycle      | 69.17 | 83.36 |
|       car        | 57.07 | 85.07 |
|    motorcycle    | 82.73 | 89.21 |
|     airplane     |  82.8 | 91.06 |
|       bus        | 80.82 | 83.91 |
|      train       | 83.37 | 93.76 |
|      truck       | 50.39 | 70.32 |
|       boat       | 56.72 | 77.82 |
|  traffic light   | 65.87 | 85.98 |
|   fire hydrant   | 83.31 | 95.07 |
|    stop sign     | 92.81 | 96.98 |
|  parking meter   | 81.23 | 85.18 |
|      bench       | 48.82 |  66.4 |
|       bird       | 78.38 | 91.31 |
|       cat        | 85.21 | 91.54 |
|       dog        | 77.61 | 86.15 |
|      horse       | 82.43 | 88.75 |
|      sheep       | 86.16 | 93.04 |
|       cow        | 81.34 | 87.79 |
|     elephant     | 89.74 | 95.01 |
|       bear       |  92.4 | 94.91 |
|      zebra       | 92.33 | 95.64 |
|     giraffe      | 87.24 | 93.03 |
|     backpack     | 34.78 | 59.74 |
|     umbrella     | 79.14 | 86.76 |
|     handbag      | 31.53 | 50.97 |
|       tie        | 12.76 | 17.84 |
|     suitcase     | 77.53 | 90.81 |
|     frisbee      | 65.68 | 89.31 |
|       skis       | 41.93 | 61.01 |
|    snowboard     | 48.73 | 54.63 |
|   sports ball    | 48.19 |  73.8 |
|       kite       |  51.7 | 60.92 |
|   baseball bat   | 50.04 | 62.07 |
|  baseball glove  | 69.38 | 81.12 |
|    skateboard    | 68.22 | 84.27 |
|    surfboard     | 78.81 | 86.42 |
|  tennis racket   | 82.42 | 89.05 |
|      bottle      | 46.87 | 71.16 |
|    wine glass    | 55.47 | 80.55 |
|       cup        | 52.89 | 78.13 |
|       fork       | 37.17 | 53.42 |
|      knife       | 27.19 | 37.04 |
|      spoon       | 34.18 | 61.41 |
|       bowl       | 46.36 | 66.91 |
|      banana      | 67.46 | 88.64 |
|      apple       | 49.43 | 70.41 |
|     sandwich     | 44.74 | 56.37 |
|      orange      | 71.08 | 83.84 |
|     broccoli     | 56.79 |  78.2 |
|      carrot      |  52.5 | 65.91 |
|     hot dog      | 52.03 |  64.4 |
|      pizza       | 69.01 |  86.8 |
|      donut       | 69.81 | 85.22 |
|       cake       | 60.62 | 72.07 |
|      chair       |  43.0 | 64.22 |
|      couch       |  52.6 | 77.83 |
|   potted plant   | 34.89 | 54.29 |
|       bed        | 62.04 | 80.14 |
|   dining table   | 42.13 | 72.91 |
|      toilet      | 80.59 |  93.1 |
|        tv        |  72.6 |  84.7 |
|      laptop      | 73.89 | 86.25 |
|      mouse       |  70.1 | 89.46 |
|      remote      |  54.1 | 67.69 |
|     keyboard     | 61.76 | 75.35 |
|    cell phone    | 70.48 |  89.3 |
|    microwave     |  65.9 | 75.41 |
|       oven       | 54.78 | 69.09 |
|     toaster      |  41.2 | 53.79 |
|       sink       | 60.21 | 78.22 |
|   refrigerator   | 76.45 |  89.8 |
|       book       | 48.67 | 67.02 |
|      clock       | 70.36 | 78.32 |
|       vase       | 58.48 | 81.68 |
|     scissors     | 71.18 | 81.59 |
|    teddy bear    | 71.82 |  82.3 |
|    hair drier    |  42.4 | 44.06 |
|    toothbrush    | 29.01 | 72.61 |
|      banner      | 37.26 | 61.04 |
|     blanket      |  1.58 |  1.78 |
|      branch      | 15.56 | 20.62 |
|      bridge      | 31.03 | 44.85 |
|  building-other  | 50.39 | 75.09 |
|       bush       | 32.57 | 47.06 |
|     cabinet      | 53.17 | 71.14 |
|       cage       | 12.47 | 17.15 |
|    cardboard     |  45.0 |  60.3 |
|      carpet      |  52.6 | 74.99 |
|  ceiling-other   | 61.44 | 76.52 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 18.79 |  24.1 |
|      clouds      | 46.89 | 60.75 |
|     counter      |  26.6 | 48.71 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 62.95 | 72.01 |
|    desk-stuff    | 42.97 | 64.25 |
|       dirt       | 39.63 | 55.03 |
|    door-stuff    | 36.44 | 52.66 |
|      fence       | 33.89 | 63.58 |
|   floor-marble   |  6.8  |  8.62 |
|   floor-other    | 19.33 | 23.39 |
|   floor-stone    |  9.25 | 11.53 |
|    floor-tile    | 59.92 | 68.55 |
|    floor-wood    | 60.72 |  75.7 |
|      flower      | 43.37 | 61.99 |
|       fog        |  2.52 |  2.58 |
|    food-other    | 22.37 | 25.86 |
|      fruit       | 34.28 | 57.72 |
| furniture-other  | 13.05 | 16.23 |
|      grass       |  69.4 | 84.52 |
|      gravel      | 25.24 | 37.24 |
|   ground-other   |  3.65 |  4.25 |
|       hill       | 13.04 | 15.58 |
|      house       |  25.4 | 31.77 |
|      leaves      | 31.29 | 56.07 |
|      light       | 35.37 | 50.96 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.45 | 49.68 |
|   mirror-stuff   | 41.74 | 50.61 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 50.74 | 64.69 |
|       mud        |  4.22 |  6.26 |
|      napkin      |  2.25 |  2.25 |
|       net        | 39.41 | 61.88 |
|      paper       | 30.72 | 45.39 |
|     pavement     | 48.81 | 65.89 |
|      pillow      | 11.01 | 18.53 |
|   plant-other    | 17.32 | 24.16 |
|     plastic      | 16.47 | 20.76 |
|     platform     | 29.76 | 55.33 |
|   playingfield   | 69.49 | 90.54 |
|     railing      |  3.97 |  4.42 |
|     railroad     | 58.57 | 81.11 |
|      river       | 28.62 | 32.55 |
|       road       | 62.79 | 84.09 |
|       rock       | 13.95 | 17.18 |
|       roof       | 10.14 | 12.03 |
|       rug        | 36.31 | 50.56 |
|      salad       |  0.0  |  0.0  |
|       sand       | 58.57 | 63.77 |
|       sea        | 85.28 | 90.78 |
|      shelf       | 32.45 | 44.38 |
|    sky-other     | 70.77 | 88.17 |
|    skyscraper    | 27.72 | 35.12 |
|       snow       | 89.25 | 94.56 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 21.65 | 36.11 |
|      stone       | 16.46 | 61.27 |
|      straw       | 23.88 | 31.67 |
| structural-other |  1.46 |  1.64 |
|      table       | 18.45 | 24.93 |
|       tent       |  8.71 | 13.04 |
|  textile-other   | 11.03 | 17.79 |
|      towel       | 31.61 | 40.23 |
|       tree       | 72.75 | 84.99 |
|    vegetable     | 31.26 | 41.67 |
|    wall-brick    | 44.34 | 57.12 |
|  wall-concrete   | 58.72 | 80.97 |
|    wall-other    | 16.71 | 26.01 |
|    wall-panel    |  1.1  |  1.14 |
|    wall-stone    | 27.72 | 43.18 |
|    wall-tile     | 63.84 | 84.81 |
|    wall-wood     | 35.87 | 61.46 |
|   water-other    | 29.81 | 67.09 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 47.37 |  57.0 |
|   window-other   |  44.8 | 66.58 |
|       wood       | 24.74 | 36.75 |
+------------------+-------+-------+
2023/05/24 01:39:47 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.2700  mIoU: 45.6000  mAcc: 58.4100  data_time: 0.0020  time: 0.0855
2023/05/24 01:39:47 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_55000.pth is removed
2023/05/24 01:39:50 - mmengine - INFO - The best checkpoint with 45.6000 mIoU at 60000 iter is saved to best_mIoU_iter_60000.pth.
2023/05/24 01:40:12 - mmengine - INFO - Iter(train) [ 60050/160000]  lr: 6.5479e-06  eta: 11:53:52  time: 0.4126  data_time: 0.0103  memory: 4838  grad_norm: 127.0135  loss: 40.4803  decode.loss_cls: 1.4506  decode.loss_mask: 0.8534  decode.loss_dice: 1.3573  decode.d0.loss_cls: 3.5015  decode.d0.loss_mask: 0.9149  decode.d0.loss_dice: 1.5868  decode.d1.loss_cls: 1.7486  decode.d1.loss_mask: 0.9022  decode.d1.loss_dice: 1.5088  decode.d2.loss_cls: 1.6960  decode.d2.loss_mask: 0.8858  decode.d2.loss_dice: 1.4343  decode.d3.loss_cls: 1.6456  decode.d3.loss_mask: 0.8799  decode.d3.loss_dice: 1.3881  decode.d4.loss_cls: 1.5822  decode.d4.loss_mask: 0.8625  decode.d4.loss_dice: 1.3835  decode.d5.loss_cls: 1.5667  decode.d5.loss_mask: 0.8414  decode.d5.loss_dice: 1.3843  decode.d6.loss_cls: 1.4847  decode.d6.loss_mask: 0.8337  decode.d6.loss_dice: 1.3675  decode.d7.loss_cls: 1.5324  decode.d7.loss_mask: 0.8078  decode.d7.loss_dice: 1.3705  decode.d8.loss_cls: 1.4900  decode.d8.loss_mask: 0.8292  decode.d8.loss_dice: 1.3897
2023/05/24 01:40:33 - mmengine - INFO - Iter(train) [ 60100/160000]  lr: 6.5449e-06  eta: 11:53:30  time: 0.4099  data_time: 0.0101  memory: 4918  grad_norm: 137.9394  loss: 35.6656  decode.loss_cls: 1.2634  decode.loss_mask: 0.7561  decode.loss_dice: 1.2923  decode.d0.loss_cls: 2.9717  decode.d0.loss_mask: 0.8011  decode.d0.loss_dice: 1.3980  decode.d1.loss_cls: 1.4245  decode.d1.loss_mask: 0.8558  decode.d1.loss_dice: 1.4319  decode.d2.loss_cls: 1.2928  decode.d2.loss_mask: 0.7963  decode.d2.loss_dice: 1.3702  decode.d3.loss_cls: 1.2584  decode.d3.loss_mask: 0.8096  decode.d3.loss_dice: 1.3017  decode.d4.loss_cls: 1.2836  decode.d4.loss_mask: 0.7628  decode.d4.loss_dice: 1.2984  decode.d5.loss_cls: 1.2642  decode.d5.loss_mask: 0.7555  decode.d5.loss_dice: 1.2965  decode.d6.loss_cls: 1.2693  decode.d6.loss_mask: 0.7552  decode.d6.loss_dice: 1.2900  decode.d7.loss_cls: 1.2699  decode.d7.loss_mask: 0.7776  decode.d7.loss_dice: 1.3042  decode.d8.loss_cls: 1.2842  decode.d8.loss_mask: 0.7385  decode.d8.loss_dice: 1.2917
2023/05/24 01:40:54 - mmengine - INFO - Iter(train) [ 60150/160000]  lr: 6.5420e-06  eta: 11:53:08  time: 0.4158  data_time: 0.0104  memory: 4836  grad_norm: 102.6282  loss: 38.0863  decode.loss_cls: 1.4011  decode.loss_mask: 0.8830  decode.loss_dice: 1.2466  decode.d0.loss_cls: 3.2069  decode.d0.loss_mask: 0.9144  decode.d0.loss_dice: 1.4153  decode.d1.loss_cls: 1.5805  decode.d1.loss_mask: 0.8823  decode.d1.loss_dice: 1.3166  decode.d2.loss_cls: 1.4654  decode.d2.loss_mask: 0.8948  decode.d2.loss_dice: 1.3365  decode.d3.loss_cls: 1.4357  decode.d3.loss_mask: 0.9415  decode.d3.loss_dice: 1.3481  decode.d4.loss_cls: 1.4198  decode.d4.loss_mask: 0.9323  decode.d4.loss_dice: 1.3316  decode.d5.loss_cls: 1.4043  decode.d5.loss_mask: 0.9452  decode.d5.loss_dice: 1.2769  decode.d6.loss_cls: 1.3642  decode.d6.loss_mask: 0.9044  decode.d6.loss_dice: 1.2523  decode.d7.loss_cls: 1.3533  decode.d7.loss_mask: 0.8807  decode.d7.loss_dice: 1.2421  decode.d8.loss_cls: 1.3687  decode.d8.loss_mask: 0.9019  decode.d8.loss_dice: 1.2402
2023/05/24 01:41:14 - mmengine - INFO - Iter(train) [ 60200/160000]  lr: 6.5390e-06  eta: 11:52:45  time: 0.4100  data_time: 0.0097  memory: 4859  grad_norm: 100.5157  loss: 31.7756  decode.loss_cls: 1.1043  decode.loss_mask: 0.7321  decode.loss_dice: 1.0415  decode.d0.loss_cls: 2.9043  decode.d0.loss_mask: 0.8252  decode.d0.loss_dice: 1.1794  decode.d1.loss_cls: 1.1932  decode.d1.loss_mask: 0.7833  decode.d1.loss_dice: 1.1252  decode.d2.loss_cls: 1.2121  decode.d2.loss_mask: 0.7479  decode.d2.loss_dice: 1.0663  decode.d3.loss_cls: 1.1273  decode.d3.loss_mask: 0.7670  decode.d3.loss_dice: 1.0600  decode.d4.loss_cls: 1.2283  decode.d4.loss_mask: 0.7685  decode.d4.loss_dice: 1.0521  decode.d5.loss_cls: 1.1988  decode.d5.loss_mask: 0.7392  decode.d5.loss_dice: 1.0218  decode.d6.loss_cls: 1.1219  decode.d6.loss_mask: 0.7967  decode.d6.loss_dice: 1.0565  decode.d7.loss_cls: 1.1274  decode.d7.loss_mask: 0.7696  decode.d7.loss_dice: 1.0495  decode.d8.loss_cls: 1.1500  decode.d8.loss_mask: 0.7714  decode.d8.loss_dice: 1.0549
2023/05/24 01:41:35 - mmengine - INFO - Iter(train) [ 60250/160000]  lr: 6.5361e-06  eta: 11:52:23  time: 0.4167  data_time: 0.0101  memory: 4836  grad_norm: 97.1599  loss: 44.0890  decode.loss_cls: 1.3655  decode.loss_mask: 1.1659  decode.loss_dice: 1.5694  decode.d0.loss_cls: 3.2859  decode.d0.loss_mask: 1.2477  decode.d0.loss_dice: 1.9361  decode.d1.loss_cls: 1.4856  decode.d1.loss_mask: 1.2585  decode.d1.loss_dice: 1.7171  decode.d2.loss_cls: 1.3936  decode.d2.loss_mask: 1.2342  decode.d2.loss_dice: 1.6577  decode.d3.loss_cls: 1.3718  decode.d3.loss_mask: 1.1856  decode.d3.loss_dice: 1.6256  decode.d4.loss_cls: 1.3143  decode.d4.loss_mask: 1.1997  decode.d4.loss_dice: 1.6462  decode.d5.loss_cls: 1.3069  decode.d5.loss_mask: 1.1617  decode.d5.loss_dice: 1.6116  decode.d6.loss_cls: 1.3692  decode.d6.loss_mask: 1.1802  decode.d6.loss_dice: 1.5983  decode.d7.loss_cls: 1.3011  decode.d7.loss_mask: 1.1663  decode.d7.loss_dice: 1.6538  decode.d8.loss_cls: 1.3359  decode.d8.loss_mask: 1.1582  decode.d8.loss_dice: 1.5854
2023/05/24 01:41:56 - mmengine - INFO - Iter(train) [ 60300/160000]  lr: 6.5331e-06  eta: 11:52:00  time: 0.4100  data_time: 0.0102  memory: 4837  grad_norm: 113.4088  loss: 34.7968  decode.loss_cls: 1.4084  decode.loss_mask: 0.7043  decode.loss_dice: 1.0797  decode.d0.loss_cls: 3.1816  decode.d0.loss_mask: 0.7556  decode.d0.loss_dice: 1.2766  decode.d1.loss_cls: 1.5699  decode.d1.loss_mask: 0.7298  decode.d1.loss_dice: 1.2234  decode.d2.loss_cls: 1.5541  decode.d2.loss_mask: 0.7221  decode.d2.loss_dice: 1.1322  decode.d3.loss_cls: 1.4575  decode.d3.loss_mask: 0.7287  decode.d3.loss_dice: 1.1237  decode.d4.loss_cls: 1.4668  decode.d4.loss_mask: 0.7287  decode.d4.loss_dice: 1.0754  decode.d5.loss_cls: 1.4060  decode.d5.loss_mask: 0.7025  decode.d5.loss_dice: 1.0809  decode.d6.loss_cls: 1.4560  decode.d6.loss_mask: 0.7132  decode.d6.loss_dice: 1.1068  decode.d7.loss_cls: 1.4280  decode.d7.loss_mask: 0.6940  decode.d7.loss_dice: 1.0802  decode.d8.loss_cls: 1.4510  decode.d8.loss_mask: 0.7064  decode.d8.loss_dice: 1.0533
2023/05/24 01:42:17 - mmengine - INFO - Iter(train) [ 60350/160000]  lr: 6.5302e-06  eta: 11:51:38  time: 0.4190  data_time: 0.0101  memory: 4937  grad_norm: 102.7238  loss: 39.4802  decode.loss_cls: 1.3844  decode.loss_mask: 0.8582  decode.loss_dice: 1.3950  decode.d0.loss_cls: 3.2104  decode.d0.loss_mask: 0.9663  decode.d0.loss_dice: 1.8012  decode.d1.loss_cls: 1.5179  decode.d1.loss_mask: 0.9371  decode.d1.loss_dice: 1.6155  decode.d2.loss_cls: 1.4819  decode.d2.loss_mask: 0.8928  decode.d2.loss_dice: 1.5052  decode.d3.loss_cls: 1.4194  decode.d3.loss_mask: 0.8459  decode.d3.loss_dice: 1.4588  decode.d4.loss_cls: 1.4518  decode.d4.loss_mask: 0.8912  decode.d4.loss_dice: 1.4370  decode.d5.loss_cls: 1.3935  decode.d5.loss_mask: 0.8387  decode.d5.loss_dice: 1.3886  decode.d6.loss_cls: 1.3936  decode.d6.loss_mask: 0.8402  decode.d6.loss_dice: 1.3555  decode.d7.loss_cls: 1.3552  decode.d7.loss_mask: 0.8427  decode.d7.loss_dice: 1.3943  decode.d8.loss_cls: 1.3849  decode.d8.loss_mask: 0.8312  decode.d8.loss_dice: 1.3920
2023/05/24 01:42:38 - mmengine - INFO - Iter(train) [ 60400/160000]  lr: 6.5272e-06  eta: 11:51:17  time: 0.4769  data_time: 0.0109  memory: 4822  grad_norm: 107.1161  loss: 37.7568  decode.loss_cls: 1.5459  decode.loss_mask: 0.7163  decode.loss_dice: 1.1803  decode.d0.loss_cls: 3.4012  decode.d0.loss_mask: 0.8411  decode.d0.loss_dice: 1.4706  decode.d1.loss_cls: 1.6489  decode.d1.loss_mask: 0.7925  decode.d1.loss_dice: 1.3831  decode.d2.loss_cls: 1.6052  decode.d2.loss_mask: 0.7409  decode.d2.loss_dice: 1.3121  decode.d3.loss_cls: 1.6096  decode.d3.loss_mask: 0.7248  decode.d3.loss_dice: 1.2140  decode.d4.loss_cls: 1.5943  decode.d4.loss_mask: 0.7108  decode.d4.loss_dice: 1.2346  decode.d5.loss_cls: 1.5811  decode.d5.loss_mask: 0.6923  decode.d5.loss_dice: 1.2564  decode.d6.loss_cls: 1.5592  decode.d6.loss_mask: 0.7303  decode.d6.loss_dice: 1.2544  decode.d7.loss_cls: 1.5368  decode.d7.loss_mask: 0.7247  decode.d7.loss_dice: 1.2312  decode.d8.loss_cls: 1.5656  decode.d8.loss_mask: 0.7241  decode.d8.loss_dice: 1.1749
2023/05/24 01:42:59 - mmengine - INFO - Iter(train) [ 60450/160000]  lr: 6.5243e-06  eta: 11:50:55  time: 0.4252  data_time: 0.0101  memory: 4890  grad_norm: 145.6887  loss: 33.5973  decode.loss_cls: 1.3017  decode.loss_mask: 0.7960  decode.loss_dice: 1.0505  decode.d0.loss_cls: 2.8779  decode.d0.loss_mask: 0.8275  decode.d0.loss_dice: 1.2192  decode.d1.loss_cls: 1.4150  decode.d1.loss_mask: 0.8100  decode.d1.loss_dice: 1.1163  decode.d2.loss_cls: 1.3289  decode.d2.loss_mask: 0.7899  decode.d2.loss_dice: 1.0895  decode.d3.loss_cls: 1.2879  decode.d3.loss_mask: 0.8156  decode.d3.loss_dice: 1.0452  decode.d4.loss_cls: 1.3070  decode.d4.loss_mask: 0.8301  decode.d4.loss_dice: 1.0603  decode.d5.loss_cls: 1.2988  decode.d5.loss_mask: 0.8129  decode.d5.loss_dice: 1.0534  decode.d6.loss_cls: 1.2968  decode.d6.loss_mask: 0.7985  decode.d6.loss_dice: 1.0554  decode.d7.loss_cls: 1.2786  decode.d7.loss_mask: 0.8040  decode.d7.loss_dice: 1.0746  decode.d8.loss_cls: 1.3798  decode.d8.loss_mask: 0.7558  decode.d8.loss_dice: 1.0203
2023/05/24 01:43:20 - mmengine - INFO - Iter(train) [ 60500/160000]  lr: 6.5213e-06  eta: 11:50:32  time: 0.4095  data_time: 0.0102  memory: 4900  grad_norm: 96.7367  loss: 36.5371  decode.loss_cls: 1.2727  decode.loss_mask: 0.7739  decode.loss_dice: 1.2887  decode.d0.loss_cls: 3.2618  decode.d0.loss_mask: 0.8818  decode.d0.loss_dice: 1.6393  decode.d1.loss_cls: 1.2954  decode.d1.loss_mask: 0.8757  decode.d1.loss_dice: 1.4695  decode.d2.loss_cls: 1.3151  decode.d2.loss_mask: 0.8281  decode.d2.loss_dice: 1.3589  decode.d3.loss_cls: 1.2579  decode.d3.loss_mask: 0.8228  decode.d3.loss_dice: 1.3844  decode.d4.loss_cls: 1.2078  decode.d4.loss_mask: 0.7951  decode.d4.loss_dice: 1.3625  decode.d5.loss_cls: 1.2765  decode.d5.loss_mask: 0.7719  decode.d5.loss_dice: 1.3442  decode.d6.loss_cls: 1.2507  decode.d6.loss_mask: 0.7561  decode.d6.loss_dice: 1.3447  decode.d7.loss_cls: 1.2376  decode.d7.loss_mask: 0.7655  decode.d7.loss_dice: 1.3299  decode.d8.loss_cls: 1.2722  decode.d8.loss_mask: 0.7769  decode.d8.loss_dice: 1.3196
2023/05/24 01:43:41 - mmengine - INFO - Iter(train) [ 60550/160000]  lr: 6.5184e-06  eta: 11:50:10  time: 0.4217  data_time: 0.0107  memory: 4845  grad_norm: 80.6628  loss: 34.4227  decode.loss_cls: 1.2239  decode.loss_mask: 0.8017  decode.loss_dice: 1.2224  decode.d0.loss_cls: 2.9953  decode.d0.loss_mask: 0.8536  decode.d0.loss_dice: 1.3228  decode.d1.loss_cls: 1.3193  decode.d1.loss_mask: 0.8202  decode.d1.loss_dice: 1.2801  decode.d2.loss_cls: 1.2031  decode.d2.loss_mask: 0.8113  decode.d2.loss_dice: 1.3010  decode.d3.loss_cls: 1.1495  decode.d3.loss_mask: 0.8003  decode.d3.loss_dice: 1.2551  decode.d4.loss_cls: 1.1398  decode.d4.loss_mask: 0.7996  decode.d4.loss_dice: 1.2494  decode.d5.loss_cls: 1.2252  decode.d5.loss_mask: 0.7627  decode.d5.loss_dice: 1.2248  decode.d6.loss_cls: 1.1723  decode.d6.loss_mask: 0.7971  decode.d6.loss_dice: 1.2301  decode.d7.loss_cls: 1.2264  decode.d7.loss_mask: 0.8009  decode.d7.loss_dice: 1.2375  decode.d8.loss_cls: 1.1726  decode.d8.loss_mask: 0.7869  decode.d8.loss_dice: 1.2379
2023/05/24 01:44:02 - mmengine - INFO - Iter(train) [ 60600/160000]  lr: 6.5154e-06  eta: 11:49:48  time: 0.4187  data_time: 0.0101  memory: 4823  grad_norm: 93.2903  loss: 33.2113  decode.loss_cls: 1.1417  decode.loss_mask: 0.7877  decode.loss_dice: 1.1559  decode.d0.loss_cls: 2.8057  decode.d0.loss_mask: 0.8486  decode.d0.loss_dice: 1.3252  decode.d1.loss_cls: 1.2512  decode.d1.loss_mask: 0.7768  decode.d1.loss_dice: 1.2330  decode.d2.loss_cls: 1.1891  decode.d2.loss_mask: 0.7716  decode.d2.loss_dice: 1.1647  decode.d3.loss_cls: 1.1866  decode.d3.loss_mask: 0.7609  decode.d3.loss_dice: 1.1577  decode.d4.loss_cls: 1.1675  decode.d4.loss_mask: 0.7811  decode.d4.loss_dice: 1.1706  decode.d5.loss_cls: 1.1503  decode.d5.loss_mask: 0.8013  decode.d5.loss_dice: 1.1720  decode.d6.loss_cls: 1.2230  decode.d6.loss_mask: 0.7828  decode.d6.loss_dice: 1.1480  decode.d7.loss_cls: 1.1800  decode.d7.loss_mask: 0.7925  decode.d7.loss_dice: 1.1725  decode.d8.loss_cls: 1.1539  decode.d8.loss_mask: 0.7955  decode.d8.loss_dice: 1.1638
2023/05/24 01:44:23 - mmengine - INFO - Iter(train) [ 60650/160000]  lr: 6.5125e-06  eta: 11:49:25  time: 0.4162  data_time: 0.0101  memory: 4838  grad_norm: 129.6264  loss: 34.5084  decode.loss_cls: 1.4194  decode.loss_mask: 0.7761  decode.loss_dice: 1.0834  decode.d0.loss_cls: 2.9838  decode.d0.loss_mask: 0.7288  decode.d0.loss_dice: 1.2221  decode.d1.loss_cls: 1.4316  decode.d1.loss_mask: 0.7706  decode.d1.loss_dice: 1.1511  decode.d2.loss_cls: 1.5218  decode.d2.loss_mask: 0.7880  decode.d2.loss_dice: 1.1547  decode.d3.loss_cls: 1.4787  decode.d3.loss_mask: 0.7537  decode.d3.loss_dice: 1.0872  decode.d4.loss_cls: 1.3684  decode.d4.loss_mask: 0.7806  decode.d4.loss_dice: 1.1252  decode.d5.loss_cls: 1.3560  decode.d5.loss_mask: 0.7730  decode.d5.loss_dice: 1.0755  decode.d6.loss_cls: 1.3881  decode.d6.loss_mask: 0.7747  decode.d6.loss_dice: 1.0556  decode.d7.loss_cls: 1.4163  decode.d7.loss_mask: 0.7873  decode.d7.loss_dice: 1.0521  decode.d8.loss_cls: 1.3526  decode.d8.loss_mask: 0.7936  decode.d8.loss_dice: 1.0586
2023/05/24 01:44:44 - mmengine - INFO - Iter(train) [ 60700/160000]  lr: 6.5095e-06  eta: 11:49:03  time: 0.4201  data_time: 0.0105  memory: 4805  grad_norm: 104.1846  loss: 30.8093  decode.loss_cls: 1.1205  decode.loss_mask: 0.7435  decode.loss_dice: 0.9507  decode.d0.loss_cls: 2.9415  decode.d0.loss_mask: 0.7923  decode.d0.loss_dice: 1.2109  decode.d1.loss_cls: 1.2617  decode.d1.loss_mask: 0.7417  decode.d1.loss_dice: 1.0615  decode.d2.loss_cls: 1.1851  decode.d2.loss_mask: 0.7225  decode.d2.loss_dice: 1.0282  decode.d3.loss_cls: 1.1527  decode.d3.loss_mask: 0.7398  decode.d3.loss_dice: 1.0171  decode.d4.loss_cls: 1.1289  decode.d4.loss_mask: 0.7422  decode.d4.loss_dice: 0.9979  decode.d5.loss_cls: 1.0818  decode.d5.loss_mask: 0.7458  decode.d5.loss_dice: 1.0022  decode.d6.loss_cls: 1.1255  decode.d6.loss_mask: 0.7016  decode.d6.loss_dice: 0.9680  decode.d7.loss_cls: 1.1128  decode.d7.loss_mask: 0.7421  decode.d7.loss_dice: 0.9728  decode.d8.loss_cls: 1.1082  decode.d8.loss_mask: 0.7415  decode.d8.loss_dice: 0.9683
2023/05/24 01:45:04 - mmengine - INFO - Iter(train) [ 60750/160000]  lr: 6.5066e-06  eta: 11:48:41  time: 0.4504  data_time: 0.0103  memory: 4837  grad_norm: 86.5368  loss: 33.9032  decode.loss_cls: 1.0349  decode.loss_mask: 0.7858  decode.loss_dice: 1.2722  decode.d0.loss_cls: 3.0466  decode.d0.loss_mask: 0.8068  decode.d0.loss_dice: 1.4670  decode.d1.loss_cls: 1.1456  decode.d1.loss_mask: 0.8607  decode.d1.loss_dice: 1.4209  decode.d2.loss_cls: 1.1113  decode.d2.loss_mask: 0.8101  decode.d2.loss_dice: 1.3563  decode.d3.loss_cls: 1.0729  decode.d3.loss_mask: 0.7790  decode.d3.loss_dice: 1.2794  decode.d4.loss_cls: 1.0473  decode.d4.loss_mask: 0.8172  decode.d4.loss_dice: 1.2936  decode.d5.loss_cls: 1.0776  decode.d5.loss_mask: 0.7827  decode.d5.loss_dice: 1.2714  decode.d6.loss_cls: 1.0507  decode.d6.loss_mask: 0.7896  decode.d6.loss_dice: 1.2809  decode.d7.loss_cls: 1.1067  decode.d7.loss_mask: 0.7856  decode.d7.loss_dice: 1.2748  decode.d8.loss_cls: 1.0033  decode.d8.loss_mask: 0.7884  decode.d8.loss_dice: 1.2839
2023/05/24 01:45:28 - mmengine - INFO - Iter(train) [ 60800/160000]  lr: 6.5036e-06  eta: 11:48:23  time: 0.4737  data_time: 0.0100  memory: 4845  grad_norm: 99.3992  loss: 35.0631  decode.loss_cls: 1.2010  decode.loss_mask: 0.8554  decode.loss_dice: 1.1520  decode.d0.loss_cls: 3.1865  decode.d0.loss_mask: 0.8710  decode.d0.loss_dice: 1.3549  decode.d1.loss_cls: 1.3127  decode.d1.loss_mask: 0.9758  decode.d1.loss_dice: 1.3001  decode.d2.loss_cls: 1.3027  decode.d2.loss_mask: 0.8471  decode.d2.loss_dice: 1.2121  decode.d3.loss_cls: 1.2779  decode.d3.loss_mask: 0.8458  decode.d3.loss_dice: 1.1641  decode.d4.loss_cls: 1.2306  decode.d4.loss_mask: 0.8400  decode.d4.loss_dice: 1.1719  decode.d5.loss_cls: 1.2120  decode.d5.loss_mask: 0.8661  decode.d5.loss_dice: 1.1725  decode.d6.loss_cls: 1.2075  decode.d6.loss_mask: 0.8770  decode.d6.loss_dice: 1.1404  decode.d7.loss_cls: 1.2000  decode.d7.loss_mask: 0.8603  decode.d7.loss_dice: 1.1602  decode.d8.loss_cls: 1.2206  decode.d8.loss_mask: 0.8626  decode.d8.loss_dice: 1.1826
2023/05/24 01:45:50 - mmengine - INFO - Iter(train) [ 60850/160000]  lr: 6.5007e-06  eta: 11:48:02  time: 0.4184  data_time: 0.0101  memory: 4846  grad_norm: 94.6462  loss: 38.6730  decode.loss_cls: 1.3104  decode.loss_mask: 0.7928  decode.loss_dice: 1.5013  decode.d0.loss_cls: 3.0800  decode.d0.loss_mask: 0.8439  decode.d0.loss_dice: 1.7511  decode.d1.loss_cls: 1.2433  decode.d1.loss_mask: 0.8509  decode.d1.loss_dice: 1.6623  decode.d2.loss_cls: 1.2527  decode.d2.loss_mask: 0.8457  decode.d2.loss_dice: 1.5980  decode.d3.loss_cls: 1.2877  decode.d3.loss_mask: 0.7897  decode.d3.loss_dice: 1.5695  decode.d4.loss_cls: 1.2942  decode.d4.loss_mask: 0.8157  decode.d4.loss_dice: 1.5633  decode.d5.loss_cls: 1.2786  decode.d5.loss_mask: 0.8185  decode.d5.loss_dice: 1.5725  decode.d6.loss_cls: 1.2735  decode.d6.loss_mask: 0.8283  decode.d6.loss_dice: 1.5705  decode.d7.loss_cls: 1.2911  decode.d7.loss_mask: 0.8290  decode.d7.loss_dice: 1.5365  decode.d8.loss_cls: 1.2711  decode.d8.loss_mask: 0.8024  decode.d8.loss_dice: 1.5484
2023/05/24 01:46:11 - mmengine - INFO - Iter(train) [ 60900/160000]  lr: 6.4977e-06  eta: 11:47:39  time: 0.4129  data_time: 0.0102  memory: 4866  grad_norm: 98.3317  loss: 43.9374  decode.loss_cls: 1.3273  decode.loss_mask: 1.1135  decode.loss_dice: 1.7303  decode.d0.loss_cls: 3.4686  decode.d0.loss_mask: 1.0499  decode.d0.loss_dice: 1.8599  decode.d1.loss_cls: 1.3834  decode.d1.loss_mask: 1.0386  decode.d1.loss_dice: 1.7567  decode.d2.loss_cls: 1.3324  decode.d2.loss_mask: 1.1588  decode.d2.loss_dice: 1.7307  decode.d3.loss_cls: 1.3934  decode.d3.loss_mask: 1.1301  decode.d3.loss_dice: 1.7219  decode.d4.loss_cls: 1.3336  decode.d4.loss_mask: 1.0799  decode.d4.loss_dice: 1.7087  decode.d5.loss_cls: 1.3451  decode.d5.loss_mask: 1.0566  decode.d5.loss_dice: 1.7169  decode.d6.loss_cls: 1.3727  decode.d6.loss_mask: 1.1154  decode.d6.loss_dice: 1.7045  decode.d7.loss_cls: 1.3486  decode.d7.loss_mask: 1.0888  decode.d7.loss_dice: 1.7086  decode.d8.loss_cls: 1.3987  decode.d8.loss_mask: 1.0503  decode.d8.loss_dice: 1.7136
2023/05/24 01:46:32 - mmengine - INFO - Iter(train) [ 60950/160000]  lr: 6.4948e-06  eta: 11:47:17  time: 0.4344  data_time: 0.0103  memory: 4823  grad_norm: 95.9057  loss: 35.0830  decode.loss_cls: 1.2857  decode.loss_mask: 0.6729  decode.loss_dice: 1.2602  decode.d0.loss_cls: 3.1909  decode.d0.loss_mask: 0.8144  decode.d0.loss_dice: 1.4984  decode.d1.loss_cls: 1.4748  decode.d1.loss_mask: 0.7486  decode.d1.loss_dice: 1.3831  decode.d2.loss_cls: 1.4158  decode.d2.loss_mask: 0.7129  decode.d2.loss_dice: 1.2771  decode.d3.loss_cls: 1.3125  decode.d3.loss_mask: 0.6949  decode.d3.loss_dice: 1.2855  decode.d4.loss_cls: 1.3083  decode.d4.loss_mask: 0.6781  decode.d4.loss_dice: 1.2461  decode.d5.loss_cls: 1.2813  decode.d5.loss_mask: 0.6792  decode.d5.loss_dice: 1.2351  decode.d6.loss_cls: 1.3071  decode.d6.loss_mask: 0.6800  decode.d6.loss_dice: 1.2400  decode.d7.loss_cls: 1.2699  decode.d7.loss_mask: 0.6840  decode.d7.loss_dice: 1.2493  decode.d8.loss_cls: 1.2660  decode.d8.loss_mask: 0.6934  decode.d8.loss_dice: 1.2375
2023/05/24 01:46:53 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 01:46:53 - mmengine - INFO - Iter(train) [ 61000/160000]  lr: 6.4918e-06  eta: 11:46:55  time: 0.4148  data_time: 0.0107  memory: 4844  grad_norm: 91.4148  loss: 25.1287  decode.loss_cls: 0.9361  decode.loss_mask: 0.5922  decode.loss_dice: 0.7956  decode.d0.loss_cls: 2.7013  decode.d0.loss_mask: 0.5798  decode.d0.loss_dice: 0.8534  decode.d1.loss_cls: 0.9951  decode.d1.loss_mask: 0.5651  decode.d1.loss_dice: 0.8366  decode.d2.loss_cls: 0.9484  decode.d2.loss_mask: 0.5974  decode.d2.loss_dice: 0.8239  decode.d3.loss_cls: 0.9177  decode.d3.loss_mask: 0.5826  decode.d3.loss_dice: 0.7937  decode.d4.loss_cls: 0.9442  decode.d4.loss_mask: 0.5660  decode.d4.loss_dice: 0.7960  decode.d5.loss_cls: 0.9810  decode.d5.loss_mask: 0.5690  decode.d5.loss_dice: 0.7671  decode.d6.loss_cls: 0.9647  decode.d6.loss_mask: 0.5831  decode.d6.loss_dice: 0.7464  decode.d7.loss_cls: 0.9482  decode.d7.loss_mask: 0.5991  decode.d7.loss_dice: 0.7759  decode.d8.loss_cls: 0.9356  decode.d8.loss_mask: 0.6099  decode.d8.loss_dice: 0.8235
2023/05/24 01:46:53 - mmengine - INFO - Saving checkpoint at 61000 iterations
2023/05/24 01:47:19 - mmengine - INFO - Iter(train) [ 61050/160000]  lr: 6.4889e-06  eta: 11:46:42  time: 0.4133  data_time: 0.0101  memory: 4807  grad_norm: 101.1330  loss: 38.0999  decode.loss_cls: 1.4877  decode.loss_mask: 0.8266  decode.loss_dice: 1.2067  decode.d0.loss_cls: 3.3313  decode.d0.loss_mask: 0.8623  decode.d0.loss_dice: 1.4641  decode.d1.loss_cls: 1.6717  decode.d1.loss_mask: 0.8374  decode.d1.loss_dice: 1.3214  decode.d2.loss_cls: 1.4942  decode.d2.loss_mask: 0.8266  decode.d2.loss_dice: 1.3060  decode.d3.loss_cls: 1.4946  decode.d3.loss_mask: 0.8347  decode.d3.loss_dice: 1.2866  decode.d4.loss_cls: 1.4854  decode.d4.loss_mask: 0.8211  decode.d4.loss_dice: 1.2930  decode.d5.loss_cls: 1.4524  decode.d5.loss_mask: 0.8370  decode.d5.loss_dice: 1.2760  decode.d6.loss_cls: 1.4975  decode.d6.loss_mask: 0.8313  decode.d6.loss_dice: 1.2507  decode.d7.loss_cls: 1.4451  decode.d7.loss_mask: 0.8330  decode.d7.loss_dice: 1.2535  decode.d8.loss_cls: 1.5302  decode.d8.loss_mask: 0.8161  decode.d8.loss_dice: 1.2254
2023/05/24 01:47:40 - mmengine - INFO - Iter(train) [ 61100/160000]  lr: 6.4859e-06  eta: 11:46:20  time: 0.4122  data_time: 0.0101  memory: 4805  grad_norm: 89.3522  loss: 38.4505  decode.loss_cls: 1.3703  decode.loss_mask: 0.8288  decode.loss_dice: 1.2707  decode.d0.loss_cls: 3.1413  decode.d0.loss_mask: 0.9295  decode.d0.loss_dice: 1.5692  decode.d1.loss_cls: 1.5328  decode.d1.loss_mask: 0.8949  decode.d1.loss_dice: 1.4327  decode.d2.loss_cls: 1.5641  decode.d2.loss_mask: 0.8799  decode.d2.loss_dice: 1.3645  decode.d3.loss_cls: 1.4917  decode.d3.loss_mask: 0.8754  decode.d3.loss_dice: 1.3094  decode.d4.loss_cls: 1.4195  decode.d4.loss_mask: 0.8521  decode.d4.loss_dice: 1.3160  decode.d5.loss_cls: 1.4559  decode.d5.loss_mask: 0.8491  decode.d5.loss_dice: 1.2800  decode.d6.loss_cls: 1.4871  decode.d6.loss_mask: 0.8338  decode.d6.loss_dice: 1.3013  decode.d7.loss_cls: 1.4540  decode.d7.loss_mask: 0.8389  decode.d7.loss_dice: 1.3216  decode.d8.loss_cls: 1.4241  decode.d8.loss_mask: 0.8408  decode.d8.loss_dice: 1.3212
2023/05/24 01:48:01 - mmengine - INFO - Iter(train) [ 61150/160000]  lr: 6.4830e-06  eta: 11:45:58  time: 0.4213  data_time: 0.0103  memory: 4807  grad_norm: 86.4434  loss: 32.5889  decode.loss_cls: 1.0734  decode.loss_mask: 0.7419  decode.loss_dice: 1.1532  decode.d0.loss_cls: 2.8828  decode.d0.loss_mask: 0.8377  decode.d0.loss_dice: 1.3149  decode.d1.loss_cls: 1.2844  decode.d1.loss_mask: 0.7943  decode.d1.loss_dice: 1.2472  decode.d2.loss_cls: 1.2047  decode.d2.loss_mask: 0.7380  decode.d2.loss_dice: 1.1635  decode.d3.loss_cls: 1.1712  decode.d3.loss_mask: 0.7216  decode.d3.loss_dice: 1.1754  decode.d4.loss_cls: 1.1565  decode.d4.loss_mask: 0.7265  decode.d4.loss_dice: 1.1763  decode.d5.loss_cls: 1.1157  decode.d5.loss_mask: 0.7565  decode.d5.loss_dice: 1.1750  decode.d6.loss_cls: 1.0593  decode.d6.loss_mask: 0.7539  decode.d6.loss_dice: 1.1676  decode.d7.loss_cls: 1.0716  decode.d7.loss_mask: 0.7579  decode.d7.loss_dice: 1.1655  decode.d8.loss_cls: 1.0866  decode.d8.loss_mask: 0.7548  decode.d8.loss_dice: 1.1612
2023/05/24 01:48:23 - mmengine - INFO - Iter(train) [ 61200/160000]  lr: 6.4800e-06  eta: 11:45:37  time: 0.4098  data_time: 0.0103  memory: 4907  grad_norm: 87.9251  loss: 32.3700  decode.loss_cls: 1.0035  decode.loss_mask: 0.7346  decode.loss_dice: 1.1557  decode.d0.loss_cls: 3.1987  decode.d0.loss_mask: 0.7741  decode.d0.loss_dice: 1.3800  decode.d1.loss_cls: 1.2533  decode.d1.loss_mask: 0.7965  decode.d1.loss_dice: 1.2699  decode.d2.loss_cls: 1.1140  decode.d2.loss_mask: 0.7474  decode.d2.loss_dice: 1.1919  decode.d3.loss_cls: 1.1163  decode.d3.loss_mask: 0.7430  decode.d3.loss_dice: 1.1771  decode.d4.loss_cls: 1.0788  decode.d4.loss_mask: 0.7376  decode.d4.loss_dice: 1.1821  decode.d5.loss_cls: 1.0448  decode.d5.loss_mask: 0.7291  decode.d5.loss_dice: 1.1880  decode.d6.loss_cls: 1.0004  decode.d6.loss_mask: 0.7348  decode.d6.loss_dice: 1.1596  decode.d7.loss_cls: 1.0289  decode.d7.loss_mask: 0.7364  decode.d7.loss_dice: 1.1671  decode.d8.loss_cls: 1.0011  decode.d8.loss_mask: 0.7445  decode.d8.loss_dice: 1.1808
2023/05/24 01:48:44 - mmengine - INFO - Iter(train) [ 61250/160000]  lr: 6.4771e-06  eta: 11:45:15  time: 0.4077  data_time: 0.0100  memory: 4857  grad_norm: 98.0444  loss: 39.4159  decode.loss_cls: 1.1436  decode.loss_mask: 0.8871  decode.loss_dice: 1.6695  decode.d0.loss_cls: 3.0025  decode.d0.loss_mask: 0.9144  decode.d0.loss_dice: 1.8606  decode.d1.loss_cls: 1.4050  decode.d1.loss_mask: 0.9223  decode.d1.loss_dice: 1.6947  decode.d2.loss_cls: 1.2828  decode.d2.loss_mask: 0.8840  decode.d2.loss_dice: 1.6431  decode.d3.loss_cls: 1.2086  decode.d3.loss_mask: 0.8765  decode.d3.loss_dice: 1.6287  decode.d4.loss_cls: 1.2151  decode.d4.loss_mask: 0.8514  decode.d4.loss_dice: 1.6494  decode.d5.loss_cls: 1.2366  decode.d5.loss_mask: 0.8621  decode.d5.loss_dice: 1.5996  decode.d6.loss_cls: 1.1736  decode.d6.loss_mask: 0.8646  decode.d6.loss_dice: 1.6429  decode.d7.loss_cls: 1.1585  decode.d7.loss_mask: 0.8817  decode.d7.loss_dice: 1.6198  decode.d8.loss_cls: 1.1386  decode.d8.loss_mask: 0.8851  decode.d8.loss_dice: 1.6137
2023/05/24 01:49:06 - mmengine - INFO - Iter(train) [ 61300/160000]  lr: 6.4741e-06  eta: 11:44:55  time: 0.4696  data_time: 0.0106  memory: 4857  grad_norm: 112.9921  loss: 36.5006  decode.loss_cls: 1.3093  decode.loss_mask: 0.9107  decode.loss_dice: 1.1209  decode.d0.loss_cls: 3.4348  decode.d0.loss_mask: 0.8954  decode.d0.loss_dice: 1.2959  decode.d1.loss_cls: 1.4248  decode.d1.loss_mask: 0.8978  decode.d1.loss_dice: 1.3210  decode.d2.loss_cls: 1.3381  decode.d2.loss_mask: 0.9336  decode.d2.loss_dice: 1.1891  decode.d3.loss_cls: 1.2892  decode.d3.loss_mask: 0.9297  decode.d3.loss_dice: 1.1627  decode.d4.loss_cls: 1.2766  decode.d4.loss_mask: 0.9110  decode.d4.loss_dice: 1.1697  decode.d5.loss_cls: 1.3435  decode.d5.loss_mask: 0.8857  decode.d5.loss_dice: 1.1779  decode.d6.loss_cls: 1.3767  decode.d6.loss_mask: 0.8773  decode.d6.loss_dice: 1.1778  decode.d7.loss_cls: 1.3113  decode.d7.loss_mask: 0.9163  decode.d7.loss_dice: 1.1867  decode.d8.loss_cls: 1.3608  decode.d8.loss_mask: 0.9032  decode.d8.loss_dice: 1.1730
2023/05/24 01:49:30 - mmengine - INFO - Iter(train) [ 61350/160000]  lr: 6.4712e-06  eta: 11:44:37  time: 0.4684  data_time: 0.0105  memory: 4860  grad_norm: 96.5642  loss: 43.3753  decode.loss_cls: 1.7154  decode.loss_mask: 0.7722  decode.loss_dice: 1.5263  decode.d0.loss_cls: 3.6774  decode.d0.loss_mask: 0.7494  decode.d0.loss_dice: 1.7975  decode.d1.loss_cls: 2.0366  decode.d1.loss_mask: 0.7363  decode.d1.loss_dice: 1.6212  decode.d2.loss_cls: 1.9110  decode.d2.loss_mask: 0.7378  decode.d2.loss_dice: 1.5536  decode.d3.loss_cls: 1.8451  decode.d3.loss_mask: 0.7614  decode.d3.loss_dice: 1.5230  decode.d4.loss_cls: 1.8099  decode.d4.loss_mask: 0.7777  decode.d4.loss_dice: 1.5437  decode.d5.loss_cls: 1.7463  decode.d5.loss_mask: 0.7692  decode.d5.loss_dice: 1.5562  decode.d6.loss_cls: 1.7901  decode.d6.loss_mask: 0.7788  decode.d6.loss_dice: 1.5205  decode.d7.loss_cls: 1.8406  decode.d7.loss_mask: 0.7603  decode.d7.loss_dice: 1.4910  decode.d8.loss_cls: 1.7511  decode.d8.loss_mask: 0.7635  decode.d8.loss_dice: 1.5121
2023/05/24 01:49:52 - mmengine - INFO - Iter(train) [ 61400/160000]  lr: 6.4682e-06  eta: 11:44:17  time: 0.4181  data_time: 0.0102  memory: 4866  grad_norm: 99.6760  loss: 39.9115  decode.loss_cls: 1.3921  decode.loss_mask: 0.8391  decode.loss_dice: 1.4571  decode.d0.loss_cls: 3.3816  decode.d0.loss_mask: 0.9356  decode.d0.loss_dice: 1.7800  decode.d1.loss_cls: 1.5829  decode.d1.loss_mask: 0.8517  decode.d1.loss_dice: 1.5719  decode.d2.loss_cls: 1.4393  decode.d2.loss_mask: 0.8244  decode.d2.loss_dice: 1.5701  decode.d3.loss_cls: 1.4480  decode.d3.loss_mask: 0.8679  decode.d3.loss_dice: 1.5128  decode.d4.loss_cls: 1.3982  decode.d4.loss_mask: 0.8413  decode.d4.loss_dice: 1.4661  decode.d5.loss_cls: 1.4215  decode.d5.loss_mask: 0.8518  decode.d5.loss_dice: 1.5018  decode.d6.loss_cls: 1.4034  decode.d6.loss_mask: 0.8554  decode.d6.loss_dice: 1.4285  decode.d7.loss_cls: 1.3776  decode.d7.loss_mask: 0.8313  decode.d7.loss_dice: 1.4579  decode.d8.loss_cls: 1.3686  decode.d8.loss_mask: 0.8243  decode.d8.loss_dice: 1.4295
2023/05/24 01:50:15 - mmengine - INFO - Iter(train) [ 61450/160000]  lr: 6.4653e-06  eta: 11:43:58  time: 0.4698  data_time: 0.0102  memory: 4817  grad_norm: 98.0829  loss: 41.8220  decode.loss_cls: 1.3638  decode.loss_mask: 0.9027  decode.loss_dice: 1.6389  decode.d0.loss_cls: 3.4412  decode.d0.loss_mask: 0.9426  decode.d0.loss_dice: 1.8403  decode.d1.loss_cls: 1.4230  decode.d1.loss_mask: 0.8979  decode.d1.loss_dice: 1.7550  decode.d2.loss_cls: 1.3326  decode.d2.loss_mask: 0.8952  decode.d2.loss_dice: 1.7819  decode.d3.loss_cls: 1.4256  decode.d3.loss_mask: 0.8886  decode.d3.loss_dice: 1.6607  decode.d4.loss_cls: 1.3765  decode.d4.loss_mask: 0.8921  decode.d4.loss_dice: 1.6569  decode.d5.loss_cls: 1.4242  decode.d5.loss_mask: 0.8877  decode.d5.loss_dice: 1.6345  decode.d6.loss_cls: 1.4016  decode.d6.loss_mask: 0.8947  decode.d6.loss_dice: 1.6318  decode.d7.loss_cls: 1.3948  decode.d7.loss_mask: 0.8953  decode.d7.loss_dice: 1.6236  decode.d8.loss_cls: 1.3535  decode.d8.loss_mask: 0.9069  decode.d8.loss_dice: 1.6579
2023/05/24 01:50:37 - mmengine - INFO - Iter(train) [ 61500/160000]  lr: 6.4623e-06  eta: 11:43:36  time: 0.4132  data_time: 0.0107  memory: 4779  grad_norm: 152.2005  loss: 33.7537  decode.loss_cls: 1.2477  decode.loss_mask: 0.7031  decode.loss_dice: 1.2151  decode.d0.loss_cls: 2.7982  decode.d0.loss_mask: 0.7804  decode.d0.loss_dice: 1.4477  decode.d1.loss_cls: 1.2149  decode.d1.loss_mask: 0.7761  decode.d1.loss_dice: 1.3518  decode.d2.loss_cls: 1.2474  decode.d2.loss_mask: 0.7359  decode.d2.loss_dice: 1.2950  decode.d3.loss_cls: 1.2453  decode.d3.loss_mask: 0.6810  decode.d3.loss_dice: 1.2402  decode.d4.loss_cls: 1.2464  decode.d4.loss_mask: 0.6883  decode.d4.loss_dice: 1.2327  decode.d5.loss_cls: 1.2800  decode.d5.loss_mask: 0.7129  decode.d5.loss_dice: 1.2499  decode.d6.loss_cls: 1.2264  decode.d6.loss_mask: 0.7033  decode.d6.loss_dice: 1.2109  decode.d7.loss_cls: 1.1507  decode.d7.loss_mask: 0.7127  decode.d7.loss_dice: 1.2341  decode.d8.loss_cls: 1.1845  decode.d8.loss_mask: 0.7166  decode.d8.loss_dice: 1.2245
2023/05/24 01:50:59 - mmengine - INFO - Iter(train) [ 61550/160000]  lr: 6.4593e-06  eta: 11:43:16  time: 0.4694  data_time: 0.0104  memory: 4951  grad_norm: 83.7554  loss: 45.9233  decode.loss_cls: 1.6391  decode.loss_mask: 0.8632  decode.loss_dice: 1.7777  decode.d0.loss_cls: 3.7073  decode.d0.loss_mask: 0.9252  decode.d0.loss_dice: 2.0711  decode.d1.loss_cls: 1.7564  decode.d1.loss_mask: 0.9164  decode.d1.loss_dice: 2.0206  decode.d2.loss_cls: 1.6828  decode.d2.loss_mask: 0.8778  decode.d2.loss_dice: 1.8834  decode.d3.loss_cls: 1.7019  decode.d3.loss_mask: 0.8850  decode.d3.loss_dice: 1.8269  decode.d4.loss_cls: 1.6171  decode.d4.loss_mask: 0.8874  decode.d4.loss_dice: 1.8152  decode.d5.loss_cls: 1.6294  decode.d5.loss_mask: 0.8641  decode.d5.loss_dice: 1.7935  decode.d6.loss_cls: 1.6017  decode.d6.loss_mask: 0.8770  decode.d6.loss_dice: 1.7798  decode.d7.loss_cls: 1.6242  decode.d7.loss_mask: 0.8713  decode.d7.loss_dice: 1.7772  decode.d8.loss_cls: 1.6105  decode.d8.loss_mask: 0.8604  decode.d8.loss_dice: 1.7798
2023/05/24 01:51:21 - mmengine - INFO - Iter(train) [ 61600/160000]  lr: 6.4564e-06  eta: 11:42:56  time: 0.4219  data_time: 0.0105  memory: 4907  grad_norm: 90.0254  loss: 38.6699  decode.loss_cls: 1.3237  decode.loss_mask: 0.8850  decode.loss_dice: 1.3905  decode.d0.loss_cls: 3.2232  decode.d0.loss_mask: 0.8983  decode.d0.loss_dice: 1.5583  decode.d1.loss_cls: 1.4347  decode.d1.loss_mask: 0.9360  decode.d1.loss_dice: 1.4927  decode.d2.loss_cls: 1.4045  decode.d2.loss_mask: 0.8860  decode.d2.loss_dice: 1.4293  decode.d3.loss_cls: 1.4020  decode.d3.loss_mask: 0.8662  decode.d3.loss_dice: 1.4092  decode.d4.loss_cls: 1.3206  decode.d4.loss_mask: 0.9073  decode.d4.loss_dice: 1.4403  decode.d5.loss_cls: 1.4042  decode.d5.loss_mask: 0.9026  decode.d5.loss_dice: 1.3911  decode.d6.loss_cls: 1.3286  decode.d6.loss_mask: 0.8919  decode.d6.loss_dice: 1.3622  decode.d7.loss_cls: 1.3908  decode.d7.loss_mask: 0.8160  decode.d7.loss_dice: 1.3735  decode.d8.loss_cls: 1.2839  decode.d8.loss_mask: 0.8931  decode.d8.loss_dice: 1.4242
2023/05/24 01:51:42 - mmengine - INFO - Iter(train) [ 61650/160000]  lr: 6.4534e-06  eta: 11:42:34  time: 0.4102  data_time: 0.0105  memory: 4884  grad_norm: 101.8157  loss: 36.1743  decode.loss_cls: 1.2828  decode.loss_mask: 0.7327  decode.loss_dice: 1.3082  decode.d0.loss_cls: 3.0707  decode.d0.loss_mask: 0.7682  decode.d0.loss_dice: 1.5955  decode.d1.loss_cls: 1.3947  decode.d1.loss_mask: 0.8037  decode.d1.loss_dice: 1.4273  decode.d2.loss_cls: 1.3549  decode.d2.loss_mask: 0.8044  decode.d2.loss_dice: 1.3520  decode.d3.loss_cls: 1.3037  decode.d3.loss_mask: 0.7654  decode.d3.loss_dice: 1.3523  decode.d4.loss_cls: 1.3019  decode.d4.loss_mask: 0.7605  decode.d4.loss_dice: 1.3462  decode.d5.loss_cls: 1.3197  decode.d5.loss_mask: 0.7342  decode.d5.loss_dice: 1.3372  decode.d6.loss_cls: 1.2822  decode.d6.loss_mask: 0.7601  decode.d6.loss_dice: 1.3252  decode.d7.loss_cls: 1.2634  decode.d7.loss_mask: 0.7522  decode.d7.loss_dice: 1.3332  decode.d8.loss_cls: 1.2749  decode.d8.loss_mask: 0.7513  decode.d8.loss_dice: 1.3154
2023/05/24 01:52:03 - mmengine - INFO - Iter(train) [ 61700/160000]  lr: 6.4505e-06  eta: 11:42:12  time: 0.4325  data_time: 0.0102  memory: 4953  grad_norm: 106.5078  loss: 39.8931  decode.loss_cls: 1.4331  decode.loss_mask: 0.8052  decode.loss_dice: 1.4214  decode.d0.loss_cls: 3.3568  decode.d0.loss_mask: 0.9202  decode.d0.loss_dice: 1.6944  decode.d1.loss_cls: 1.6016  decode.d1.loss_mask: 0.9377  decode.d1.loss_dice: 1.5278  decode.d2.loss_cls: 1.5163  decode.d2.loss_mask: 0.8724  decode.d2.loss_dice: 1.4901  decode.d3.loss_cls: 1.5298  decode.d3.loss_mask: 0.8496  decode.d3.loss_dice: 1.4598  decode.d4.loss_cls: 1.5180  decode.d4.loss_mask: 0.8458  decode.d4.loss_dice: 1.4682  decode.d5.loss_cls: 1.3963  decode.d5.loss_mask: 0.8506  decode.d5.loss_dice: 1.4659  decode.d6.loss_cls: 1.4218  decode.d6.loss_mask: 0.8186  decode.d6.loss_dice: 1.4286  decode.d7.loss_cls: 1.4029  decode.d7.loss_mask: 0.8124  decode.d7.loss_dice: 1.4388  decode.d8.loss_cls: 1.3745  decode.d8.loss_mask: 0.8269  decode.d8.loss_dice: 1.4073
2023/05/24 01:52:26 - mmengine - INFO - Iter(train) [ 61750/160000]  lr: 6.4475e-06  eta: 11:41:52  time: 0.4098  data_time: 0.0101  memory: 4890  grad_norm: 87.6116  loss: 41.6913  decode.loss_cls: 1.5666  decode.loss_mask: 0.8437  decode.loss_dice: 1.4887  decode.d0.loss_cls: 3.6247  decode.d0.loss_mask: 0.9116  decode.d0.loss_dice: 1.7134  decode.d1.loss_cls: 1.7480  decode.d1.loss_mask: 0.8817  decode.d1.loss_dice: 1.5656  decode.d2.loss_cls: 1.6341  decode.d2.loss_mask: 0.8700  decode.d2.loss_dice: 1.4912  decode.d3.loss_cls: 1.5903  decode.d3.loss_mask: 0.8562  decode.d3.loss_dice: 1.4934  decode.d4.loss_cls: 1.5810  decode.d4.loss_mask: 0.8578  decode.d4.loss_dice: 1.5022  decode.d5.loss_cls: 1.5864  decode.d5.loss_mask: 0.8677  decode.d5.loss_dice: 1.4498  decode.d6.loss_cls: 1.5474  decode.d6.loss_mask: 0.8635  decode.d6.loss_dice: 1.4701  decode.d7.loss_cls: 1.5169  decode.d7.loss_mask: 0.8545  decode.d7.loss_dice: 1.4622  decode.d8.loss_cls: 1.5391  decode.d8.loss_mask: 0.8558  decode.d8.loss_dice: 1.4574
2023/05/24 01:52:47 - mmengine - INFO - Iter(train) [ 61800/160000]  lr: 6.4446e-06  eta: 11:41:30  time: 0.4083  data_time: 0.0101  memory: 4892  grad_norm: 105.5897  loss: 44.4263  decode.loss_cls: 1.4892  decode.loss_mask: 0.9610  decode.loss_dice: 1.6130  decode.d0.loss_cls: 3.3904  decode.d0.loss_mask: 1.1138  decode.d0.loss_dice: 1.8898  decode.d1.loss_cls: 1.6161  decode.d1.loss_mask: 1.0981  decode.d1.loss_dice: 1.7816  decode.d2.loss_cls: 1.6322  decode.d2.loss_mask: 1.0387  decode.d2.loss_dice: 1.7126  decode.d3.loss_cls: 1.5399  decode.d3.loss_mask: 1.0386  decode.d3.loss_dice: 1.7511  decode.d4.loss_cls: 1.5585  decode.d4.loss_mask: 1.0079  decode.d4.loss_dice: 1.6611  decode.d5.loss_cls: 1.4990  decode.d5.loss_mask: 1.0262  decode.d5.loss_dice: 1.7168  decode.d6.loss_cls: 1.5152  decode.d6.loss_mask: 0.9797  decode.d6.loss_dice: 1.6113  decode.d7.loss_cls: 1.4664  decode.d7.loss_mask: 0.9704  decode.d7.loss_dice: 1.6584  decode.d8.loss_cls: 1.4650  decode.d8.loss_mask: 0.9879  decode.d8.loss_dice: 1.6365
2023/05/24 01:53:07 - mmengine - INFO - Iter(train) [ 61850/160000]  lr: 6.4416e-06  eta: 11:41:08  time: 0.4193  data_time: 0.0100  memory: 4880  grad_norm: 90.1492  loss: 42.5631  decode.loss_cls: 1.3083  decode.loss_mask: 0.9062  decode.loss_dice: 1.6710  decode.d0.loss_cls: 3.4241  decode.d0.loss_mask: 0.9873  decode.d0.loss_dice: 1.9471  decode.d1.loss_cls: 1.5078  decode.d1.loss_mask: 1.0108  decode.d1.loss_dice: 1.8386  decode.d2.loss_cls: 1.4179  decode.d2.loss_mask: 0.9785  decode.d2.loss_dice: 1.7787  decode.d3.loss_cls: 1.3271  decode.d3.loss_mask: 0.9423  decode.d3.loss_dice: 1.6946  decode.d4.loss_cls: 1.3476  decode.d4.loss_mask: 0.9081  decode.d4.loss_dice: 1.6922  decode.d5.loss_cls: 1.3609  decode.d5.loss_mask: 0.9310  decode.d5.loss_dice: 1.7211  decode.d6.loss_cls: 1.3427  decode.d6.loss_mask: 0.9487  decode.d6.loss_dice: 1.6698  decode.d7.loss_cls: 1.3246  decode.d7.loss_mask: 0.9519  decode.d7.loss_dice: 1.6778  decode.d8.loss_cls: 1.2978  decode.d8.loss_mask: 0.9397  decode.d8.loss_dice: 1.7089
2023/05/24 01:53:29 - mmengine - INFO - Iter(train) [ 61900/160000]  lr: 6.4387e-06  eta: 11:40:46  time: 0.4375  data_time: 0.0108  memory: 4865  grad_norm: 131.5516  loss: 38.9963  decode.loss_cls: 1.2799  decode.loss_mask: 0.9760  decode.loss_dice: 1.4307  decode.d0.loss_cls: 3.2315  decode.d0.loss_mask: 0.9571  decode.d0.loss_dice: 1.5929  decode.d1.loss_cls: 1.4096  decode.d1.loss_mask: 0.9495  decode.d1.loss_dice: 1.5269  decode.d2.loss_cls: 1.4381  decode.d2.loss_mask: 0.9428  decode.d2.loss_dice: 1.4693  decode.d3.loss_cls: 1.3339  decode.d3.loss_mask: 0.9034  decode.d3.loss_dice: 1.4150  decode.d4.loss_cls: 1.2932  decode.d4.loss_mask: 0.9082  decode.d4.loss_dice: 1.4327  decode.d5.loss_cls: 1.2888  decode.d5.loss_mask: 0.8542  decode.d5.loss_dice: 1.4272  decode.d6.loss_cls: 1.3207  decode.d6.loss_mask: 0.9047  decode.d6.loss_dice: 1.3971  decode.d7.loss_cls: 1.3153  decode.d7.loss_mask: 0.9154  decode.d7.loss_dice: 1.4014  decode.d8.loss_cls: 1.2714  decode.d8.loss_mask: 0.9800  decode.d8.loss_dice: 1.4294
2023/05/24 01:53:50 - mmengine - INFO - Iter(train) [ 61950/160000]  lr: 6.4357e-06  eta: 11:40:24  time: 0.4106  data_time: 0.0103  memory: 4789  grad_norm: 93.8684  loss: 37.3805  decode.loss_cls: 1.2187  decode.loss_mask: 0.8776  decode.loss_dice: 1.2851  decode.d0.loss_cls: 3.2733  decode.d0.loss_mask: 0.9179  decode.d0.loss_dice: 1.5253  decode.d1.loss_cls: 1.3631  decode.d1.loss_mask: 0.9423  decode.d1.loss_dice: 1.4332  decode.d2.loss_cls: 1.2990  decode.d2.loss_mask: 0.9162  decode.d2.loss_dice: 1.3758  decode.d3.loss_cls: 1.2689  decode.d3.loss_mask: 0.9652  decode.d3.loss_dice: 1.3866  decode.d4.loss_cls: 1.2274  decode.d4.loss_mask: 0.9500  decode.d4.loss_dice: 1.3510  decode.d5.loss_cls: 1.2068  decode.d5.loss_mask: 0.9434  decode.d5.loss_dice: 1.3375  decode.d6.loss_cls: 1.2136  decode.d6.loss_mask: 0.9072  decode.d6.loss_dice: 1.3167  decode.d7.loss_cls: 1.2124  decode.d7.loss_mask: 0.9026  decode.d7.loss_dice: 1.3473  decode.d8.loss_cls: 1.1838  decode.d8.loss_mask: 0.8939  decode.d8.loss_dice: 1.3388
2023/05/24 01:54:11 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 01:54:11 - mmengine - INFO - Iter(train) [ 62000/160000]  lr: 6.4328e-06  eta: 11:40:02  time: 0.4563  data_time: 0.0103  memory: 4890  grad_norm: 99.6583  loss: 37.3536  decode.loss_cls: 1.0401  decode.loss_mask: 0.9337  decode.loss_dice: 1.4567  decode.d0.loss_cls: 3.0263  decode.d0.loss_mask: 1.0126  decode.d0.loss_dice: 1.6396  decode.d1.loss_cls: 1.1938  decode.d1.loss_mask: 1.0256  decode.d1.loss_dice: 1.5533  decode.d2.loss_cls: 1.1538  decode.d2.loss_mask: 0.9297  decode.d2.loss_dice: 1.4502  decode.d3.loss_cls: 1.1247  decode.d3.loss_mask: 0.9516  decode.d3.loss_dice: 1.4290  decode.d4.loss_cls: 1.0682  decode.d4.loss_mask: 0.9884  decode.d4.loss_dice: 1.4866  decode.d5.loss_cls: 1.0401  decode.d5.loss_mask: 0.9661  decode.d5.loss_dice: 1.5056  decode.d6.loss_cls: 1.0634  decode.d6.loss_mask: 0.9502  decode.d6.loss_dice: 1.4479  decode.d7.loss_cls: 1.0639  decode.d7.loss_mask: 0.9548  decode.d7.loss_dice: 1.4418  decode.d8.loss_cls: 1.0967  decode.d8.loss_mask: 0.9364  decode.d8.loss_dice: 1.4229
2023/05/24 01:54:11 - mmengine - INFO - Saving checkpoint at 62000 iterations
2023/05/24 01:54:38 - mmengine - INFO - Iter(train) [ 62050/160000]  lr: 6.4298e-06  eta: 11:39:49  time: 0.4191  data_time: 0.0111  memory: 4961  grad_norm: 108.7606  loss: 39.4381  decode.loss_cls: 1.4528  decode.loss_mask: 0.9639  decode.loss_dice: 1.3356  decode.d0.loss_cls: 3.4688  decode.d0.loss_mask: 0.8481  decode.d0.loss_dice: 1.5582  decode.d1.loss_cls: 1.6025  decode.d1.loss_mask: 0.8568  decode.d1.loss_dice: 1.4381  decode.d2.loss_cls: 1.4822  decode.d2.loss_mask: 0.8956  decode.d2.loss_dice: 1.3937  decode.d3.loss_cls: 1.4994  decode.d3.loss_mask: 0.8855  decode.d3.loss_dice: 1.3679  decode.d4.loss_cls: 1.4716  decode.d4.loss_mask: 0.8600  decode.d4.loss_dice: 1.3344  decode.d5.loss_cls: 1.4189  decode.d5.loss_mask: 0.8939  decode.d5.loss_dice: 1.3365  decode.d6.loss_cls: 1.4471  decode.d6.loss_mask: 0.9091  decode.d6.loss_dice: 1.3319  decode.d7.loss_cls: 1.4347  decode.d7.loss_mask: 0.9337  decode.d7.loss_dice: 1.3330  decode.d8.loss_cls: 1.4538  decode.d8.loss_mask: 0.9028  decode.d8.loss_dice: 1.3275
2023/05/24 01:54:58 - mmengine - INFO - Iter(train) [ 62100/160000]  lr: 6.4269e-06  eta: 11:39:26  time: 0.4115  data_time: 0.0101  memory: 4890  grad_norm: 102.9635  loss: 40.2295  decode.loss_cls: 1.2693  decode.loss_mask: 1.0095  decode.loss_dice: 1.4910  decode.d0.loss_cls: 3.0787  decode.d0.loss_mask: 1.0891  decode.d0.loss_dice: 1.6674  decode.d1.loss_cls: 1.3557  decode.d1.loss_mask: 1.0564  decode.d1.loss_dice: 1.5817  decode.d2.loss_cls: 1.3304  decode.d2.loss_mask: 1.0271  decode.d2.loss_dice: 1.5223  decode.d3.loss_cls: 1.3608  decode.d3.loss_mask: 1.0028  decode.d3.loss_dice: 1.4677  decode.d4.loss_cls: 1.3249  decode.d4.loss_mask: 0.9862  decode.d4.loss_dice: 1.4780  decode.d5.loss_cls: 1.2707  decode.d5.loss_mask: 1.0181  decode.d5.loss_dice: 1.4932  decode.d6.loss_cls: 1.3516  decode.d6.loss_mask: 0.9886  decode.d6.loss_dice: 1.4650  decode.d7.loss_cls: 1.3215  decode.d7.loss_mask: 0.9833  decode.d7.loss_dice: 1.4600  decode.d8.loss_cls: 1.3059  decode.d8.loss_mask: 0.9915  decode.d8.loss_dice: 1.4813
2023/05/24 01:55:19 - mmengine - INFO - Iter(train) [ 62150/160000]  lr: 6.4239e-06  eta: 11:39:04  time: 0.4202  data_time: 0.0105  memory: 4846  grad_norm: 89.4488  loss: 29.7153  decode.loss_cls: 1.1183  decode.loss_mask: 0.6137  decode.loss_dice: 1.0824  decode.d0.loss_cls: 2.7726  decode.d0.loss_mask: 0.6505  decode.d0.loss_dice: 1.1954  decode.d1.loss_cls: 1.1926  decode.d1.loss_mask: 0.6389  decode.d1.loss_dice: 1.1520  decode.d2.loss_cls: 1.0751  decode.d2.loss_mask: 0.6387  decode.d2.loss_dice: 1.1170  decode.d3.loss_cls: 1.0982  decode.d3.loss_mask: 0.6193  decode.d3.loss_dice: 1.0823  decode.d4.loss_cls: 1.0483  decode.d4.loss_mask: 0.6230  decode.d4.loss_dice: 1.0768  decode.d5.loss_cls: 0.9921  decode.d5.loss_mask: 0.6238  decode.d5.loss_dice: 1.0941  decode.d6.loss_cls: 1.0102  decode.d6.loss_mask: 0.6261  decode.d6.loss_dice: 1.0934  decode.d7.loss_cls: 0.9866  decode.d7.loss_mask: 0.6272  decode.d7.loss_dice: 1.1082  decode.d8.loss_cls: 1.0401  decode.d8.loss_mask: 0.6337  decode.d8.loss_dice: 1.0848
2023/05/24 01:55:40 - mmengine - INFO - Iter(train) [ 62200/160000]  lr: 6.4210e-06  eta: 11:38:42  time: 0.4219  data_time: 0.0102  memory: 4918  grad_norm: 92.0188  loss: 44.9118  decode.loss_cls: 1.6987  decode.loss_mask: 0.9120  decode.loss_dice: 1.6251  decode.d0.loss_cls: 3.6002  decode.d0.loss_mask: 0.8791  decode.d0.loss_dice: 1.8237  decode.d1.loss_cls: 1.9094  decode.d1.loss_mask: 0.9084  decode.d1.loss_dice: 1.6918  decode.d2.loss_cls: 1.7602  decode.d2.loss_mask: 0.9377  decode.d2.loss_dice: 1.6664  decode.d3.loss_cls: 1.6936  decode.d3.loss_mask: 0.9125  decode.d3.loss_dice: 1.6938  decode.d4.loss_cls: 1.6882  decode.d4.loss_mask: 0.8848  decode.d4.loss_dice: 1.6909  decode.d5.loss_cls: 1.7320  decode.d5.loss_mask: 0.8980  decode.d5.loss_dice: 1.7118  decode.d6.loss_cls: 1.7177  decode.d6.loss_mask: 0.8926  decode.d6.loss_dice: 1.6227  decode.d7.loss_cls: 1.6404  decode.d7.loss_mask: 0.8905  decode.d7.loss_dice: 1.6344  decode.d8.loss_cls: 1.6246  decode.d8.loss_mask: 0.9073  decode.d8.loss_dice: 1.6634
2023/05/24 01:56:01 - mmengine - INFO - Iter(train) [ 62250/160000]  lr: 6.4180e-06  eta: 11:38:20  time: 0.4153  data_time: 0.0106  memory: 4869  grad_norm: 95.3324  loss: 37.6774  decode.loss_cls: 1.3593  decode.loss_mask: 0.8147  decode.loss_dice: 1.3627  decode.d0.loss_cls: 3.4452  decode.d0.loss_mask: 0.8512  decode.d0.loss_dice: 1.5769  decode.d1.loss_cls: 1.4411  decode.d1.loss_mask: 0.8135  decode.d1.loss_dice: 1.4321  decode.d2.loss_cls: 1.3526  decode.d2.loss_mask: 0.8116  decode.d2.loss_dice: 1.3841  decode.d3.loss_cls: 1.4471  decode.d3.loss_mask: 0.7691  decode.d3.loss_dice: 1.3287  decode.d4.loss_cls: 1.3798  decode.d4.loss_mask: 0.8096  decode.d4.loss_dice: 1.3325  decode.d5.loss_cls: 1.3040  decode.d5.loss_mask: 0.8058  decode.d5.loss_dice: 1.3487  decode.d6.loss_cls: 1.3501  decode.d6.loss_mask: 0.8202  decode.d6.loss_dice: 1.3498  decode.d7.loss_cls: 1.3447  decode.d7.loss_mask: 0.8168  decode.d7.loss_dice: 1.3395  decode.d8.loss_cls: 1.3059  decode.d8.loss_mask: 0.8135  decode.d8.loss_dice: 1.3669
2023/05/24 01:56:22 - mmengine - INFO - Iter(train) [ 62300/160000]  lr: 6.4150e-06  eta: 11:37:57  time: 0.4131  data_time: 0.0101  memory: 4822  grad_norm: 89.6656  loss: 38.6659  decode.loss_cls: 1.3935  decode.loss_mask: 0.8329  decode.loss_dice: 1.4051  decode.d0.loss_cls: 3.1670  decode.d0.loss_mask: 0.8429  decode.d0.loss_dice: 1.5366  decode.d1.loss_cls: 1.5310  decode.d1.loss_mask: 0.8928  decode.d1.loss_dice: 1.4547  decode.d2.loss_cls: 1.4635  decode.d2.loss_mask: 0.8663  decode.d2.loss_dice: 1.4484  decode.d3.loss_cls: 1.4789  decode.d3.loss_mask: 0.8576  decode.d3.loss_dice: 1.3325  decode.d4.loss_cls: 1.4255  decode.d4.loss_mask: 0.8615  decode.d4.loss_dice: 1.3611  decode.d5.loss_cls: 1.4045  decode.d5.loss_mask: 0.8681  decode.d5.loss_dice: 1.3485  decode.d6.loss_cls: 1.4002  decode.d6.loss_mask: 0.8663  decode.d6.loss_dice: 1.3837  decode.d7.loss_cls: 1.3375  decode.d7.loss_mask: 0.8540  decode.d7.loss_dice: 1.4032  decode.d8.loss_cls: 1.4454  decode.d8.loss_mask: 0.8310  decode.d8.loss_dice: 1.3717
2023/05/24 01:56:43 - mmengine - INFO - Iter(train) [ 62350/160000]  lr: 6.4121e-06  eta: 11:37:35  time: 0.4117  data_time: 0.0100  memory: 4878  grad_norm: 106.7863  loss: 31.7904  decode.loss_cls: 0.8891  decode.loss_mask: 0.7906  decode.loss_dice: 1.1953  decode.d0.loss_cls: 2.9570  decode.d0.loss_mask: 0.8409  decode.d0.loss_dice: 1.4136  decode.d1.loss_cls: 1.1068  decode.d1.loss_mask: 0.8278  decode.d1.loss_dice: 1.3160  decode.d2.loss_cls: 1.0272  decode.d2.loss_mask: 0.7912  decode.d2.loss_dice: 1.2166  decode.d3.loss_cls: 1.0067  decode.d3.loss_mask: 0.7724  decode.d3.loss_dice: 1.1707  decode.d4.loss_cls: 0.9784  decode.d4.loss_mask: 0.7766  decode.d4.loss_dice: 1.2100  decode.d5.loss_cls: 0.9283  decode.d5.loss_mask: 0.7859  decode.d5.loss_dice: 1.1945  decode.d6.loss_cls: 0.8874  decode.d6.loss_mask: 0.7801  decode.d6.loss_dice: 1.2213  decode.d7.loss_cls: 0.9031  decode.d7.loss_mask: 0.7727  decode.d7.loss_dice: 1.1967  decode.d8.loss_cls: 0.8866  decode.d8.loss_mask: 0.7723  decode.d8.loss_dice: 1.1748
2023/05/24 01:57:04 - mmengine - INFO - Iter(train) [ 62400/160000]  lr: 6.4091e-06  eta: 11:37:13  time: 0.4449  data_time: 0.0100  memory: 4861  grad_norm: 89.8918  loss: 46.3708  decode.loss_cls: 1.5050  decode.loss_mask: 0.8512  decode.loss_dice: 1.9206  decode.d0.loss_cls: 3.5192  decode.d0.loss_mask: 0.9650  decode.d0.loss_dice: 2.2547  decode.d1.loss_cls: 1.6664  decode.d1.loss_mask: 1.0215  decode.d1.loss_dice: 2.1697  decode.d2.loss_cls: 1.5438  decode.d2.loss_mask: 0.9562  decode.d2.loss_dice: 2.0019  decode.d3.loss_cls: 1.5233  decode.d3.loss_mask: 0.9305  decode.d3.loss_dice: 1.9678  decode.d4.loss_cls: 1.5498  decode.d4.loss_mask: 0.8713  decode.d4.loss_dice: 1.9749  decode.d5.loss_cls: 1.4798  decode.d5.loss_mask: 0.8944  decode.d5.loss_dice: 1.9442  decode.d6.loss_cls: 1.5071  decode.d6.loss_mask: 0.8577  decode.d6.loss_dice: 1.9124  decode.d7.loss_cls: 1.5407  decode.d7.loss_mask: 0.8600  decode.d7.loss_dice: 1.8863  decode.d8.loss_cls: 1.5595  decode.d8.loss_mask: 0.8356  decode.d8.loss_dice: 1.9002
2023/05/24 01:57:25 - mmengine - INFO - Iter(train) [ 62450/160000]  lr: 6.4062e-06  eta: 11:36:50  time: 0.4145  data_time: 0.0103  memory: 4901  grad_norm: 80.9866  loss: 35.5255  decode.loss_cls: 1.2769  decode.loss_mask: 0.6674  decode.loss_dice: 1.3113  decode.d0.loss_cls: 3.1311  decode.d0.loss_mask: 0.7326  decode.d0.loss_dice: 1.5995  decode.d1.loss_cls: 1.3889  decode.d1.loss_mask: 0.7192  decode.d1.loss_dice: 1.4390  decode.d2.loss_cls: 1.2906  decode.d2.loss_mask: 0.6954  decode.d2.loss_dice: 1.4379  decode.d3.loss_cls: 1.2844  decode.d3.loss_mask: 0.6833  decode.d3.loss_dice: 1.3768  decode.d4.loss_cls: 1.2597  decode.d4.loss_mask: 0.6849  decode.d4.loss_dice: 1.3604  decode.d5.loss_cls: 1.2550  decode.d5.loss_mask: 0.6805  decode.d5.loss_dice: 1.3732  decode.d6.loss_cls: 1.2304  decode.d6.loss_mask: 0.6990  decode.d6.loss_dice: 1.3513  decode.d7.loss_cls: 1.2279  decode.d7.loss_mask: 0.7011  decode.d7.loss_dice: 1.3879  decode.d8.loss_cls: 1.2355  decode.d8.loss_mask: 0.6787  decode.d8.loss_dice: 1.3659
2023/05/24 01:57:45 - mmengine - INFO - Iter(train) [ 62500/160000]  lr: 6.4032e-06  eta: 11:36:28  time: 0.4099  data_time: 0.0100  memory: 4907  grad_norm: 87.6302  loss: 40.0218  decode.loss_cls: 1.5159  decode.loss_mask: 0.7588  decode.loss_dice: 1.3985  decode.d0.loss_cls: 3.4322  decode.d0.loss_mask: 0.7824  decode.d0.loss_dice: 1.6525  decode.d1.loss_cls: 1.6313  decode.d1.loss_mask: 0.7917  decode.d1.loss_dice: 1.5159  decode.d2.loss_cls: 1.6079  decode.d2.loss_mask: 0.8175  decode.d2.loss_dice: 1.4883  decode.d3.loss_cls: 1.6615  decode.d3.loss_mask: 0.8052  decode.d3.loss_dice: 1.4356  decode.d4.loss_cls: 1.6354  decode.d4.loss_mask: 0.7873  decode.d4.loss_dice: 1.4183  decode.d5.loss_cls: 1.5566  decode.d5.loss_mask: 0.7930  decode.d5.loss_dice: 1.4159  decode.d6.loss_cls: 1.5682  decode.d6.loss_mask: 0.7580  decode.d6.loss_dice: 1.4019  decode.d7.loss_cls: 1.5681  decode.d7.loss_mask: 0.7546  decode.d7.loss_dice: 1.4094  decode.d8.loss_cls: 1.5119  decode.d8.loss_mask: 0.7463  decode.d8.loss_dice: 1.4017
2023/05/24 01:58:06 - mmengine - INFO - Iter(train) [ 62550/160000]  lr: 6.4003e-06  eta: 11:36:05  time: 0.4118  data_time: 0.0104  memory: 4886  grad_norm: 90.6489  loss: 38.1152  decode.loss_cls: 1.1926  decode.loss_mask: 0.8873  decode.loss_dice: 1.3952  decode.d0.loss_cls: 3.3016  decode.d0.loss_mask: 0.9472  decode.d0.loss_dice: 1.5537  decode.d1.loss_cls: 1.3425  decode.d1.loss_mask: 0.9563  decode.d1.loss_dice: 1.5005  decode.d2.loss_cls: 1.4050  decode.d2.loss_mask: 0.9725  decode.d2.loss_dice: 1.4491  decode.d3.loss_cls: 1.3379  decode.d3.loss_mask: 0.8845  decode.d3.loss_dice: 1.3788  decode.d4.loss_cls: 1.2533  decode.d4.loss_mask: 0.8758  decode.d4.loss_dice: 1.3920  decode.d5.loss_cls: 1.2650  decode.d5.loss_mask: 0.8774  decode.d5.loss_dice: 1.4318  decode.d6.loss_cls: 1.2311  decode.d6.loss_mask: 0.9080  decode.d6.loss_dice: 1.3841  decode.d7.loss_cls: 1.2226  decode.d7.loss_mask: 0.8998  decode.d7.loss_dice: 1.4065  decode.d8.loss_cls: 1.1909  decode.d8.loss_mask: 0.8792  decode.d8.loss_dice: 1.3934
2023/05/24 01:58:27 - mmengine - INFO - Iter(train) [ 62600/160000]  lr: 6.3973e-06  eta: 11:35:43  time: 0.4085  data_time: 0.0102  memory: 4857  grad_norm: 81.0942  loss: 35.5624  decode.loss_cls: 1.3145  decode.loss_mask: 0.8528  decode.loss_dice: 1.1583  decode.d0.loss_cls: 3.0696  decode.d0.loss_mask: 0.9362  decode.d0.loss_dice: 1.4749  decode.d1.loss_cls: 1.3271  decode.d1.loss_mask: 0.9566  decode.d1.loss_dice: 1.2822  decode.d2.loss_cls: 1.3321  decode.d2.loss_mask: 0.8529  decode.d2.loss_dice: 1.2177  decode.d3.loss_cls: 1.3032  decode.d3.loss_mask: 0.8547  decode.d3.loss_dice: 1.1785  decode.d4.loss_cls: 1.2579  decode.d4.loss_mask: 0.8598  decode.d4.loss_dice: 1.1805  decode.d5.loss_cls: 1.2929  decode.d5.loss_mask: 0.8086  decode.d5.loss_dice: 1.1689  decode.d6.loss_cls: 1.3637  decode.d6.loss_mask: 0.8262  decode.d6.loss_dice: 1.1284  decode.d7.loss_cls: 1.3268  decode.d7.loss_mask: 0.8237  decode.d7.loss_dice: 1.1363  decode.d8.loss_cls: 1.2850  decode.d8.loss_mask: 0.8364  decode.d8.loss_dice: 1.1561
2023/05/24 01:58:48 - mmengine - INFO - Iter(train) [ 62650/160000]  lr: 6.3944e-06  eta: 11:35:21  time: 0.4100  data_time: 0.0101  memory: 4837  grad_norm: 110.2167  loss: 37.5575  decode.loss_cls: 1.2861  decode.loss_mask: 0.8006  decode.loss_dice: 1.3673  decode.d0.loss_cls: 3.2087  decode.d0.loss_mask: 0.8565  decode.d0.loss_dice: 1.5999  decode.d1.loss_cls: 1.4744  decode.d1.loss_mask: 0.8570  decode.d1.loss_dice: 1.4825  decode.d2.loss_cls: 1.3897  decode.d2.loss_mask: 0.8010  decode.d2.loss_dice: 1.4401  decode.d3.loss_cls: 1.3523  decode.d3.loss_mask: 0.7879  decode.d3.loss_dice: 1.3688  decode.d4.loss_cls: 1.3119  decode.d4.loss_mask: 0.7917  decode.d4.loss_dice: 1.3810  decode.d5.loss_cls: 1.3272  decode.d5.loss_mask: 0.8181  decode.d5.loss_dice: 1.3745  decode.d6.loss_cls: 1.3432  decode.d6.loss_mask: 0.8003  decode.d6.loss_dice: 1.3438  decode.d7.loss_cls: 1.2696  decode.d7.loss_mask: 0.8113  decode.d7.loss_dice: 1.3828  decode.d8.loss_cls: 1.3076  decode.d8.loss_mask: 0.8317  decode.d8.loss_dice: 1.3899
2023/05/24 01:59:09 - mmengine - INFO - Iter(train) [ 62700/160000]  lr: 6.3914e-06  eta: 11:34:59  time: 0.4106  data_time: 0.0104  memory: 4866  grad_norm: 117.3353  loss: 40.2749  decode.loss_cls: 1.3026  decode.loss_mask: 0.9497  decode.loss_dice: 1.4703  decode.d0.loss_cls: 3.4787  decode.d0.loss_mask: 0.9478  decode.d0.loss_dice: 1.7643  decode.d1.loss_cls: 1.4514  decode.d1.loss_mask: 1.0262  decode.d1.loss_dice: 1.5851  decode.d2.loss_cls: 1.3947  decode.d2.loss_mask: 0.9888  decode.d2.loss_dice: 1.5029  decode.d3.loss_cls: 1.3226  decode.d3.loss_mask: 0.9310  decode.d3.loss_dice: 1.4759  decode.d4.loss_cls: 1.2920  decode.d4.loss_mask: 0.9762  decode.d4.loss_dice: 1.4751  decode.d5.loss_cls: 1.2755  decode.d5.loss_mask: 0.9646  decode.d5.loss_dice: 1.4776  decode.d6.loss_cls: 1.3058  decode.d6.loss_mask: 0.9533  decode.d6.loss_dice: 1.4943  decode.d7.loss_cls: 1.3183  decode.d7.loss_mask: 0.9371  decode.d7.loss_dice: 1.4763  decode.d8.loss_cls: 1.3226  decode.d8.loss_mask: 0.9369  decode.d8.loss_dice: 1.4773
2023/05/24 01:59:30 - mmengine - INFO - Iter(train) [ 62750/160000]  lr: 6.3884e-06  eta: 11:34:36  time: 0.4089  data_time: 0.0103  memory: 4882  grad_norm: 111.1014  loss: 32.8125  decode.loss_cls: 1.0234  decode.loss_mask: 0.7950  decode.loss_dice: 1.1728  decode.d0.loss_cls: 2.9420  decode.d0.loss_mask: 0.8144  decode.d0.loss_dice: 1.3241  decode.d1.loss_cls: 1.2597  decode.d1.loss_mask: 0.8259  decode.d1.loss_dice: 1.2393  decode.d2.loss_cls: 1.1497  decode.d2.loss_mask: 0.8055  decode.d2.loss_dice: 1.2248  decode.d3.loss_cls: 1.0525  decode.d3.loss_mask: 0.7706  decode.d3.loss_dice: 1.1752  decode.d4.loss_cls: 1.0905  decode.d4.loss_mask: 0.7695  decode.d4.loss_dice: 1.1677  decode.d5.loss_cls: 1.0584  decode.d5.loss_mask: 0.8315  decode.d5.loss_dice: 1.1802  decode.d6.loss_cls: 1.1086  decode.d6.loss_mask: 0.7928  decode.d6.loss_dice: 1.1656  decode.d7.loss_cls: 1.0597  decode.d7.loss_mask: 0.8027  decode.d7.loss_dice: 1.1811  decode.d8.loss_cls: 1.0622  decode.d8.loss_mask: 0.7964  decode.d8.loss_dice: 1.1707
2023/05/24 01:59:50 - mmengine - INFO - Iter(train) [ 62800/160000]  lr: 6.3855e-06  eta: 11:34:13  time: 0.4118  data_time: 0.0101  memory: 4891  grad_norm: 92.9660  loss: 41.6291  decode.loss_cls: 1.1862  decode.loss_mask: 0.9587  decode.loss_dice: 1.7339  decode.d0.loss_cls: 3.1290  decode.d0.loss_mask: 1.0303  decode.d0.loss_dice: 1.9975  decode.d1.loss_cls: 1.2798  decode.d1.loss_mask: 0.9907  decode.d1.loss_dice: 1.9345  decode.d2.loss_cls: 1.1702  decode.d2.loss_mask: 0.9682  decode.d2.loss_dice: 1.8509  decode.d3.loss_cls: 1.2735  decode.d3.loss_mask: 0.9532  decode.d3.loss_dice: 1.7689  decode.d4.loss_cls: 1.1745  decode.d4.loss_mask: 0.9508  decode.d4.loss_dice: 1.8296  decode.d5.loss_cls: 1.1908  decode.d5.loss_mask: 0.9262  decode.d5.loss_dice: 1.7827  decode.d6.loss_cls: 1.1620  decode.d6.loss_mask: 0.9627  decode.d6.loss_dice: 1.7462  decode.d7.loss_cls: 1.1565  decode.d7.loss_mask: 0.9575  decode.d7.loss_dice: 1.7231  decode.d8.loss_cls: 1.1695  decode.d8.loss_mask: 0.9459  decode.d8.loss_dice: 1.7254
2023/05/24 02:00:11 - mmengine - INFO - Iter(train) [ 62850/160000]  lr: 6.3825e-06  eta: 11:33:51  time: 0.4448  data_time: 0.0098  memory: 4853  grad_norm: 94.4962  loss: 47.2011  decode.loss_cls: 1.6254  decode.loss_mask: 1.0519  decode.loss_dice: 1.7118  decode.d0.loss_cls: 3.4126  decode.d0.loss_mask: 1.1914  decode.d0.loss_dice: 2.1072  decode.d1.loss_cls: 1.7846  decode.d1.loss_mask: 1.1146  decode.d1.loss_dice: 1.9100  decode.d2.loss_cls: 1.6044  decode.d2.loss_mask: 1.1762  decode.d2.loss_dice: 1.8674  decode.d3.loss_cls: 1.5993  decode.d3.loss_mask: 1.1435  decode.d3.loss_dice: 1.8225  decode.d4.loss_cls: 1.5398  decode.d4.loss_mask: 1.1097  decode.d4.loss_dice: 1.8282  decode.d5.loss_cls: 1.5874  decode.d5.loss_mask: 1.0890  decode.d5.loss_dice: 1.7762  decode.d6.loss_cls: 1.5484  decode.d6.loss_mask: 1.0807  decode.d6.loss_dice: 1.7562  decode.d7.loss_cls: 1.5803  decode.d7.loss_mask: 1.0657  decode.d7.loss_dice: 1.7351  decode.d8.loss_cls: 1.5640  decode.d8.loss_mask: 1.0528  decode.d8.loss_dice: 1.7646
2023/05/24 02:00:33 - mmengine - INFO - Iter(train) [ 62900/160000]  lr: 6.3796e-06  eta: 11:33:30  time: 0.4205  data_time: 0.0102  memory: 4885  grad_norm: 101.4137  loss: 32.3600  decode.loss_cls: 1.1633  decode.loss_mask: 0.7155  decode.loss_dice: 1.0667  decode.d0.loss_cls: 3.0330  decode.d0.loss_mask: 0.6805  decode.d0.loss_dice: 1.1726  decode.d1.loss_cls: 1.3698  decode.d1.loss_mask: 0.7979  decode.d1.loss_dice: 1.1317  decode.d2.loss_cls: 1.2891  decode.d2.loss_mask: 0.7280  decode.d2.loss_dice: 1.1046  decode.d3.loss_cls: 1.2538  decode.d3.loss_mask: 0.7796  decode.d3.loss_dice: 1.0880  decode.d4.loss_cls: 1.2189  decode.d4.loss_mask: 0.7482  decode.d4.loss_dice: 1.0775  decode.d5.loss_cls: 1.2470  decode.d5.loss_mask: 0.7356  decode.d5.loss_dice: 1.0248  decode.d6.loss_cls: 1.2551  decode.d6.loss_mask: 0.7232  decode.d6.loss_dice: 1.0305  decode.d7.loss_cls: 1.1808  decode.d7.loss_mask: 0.7111  decode.d7.loss_dice: 1.0658  decode.d8.loss_cls: 1.1654  decode.d8.loss_mask: 0.7214  decode.d8.loss_dice: 1.0806
2023/05/24 02:00:54 - mmengine - INFO - Iter(train) [ 62950/160000]  lr: 6.3766e-06  eta: 11:33:08  time: 0.4366  data_time: 0.0101  memory: 4938  grad_norm: 80.2171  loss: 34.2029  decode.loss_cls: 1.0138  decode.loss_mask: 0.8834  decode.loss_dice: 1.2960  decode.d0.loss_cls: 2.8291  decode.d0.loss_mask: 0.8987  decode.d0.loss_dice: 1.4349  decode.d1.loss_cls: 1.1336  decode.d1.loss_mask: 0.8813  decode.d1.loss_dice: 1.3785  decode.d2.loss_cls: 1.0788  decode.d2.loss_mask: 0.8478  decode.d2.loss_dice: 1.3518  decode.d3.loss_cls: 1.0320  decode.d3.loss_mask: 0.8403  decode.d3.loss_dice: 1.3248  decode.d4.loss_cls: 1.0221  decode.d4.loss_mask: 0.8307  decode.d4.loss_dice: 1.3127  decode.d5.loss_cls: 1.0151  decode.d5.loss_mask: 0.8543  decode.d5.loss_dice: 1.3116  decode.d6.loss_cls: 1.0606  decode.d6.loss_mask: 0.8395  decode.d6.loss_dice: 1.2968  decode.d7.loss_cls: 1.0574  decode.d7.loss_mask: 0.8378  decode.d7.loss_dice: 1.2953  decode.d8.loss_cls: 1.0565  decode.d8.loss_mask: 0.8671  decode.d8.loss_dice: 1.3204
2023/05/24 02:01:15 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 02:01:15 - mmengine - INFO - Iter(train) [ 63000/160000]  lr: 6.3737e-06  eta: 11:32:47  time: 0.4217  data_time: 0.0103  memory: 4909  grad_norm: 114.5421  loss: 29.8700  decode.loss_cls: 1.1382  decode.loss_mask: 0.5899  decode.loss_dice: 0.9948  decode.d0.loss_cls: 3.0026  decode.d0.loss_mask: 0.6777  decode.d0.loss_dice: 1.1772  decode.d1.loss_cls: 1.2903  decode.d1.loss_mask: 0.6484  decode.d1.loss_dice: 1.0869  decode.d2.loss_cls: 1.1610  decode.d2.loss_mask: 0.6178  decode.d2.loss_dice: 1.0329  decode.d3.loss_cls: 1.1643  decode.d3.loss_mask: 0.6198  decode.d3.loss_dice: 1.0120  decode.d4.loss_cls: 1.0564  decode.d4.loss_mask: 0.6178  decode.d4.loss_dice: 1.0361  decode.d5.loss_cls: 1.1159  decode.d5.loss_mask: 0.6259  decode.d5.loss_dice: 1.0503  decode.d6.loss_cls: 1.1030  decode.d6.loss_mask: 0.6090  decode.d6.loss_dice: 0.9995  decode.d7.loss_cls: 1.1066  decode.d7.loss_mask: 0.6136  decode.d7.loss_dice: 1.0136  decode.d8.loss_cls: 1.1287  decode.d8.loss_mask: 0.5904  decode.d8.loss_dice: 0.9893
2023/05/24 02:01:15 - mmengine - INFO - Saving checkpoint at 63000 iterations
2023/05/24 02:01:41 - mmengine - INFO - Iter(train) [ 63050/160000]  lr: 6.3707e-06  eta: 11:32:32  time: 0.4087  data_time: 0.0100  memory: 4876  grad_norm: 101.9043  loss: 35.0862  decode.loss_cls: 1.1212  decode.loss_mask: 0.8258  decode.loss_dice: 1.2435  decode.d0.loss_cls: 3.1220  decode.d0.loss_mask: 0.8458  decode.d0.loss_dice: 1.4777  decode.d1.loss_cls: 1.3045  decode.d1.loss_mask: 0.8739  decode.d1.loss_dice: 1.3823  decode.d2.loss_cls: 1.2884  decode.d2.loss_mask: 0.8252  decode.d2.loss_dice: 1.3240  decode.d3.loss_cls: 1.1323  decode.d3.loss_mask: 0.8269  decode.d3.loss_dice: 1.2909  decode.d4.loss_cls: 1.1594  decode.d4.loss_mask: 0.8309  decode.d4.loss_dice: 1.2699  decode.d5.loss_cls: 1.1816  decode.d5.loss_mask: 0.7997  decode.d5.loss_dice: 1.2659  decode.d6.loss_cls: 1.1174  decode.d6.loss_mask: 0.8616  decode.d6.loss_dice: 1.2607  decode.d7.loss_cls: 1.1380  decode.d7.loss_mask: 0.8432  decode.d7.loss_dice: 1.2431  decode.d8.loss_cls: 1.1471  decode.d8.loss_mask: 0.8496  decode.d8.loss_dice: 1.2338
2023/05/24 02:02:02 - mmengine - INFO - Iter(train) [ 63100/160000]  lr: 6.3677e-06  eta: 11:32:10  time: 0.4114  data_time: 0.0103  memory: 4804  grad_norm: 94.0856  loss: 35.6435  decode.loss_cls: 1.3227  decode.loss_mask: 0.7857  decode.loss_dice: 1.0969  decode.d0.loss_cls: 3.3110  decode.d0.loss_mask: 0.8561  decode.d0.loss_dice: 1.2885  decode.d1.loss_cls: 1.3569  decode.d1.loss_mask: 0.8925  decode.d1.loss_dice: 1.2513  decode.d2.loss_cls: 1.4171  decode.d2.loss_mask: 0.8643  decode.d2.loss_dice: 1.1436  decode.d3.loss_cls: 1.3916  decode.d3.loss_mask: 0.8329  decode.d3.loss_dice: 1.1464  decode.d4.loss_cls: 1.3562  decode.d4.loss_mask: 0.8449  decode.d4.loss_dice: 1.1622  decode.d5.loss_cls: 1.4051  decode.d5.loss_mask: 0.8171  decode.d5.loss_dice: 1.1268  decode.d6.loss_cls: 1.3883  decode.d6.loss_mask: 0.8232  decode.d6.loss_dice: 1.1348  decode.d7.loss_cls: 1.4152  decode.d7.loss_mask: 0.8045  decode.d7.loss_dice: 1.1126  decode.d8.loss_cls: 1.3220  decode.d8.loss_mask: 0.8155  decode.d8.loss_dice: 1.1575
2023/05/24 02:02:23 - mmengine - INFO - Iter(train) [ 63150/160000]  lr: 6.3648e-06  eta: 11:31:47  time: 0.4162  data_time: 0.0105  memory: 4905  grad_norm: 85.0106  loss: 33.0339  decode.loss_cls: 1.1469  decode.loss_mask: 0.6960  decode.loss_dice: 1.1406  decode.d0.loss_cls: 2.7833  decode.d0.loss_mask: 0.7738  decode.d0.loss_dice: 1.3992  decode.d1.loss_cls: 1.3756  decode.d1.loss_mask: 0.7749  decode.d1.loss_dice: 1.2615  decode.d2.loss_cls: 1.2728  decode.d2.loss_mask: 0.7229  decode.d2.loss_dice: 1.1918  decode.d3.loss_cls: 1.2828  decode.d3.loss_mask: 0.7017  decode.d3.loss_dice: 1.1519  decode.d4.loss_cls: 1.2631  decode.d4.loss_mask: 0.6982  decode.d4.loss_dice: 1.1731  decode.d5.loss_cls: 1.2179  decode.d5.loss_mask: 0.7028  decode.d5.loss_dice: 1.1693  decode.d6.loss_cls: 1.1907  decode.d6.loss_mask: 0.7161  decode.d6.loss_dice: 1.1531  decode.d7.loss_cls: 1.1487  decode.d7.loss_mask: 0.7082  decode.d7.loss_dice: 1.1517  decode.d8.loss_cls: 1.2348  decode.d8.loss_mask: 0.6958  decode.d8.loss_dice: 1.1346
2023/05/24 02:02:44 - mmengine - INFO - Iter(train) [ 63200/160000]  lr: 6.3618e-06  eta: 11:31:25  time: 0.4091  data_time: 0.0103  memory: 4840  grad_norm: 84.4251  loss: 37.9107  decode.loss_cls: 1.3760  decode.loss_mask: 0.7270  decode.loss_dice: 1.3935  decode.d0.loss_cls: 3.1764  decode.d0.loss_mask: 0.8367  decode.d0.loss_dice: 1.6565  decode.d1.loss_cls: 1.3626  decode.d1.loss_mask: 0.8521  decode.d1.loss_dice: 1.6069  decode.d2.loss_cls: 1.3709  decode.d2.loss_mask: 0.7929  decode.d2.loss_dice: 1.4951  decode.d3.loss_cls: 1.4453  decode.d3.loss_mask: 0.7513  decode.d3.loss_dice: 1.4407  decode.d4.loss_cls: 1.4599  decode.d4.loss_mask: 0.7429  decode.d4.loss_dice: 1.4031  decode.d5.loss_cls: 1.4004  decode.d5.loss_mask: 0.7238  decode.d5.loss_dice: 1.3945  decode.d6.loss_cls: 1.3942  decode.d6.loss_mask: 0.7349  decode.d6.loss_dice: 1.4120  decode.d7.loss_cls: 1.3795  decode.d7.loss_mask: 0.7296  decode.d7.loss_dice: 1.3865  decode.d8.loss_cls: 1.3445  decode.d8.loss_mask: 0.7364  decode.d8.loss_dice: 1.3844
2023/05/24 02:03:04 - mmengine - INFO - Iter(train) [ 63250/160000]  lr: 6.3589e-06  eta: 11:31:02  time: 0.4132  data_time: 0.0101  memory: 4845  grad_norm: 89.9372  loss: 36.0587  decode.loss_cls: 1.2278  decode.loss_mask: 0.7412  decode.loss_dice: 1.3844  decode.d0.loss_cls: 3.1952  decode.d0.loss_mask: 0.7451  decode.d0.loss_dice: 1.6434  decode.d1.loss_cls: 1.2750  decode.d1.loss_mask: 0.7656  decode.d1.loss_dice: 1.5306  decode.d2.loss_cls: 1.2532  decode.d2.loss_mask: 0.7437  decode.d2.loss_dice: 1.4675  decode.d3.loss_cls: 1.2887  decode.d3.loss_mask: 0.7454  decode.d3.loss_dice: 1.3944  decode.d4.loss_cls: 1.2525  decode.d4.loss_mask: 0.7552  decode.d4.loss_dice: 1.3555  decode.d5.loss_cls: 1.1920  decode.d5.loss_mask: 0.7306  decode.d5.loss_dice: 1.4191  decode.d6.loss_cls: 1.2370  decode.d6.loss_mask: 0.7467  decode.d6.loss_dice: 1.3583  decode.d7.loss_cls: 1.1914  decode.d7.loss_mask: 0.7486  decode.d7.loss_dice: 1.3511  decode.d8.loss_cls: 1.2117  decode.d8.loss_mask: 0.7387  decode.d8.loss_dice: 1.3692
2023/05/24 02:03:26 - mmengine - INFO - Iter(train) [ 63300/160000]  lr: 6.3559e-06  eta: 11:30:41  time: 0.4537  data_time: 0.0103  memory: 4816  grad_norm: 88.2913  loss: 33.3912  decode.loss_cls: 1.2160  decode.loss_mask: 0.6230  decode.loss_dice: 1.1873  decode.d0.loss_cls: 3.1654  decode.d0.loss_mask: 0.6374  decode.d0.loss_dice: 1.4101  decode.d1.loss_cls: 1.4996  decode.d1.loss_mask: 0.6283  decode.d1.loss_dice: 1.3540  decode.d2.loss_cls: 1.3148  decode.d2.loss_mask: 0.6277  decode.d2.loss_dice: 1.2566  decode.d3.loss_cls: 1.3237  decode.d3.loss_mask: 0.6108  decode.d3.loss_dice: 1.2430  decode.d4.loss_cls: 1.3200  decode.d4.loss_mask: 0.6242  decode.d4.loss_dice: 1.1947  decode.d5.loss_cls: 1.2604  decode.d5.loss_mask: 0.6134  decode.d5.loss_dice: 1.2354  decode.d6.loss_cls: 1.1628  decode.d6.loss_mask: 0.6168  decode.d6.loss_dice: 1.2260  decode.d7.loss_cls: 1.1890  decode.d7.loss_mask: 0.6246  decode.d7.loss_dice: 1.2270  decode.d8.loss_cls: 1.1637  decode.d8.loss_mask: 0.6295  decode.d8.loss_dice: 1.2059
2023/05/24 02:03:48 - mmengine - INFO - Iter(train) [ 63350/160000]  lr: 6.3530e-06  eta: 11:30:20  time: 0.4185  data_time: 0.0102  memory: 4859  grad_norm: 100.8656  loss: 33.6982  decode.loss_cls: 1.1267  decode.loss_mask: 0.7399  decode.loss_dice: 1.2525  decode.d0.loss_cls: 2.9448  decode.d0.loss_mask: 0.7629  decode.d0.loss_dice: 1.4999  decode.d1.loss_cls: 1.2761  decode.d1.loss_mask: 0.7340  decode.d1.loss_dice: 1.3467  decode.d2.loss_cls: 1.1759  decode.d2.loss_mask: 0.7287  decode.d2.loss_dice: 1.2766  decode.d3.loss_cls: 1.1578  decode.d3.loss_mask: 0.7804  decode.d3.loss_dice: 1.2643  decode.d4.loss_cls: 1.1516  decode.d4.loss_mask: 0.7536  decode.d4.loss_dice: 1.2633  decode.d5.loss_cls: 1.1692  decode.d5.loss_mask: 0.7324  decode.d5.loss_dice: 1.2335  decode.d6.loss_cls: 1.1884  decode.d6.loss_mask: 0.7086  decode.d6.loss_dice: 1.2153  decode.d7.loss_cls: 1.1534  decode.d7.loss_mask: 0.7102  decode.d7.loss_dice: 1.2217  decode.d8.loss_cls: 1.1319  decode.d8.loss_mask: 0.7319  decode.d8.loss_dice: 1.2658
2023/05/24 02:04:09 - mmengine - INFO - Iter(train) [ 63400/160000]  lr: 6.3500e-06  eta: 11:29:58  time: 0.4188  data_time: 0.0104  memory: 4856  grad_norm: 103.0772  loss: 42.8340  decode.loss_cls: 1.5240  decode.loss_mask: 0.8875  decode.loss_dice: 1.6319  decode.d0.loss_cls: 3.4019  decode.d0.loss_mask: 0.8861  decode.d0.loss_dice: 1.8851  decode.d1.loss_cls: 1.7435  decode.d1.loss_mask: 0.9025  decode.d1.loss_dice: 1.7177  decode.d2.loss_cls: 1.5014  decode.d2.loss_mask: 0.8998  decode.d2.loss_dice: 1.6380  decode.d3.loss_cls: 1.5669  decode.d3.loss_mask: 0.8699  decode.d3.loss_dice: 1.6432  decode.d4.loss_cls: 1.5430  decode.d4.loss_mask: 0.8711  decode.d4.loss_dice: 1.6428  decode.d5.loss_cls: 1.5285  decode.d5.loss_mask: 0.8776  decode.d5.loss_dice: 1.6012  decode.d6.loss_cls: 1.5241  decode.d6.loss_mask: 0.8932  decode.d6.loss_dice: 1.6156  decode.d7.loss_cls: 1.4700  decode.d7.loss_mask: 0.9134  decode.d7.loss_dice: 1.6254  decode.d8.loss_cls: 1.4787  decode.d8.loss_mask: 0.9236  decode.d8.loss_dice: 1.6264
2023/05/24 02:04:30 - mmengine - INFO - Iter(train) [ 63450/160000]  lr: 6.3470e-06  eta: 11:29:36  time: 0.4290  data_time: 0.0102  memory: 4909  grad_norm: 156.5340  loss: 37.8065  decode.loss_cls: 1.6073  decode.loss_mask: 0.7277  decode.loss_dice: 1.1498  decode.d0.loss_cls: 3.4826  decode.d0.loss_mask: 0.8088  decode.d0.loss_dice: 1.4211  decode.d1.loss_cls: 1.7142  decode.d1.loss_mask: 0.7638  decode.d1.loss_dice: 1.3613  decode.d2.loss_cls: 1.6883  decode.d2.loss_mask: 0.7662  decode.d2.loss_dice: 1.2430  decode.d3.loss_cls: 1.5947  decode.d3.loss_mask: 0.7440  decode.d3.loss_dice: 1.1997  decode.d4.loss_cls: 1.5599  decode.d4.loss_mask: 0.7373  decode.d4.loss_dice: 1.2142  decode.d5.loss_cls: 1.6036  decode.d5.loss_mask: 0.7413  decode.d5.loss_dice: 1.1906  decode.d6.loss_cls: 1.5892  decode.d6.loss_mask: 0.7434  decode.d6.loss_dice: 1.1761  decode.d7.loss_cls: 1.5499  decode.d7.loss_mask: 0.7567  decode.d7.loss_dice: 1.1713  decode.d8.loss_cls: 1.5916  decode.d8.loss_mask: 0.7369  decode.d8.loss_dice: 1.1717
2023/05/24 02:04:51 - mmengine - INFO - Iter(train) [ 63500/160000]  lr: 6.3441e-06  eta: 11:29:15  time: 0.4335  data_time: 0.0102  memory: 4852  grad_norm: 91.9128  loss: 39.9949  decode.loss_cls: 1.4481  decode.loss_mask: 0.7756  decode.loss_dice: 1.4632  decode.d0.loss_cls: 3.3380  decode.d0.loss_mask: 0.8521  decode.d0.loss_dice: 1.6990  decode.d1.loss_cls: 1.5939  decode.d1.loss_mask: 0.7948  decode.d1.loss_dice: 1.5790  decode.d2.loss_cls: 1.4248  decode.d2.loss_mask: 0.8313  decode.d2.loss_dice: 1.5410  decode.d3.loss_cls: 1.5740  decode.d3.loss_mask: 0.7661  decode.d3.loss_dice: 1.4965  decode.d4.loss_cls: 1.5245  decode.d4.loss_mask: 0.7977  decode.d4.loss_dice: 1.5230  decode.d5.loss_cls: 1.4765  decode.d5.loss_mask: 0.7987  decode.d5.loss_dice: 1.5190  decode.d6.loss_cls: 1.5421  decode.d6.loss_mask: 0.7671  decode.d6.loss_dice: 1.4631  decode.d7.loss_cls: 1.4649  decode.d7.loss_mask: 0.7793  decode.d7.loss_dice: 1.4861  decode.d8.loss_cls: 1.4282  decode.d8.loss_mask: 0.7772  decode.d8.loss_dice: 1.4701
2023/05/24 02:05:12 - mmengine - INFO - Iter(train) [ 63550/160000]  lr: 6.3411e-06  eta: 11:28:53  time: 0.4116  data_time: 0.0100  memory: 4918  grad_norm: 125.6718  loss: 39.8431  decode.loss_cls: 1.4747  decode.loss_mask: 0.7717  decode.loss_dice: 1.3923  decode.d0.loss_cls: 3.5201  decode.d0.loss_mask: 0.8171  decode.d0.loss_dice: 1.6533  decode.d1.loss_cls: 1.8472  decode.d1.loss_mask: 0.7857  decode.d1.loss_dice: 1.4791  decode.d2.loss_cls: 1.7227  decode.d2.loss_mask: 0.8155  decode.d2.loss_dice: 1.4099  decode.d3.loss_cls: 1.5439  decode.d3.loss_mask: 0.7299  decode.d3.loss_dice: 1.4502  decode.d4.loss_cls: 1.3679  decode.d4.loss_mask: 0.7799  decode.d4.loss_dice: 1.4635  decode.d5.loss_cls: 1.5709  decode.d5.loss_mask: 0.7535  decode.d5.loss_dice: 1.4463  decode.d6.loss_cls: 1.5574  decode.d6.loss_mask: 0.7587  decode.d6.loss_dice: 1.4253  decode.d7.loss_cls: 1.4529  decode.d7.loss_mask: 0.7846  decode.d7.loss_dice: 1.4039  decode.d8.loss_cls: 1.4709  decode.d8.loss_mask: 0.7821  decode.d8.loss_dice: 1.4116
2023/05/24 02:05:34 - mmengine - INFO - Iter(train) [ 63600/160000]  lr: 6.3382e-06  eta: 11:28:32  time: 0.4742  data_time: 0.0106  memory: 4829  grad_norm: 96.3439  loss: 32.4450  decode.loss_cls: 1.1416  decode.loss_mask: 0.5633  decode.loss_dice: 1.2256  decode.d0.loss_cls: 3.0452  decode.d0.loss_mask: 0.6129  decode.d0.loss_dice: 1.4581  decode.d1.loss_cls: 1.2918  decode.d1.loss_mask: 0.5853  decode.d1.loss_dice: 1.3742  decode.d2.loss_cls: 1.2459  decode.d2.loss_mask: 0.5947  decode.d2.loss_dice: 1.3363  decode.d3.loss_cls: 1.2149  decode.d3.loss_mask: 0.5946  decode.d3.loss_dice: 1.2600  decode.d4.loss_cls: 1.1542  decode.d4.loss_mask: 0.5704  decode.d4.loss_dice: 1.2433  decode.d5.loss_cls: 1.1757  decode.d5.loss_mask: 0.5788  decode.d5.loss_dice: 1.2475  decode.d6.loss_cls: 1.1802  decode.d6.loss_mask: 0.5800  decode.d6.loss_dice: 1.2183  decode.d7.loss_cls: 1.1570  decode.d7.loss_mask: 0.5851  decode.d7.loss_dice: 1.2381  decode.d8.loss_cls: 1.1614  decode.d8.loss_mask: 0.5699  decode.d8.loss_dice: 1.2407
2023/05/24 02:05:55 - mmengine - INFO - Iter(train) [ 63650/160000]  lr: 6.3352e-06  eta: 11:28:10  time: 0.4128  data_time: 0.0103  memory: 4910  grad_norm: 97.2201  loss: 38.0482  decode.loss_cls: 1.2297  decode.loss_mask: 0.8834  decode.loss_dice: 1.3781  decode.d0.loss_cls: 3.3170  decode.d0.loss_mask: 0.9105  decode.d0.loss_dice: 1.6007  decode.d1.loss_cls: 1.4803  decode.d1.loss_mask: 0.9593  decode.d1.loss_dice: 1.4604  decode.d2.loss_cls: 1.3435  decode.d2.loss_mask: 0.9436  decode.d2.loss_dice: 1.4270  decode.d3.loss_cls: 1.2956  decode.d3.loss_mask: 0.9046  decode.d3.loss_dice: 1.3730  decode.d4.loss_cls: 1.3387  decode.d4.loss_mask: 0.8757  decode.d4.loss_dice: 1.3853  decode.d5.loss_cls: 1.2789  decode.d5.loss_mask: 0.8789  decode.d5.loss_dice: 1.3621  decode.d6.loss_cls: 1.2767  decode.d6.loss_mask: 0.8802  decode.d6.loss_dice: 1.3503  decode.d7.loss_cls: 1.2724  decode.d7.loss_mask: 0.8518  decode.d7.loss_dice: 1.3205  decode.d8.loss_cls: 1.2942  decode.d8.loss_mask: 0.8571  decode.d8.loss_dice: 1.3187
2023/05/24 02:06:16 - mmengine - INFO - Iter(train) [ 63700/160000]  lr: 6.3323e-06  eta: 11:27:48  time: 0.4201  data_time: 0.0102  memory: 4869  grad_norm: 103.2368  loss: 44.3980  decode.loss_cls: 1.5990  decode.loss_mask: 1.0057  decode.loss_dice: 1.5667  decode.d0.loss_cls: 3.5209  decode.d0.loss_mask: 0.9711  decode.d0.loss_dice: 1.7735  decode.d1.loss_cls: 1.7865  decode.d1.loss_mask: 1.0087  decode.d1.loss_dice: 1.7128  decode.d2.loss_cls: 1.6682  decode.d2.loss_mask: 0.9743  decode.d2.loss_dice: 1.6700  decode.d3.loss_cls: 1.6127  decode.d3.loss_mask: 0.9830  decode.d3.loss_dice: 1.6122  decode.d4.loss_cls: 1.6075  decode.d4.loss_mask: 0.9998  decode.d4.loss_dice: 1.6190  decode.d5.loss_cls: 1.6138  decode.d5.loss_mask: 1.0175  decode.d5.loss_dice: 1.5658  decode.d6.loss_cls: 1.5598  decode.d6.loss_mask: 1.0370  decode.d6.loss_dice: 1.5693  decode.d7.loss_cls: 1.6035  decode.d7.loss_mask: 1.0466  decode.d7.loss_dice: 1.5740  decode.d8.loss_cls: 1.5740  decode.d8.loss_mask: 0.9929  decode.d8.loss_dice: 1.5521
2023/05/24 02:06:37 - mmengine - INFO - Iter(train) [ 63750/160000]  lr: 6.3293e-06  eta: 11:27:25  time: 0.4142  data_time: 0.0107  memory: 4833  grad_norm: 88.0238  loss: 31.0340  decode.loss_cls: 1.0129  decode.loss_mask: 0.7053  decode.loss_dice: 1.1372  decode.d0.loss_cls: 2.8753  decode.d0.loss_mask: 0.7563  decode.d0.loss_dice: 1.2190  decode.d1.loss_cls: 1.1258  decode.d1.loss_mask: 0.7539  decode.d1.loss_dice: 1.2279  decode.d2.loss_cls: 1.0159  decode.d2.loss_mask: 0.7323  decode.d2.loss_dice: 1.2034  decode.d3.loss_cls: 1.1059  decode.d3.loss_mask: 0.7044  decode.d3.loss_dice: 1.1167  decode.d4.loss_cls: 1.0179  decode.d4.loss_mask: 0.7150  decode.d4.loss_dice: 1.1493  decode.d5.loss_cls: 1.0353  decode.d5.loss_mask: 0.7146  decode.d5.loss_dice: 1.0832  decode.d6.loss_cls: 1.0250  decode.d6.loss_mask: 0.7203  decode.d6.loss_dice: 1.1097  decode.d7.loss_cls: 1.0746  decode.d7.loss_mask: 0.7075  decode.d7.loss_dice: 1.1345  decode.d8.loss_cls: 1.0294  decode.d8.loss_mask: 0.7121  decode.d8.loss_dice: 1.1133
2023/05/24 02:06:57 - mmengine - INFO - Iter(train) [ 63800/160000]  lr: 6.3263e-06  eta: 11:27:03  time: 0.4162  data_time: 0.0105  memory: 4875  grad_norm: 85.4812  loss: 33.4914  decode.loss_cls: 1.1730  decode.loss_mask: 0.7486  decode.loss_dice: 1.2260  decode.d0.loss_cls: 2.8877  decode.d0.loss_mask: 0.8384  decode.d0.loss_dice: 1.4150  decode.d1.loss_cls: 1.1730  decode.d1.loss_mask: 0.8071  decode.d1.loss_dice: 1.3167  decode.d2.loss_cls: 1.1366  decode.d2.loss_mask: 0.7883  decode.d2.loss_dice: 1.2974  decode.d3.loss_cls: 1.0874  decode.d3.loss_mask: 0.7664  decode.d3.loss_dice: 1.2926  decode.d4.loss_cls: 1.1009  decode.d4.loss_mask: 0.7538  decode.d4.loss_dice: 1.2197  decode.d5.loss_cls: 1.1216  decode.d5.loss_mask: 0.7589  decode.d5.loss_dice: 1.2366  decode.d6.loss_cls: 1.1271  decode.d6.loss_mask: 0.7574  decode.d6.loss_dice: 1.2655  decode.d7.loss_cls: 1.1081  decode.d7.loss_mask: 0.7560  decode.d7.loss_dice: 1.2134  decode.d8.loss_cls: 1.1491  decode.d8.loss_mask: 0.7391  decode.d8.loss_dice: 1.2302
2023/05/24 02:07:20 - mmengine - INFO - Iter(train) [ 63850/160000]  lr: 6.3234e-06  eta: 11:26:42  time: 0.4734  data_time: 0.0109  memory: 4919  grad_norm: 96.7241  loss: 37.7259  decode.loss_cls: 1.2889  decode.loss_mask: 0.8332  decode.loss_dice: 1.3666  decode.d0.loss_cls: 3.3615  decode.d0.loss_mask: 0.8278  decode.d0.loss_dice: 1.5621  decode.d1.loss_cls: 1.5038  decode.d1.loss_mask: 0.8187  decode.d1.loss_dice: 1.4183  decode.d2.loss_cls: 1.4816  decode.d2.loss_mask: 0.8132  decode.d2.loss_dice: 1.4309  decode.d3.loss_cls: 1.3346  decode.d3.loss_mask: 0.7928  decode.d3.loss_dice: 1.3868  decode.d4.loss_cls: 1.3419  decode.d4.loss_mask: 0.8107  decode.d4.loss_dice: 1.3691  decode.d5.loss_cls: 1.3560  decode.d5.loss_mask: 0.7821  decode.d5.loss_dice: 1.3468  decode.d6.loss_cls: 1.3974  decode.d6.loss_mask: 0.8063  decode.d6.loss_dice: 1.3369  decode.d7.loss_cls: 1.3298  decode.d7.loss_mask: 0.8210  decode.d7.loss_dice: 1.3651  decode.d8.loss_cls: 1.3005  decode.d8.loss_mask: 0.7979  decode.d8.loss_dice: 1.3437
2023/05/24 02:07:41 - mmengine - INFO - Iter(train) [ 63900/160000]  lr: 6.3204e-06  eta: 11:26:20  time: 0.4059  data_time: 0.0101  memory: 4905  grad_norm: 120.0265  loss: 45.7166  decode.loss_cls: 1.6571  decode.loss_mask: 0.7873  decode.loss_dice: 1.7287  decode.d0.loss_cls: 3.8282  decode.d0.loss_mask: 0.9481  decode.d0.loss_dice: 2.0551  decode.d1.loss_cls: 1.7744  decode.d1.loss_mask: 0.8790  decode.d1.loss_dice: 1.9128  decode.d2.loss_cls: 1.6625  decode.d2.loss_mask: 0.8890  decode.d2.loss_dice: 1.8897  decode.d3.loss_cls: 1.7075  decode.d3.loss_mask: 0.8281  decode.d3.loss_dice: 1.8046  decode.d4.loss_cls: 1.6309  decode.d4.loss_mask: 0.8373  decode.d4.loss_dice: 1.8360  decode.d5.loss_cls: 1.6806  decode.d5.loss_mask: 0.8261  decode.d5.loss_dice: 1.8439  decode.d6.loss_cls: 1.7609  decode.d6.loss_mask: 0.7647  decode.d6.loss_dice: 1.7548  decode.d7.loss_cls: 1.7100  decode.d7.loss_mask: 0.7671  decode.d7.loss_dice: 1.7720  decode.d8.loss_cls: 1.6560  decode.d8.loss_mask: 0.7752  decode.d8.loss_dice: 1.7489
2023/05/24 02:08:02 - mmengine - INFO - Iter(train) [ 63950/160000]  lr: 6.3175e-06  eta: 11:25:58  time: 0.4227  data_time: 0.0101  memory: 4836  grad_norm: 98.3156  loss: 25.9859  decode.loss_cls: 0.9615  decode.loss_mask: 0.5274  decode.loss_dice: 0.8850  decode.d0.loss_cls: 2.7039  decode.d0.loss_mask: 0.5175  decode.d0.loss_dice: 0.9919  decode.d1.loss_cls: 1.0630  decode.d1.loss_mask: 0.5606  decode.d1.loss_dice: 0.9547  decode.d2.loss_cls: 1.0218  decode.d2.loss_mask: 0.5178  decode.d2.loss_dice: 0.8944  decode.d3.loss_cls: 0.9637  decode.d3.loss_mask: 0.5181  decode.d3.loss_dice: 0.8814  decode.d4.loss_cls: 0.9797  decode.d4.loss_mask: 0.5196  decode.d4.loss_dice: 0.8855  decode.d5.loss_cls: 0.9747  decode.d5.loss_mask: 0.5332  decode.d5.loss_dice: 0.9017  decode.d6.loss_cls: 0.9723  decode.d6.loss_mask: 0.5491  decode.d6.loss_dice: 0.8936  decode.d7.loss_cls: 0.9524  decode.d7.loss_mask: 0.5391  decode.d7.loss_dice: 0.9016  decode.d8.loss_cls: 0.9604  decode.d8.loss_mask: 0.5392  decode.d8.loss_dice: 0.9210
2023/05/24 02:08:24 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 02:08:24 - mmengine - INFO - Iter(train) [ 64000/160000]  lr: 6.3145e-06  eta: 11:25:38  time: 0.4736  data_time: 0.0103  memory: 4838  grad_norm: 114.7848  loss: 43.3942  decode.loss_cls: 1.5000  decode.loss_mask: 0.9872  decode.loss_dice: 1.5405  decode.d0.loss_cls: 3.3908  decode.d0.loss_mask: 1.1140  decode.d0.loss_dice: 1.8113  decode.d1.loss_cls: 1.6243  decode.d1.loss_mask: 1.0862  decode.d1.loss_dice: 1.6049  decode.d2.loss_cls: 1.5597  decode.d2.loss_mask: 1.0414  decode.d2.loss_dice: 1.6454  decode.d3.loss_cls: 1.5298  decode.d3.loss_mask: 1.0204  decode.d3.loss_dice: 1.5906  decode.d4.loss_cls: 1.5162  decode.d4.loss_mask: 0.9950  decode.d4.loss_dice: 1.5727  decode.d5.loss_cls: 1.4709  decode.d5.loss_mask: 0.9914  decode.d5.loss_dice: 1.5710  decode.d6.loss_cls: 1.5055  decode.d6.loss_mask: 1.0125  decode.d6.loss_dice: 1.5447  decode.d7.loss_cls: 1.5497  decode.d7.loss_mask: 0.9825  decode.d7.loss_dice: 1.5408  decode.d8.loss_cls: 1.5472  decode.d8.loss_mask: 1.0026  decode.d8.loss_dice: 1.5451
2023/05/24 02:08:24 - mmengine - INFO - Saving checkpoint at 64000 iterations
2023/05/24 02:08:50 - mmengine - INFO - Iter(train) [ 64050/160000]  lr: 6.3115e-06  eta: 11:25:24  time: 0.4125  data_time: 0.0107  memory: 4859  grad_norm: 101.5362  loss: 33.7393  decode.loss_cls: 1.1854  decode.loss_mask: 0.7777  decode.loss_dice: 1.1187  decode.d0.loss_cls: 3.1556  decode.d0.loss_mask: 0.8058  decode.d0.loss_dice: 1.3857  decode.d1.loss_cls: 1.3548  decode.d1.loss_mask: 0.7628  decode.d1.loss_dice: 1.2605  decode.d2.loss_cls: 1.3292  decode.d2.loss_mask: 0.7482  decode.d2.loss_dice: 1.1388  decode.d3.loss_cls: 1.2485  decode.d3.loss_mask: 0.7579  decode.d3.loss_dice: 1.1416  decode.d4.loss_cls: 1.2053  decode.d4.loss_mask: 0.7540  decode.d4.loss_dice: 1.1330  decode.d5.loss_cls: 1.2509  decode.d5.loss_mask: 0.7431  decode.d5.loss_dice: 1.1045  decode.d6.loss_cls: 1.2408  decode.d6.loss_mask: 0.7538  decode.d6.loss_dice: 1.1238  decode.d7.loss_cls: 1.2617  decode.d7.loss_mask: 0.7438  decode.d7.loss_dice: 1.1351  decode.d8.loss_cls: 1.2051  decode.d8.loss_mask: 0.7603  decode.d8.loss_dice: 1.1529
2023/05/24 02:09:11 - mmengine - INFO - Iter(train) [ 64100/160000]  lr: 6.3086e-06  eta: 11:25:01  time: 0.4147  data_time: 0.0103  memory: 4785  grad_norm: 106.3524  loss: 35.2379  decode.loss_cls: 1.1949  decode.loss_mask: 0.7605  decode.loss_dice: 1.2333  decode.d0.loss_cls: 3.1816  decode.d0.loss_mask: 0.8722  decode.d0.loss_dice: 1.4872  decode.d1.loss_cls: 1.3729  decode.d1.loss_mask: 0.8685  decode.d1.loss_dice: 1.3571  decode.d2.loss_cls: 1.2334  decode.d2.loss_mask: 0.8445  decode.d2.loss_dice: 1.3263  decode.d3.loss_cls: 1.2648  decode.d3.loss_mask: 0.7840  decode.d3.loss_dice: 1.3215  decode.d4.loss_cls: 1.1963  decode.d4.loss_mask: 0.7855  decode.d4.loss_dice: 1.2794  decode.d5.loss_cls: 1.1703  decode.d5.loss_mask: 0.7828  decode.d5.loss_dice: 1.2538  decode.d6.loss_cls: 1.1532  decode.d6.loss_mask: 0.8041  decode.d6.loss_dice: 1.2843  decode.d7.loss_cls: 1.1653  decode.d7.loss_mask: 0.7774  decode.d7.loss_dice: 1.2403  decode.d8.loss_cls: 1.2380  decode.d8.loss_mask: 0.7836  decode.d8.loss_dice: 1.2208
2023/05/24 02:09:33 - mmengine - INFO - Iter(train) [ 64150/160000]  lr: 6.3056e-06  eta: 11:24:41  time: 0.4150  data_time: 0.0105  memory: 4870  grad_norm: 108.4475  loss: 31.3643  decode.loss_cls: 1.1263  decode.loss_mask: 0.7017  decode.loss_dice: 1.0792  decode.d0.loss_cls: 2.9702  decode.d0.loss_mask: 0.7906  decode.d0.loss_dice: 1.2314  decode.d1.loss_cls: 1.2365  decode.d1.loss_mask: 0.7171  decode.d1.loss_dice: 1.1862  decode.d2.loss_cls: 1.1193  decode.d2.loss_mask: 0.7411  decode.d2.loss_dice: 1.1114  decode.d3.loss_cls: 1.1240  decode.d3.loss_mask: 0.7091  decode.d3.loss_dice: 1.0873  decode.d4.loss_cls: 1.1709  decode.d4.loss_mask: 0.6888  decode.d4.loss_dice: 1.0805  decode.d5.loss_cls: 1.0808  decode.d5.loss_mask: 0.6842  decode.d5.loss_dice: 1.0717  decode.d6.loss_cls: 1.1065  decode.d6.loss_mask: 0.6844  decode.d6.loss_dice: 1.0789  decode.d7.loss_cls: 1.1395  decode.d7.loss_mask: 0.6974  decode.d7.loss_dice: 1.0832  decode.d8.loss_cls: 1.1094  decode.d8.loss_mask: 0.6848  decode.d8.loss_dice: 1.0716
2023/05/24 02:09:56 - mmengine - INFO - Iter(train) [ 64200/160000]  lr: 6.3027e-06  eta: 11:24:22  time: 0.4276  data_time: 0.0101  memory: 4823  grad_norm: 101.8747  loss: 42.1362  decode.loss_cls: 1.4848  decode.loss_mask: 0.9581  decode.loss_dice: 1.4946  decode.d0.loss_cls: 3.3420  decode.d0.loss_mask: 0.9321  decode.d0.loss_dice: 1.7568  decode.d1.loss_cls: 1.6187  decode.d1.loss_mask: 1.0299  decode.d1.loss_dice: 1.6515  decode.d2.loss_cls: 1.6530  decode.d2.loss_mask: 0.9775  decode.d2.loss_dice: 1.5911  decode.d3.loss_cls: 1.4643  decode.d3.loss_mask: 0.9463  decode.d3.loss_dice: 1.5392  decode.d4.loss_cls: 1.5380  decode.d4.loss_mask: 0.9253  decode.d4.loss_dice: 1.4865  decode.d5.loss_cls: 1.4981  decode.d5.loss_mask: 0.9374  decode.d5.loss_dice: 1.4473  decode.d6.loss_cls: 1.5478  decode.d6.loss_mask: 0.9006  decode.d6.loss_dice: 1.5213  decode.d7.loss_cls: 1.5543  decode.d7.loss_mask: 0.9076  decode.d7.loss_dice: 1.4567  decode.d8.loss_cls: 1.6159  decode.d8.loss_mask: 0.9141  decode.d8.loss_dice: 1.4457
2023/05/24 02:10:19 - mmengine - INFO - Iter(train) [ 64250/160000]  lr: 6.2997e-06  eta: 11:24:02  time: 0.4715  data_time: 0.0107  memory: 4815  grad_norm: 95.7741  loss: 33.0611  decode.loss_cls: 1.1611  decode.loss_mask: 0.7074  decode.loss_dice: 1.1120  decode.d0.loss_cls: 3.2184  decode.d0.loss_mask: 0.7620  decode.d0.loss_dice: 1.3082  decode.d1.loss_cls: 1.4040  decode.d1.loss_mask: 0.7300  decode.d1.loss_dice: 1.2155  decode.d2.loss_cls: 1.3550  decode.d2.loss_mask: 0.7296  decode.d2.loss_dice: 1.1678  decode.d3.loss_cls: 1.1997  decode.d3.loss_mask: 0.7220  decode.d3.loss_dice: 1.1466  decode.d4.loss_cls: 1.1560  decode.d4.loss_mask: 0.7353  decode.d4.loss_dice: 1.1435  decode.d5.loss_cls: 1.2428  decode.d5.loss_mask: 0.7323  decode.d5.loss_dice: 1.1096  decode.d6.loss_cls: 1.1753  decode.d6.loss_mask: 0.7240  decode.d6.loss_dice: 1.0892  decode.d7.loss_cls: 1.1428  decode.d7.loss_mask: 0.7294  decode.d7.loss_dice: 1.1032  decode.d8.loss_cls: 1.2495  decode.d8.loss_mask: 0.6983  decode.d8.loss_dice: 1.0906
2023/05/24 02:10:41 - mmengine - INFO - Iter(train) [ 64300/160000]  lr: 6.2967e-06  eta: 11:23:42  time: 0.4148  data_time: 0.0102  memory: 4847  grad_norm: 87.5621  loss: 39.7945  decode.loss_cls: 1.5547  decode.loss_mask: 0.7349  decode.loss_dice: 1.3839  decode.d0.loss_cls: 3.5289  decode.d0.loss_mask: 0.8554  decode.d0.loss_dice: 1.6945  decode.d1.loss_cls: 1.6179  decode.d1.loss_mask: 0.8996  decode.d1.loss_dice: 1.5387  decode.d2.loss_cls: 1.5826  decode.d2.loss_mask: 0.7535  decode.d2.loss_dice: 1.4581  decode.d3.loss_cls: 1.5267  decode.d3.loss_mask: 0.7691  decode.d3.loss_dice: 1.4384  decode.d4.loss_cls: 1.4143  decode.d4.loss_mask: 0.7813  decode.d4.loss_dice: 1.4842  decode.d5.loss_cls: 1.5537  decode.d5.loss_mask: 0.7680  decode.d5.loss_dice: 1.4110  decode.d6.loss_cls: 1.5185  decode.d6.loss_mask: 0.7758  decode.d6.loss_dice: 1.3880  decode.d7.loss_cls: 1.5370  decode.d7.loss_mask: 0.7388  decode.d7.loss_dice: 1.3916  decode.d8.loss_cls: 1.5710  decode.d8.loss_mask: 0.7315  decode.d8.loss_dice: 1.3928
2023/05/24 02:11:03 - mmengine - INFO - Iter(train) [ 64350/160000]  lr: 6.2938e-06  eta: 11:23:21  time: 0.4170  data_time: 0.0104  memory: 4876  grad_norm: 97.0247  loss: 44.2141  decode.loss_cls: 1.4210  decode.loss_mask: 1.0636  decode.loss_dice: 1.6724  decode.d0.loss_cls: 3.2298  decode.d0.loss_mask: 1.1158  decode.d0.loss_dice: 1.9036  decode.d1.loss_cls: 1.4960  decode.d1.loss_mask: 1.1116  decode.d1.loss_dice: 1.8313  decode.d2.loss_cls: 1.4368  decode.d2.loss_mask: 1.1040  decode.d2.loss_dice: 1.7911  decode.d3.loss_cls: 1.3893  decode.d3.loss_mask: 1.0977  decode.d3.loss_dice: 1.7502  decode.d4.loss_cls: 1.3229  decode.d4.loss_mask: 1.0967  decode.d4.loss_dice: 1.7153  decode.d5.loss_cls: 1.3419  decode.d5.loss_mask: 1.0679  decode.d5.loss_dice: 1.6994  decode.d6.loss_cls: 1.4254  decode.d6.loss_mask: 1.0671  decode.d6.loss_dice: 1.6605  decode.d7.loss_cls: 1.4053  decode.d7.loss_mask: 1.0799  decode.d7.loss_dice: 1.7393  decode.d8.loss_cls: 1.4251  decode.d8.loss_mask: 1.0637  decode.d8.loss_dice: 1.6894
2023/05/24 02:11:24 - mmengine - INFO - Iter(train) [ 64400/160000]  lr: 6.2908e-06  eta: 11:22:59  time: 0.4206  data_time: 0.0102  memory: 4805  grad_norm: 90.3743  loss: 32.3903  decode.loss_cls: 1.2664  decode.loss_mask: 0.6370  decode.loss_dice: 1.0271  decode.d0.loss_cls: 3.1838  decode.d0.loss_mask: 0.7395  decode.d0.loss_dice: 1.1078  decode.d1.loss_cls: 1.4197  decode.d1.loss_mask: 0.6897  decode.d1.loss_dice: 1.0747  decode.d2.loss_cls: 1.3785  decode.d2.loss_mask: 0.6842  decode.d2.loss_dice: 1.1042  decode.d3.loss_cls: 1.3286  decode.d3.loss_mask: 0.6782  decode.d3.loss_dice: 1.0622  decode.d4.loss_cls: 1.2837  decode.d4.loss_mask: 0.6842  decode.d4.loss_dice: 1.0809  decode.d5.loss_cls: 1.3193  decode.d5.loss_mask: 0.6694  decode.d5.loss_dice: 1.0635  decode.d6.loss_cls: 1.2753  decode.d6.loss_mask: 0.6541  decode.d6.loss_dice: 1.0374  decode.d7.loss_cls: 1.2418  decode.d7.loss_mask: 0.6611  decode.d7.loss_dice: 1.0572  decode.d8.loss_cls: 1.2750  decode.d8.loss_mask: 0.6538  decode.d8.loss_dice: 1.0520
2023/05/24 02:11:45 - mmengine - INFO - Iter(train) [ 64450/160000]  lr: 6.2878e-06  eta: 11:22:37  time: 0.4124  data_time: 0.0101  memory: 4885  grad_norm: 106.8691  loss: 41.7078  decode.loss_cls: 1.2024  decode.loss_mask: 1.0642  decode.loss_dice: 1.6746  decode.d0.loss_cls: 3.0259  decode.d0.loss_mask: 1.1275  decode.d0.loss_dice: 1.8871  decode.d1.loss_cls: 1.2485  decode.d1.loss_mask: 1.0322  decode.d1.loss_dice: 1.7796  decode.d2.loss_cls: 1.2892  decode.d2.loss_mask: 1.0405  decode.d2.loss_dice: 1.7404  decode.d3.loss_cls: 1.2388  decode.d3.loss_mask: 1.0431  decode.d3.loss_dice: 1.6776  decode.d4.loss_cls: 1.2114  decode.d4.loss_mask: 1.0648  decode.d4.loss_dice: 1.7090  decode.d5.loss_cls: 1.2072  decode.d5.loss_mask: 1.0392  decode.d5.loss_dice: 1.6706  decode.d6.loss_cls: 1.1809  decode.d6.loss_mask: 1.0668  decode.d6.loss_dice: 1.6668  decode.d7.loss_cls: 1.1938  decode.d7.loss_mask: 1.0659  decode.d7.loss_dice: 1.6607  decode.d8.loss_cls: 1.1727  decode.d8.loss_mask: 1.0518  decode.d8.loss_dice: 1.6748
2023/05/24 02:12:06 - mmengine - INFO - Iter(train) [ 64500/160000]  lr: 6.2849e-06  eta: 11:22:15  time: 0.4171  data_time: 0.0102  memory: 4845  grad_norm: 108.5528  loss: 40.4785  decode.loss_cls: 1.3534  decode.loss_mask: 0.8260  decode.loss_dice: 1.5692  decode.d0.loss_cls: 3.2218  decode.d0.loss_mask: 0.8566  decode.d0.loss_dice: 1.7527  decode.d1.loss_cls: 1.4102  decode.d1.loss_mask: 0.8950  decode.d1.loss_dice: 1.7677  decode.d2.loss_cls: 1.4205  decode.d2.loss_mask: 0.8572  decode.d2.loss_dice: 1.6078  decode.d3.loss_cls: 1.4062  decode.d3.loss_mask: 0.8428  decode.d3.loss_dice: 1.5946  decode.d4.loss_cls: 1.4173  decode.d4.loss_mask: 0.8795  decode.d4.loss_dice: 1.6059  decode.d5.loss_cls: 1.4142  decode.d5.loss_mask: 0.9076  decode.d5.loss_dice: 1.6187  decode.d6.loss_cls: 1.3576  decode.d6.loss_mask: 0.8468  decode.d6.loss_dice: 1.5833  decode.d7.loss_cls: 1.2837  decode.d7.loss_mask: 0.8428  decode.d7.loss_dice: 1.5950  decode.d8.loss_cls: 1.3327  decode.d8.loss_mask: 0.8413  decode.d8.loss_dice: 1.5704
2023/05/24 02:12:27 - mmengine - INFO - Iter(train) [ 64550/160000]  lr: 6.2819e-06  eta: 11:21:52  time: 0.4098  data_time: 0.0103  memory: 4874  grad_norm: 93.5481  loss: 39.3075  decode.loss_cls: 1.5712  decode.loss_mask: 0.7710  decode.loss_dice: 1.3014  decode.d0.loss_cls: 3.0781  decode.d0.loss_mask: 0.8797  decode.d0.loss_dice: 1.5639  decode.d1.loss_cls: 1.7059  decode.d1.loss_mask: 0.7630  decode.d1.loss_dice: 1.4535  decode.d2.loss_cls: 1.6665  decode.d2.loss_mask: 0.8083  decode.d2.loss_dice: 1.4100  decode.d3.loss_cls: 1.6392  decode.d3.loss_mask: 0.7997  decode.d3.loss_dice: 1.3891  decode.d4.loss_cls: 1.5533  decode.d4.loss_mask: 0.8150  decode.d4.loss_dice: 1.3807  decode.d5.loss_cls: 1.5726  decode.d5.loss_mask: 0.7994  decode.d5.loss_dice: 1.3539  decode.d6.loss_cls: 1.5542  decode.d6.loss_mask: 0.7950  decode.d6.loss_dice: 1.3246  decode.d7.loss_cls: 1.5543  decode.d7.loss_mask: 0.7927  decode.d7.loss_dice: 1.3213  decode.d8.loss_cls: 1.5284  decode.d8.loss_mask: 0.8171  decode.d8.loss_dice: 1.3446
2023/05/24 02:12:48 - mmengine - INFO - Iter(train) [ 64600/160000]  lr: 6.2790e-06  eta: 11:21:30  time: 0.4129  data_time: 0.0099  memory: 4818  grad_norm: 87.4134  loss: 32.5509  decode.loss_cls: 1.1459  decode.loss_mask: 0.7245  decode.loss_dice: 1.0891  decode.d0.loss_cls: 3.1360  decode.d0.loss_mask: 0.7416  decode.d0.loss_dice: 1.3358  decode.d1.loss_cls: 1.1776  decode.d1.loss_mask: 0.7575  decode.d1.loss_dice: 1.2470  decode.d2.loss_cls: 1.1875  decode.d2.loss_mask: 0.7297  decode.d2.loss_dice: 1.1699  decode.d3.loss_cls: 1.1616  decode.d3.loss_mask: 0.7448  decode.d3.loss_dice: 1.1481  decode.d4.loss_cls: 1.1439  decode.d4.loss_mask: 0.7612  decode.d4.loss_dice: 1.1524  decode.d5.loss_cls: 1.1397  decode.d5.loss_mask: 0.7245  decode.d5.loss_dice: 1.1199  decode.d6.loss_cls: 1.1812  decode.d6.loss_mask: 0.7315  decode.d6.loss_dice: 1.1172  decode.d7.loss_cls: 1.1629  decode.d7.loss_mask: 0.7381  decode.d7.loss_dice: 1.1040  decode.d8.loss_cls: 1.1463  decode.d8.loss_mask: 0.7189  decode.d8.loss_dice: 1.1124
2023/05/24 02:13:09 - mmengine - INFO - Iter(train) [ 64650/160000]  lr: 6.2760e-06  eta: 11:21:09  time: 0.4727  data_time: 0.0109  memory: 4853  grad_norm: 92.5848  loss: 22.2500  decode.loss_cls: 0.7500  decode.loss_mask: 0.5710  decode.loss_dice: 0.6872  decode.d0.loss_cls: 2.6347  decode.d0.loss_mask: 0.5900  decode.d0.loss_dice: 0.7168  decode.d1.loss_cls: 0.8797  decode.d1.loss_mask: 0.5788  decode.d1.loss_dice: 0.7016  decode.d2.loss_cls: 0.6814  decode.d2.loss_mask: 0.6177  decode.d2.loss_dice: 0.7466  decode.d3.loss_cls: 0.7237  decode.d3.loss_mask: 0.5760  decode.d3.loss_dice: 0.7008  decode.d4.loss_cls: 0.7062  decode.d4.loss_mask: 0.5985  decode.d4.loss_dice: 0.7041  decode.d5.loss_cls: 0.7816  decode.d5.loss_mask: 0.5729  decode.d5.loss_dice: 0.7059  decode.d6.loss_cls: 0.7646  decode.d6.loss_mask: 0.5630  decode.d6.loss_dice: 0.6918  decode.d7.loss_cls: 0.7523  decode.d7.loss_mask: 0.5695  decode.d7.loss_dice: 0.6900  decode.d8.loss_cls: 0.7499  decode.d8.loss_mask: 0.5483  decode.d8.loss_dice: 0.6954
2023/05/24 02:13:31 - mmengine - INFO - Iter(train) [ 64700/160000]  lr: 6.2730e-06  eta: 11:20:48  time: 0.4128  data_time: 0.0101  memory: 4886  grad_norm: 99.0215  loss: 42.1389  decode.loss_cls: 1.2418  decode.loss_mask: 0.9719  decode.loss_dice: 1.6352  decode.d0.loss_cls: 3.3993  decode.d0.loss_mask: 1.0456  decode.d0.loss_dice: 1.9611  decode.d1.loss_cls: 1.4737  decode.d1.loss_mask: 1.0339  decode.d1.loss_dice: 1.8032  decode.d2.loss_cls: 1.3523  decode.d2.loss_mask: 1.0034  decode.d2.loss_dice: 1.7091  decode.d3.loss_cls: 1.2930  decode.d3.loss_mask: 1.0157  decode.d3.loss_dice: 1.6640  decode.d4.loss_cls: 1.2691  decode.d4.loss_mask: 0.9973  decode.d4.loss_dice: 1.7289  decode.d5.loss_cls: 1.3239  decode.d5.loss_mask: 0.9882  decode.d5.loss_dice: 1.6179  decode.d6.loss_cls: 1.2557  decode.d6.loss_mask: 0.9883  decode.d6.loss_dice: 1.6386  decode.d7.loss_cls: 1.2477  decode.d7.loss_mask: 0.9899  decode.d7.loss_dice: 1.6209  decode.d8.loss_cls: 1.2358  decode.d8.loss_mask: 0.9816  decode.d8.loss_dice: 1.6520
2023/05/24 02:13:52 - mmengine - INFO - Iter(train) [ 64750/160000]  lr: 6.2701e-06  eta: 11:20:26  time: 0.4202  data_time: 0.0104  memory: 4835  grad_norm: 103.4558  loss: 45.4784  decode.loss_cls: 1.6592  decode.loss_mask: 0.9927  decode.loss_dice: 1.6387  decode.d0.loss_cls: 3.6425  decode.d0.loss_mask: 0.9611  decode.d0.loss_dice: 1.8889  decode.d1.loss_cls: 1.6857  decode.d1.loss_mask: 1.0622  decode.d1.loss_dice: 1.8538  decode.d2.loss_cls: 1.6439  decode.d2.loss_mask: 1.0138  decode.d2.loss_dice: 1.7494  decode.d3.loss_cls: 1.6710  decode.d3.loss_mask: 0.9784  decode.d3.loss_dice: 1.6798  decode.d4.loss_cls: 1.6381  decode.d4.loss_mask: 0.9627  decode.d4.loss_dice: 1.6828  decode.d5.loss_cls: 1.6388  decode.d5.loss_mask: 0.9631  decode.d5.loss_dice: 1.6586  decode.d6.loss_cls: 1.7199  decode.d6.loss_mask: 0.9540  decode.d6.loss_dice: 1.5988  decode.d7.loss_cls: 1.6556  decode.d7.loss_mask: 0.9841  decode.d7.loss_dice: 1.6540  decode.d8.loss_cls: 1.6404  decode.d8.loss_mask: 0.9510  decode.d8.loss_dice: 1.6554
2023/05/24 02:14:13 - mmengine - INFO - Iter(train) [ 64800/160000]  lr: 6.2671e-06  eta: 11:20:04  time: 0.4095  data_time: 0.0103  memory: 4866  grad_norm: 91.3750  loss: 40.7444  decode.loss_cls: 1.2884  decode.loss_mask: 0.9218  decode.loss_dice: 1.6148  decode.d0.loss_cls: 3.2379  decode.d0.loss_mask: 0.9952  decode.d0.loss_dice: 1.7673  decode.d1.loss_cls: 1.3066  decode.d1.loss_mask: 0.9908  decode.d1.loss_dice: 1.7552  decode.d2.loss_cls: 1.2745  decode.d2.loss_mask: 0.9529  decode.d2.loss_dice: 1.6856  decode.d3.loss_cls: 1.2959  decode.d3.loss_mask: 0.9378  decode.d3.loss_dice: 1.6553  decode.d4.loss_cls: 1.2190  decode.d4.loss_mask: 0.9364  decode.d4.loss_dice: 1.6591  decode.d5.loss_cls: 1.1955  decode.d5.loss_mask: 0.9316  decode.d5.loss_dice: 1.6407  decode.d6.loss_cls: 1.3320  decode.d6.loss_mask: 0.9182  decode.d6.loss_dice: 1.6182  decode.d7.loss_cls: 1.2607  decode.d7.loss_mask: 0.9318  decode.d7.loss_dice: 1.6267  decode.d8.loss_cls: 1.2659  decode.d8.loss_mask: 0.9230  decode.d8.loss_dice: 1.6054
2023/05/24 02:14:34 - mmengine - INFO - Iter(train) [ 64850/160000]  lr: 6.2642e-06  eta: 11:19:42  time: 0.4185  data_time: 0.0104  memory: 4821  grad_norm: 105.5602  loss: 36.2868  decode.loss_cls: 1.1232  decode.loss_mask: 0.8753  decode.loss_dice: 1.3214  decode.d0.loss_cls: 3.2716  decode.d0.loss_mask: 0.8226  decode.d0.loss_dice: 1.5149  decode.d1.loss_cls: 1.3274  decode.d1.loss_mask: 0.8450  decode.d1.loss_dice: 1.3970  decode.d2.loss_cls: 1.2728  decode.d2.loss_mask: 0.8704  decode.d2.loss_dice: 1.3657  decode.d3.loss_cls: 1.2475  decode.d3.loss_mask: 0.8546  decode.d3.loss_dice: 1.3124  decode.d4.loss_cls: 1.2702  decode.d4.loss_mask: 0.8488  decode.d4.loss_dice: 1.3388  decode.d5.loss_cls: 1.1798  decode.d5.loss_mask: 0.8755  decode.d5.loss_dice: 1.3167  decode.d6.loss_cls: 1.1493  decode.d6.loss_mask: 0.8789  decode.d6.loss_dice: 1.3341  decode.d7.loss_cls: 1.1218  decode.d7.loss_mask: 0.8892  decode.d7.loss_dice: 1.3514  decode.d8.loss_cls: 1.0837  decode.d8.loss_mask: 0.8881  decode.d8.loss_dice: 1.3387
2023/05/24 02:14:55 - mmengine - INFO - Iter(train) [ 64900/160000]  lr: 6.2612e-06  eta: 11:19:19  time: 0.4123  data_time: 0.0103  memory: 4829  grad_norm: 99.0780  loss: 36.4088  decode.loss_cls: 1.2682  decode.loss_mask: 0.7806  decode.loss_dice: 1.3663  decode.d0.loss_cls: 2.9736  decode.d0.loss_mask: 0.8039  decode.d0.loss_dice: 1.5925  decode.d1.loss_cls: 1.3302  decode.d1.loss_mask: 0.8186  decode.d1.loss_dice: 1.5133  decode.d2.loss_cls: 1.1967  decode.d2.loss_mask: 0.8042  decode.d2.loss_dice: 1.4722  decode.d3.loss_cls: 1.1965  decode.d3.loss_mask: 0.7952  decode.d3.loss_dice: 1.4187  decode.d4.loss_cls: 1.2201  decode.d4.loss_mask: 0.7902  decode.d4.loss_dice: 1.4134  decode.d5.loss_cls: 1.1959  decode.d5.loss_mask: 0.8175  decode.d5.loss_dice: 1.4465  decode.d6.loss_cls: 1.2300  decode.d6.loss_mask: 0.7905  decode.d6.loss_dice: 1.3961  decode.d7.loss_cls: 1.1998  decode.d7.loss_mask: 0.7814  decode.d7.loss_dice: 1.4063  decode.d8.loss_cls: 1.1938  decode.d8.loss_mask: 0.8013  decode.d8.loss_dice: 1.3950
2023/05/24 02:15:15 - mmengine - INFO - Iter(train) [ 64950/160000]  lr: 6.2582e-06  eta: 11:18:57  time: 0.4086  data_time: 0.0102  memory: 4792  grad_norm: 78.9974  loss: 32.3709  decode.loss_cls: 1.1026  decode.loss_mask: 0.6513  decode.loss_dice: 1.2295  decode.d0.loss_cls: 2.7555  decode.d0.loss_mask: 0.6579  decode.d0.loss_dice: 1.3667  decode.d1.loss_cls: 1.2003  decode.d1.loss_mask: 0.7049  decode.d1.loss_dice: 1.3360  decode.d2.loss_cls: 1.1581  decode.d2.loss_mask: 0.6508  decode.d2.loss_dice: 1.2967  decode.d3.loss_cls: 1.1643  decode.d3.loss_mask: 0.6448  decode.d3.loss_dice: 1.2630  decode.d4.loss_cls: 1.1424  decode.d4.loss_mask: 0.6359  decode.d4.loss_dice: 1.2523  decode.d5.loss_cls: 1.1829  decode.d5.loss_mask: 0.6291  decode.d5.loss_dice: 1.2771  decode.d6.loss_cls: 1.0634  decode.d6.loss_mask: 0.6810  decode.d6.loss_dice: 1.2830  decode.d7.loss_cls: 1.1745  decode.d7.loss_mask: 0.6330  decode.d7.loss_dice: 1.2191  decode.d8.loss_cls: 1.1392  decode.d8.loss_mask: 0.6444  decode.d8.loss_dice: 1.2309
2023/05/24 02:15:36 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 02:15:36 - mmengine - INFO - Iter(train) [ 65000/160000]  lr: 6.2553e-06  eta: 11:18:34  time: 0.4215  data_time: 0.0101  memory: 4836  grad_norm: 81.7626  loss: 40.3309  decode.loss_cls: 1.5083  decode.loss_mask: 0.7904  decode.loss_dice: 1.5091  decode.d0.loss_cls: 3.3445  decode.d0.loss_mask: 0.8599  decode.d0.loss_dice: 1.6958  decode.d1.loss_cls: 1.5993  decode.d1.loss_mask: 0.8129  decode.d1.loss_dice: 1.6645  decode.d2.loss_cls: 1.5868  decode.d2.loss_mask: 0.8134  decode.d2.loss_dice: 1.5155  decode.d3.loss_cls: 1.5890  decode.d3.loss_mask: 0.7848  decode.d3.loss_dice: 1.4608  decode.d4.loss_cls: 1.4945  decode.d4.loss_mask: 0.7841  decode.d4.loss_dice: 1.4959  decode.d5.loss_cls: 1.4541  decode.d5.loss_mask: 0.8015  decode.d5.loss_dice: 1.5038  decode.d6.loss_cls: 1.4852  decode.d6.loss_mask: 0.8087  decode.d6.loss_dice: 1.4609  decode.d7.loss_cls: 1.5195  decode.d7.loss_mask: 0.7992  decode.d7.loss_dice: 1.4405  decode.d8.loss_cls: 1.5094  decode.d8.loss_mask: 0.7929  decode.d8.loss_dice: 1.4457
2023/05/24 02:15:36 - mmengine - INFO - Saving checkpoint at 65000 iterations
2023/05/24 02:15:47 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:01:02  time: 0.0799  data_time: 0.0019  memory: 2167  
2023/05/24 02:15:52 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:52  time: 0.0898  data_time: 0.0019  memory: 2216  
2023/05/24 02:15:56 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:44  time: 0.0789  data_time: 0.0017  memory: 2167  
2023/05/24 02:16:00 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:38  time: 0.0845  data_time: 0.0021  memory: 2104  
2023/05/24 02:16:04 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:33  time: 0.0783  data_time: 0.0018  memory: 2831  
2023/05/24 02:16:08 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:28  time: 0.0902  data_time: 0.0019  memory: 2167  
2023/05/24 02:16:12 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:23  time: 0.0808  data_time: 0.0018  memory: 2167  
2023/05/24 02:16:16 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0801  data_time: 0.0018  memory: 2167  
2023/05/24 02:16:20 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0856  data_time: 0.0019  memory: 2944  
2023/05/24 02:16:25 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0904  data_time: 0.0019  memory: 2356  
2023/05/24 02:16:29 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0789  data_time: 0.0017  memory: 2217  
2023/05/24 02:16:33 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0784  data_time: 0.0018  memory: 2328  
2023/05/24 02:16:36 - mmengine - INFO - per class results:
2023/05/24 02:16:36 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.75 | 92.97 |
|     bicycle      | 68.65 | 83.23 |
|       car        | 60.22 |  84.3 |
|    motorcycle    | 83.29 | 89.75 |
|     airplane     | 84.06 | 93.54 |
|       bus        |  80.5 | 89.44 |
|      train       | 85.83 |  94.7 |
|      truck       | 50.55 | 61.28 |
|       boat       | 57.83 | 79.16 |
|  traffic light   | 67.24 | 86.15 |
|   fire hydrant   | 86.11 | 94.85 |
|    stop sign     | 90.39 | 96.76 |
|  parking meter   | 75.55 | 86.27 |
|      bench       | 46.12 | 68.94 |
|       bird       | 79.78 | 90.54 |
|       cat        | 84.32 | 91.11 |
|       dog        |  79.3 | 88.98 |
|      horse       | 78.02 | 90.56 |
|      sheep       | 88.18 | 94.07 |
|       cow        | 82.24 | 89.52 |
|     elephant     | 88.76 | 95.27 |
|       bear       | 92.24 | 95.55 |
|      zebra       | 90.06 |  93.0 |
|     giraffe      | 87.06 | 93.66 |
|     backpack     | 27.27 | 62.98 |
|     umbrella     |  81.3 | 87.56 |
|     handbag      | 28.47 | 52.49 |
|       tie        | 14.25 | 25.25 |
|     suitcase     | 74.46 | 88.04 |
|     frisbee      | 75.75 | 88.49 |
|       skis       | 40.94 | 58.35 |
|    snowboard     |  52.8 | 66.69 |
|   sports ball    | 52.94 | 72.34 |
|       kite       | 50.96 |  60.0 |
|   baseball bat   | 44.66 | 55.52 |
|  baseball glove  | 64.71 | 88.75 |
|    skateboard    |  55.9 | 63.82 |
|    surfboard     | 64.06 | 87.28 |
|  tennis racket   | 80.93 | 90.57 |
|      bottle      | 39.74 | 50.28 |
|    wine glass    | 49.38 | 72.26 |
|       cup        | 50.55 | 65.19 |
|       fork       | 22.67 | 26.49 |
|      knife       | 22.28 | 35.31 |
|      spoon       |  38.7 | 56.55 |
|       bowl       | 47.18 | 64.97 |
|      banana      | 63.89 | 88.81 |
|      apple       | 51.53 | 72.97 |
|     sandwich     | 46.49 | 66.35 |
|      orange      | 63.58 | 74.97 |
|     broccoli     |  56.0 | 68.61 |
|      carrot      |  47.7 | 54.93 |
|     hot dog      |  53.6 | 63.39 |
|      pizza       | 62.48 | 69.94 |
|      donut       | 64.61 | 75.13 |
|       cake       | 55.11 | 65.27 |
|      chair       | 42.33 | 62.52 |
|      couch       | 54.18 | 68.27 |
|   potted plant   | 31.81 | 47.89 |
|       bed        | 61.99 | 81.95 |
|   dining table   | 41.06 | 81.96 |
|      toilet      | 79.66 | 93.92 |
|        tv        | 74.76 | 88.15 |
|      laptop      | 72.84 | 86.85 |
|      mouse       |  68.7 | 88.76 |
|      remote      | 61.34 | 71.37 |
|     keyboard     |  61.5 | 75.91 |
|    cell phone    | 67.61 | 90.63 |
|    microwave     | 61.88 | 76.32 |
|       oven       |  50.4 |  90.0 |
|     toaster      | 41.04 | 54.19 |
|       sink       | 60.04 | 82.47 |
|   refrigerator   | 76.34 |  92.8 |
|       book       |  47.0 | 73.56 |
|      clock       |  72.0 | 80.57 |
|       vase       | 53.31 | 88.46 |
|     scissors     | 77.94 | 88.79 |
|    teddy bear    | 74.21 | 84.13 |
|    hair drier    | 41.15 | 42.51 |
|    toothbrush    | 33.73 | 72.63 |
|      banner      | 36.83 | 64.69 |
|     blanket      |  6.99 |  7.97 |
|      branch      | 20.94 | 27.59 |
|      bridge      | 33.45 | 46.63 |
|  building-other  | 53.93 |  74.8 |
|       bush       | 31.76 | 43.12 |
|     cabinet      | 52.07 | 70.63 |
|       cage       | 21.38 | 41.15 |
|    cardboard     |  40.8 | 46.82 |
|      carpet      | 55.33 | 71.15 |
|  ceiling-other   |  63.9 | 81.25 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 18.63 | 26.82 |
|      clouds      | 44.07 | 54.29 |
|     counter      | 24.28 | 35.12 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 64.07 | 78.88 |
|    desk-stuff    | 43.92 | 57.73 |
|       dirt       | 36.65 | 49.16 |
|    door-stuff    | 37.32 | 63.48 |
|      fence       | 25.17 | 40.85 |
|   floor-marble   |  0.05 |  0.05 |
|   floor-other    | 22.98 | 36.69 |
|   floor-stone    |  1.92 |  1.98 |
|    floor-tile    |  57.0 | 64.62 |
|    floor-wood    | 60.52 | 74.32 |
|      flower      | 45.52 | 63.95 |
|       fog        |  6.7  |  7.0  |
|    food-other    | 14.78 | 16.68 |
|      fruit       | 34.92 | 47.23 |
| furniture-other  | 12.67 | 15.97 |
|      grass       | 69.82 | 84.83 |
|      gravel      | 28.51 | 36.68 |
|   ground-other   |  0.62 |  0.68 |
|       hill       | 20.86 | 33.09 |
|      house       | 25.43 | 31.05 |
|      leaves      |  28.8 | 42.69 |
|      light       | 35.05 | 52.85 |
|       mat        |  0.0  |  0.0  |
|      metal       |  31.3 |  47.7 |
|   mirror-stuff   | 38.28 | 72.69 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 50.72 | 66.84 |
|       mud        |  2.89 |  8.19 |
|      napkin      |  7.88 |  7.91 |
|       net        | 40.89 | 63.58 |
|      paper       | 27.86 | 37.74 |
|     pavement     | 51.13 | 73.35 |
|      pillow      |  8.78 | 10.14 |
|   plant-other    | 21.58 | 37.61 |
|     plastic      | 18.93 | 24.51 |
|     platform     | 28.17 | 39.72 |
|   playingfield   | 68.98 | 92.69 |
|     railing      |  3.62 |  6.24 |
|     railroad     | 59.02 | 73.33 |
|      river       | 43.98 | 55.52 |
|       road       | 65.78 | 81.56 |
|       rock       | 39.52 | 64.22 |
|       roof       | 10.27 | 12.45 |
|       rug        |  32.6 | 49.04 |
|      salad       |  0.0  |  0.0  |
|       sand       | 61.09 |  76.0 |
|       sea        | 86.27 | 90.87 |
|      shelf       | 33.13 |  47.2 |
|    sky-other     | 70.42 | 89.39 |
|    skyscraper    | 33.33 | 43.22 |
|       snow       | 89.39 | 92.61 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 24.16 | 44.41 |
|      stone       |  5.9  |  9.42 |
|      straw       |  28.3 | 34.16 |
| structural-other |  0.37 |  0.38 |
|      table       | 17.53 | 23.69 |
|       tent       |  8.34 | 12.09 |
|  textile-other   | 11.14 | 18.21 |
|      towel       | 32.02 | 42.28 |
|       tree       | 73.74 | 84.93 |
|    vegetable     | 34.44 | 46.37 |
|    wall-brick    | 48.71 | 63.45 |
|  wall-concrete   | 60.24 | 79.37 |
|    wall-other    | 17.31 | 24.71 |
|    wall-panel    |  2.74 |  3.06 |
|    wall-stone    | 29.16 | 37.02 |
|    wall-tile     | 66.91 |  80.9 |
|    wall-wood     | 38.51 | 55.23 |
|   water-other    | 28.62 | 55.22 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 51.31 | 59.88 |
|   window-other   |  44.4 | 74.18 |
|       wood       | 21.25 | 30.05 |
+------------------+-------+-------+
2023/05/24 02:16:36 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.5100  mIoU: 45.4500  mAcc: 58.1500  data_time: 0.0020  time: 0.0842
2023/05/24 02:16:57 - mmengine - INFO - Iter(train) [ 65050/160000]  lr: 6.2523e-06  eta: 11:18:14  time: 0.4094  data_time: 0.0106  memory: 4930  grad_norm: 106.8191  loss: 45.1196  decode.loss_cls: 1.6995  decode.loss_mask: 0.7512  decode.loss_dice: 1.7577  decode.d0.loss_cls: 3.5812  decode.d0.loss_mask: 0.8288  decode.d0.loss_dice: 2.0921  decode.d1.loss_cls: 1.7972  decode.d1.loss_mask: 0.8832  decode.d1.loss_dice: 1.9437  decode.d2.loss_cls: 1.8312  decode.d2.loss_mask: 0.7770  decode.d2.loss_dice: 1.8240  decode.d3.loss_cls: 1.6444  decode.d3.loss_mask: 0.7725  decode.d3.loss_dice: 1.8051  decode.d4.loss_cls: 1.6507  decode.d4.loss_mask: 0.7629  decode.d4.loss_dice: 1.7698  decode.d5.loss_cls: 1.6503  decode.d5.loss_mask: 0.7578  decode.d5.loss_dice: 1.8134  decode.d6.loss_cls: 1.6394  decode.d6.loss_mask: 0.7759  decode.d6.loss_dice: 1.7903  decode.d7.loss_cls: 1.6774  decode.d7.loss_mask: 0.7881  decode.d7.loss_dice: 1.7773  decode.d8.loss_cls: 1.6976  decode.d8.loss_mask: 0.7712  decode.d8.loss_dice: 1.8086
2023/05/24 02:17:18 - mmengine - INFO - Iter(train) [ 65100/160000]  lr: 6.2493e-06  eta: 11:17:52  time: 0.4239  data_time: 0.0101  memory: 4823  grad_norm: 87.1132  loss: 32.5106  decode.loss_cls: 1.0602  decode.loss_mask: 0.7717  decode.loss_dice: 1.1730  decode.d0.loss_cls: 2.8227  decode.d0.loss_mask: 0.8289  decode.d0.loss_dice: 1.4001  decode.d1.loss_cls: 1.0905  decode.d1.loss_mask: 0.8414  decode.d1.loss_dice: 1.2511  decode.d2.loss_cls: 1.1397  decode.d2.loss_mask: 0.7814  decode.d2.loss_dice: 1.2275  decode.d3.loss_cls: 1.0537  decode.d3.loss_mask: 0.8007  decode.d3.loss_dice: 1.2300  decode.d4.loss_cls: 1.0302  decode.d4.loss_mask: 0.7932  decode.d4.loss_dice: 1.2212  decode.d5.loss_cls: 1.0653  decode.d5.loss_mask: 0.7858  decode.d5.loss_dice: 1.2039  decode.d6.loss_cls: 1.0445  decode.d6.loss_mask: 0.7796  decode.d6.loss_dice: 1.1383  decode.d7.loss_cls: 1.0025  decode.d7.loss_mask: 0.7951  decode.d7.loss_dice: 1.1661  decode.d8.loss_cls: 1.0657  decode.d8.loss_mask: 0.7795  decode.d8.loss_dice: 1.1670
2023/05/24 02:17:39 - mmengine - INFO - Iter(train) [ 65150/160000]  lr: 6.2464e-06  eta: 11:17:31  time: 0.4126  data_time: 0.0102  memory: 4840  grad_norm: 104.6874  loss: 35.3429  decode.loss_cls: 1.2505  decode.loss_mask: 0.6807  decode.loss_dice: 1.2966  decode.d0.loss_cls: 2.9400  decode.d0.loss_mask: 0.8082  decode.d0.loss_dice: 1.5903  decode.d1.loss_cls: 1.3352  decode.d1.loss_mask: 0.7776  decode.d1.loss_dice: 1.4948  decode.d2.loss_cls: 1.2561  decode.d2.loss_mask: 0.8118  decode.d2.loss_dice: 1.3875  decode.d3.loss_cls: 1.2301  decode.d3.loss_mask: 0.7385  decode.d3.loss_dice: 1.3450  decode.d4.loss_cls: 1.2345  decode.d4.loss_mask: 0.7288  decode.d4.loss_dice: 1.3484  decode.d5.loss_cls: 1.2289  decode.d5.loss_mask: 0.7065  decode.d5.loss_dice: 1.3308  decode.d6.loss_cls: 1.2725  decode.d6.loss_mask: 0.6915  decode.d6.loss_dice: 1.3241  decode.d7.loss_cls: 1.2256  decode.d7.loss_mask: 0.7194  decode.d7.loss_dice: 1.3220  decode.d8.loss_cls: 1.2426  decode.d8.loss_mask: 0.7055  decode.d8.loss_dice: 1.3190
2023/05/24 02:18:00 - mmengine - INFO - Iter(train) [ 65200/160000]  lr: 6.2434e-06  eta: 11:17:08  time: 0.4123  data_time: 0.0101  memory: 4828  grad_norm: 79.8843  loss: 45.4059  decode.loss_cls: 1.4417  decode.loss_mask: 0.9488  decode.loss_dice: 1.8773  decode.d0.loss_cls: 3.3644  decode.d0.loss_mask: 0.9561  decode.d0.loss_dice: 2.0855  decode.d1.loss_cls: 1.6000  decode.d1.loss_mask: 0.9775  decode.d1.loss_dice: 1.9345  decode.d2.loss_cls: 1.6068  decode.d2.loss_mask: 0.9736  decode.d2.loss_dice: 1.9173  decode.d3.loss_cls: 1.5425  decode.d3.loss_mask: 0.9495  decode.d3.loss_dice: 1.8517  decode.d4.loss_cls: 1.5413  decode.d4.loss_mask: 0.9647  decode.d4.loss_dice: 1.8351  decode.d5.loss_cls: 1.4837  decode.d5.loss_mask: 0.9401  decode.d5.loss_dice: 1.8600  decode.d6.loss_cls: 1.4132  decode.d6.loss_mask: 0.9535  decode.d6.loss_dice: 1.8480  decode.d7.loss_cls: 1.4602  decode.d7.loss_mask: 0.9425  decode.d7.loss_dice: 1.8754  decode.d8.loss_cls: 1.4793  decode.d8.loss_mask: 0.9422  decode.d8.loss_dice: 1.8398
2023/05/24 02:18:21 - mmengine - INFO - Iter(train) [ 65250/160000]  lr: 6.2404e-06  eta: 11:16:47  time: 0.4233  data_time: 0.0105  memory: 4876  grad_norm: 105.2416  loss: 36.6174  decode.loss_cls: 1.2385  decode.loss_mask: 0.8286  decode.loss_dice: 1.3113  decode.d0.loss_cls: 3.1713  decode.d0.loss_mask: 0.9250  decode.d0.loss_dice: 1.5319  decode.d1.loss_cls: 1.3209  decode.d1.loss_mask: 0.8782  decode.d1.loss_dice: 1.4327  decode.d2.loss_cls: 1.3286  decode.d2.loss_mask: 0.8125  decode.d2.loss_dice: 1.3552  decode.d3.loss_cls: 1.2968  decode.d3.loss_mask: 0.8088  decode.d3.loss_dice: 1.3782  decode.d4.loss_cls: 1.2492  decode.d4.loss_mask: 0.8387  decode.d4.loss_dice: 1.3653  decode.d5.loss_cls: 1.2024  decode.d5.loss_mask: 0.8889  decode.d5.loss_dice: 1.3882  decode.d6.loss_cls: 1.2289  decode.d6.loss_mask: 0.8045  decode.d6.loss_dice: 1.3512  decode.d7.loss_cls: 1.2184  decode.d7.loss_mask: 0.7953  decode.d7.loss_dice: 1.3047  decode.d8.loss_cls: 1.1978  decode.d8.loss_mask: 0.8365  decode.d8.loss_dice: 1.3291
2023/05/24 02:18:43 - mmengine - INFO - Iter(train) [ 65300/160000]  lr: 6.2375e-06  eta: 11:16:25  time: 0.4344  data_time: 0.0099  memory: 4860  grad_norm: 125.0713  loss: 36.0316  decode.loss_cls: 1.3577  decode.loss_mask: 0.7944  decode.loss_dice: 1.1356  decode.d0.loss_cls: 3.3196  decode.d0.loss_mask: 0.8299  decode.d0.loss_dice: 1.4306  decode.d1.loss_cls: 1.4498  decode.d1.loss_mask: 0.8321  decode.d1.loss_dice: 1.2325  decode.d2.loss_cls: 1.4195  decode.d2.loss_mask: 0.8150  decode.d2.loss_dice: 1.1967  decode.d3.loss_cls: 1.3905  decode.d3.loss_mask: 0.8022  decode.d3.loss_dice: 1.1839  decode.d4.loss_cls: 1.3581  decode.d4.loss_mask: 0.7983  decode.d4.loss_dice: 1.1986  decode.d5.loss_cls: 1.4031  decode.d5.loss_mask: 0.8433  decode.d5.loss_dice: 1.1828  decode.d6.loss_cls: 1.3997  decode.d6.loss_mask: 0.7899  decode.d6.loss_dice: 1.1451  decode.d7.loss_cls: 1.3716  decode.d7.loss_mask: 0.8216  decode.d7.loss_dice: 1.1631  decode.d8.loss_cls: 1.3903  decode.d8.loss_mask: 0.8483  decode.d8.loss_dice: 1.1277
2023/05/24 02:19:04 - mmengine - INFO - Iter(train) [ 65350/160000]  lr: 6.2345e-06  eta: 11:16:03  time: 0.4224  data_time: 0.0105  memory: 4869  grad_norm: 114.1352  loss: 36.1704  decode.loss_cls: 1.2187  decode.loss_mask: 0.8763  decode.loss_dice: 1.2073  decode.d0.loss_cls: 3.3193  decode.d0.loss_mask: 0.9816  decode.d0.loss_dice: 1.4014  decode.d1.loss_cls: 1.3186  decode.d1.loss_mask: 0.9426  decode.d1.loss_dice: 1.3040  decode.d2.loss_cls: 1.3024  decode.d2.loss_mask: 0.9423  decode.d2.loss_dice: 1.2538  decode.d3.loss_cls: 1.2732  decode.d3.loss_mask: 0.8898  decode.d3.loss_dice: 1.2271  decode.d4.loss_cls: 1.1870  decode.d4.loss_mask: 0.9148  decode.d4.loss_dice: 1.1996  decode.d5.loss_cls: 1.2032  decode.d5.loss_mask: 0.8659  decode.d5.loss_dice: 1.2298  decode.d6.loss_cls: 1.2237  decode.d6.loss_mask: 0.9180  decode.d6.loss_dice: 1.2343  decode.d7.loss_cls: 1.2018  decode.d7.loss_mask: 0.9386  decode.d7.loss_dice: 1.2482  decode.d8.loss_cls: 1.2059  decode.d8.loss_mask: 0.8911  decode.d8.loss_dice: 1.2502
2023/05/24 02:19:26 - mmengine - INFO - Iter(train) [ 65400/160000]  lr: 6.2316e-06  eta: 11:15:43  time: 0.4367  data_time: 0.0102  memory: 4835  grad_norm: 91.8074  loss: 34.4655  decode.loss_cls: 1.1300  decode.loss_mask: 0.7371  decode.loss_dice: 1.2860  decode.d0.loss_cls: 3.0356  decode.d0.loss_mask: 0.8572  decode.d0.loss_dice: 1.4794  decode.d1.loss_cls: 1.2588  decode.d1.loss_mask: 0.8083  decode.d1.loss_dice: 1.3916  decode.d2.loss_cls: 1.1627  decode.d2.loss_mask: 0.7852  decode.d2.loss_dice: 1.3747  decode.d3.loss_cls: 1.1686  decode.d3.loss_mask: 0.7965  decode.d3.loss_dice: 1.3243  decode.d4.loss_cls: 1.1066  decode.d4.loss_mask: 0.7796  decode.d4.loss_dice: 1.3302  decode.d5.loss_cls: 1.0576  decode.d5.loss_mask: 0.7720  decode.d5.loss_dice: 1.3516  decode.d6.loss_cls: 1.0776  decode.d6.loss_mask: 0.7743  decode.d6.loss_dice: 1.3463  decode.d7.loss_cls: 1.1031  decode.d7.loss_mask: 0.7417  decode.d7.loss_dice: 1.3020  decode.d8.loss_cls: 1.0644  decode.d8.loss_mask: 0.7477  decode.d8.loss_dice: 1.3151
2023/05/24 02:19:47 - mmengine - INFO - Iter(train) [ 65450/160000]  lr: 6.2286e-06  eta: 11:15:20  time: 0.4198  data_time: 0.0104  memory: 4953  grad_norm: 176.0375  loss: 37.9964  decode.loss_cls: 1.5151  decode.loss_mask: 0.6979  decode.loss_dice: 1.3145  decode.d0.loss_cls: 3.3487  decode.d0.loss_mask: 0.8028  decode.d0.loss_dice: 1.6263  decode.d1.loss_cls: 1.6687  decode.d1.loss_mask: 0.7203  decode.d1.loss_dice: 1.4355  decode.d2.loss_cls: 1.5858  decode.d2.loss_mask: 0.7303  decode.d2.loss_dice: 1.3617  decode.d3.loss_cls: 1.5031  decode.d3.loss_mask: 0.7273  decode.d3.loss_dice: 1.3997  decode.d4.loss_cls: 1.4698  decode.d4.loss_mask: 0.7120  decode.d4.loss_dice: 1.3609  decode.d5.loss_cls: 1.4622  decode.d5.loss_mask: 0.6936  decode.d5.loss_dice: 1.3489  decode.d6.loss_cls: 1.4251  decode.d6.loss_mask: 0.7257  decode.d6.loss_dice: 1.3362  decode.d7.loss_cls: 1.4591  decode.d7.loss_mask: 0.7098  decode.d7.loss_dice: 1.3354  decode.d8.loss_cls: 1.4694  decode.d8.loss_mask: 0.7108  decode.d8.loss_dice: 1.3398
2023/05/24 02:20:08 - mmengine - INFO - Iter(train) [ 65500/160000]  lr: 6.2256e-06  eta: 11:14:59  time: 0.4216  data_time: 0.0101  memory: 4860  grad_norm: 94.2463  loss: 33.0206  decode.loss_cls: 1.2515  decode.loss_mask: 0.6504  decode.loss_dice: 1.1746  decode.d0.loss_cls: 3.0959  decode.d0.loss_mask: 0.7516  decode.d0.loss_dice: 1.3806  decode.d1.loss_cls: 1.2643  decode.d1.loss_mask: 0.6903  decode.d1.loss_dice: 1.2995  decode.d2.loss_cls: 1.2753  decode.d2.loss_mask: 0.6767  decode.d2.loss_dice: 1.2363  decode.d3.loss_cls: 1.1881  decode.d3.loss_mask: 0.6715  decode.d3.loss_dice: 1.1790  decode.d4.loss_cls: 1.2629  decode.d4.loss_mask: 0.6732  decode.d4.loss_dice: 1.1648  decode.d5.loss_cls: 1.2488  decode.d5.loss_mask: 0.6491  decode.d5.loss_dice: 1.2098  decode.d6.loss_cls: 1.2087  decode.d6.loss_mask: 0.6607  decode.d6.loss_dice: 1.1516  decode.d7.loss_cls: 1.1947  decode.d7.loss_mask: 0.6537  decode.d7.loss_dice: 1.1571  decode.d8.loss_cls: 1.1762  decode.d8.loss_mask: 0.6484  decode.d8.loss_dice: 1.1752
2023/05/24 02:20:30 - mmengine - INFO - Iter(train) [ 65550/160000]  lr: 6.2227e-06  eta: 11:14:38  time: 0.4788  data_time: 0.0100  memory: 4845  grad_norm: 120.9130  loss: 32.5847  decode.loss_cls: 1.0490  decode.loss_mask: 0.8448  decode.loss_dice: 1.0719  decode.d0.loss_cls: 2.9593  decode.d0.loss_mask: 0.8788  decode.d0.loss_dice: 1.1897  decode.d1.loss_cls: 1.1703  decode.d1.loss_mask: 0.8574  decode.d1.loss_dice: 1.1492  decode.d2.loss_cls: 1.0975  decode.d2.loss_mask: 0.8479  decode.d2.loss_dice: 1.1068  decode.d3.loss_cls: 1.1194  decode.d3.loss_mask: 0.8711  decode.d3.loss_dice: 1.1169  decode.d4.loss_cls: 1.0868  decode.d4.loss_mask: 0.8479  decode.d4.loss_dice: 1.0947  decode.d5.loss_cls: 1.1277  decode.d5.loss_mask: 0.8595  decode.d5.loss_dice: 1.0891  decode.d6.loss_cls: 1.1559  decode.d6.loss_mask: 0.8616  decode.d6.loss_dice: 1.0691  decode.d7.loss_cls: 1.1118  decode.d7.loss_mask: 0.8621  decode.d7.loss_dice: 1.0527  decode.d8.loss_cls: 1.1258  decode.d8.loss_mask: 0.8508  decode.d8.loss_dice: 1.0591
2023/05/24 02:20:51 - mmengine - INFO - Iter(train) [ 65600/160000]  lr: 6.2197e-06  eta: 11:14:17  time: 0.4218  data_time: 0.0104  memory: 4845  grad_norm: 93.7081  loss: 44.7713  decode.loss_cls: 1.7312  decode.loss_mask: 0.7075  decode.loss_dice: 1.7359  decode.d0.loss_cls: 3.7826  decode.d0.loss_mask: 0.8637  decode.d0.loss_dice: 2.0589  decode.d1.loss_cls: 1.7423  decode.d1.loss_mask: 0.8332  decode.d1.loss_dice: 1.9191  decode.d2.loss_cls: 1.6990  decode.d2.loss_mask: 0.7612  decode.d2.loss_dice: 1.8204  decode.d3.loss_cls: 1.6349  decode.d3.loss_mask: 0.7496  decode.d3.loss_dice: 1.7691  decode.d4.loss_cls: 1.6309  decode.d4.loss_mask: 0.7279  decode.d4.loss_dice: 1.8067  decode.d5.loss_cls: 1.7056  decode.d5.loss_mask: 0.7319  decode.d5.loss_dice: 1.8194  decode.d6.loss_cls: 1.7304  decode.d6.loss_mask: 0.7193  decode.d6.loss_dice: 1.7514  decode.d7.loss_cls: 1.7132  decode.d7.loss_mask: 0.7039  decode.d7.loss_dice: 1.7346  decode.d8.loss_cls: 1.7362  decode.d8.loss_mask: 0.6962  decode.d8.loss_dice: 1.7552
2023/05/24 02:21:14 - mmengine - INFO - Iter(train) [ 65650/160000]  lr: 6.2167e-06  eta: 11:13:56  time: 0.4716  data_time: 0.0101  memory: 4843  grad_norm: 79.9005  loss: 38.3027  decode.loss_cls: 1.5449  decode.loss_mask: 0.7370  decode.loss_dice: 1.2884  decode.d0.loss_cls: 3.4109  decode.d0.loss_mask: 0.8127  decode.d0.loss_dice: 1.5043  decode.d1.loss_cls: 1.6631  decode.d1.loss_mask: 0.8313  decode.d1.loss_dice: 1.4621  decode.d2.loss_cls: 1.5551  decode.d2.loss_mask: 0.7635  decode.d2.loss_dice: 1.4095  decode.d3.loss_cls: 1.4928  decode.d3.loss_mask: 0.7946  decode.d3.loss_dice: 1.3414  decode.d4.loss_cls: 1.5532  decode.d4.loss_mask: 0.7461  decode.d4.loss_dice: 1.3159  decode.d5.loss_cls: 1.5875  decode.d5.loss_mask: 0.7403  decode.d5.loss_dice: 1.3255  decode.d6.loss_cls: 1.4749  decode.d6.loss_mask: 0.7188  decode.d6.loss_dice: 1.2694  decode.d7.loss_cls: 1.4441  decode.d7.loss_mask: 0.7145  decode.d7.loss_dice: 1.3070  decode.d8.loss_cls: 1.4792  decode.d8.loss_mask: 0.7345  decode.d8.loss_dice: 1.2802
2023/05/24 02:21:35 - mmengine - INFO - Iter(train) [ 65700/160000]  lr: 6.2138e-06  eta: 11:13:35  time: 0.4430  data_time: 0.0102  memory: 4846  grad_norm: 103.0022  loss: 37.8655  decode.loss_cls: 1.3709  decode.loss_mask: 0.7858  decode.loss_dice: 1.3406  decode.d0.loss_cls: 3.2308  decode.d0.loss_mask: 0.8775  decode.d0.loss_dice: 1.6011  decode.d1.loss_cls: 1.5095  decode.d1.loss_mask: 0.8132  decode.d1.loss_dice: 1.4380  decode.d2.loss_cls: 1.3739  decode.d2.loss_mask: 0.8313  decode.d2.loss_dice: 1.3708  decode.d3.loss_cls: 1.4038  decode.d3.loss_mask: 0.7998  decode.d3.loss_dice: 1.3363  decode.d4.loss_cls: 1.4355  decode.d4.loss_mask: 0.7936  decode.d4.loss_dice: 1.3500  decode.d5.loss_cls: 1.4494  decode.d5.loss_mask: 0.8042  decode.d5.loss_dice: 1.3644  decode.d6.loss_cls: 1.4006  decode.d6.loss_mask: 0.7883  decode.d6.loss_dice: 1.3632  decode.d7.loss_cls: 1.3805  decode.d7.loss_mask: 0.8104  decode.d7.loss_dice: 1.3576  decode.d8.loss_cls: 1.3656  decode.d8.loss_mask: 0.7837  decode.d8.loss_dice: 1.3351
2023/05/24 02:21:57 - mmengine - INFO - Iter(train) [ 65750/160000]  lr: 6.2108e-06  eta: 11:13:14  time: 0.4145  data_time: 0.0108  memory: 4900  grad_norm: 86.0688  loss: 33.9026  decode.loss_cls: 1.0867  decode.loss_mask: 0.5904  decode.loss_dice: 1.4502  decode.d0.loss_cls: 2.8716  decode.d0.loss_mask: 0.6042  decode.d0.loss_dice: 1.6548  decode.d1.loss_cls: 1.3061  decode.d1.loss_mask: 0.5894  decode.d1.loss_dice: 1.5856  decode.d2.loss_cls: 1.2319  decode.d2.loss_mask: 0.5685  decode.d2.loss_dice: 1.5112  decode.d3.loss_cls: 1.1083  decode.d3.loss_mask: 0.5579  decode.d3.loss_dice: 1.4859  decode.d4.loss_cls: 1.1000  decode.d4.loss_mask: 0.5626  decode.d4.loss_dice: 1.5047  decode.d5.loss_cls: 1.1776  decode.d5.loss_mask: 0.5339  decode.d5.loss_dice: 1.4346  decode.d6.loss_cls: 1.1126  decode.d6.loss_mask: 0.5452  decode.d6.loss_dice: 1.4674  decode.d7.loss_cls: 1.1771  decode.d7.loss_mask: 0.5238  decode.d7.loss_dice: 1.4157  decode.d8.loss_cls: 1.1075  decode.d8.loss_mask: 0.5599  decode.d8.loss_dice: 1.4771
2023/05/24 02:22:18 - mmengine - INFO - Iter(train) [ 65800/160000]  lr: 6.2078e-06  eta: 11:12:52  time: 0.4229  data_time: 0.0101  memory: 4816  grad_norm: 111.1629  loss: 34.5132  decode.loss_cls: 1.2731  decode.loss_mask: 0.7733  decode.loss_dice: 1.1228  decode.d0.loss_cls: 3.3224  decode.d0.loss_mask: 0.7981  decode.d0.loss_dice: 1.2467  decode.d1.loss_cls: 1.3961  decode.d1.loss_mask: 0.7914  decode.d1.loss_dice: 1.2329  decode.d2.loss_cls: 1.3214  decode.d2.loss_mask: 0.7583  decode.d2.loss_dice: 1.1979  decode.d3.loss_cls: 1.3156  decode.d3.loss_mask: 0.7660  decode.d3.loss_dice: 1.1663  decode.d4.loss_cls: 1.2701  decode.d4.loss_mask: 0.7556  decode.d4.loss_dice: 1.1602  decode.d5.loss_cls: 1.2989  decode.d5.loss_mask: 0.7673  decode.d5.loss_dice: 1.1607  decode.d6.loss_cls: 1.3106  decode.d6.loss_mask: 0.7857  decode.d6.loss_dice: 1.1252  decode.d7.loss_cls: 1.2491  decode.d7.loss_mask: 0.7818  decode.d7.loss_dice: 1.1305  decode.d8.loss_cls: 1.3353  decode.d8.loss_mask: 0.7635  decode.d8.loss_dice: 1.1365
2023/05/24 02:22:39 - mmengine - INFO - Iter(train) [ 65850/160000]  lr: 6.2049e-06  eta: 11:12:30  time: 0.4169  data_time: 0.0102  memory: 4845  grad_norm: 85.2001  loss: 33.6851  decode.loss_cls: 1.1490  decode.loss_mask: 0.8502  decode.loss_dice: 1.1511  decode.d0.loss_cls: 2.9200  decode.d0.loss_mask: 0.9257  decode.d0.loss_dice: 1.2593  decode.d1.loss_cls: 1.2872  decode.d1.loss_mask: 0.9022  decode.d1.loss_dice: 1.2608  decode.d2.loss_cls: 1.1653  decode.d2.loss_mask: 0.9234  decode.d2.loss_dice: 1.1689  decode.d3.loss_cls: 1.1675  decode.d3.loss_mask: 0.8620  decode.d3.loss_dice: 1.1309  decode.d4.loss_cls: 1.0898  decode.d4.loss_mask: 0.8591  decode.d4.loss_dice: 1.1822  decode.d5.loss_cls: 1.1219  decode.d5.loss_mask: 0.8558  decode.d5.loss_dice: 1.1407  decode.d6.loss_cls: 1.1476  decode.d6.loss_mask: 0.8271  decode.d6.loss_dice: 1.1403  decode.d7.loss_cls: 1.0722  decode.d7.loss_mask: 0.8398  decode.d7.loss_dice: 1.1641  decode.d8.loss_cls: 1.1412  decode.d8.loss_mask: 0.8332  decode.d8.loss_dice: 1.1464
2023/05/24 02:23:00 - mmengine - INFO - Iter(train) [ 65900/160000]  lr: 6.2019e-06  eta: 11:12:08  time: 0.4223  data_time: 0.0103  memory: 4858  grad_norm: 111.2422  loss: 26.9757  decode.loss_cls: 0.9109  decode.loss_mask: 0.5131  decode.loss_dice: 0.9702  decode.d0.loss_cls: 2.8661  decode.d0.loss_mask: 0.6100  decode.d0.loss_dice: 1.1044  decode.d1.loss_cls: 0.9233  decode.d1.loss_mask: 0.6155  decode.d1.loss_dice: 1.0976  decode.d2.loss_cls: 1.0249  decode.d2.loss_mask: 0.5689  decode.d2.loss_dice: 1.0244  decode.d3.loss_cls: 0.9317  decode.d3.loss_mask: 0.5568  decode.d3.loss_dice: 1.0216  decode.d4.loss_cls: 0.9127  decode.d4.loss_mask: 0.5296  decode.d4.loss_dice: 0.9959  decode.d5.loss_cls: 0.9197  decode.d5.loss_mask: 0.5275  decode.d5.loss_dice: 0.9928  decode.d6.loss_cls: 0.9583  decode.d6.loss_mask: 0.5148  decode.d6.loss_dice: 0.9877  decode.d7.loss_cls: 0.9409  decode.d7.loss_mask: 0.5200  decode.d7.loss_dice: 0.9803  decode.d8.loss_cls: 0.9634  decode.d8.loss_mask: 0.5107  decode.d8.loss_dice: 0.9821
2023/05/24 02:23:20 - mmengine - INFO - Iter(train) [ 65950/160000]  lr: 6.1989e-06  eta: 11:11:45  time: 0.4093  data_time: 0.0103  memory: 4835  grad_norm: 167.5316  loss: 37.0655  decode.loss_cls: 1.5377  decode.loss_mask: 0.7869  decode.loss_dice: 1.0803  decode.d0.loss_cls: 3.1809  decode.d0.loss_mask: 0.8812  decode.d0.loss_dice: 1.3373  decode.d1.loss_cls: 1.6091  decode.d1.loss_mask: 0.8494  decode.d1.loss_dice: 1.2706  decode.d2.loss_cls: 1.6402  decode.d2.loss_mask: 0.8418  decode.d2.loss_dice: 1.2097  decode.d3.loss_cls: 1.5803  decode.d3.loss_mask: 0.7987  decode.d3.loss_dice: 1.0993  decode.d4.loss_cls: 1.5549  decode.d4.loss_mask: 0.7941  decode.d4.loss_dice: 1.1233  decode.d5.loss_cls: 1.5329  decode.d5.loss_mask: 0.8451  decode.d5.loss_dice: 1.1364  decode.d6.loss_cls: 1.6028  decode.d6.loss_mask: 0.8153  decode.d6.loss_dice: 1.0897  decode.d7.loss_cls: 1.5868  decode.d7.loss_mask: 0.7889  decode.d7.loss_dice: 1.0524  decode.d8.loss_cls: 1.5204  decode.d8.loss_mask: 0.7987  decode.d8.loss_dice: 1.1204
2023/05/24 02:23:42 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 02:23:42 - mmengine - INFO - Iter(train) [ 66000/160000]  lr: 6.1960e-06  eta: 11:11:24  time: 0.4675  data_time: 0.0103  memory: 4857  grad_norm: 91.1778  loss: 33.1983  decode.loss_cls: 1.0559  decode.loss_mask: 0.7956  decode.loss_dice: 1.1888  decode.d0.loss_cls: 3.1683  decode.d0.loss_mask: 0.8390  decode.d0.loss_dice: 1.3447  decode.d1.loss_cls: 1.1909  decode.d1.loss_mask: 0.8212  decode.d1.loss_dice: 1.3090  decode.d2.loss_cls: 1.0929  decode.d2.loss_mask: 0.7963  decode.d2.loss_dice: 1.2571  decode.d3.loss_cls: 1.0681  decode.d3.loss_mask: 0.7983  decode.d3.loss_dice: 1.2310  decode.d4.loss_cls: 1.0489  decode.d4.loss_mask: 0.7884  decode.d4.loss_dice: 1.2252  decode.d5.loss_cls: 1.0582  decode.d5.loss_mask: 0.7820  decode.d5.loss_dice: 1.2237  decode.d6.loss_cls: 1.0687  decode.d6.loss_mask: 0.7801  decode.d6.loss_dice: 1.2008  decode.d7.loss_cls: 1.0381  decode.d7.loss_mask: 0.7871  decode.d7.loss_dice: 1.1779  decode.d8.loss_cls: 1.0481  decode.d8.loss_mask: 0.8141  decode.d8.loss_dice: 1.1998
2023/05/24 02:23:42 - mmengine - INFO - Saving checkpoint at 66000 iterations
2023/05/24 02:24:09 - mmengine - INFO - Iter(train) [ 66050/160000]  lr: 6.1930e-06  eta: 11:11:10  time: 0.4158  data_time: 0.0100  memory: 4866  grad_norm: 105.5132  loss: 41.7150  decode.loss_cls: 1.3778  decode.loss_mask: 0.9829  decode.loss_dice: 1.4713  decode.d0.loss_cls: 3.4860  decode.d0.loss_mask: 1.0395  decode.d0.loss_dice: 1.7957  decode.d1.loss_cls: 1.5952  decode.d1.loss_mask: 1.0192  decode.d1.loss_dice: 1.5880  decode.d2.loss_cls: 1.4463  decode.d2.loss_mask: 1.0189  decode.d2.loss_dice: 1.5772  decode.d3.loss_cls: 1.3747  decode.d3.loss_mask: 1.0160  decode.d3.loss_dice: 1.5132  decode.d4.loss_cls: 1.3383  decode.d4.loss_mask: 1.0215  decode.d4.loss_dice: 1.5308  decode.d5.loss_cls: 1.3601  decode.d5.loss_mask: 1.0127  decode.d5.loss_dice: 1.5399  decode.d6.loss_cls: 1.3582  decode.d6.loss_mask: 0.9892  decode.d6.loss_dice: 1.4611  decode.d7.loss_cls: 1.4025  decode.d7.loss_mask: 0.9849  decode.d7.loss_dice: 1.5004  decode.d8.loss_cls: 1.4462  decode.d8.loss_mask: 0.9774  decode.d8.loss_dice: 1.4896
2023/05/24 02:24:29 - mmengine - INFO - Iter(train) [ 66100/160000]  lr: 6.1900e-06  eta: 11:10:48  time: 0.4110  data_time: 0.0103  memory: 4836  grad_norm: 91.6992  loss: 39.1749  decode.loss_cls: 1.3042  decode.loss_mask: 0.9411  decode.loss_dice: 1.4141  decode.d0.loss_cls: 3.0940  decode.d0.loss_mask: 1.0169  decode.d0.loss_dice: 1.5750  decode.d1.loss_cls: 1.4303  decode.d1.loss_mask: 1.0120  decode.d1.loss_dice: 1.4987  decode.d2.loss_cls: 1.3280  decode.d2.loss_mask: 0.9637  decode.d2.loss_dice: 1.4587  decode.d3.loss_cls: 1.2160  decode.d3.loss_mask: 0.9471  decode.d3.loss_dice: 1.4441  decode.d4.loss_cls: 1.2991  decode.d4.loss_mask: 0.9736  decode.d4.loss_dice: 1.4269  decode.d5.loss_cls: 1.2777  decode.d5.loss_mask: 1.0121  decode.d5.loss_dice: 1.4418  decode.d6.loss_cls: 1.2656  decode.d6.loss_mask: 0.9517  decode.d6.loss_dice: 1.4366  decode.d7.loss_cls: 1.3829  decode.d7.loss_mask: 0.9386  decode.d7.loss_dice: 1.4199  decode.d8.loss_cls: 1.2861  decode.d8.loss_mask: 0.9697  decode.d8.loss_dice: 1.4490
2023/05/24 02:24:50 - mmengine - INFO - Iter(train) [ 66150/160000]  lr: 6.1871e-06  eta: 11:10:25  time: 0.4263  data_time: 0.0108  memory: 4845  grad_norm: 96.5905  loss: 38.9455  decode.loss_cls: 1.4507  decode.loss_mask: 0.8409  decode.loss_dice: 1.3500  decode.d0.loss_cls: 3.4441  decode.d0.loss_mask: 0.9518  decode.d0.loss_dice: 1.6353  decode.d1.loss_cls: 1.6576  decode.d1.loss_mask: 0.8909  decode.d1.loss_dice: 1.4034  decode.d2.loss_cls: 1.5340  decode.d2.loss_mask: 0.8674  decode.d2.loss_dice: 1.3376  decode.d3.loss_cls: 1.4607  decode.d3.loss_mask: 0.8794  decode.d3.loss_dice: 1.3286  decode.d4.loss_cls: 1.4554  decode.d4.loss_mask: 0.8580  decode.d4.loss_dice: 1.2965  decode.d5.loss_cls: 1.4081  decode.d5.loss_mask: 0.8609  decode.d5.loss_dice: 1.3101  decode.d6.loss_cls: 1.4189  decode.d6.loss_mask: 0.8524  decode.d6.loss_dice: 1.3233  decode.d7.loss_cls: 1.4006  decode.d7.loss_mask: 0.8333  decode.d7.loss_dice: 1.3310  decode.d8.loss_cls: 1.3880  decode.d8.loss_mask: 0.8504  decode.d8.loss_dice: 1.3262
2023/05/24 02:25:11 - mmengine - INFO - Iter(train) [ 66200/160000]  lr: 6.1841e-06  eta: 11:10:04  time: 0.4219  data_time: 0.0107  memory: 4829  grad_norm: 95.1110  loss: 33.1502  decode.loss_cls: 1.1965  decode.loss_mask: 0.7583  decode.loss_dice: 1.0704  decode.d0.loss_cls: 2.9016  decode.d0.loss_mask: 0.8228  decode.d0.loss_dice: 1.2884  decode.d1.loss_cls: 1.3102  decode.d1.loss_mask: 0.8086  decode.d1.loss_dice: 1.2486  decode.d2.loss_cls: 1.3204  decode.d2.loss_mask: 0.7861  decode.d2.loss_dice: 1.1216  decode.d3.loss_cls: 1.2633  decode.d3.loss_mask: 0.8207  decode.d3.loss_dice: 1.1046  decode.d4.loss_cls: 1.1604  decode.d4.loss_mask: 0.7913  decode.d4.loss_dice: 1.1144  decode.d5.loss_cls: 1.1842  decode.d5.loss_mask: 0.7695  decode.d5.loss_dice: 1.1138  decode.d6.loss_cls: 1.2142  decode.d6.loss_mask: 0.7690  decode.d6.loss_dice: 1.0860  decode.d7.loss_cls: 1.2146  decode.d7.loss_mask: 0.7690  decode.d7.loss_dice: 1.0781  decode.d8.loss_cls: 1.1860  decode.d8.loss_mask: 0.7667  decode.d8.loss_dice: 1.1111
2023/05/24 02:25:32 - mmengine - INFO - Iter(train) [ 66250/160000]  lr: 6.1811e-06  eta: 11:09:41  time: 0.4240  data_time: 0.0101  memory: 4866  grad_norm: 107.0212  loss: 45.6106  decode.loss_cls: 1.8809  decode.loss_mask: 0.7577  decode.loss_dice: 1.5615  decode.d0.loss_cls: 3.7372  decode.d0.loss_mask: 0.8661  decode.d0.loss_dice: 1.8738  decode.d1.loss_cls: 2.1481  decode.d1.loss_mask: 0.8238  decode.d1.loss_dice: 1.7674  decode.d2.loss_cls: 1.9769  decode.d2.loss_mask: 0.7817  decode.d2.loss_dice: 1.6663  decode.d3.loss_cls: 1.9676  decode.d3.loss_mask: 0.7534  decode.d3.loss_dice: 1.6342  decode.d4.loss_cls: 1.8899  decode.d4.loss_mask: 0.7717  decode.d4.loss_dice: 1.6541  decode.d5.loss_cls: 1.9696  decode.d5.loss_mask: 0.7551  decode.d5.loss_dice: 1.6081  decode.d6.loss_cls: 1.9057  decode.d6.loss_mask: 0.7691  decode.d6.loss_dice: 1.5548  decode.d7.loss_cls: 1.8577  decode.d7.loss_mask: 0.7785  decode.d7.loss_dice: 1.6131  decode.d8.loss_cls: 1.9409  decode.d8.loss_mask: 0.7681  decode.d8.loss_dice: 1.5775
2023/05/24 02:25:54 - mmengine - INFO - Iter(train) [ 66300/160000]  lr: 6.1782e-06  eta: 11:09:21  time: 0.4132  data_time: 0.0102  memory: 4844  grad_norm: 122.0748  loss: 35.3467  decode.loss_cls: 1.1745  decode.loss_mask: 0.8329  decode.loss_dice: 1.2955  decode.d0.loss_cls: 3.1475  decode.d0.loss_mask: 0.8031  decode.d0.loss_dice: 1.4577  decode.d1.loss_cls: 1.2141  decode.d1.loss_mask: 0.8478  decode.d1.loss_dice: 1.3838  decode.d2.loss_cls: 1.1646  decode.d2.loss_mask: 0.8471  decode.d2.loss_dice: 1.3306  decode.d3.loss_cls: 1.1545  decode.d3.loss_mask: 0.8584  decode.d3.loss_dice: 1.3258  decode.d4.loss_cls: 1.1186  decode.d4.loss_mask: 0.8654  decode.d4.loss_dice: 1.3375  decode.d5.loss_cls: 1.1533  decode.d5.loss_mask: 0.8458  decode.d5.loss_dice: 1.3161  decode.d6.loss_cls: 1.1864  decode.d6.loss_mask: 0.8430  decode.d6.loss_dice: 1.3039  decode.d7.loss_cls: 1.1594  decode.d7.loss_mask: 0.8470  decode.d7.loss_dice: 1.2975  decode.d8.loss_cls: 1.1435  decode.d8.loss_mask: 0.8067  decode.d8.loss_dice: 1.2845
2023/05/24 02:26:15 - mmengine - INFO - Iter(train) [ 66350/160000]  lr: 6.1752e-06  eta: 11:08:58  time: 0.4115  data_time: 0.0100  memory: 4855  grad_norm: 88.9029  loss: 31.8736  decode.loss_cls: 1.1184  decode.loss_mask: 0.6778  decode.loss_dice: 1.1463  decode.d0.loss_cls: 2.7708  decode.d0.loss_mask: 0.6619  decode.d0.loss_dice: 1.2417  decode.d1.loss_cls: 1.3779  decode.d1.loss_mask: 0.6678  decode.d1.loss_dice: 1.1511  decode.d2.loss_cls: 1.3249  decode.d2.loss_mask: 0.6265  decode.d2.loss_dice: 1.1500  decode.d3.loss_cls: 1.2090  decode.d3.loss_mask: 0.6379  decode.d3.loss_dice: 1.1665  decode.d4.loss_cls: 1.2461  decode.d4.loss_mask: 0.6560  decode.d4.loss_dice: 1.1830  decode.d5.loss_cls: 1.2765  decode.d5.loss_mask: 0.6391  decode.d5.loss_dice: 1.1601  decode.d6.loss_cls: 1.1505  decode.d6.loss_mask: 0.6756  decode.d6.loss_dice: 1.1247  decode.d7.loss_cls: 1.2302  decode.d7.loss_mask: 0.6204  decode.d7.loss_dice: 1.0896  decode.d8.loss_cls: 1.1200  decode.d8.loss_mask: 0.6533  decode.d8.loss_dice: 1.1200
2023/05/24 02:26:36 - mmengine - INFO - Iter(train) [ 66400/160000]  lr: 6.1722e-06  eta: 11:08:36  time: 0.4194  data_time: 0.0104  memory: 4805  grad_norm: 91.2772  loss: 32.7602  decode.loss_cls: 1.2747  decode.loss_mask: 0.7142  decode.loss_dice: 1.0885  decode.d0.loss_cls: 3.1428  decode.d0.loss_mask: 0.7674  decode.d0.loss_dice: 1.1721  decode.d1.loss_cls: 1.4100  decode.d1.loss_mask: 0.7248  decode.d1.loss_dice: 1.0978  decode.d2.loss_cls: 1.3815  decode.d2.loss_mask: 0.7428  decode.d2.loss_dice: 1.0845  decode.d3.loss_cls: 1.2660  decode.d3.loss_mask: 0.7110  decode.d3.loss_dice: 1.0463  decode.d4.loss_cls: 1.3077  decode.d4.loss_mask: 0.7413  decode.d4.loss_dice: 1.0463  decode.d5.loss_cls: 1.1958  decode.d5.loss_mask: 0.7181  decode.d5.loss_dice: 1.0559  decode.d6.loss_cls: 1.2699  decode.d6.loss_mask: 0.7216  decode.d6.loss_dice: 1.0643  decode.d7.loss_cls: 1.2393  decode.d7.loss_mask: 0.7057  decode.d7.loss_dice: 1.0620  decode.d8.loss_cls: 1.2407  decode.d8.loss_mask: 0.6949  decode.d8.loss_dice: 1.0724
2023/05/24 02:26:58 - mmengine - INFO - Iter(train) [ 66450/160000]  lr: 6.1693e-06  eta: 11:08:15  time: 0.4723  data_time: 0.0108  memory: 4829  grad_norm: 109.6360  loss: 42.1510  decode.loss_cls: 1.5640  decode.loss_mask: 0.9184  decode.loss_dice: 1.4256  decode.d0.loss_cls: 3.5559  decode.d0.loss_mask: 0.9896  decode.d0.loss_dice: 1.6914  decode.d1.loss_cls: 1.5378  decode.d1.loss_mask: 0.9443  decode.d1.loss_dice: 1.5079  decode.d2.loss_cls: 1.6637  decode.d2.loss_mask: 0.9561  decode.d2.loss_dice: 1.5073  decode.d3.loss_cls: 1.6733  decode.d3.loss_mask: 0.9050  decode.d3.loss_dice: 1.4557  decode.d4.loss_cls: 1.6744  decode.d4.loss_mask: 0.9128  decode.d4.loss_dice: 1.4230  decode.d5.loss_cls: 1.6104  decode.d5.loss_mask: 0.9219  decode.d5.loss_dice: 1.4521  decode.d6.loss_cls: 1.5427  decode.d6.loss_mask: 0.9544  decode.d6.loss_dice: 1.4393  decode.d7.loss_cls: 1.5296  decode.d7.loss_mask: 0.9662  decode.d7.loss_dice: 1.4555  decode.d8.loss_cls: 1.5733  decode.d8.loss_mask: 0.9640  decode.d8.loss_dice: 1.4356
2023/05/24 02:27:20 - mmengine - INFO - Iter(train) [ 66500/160000]  lr: 6.1663e-06  eta: 11:07:55  time: 0.4169  data_time: 0.0105  memory: 4856  grad_norm: 113.2549  loss: 48.2829  decode.loss_cls: 1.6966  decode.loss_mask: 0.9809  decode.loss_dice: 1.7582  decode.d0.loss_cls: 3.7525  decode.d0.loss_mask: 1.1458  decode.d0.loss_dice: 2.0934  decode.d1.loss_cls: 1.9029  decode.d1.loss_mask: 1.1588  decode.d1.loss_dice: 2.0288  decode.d2.loss_cls: 1.7885  decode.d2.loss_mask: 1.0395  decode.d2.loss_dice: 1.8623  decode.d3.loss_cls: 1.8292  decode.d3.loss_mask: 0.9759  decode.d3.loss_dice: 1.7676  decode.d4.loss_cls: 1.8004  decode.d4.loss_mask: 1.0005  decode.d4.loss_dice: 1.7621  decode.d5.loss_cls: 1.7537  decode.d5.loss_mask: 1.0152  decode.d5.loss_dice: 1.8154  decode.d6.loss_cls: 1.7333  decode.d6.loss_mask: 0.9911  decode.d6.loss_dice: 1.7224  decode.d7.loss_cls: 1.6889  decode.d7.loss_mask: 0.9963  decode.d7.loss_dice: 1.7721  decode.d8.loss_cls: 1.6867  decode.d8.loss_mask: 0.9865  decode.d8.loss_dice: 1.7776
2023/05/24 02:27:41 - mmengine - INFO - Iter(train) [ 66550/160000]  lr: 6.1633e-06  eta: 11:07:33  time: 0.4100  data_time: 0.0099  memory: 4869  grad_norm: 139.1954  loss: 40.8617  decode.loss_cls: 1.5007  decode.loss_mask: 0.8370  decode.loss_dice: 1.4562  decode.d0.loss_cls: 3.5318  decode.d0.loss_mask: 0.9410  decode.d0.loss_dice: 1.8390  decode.d1.loss_cls: 1.6195  decode.d1.loss_mask: 0.9048  decode.d1.loss_dice: 1.6325  decode.d2.loss_cls: 1.5857  decode.d2.loss_mask: 0.8755  decode.d2.loss_dice: 1.5026  decode.d3.loss_cls: 1.5653  decode.d3.loss_mask: 0.8128  decode.d3.loss_dice: 1.4253  decode.d4.loss_cls: 1.4976  decode.d4.loss_mask: 0.8190  decode.d4.loss_dice: 1.4514  decode.d5.loss_cls: 1.4897  decode.d5.loss_mask: 0.8395  decode.d5.loss_dice: 1.4532  decode.d6.loss_cls: 1.5463  decode.d6.loss_mask: 0.8160  decode.d6.loss_dice: 1.4461  decode.d7.loss_cls: 1.5436  decode.d7.loss_mask: 0.8058  decode.d7.loss_dice: 1.4348  decode.d8.loss_cls: 1.5011  decode.d8.loss_mask: 0.8090  decode.d8.loss_dice: 1.3790
2023/05/24 02:28:02 - mmengine - INFO - Iter(train) [ 66600/160000]  lr: 6.1604e-06  eta: 11:07:10  time: 0.4149  data_time: 0.0102  memory: 4821  grad_norm: 91.8875  loss: 34.1993  decode.loss_cls: 1.3111  decode.loss_mask: 0.6649  decode.loss_dice: 1.2624  decode.d0.loss_cls: 2.9754  decode.d0.loss_mask: 0.6944  decode.d0.loss_dice: 1.4054  decode.d1.loss_cls: 1.3226  decode.d1.loss_mask: 0.7107  decode.d1.loss_dice: 1.2961  decode.d2.loss_cls: 1.2170  decode.d2.loss_mask: 0.6276  decode.d2.loss_dice: 1.3129  decode.d3.loss_cls: 1.2948  decode.d3.loss_mask: 0.6672  decode.d3.loss_dice: 1.2522  decode.d4.loss_cls: 1.2624  decode.d4.loss_mask: 0.6796  decode.d4.loss_dice: 1.2590  decode.d5.loss_cls: 1.3299  decode.d5.loss_mask: 0.6393  decode.d5.loss_dice: 1.2406  decode.d6.loss_cls: 1.3145  decode.d6.loss_mask: 0.6834  decode.d6.loss_dice: 1.2789  decode.d7.loss_cls: 1.3485  decode.d7.loss_mask: 0.6561  decode.d7.loss_dice: 1.2711  decode.d8.loss_cls: 1.3059  decode.d8.loss_mask: 0.6734  decode.d8.loss_dice: 1.2422
2023/05/24 02:28:24 - mmengine - INFO - Iter(train) [ 66650/160000]  lr: 6.1574e-06  eta: 11:06:50  time: 0.4477  data_time: 0.0104  memory: 4805  grad_norm: 104.2874  loss: 31.4073  decode.loss_cls: 1.0565  decode.loss_mask: 0.7032  decode.loss_dice: 1.1060  decode.d0.loss_cls: 3.1335  decode.d0.loss_mask: 0.7327  decode.d0.loss_dice: 1.2253  decode.d1.loss_cls: 1.1917  decode.d1.loss_mask: 0.7570  decode.d1.loss_dice: 1.2223  decode.d2.loss_cls: 1.0672  decode.d2.loss_mask: 0.7502  decode.d2.loss_dice: 1.1487  decode.d3.loss_cls: 1.1188  decode.d3.loss_mask: 0.6835  decode.d3.loss_dice: 1.1102  decode.d4.loss_cls: 1.0480  decode.d4.loss_mask: 0.7053  decode.d4.loss_dice: 1.0980  decode.d5.loss_cls: 1.0792  decode.d5.loss_mask: 0.7197  decode.d5.loss_dice: 1.1046  decode.d6.loss_cls: 1.1052  decode.d6.loss_mask: 0.7069  decode.d6.loss_dice: 1.0910  decode.d7.loss_cls: 1.0344  decode.d7.loss_mask: 0.7134  decode.d7.loss_dice: 1.1146  decode.d8.loss_cls: 1.0339  decode.d8.loss_mask: 0.7267  decode.d8.loss_dice: 1.1197
2023/05/24 02:28:45 - mmengine - INFO - Iter(train) [ 66700/160000]  lr: 6.1544e-06  eta: 11:06:29  time: 0.4242  data_time: 0.0104  memory: 4869  grad_norm: 92.6937  loss: 35.0060  decode.loss_cls: 1.4567  decode.loss_mask: 0.6668  decode.loss_dice: 1.0821  decode.d0.loss_cls: 3.3308  decode.d0.loss_mask: 0.7714  decode.d0.loss_dice: 1.3176  decode.d1.loss_cls: 1.6082  decode.d1.loss_mask: 0.7450  decode.d1.loss_dice: 1.1938  decode.d2.loss_cls: 1.5169  decode.d2.loss_mask: 0.6907  decode.d2.loss_dice: 1.1207  decode.d3.loss_cls: 1.4773  decode.d3.loss_mask: 0.6706  decode.d3.loss_dice: 1.1176  decode.d4.loss_cls: 1.5280  decode.d4.loss_mask: 0.6701  decode.d4.loss_dice: 1.0708  decode.d5.loss_cls: 1.5422  decode.d5.loss_mask: 0.6673  decode.d5.loss_dice: 1.0852  decode.d6.loss_cls: 1.4243  decode.d6.loss_mask: 0.6697  decode.d6.loss_dice: 1.0864  decode.d7.loss_cls: 1.4647  decode.d7.loss_mask: 0.6745  decode.d7.loss_dice: 1.0943  decode.d8.loss_cls: 1.5124  decode.d8.loss_mask: 0.6700  decode.d8.loss_dice: 1.0799
2023/05/24 02:29:06 - mmengine - INFO - Iter(train) [ 66750/160000]  lr: 6.1515e-06  eta: 11:06:07  time: 0.4192  data_time: 0.0103  memory: 4872  grad_norm: 87.2483  loss: 49.1885  decode.loss_cls: 1.7969  decode.loss_mask: 0.9382  decode.loss_dice: 1.8052  decode.d0.loss_cls: 3.9056  decode.d0.loss_mask: 0.9237  decode.d0.loss_dice: 2.1037  decode.d1.loss_cls: 2.0847  decode.d1.loss_mask: 0.9873  decode.d1.loss_dice: 2.0182  decode.d2.loss_cls: 2.0182  decode.d2.loss_mask: 0.9625  decode.d2.loss_dice: 1.8904  decode.d3.loss_cls: 1.8286  decode.d3.loss_mask: 0.9774  decode.d3.loss_dice: 1.8374  decode.d4.loss_cls: 1.8853  decode.d4.loss_mask: 0.9232  decode.d4.loss_dice: 1.8564  decode.d5.loss_cls: 1.8571  decode.d5.loss_mask: 0.9362  decode.d5.loss_dice: 1.7958  decode.d6.loss_cls: 1.8391  decode.d6.loss_mask: 0.9650  decode.d6.loss_dice: 1.8518  decode.d7.loss_cls: 1.9113  decode.d7.loss_mask: 0.9161  decode.d7.loss_dice: 1.7619  decode.d8.loss_cls: 1.8401  decode.d8.loss_mask: 0.9647  decode.d8.loss_dice: 1.8066
2023/05/24 02:29:28 - mmengine - INFO - Iter(train) [ 66800/160000]  lr: 6.1485e-06  eta: 11:05:45  time: 0.4192  data_time: 0.0102  memory: 4856  grad_norm: 105.9937  loss: 26.8985  decode.loss_cls: 0.7114  decode.loss_mask: 0.7010  decode.loss_dice: 1.0152  decode.d0.loss_cls: 2.6755  decode.d0.loss_mask: 0.6615  decode.d0.loss_dice: 1.1133  decode.d1.loss_cls: 0.8419  decode.d1.loss_mask: 0.6676  decode.d1.loss_dice: 1.0896  decode.d2.loss_cls: 0.8440  decode.d2.loss_mask: 0.6408  decode.d2.loss_dice: 1.0347  decode.d3.loss_cls: 0.8549  decode.d3.loss_mask: 0.6383  decode.d3.loss_dice: 1.0256  decode.d4.loss_cls: 0.7739  decode.d4.loss_mask: 0.6808  decode.d4.loss_dice: 1.0409  decode.d5.loss_cls: 0.8232  decode.d5.loss_mask: 0.6458  decode.d5.loss_dice: 1.0178  decode.d6.loss_cls: 0.7670  decode.d6.loss_mask: 0.6893  decode.d6.loss_dice: 1.0302  decode.d7.loss_cls: 0.7450  decode.d7.loss_mask: 0.6896  decode.d7.loss_dice: 1.0470  decode.d8.loss_cls: 0.7282  decode.d8.loss_mask: 0.6845  decode.d8.loss_dice: 1.0199
2023/05/24 02:29:49 - mmengine - INFO - Iter(train) [ 66850/160000]  lr: 6.1455e-06  eta: 11:05:23  time: 0.4155  data_time: 0.0106  memory: 4970  grad_norm: 113.4313  loss: 43.5308  decode.loss_cls: 1.6062  decode.loss_mask: 0.8808  decode.loss_dice: 1.6015  decode.d0.loss_cls: 3.1166  decode.d0.loss_mask: 1.0273  decode.d0.loss_dice: 1.9469  decode.d1.loss_cls: 1.6358  decode.d1.loss_mask: 0.9277  decode.d1.loss_dice: 1.8149  decode.d2.loss_cls: 1.5501  decode.d2.loss_mask: 0.9279  decode.d2.loss_dice: 1.7099  decode.d3.loss_cls: 1.5833  decode.d3.loss_mask: 0.9332  decode.d3.loss_dice: 1.6831  decode.d4.loss_cls: 1.5796  decode.d4.loss_mask: 0.9097  decode.d4.loss_dice: 1.6455  decode.d5.loss_cls: 1.5732  decode.d5.loss_mask: 0.9036  decode.d5.loss_dice: 1.6745  decode.d6.loss_cls: 1.5795  decode.d6.loss_mask: 0.8944  decode.d6.loss_dice: 1.6352  decode.d7.loss_cls: 1.6112  decode.d7.loss_mask: 0.9000  decode.d7.loss_dice: 1.6165  decode.d8.loss_cls: 1.5618  decode.d8.loss_mask: 0.8872  decode.d8.loss_dice: 1.6137
2023/05/24 02:30:09 - mmengine - INFO - Iter(train) [ 66900/160000]  lr: 6.1426e-06  eta: 11:05:00  time: 0.4074  data_time: 0.0100  memory: 4871  grad_norm: 89.8233  loss: 37.9256  decode.loss_cls: 1.3537  decode.loss_mask: 0.8307  decode.loss_dice: 1.3440  decode.d0.loss_cls: 3.1096  decode.d0.loss_mask: 0.8745  decode.d0.loss_dice: 1.6483  decode.d1.loss_cls: 1.4318  decode.d1.loss_mask: 0.8761  decode.d1.loss_dice: 1.5042  decode.d2.loss_cls: 1.3192  decode.d2.loss_mask: 0.8604  decode.d2.loss_dice: 1.4433  decode.d3.loss_cls: 1.3128  decode.d3.loss_mask: 0.9258  decode.d3.loss_dice: 1.4124  decode.d4.loss_cls: 1.3376  decode.d4.loss_mask: 0.9018  decode.d4.loss_dice: 1.3901  decode.d5.loss_cls: 1.3192  decode.d5.loss_mask: 0.8776  decode.d5.loss_dice: 1.3528  decode.d6.loss_cls: 1.3103  decode.d6.loss_mask: 0.8478  decode.d6.loss_dice: 1.3289  decode.d7.loss_cls: 1.3103  decode.d7.loss_mask: 0.8483  decode.d7.loss_dice: 1.3485  decode.d8.loss_cls: 1.2972  decode.d8.loss_mask: 0.8537  decode.d8.loss_dice: 1.3546
2023/05/24 02:30:30 - mmengine - INFO - Iter(train) [ 66950/160000]  lr: 6.1396e-06  eta: 11:04:38  time: 0.4109  data_time: 0.0102  memory: 4846  grad_norm: 101.0805  loss: 34.1029  decode.loss_cls: 1.2153  decode.loss_mask: 0.7451  decode.loss_dice: 1.1764  decode.d0.loss_cls: 3.0501  decode.d0.loss_mask: 0.7744  decode.d0.loss_dice: 1.3220  decode.d1.loss_cls: 1.3639  decode.d1.loss_mask: 0.7775  decode.d1.loss_dice: 1.2793  decode.d2.loss_cls: 1.2578  decode.d2.loss_mask: 0.7347  decode.d2.loss_dice: 1.2444  decode.d3.loss_cls: 1.2931  decode.d3.loss_mask: 0.7767  decode.d3.loss_dice: 1.2533  decode.d4.loss_cls: 1.2981  decode.d4.loss_mask: 0.7757  decode.d4.loss_dice: 1.2273  decode.d5.loss_cls: 1.2399  decode.d5.loss_mask: 0.7464  decode.d5.loss_dice: 1.1874  decode.d6.loss_cls: 1.1966  decode.d6.loss_mask: 0.7553  decode.d6.loss_dice: 1.1843  decode.d7.loss_cls: 1.1985  decode.d7.loss_mask: 0.7511  decode.d7.loss_dice: 1.1592  decode.d8.loss_cls: 1.1974  decode.d8.loss_mask: 0.7430  decode.d8.loss_dice: 1.1785
2023/05/24 02:30:51 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 02:30:51 - mmengine - INFO - Iter(train) [ 67000/160000]  lr: 6.1366e-06  eta: 11:04:16  time: 0.4153  data_time: 0.0106  memory: 4832  grad_norm: 92.1123  loss: 36.5805  decode.loss_cls: 1.3234  decode.loss_mask: 0.8192  decode.loss_dice: 1.2495  decode.d0.loss_cls: 3.2632  decode.d0.loss_mask: 0.8084  decode.d0.loss_dice: 1.5257  decode.d1.loss_cls: 1.3856  decode.d1.loss_mask: 0.9007  decode.d1.loss_dice: 1.3613  decode.d2.loss_cls: 1.3853  decode.d2.loss_mask: 0.8415  decode.d2.loss_dice: 1.3133  decode.d3.loss_cls: 1.3169  decode.d3.loss_mask: 0.8395  decode.d3.loss_dice: 1.2910  decode.d4.loss_cls: 1.3252  decode.d4.loss_mask: 0.8308  decode.d4.loss_dice: 1.3013  decode.d5.loss_cls: 1.2330  decode.d5.loss_mask: 0.8614  decode.d5.loss_dice: 1.3105  decode.d6.loss_cls: 1.2716  decode.d6.loss_mask: 0.8279  decode.d6.loss_dice: 1.2734  decode.d7.loss_cls: 1.2861  decode.d7.loss_mask: 0.8027  decode.d7.loss_dice: 1.2594  decode.d8.loss_cls: 1.2414  decode.d8.loss_mask: 0.8343  decode.d8.loss_dice: 1.2971
2023/05/24 02:30:51 - mmengine - INFO - Saving checkpoint at 67000 iterations
2023/05/24 02:31:18 - mmengine - INFO - Iter(train) [ 67050/160000]  lr: 6.1336e-06  eta: 11:04:02  time: 0.4231  data_time: 0.0109  memory: 4831  grad_norm: 119.3139  loss: 38.0351  decode.loss_cls: 1.0154  decode.loss_mask: 0.9416  decode.loss_dice: 1.4916  decode.d0.loss_cls: 3.2688  decode.d0.loss_mask: 1.0056  decode.d0.loss_dice: 1.6883  decode.d1.loss_cls: 1.1589  decode.d1.loss_mask: 0.9878  decode.d1.loss_dice: 1.6556  decode.d2.loss_cls: 1.1092  decode.d2.loss_mask: 0.9688  decode.d2.loss_dice: 1.5690  decode.d3.loss_cls: 1.0220  decode.d3.loss_mask: 1.0119  decode.d3.loss_dice: 1.5315  decode.d4.loss_cls: 1.0663  decode.d4.loss_mask: 0.9597  decode.d4.loss_dice: 1.5622  decode.d5.loss_cls: 1.0621  decode.d5.loss_mask: 0.9272  decode.d5.loss_dice: 1.5131  decode.d6.loss_cls: 1.0758  decode.d6.loss_mask: 0.9334  decode.d6.loss_dice: 1.4891  decode.d7.loss_cls: 1.0281  decode.d7.loss_mask: 0.9712  decode.d7.loss_dice: 1.5053  decode.d8.loss_cls: 1.0148  decode.d8.loss_mask: 0.9787  decode.d8.loss_dice: 1.5219
2023/05/24 02:31:39 - mmengine - INFO - Iter(train) [ 67100/160000]  lr: 6.1307e-06  eta: 11:03:41  time: 0.4249  data_time: 0.0101  memory: 4846  grad_norm: 106.3617  loss: 31.1847  decode.loss_cls: 0.9739  decode.loss_mask: 0.7715  decode.loss_dice: 1.0652  decode.d0.loss_cls: 2.9897  decode.d0.loss_mask: 0.8422  decode.d0.loss_dice: 1.2961  decode.d1.loss_cls: 1.1259  decode.d1.loss_mask: 0.7559  decode.d1.loss_dice: 1.1953  decode.d2.loss_cls: 1.1071  decode.d2.loss_mask: 0.7518  decode.d2.loss_dice: 1.1422  decode.d3.loss_cls: 1.0720  decode.d3.loss_mask: 0.7527  decode.d3.loss_dice: 1.1087  decode.d4.loss_cls: 1.0265  decode.d4.loss_mask: 0.7363  decode.d4.loss_dice: 1.1082  decode.d5.loss_cls: 1.0022  decode.d5.loss_mask: 0.7349  decode.d5.loss_dice: 1.0777  decode.d6.loss_cls: 1.0045  decode.d6.loss_mask: 0.7434  decode.d6.loss_dice: 1.0764  decode.d7.loss_cls: 0.9920  decode.d7.loss_mask: 0.7756  decode.d7.loss_dice: 1.1009  decode.d8.loss_cls: 0.9813  decode.d8.loss_mask: 0.7848  decode.d8.loss_dice: 1.0899
2023/05/24 02:32:00 - mmengine - INFO - Iter(train) [ 67150/160000]  lr: 6.1277e-06  eta: 11:03:19  time: 0.4191  data_time: 0.0103  memory: 4875  grad_norm: 103.9994  loss: 47.8162  decode.loss_cls: 1.7733  decode.loss_mask: 0.8365  decode.loss_dice: 1.8624  decode.d0.loss_cls: 3.3887  decode.d0.loss_mask: 0.9405  decode.d0.loss_dice: 2.1667  decode.d1.loss_cls: 1.9125  decode.d1.loss_mask: 0.8823  decode.d1.loss_dice: 2.0412  decode.d2.loss_cls: 1.8692  decode.d2.loss_mask: 0.8916  decode.d2.loss_dice: 1.9297  decode.d3.loss_cls: 1.8206  decode.d3.loss_mask: 0.8683  decode.d3.loss_dice: 1.9017  decode.d4.loss_cls: 1.8238  decode.d4.loss_mask: 0.8676  decode.d4.loss_dice: 1.8396  decode.d5.loss_cls: 1.8481  decode.d5.loss_mask: 0.8830  decode.d5.loss_dice: 1.9052  decode.d6.loss_cls: 1.8205  decode.d6.loss_mask: 0.8549  decode.d6.loss_dice: 1.8954  decode.d7.loss_cls: 1.7755  decode.d7.loss_mask: 0.8432  decode.d7.loss_dice: 1.8631  decode.d8.loss_cls: 1.7903  decode.d8.loss_mask: 0.8594  decode.d8.loss_dice: 1.8615
2023/05/24 02:32:22 - mmengine - INFO - Iter(train) [ 67200/160000]  lr: 6.1247e-06  eta: 11:02:57  time: 0.4279  data_time: 0.0111  memory: 4804  grad_norm: 93.0723  loss: 30.8581  decode.loss_cls: 1.1018  decode.loss_mask: 0.7245  decode.loss_dice: 0.9676  decode.d0.loss_cls: 2.7621  decode.d0.loss_mask: 0.7833  decode.d0.loss_dice: 1.1614  decode.d1.loss_cls: 1.2776  decode.d1.loss_mask: 0.7468  decode.d1.loss_dice: 1.1176  decode.d2.loss_cls: 1.1042  decode.d2.loss_mask: 0.7328  decode.d2.loss_dice: 1.0903  decode.d3.loss_cls: 1.1336  decode.d3.loss_mask: 0.7544  decode.d3.loss_dice: 1.0674  decode.d4.loss_cls: 1.1709  decode.d4.loss_mask: 0.7321  decode.d4.loss_dice: 1.0144  decode.d5.loss_cls: 1.1029  decode.d5.loss_mask: 0.7321  decode.d5.loss_dice: 1.0498  decode.d6.loss_cls: 1.1243  decode.d6.loss_mask: 0.7201  decode.d6.loss_dice: 1.0073  decode.d7.loss_cls: 1.1039  decode.d7.loss_mask: 0.7432  decode.d7.loss_dice: 0.9914  decode.d8.loss_cls: 1.1349  decode.d8.loss_mask: 0.7325  decode.d8.loss_dice: 0.9729
2023/05/24 02:32:43 - mmengine - INFO - Iter(train) [ 67250/160000]  lr: 6.1218e-06  eta: 11:02:35  time: 0.4197  data_time: 0.0101  memory: 4886  grad_norm: 95.3072  loss: 38.9499  decode.loss_cls: 1.3087  decode.loss_mask: 0.7628  decode.loss_dice: 1.5334  decode.d0.loss_cls: 3.3526  decode.d0.loss_mask: 0.8360  decode.d0.loss_dice: 1.8239  decode.d1.loss_cls: 1.4727  decode.d1.loss_mask: 0.8473  decode.d1.loss_dice: 1.6892  decode.d2.loss_cls: 1.3854  decode.d2.loss_mask: 0.8083  decode.d2.loss_dice: 1.5784  decode.d3.loss_cls: 1.3713  decode.d3.loss_mask: 0.7772  decode.d3.loss_dice: 1.5483  decode.d4.loss_cls: 1.3412  decode.d4.loss_mask: 0.7589  decode.d4.loss_dice: 1.5283  decode.d5.loss_cls: 1.2819  decode.d5.loss_mask: 0.7611  decode.d5.loss_dice: 1.5264  decode.d6.loss_cls: 1.2829  decode.d6.loss_mask: 0.7392  decode.d6.loss_dice: 1.5250  decode.d7.loss_cls: 1.2622  decode.d7.loss_mask: 0.7466  decode.d7.loss_dice: 1.4849  decode.d8.loss_cls: 1.3013  decode.d8.loss_mask: 0.7754  decode.d8.loss_dice: 1.5392
2023/05/24 02:33:06 - mmengine - INFO - Iter(train) [ 67300/160000]  lr: 6.1188e-06  eta: 11:02:16  time: 0.4731  data_time: 0.0110  memory: 4847  grad_norm: 85.9030  loss: 31.9024  decode.loss_cls: 1.1214  decode.loss_mask: 0.6794  decode.loss_dice: 1.1615  decode.d0.loss_cls: 2.8655  decode.d0.loss_mask: 0.7518  decode.d0.loss_dice: 1.3898  decode.d1.loss_cls: 1.1597  decode.d1.loss_mask: 0.7453  decode.d1.loss_dice: 1.2201  decode.d2.loss_cls: 1.1307  decode.d2.loss_mask: 0.7054  decode.d2.loss_dice: 1.2168  decode.d3.loss_cls: 1.1418  decode.d3.loss_mask: 0.6819  decode.d3.loss_dice: 1.1823  decode.d4.loss_cls: 1.0821  decode.d4.loss_mask: 0.6760  decode.d4.loss_dice: 1.1690  decode.d5.loss_cls: 1.0912  decode.d5.loss_mask: 0.6784  decode.d5.loss_dice: 1.1986  decode.d6.loss_cls: 1.1199  decode.d6.loss_mask: 0.6766  decode.d6.loss_dice: 1.1494  decode.d7.loss_cls: 1.1102  decode.d7.loss_mask: 0.6829  decode.d7.loss_dice: 1.1626  decode.d8.loss_cls: 1.0878  decode.d8.loss_mask: 0.6891  decode.d8.loss_dice: 1.1752
2023/05/24 02:33:28 - mmengine - INFO - Iter(train) [ 67350/160000]  lr: 6.1158e-06  eta: 11:01:56  time: 0.4166  data_time: 0.0109  memory: 4886  grad_norm: 92.4806  loss: 33.5143  decode.loss_cls: 1.1590  decode.loss_mask: 0.6763  decode.loss_dice: 1.1463  decode.d0.loss_cls: 2.9049  decode.d0.loss_mask: 0.7799  decode.d0.loss_dice: 1.4631  decode.d1.loss_cls: 1.3894  decode.d1.loss_mask: 0.7600  decode.d1.loss_dice: 1.3308  decode.d2.loss_cls: 1.3148  decode.d2.loss_mask: 0.7462  decode.d2.loss_dice: 1.1998  decode.d3.loss_cls: 1.2229  decode.d3.loss_mask: 0.7162  decode.d3.loss_dice: 1.2065  decode.d4.loss_cls: 1.2139  decode.d4.loss_mask: 0.7136  decode.d4.loss_dice: 1.2215  decode.d5.loss_cls: 1.1934  decode.d5.loss_mask: 0.7025  decode.d5.loss_dice: 1.2326  decode.d6.loss_cls: 1.2092  decode.d6.loss_mask: 0.6941  decode.d6.loss_dice: 1.1967  decode.d7.loss_cls: 1.1602  decode.d7.loss_mask: 0.7063  decode.d7.loss_dice: 1.2269  decode.d8.loss_cls: 1.1636  decode.d8.loss_mask: 0.6770  decode.d8.loss_dice: 1.1868
2023/05/24 02:33:51 - mmengine - INFO - Iter(train) [ 67400/160000]  lr: 6.1129e-06  eta: 11:01:36  time: 0.4721  data_time: 0.0104  memory: 4835  grad_norm: 102.7904  loss: 41.7969  decode.loss_cls: 1.4493  decode.loss_mask: 0.8732  decode.loss_dice: 1.4197  decode.d0.loss_cls: 3.4434  decode.d0.loss_mask: 0.9503  decode.d0.loss_dice: 1.7799  decode.d1.loss_cls: 1.6526  decode.d1.loss_mask: 0.9618  decode.d1.loss_dice: 1.6420  decode.d2.loss_cls: 1.5338  decode.d2.loss_mask: 0.9690  decode.d2.loss_dice: 1.5528  decode.d3.loss_cls: 1.4929  decode.d3.loss_mask: 1.0021  decode.d3.loss_dice: 1.5159  decode.d4.loss_cls: 1.5167  decode.d4.loss_mask: 0.9991  decode.d4.loss_dice: 1.5171  decode.d5.loss_cls: 1.5453  decode.d5.loss_mask: 0.9879  decode.d5.loss_dice: 1.4631  decode.d6.loss_cls: 1.4934  decode.d6.loss_mask: 0.9408  decode.d6.loss_dice: 1.4345  decode.d7.loss_cls: 1.4845  decode.d7.loss_mask: 0.9531  decode.d7.loss_dice: 1.4536  decode.d8.loss_cls: 1.4602  decode.d8.loss_mask: 0.8804  decode.d8.loss_dice: 1.4286
2023/05/24 02:34:12 - mmengine - INFO - Iter(train) [ 67450/160000]  lr: 6.1099e-06  eta: 11:01:15  time: 0.4214  data_time: 0.0106  memory: 4930  grad_norm: 116.2829  loss: 39.8778  decode.loss_cls: 1.3553  decode.loss_mask: 0.8935  decode.loss_dice: 1.5513  decode.d0.loss_cls: 3.3080  decode.d0.loss_mask: 0.8742  decode.d0.loss_dice: 1.6801  decode.d1.loss_cls: 1.3467  decode.d1.loss_mask: 0.8801  decode.d1.loss_dice: 1.6720  decode.d2.loss_cls: 1.3680  decode.d2.loss_mask: 0.8478  decode.d2.loss_dice: 1.5918  decode.d3.loss_cls: 1.3954  decode.d3.loss_mask: 0.8600  decode.d3.loss_dice: 1.5393  decode.d4.loss_cls: 1.3202  decode.d4.loss_mask: 0.8767  decode.d4.loss_dice: 1.5553  decode.d5.loss_cls: 1.3008  decode.d5.loss_mask: 0.8863  decode.d5.loss_dice: 1.5560  decode.d6.loss_cls: 1.3034  decode.d6.loss_mask: 0.8943  decode.d6.loss_dice: 1.5553  decode.d7.loss_cls: 1.2669  decode.d7.loss_mask: 0.8869  decode.d7.loss_dice: 1.5778  decode.d8.loss_cls: 1.2879  decode.d8.loss_mask: 0.8920  decode.d8.loss_dice: 1.5546
2023/05/24 02:34:34 - mmengine - INFO - Iter(train) [ 67500/160000]  lr: 6.1069e-06  eta: 11:00:53  time: 0.4241  data_time: 0.0118  memory: 4879  grad_norm: 80.8570  loss: 34.7740  decode.loss_cls: 1.1706  decode.loss_mask: 0.7899  decode.loss_dice: 1.2457  decode.d0.loss_cls: 3.2656  decode.d0.loss_mask: 0.8261  decode.d0.loss_dice: 1.4280  decode.d1.loss_cls: 1.3476  decode.d1.loss_mask: 0.7846  decode.d1.loss_dice: 1.3153  decode.d2.loss_cls: 1.3112  decode.d2.loss_mask: 0.7657  decode.d2.loss_dice: 1.2573  decode.d3.loss_cls: 1.2787  decode.d3.loss_mask: 0.7818  decode.d3.loss_dice: 1.2386  decode.d4.loss_cls: 1.2228  decode.d4.loss_mask: 0.7889  decode.d4.loss_dice: 1.2463  decode.d5.loss_cls: 1.1850  decode.d5.loss_mask: 0.7924  decode.d5.loss_dice: 1.2620  decode.d6.loss_cls: 1.1391  decode.d6.loss_mask: 0.7868  decode.d6.loss_dice: 1.2354  decode.d7.loss_cls: 1.1829  decode.d7.loss_mask: 0.7742  decode.d7.loss_dice: 1.2083  decode.d8.loss_cls: 1.1623  decode.d8.loss_mask: 0.7753  decode.d8.loss_dice: 1.2056
2023/05/24 02:34:55 - mmengine - INFO - Iter(train) [ 67550/160000]  lr: 6.1039e-06  eta: 11:00:31  time: 0.4357  data_time: 0.0105  memory: 4889  grad_norm: 96.5370  loss: 50.2309  decode.loss_cls: 1.6927  decode.loss_mask: 1.1789  decode.loss_dice: 1.8886  decode.d0.loss_cls: 3.7294  decode.d0.loss_mask: 1.1693  decode.d0.loss_dice: 2.1805  decode.d1.loss_cls: 1.8279  decode.d1.loss_mask: 1.1031  decode.d1.loss_dice: 2.0281  decode.d2.loss_cls: 1.7703  decode.d2.loss_mask: 1.1461  decode.d2.loss_dice: 1.9915  decode.d3.loss_cls: 1.7230  decode.d3.loss_mask: 1.1589  decode.d3.loss_dice: 1.8905  decode.d4.loss_cls: 1.7059  decode.d4.loss_mask: 1.1325  decode.d4.loss_dice: 1.9117  decode.d5.loss_cls: 1.7363  decode.d5.loss_mask: 1.1244  decode.d5.loss_dice: 1.9057  decode.d6.loss_cls: 1.6897  decode.d6.loss_mask: 1.1585  decode.d6.loss_dice: 1.8764  decode.d7.loss_cls: 1.6951  decode.d7.loss_mask: 1.1520  decode.d7.loss_dice: 1.8729  decode.d8.loss_cls: 1.7319  decode.d8.loss_mask: 1.1572  decode.d8.loss_dice: 1.9017
2023/05/24 02:35:16 - mmengine - INFO - Iter(train) [ 67600/160000]  lr: 6.1010e-06  eta: 11:00:09  time: 0.4073  data_time: 0.0102  memory: 4850  grad_norm: 104.8586  loss: 33.0984  decode.loss_cls: 1.2396  decode.loss_mask: 0.7070  decode.loss_dice: 1.0718  decode.d0.loss_cls: 2.9227  decode.d0.loss_mask: 0.8173  decode.d0.loss_dice: 1.2847  decode.d1.loss_cls: 1.3301  decode.d1.loss_mask: 0.7615  decode.d1.loss_dice: 1.1705  decode.d2.loss_cls: 1.3300  decode.d2.loss_mask: 0.7541  decode.d2.loss_dice: 1.1116  decode.d3.loss_cls: 1.3248  decode.d3.loss_mask: 0.7519  decode.d3.loss_dice: 1.0999  decode.d4.loss_cls: 1.2903  decode.d4.loss_mask: 0.7542  decode.d4.loss_dice: 1.1148  decode.d5.loss_cls: 1.2992  decode.d5.loss_mask: 0.7244  decode.d5.loss_dice: 1.1034  decode.d6.loss_cls: 1.2941  decode.d6.loss_mask: 0.6891  decode.d6.loss_dice: 1.0578  decode.d7.loss_cls: 1.2711  decode.d7.loss_mask: 0.7000  decode.d7.loss_dice: 1.0831  decode.d8.loss_cls: 1.2560  decode.d8.loss_mask: 0.7049  decode.d8.loss_dice: 1.0788
2023/05/24 02:35:37 - mmengine - INFO - Iter(train) [ 67650/160000]  lr: 6.0980e-06  eta: 10:59:47  time: 0.4138  data_time: 0.0103  memory: 4958  grad_norm: 96.9551  loss: 40.3162  decode.loss_cls: 1.2648  decode.loss_mask: 0.7660  decode.loss_dice: 1.6670  decode.d0.loss_cls: 3.2232  decode.d0.loss_mask: 0.8985  decode.d0.loss_dice: 1.9781  decode.d1.loss_cls: 1.3971  decode.d1.loss_mask: 0.8217  decode.d1.loss_dice: 1.8236  decode.d2.loss_cls: 1.3947  decode.d2.loss_mask: 0.8182  decode.d2.loss_dice: 1.7089  decode.d3.loss_cls: 1.4453  decode.d3.loss_mask: 0.7345  decode.d3.loss_dice: 1.6737  decode.d4.loss_cls: 1.4452  decode.d4.loss_mask: 0.7283  decode.d4.loss_dice: 1.6620  decode.d5.loss_cls: 1.3222  decode.d5.loss_mask: 0.7779  decode.d5.loss_dice: 1.6560  decode.d6.loss_cls: 1.2975  decode.d6.loss_mask: 0.7662  decode.d6.loss_dice: 1.6439  decode.d7.loss_cls: 1.3472  decode.d7.loss_mask: 0.7584  decode.d7.loss_dice: 1.6364  decode.d8.loss_cls: 1.2523  decode.d8.loss_mask: 0.7594  decode.d8.loss_dice: 1.6478
2023/05/24 02:35:57 - mmengine - INFO - Iter(train) [ 67700/160000]  lr: 6.0950e-06  eta: 10:59:24  time: 0.4129  data_time: 0.0103  memory: 4846  grad_norm: 90.3538  loss: 38.0038  decode.loss_cls: 1.3745  decode.loss_mask: 0.8333  decode.loss_dice: 1.3843  decode.d0.loss_cls: 3.0151  decode.d0.loss_mask: 0.8708  decode.d0.loss_dice: 1.6029  decode.d1.loss_cls: 1.4591  decode.d1.loss_mask: 0.8790  decode.d1.loss_dice: 1.5659  decode.d2.loss_cls: 1.4159  decode.d2.loss_mask: 0.8036  decode.d2.loss_dice: 1.4257  decode.d3.loss_cls: 1.3815  decode.d3.loss_mask: 0.8158  decode.d3.loss_dice: 1.4162  decode.d4.loss_cls: 1.3502  decode.d4.loss_mask: 0.8070  decode.d4.loss_dice: 1.3999  decode.d5.loss_cls: 1.3435  decode.d5.loss_mask: 0.8057  decode.d5.loss_dice: 1.4084  decode.d6.loss_cls: 1.3379  decode.d6.loss_mask: 0.7979  decode.d6.loss_dice: 1.3859  decode.d7.loss_cls: 1.3782  decode.d7.loss_mask: 0.8004  decode.d7.loss_dice: 1.3864  decode.d8.loss_cls: 1.3764  decode.d8.loss_mask: 0.8020  decode.d8.loss_dice: 1.3806
2023/05/24 02:36:19 - mmengine - INFO - Iter(train) [ 67750/160000]  lr: 6.0921e-06  eta: 10:59:03  time: 0.4184  data_time: 0.0102  memory: 4866  grad_norm: 108.5813  loss: 42.7328  decode.loss_cls: 1.6767  decode.loss_mask: 0.7986  decode.loss_dice: 1.4740  decode.d0.loss_cls: 3.7172  decode.d0.loss_mask: 0.9140  decode.d0.loss_dice: 1.7920  decode.d1.loss_cls: 1.8584  decode.d1.loss_mask: 0.8722  decode.d1.loss_dice: 1.6436  decode.d2.loss_cls: 1.7066  decode.d2.loss_mask: 0.8437  decode.d2.loss_dice: 1.5442  decode.d3.loss_cls: 1.6561  decode.d3.loss_mask: 0.8428  decode.d3.loss_dice: 1.4921  decode.d4.loss_cls: 1.7031  decode.d4.loss_mask: 0.8297  decode.d4.loss_dice: 1.5328  decode.d5.loss_cls: 1.7229  decode.d5.loss_mask: 0.7900  decode.d5.loss_dice: 1.4785  decode.d6.loss_cls: 1.7460  decode.d6.loss_mask: 0.7809  decode.d6.loss_dice: 1.4780  decode.d7.loss_cls: 1.6606  decode.d7.loss_mask: 0.7967  decode.d7.loss_dice: 1.4731  decode.d8.loss_cls: 1.6458  decode.d8.loss_mask: 0.7950  decode.d8.loss_dice: 1.4675
2023/05/24 02:36:42 - mmengine - INFO - Iter(train) [ 67800/160000]  lr: 6.0891e-06  eta: 10:58:44  time: 0.4703  data_time: 0.0096  memory: 4822  grad_norm: 80.6576  loss: 38.7518  decode.loss_cls: 1.1208  decode.loss_mask: 0.8731  decode.loss_dice: 1.5665  decode.d0.loss_cls: 3.0509  decode.d0.loss_mask: 0.8990  decode.d0.loss_dice: 1.6745  decode.d1.loss_cls: 1.4827  decode.d1.loss_mask: 0.8868  decode.d1.loss_dice: 1.5909  decode.d2.loss_cls: 1.3513  decode.d2.loss_mask: 0.8853  decode.d2.loss_dice: 1.5543  decode.d3.loss_cls: 1.2333  decode.d3.loss_mask: 0.8764  decode.d3.loss_dice: 1.5484  decode.d4.loss_cls: 1.2284  decode.d4.loss_mask: 0.8765  decode.d4.loss_dice: 1.5401  decode.d5.loss_cls: 1.2366  decode.d5.loss_mask: 0.8694  decode.d5.loss_dice: 1.5816  decode.d6.loss_cls: 1.2316  decode.d6.loss_mask: 0.8715  decode.d6.loss_dice: 1.5120  decode.d7.loss_cls: 1.2430  decode.d7.loss_mask: 0.8892  decode.d7.loss_dice: 1.5391  decode.d8.loss_cls: 1.1482  decode.d8.loss_mask: 0.8710  decode.d8.loss_dice: 1.5194
2023/05/24 02:37:04 - mmengine - INFO - Iter(train) [ 67850/160000]  lr: 6.0861e-06  eta: 10:58:23  time: 0.4162  data_time: 0.0102  memory: 4870  grad_norm: 101.1014  loss: 37.0195  decode.loss_cls: 1.1028  decode.loss_mask: 0.8443  decode.loss_dice: 1.3738  decode.d0.loss_cls: 3.2144  decode.d0.loss_mask: 0.8503  decode.d0.loss_dice: 1.7046  decode.d1.loss_cls: 1.3224  decode.d1.loss_mask: 0.9088  decode.d1.loss_dice: 1.6425  decode.d2.loss_cls: 1.2282  decode.d2.loss_mask: 0.9336  decode.d2.loss_dice: 1.5296  decode.d3.loss_cls: 1.1419  decode.d3.loss_mask: 0.8616  decode.d3.loss_dice: 1.4371  decode.d4.loss_cls: 1.1550  decode.d4.loss_mask: 0.8515  decode.d4.loss_dice: 1.4464  decode.d5.loss_cls: 1.0900  decode.d5.loss_mask: 0.8912  decode.d5.loss_dice: 1.4588  decode.d6.loss_cls: 1.0936  decode.d6.loss_mask: 0.8716  decode.d6.loss_dice: 1.3788  decode.d7.loss_cls: 1.0805  decode.d7.loss_mask: 0.8568  decode.d7.loss_dice: 1.4233  decode.d8.loss_cls: 1.0937  decode.d8.loss_mask: 0.8418  decode.d8.loss_dice: 1.3904
2023/05/24 02:37:27 - mmengine - INFO - Iter(train) [ 67900/160000]  lr: 6.0831e-06  eta: 10:58:04  time: 0.4718  data_time: 0.0100  memory: 4875  grad_norm: 92.3318  loss: 40.4875  decode.loss_cls: 1.4300  decode.loss_mask: 0.8182  decode.loss_dice: 1.4418  decode.d0.loss_cls: 2.9899  decode.d0.loss_mask: 0.9497  decode.d0.loss_dice: 1.8469  decode.d1.loss_cls: 1.5693  decode.d1.loss_mask: 0.9506  decode.d1.loss_dice: 1.7099  decode.d2.loss_cls: 1.4879  decode.d2.loss_mask: 0.9341  decode.d2.loss_dice: 1.6004  decode.d3.loss_cls: 1.4746  decode.d3.loss_mask: 0.8654  decode.d3.loss_dice: 1.5318  decode.d4.loss_cls: 1.4679  decode.d4.loss_mask: 0.8372  decode.d4.loss_dice: 1.4995  decode.d5.loss_cls: 1.4598  decode.d5.loss_mask: 0.8568  decode.d5.loss_dice: 1.5155  decode.d6.loss_cls: 1.4316  decode.d6.loss_mask: 0.8235  decode.d6.loss_dice: 1.4854  decode.d7.loss_cls: 1.4361  decode.d7.loss_mask: 0.8119  decode.d7.loss_dice: 1.4628  decode.d8.loss_cls: 1.4418  decode.d8.loss_mask: 0.8282  decode.d8.loss_dice: 1.5291
2023/05/24 02:37:50 - mmengine - INFO - Iter(train) [ 67950/160000]  lr: 6.0802e-06  eta: 10:57:44  time: 0.4737  data_time: 0.0100  memory: 4835  grad_norm: 89.9535  loss: 38.8474  decode.loss_cls: 1.3764  decode.loss_mask: 0.7252  decode.loss_dice: 1.4851  decode.d0.loss_cls: 3.7263  decode.d0.loss_mask: 0.6887  decode.d0.loss_dice: 1.7142  decode.d1.loss_cls: 1.5916  decode.d1.loss_mask: 0.7156  decode.d1.loss_dice: 1.6040  decode.d2.loss_cls: 1.4839  decode.d2.loss_mask: 0.6560  decode.d2.loss_dice: 1.5338  decode.d3.loss_cls: 1.5374  decode.d3.loss_mask: 0.6597  decode.d3.loss_dice: 1.4979  decode.d4.loss_cls: 1.5003  decode.d4.loss_mask: 0.6566  decode.d4.loss_dice: 1.4614  decode.d5.loss_cls: 1.4263  decode.d5.loss_mask: 0.6569  decode.d5.loss_dice: 1.5047  decode.d6.loss_cls: 1.4260  decode.d6.loss_mask: 0.6431  decode.d6.loss_dice: 1.4845  decode.d7.loss_cls: 1.4417  decode.d7.loss_mask: 0.6625  decode.d7.loss_dice: 1.4913  decode.d8.loss_cls: 1.3802  decode.d8.loss_mask: 0.6923  decode.d8.loss_dice: 1.4240
2023/05/24 02:38:13 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 02:38:13 - mmengine - INFO - Iter(train) [ 68000/160000]  lr: 6.0772e-06  eta: 10:57:26  time: 0.4697  data_time: 0.0099  memory: 4787  grad_norm: 100.0056  loss: 27.1848  decode.loss_cls: 0.9153  decode.loss_mask: 0.5676  decode.loss_dice: 0.9491  decode.d0.loss_cls: 2.7213  decode.d0.loss_mask: 0.6481  decode.d0.loss_dice: 1.1168  decode.d1.loss_cls: 0.8972  decode.d1.loss_mask: 0.6278  decode.d1.loss_dice: 1.0721  decode.d2.loss_cls: 0.9460  decode.d2.loss_mask: 0.6054  decode.d2.loss_dice: 1.0332  decode.d3.loss_cls: 0.9615  decode.d3.loss_mask: 0.5852  decode.d3.loss_dice: 0.9995  decode.d4.loss_cls: 0.9889  decode.d4.loss_mask: 0.5601  decode.d4.loss_dice: 0.9765  decode.d5.loss_cls: 0.9483  decode.d5.loss_mask: 0.5949  decode.d5.loss_dice: 0.9964  decode.d6.loss_cls: 0.9244  decode.d6.loss_mask: 0.5911  decode.d6.loss_dice: 0.9871  decode.d7.loss_cls: 0.9313  decode.d7.loss_mask: 0.5709  decode.d7.loss_dice: 0.9815  decode.d8.loss_cls: 0.9216  decode.d8.loss_mask: 0.5863  decode.d8.loss_dice: 0.9792
2023/05/24 02:38:13 - mmengine - INFO - Saving checkpoint at 68000 iterations
2023/05/24 02:38:41 - mmengine - INFO - Iter(train) [ 68050/160000]  lr: 6.0742e-06  eta: 10:57:13  time: 0.4109  data_time: 0.0102  memory: 4889  grad_norm: 93.8874  loss: 37.2577  decode.loss_cls: 1.3510  decode.loss_mask: 0.7691  decode.loss_dice: 1.3207  decode.d0.loss_cls: 3.2354  decode.d0.loss_mask: 0.7788  decode.d0.loss_dice: 1.5269  decode.d1.loss_cls: 1.5108  decode.d1.loss_mask: 0.7934  decode.d1.loss_dice: 1.4020  decode.d2.loss_cls: 1.4117  decode.d2.loss_mask: 0.7863  decode.d2.loss_dice: 1.3636  decode.d3.loss_cls: 1.3729  decode.d3.loss_mask: 0.7601  decode.d3.loss_dice: 1.3256  decode.d4.loss_cls: 1.4059  decode.d4.loss_mask: 0.7538  decode.d4.loss_dice: 1.3485  decode.d5.loss_cls: 1.3674  decode.d5.loss_mask: 0.7606  decode.d5.loss_dice: 1.3450  decode.d6.loss_cls: 1.4309  decode.d6.loss_mask: 0.7643  decode.d6.loss_dice: 1.3496  decode.d7.loss_cls: 1.4177  decode.d7.loss_mask: 0.7747  decode.d7.loss_dice: 1.3269  decode.d8.loss_cls: 1.3595  decode.d8.loss_mask: 0.7908  decode.d8.loss_dice: 1.3536
2023/05/24 02:39:04 - mmengine - INFO - Iter(train) [ 68100/160000]  lr: 6.0713e-06  eta: 10:56:53  time: 0.4706  data_time: 0.0103  memory: 4807  grad_norm: 126.5617  loss: 37.1849  decode.loss_cls: 1.2471  decode.loss_mask: 0.8007  decode.loss_dice: 1.3440  decode.d0.loss_cls: 3.3609  decode.d0.loss_mask: 0.8365  decode.d0.loss_dice: 1.6109  decode.d1.loss_cls: 1.3895  decode.d1.loss_mask: 0.8440  decode.d1.loss_dice: 1.4942  decode.d2.loss_cls: 1.2899  decode.d2.loss_mask: 0.8184  decode.d2.loss_dice: 1.4638  decode.d3.loss_cls: 1.3340  decode.d3.loss_mask: 0.7895  decode.d3.loss_dice: 1.3975  decode.d4.loss_cls: 1.2362  decode.d4.loss_mask: 0.7994  decode.d4.loss_dice: 1.4047  decode.d5.loss_cls: 1.2645  decode.d5.loss_mask: 0.7979  decode.d5.loss_dice: 1.3550  decode.d6.loss_cls: 1.2661  decode.d6.loss_mask: 0.7929  decode.d6.loss_dice: 1.3910  decode.d7.loss_cls: 1.2517  decode.d7.loss_mask: 0.8010  decode.d7.loss_dice: 1.3883  decode.d8.loss_cls: 1.2380  decode.d8.loss_mask: 0.8115  decode.d8.loss_dice: 1.3658
2023/05/24 02:39:25 - mmengine - INFO - Iter(train) [ 68150/160000]  lr: 6.0683e-06  eta: 10:56:31  time: 0.4229  data_time: 0.0102  memory: 4815  grad_norm: 124.7606  loss: 44.4847  decode.loss_cls: 1.5562  decode.loss_mask: 0.9819  decode.loss_dice: 1.6102  decode.d0.loss_cls: 3.5029  decode.d0.loss_mask: 1.0402  decode.d0.loss_dice: 1.8968  decode.d1.loss_cls: 1.7285  decode.d1.loss_mask: 1.0097  decode.d1.loss_dice: 1.7636  decode.d2.loss_cls: 1.5431  decode.d2.loss_mask: 1.0578  decode.d2.loss_dice: 1.7027  decode.d3.loss_cls: 1.5915  decode.d3.loss_mask: 1.0048  decode.d3.loss_dice: 1.6438  decode.d4.loss_cls: 1.5378  decode.d4.loss_mask: 1.0240  decode.d4.loss_dice: 1.6529  decode.d5.loss_cls: 1.4810  decode.d5.loss_mask: 0.9897  decode.d5.loss_dice: 1.6595  decode.d6.loss_cls: 1.5818  decode.d6.loss_mask: 0.9783  decode.d6.loss_dice: 1.6339  decode.d7.loss_cls: 1.5381  decode.d7.loss_mask: 0.9803  decode.d7.loss_dice: 1.6451  decode.d8.loss_cls: 1.5320  decode.d8.loss_mask: 0.9774  decode.d8.loss_dice: 1.6390
2023/05/24 02:39:47 - mmengine - INFO - Iter(train) [ 68200/160000]  lr: 6.0653e-06  eta: 10:56:11  time: 0.4208  data_time: 0.0106  memory: 4877  grad_norm: 102.7350  loss: 37.6117  decode.loss_cls: 1.2361  decode.loss_mask: 0.7568  decode.loss_dice: 1.5384  decode.d0.loss_cls: 2.9533  decode.d0.loss_mask: 0.8899  decode.d0.loss_dice: 1.7671  decode.d1.loss_cls: 1.3350  decode.d1.loss_mask: 0.8451  decode.d1.loss_dice: 1.6693  decode.d2.loss_cls: 1.2935  decode.d2.loss_mask: 0.8173  decode.d2.loss_dice: 1.5962  decode.d3.loss_cls: 1.2625  decode.d3.loss_mask: 0.7563  decode.d3.loss_dice: 1.5049  decode.d4.loss_cls: 1.2406  decode.d4.loss_mask: 0.7398  decode.d4.loss_dice: 1.5152  decode.d5.loss_cls: 1.2134  decode.d5.loss_mask: 0.7549  decode.d5.loss_dice: 1.5012  decode.d6.loss_cls: 1.1392  decode.d6.loss_mask: 0.7699  decode.d6.loss_dice: 1.5688  decode.d7.loss_cls: 1.1350  decode.d7.loss_mask: 0.7807  decode.d7.loss_dice: 1.5719  decode.d8.loss_cls: 1.1375  decode.d8.loss_mask: 0.7802  decode.d8.loss_dice: 1.5416
2023/05/24 02:40:09 - mmengine - INFO - Iter(train) [ 68250/160000]  lr: 6.0623e-06  eta: 10:55:49  time: 0.4300  data_time: 0.0104  memory: 4876  grad_norm: 110.9614  loss: 34.6012  decode.loss_cls: 1.0989  decode.loss_mask: 0.7062  decode.loss_dice: 1.3876  decode.d0.loss_cls: 3.0194  decode.d0.loss_mask: 0.7554  decode.d0.loss_dice: 1.6870  decode.d1.loss_cls: 1.1632  decode.d1.loss_mask: 0.7301  decode.d1.loss_dice: 1.5103  decode.d2.loss_cls: 1.1433  decode.d2.loss_mask: 0.7271  decode.d2.loss_dice: 1.4630  decode.d3.loss_cls: 1.1269  decode.d3.loss_mask: 0.7112  decode.d3.loss_dice: 1.3894  decode.d4.loss_cls: 1.1066  decode.d4.loss_mask: 0.7086  decode.d4.loss_dice: 1.3983  decode.d5.loss_cls: 1.0932  decode.d5.loss_mask: 0.7168  decode.d5.loss_dice: 1.3780  decode.d6.loss_cls: 1.1229  decode.d6.loss_mask: 0.7069  decode.d6.loss_dice: 1.3318  decode.d7.loss_cls: 1.0728  decode.d7.loss_mask: 0.7218  decode.d7.loss_dice: 1.4454  decode.d8.loss_cls: 1.0998  decode.d8.loss_mask: 0.7166  decode.d8.loss_dice: 1.3628
2023/05/24 02:40:30 - mmengine - INFO - Iter(train) [ 68300/160000]  lr: 6.0594e-06  eta: 10:55:27  time: 0.4437  data_time: 0.0103  memory: 4866  grad_norm: 149.1702  loss: 32.7377  decode.loss_cls: 1.0787  decode.loss_mask: 0.6013  decode.loss_dice: 1.2895  decode.d0.loss_cls: 3.0737  decode.d0.loss_mask: 0.6384  decode.d0.loss_dice: 1.5160  decode.d1.loss_cls: 1.2453  decode.d1.loss_mask: 0.6385  decode.d1.loss_dice: 1.4488  decode.d2.loss_cls: 1.0624  decode.d2.loss_mask: 0.6237  decode.d2.loss_dice: 1.4047  decode.d3.loss_cls: 1.0557  decode.d3.loss_mask: 0.6296  decode.d3.loss_dice: 1.3679  decode.d4.loss_cls: 1.0587  decode.d4.loss_mask: 0.6643  decode.d4.loss_dice: 1.3794  decode.d5.loss_cls: 1.1274  decode.d5.loss_mask: 0.6015  decode.d5.loss_dice: 1.3529  decode.d6.loss_cls: 1.0321  decode.d6.loss_mask: 0.6130  decode.d6.loss_dice: 1.3422  decode.d7.loss_cls: 0.9768  decode.d7.loss_mask: 0.6135  decode.d7.loss_dice: 1.3363  decode.d8.loss_cls: 1.0227  decode.d8.loss_mask: 0.6120  decode.d8.loss_dice: 1.3311
2023/05/24 02:40:51 - mmengine - INFO - Iter(train) [ 68350/160000]  lr: 6.0564e-06  eta: 10:55:05  time: 0.4172  data_time: 0.0104  memory: 4839  grad_norm: 102.8481  loss: 30.0754  decode.loss_cls: 1.0496  decode.loss_mask: 0.6365  decode.loss_dice: 1.0530  decode.d0.loss_cls: 2.9804  decode.d0.loss_mask: 0.6751  decode.d0.loss_dice: 1.2675  decode.d1.loss_cls: 1.1842  decode.d1.loss_mask: 0.6568  decode.d1.loss_dice: 1.1781  decode.d2.loss_cls: 1.0845  decode.d2.loss_mask: 0.6382  decode.d2.loss_dice: 1.1100  decode.d3.loss_cls: 1.0665  decode.d3.loss_mask: 0.6337  decode.d3.loss_dice: 1.0965  decode.d4.loss_cls: 1.0648  decode.d4.loss_mask: 0.6494  decode.d4.loss_dice: 1.1015  decode.d5.loss_cls: 1.0014  decode.d5.loss_mask: 0.6450  decode.d5.loss_dice: 1.0873  decode.d6.loss_cls: 1.0135  decode.d6.loss_mask: 0.6386  decode.d6.loss_dice: 1.0606  decode.d7.loss_cls: 1.0401  decode.d7.loss_mask: 0.6194  decode.d7.loss_dice: 1.0507  decode.d8.loss_cls: 1.0512  decode.d8.loss_mask: 0.6412  decode.d8.loss_dice: 1.1003
2023/05/24 02:41:12 - mmengine - INFO - Iter(train) [ 68400/160000]  lr: 6.0534e-06  eta: 10:54:43  time: 0.4260  data_time: 0.0102  memory: 4886  grad_norm: 100.0800  loss: 35.2586  decode.loss_cls: 1.0845  decode.loss_mask: 0.9427  decode.loss_dice: 1.2041  decode.d0.loss_cls: 2.8951  decode.d0.loss_mask: 0.9858  decode.d0.loss_dice: 1.3836  decode.d1.loss_cls: 1.1955  decode.d1.loss_mask: 1.0272  decode.d1.loss_dice: 1.3305  decode.d2.loss_cls: 1.1761  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 1.2528  decode.d3.loss_cls: 1.1609  decode.d3.loss_mask: 0.9366  decode.d3.loss_dice: 1.2051  decode.d4.loss_cls: 1.1740  decode.d4.loss_mask: 0.9395  decode.d4.loss_dice: 1.2683  decode.d5.loss_cls: 1.1098  decode.d5.loss_mask: 0.9450  decode.d5.loss_dice: 1.2359  decode.d6.loss_cls: 1.1475  decode.d6.loss_mask: 0.9490  decode.d6.loss_dice: 1.1998  decode.d7.loss_cls: 1.1110  decode.d7.loss_mask: 0.9543  decode.d7.loss_dice: 1.2026  decode.d8.loss_cls: 1.0999  decode.d8.loss_mask: 0.9694  decode.d8.loss_dice: 1.2013
2023/05/24 02:41:33 - mmengine - INFO - Iter(train) [ 68450/160000]  lr: 6.0504e-06  eta: 10:54:22  time: 0.4334  data_time: 0.0102  memory: 4866  grad_norm: 122.5253  loss: 36.6421  decode.loss_cls: 1.1978  decode.loss_mask: 0.8796  decode.loss_dice: 1.2393  decode.d0.loss_cls: 3.3037  decode.d0.loss_mask: 0.9516  decode.d0.loss_dice: 1.4991  decode.d1.loss_cls: 1.2462  decode.d1.loss_mask: 0.9992  decode.d1.loss_dice: 1.3663  decode.d2.loss_cls: 1.1650  decode.d2.loss_mask: 0.9701  decode.d2.loss_dice: 1.3656  decode.d3.loss_cls: 1.1909  decode.d3.loss_mask: 0.9416  decode.d3.loss_dice: 1.3277  decode.d4.loss_cls: 1.2457  decode.d4.loss_mask: 0.8928  decode.d4.loss_dice: 1.2916  decode.d5.loss_cls: 1.2207  decode.d5.loss_mask: 0.8849  decode.d5.loss_dice: 1.3001  decode.d6.loss_cls: 1.2351  decode.d6.loss_mask: 0.8762  decode.d6.loss_dice: 1.2674  decode.d7.loss_cls: 1.2146  decode.d7.loss_mask: 0.9299  decode.d7.loss_dice: 1.2970  decode.d8.loss_cls: 1.1596  decode.d8.loss_mask: 0.8946  decode.d8.loss_dice: 1.2882
2023/05/24 02:41:54 - mmengine - INFO - Iter(train) [ 68500/160000]  lr: 6.0475e-06  eta: 10:54:00  time: 0.4217  data_time: 0.0102  memory: 4943  grad_norm: 106.3168  loss: 39.5777  decode.loss_cls: 1.3087  decode.loss_mask: 0.7370  decode.loss_dice: 1.6080  decode.d0.loss_cls: 3.3619  decode.d0.loss_mask: 0.7893  decode.d0.loss_dice: 1.9187  decode.d1.loss_cls: 1.4319  decode.d1.loss_mask: 0.7999  decode.d1.loss_dice: 1.7719  decode.d2.loss_cls: 1.4296  decode.d2.loss_mask: 0.7507  decode.d2.loss_dice: 1.6881  decode.d3.loss_cls: 1.3678  decode.d3.loss_mask: 0.7389  decode.d3.loss_dice: 1.5988  decode.d4.loss_cls: 1.3498  decode.d4.loss_mask: 0.7554  decode.d4.loss_dice: 1.6086  decode.d5.loss_cls: 1.3126  decode.d5.loss_mask: 0.7448  decode.d5.loss_dice: 1.5933  decode.d6.loss_cls: 1.3167  decode.d6.loss_mask: 0.7228  decode.d6.loss_dice: 1.5737  decode.d7.loss_cls: 1.3044  decode.d7.loss_mask: 0.7302  decode.d7.loss_dice: 1.6200  decode.d8.loss_cls: 1.2870  decode.d8.loss_mask: 0.7382  decode.d8.loss_dice: 1.6188
2023/05/24 02:42:15 - mmengine - INFO - Iter(train) [ 68550/160000]  lr: 6.0445e-06  eta: 10:53:38  time: 0.4180  data_time: 0.0101  memory: 4857  grad_norm: 99.2311  loss: 39.5708  decode.loss_cls: 1.3376  decode.loss_mask: 0.8564  decode.loss_dice: 1.4761  decode.d0.loss_cls: 3.2886  decode.d0.loss_mask: 0.9311  decode.d0.loss_dice: 1.7037  decode.d1.loss_cls: 1.4467  decode.d1.loss_mask: 0.8827  decode.d1.loss_dice: 1.6093  decode.d2.loss_cls: 1.3709  decode.d2.loss_mask: 0.8752  decode.d2.loss_dice: 1.5679  decode.d3.loss_cls: 1.3752  decode.d3.loss_mask: 0.8615  decode.d3.loss_dice: 1.5004  decode.d4.loss_cls: 1.3827  decode.d4.loss_mask: 0.8776  decode.d4.loss_dice: 1.5383  decode.d5.loss_cls: 1.3208  decode.d5.loss_mask: 0.8653  decode.d5.loss_dice: 1.4986  decode.d6.loss_cls: 1.2689  decode.d6.loss_mask: 0.8756  decode.d6.loss_dice: 1.4904  decode.d7.loss_cls: 1.3791  decode.d7.loss_mask: 0.8550  decode.d7.loss_dice: 1.4830  decode.d8.loss_cls: 1.2912  decode.d8.loss_mask: 0.8619  decode.d8.loss_dice: 1.4991
2023/05/24 02:42:37 - mmengine - INFO - Iter(train) [ 68600/160000]  lr: 6.0415e-06  eta: 10:53:16  time: 0.4230  data_time: 0.0105  memory: 4866  grad_norm: 100.8836  loss: 42.4041  decode.loss_cls: 1.5347  decode.loss_mask: 0.9072  decode.loss_dice: 1.4587  decode.d0.loss_cls: 3.5073  decode.d0.loss_mask: 1.0664  decode.d0.loss_dice: 1.6748  decode.d1.loss_cls: 1.6118  decode.d1.loss_mask: 1.0514  decode.d1.loss_dice: 1.5835  decode.d2.loss_cls: 1.5722  decode.d2.loss_mask: 0.9711  decode.d2.loss_dice: 1.5071  decode.d3.loss_cls: 1.6346  decode.d3.loss_mask: 0.9629  decode.d3.loss_dice: 1.4924  decode.d4.loss_cls: 1.5083  decode.d4.loss_mask: 0.9803  decode.d4.loss_dice: 1.4789  decode.d5.loss_cls: 1.5448  decode.d5.loss_mask: 0.9702  decode.d5.loss_dice: 1.4787  decode.d6.loss_cls: 1.5461  decode.d6.loss_mask: 1.0060  decode.d6.loss_dice: 1.4483  decode.d7.loss_cls: 1.4999  decode.d7.loss_mask: 1.0214  decode.d7.loss_dice: 1.4525  decode.d8.loss_cls: 1.5305  decode.d8.loss_mask: 0.9506  decode.d8.loss_dice: 1.4514
2023/05/24 02:42:58 - mmengine - INFO - Iter(train) [ 68650/160000]  lr: 6.0385e-06  eta: 10:52:55  time: 0.4208  data_time: 0.0101  memory: 4869  grad_norm: 96.2372  loss: 38.1272  decode.loss_cls: 1.3302  decode.loss_mask: 0.7617  decode.loss_dice: 1.3033  decode.d0.loss_cls: 3.5369  decode.d0.loss_mask: 0.8690  decode.d0.loss_dice: 1.5695  decode.d1.loss_cls: 1.5391  decode.d1.loss_mask: 0.8504  decode.d1.loss_dice: 1.5081  decode.d2.loss_cls: 1.4270  decode.d2.loss_mask: 0.8604  decode.d2.loss_dice: 1.4586  decode.d3.loss_cls: 1.4035  decode.d3.loss_mask: 0.8124  decode.d3.loss_dice: 1.3899  decode.d4.loss_cls: 1.3361  decode.d4.loss_mask: 0.8283  decode.d4.loss_dice: 1.4134  decode.d5.loss_cls: 1.3349  decode.d5.loss_mask: 0.8080  decode.d5.loss_dice: 1.3962  decode.d6.loss_cls: 1.3375  decode.d6.loss_mask: 0.7893  decode.d6.loss_dice: 1.3482  decode.d7.loss_cls: 1.3692  decode.d7.loss_mask: 0.7737  decode.d7.loss_dice: 1.3546  decode.d8.loss_cls: 1.3282  decode.d8.loss_mask: 0.7696  decode.d8.loss_dice: 1.3198
2023/05/24 02:43:19 - mmengine - INFO - Iter(train) [ 68700/160000]  lr: 6.0356e-06  eta: 10:52:32  time: 0.4125  data_time: 0.0102  memory: 4910  grad_norm: 98.4645  loss: 50.4854  decode.loss_cls: 1.7109  decode.loss_mask: 1.0319  decode.loss_dice: 1.9875  decode.d0.loss_cls: 3.7566  decode.d0.loss_mask: 1.0536  decode.d0.loss_dice: 2.2680  decode.d1.loss_cls: 1.8739  decode.d1.loss_mask: 1.1114  decode.d1.loss_dice: 2.1580  decode.d2.loss_cls: 1.8036  decode.d2.loss_mask: 1.0223  decode.d2.loss_dice: 2.0718  decode.d3.loss_cls: 1.8196  decode.d3.loss_mask: 1.0412  decode.d3.loss_dice: 2.0215  decode.d4.loss_cls: 1.7584  decode.d4.loss_mask: 1.0297  decode.d4.loss_dice: 2.0440  decode.d5.loss_cls: 1.7452  decode.d5.loss_mask: 1.0228  decode.d5.loss_dice: 1.9999  decode.d6.loss_cls: 1.7099  decode.d6.loss_mask: 1.0130  decode.d6.loss_dice: 1.9993  decode.d7.loss_cls: 1.7083  decode.d7.loss_mask: 1.0126  decode.d7.loss_dice: 2.0262  decode.d8.loss_cls: 1.7003  decode.d8.loss_mask: 1.0015  decode.d8.loss_dice: 1.9826
2023/05/24 02:43:39 - mmengine - INFO - Iter(train) [ 68750/160000]  lr: 6.0326e-06  eta: 10:52:10  time: 0.4173  data_time: 0.0103  memory: 4896  grad_norm: 85.8855  loss: 39.5173  decode.loss_cls: 1.5050  decode.loss_mask: 0.7450  decode.loss_dice: 1.3688  decode.d0.loss_cls: 3.4868  decode.d0.loss_mask: 0.9245  decode.d0.loss_dice: 1.7341  decode.d1.loss_cls: 1.6617  decode.d1.loss_mask: 0.8740  decode.d1.loss_dice: 1.5007  decode.d2.loss_cls: 1.4880  decode.d2.loss_mask: 0.8632  decode.d2.loss_dice: 1.4901  decode.d3.loss_cls: 1.4777  decode.d3.loss_mask: 0.7508  decode.d3.loss_dice: 1.4037  decode.d4.loss_cls: 1.4686  decode.d4.loss_mask: 0.8538  decode.d4.loss_dice: 1.4158  decode.d5.loss_cls: 1.4737  decode.d5.loss_mask: 0.7564  decode.d5.loss_dice: 1.4056  decode.d6.loss_cls: 1.3921  decode.d6.loss_mask: 0.8205  decode.d6.loss_dice: 1.4099  decode.d7.loss_cls: 1.4724  decode.d7.loss_mask: 0.7575  decode.d7.loss_dice: 1.3798  decode.d8.loss_cls: 1.4800  decode.d8.loss_mask: 0.7708  decode.d8.loss_dice: 1.3862
2023/05/24 02:44:00 - mmengine - INFO - Iter(train) [ 68800/160000]  lr: 6.0296e-06  eta: 10:51:48  time: 0.4162  data_time: 0.0102  memory: 4857  grad_norm: 106.9118  loss: 32.2827  decode.loss_cls: 1.1197  decode.loss_mask: 0.8975  decode.loss_dice: 0.9971  decode.d0.loss_cls: 2.8420  decode.d0.loss_mask: 0.9263  decode.d0.loss_dice: 1.1179  decode.d1.loss_cls: 1.1990  decode.d1.loss_mask: 0.9035  decode.d1.loss_dice: 1.0723  decode.d2.loss_cls: 1.1460  decode.d2.loss_mask: 0.8755  decode.d2.loss_dice: 1.0450  decode.d3.loss_cls: 1.1632  decode.d3.loss_mask: 0.8818  decode.d3.loss_dice: 1.0272  decode.d4.loss_cls: 1.1352  decode.d4.loss_mask: 0.8817  decode.d4.loss_dice: 1.0310  decode.d5.loss_cls: 1.1347  decode.d5.loss_mask: 0.8785  decode.d5.loss_dice: 1.0209  decode.d6.loss_cls: 1.1120  decode.d6.loss_mask: 0.8747  decode.d6.loss_dice: 0.9999  decode.d7.loss_cls: 1.1282  decode.d7.loss_mask: 0.8854  decode.d7.loss_dice: 1.0085  decode.d8.loss_cls: 1.1068  decode.d8.loss_mask: 0.8871  decode.d8.loss_dice: 0.9839
2023/05/24 02:44:21 - mmengine - INFO - Iter(train) [ 68850/160000]  lr: 6.0266e-06  eta: 10:51:26  time: 0.4261  data_time: 0.0102  memory: 4844  grad_norm: 89.5878  loss: 26.9188  decode.loss_cls: 0.9187  decode.loss_mask: 0.5670  decode.loss_dice: 0.9651  decode.d0.loss_cls: 2.7388  decode.d0.loss_mask: 0.6297  decode.d0.loss_dice: 1.1287  decode.d1.loss_cls: 1.0188  decode.d1.loss_mask: 0.6414  decode.d1.loss_dice: 1.0862  decode.d2.loss_cls: 0.9226  decode.d2.loss_mask: 0.6150  decode.d2.loss_dice: 1.0682  decode.d3.loss_cls: 0.9673  decode.d3.loss_mask: 0.5655  decode.d3.loss_dice: 0.9643  decode.d4.loss_cls: 0.8771  decode.d4.loss_mask: 0.5722  decode.d4.loss_dice: 0.9658  decode.d5.loss_cls: 0.8561  decode.d5.loss_mask: 0.5901  decode.d5.loss_dice: 0.9816  decode.d6.loss_cls: 0.8534  decode.d6.loss_mask: 0.6049  decode.d6.loss_dice: 0.9613  decode.d7.loss_cls: 0.8674  decode.d7.loss_mask: 0.5742  decode.d7.loss_dice: 0.9770  decode.d8.loss_cls: 0.8956  decode.d8.loss_mask: 0.5808  decode.d8.loss_dice: 0.9641
2023/05/24 02:44:43 - mmengine - INFO - Iter(train) [ 68900/160000]  lr: 6.0237e-06  eta: 10:51:04  time: 0.4462  data_time: 0.0104  memory: 4885  grad_norm: 133.2839  loss: 40.2147  decode.loss_cls: 1.3229  decode.loss_mask: 0.8320  decode.loss_dice: 1.5966  decode.d0.loss_cls: 3.2999  decode.d0.loss_mask: 0.8863  decode.d0.loss_dice: 1.8516  decode.d1.loss_cls: 1.4462  decode.d1.loss_mask: 0.8348  decode.d1.loss_dice: 1.7389  decode.d2.loss_cls: 1.4917  decode.d2.loss_mask: 0.7892  decode.d2.loss_dice: 1.6275  decode.d3.loss_cls: 1.4317  decode.d3.loss_mask: 0.7936  decode.d3.loss_dice: 1.6106  decode.d4.loss_cls: 1.3799  decode.d4.loss_mask: 0.7913  decode.d4.loss_dice: 1.5797  decode.d5.loss_cls: 1.3879  decode.d5.loss_mask: 0.7970  decode.d5.loss_dice: 1.5905  decode.d6.loss_cls: 1.3489  decode.d6.loss_mask: 0.8025  decode.d6.loss_dice: 1.5407  decode.d7.loss_cls: 1.3451  decode.d7.loss_mask: 0.8003  decode.d7.loss_dice: 1.5688  decode.d8.loss_cls: 1.3022  decode.d8.loss_mask: 0.8420  decode.d8.loss_dice: 1.5844
2023/05/24 02:45:04 - mmengine - INFO - Iter(train) [ 68950/160000]  lr: 6.0207e-06  eta: 10:50:43  time: 0.4352  data_time: 0.0106  memory: 4825  grad_norm: 115.5286  loss: 37.2939  decode.loss_cls: 1.4659  decode.loss_mask: 0.7824  decode.loss_dice: 1.2126  decode.d0.loss_cls: 3.2398  decode.d0.loss_mask: 0.9349  decode.d0.loss_dice: 1.4623  decode.d1.loss_cls: 1.5454  decode.d1.loss_mask: 0.8158  decode.d1.loss_dice: 1.3575  decode.d2.loss_cls: 1.4684  decode.d2.loss_mask: 0.7988  decode.d2.loss_dice: 1.2524  decode.d3.loss_cls: 1.3422  decode.d3.loss_mask: 0.8525  decode.d3.loss_dice: 1.2490  decode.d4.loss_cls: 1.4618  decode.d4.loss_mask: 0.8290  decode.d4.loss_dice: 1.2592  decode.d5.loss_cls: 1.4370  decode.d5.loss_mask: 0.8325  decode.d5.loss_dice: 1.2717  decode.d6.loss_cls: 1.4011  decode.d6.loss_mask: 0.7895  decode.d6.loss_dice: 1.2314  decode.d7.loss_cls: 1.4622  decode.d7.loss_mask: 0.7893  decode.d7.loss_dice: 1.2673  decode.d8.loss_cls: 1.4842  decode.d8.loss_mask: 0.7760  decode.d8.loss_dice: 1.2217
2023/05/24 02:45:26 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 02:45:26 - mmengine - INFO - Iter(train) [ 69000/160000]  lr: 6.0177e-06  eta: 10:50:21  time: 0.4300  data_time: 0.0107  memory: 4818  grad_norm: 93.5844  loss: 30.2571  decode.loss_cls: 1.0183  decode.loss_mask: 0.6767  decode.loss_dice: 1.0770  decode.d0.loss_cls: 2.7214  decode.d0.loss_mask: 0.7828  decode.d0.loss_dice: 1.2573  decode.d1.loss_cls: 1.0888  decode.d1.loss_mask: 0.7235  decode.d1.loss_dice: 1.2018  decode.d2.loss_cls: 1.1319  decode.d2.loss_mask: 0.7148  decode.d2.loss_dice: 1.1083  decode.d3.loss_cls: 1.0642  decode.d3.loss_mask: 0.7027  decode.d3.loss_dice: 1.0935  decode.d4.loss_cls: 1.0016  decode.d4.loss_mask: 0.6922  decode.d4.loss_dice: 1.0878  decode.d5.loss_cls: 0.9928  decode.d5.loss_mask: 0.6935  decode.d5.loss_dice: 1.0818  decode.d6.loss_cls: 1.0195  decode.d6.loss_mask: 0.6945  decode.d6.loss_dice: 1.0631  decode.d7.loss_cls: 1.0026  decode.d7.loss_mask: 0.7062  decode.d7.loss_dice: 1.0829  decode.d8.loss_cls: 1.0482  decode.d8.loss_mask: 0.6688  decode.d8.loss_dice: 1.0582
2023/05/24 02:45:26 - mmengine - INFO - Saving checkpoint at 69000 iterations
2023/05/24 02:45:52 - mmengine - INFO - Iter(train) [ 69050/160000]  lr: 6.0147e-06  eta: 10:50:06  time: 0.4208  data_time: 0.0103  memory: 4929  grad_norm: 96.1550  loss: 40.3925  decode.loss_cls: 1.4325  decode.loss_mask: 0.7826  decode.loss_dice: 1.5325  decode.d0.loss_cls: 3.3985  decode.d0.loss_mask: 0.7792  decode.d0.loss_dice: 1.7486  decode.d1.loss_cls: 1.6505  decode.d1.loss_mask: 0.7913  decode.d1.loss_dice: 1.6985  decode.d2.loss_cls: 1.4715  decode.d2.loss_mask: 0.8018  decode.d2.loss_dice: 1.6573  decode.d3.loss_cls: 1.4652  decode.d3.loss_mask: 0.7756  decode.d3.loss_dice: 1.5660  decode.d4.loss_cls: 1.5103  decode.d4.loss_mask: 0.7616  decode.d4.loss_dice: 1.5623  decode.d5.loss_cls: 1.4507  decode.d5.loss_mask: 0.7686  decode.d5.loss_dice: 1.5293  decode.d6.loss_cls: 1.4184  decode.d6.loss_mask: 0.7869  decode.d6.loss_dice: 1.5372  decode.d7.loss_cls: 1.4490  decode.d7.loss_mask: 0.7707  decode.d7.loss_dice: 1.5338  decode.d8.loss_cls: 1.4481  decode.d8.loss_mask: 0.7626  decode.d8.loss_dice: 1.5514
2023/05/24 02:46:13 - mmengine - INFO - Iter(train) [ 69100/160000]  lr: 6.0118e-06  eta: 10:49:44  time: 0.4086  data_time: 0.0100  memory: 4859  grad_norm: 88.3056  loss: 31.6231  decode.loss_cls: 1.1282  decode.loss_mask: 0.6010  decode.loss_dice: 1.1127  decode.d0.loss_cls: 3.0853  decode.d0.loss_mask: 0.6821  decode.d0.loss_dice: 1.3381  decode.d1.loss_cls: 1.3008  decode.d1.loss_mask: 0.6719  decode.d1.loss_dice: 1.2312  decode.d2.loss_cls: 1.1596  decode.d2.loss_mask: 0.6807  decode.d2.loss_dice: 1.1857  decode.d3.loss_cls: 1.1935  decode.d3.loss_mask: 0.6433  decode.d3.loss_dice: 1.1344  decode.d4.loss_cls: 1.1516  decode.d4.loss_mask: 0.6392  decode.d4.loss_dice: 1.1039  decode.d5.loss_cls: 1.1571  decode.d5.loss_mask: 0.6190  decode.d5.loss_dice: 1.1307  decode.d6.loss_cls: 1.0822  decode.d6.loss_mask: 0.6448  decode.d6.loss_dice: 1.1120  decode.d7.loss_cls: 1.1362  decode.d7.loss_mask: 0.6379  decode.d7.loss_dice: 1.1322  decode.d8.loss_cls: 1.1932  decode.d8.loss_mask: 0.6046  decode.d8.loss_dice: 1.1299
2023/05/24 02:46:34 - mmengine - INFO - Iter(train) [ 69150/160000]  lr: 6.0088e-06  eta: 10:49:22  time: 0.4225  data_time: 0.0103  memory: 4872  grad_norm: 86.8365  loss: 38.4562  decode.loss_cls: 1.2284  decode.loss_mask: 0.8811  decode.loss_dice: 1.4035  decode.d0.loss_cls: 3.4768  decode.d0.loss_mask: 0.9345  decode.d0.loss_dice: 1.6750  decode.d1.loss_cls: 1.3306  decode.d1.loss_mask: 0.8915  decode.d1.loss_dice: 1.5339  decode.d2.loss_cls: 1.2671  decode.d2.loss_mask: 0.9669  decode.d2.loss_dice: 1.4361  decode.d3.loss_cls: 1.3190  decode.d3.loss_mask: 0.9109  decode.d3.loss_dice: 1.4011  decode.d4.loss_cls: 1.2092  decode.d4.loss_mask: 0.9747  decode.d4.loss_dice: 1.4086  decode.d5.loss_cls: 1.2426  decode.d5.loss_mask: 0.9604  decode.d5.loss_dice: 1.4200  decode.d6.loss_cls: 1.2781  decode.d6.loss_mask: 0.8789  decode.d6.loss_dice: 1.4111  decode.d7.loss_cls: 1.2174  decode.d7.loss_mask: 0.8828  decode.d7.loss_dice: 1.4202  decode.d8.loss_cls: 1.2376  decode.d8.loss_mask: 0.8885  decode.d8.loss_dice: 1.3697
2023/05/24 02:46:55 - mmengine - INFO - Iter(train) [ 69200/160000]  lr: 6.0058e-06  eta: 10:49:00  time: 0.4397  data_time: 0.0102  memory: 4848  grad_norm: 140.1093  loss: 29.4929  decode.loss_cls: 1.0515  decode.loss_mask: 0.6290  decode.loss_dice: 1.0547  decode.d0.loss_cls: 2.8549  decode.d0.loss_mask: 0.6883  decode.d0.loss_dice: 1.2360  decode.d1.loss_cls: 1.1122  decode.d1.loss_mask: 0.6610  decode.d1.loss_dice: 1.0961  decode.d2.loss_cls: 1.0219  decode.d2.loss_mask: 0.6689  decode.d2.loss_dice: 1.0663  decode.d3.loss_cls: 0.9795  decode.d3.loss_mask: 0.6788  decode.d3.loss_dice: 1.0851  decode.d4.loss_cls: 1.0132  decode.d4.loss_mask: 0.6325  decode.d4.loss_dice: 1.0557  decode.d5.loss_cls: 0.9945  decode.d5.loss_mask: 0.6434  decode.d5.loss_dice: 1.0675  decode.d6.loss_cls: 1.0651  decode.d6.loss_mask: 0.6284  decode.d6.loss_dice: 1.0600  decode.d7.loss_cls: 1.0147  decode.d7.loss_mask: 0.6368  decode.d7.loss_dice: 1.0585  decode.d8.loss_cls: 1.0396  decode.d8.loss_mask: 0.6274  decode.d8.loss_dice: 1.0714
2023/05/24 02:47:16 - mmengine - INFO - Iter(train) [ 69250/160000]  lr: 6.0028e-06  eta: 10:48:38  time: 0.4173  data_time: 0.0106  memory: 4879  grad_norm: 109.4545  loss: 29.4122  decode.loss_cls: 1.0631  decode.loss_mask: 0.5671  decode.loss_dice: 1.0380  decode.d0.loss_cls: 2.8073  decode.d0.loss_mask: 0.7005  decode.d0.loss_dice: 1.2022  decode.d1.loss_cls: 1.1777  decode.d1.loss_mask: 0.6415  decode.d1.loss_dice: 1.2021  decode.d2.loss_cls: 1.1317  decode.d2.loss_mask: 0.5793  decode.d2.loss_dice: 1.1069  decode.d3.loss_cls: 1.0851  decode.d3.loss_mask: 0.5778  decode.d3.loss_dice: 1.0822  decode.d4.loss_cls: 1.0438  decode.d4.loss_mask: 0.5752  decode.d4.loss_dice: 1.0738  decode.d5.loss_cls: 1.0682  decode.d5.loss_mask: 0.6205  decode.d5.loss_dice: 1.0435  decode.d6.loss_cls: 1.0375  decode.d6.loss_mask: 0.5618  decode.d6.loss_dice: 1.0756  decode.d7.loss_cls: 1.0475  decode.d7.loss_mask: 0.5655  decode.d7.loss_dice: 1.0573  decode.d8.loss_cls: 1.0535  decode.d8.loss_mask: 0.5771  decode.d8.loss_dice: 1.0490
2023/05/24 02:47:39 - mmengine - INFO - Iter(train) [ 69300/160000]  lr: 5.9999e-06  eta: 10:48:19  time: 0.4769  data_time: 0.0099  memory: 4876  grad_norm: 99.0088  loss: 41.0757  decode.loss_cls: 1.4138  decode.loss_mask: 0.7804  decode.loss_dice: 1.5238  decode.d0.loss_cls: 3.6082  decode.d0.loss_mask: 0.8038  decode.d0.loss_dice: 1.7969  decode.d1.loss_cls: 1.6260  decode.d1.loss_mask: 0.8040  decode.d1.loss_dice: 1.6974  decode.d2.loss_cls: 1.5060  decode.d2.loss_mask: 0.8261  decode.d2.loss_dice: 1.6524  decode.d3.loss_cls: 1.4548  decode.d3.loss_mask: 0.7913  decode.d3.loss_dice: 1.6347  decode.d4.loss_cls: 1.4854  decode.d4.loss_mask: 0.7876  decode.d4.loss_dice: 1.6367  decode.d5.loss_cls: 1.4611  decode.d5.loss_mask: 0.8093  decode.d5.loss_dice: 1.6030  decode.d6.loss_cls: 1.4236  decode.d6.loss_mask: 0.8015  decode.d6.loss_dice: 1.6005  decode.d7.loss_cls: 1.4315  decode.d7.loss_mask: 0.7597  decode.d7.loss_dice: 1.5869  decode.d8.loss_cls: 1.4059  decode.d8.loss_mask: 0.7746  decode.d8.loss_dice: 1.5889
2023/05/24 02:48:00 - mmengine - INFO - Iter(train) [ 69350/160000]  lr: 5.9969e-06  eta: 10:47:57  time: 0.4162  data_time: 0.0102  memory: 4817  grad_norm: 104.5316  loss: 35.9254  decode.loss_cls: 1.2323  decode.loss_mask: 0.8006  decode.loss_dice: 1.2856  decode.d0.loss_cls: 3.2160  decode.d0.loss_mask: 0.9505  decode.d0.loss_dice: 1.4769  decode.d1.loss_cls: 1.2929  decode.d1.loss_mask: 0.8590  decode.d1.loss_dice: 1.3650  decode.d2.loss_cls: 1.2245  decode.d2.loss_mask: 0.8359  decode.d2.loss_dice: 1.3197  decode.d3.loss_cls: 1.2370  decode.d3.loss_mask: 0.8175  decode.d3.loss_dice: 1.2927  decode.d4.loss_cls: 1.2744  decode.d4.loss_mask: 0.8340  decode.d4.loss_dice: 1.3047  decode.d5.loss_cls: 1.2417  decode.d5.loss_mask: 0.8146  decode.d5.loss_dice: 1.2820  decode.d6.loss_cls: 1.2553  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 1.2920  decode.d7.loss_cls: 1.2193  decode.d7.loss_mask: 0.7999  decode.d7.loss_dice: 1.2589  decode.d8.loss_cls: 1.2688  decode.d8.loss_mask: 0.8063  decode.d8.loss_dice: 1.2587
2023/05/24 02:48:21 - mmengine - INFO - Iter(train) [ 69400/160000]  lr: 5.9939e-06  eta: 10:47:35  time: 0.4144  data_time: 0.0102  memory: 4836  grad_norm: 122.3922  loss: 38.1509  decode.loss_cls: 1.3536  decode.loss_mask: 0.8368  decode.loss_dice: 1.3121  decode.d0.loss_cls: 3.4295  decode.d0.loss_mask: 0.8682  decode.d0.loss_dice: 1.5013  decode.d1.loss_cls: 1.4596  decode.d1.loss_mask: 0.8471  decode.d1.loss_dice: 1.4011  decode.d2.loss_cls: 1.4843  decode.d2.loss_mask: 0.8378  decode.d2.loss_dice: 1.3478  decode.d3.loss_cls: 1.4016  decode.d3.loss_mask: 0.8509  decode.d3.loss_dice: 1.3787  decode.d4.loss_cls: 1.3888  decode.d4.loss_mask: 0.8666  decode.d4.loss_dice: 1.3435  decode.d5.loss_cls: 1.3179  decode.d5.loss_mask: 0.8920  decode.d5.loss_dice: 1.3664  decode.d6.loss_cls: 1.4077  decode.d6.loss_mask: 0.8438  decode.d6.loss_dice: 1.3220  decode.d7.loss_cls: 1.3737  decode.d7.loss_mask: 0.8366  decode.d7.loss_dice: 1.3418  decode.d8.loss_cls: 1.2980  decode.d8.loss_mask: 0.8629  decode.d8.loss_dice: 1.3787
2023/05/24 02:48:42 - mmengine - INFO - Iter(train) [ 69450/160000]  lr: 5.9909e-06  eta: 10:47:13  time: 0.4242  data_time: 0.0101  memory: 4823  grad_norm: 107.3468  loss: 34.9579  decode.loss_cls: 1.2135  decode.loss_mask: 0.8820  decode.loss_dice: 1.0576  decode.d0.loss_cls: 3.1734  decode.d0.loss_mask: 1.0114  decode.d0.loss_dice: 1.3546  decode.d1.loss_cls: 1.2899  decode.d1.loss_mask: 0.9950  decode.d1.loss_dice: 1.2319  decode.d2.loss_cls: 1.3409  decode.d2.loss_mask: 0.9567  decode.d2.loss_dice: 1.1727  decode.d3.loss_cls: 1.3175  decode.d3.loss_mask: 0.9052  decode.d3.loss_dice: 1.0924  decode.d4.loss_cls: 1.2484  decode.d4.loss_mask: 0.9030  decode.d4.loss_dice: 1.0999  decode.d5.loss_cls: 1.2759  decode.d5.loss_mask: 0.9035  decode.d5.loss_dice: 1.0435  decode.d6.loss_cls: 1.1626  decode.d6.loss_mask: 0.9050  decode.d6.loss_dice: 1.0641  decode.d7.loss_cls: 1.2283  decode.d7.loss_mask: 0.8977  decode.d7.loss_dice: 1.0812  decode.d8.loss_cls: 1.1726  decode.d8.loss_mask: 0.9098  decode.d8.loss_dice: 1.0676
2023/05/24 02:49:03 - mmengine - INFO - Iter(train) [ 69500/160000]  lr: 5.9880e-06  eta: 10:46:51  time: 0.4271  data_time: 0.0110  memory: 4877  grad_norm: 104.0704  loss: 37.6481  decode.loss_cls: 1.2107  decode.loss_mask: 0.8648  decode.loss_dice: 1.4311  decode.d0.loss_cls: 3.2004  decode.d0.loss_mask: 0.8956  decode.d0.loss_dice: 1.5898  decode.d1.loss_cls: 1.3530  decode.d1.loss_mask: 0.9100  decode.d1.loss_dice: 1.4960  decode.d2.loss_cls: 1.2244  decode.d2.loss_mask: 0.8914  decode.d2.loss_dice: 1.4747  decode.d3.loss_cls: 1.2243  decode.d3.loss_mask: 0.8767  decode.d3.loss_dice: 1.4619  decode.d4.loss_cls: 1.2898  decode.d4.loss_mask: 0.8944  decode.d4.loss_dice: 1.3718  decode.d5.loss_cls: 1.2017  decode.d5.loss_mask: 0.8585  decode.d5.loss_dice: 1.3816  decode.d6.loss_cls: 1.2227  decode.d6.loss_mask: 0.8545  decode.d6.loss_dice: 1.4259  decode.d7.loss_cls: 1.2394  decode.d7.loss_mask: 0.8760  decode.d7.loss_dice: 1.4305  decode.d8.loss_cls: 1.1550  decode.d8.loss_mask: 0.9013  decode.d8.loss_dice: 1.4401
2023/05/24 02:49:27 - mmengine - INFO - Iter(train) [ 69550/160000]  lr: 5.9850e-06  eta: 10:46:32  time: 0.4771  data_time: 0.0101  memory: 4871  grad_norm: 100.1242  loss: 41.0381  decode.loss_cls: 1.4821  decode.loss_mask: 0.8553  decode.loss_dice: 1.4189  decode.d0.loss_cls: 3.3786  decode.d0.loss_mask: 0.9509  decode.d0.loss_dice: 1.6758  decode.d1.loss_cls: 1.6932  decode.d1.loss_mask: 0.9821  decode.d1.loss_dice: 1.5676  decode.d2.loss_cls: 1.6965  decode.d2.loss_mask: 0.8898  decode.d2.loss_dice: 1.4787  decode.d3.loss_cls: 1.5560  decode.d3.loss_mask: 0.8699  decode.d3.loss_dice: 1.4482  decode.d4.loss_cls: 1.5555  decode.d4.loss_mask: 0.8784  decode.d4.loss_dice: 1.4476  decode.d5.loss_cls: 1.4789  decode.d5.loss_mask: 0.9225  decode.d5.loss_dice: 1.4722  decode.d6.loss_cls: 1.5803  decode.d6.loss_mask: 0.8517  decode.d6.loss_dice: 1.3976  decode.d7.loss_cls: 1.4909  decode.d7.loss_mask: 0.8440  decode.d7.loss_dice: 1.4305  decode.d8.loss_cls: 1.4778  decode.d8.loss_mask: 0.8379  decode.d8.loss_dice: 1.4286
2023/05/24 02:49:48 - mmengine - INFO - Iter(train) [ 69600/160000]  lr: 5.9820e-06  eta: 10:46:11  time: 0.4105  data_time: 0.0104  memory: 4906  grad_norm: 91.9972  loss: 33.5082  decode.loss_cls: 1.1150  decode.loss_mask: 0.8372  decode.loss_dice: 1.1578  decode.d0.loss_cls: 2.8804  decode.d0.loss_mask: 0.8624  decode.d0.loss_dice: 1.3427  decode.d1.loss_cls: 1.1556  decode.d1.loss_mask: 0.8185  decode.d1.loss_dice: 1.2792  decode.d2.loss_cls: 1.1266  decode.d2.loss_mask: 0.8336  decode.d2.loss_dice: 1.2030  decode.d3.loss_cls: 1.1431  decode.d3.loss_mask: 0.8242  decode.d3.loss_dice: 1.2010  decode.d4.loss_cls: 1.1536  decode.d4.loss_mask: 0.8185  decode.d4.loss_dice: 1.1716  decode.d5.loss_cls: 1.0918  decode.d5.loss_mask: 0.8337  decode.d5.loss_dice: 1.1914  decode.d6.loss_cls: 1.1391  decode.d6.loss_mask: 0.8572  decode.d6.loss_dice: 1.1752  decode.d7.loss_cls: 1.1281  decode.d7.loss_mask: 0.8520  decode.d7.loss_dice: 1.1857  decode.d8.loss_cls: 1.1316  decode.d8.loss_mask: 0.8421  decode.d8.loss_dice: 1.1565
2023/05/24 02:50:09 - mmengine - INFO - Iter(train) [ 69650/160000]  lr: 5.9790e-06  eta: 10:45:49  time: 0.4393  data_time: 0.0103  memory: 4835  grad_norm: 86.8130  loss: 40.0074  decode.loss_cls: 1.1151  decode.loss_mask: 0.9365  decode.loss_dice: 1.6036  decode.d0.loss_cls: 3.3599  decode.d0.loss_mask: 1.0355  decode.d0.loss_dice: 1.9074  decode.d1.loss_cls: 1.2512  decode.d1.loss_mask: 0.9826  decode.d1.loss_dice: 1.7038  decode.d2.loss_cls: 1.1478  decode.d2.loss_mask: 0.9659  decode.d2.loss_dice: 1.6588  decode.d3.loss_cls: 1.1847  decode.d3.loss_mask: 0.9666  decode.d3.loss_dice: 1.6319  decode.d4.loss_cls: 1.1318  decode.d4.loss_mask: 0.9668  decode.d4.loss_dice: 1.6460  decode.d5.loss_cls: 1.1364  decode.d5.loss_mask: 0.9583  decode.d5.loss_dice: 1.6384  decode.d6.loss_cls: 1.1385  decode.d6.loss_mask: 0.9478  decode.d6.loss_dice: 1.6194  decode.d7.loss_cls: 1.1577  decode.d7.loss_mask: 0.9459  decode.d7.loss_dice: 1.6125  decode.d8.loss_cls: 1.0988  decode.d8.loss_mask: 0.9395  decode.d8.loss_dice: 1.6181
2023/05/24 02:50:33 - mmengine - INFO - Iter(train) [ 69700/160000]  lr: 5.9760e-06  eta: 10:45:30  time: 0.4678  data_time: 0.0104  memory: 4949  grad_norm: 113.3987  loss: 40.8764  decode.loss_cls: 1.5273  decode.loss_mask: 0.8332  decode.loss_dice: 1.3986  decode.d0.loss_cls: 3.4961  decode.d0.loss_mask: 0.8998  decode.d0.loss_dice: 1.6263  decode.d1.loss_cls: 1.6606  decode.d1.loss_mask: 0.9132  decode.d1.loss_dice: 1.5210  decode.d2.loss_cls: 1.6196  decode.d2.loss_mask: 0.9004  decode.d2.loss_dice: 1.4729  decode.d3.loss_cls: 1.5635  decode.d3.loss_mask: 0.9107  decode.d3.loss_dice: 1.4072  decode.d4.loss_cls: 1.5630  decode.d4.loss_mask: 0.9037  decode.d4.loss_dice: 1.4541  decode.d5.loss_cls: 1.4775  decode.d5.loss_mask: 0.8841  decode.d5.loss_dice: 1.4207  decode.d6.loss_cls: 1.5717  decode.d6.loss_mask: 0.8455  decode.d6.loss_dice: 1.3991  decode.d7.loss_cls: 1.5150  decode.d7.loss_mask: 0.8645  decode.d7.loss_dice: 1.4126  decode.d8.loss_cls: 1.5285  decode.d8.loss_mask: 0.8664  decode.d8.loss_dice: 1.4196
2023/05/24 02:50:55 - mmengine - INFO - Iter(train) [ 69750/160000]  lr: 5.9731e-06  eta: 10:45:09  time: 0.4227  data_time: 0.0104  memory: 4928  grad_norm: 108.5889  loss: 48.9472  decode.loss_cls: 1.6550  decode.loss_mask: 0.9187  decode.loss_dice: 2.0149  decode.d0.loss_cls: 3.7897  decode.d0.loss_mask: 0.9950  decode.d0.loss_dice: 2.3311  decode.d1.loss_cls: 1.6697  decode.d1.loss_mask: 0.9399  decode.d1.loss_dice: 2.1598  decode.d2.loss_cls: 1.6009  decode.d2.loss_mask: 0.9937  decode.d2.loss_dice: 2.1308  decode.d3.loss_cls: 1.6525  decode.d3.loss_mask: 0.9427  decode.d3.loss_dice: 2.0221  decode.d4.loss_cls: 1.6616  decode.d4.loss_mask: 0.9806  decode.d4.loss_dice: 2.0372  decode.d5.loss_cls: 1.6079  decode.d5.loss_mask: 0.9754  decode.d5.loss_dice: 2.0676  decode.d6.loss_cls: 1.6520  decode.d6.loss_mask: 0.9604  decode.d6.loss_dice: 1.9859  decode.d7.loss_cls: 1.6109  decode.d7.loss_mask: 0.9687  decode.d7.loss_dice: 2.0230  decode.d8.loss_cls: 1.6415  decode.d8.loss_mask: 0.9602  decode.d8.loss_dice: 1.9977
2023/05/24 02:51:16 - mmengine - INFO - Iter(train) [ 69800/160000]  lr: 5.9701e-06  eta: 10:44:47  time: 0.4098  data_time: 0.0103  memory: 4826  grad_norm: 83.3462  loss: 39.6607  decode.loss_cls: 1.5292  decode.loss_mask: 0.7176  decode.loss_dice: 1.4564  decode.d0.loss_cls: 3.1797  decode.d0.loss_mask: 0.7855  decode.d0.loss_dice: 1.7188  decode.d1.loss_cls: 1.5910  decode.d1.loss_mask: 0.7220  decode.d1.loss_dice: 1.5572  decode.d2.loss_cls: 1.5173  decode.d2.loss_mask: 0.7581  decode.d2.loss_dice: 1.5679  decode.d3.loss_cls: 1.4852  decode.d3.loss_mask: 0.7656  decode.d3.loss_dice: 1.5419  decode.d4.loss_cls: 1.4991  decode.d4.loss_mask: 0.7500  decode.d4.loss_dice: 1.5465  decode.d5.loss_cls: 1.5387  decode.d5.loss_mask: 0.7485  decode.d5.loss_dice: 1.5237  decode.d6.loss_cls: 1.5053  decode.d6.loss_mask: 0.7316  decode.d6.loss_dice: 1.5076  decode.d7.loss_cls: 1.5491  decode.d7.loss_mask: 0.7287  decode.d7.loss_dice: 1.4524  decode.d8.loss_cls: 1.4847  decode.d8.loss_mask: 0.7407  decode.d8.loss_dice: 1.4605
2023/05/24 02:51:38 - mmengine - INFO - Iter(train) [ 69850/160000]  lr: 5.9671e-06  eta: 10:44:26  time: 0.4122  data_time: 0.0101  memory: 4889  grad_norm: 93.9840  loss: 40.2147  decode.loss_cls: 1.4367  decode.loss_mask: 0.7885  decode.loss_dice: 1.4378  decode.d0.loss_cls: 3.3516  decode.d0.loss_mask: 0.9048  decode.d0.loss_dice: 1.8247  decode.d1.loss_cls: 1.5632  decode.d1.loss_mask: 0.8543  decode.d1.loss_dice: 1.6331  decode.d2.loss_cls: 1.4894  decode.d2.loss_mask: 0.8570  decode.d2.loss_dice: 1.5454  decode.d3.loss_cls: 1.4727  decode.d3.loss_mask: 0.8549  decode.d3.loss_dice: 1.5021  decode.d4.loss_cls: 1.4102  decode.d4.loss_mask: 0.8291  decode.d4.loss_dice: 1.5601  decode.d5.loss_cls: 1.4436  decode.d5.loss_mask: 0.8152  decode.d5.loss_dice: 1.5522  decode.d6.loss_cls: 1.4178  decode.d6.loss_mask: 0.8181  decode.d6.loss_dice: 1.4484  decode.d7.loss_cls: 1.4350  decode.d7.loss_mask: 0.7942  decode.d7.loss_dice: 1.4674  decode.d8.loss_cls: 1.4307  decode.d8.loss_mask: 0.8108  decode.d8.loss_dice: 1.4657
2023/05/24 02:52:00 - mmengine - INFO - Iter(train) [ 69900/160000]  lr: 5.9641e-06  eta: 10:44:06  time: 0.4164  data_time: 0.0118  memory: 4868  grad_norm: 88.1255  loss: 39.1345  decode.loss_cls: 1.3590  decode.loss_mask: 0.8347  decode.loss_dice: 1.4305  decode.d0.loss_cls: 3.2283  decode.d0.loss_mask: 0.9343  decode.d0.loss_dice: 1.7238  decode.d1.loss_cls: 1.4361  decode.d1.loss_mask: 0.8731  decode.d1.loss_dice: 1.5682  decode.d2.loss_cls: 1.3509  decode.d2.loss_mask: 0.8822  decode.d2.loss_dice: 1.5347  decode.d3.loss_cls: 1.3421  decode.d3.loss_mask: 0.8948  decode.d3.loss_dice: 1.4958  decode.d4.loss_cls: 1.3548  decode.d4.loss_mask: 0.8667  decode.d4.loss_dice: 1.5014  decode.d5.loss_cls: 1.3653  decode.d5.loss_mask: 0.8297  decode.d5.loss_dice: 1.4324  decode.d6.loss_cls: 1.4165  decode.d6.loss_mask: 0.8398  decode.d6.loss_dice: 1.4117  decode.d7.loss_cls: 1.2857  decode.d7.loss_mask: 0.8568  decode.d7.loss_dice: 1.4491  decode.d8.loss_cls: 1.3646  decode.d8.loss_mask: 0.8540  decode.d8.loss_dice: 1.4174
2023/05/24 02:52:21 - mmengine - INFO - Iter(train) [ 69950/160000]  lr: 5.9611e-06  eta: 10:43:44  time: 0.4100  data_time: 0.0104  memory: 4870  grad_norm: 89.5869  loss: 31.3231  decode.loss_cls: 1.1352  decode.loss_mask: 0.7145  decode.loss_dice: 0.9592  decode.d0.loss_cls: 3.1862  decode.d0.loss_mask: 0.8074  decode.d0.loss_dice: 1.1182  decode.d1.loss_cls: 1.3791  decode.d1.loss_mask: 0.7066  decode.d1.loss_dice: 1.0364  decode.d2.loss_cls: 1.2770  decode.d2.loss_mask: 0.7386  decode.d2.loss_dice: 0.9819  decode.d3.loss_cls: 1.1933  decode.d3.loss_mask: 0.7843  decode.d3.loss_dice: 0.9680  decode.d4.loss_cls: 1.2255  decode.d4.loss_mask: 0.7428  decode.d4.loss_dice: 0.9563  decode.d5.loss_cls: 1.2490  decode.d5.loss_mask: 0.7153  decode.d5.loss_dice: 0.9662  decode.d6.loss_cls: 1.1771  decode.d6.loss_mask: 0.7168  decode.d6.loss_dice: 0.9322  decode.d7.loss_cls: 1.1372  decode.d7.loss_mask: 0.7225  decode.d7.loss_dice: 0.9745  decode.d8.loss_cls: 1.0886  decode.d8.loss_mask: 0.7576  decode.d8.loss_dice: 0.9757
2023/05/24 02:52:42 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 02:52:42 - mmengine - INFO - Iter(train) [ 70000/160000]  lr: 5.9582e-06  eta: 10:43:22  time: 0.4104  data_time: 0.0107  memory: 4911  grad_norm: 129.0124  loss: 37.6366  decode.loss_cls: 1.3172  decode.loss_mask: 0.7811  decode.loss_dice: 1.4154  decode.d0.loss_cls: 3.3716  decode.d0.loss_mask: 0.8052  decode.d0.loss_dice: 1.6101  decode.d1.loss_cls: 1.3994  decode.d1.loss_mask: 0.8546  decode.d1.loss_dice: 1.5461  decode.d2.loss_cls: 1.3364  decode.d2.loss_mask: 0.8063  decode.d2.loss_dice: 1.4426  decode.d3.loss_cls: 1.3352  decode.d3.loss_mask: 0.7798  decode.d3.loss_dice: 1.4075  decode.d4.loss_cls: 1.2857  decode.d4.loss_mask: 0.7853  decode.d4.loss_dice: 1.3926  decode.d5.loss_cls: 1.3055  decode.d5.loss_mask: 0.7760  decode.d5.loss_dice: 1.3793  decode.d6.loss_cls: 1.3016  decode.d6.loss_mask: 0.7673  decode.d6.loss_dice: 1.3981  decode.d7.loss_cls: 1.3206  decode.d7.loss_mask: 0.7858  decode.d7.loss_dice: 1.4160  decode.d8.loss_cls: 1.3162  decode.d8.loss_mask: 0.8074  decode.d8.loss_dice: 1.3909
2023/05/24 02:52:42 - mmengine - INFO - Saving checkpoint at 70000 iterations
2023/05/24 02:52:51 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0784  data_time: 0.0018  memory: 2167  
2023/05/24 02:52:55 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:42  time: 0.0785  data_time: 0.0018  memory: 2216  
2023/05/24 02:53:00 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:38  time: 0.0811  data_time: 0.0019  memory: 2167  
2023/05/24 02:53:04 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0804  data_time: 0.0019  memory: 2104  
2023/05/24 02:53:08 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0795  data_time: 0.0017  memory: 2831  
2023/05/24 02:53:12 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0790  data_time: 0.0018  memory: 2167  
2023/05/24 02:53:16 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0797  data_time: 0.0018  memory: 2167  
2023/05/24 02:53:20 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0843  data_time: 0.0018  memory: 2167  
2023/05/24 02:53:25 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0917  data_time: 0.0021  memory: 2944  
2023/05/24 02:53:29 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0789  data_time: 0.0019  memory: 2356  
2023/05/24 02:53:33 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0780  data_time: 0.0019  memory: 2217  
2023/05/24 02:53:39 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.2880  data_time: 0.0019  memory: 2328  
2023/05/24 02:53:43 - mmengine - INFO - per class results:
2023/05/24 02:53:43 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.85 | 93.47 |
|     bicycle      | 67.02 | 83.21 |
|       car        | 58.89 | 81.75 |
|    motorcycle    | 82.89 | 90.21 |
|     airplane     | 84.66 | 92.39 |
|       bus        | 78.58 |  89.6 |
|      train       | 84.81 | 92.05 |
|      truck       | 52.47 |  69.1 |
|       boat       | 58.51 | 79.96 |
|  traffic light   | 68.82 | 84.84 |
|   fire hydrant   | 86.98 |  94.7 |
|    stop sign     | 90.39 | 96.83 |
|  parking meter   | 71.07 | 81.12 |
|      bench       | 47.73 | 67.63 |
|       bird       |  80.5 | 90.48 |
|       cat        |  84.4 | 91.35 |
|       dog        | 76.94 | 84.84 |
|      horse       |  78.0 |  89.6 |
|      sheep       | 86.93 | 93.88 |
|       cow        | 81.84 | 88.44 |
|     elephant     | 89.95 |  94.7 |
|       bear       | 91.57 | 95.05 |
|      zebra       | 90.14 | 92.87 |
|     giraffe      | 87.07 | 92.52 |
|     backpack     | 33.21 | 58.75 |
|     umbrella     |  81.2 | 86.47 |
|     handbag      | 31.98 | 46.53 |
|       tie        |  13.8 | 23.76 |
|     suitcase     |  72.6 | 91.61 |
|     frisbee      | 76.04 | 89.18 |
|       skis       |  37.4 | 50.16 |
|    snowboard     | 45.76 | 73.06 |
|   sports ball    | 52.43 | 72.41 |
|       kite       | 58.57 | 72.47 |
|   baseball bat   | 43.32 | 51.64 |
|  baseball glove  | 40.14 | 45.37 |
|    skateboard    | 73.76 | 84.28 |
|    surfboard     | 71.63 | 87.44 |
|  tennis racket   | 81.18 | 90.08 |
|      bottle      | 44.97 | 65.04 |
|    wine glass    | 56.16 | 77.98 |
|       cup        | 56.63 | 76.49 |
|       fork       | 42.07 | 55.08 |
|      knife       | 32.08 | 43.26 |
|      spoon       | 31.89 | 52.15 |
|       bowl       | 49.67 | 68.72 |
|      banana      | 67.13 | 87.68 |
|      apple       | 46.21 | 66.86 |
|     sandwich     | 47.59 | 67.74 |
|      orange      | 66.32 | 71.03 |
|     broccoli     | 53.43 | 64.98 |
|      carrot      |  47.7 | 52.44 |
|     hot dog      | 50.96 | 60.38 |
|      pizza       | 68.35 | 81.41 |
|      donut       | 67.72 | 83.36 |
|       cake       | 61.42 |  80.5 |
|      chair       | 44.01 | 62.28 |
|      couch       | 51.73 | 81.58 |
|   potted plant   | 29.12 | 47.35 |
|       bed        |  61.5 | 80.15 |
|   dining table   |  42.3 |  73.6 |
|      toilet      | 77.88 | 93.96 |
|        tv        | 75.87 | 87.86 |
|      laptop      | 74.43 | 89.88 |
|      mouse       |  72.3 | 88.74 |
|      remote      | 59.37 | 71.98 |
|     keyboard     | 60.25 | 69.46 |
|    cell phone    | 69.31 |  90.7 |
|    microwave     | 58.12 | 76.34 |
|       oven       | 57.51 | 84.34 |
|     toaster      |  0.59 |  0.73 |
|       sink       | 58.48 | 78.98 |
|   refrigerator   | 72.63 | 92.59 |
|       book       | 47.03 | 69.29 |
|      clock       | 72.17 | 88.21 |
|       vase       | 57.73 | 85.15 |
|     scissors     |  74.3 | 90.88 |
|    teddy bear    | 73.54 |  87.0 |
|    hair drier    | 46.55 | 47.65 |
|    toothbrush    |  30.3 | 70.51 |
|      banner      | 38.69 | 63.52 |
|     blanket      |  5.87 |  6.78 |
|      branch      | 25.01 | 34.85 |
|      bridge      | 28.21 | 45.98 |
|  building-other  | 52.35 | 70.14 |
|       bush       | 29.07 | 38.89 |
|     cabinet      | 49.21 | 75.13 |
|       cage       |  15.3 | 19.28 |
|    cardboard     | 41.98 | 50.09 |
|      carpet      | 53.34 | 75.39 |
|  ceiling-other   | 61.12 | 81.38 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      |  18.0 | 24.33 |
|      clouds      |  43.4 | 52.77 |
|     counter      | 28.02 | 44.75 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 60.06 | 69.14 |
|    desk-stuff    | 46.96 | 63.27 |
|       dirt       | 41.19 | 61.34 |
|    door-stuff    |  37.3 | 63.56 |
|      fence       | 33.24 | 62.52 |
|   floor-marble   |  5.98 |  7.54 |
|   floor-other    | 21.26 | 29.08 |
|   floor-stone    |  2.49 |  2.74 |
|    floor-tile    | 59.38 | 73.25 |
|    floor-wood    | 58.68 | 78.06 |
|      flower      | 36.72 |  53.3 |
|       fog        |  0.74 |  0.75 |
|    food-other    | 25.31 | 30.16 |
|      fruit       | 36.28 | 52.48 |
| furniture-other  | 13.58 | 16.74 |
|      grass       |  70.6 | 84.19 |
|      gravel      | 27.92 | 40.99 |
|   ground-other   |  3.94 |  5.05 |
|       hill       | 15.61 | 18.99 |
|      house       | 26.84 | 35.21 |
|      leaves      | 30.42 | 48.81 |
|      light       |  36.4 | 50.69 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.74 | 45.74 |
|   mirror-stuff   | 44.69 | 70.91 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 54.03 | 76.46 |
|       mud        |  0.0  |  0.0  |
|      napkin      | 11.67 | 12.48 |
|       net        | 45.02 |  67.9 |
|      paper       | 31.74 | 47.08 |
|     pavement     | 52.65 | 71.76 |
|      pillow      |  6.75 |  8.24 |
|   plant-other    | 17.85 | 25.85 |
|     plastic      | 16.28 | 21.98 |
|     platform     | 28.95 | 48.79 |
|   playingfield   | 70.21 | 90.58 |
|     railing      |  4.75 |  6.1  |
|     railroad     | 58.58 | 77.41 |
|      river       | 46.66 | 62.52 |
|       road       | 65.08 | 81.22 |
|       rock       | 26.77 | 36.11 |
|       roof       | 12.07 | 14.91 |
|       rug        | 31.91 | 47.18 |
|      salad       |  0.02 |  0.02 |
|       sand       | 59.83 | 65.63 |
|       sea        | 84.96 | 92.09 |
|      shelf       | 29.54 | 35.89 |
|    sky-other     | 70.21 | 90.02 |
|    skyscraper    | 34.86 | 49.11 |
|       snow       | 89.29 | 94.67 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 24.07 | 41.45 |
|      stone       | 20.32 | 55.09 |
|      straw       | 23.81 | 29.26 |
| structural-other |  0.01 |  0.01 |
|      table       | 20.25 | 29.06 |
|       tent       |  8.21 | 11.46 |
|  textile-other   |  9.92 | 16.31 |
|      towel       | 30.36 | 41.43 |
|       tree       | 72.75 | 87.31 |
|    vegetable     | 39.27 | 58.04 |
|    wall-brick    | 45.71 |  57.3 |
|  wall-concrete   | 59.34 | 79.71 |
|    wall-other    | 17.35 | 27.16 |
|    wall-panel    |  4.17 |  4.64 |
|    wall-stone    | 33.49 | 38.36 |
|    wall-tile     | 64.59 | 80.51 |
|    wall-wood     |  37.4 | 49.74 |
|   water-other    | 29.24 | 46.43 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 48.02 | 55.22 |
|   window-other   |  44.2 | 72.88 |
|       wood       | 24.63 | 36.34 |
+------------------+-------+-------+
2023/05/24 02:53:44 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.7900  mIoU: 45.6100  mAcc: 58.4100  data_time: 0.0021  time: 0.0862
2023/05/24 02:53:44 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_60000.pth is removed
2023/05/24 02:53:47 - mmengine - INFO - The best checkpoint with 45.6100 mIoU at 70000 iter is saved to best_mIoU_iter_70000.pth.
2023/05/24 02:54:08 - mmengine - INFO - Iter(train) [ 70050/160000]  lr: 5.9552e-06  eta: 10:43:06  time: 0.4108  data_time: 0.0100  memory: 4925  grad_norm: 111.2392  loss: 33.8880  decode.loss_cls: 1.1344  decode.loss_mask: 0.8139  decode.loss_dice: 1.1558  decode.d0.loss_cls: 3.2413  decode.d0.loss_mask: 0.8768  decode.d0.loss_dice: 1.4188  decode.d1.loss_cls: 1.2869  decode.d1.loss_mask: 0.9084  decode.d1.loss_dice: 1.2695  decode.d2.loss_cls: 1.1315  decode.d2.loss_mask: 0.8352  decode.d2.loss_dice: 1.2292  decode.d3.loss_cls: 1.1383  decode.d3.loss_mask: 0.8259  decode.d3.loss_dice: 1.1519  decode.d4.loss_cls: 1.0873  decode.d4.loss_mask: 0.8353  decode.d4.loss_dice: 1.1519  decode.d5.loss_cls: 1.1839  decode.d5.loss_mask: 0.8134  decode.d5.loss_dice: 1.1426  decode.d6.loss_cls: 1.1800  decode.d6.loss_mask: 0.7955  decode.d6.loss_dice: 1.1028  decode.d7.loss_cls: 1.1374  decode.d7.loss_mask: 0.8303  decode.d7.loss_dice: 1.1224  decode.d8.loss_cls: 1.1619  decode.d8.loss_mask: 0.7880  decode.d8.loss_dice: 1.1373
2023/05/24 02:54:29 - mmengine - INFO - Iter(train) [ 70100/160000]  lr: 5.9522e-06  eta: 10:42:45  time: 0.4235  data_time: 0.0104  memory: 4772  grad_norm: 121.8854  loss: 40.6739  decode.loss_cls: 1.6540  decode.loss_mask: 0.7746  decode.loss_dice: 1.3700  decode.d0.loss_cls: 3.4259  decode.d0.loss_mask: 0.8501  decode.d0.loss_dice: 1.6185  decode.d1.loss_cls: 1.7114  decode.d1.loss_mask: 0.8416  decode.d1.loss_dice: 1.5480  decode.d2.loss_cls: 1.6371  decode.d2.loss_mask: 0.8562  decode.d2.loss_dice: 1.4582  decode.d3.loss_cls: 1.6679  decode.d3.loss_mask: 0.8063  decode.d3.loss_dice: 1.4464  decode.d4.loss_cls: 1.5963  decode.d4.loss_mask: 0.7908  decode.d4.loss_dice: 1.4418  decode.d5.loss_cls: 1.6250  decode.d5.loss_mask: 0.7809  decode.d5.loss_dice: 1.4348  decode.d6.loss_cls: 1.6432  decode.d6.loss_mask: 0.7633  decode.d6.loss_dice: 1.3841  decode.d7.loss_cls: 1.5792  decode.d7.loss_mask: 0.7677  decode.d7.loss_dice: 1.4068  decode.d8.loss_cls: 1.5949  decode.d8.loss_mask: 0.7738  decode.d8.loss_dice: 1.4246
2023/05/24 02:54:50 - mmengine - INFO - Iter(train) [ 70150/160000]  lr: 5.9492e-06  eta: 10:42:23  time: 0.4146  data_time: 0.0102  memory: 4836  grad_norm: 111.0961  loss: 36.5909  decode.loss_cls: 1.0681  decode.loss_mask: 0.9254  decode.loss_dice: 1.4742  decode.d0.loss_cls: 2.7266  decode.d0.loss_mask: 0.9645  decode.d0.loss_dice: 1.6780  decode.d1.loss_cls: 1.1064  decode.d1.loss_mask: 0.9616  decode.d1.loss_dice: 1.5884  decode.d2.loss_cls: 1.0700  decode.d2.loss_mask: 0.8997  decode.d2.loss_dice: 1.4889  decode.d3.loss_cls: 0.9720  decode.d3.loss_mask: 0.9443  decode.d3.loss_dice: 1.4893  decode.d4.loss_cls: 1.0058  decode.d4.loss_mask: 0.9211  decode.d4.loss_dice: 1.4749  decode.d5.loss_cls: 0.9990  decode.d5.loss_mask: 0.9038  decode.d5.loss_dice: 1.5038  decode.d6.loss_cls: 1.0475  decode.d6.loss_mask: 0.9030  decode.d6.loss_dice: 1.5009  decode.d7.loss_cls: 1.0346  decode.d7.loss_mask: 0.9023  decode.d7.loss_dice: 1.5244  decode.d8.loss_cls: 1.1368  decode.d8.loss_mask: 0.9148  decode.d8.loss_dice: 1.4608
2023/05/24 02:55:11 - mmengine - INFO - Iter(train) [ 70200/160000]  lr: 5.9462e-06  eta: 10:42:01  time: 0.4640  data_time: 0.0109  memory: 4901  grad_norm: 105.8308  loss: 24.9766  decode.loss_cls: 0.8274  decode.loss_mask: 0.6322  decode.loss_dice: 0.7468  decode.d0.loss_cls: 2.6604  decode.d0.loss_mask: 0.5988  decode.d0.loss_dice: 0.8034  decode.d1.loss_cls: 1.0265  decode.d1.loss_mask: 0.6200  decode.d1.loss_dice: 0.7819  decode.d2.loss_cls: 0.9154  decode.d2.loss_mask: 0.7004  decode.d2.loss_dice: 0.7745  decode.d3.loss_cls: 0.9351  decode.d3.loss_mask: 0.6696  decode.d3.loss_dice: 0.7507  decode.d4.loss_cls: 0.9112  decode.d4.loss_mask: 0.6712  decode.d4.loss_dice: 0.7422  decode.d5.loss_cls: 0.8885  decode.d5.loss_mask: 0.6833  decode.d5.loss_dice: 0.7265  decode.d6.loss_cls: 0.9143  decode.d6.loss_mask: 0.6410  decode.d6.loss_dice: 0.7566  decode.d7.loss_cls: 0.9105  decode.d7.loss_mask: 0.6785  decode.d7.loss_dice: 0.7589  decode.d8.loss_cls: 0.8620  decode.d8.loss_mask: 0.6357  decode.d8.loss_dice: 0.7530
2023/05/24 02:55:32 - mmengine - INFO - Iter(train) [ 70250/160000]  lr: 5.9433e-06  eta: 10:41:39  time: 0.4140  data_time: 0.0103  memory: 4836  grad_norm: 88.0002  loss: 37.3793  decode.loss_cls: 1.3431  decode.loss_mask: 0.7970  decode.loss_dice: 1.3180  decode.d0.loss_cls: 3.3191  decode.d0.loss_mask: 0.8390  decode.d0.loss_dice: 1.4914  decode.d1.loss_cls: 1.4387  decode.d1.loss_mask: 0.8449  decode.d1.loss_dice: 1.5350  decode.d2.loss_cls: 1.3784  decode.d2.loss_mask: 0.8205  decode.d2.loss_dice: 1.3952  decode.d3.loss_cls: 1.3474  decode.d3.loss_mask: 0.8069  decode.d3.loss_dice: 1.3794  decode.d4.loss_cls: 1.3479  decode.d4.loss_mask: 0.8092  decode.d4.loss_dice: 1.3445  decode.d5.loss_cls: 1.3185  decode.d5.loss_mask: 0.8015  decode.d5.loss_dice: 1.3666  decode.d6.loss_cls: 1.3459  decode.d6.loss_mask: 0.7927  decode.d6.loss_dice: 1.3310  decode.d7.loss_cls: 1.2903  decode.d7.loss_mask: 0.8015  decode.d7.loss_dice: 1.3433  decode.d8.loss_cls: 1.3288  decode.d8.loss_mask: 0.7909  decode.d8.loss_dice: 1.3126
2023/05/24 02:55:54 - mmengine - INFO - Iter(train) [ 70300/160000]  lr: 5.9403e-06  eta: 10:41:18  time: 0.4809  data_time: 0.0105  memory: 4824  grad_norm: 93.2459  loss: 40.9144  decode.loss_cls: 1.4386  decode.loss_mask: 0.8684  decode.loss_dice: 1.4895  decode.d0.loss_cls: 3.2896  decode.d0.loss_mask: 0.9539  decode.d0.loss_dice: 1.7811  decode.d1.loss_cls: 1.5202  decode.d1.loss_mask: 0.9230  decode.d1.loss_dice: 1.6246  decode.d2.loss_cls: 1.5069  decode.d2.loss_mask: 0.8700  decode.d2.loss_dice: 1.5709  decode.d3.loss_cls: 1.5218  decode.d3.loss_mask: 0.8782  decode.d3.loss_dice: 1.5200  decode.d4.loss_cls: 1.4376  decode.d4.loss_mask: 0.8999  decode.d4.loss_dice: 1.5430  decode.d5.loss_cls: 1.4882  decode.d5.loss_mask: 0.8697  decode.d5.loss_dice: 1.4833  decode.d6.loss_cls: 1.4597  decode.d6.loss_mask: 0.8739  decode.d6.loss_dice: 1.4755  decode.d7.loss_cls: 1.4724  decode.d7.loss_mask: 0.8563  decode.d7.loss_dice: 1.4863  decode.d8.loss_cls: 1.4285  decode.d8.loss_mask: 0.8786  decode.d8.loss_dice: 1.5047
2023/05/24 02:56:17 - mmengine - INFO - Iter(train) [ 70350/160000]  lr: 5.9373e-06  eta: 10:40:58  time: 0.4736  data_time: 0.0102  memory: 4961  grad_norm: 96.6451  loss: 37.5756  decode.loss_cls: 1.2544  decode.loss_mask: 0.8241  decode.loss_dice: 1.3942  decode.d0.loss_cls: 3.4072  decode.d0.loss_mask: 0.9102  decode.d0.loss_dice: 1.5686  decode.d1.loss_cls: 1.4090  decode.d1.loss_mask: 0.8419  decode.d1.loss_dice: 1.5056  decode.d2.loss_cls: 1.3426  decode.d2.loss_mask: 0.8270  decode.d2.loss_dice: 1.4121  decode.d3.loss_cls: 1.3250  decode.d3.loss_mask: 0.8299  decode.d3.loss_dice: 1.3259  decode.d4.loss_cls: 1.3238  decode.d4.loss_mask: 0.8343  decode.d4.loss_dice: 1.3443  decode.d5.loss_cls: 1.2753  decode.d5.loss_mask: 0.8540  decode.d5.loss_dice: 1.3524  decode.d6.loss_cls: 1.3091  decode.d6.loss_mask: 0.8336  decode.d6.loss_dice: 1.3363  decode.d7.loss_cls: 1.2821  decode.d7.loss_mask: 0.8148  decode.d7.loss_dice: 1.3584  decode.d8.loss_cls: 1.2432  decode.d8.loss_mask: 0.8458  decode.d8.loss_dice: 1.3902
2023/05/24 02:56:38 - mmengine - INFO - Iter(train) [ 70400/160000]  lr: 5.9343e-06  eta: 10:40:37  time: 0.4266  data_time: 0.0107  memory: 4838  grad_norm: 125.9301  loss: 39.5523  decode.loss_cls: 1.3160  decode.loss_mask: 0.7448  decode.loss_dice: 1.5778  decode.d0.loss_cls: 3.2241  decode.d0.loss_mask: 0.8839  decode.d0.loss_dice: 1.8982  decode.d1.loss_cls: 1.4284  decode.d1.loss_mask: 0.8129  decode.d1.loss_dice: 1.7282  decode.d2.loss_cls: 1.3419  decode.d2.loss_mask: 0.8327  decode.d2.loss_dice: 1.6652  decode.d3.loss_cls: 1.3888  decode.d3.loss_mask: 0.7636  decode.d3.loss_dice: 1.6246  decode.d4.loss_cls: 1.3051  decode.d4.loss_mask: 0.8075  decode.d4.loss_dice: 1.6099  decode.d5.loss_cls: 1.2910  decode.d5.loss_mask: 0.8021  decode.d5.loss_dice: 1.5891  decode.d6.loss_cls: 1.2915  decode.d6.loss_mask: 0.7358  decode.d6.loss_dice: 1.5797  decode.d7.loss_cls: 1.3183  decode.d7.loss_mask: 0.7318  decode.d7.loss_dice: 1.5777  decode.d8.loss_cls: 1.3660  decode.d8.loss_mask: 0.7446  decode.d8.loss_dice: 1.5711
2023/05/24 02:56:59 - mmengine - INFO - Iter(train) [ 70450/160000]  lr: 5.9313e-06  eta: 10:40:15  time: 0.4197  data_time: 0.0105  memory: 4814  grad_norm: 96.1315  loss: 28.1107  decode.loss_cls: 0.8864  decode.loss_mask: 0.7211  decode.loss_dice: 0.8664  decode.d0.loss_cls: 2.8342  decode.d0.loss_mask: 0.7854  decode.d0.loss_dice: 1.0161  decode.d1.loss_cls: 1.0517  decode.d1.loss_mask: 0.7624  decode.d1.loss_dice: 0.9708  decode.d2.loss_cls: 0.9532  decode.d2.loss_mask: 0.7673  decode.d2.loss_dice: 0.9094  decode.d3.loss_cls: 0.9643  decode.d3.loss_mask: 0.7335  decode.d3.loss_dice: 0.9291  decode.d4.loss_cls: 0.9484  decode.d4.loss_mask: 0.7603  decode.d4.loss_dice: 0.9095  decode.d5.loss_cls: 0.9015  decode.d5.loss_mask: 0.7893  decode.d5.loss_dice: 0.9362  decode.d6.loss_cls: 0.9461  decode.d6.loss_mask: 0.7563  decode.d6.loss_dice: 0.8962  decode.d7.loss_cls: 0.8712  decode.d7.loss_mask: 0.7810  decode.d7.loss_dice: 0.9063  decode.d8.loss_cls: 0.8918  decode.d8.loss_mask: 0.7509  decode.d8.loss_dice: 0.9144
2023/05/24 02:57:20 - mmengine - INFO - Iter(train) [ 70500/160000]  lr: 5.9284e-06  eta: 10:39:53  time: 0.4151  data_time: 0.0102  memory: 4821  grad_norm: 111.2793  loss: 35.6123  decode.loss_cls: 1.2311  decode.loss_mask: 0.6684  decode.loss_dice: 1.3747  decode.d0.loss_cls: 2.9164  decode.d0.loss_mask: 0.7343  decode.d0.loss_dice: 1.6218  decode.d1.loss_cls: 1.3824  decode.d1.loss_mask: 0.7191  decode.d1.loss_dice: 1.5628  decode.d2.loss_cls: 1.3900  decode.d2.loss_mask: 0.6657  decode.d2.loss_dice: 1.4733  decode.d3.loss_cls: 1.2577  decode.d3.loss_mask: 0.6515  decode.d3.loss_dice: 1.4353  decode.d4.loss_cls: 1.2450  decode.d4.loss_mask: 0.6432  decode.d4.loss_dice: 1.4061  decode.d5.loss_cls: 1.2274  decode.d5.loss_mask: 0.6396  decode.d5.loss_dice: 1.4104  decode.d6.loss_cls: 1.2768  decode.d6.loss_mask: 0.6577  decode.d6.loss_dice: 1.3964  decode.d7.loss_cls: 1.2385  decode.d7.loss_mask: 0.6659  decode.d7.loss_dice: 1.3923  decode.d8.loss_cls: 1.2292  decode.d8.loss_mask: 0.6923  decode.d8.loss_dice: 1.4068
2023/05/24 02:57:41 - mmengine - INFO - Iter(train) [ 70550/160000]  lr: 5.9254e-06  eta: 10:39:31  time: 0.4143  data_time: 0.0104  memory: 4890  grad_norm: 82.1467  loss: 36.6625  decode.loss_cls: 1.3796  decode.loss_mask: 0.6888  decode.loss_dice: 1.3349  decode.d0.loss_cls: 3.3065  decode.d0.loss_mask: 0.7594  decode.d0.loss_dice: 1.5989  decode.d1.loss_cls: 1.4996  decode.d1.loss_mask: 0.6834  decode.d1.loss_dice: 1.4416  decode.d2.loss_cls: 1.4677  decode.d2.loss_mask: 0.6694  decode.d2.loss_dice: 1.3645  decode.d3.loss_cls: 1.4954  decode.d3.loss_mask: 0.6499  decode.d3.loss_dice: 1.3487  decode.d4.loss_cls: 1.4193  decode.d4.loss_mask: 0.6497  decode.d4.loss_dice: 1.2986  decode.d5.loss_cls: 1.4374  decode.d5.loss_mask: 0.6722  decode.d5.loss_dice: 1.3065  decode.d6.loss_cls: 1.4404  decode.d6.loss_mask: 0.6547  decode.d6.loss_dice: 1.3174  decode.d7.loss_cls: 1.4144  decode.d7.loss_mask: 0.7033  decode.d7.loss_dice: 1.3199  decode.d8.loss_cls: 1.3771  decode.d8.loss_mask: 0.6679  decode.d8.loss_dice: 1.2955
2023/05/24 02:58:03 - mmengine - INFO - Iter(train) [ 70600/160000]  lr: 5.9224e-06  eta: 10:39:09  time: 0.4179  data_time: 0.0108  memory: 4791  grad_norm: 85.4509  loss: 29.8216  decode.loss_cls: 0.9563  decode.loss_mask: 0.7234  decode.loss_dice: 1.1266  decode.d0.loss_cls: 2.5529  decode.d0.loss_mask: 0.7434  decode.d0.loss_dice: 1.3163  decode.d1.loss_cls: 1.1078  decode.d1.loss_mask: 0.7012  decode.d1.loss_dice: 1.1530  decode.d2.loss_cls: 0.9208  decode.d2.loss_mask: 0.7413  decode.d2.loss_dice: 1.2011  decode.d3.loss_cls: 0.9405  decode.d3.loss_mask: 0.7086  decode.d3.loss_dice: 1.1448  decode.d4.loss_cls: 0.9306  decode.d4.loss_mask: 0.7006  decode.d4.loss_dice: 1.1202  decode.d5.loss_cls: 0.9006  decode.d5.loss_mask: 0.7137  decode.d5.loss_dice: 1.1438  decode.d6.loss_cls: 0.9358  decode.d6.loss_mask: 0.7151  decode.d6.loss_dice: 1.1054  decode.d7.loss_cls: 0.9490  decode.d7.loss_mask: 0.6844  decode.d7.loss_dice: 1.1013  decode.d8.loss_cls: 0.9339  decode.d8.loss_mask: 0.7163  decode.d8.loss_dice: 1.1330
2023/05/24 02:58:24 - mmengine - INFO - Iter(train) [ 70650/160000]  lr: 5.9194e-06  eta: 10:38:47  time: 0.4184  data_time: 0.0101  memory: 4824  grad_norm: 112.0134  loss: 35.8976  decode.loss_cls: 1.1820  decode.loss_mask: 0.7599  decode.loss_dice: 1.3446  decode.d0.loss_cls: 3.1102  decode.d0.loss_mask: 0.7808  decode.d0.loss_dice: 1.5065  decode.d1.loss_cls: 1.3448  decode.d1.loss_mask: 0.8389  decode.d1.loss_dice: 1.4615  decode.d2.loss_cls: 1.1839  decode.d2.loss_mask: 0.7798  decode.d2.loss_dice: 1.4325  decode.d3.loss_cls: 1.2820  decode.d3.loss_mask: 0.7818  decode.d3.loss_dice: 1.3885  decode.d4.loss_cls: 1.1818  decode.d4.loss_mask: 0.8013  decode.d4.loss_dice: 1.4358  decode.d5.loss_cls: 1.1638  decode.d5.loss_mask: 0.7711  decode.d5.loss_dice: 1.4052  decode.d6.loss_cls: 1.2824  decode.d6.loss_mask: 0.7378  decode.d6.loss_dice: 1.3336  decode.d7.loss_cls: 1.2379  decode.d7.loss_mask: 0.7472  decode.d7.loss_dice: 1.3446  decode.d8.loss_cls: 1.1688  decode.d8.loss_mask: 0.7587  decode.d8.loss_dice: 1.3498
2023/05/24 02:58:47 - mmengine - INFO - Iter(train) [ 70700/160000]  lr: 5.9164e-06  eta: 10:38:27  time: 0.4743  data_time: 0.0104  memory: 4836  grad_norm: 88.2717  loss: 36.8654  decode.loss_cls: 1.2121  decode.loss_mask: 0.7865  decode.loss_dice: 1.4169  decode.d0.loss_cls: 3.0698  decode.d0.loss_mask: 0.8672  decode.d0.loss_dice: 1.6591  decode.d1.loss_cls: 1.3219  decode.d1.loss_mask: 0.8505  decode.d1.loss_dice: 1.5496  decode.d2.loss_cls: 1.2824  decode.d2.loss_mask: 0.7910  decode.d2.loss_dice: 1.4432  decode.d3.loss_cls: 1.2423  decode.d3.loss_mask: 0.7762  decode.d3.loss_dice: 1.4644  decode.d4.loss_cls: 1.2283  decode.d4.loss_mask: 0.7757  decode.d4.loss_dice: 1.4801  decode.d5.loss_cls: 1.1959  decode.d5.loss_mask: 0.7965  decode.d5.loss_dice: 1.4853  decode.d6.loss_cls: 1.2063  decode.d6.loss_mask: 0.7646  decode.d6.loss_dice: 1.4326  decode.d7.loss_cls: 1.1576  decode.d7.loss_mask: 0.7801  decode.d7.loss_dice: 1.4174  decode.d8.loss_cls: 1.1999  decode.d8.loss_mask: 0.7729  decode.d8.loss_dice: 1.4390
2023/05/24 02:59:09 - mmengine - INFO - Iter(train) [ 70750/160000]  lr: 5.9135e-06  eta: 10:38:07  time: 0.4597  data_time: 0.0102  memory: 4870  grad_norm: 97.4222  loss: 39.7547  decode.loss_cls: 1.5411  decode.loss_mask: 0.7875  decode.loss_dice: 1.4243  decode.d0.loss_cls: 3.0243  decode.d0.loss_mask: 0.8351  decode.d0.loss_dice: 1.5355  decode.d1.loss_cls: 1.5889  decode.d1.loss_mask: 0.8493  decode.d1.loss_dice: 1.5544  decode.d2.loss_cls: 1.5480  decode.d2.loss_mask: 0.8403  decode.d2.loss_dice: 1.5145  decode.d3.loss_cls: 1.5899  decode.d3.loss_mask: 0.8008  decode.d3.loss_dice: 1.4417  decode.d4.loss_cls: 1.4612  decode.d4.loss_mask: 0.8621  decode.d4.loss_dice: 1.4818  decode.d5.loss_cls: 1.5948  decode.d5.loss_mask: 0.8345  decode.d5.loss_dice: 1.4706  decode.d6.loss_cls: 1.5921  decode.d6.loss_mask: 0.7726  decode.d6.loss_dice: 1.4133  decode.d7.loss_cls: 1.5999  decode.d7.loss_mask: 0.7552  decode.d7.loss_dice: 1.3553  decode.d8.loss_cls: 1.4684  decode.d8.loss_mask: 0.8129  decode.d8.loss_dice: 1.4044
2023/05/24 02:59:32 - mmengine - INFO - Iter(train) [ 70800/160000]  lr: 5.9105e-06  eta: 10:37:48  time: 0.4733  data_time: 0.0102  memory: 4781  grad_norm: 85.7219  loss: 30.6025  decode.loss_cls: 1.1271  decode.loss_mask: 0.7235  decode.loss_dice: 0.9497  decode.d0.loss_cls: 3.0180  decode.d0.loss_mask: 0.7399  decode.d0.loss_dice: 1.1310  decode.d1.loss_cls: 1.2536  decode.d1.loss_mask: 0.7995  decode.d1.loss_dice: 1.0896  decode.d2.loss_cls: 1.1834  decode.d2.loss_mask: 0.7363  decode.d2.loss_dice: 1.0421  decode.d3.loss_cls: 1.1178  decode.d3.loss_mask: 0.7229  decode.d3.loss_dice: 0.9355  decode.d4.loss_cls: 1.1005  decode.d4.loss_mask: 0.7238  decode.d4.loss_dice: 0.9384  decode.d5.loss_cls: 1.1271  decode.d5.loss_mask: 0.7299  decode.d5.loss_dice: 0.9563  decode.d6.loss_cls: 1.1431  decode.d6.loss_mask: 0.7397  decode.d6.loss_dice: 0.9584  decode.d7.loss_cls: 1.1431  decode.d7.loss_mask: 0.7341  decode.d7.loss_dice: 0.9474  decode.d8.loss_cls: 1.1119  decode.d8.loss_mask: 0.7169  decode.d8.loss_dice: 0.9621
2023/05/24 02:59:55 - mmengine - INFO - Iter(train) [ 70850/160000]  lr: 5.9075e-06  eta: 10:37:28  time: 0.4184  data_time: 0.0104  memory: 4839  grad_norm: 112.9411  loss: 39.9982  decode.loss_cls: 1.3321  decode.loss_mask: 0.8846  decode.loss_dice: 1.4641  decode.d0.loss_cls: 3.4072  decode.d0.loss_mask: 0.9040  decode.d0.loss_dice: 1.7290  decode.d1.loss_cls: 1.5761  decode.d1.loss_mask: 0.8899  decode.d1.loss_dice: 1.6111  decode.d2.loss_cls: 1.5013  decode.d2.loss_mask: 0.8663  decode.d2.loss_dice: 1.5332  decode.d3.loss_cls: 1.4912  decode.d3.loss_mask: 0.8496  decode.d3.loss_dice: 1.4883  decode.d4.loss_cls: 1.4149  decode.d4.loss_mask: 0.8357  decode.d4.loss_dice: 1.4571  decode.d5.loss_cls: 1.3291  decode.d5.loss_mask: 0.8638  decode.d5.loss_dice: 1.5069  decode.d6.loss_cls: 1.3703  decode.d6.loss_mask: 0.8761  decode.d6.loss_dice: 1.4292  decode.d7.loss_cls: 1.3531  decode.d7.loss_mask: 0.8722  decode.d7.loss_dice: 1.4487  decode.d8.loss_cls: 1.3713  decode.d8.loss_mask: 0.8728  decode.d8.loss_dice: 1.4688
2023/05/24 03:00:16 - mmengine - INFO - Iter(train) [ 70900/160000]  lr: 5.9045e-06  eta: 10:37:06  time: 0.4120  data_time: 0.0102  memory: 4823  grad_norm: 137.5292  loss: 25.3886  decode.loss_cls: 0.9535  decode.loss_mask: 0.6139  decode.loss_dice: 0.6686  decode.d0.loss_cls: 2.7334  decode.d0.loss_mask: 0.7924  decode.d0.loss_dice: 0.9099  decode.d1.loss_cls: 1.0076  decode.d1.loss_mask: 0.7316  decode.d1.loss_dice: 0.8088  decode.d2.loss_cls: 1.0086  decode.d2.loss_mask: 0.7027  decode.d2.loss_dice: 0.7521  decode.d3.loss_cls: 0.9332  decode.d3.loss_mask: 0.6616  decode.d3.loss_dice: 0.7465  decode.d4.loss_cls: 0.9204  decode.d4.loss_mask: 0.6705  decode.d4.loss_dice: 0.7013  decode.d5.loss_cls: 0.8917  decode.d5.loss_mask: 0.6868  decode.d5.loss_dice: 0.7102  decode.d6.loss_cls: 0.8839  decode.d6.loss_mask: 0.6330  decode.d6.loss_dice: 0.7326  decode.d7.loss_cls: 0.9621  decode.d7.loss_mask: 0.6362  decode.d7.loss_dice: 0.6969  decode.d8.loss_cls: 0.9401  decode.d8.loss_mask: 0.6155  decode.d8.loss_dice: 0.6830
2023/05/24 03:00:37 - mmengine - INFO - Iter(train) [ 70950/160000]  lr: 5.9015e-06  eta: 10:36:44  time: 0.4071  data_time: 0.0102  memory: 4802  grad_norm: 84.2448  loss: 37.0321  decode.loss_cls: 1.1833  decode.loss_mask: 0.8910  decode.loss_dice: 1.3153  decode.d0.loss_cls: 3.1338  decode.d0.loss_mask: 0.8974  decode.d0.loss_dice: 1.5099  decode.d1.loss_cls: 1.2635  decode.d1.loss_mask: 0.9259  decode.d1.loss_dice: 1.4701  decode.d2.loss_cls: 1.2099  decode.d2.loss_mask: 0.9313  decode.d2.loss_dice: 1.4450  decode.d3.loss_cls: 1.2367  decode.d3.loss_mask: 0.9344  decode.d3.loss_dice: 1.3509  decode.d4.loss_cls: 1.1736  decode.d4.loss_mask: 0.9393  decode.d4.loss_dice: 1.3973  decode.d5.loss_cls: 1.1470  decode.d5.loss_mask: 0.9550  decode.d5.loss_dice: 1.3821  decode.d6.loss_cls: 1.1656  decode.d6.loss_mask: 0.9163  decode.d6.loss_dice: 1.3493  decode.d7.loss_cls: 1.2321  decode.d7.loss_mask: 0.8993  decode.d7.loss_dice: 1.3503  decode.d8.loss_cls: 1.1927  decode.d8.loss_mask: 0.8992  decode.d8.loss_dice: 1.3347
2023/05/24 03:00:57 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 03:00:57 - mmengine - INFO - Iter(train) [ 71000/160000]  lr: 5.8986e-06  eta: 10:36:21  time: 0.4122  data_time: 0.0102  memory: 4919  grad_norm: 88.9313  loss: 31.1690  decode.loss_cls: 1.2339  decode.loss_mask: 0.6343  decode.loss_dice: 1.0722  decode.d0.loss_cls: 2.9732  decode.d0.loss_mask: 0.7203  decode.d0.loss_dice: 1.2876  decode.d1.loss_cls: 1.1970  decode.d1.loss_mask: 0.6458  decode.d1.loss_dice: 1.1407  decode.d2.loss_cls: 1.1492  decode.d2.loss_mask: 0.6588  decode.d2.loss_dice: 1.1383  decode.d3.loss_cls: 1.1201  decode.d3.loss_mask: 0.6510  decode.d3.loss_dice: 1.1017  decode.d4.loss_cls: 1.1458  decode.d4.loss_mask: 0.6448  decode.d4.loss_dice: 1.1218  decode.d5.loss_cls: 1.1572  decode.d5.loss_mask: 0.6328  decode.d5.loss_dice: 1.0908  decode.d6.loss_cls: 1.1318  decode.d6.loss_mask: 0.6336  decode.d6.loss_dice: 1.0894  decode.d7.loss_cls: 1.1716  decode.d7.loss_mask: 0.6366  decode.d7.loss_dice: 1.1044  decode.d8.loss_cls: 1.1893  decode.d8.loss_mask: 0.6274  decode.d8.loss_dice: 1.0676
2023/05/24 03:00:57 - mmengine - INFO - Saving checkpoint at 71000 iterations
2023/05/24 03:01:24 - mmengine - INFO - Iter(train) [ 71050/160000]  lr: 5.8956e-06  eta: 10:36:06  time: 0.4209  data_time: 0.0105  memory: 4804  grad_norm: 82.6757  loss: 30.3126  decode.loss_cls: 0.9240  decode.loss_mask: 0.7288  decode.loss_dice: 1.0975  decode.d0.loss_cls: 2.7342  decode.d0.loss_mask: 0.7690  decode.d0.loss_dice: 1.2508  decode.d1.loss_cls: 1.0714  decode.d1.loss_mask: 0.7758  decode.d1.loss_dice: 1.1914  decode.d2.loss_cls: 0.9932  decode.d2.loss_mask: 0.7565  decode.d2.loss_dice: 1.1253  decode.d3.loss_cls: 0.9916  decode.d3.loss_mask: 0.7528  decode.d3.loss_dice: 1.1353  decode.d4.loss_cls: 0.9842  decode.d4.loss_mask: 0.7464  decode.d4.loss_dice: 1.1386  decode.d5.loss_cls: 0.9803  decode.d5.loss_mask: 0.7221  decode.d5.loss_dice: 1.1034  decode.d6.loss_cls: 0.9541  decode.d6.loss_mask: 0.7438  decode.d6.loss_dice: 1.1246  decode.d7.loss_cls: 0.9516  decode.d7.loss_mask: 0.7145  decode.d7.loss_dice: 1.1001  decode.d8.loss_cls: 0.9332  decode.d8.loss_mask: 0.7209  decode.d8.loss_dice: 1.0972
2023/05/24 03:01:45 - mmengine - INFO - Iter(train) [ 71100/160000]  lr: 5.8926e-06  eta: 10:35:44  time: 0.4361  data_time: 0.0102  memory: 4850  grad_norm: 99.7332  loss: 31.4954  decode.loss_cls: 1.0800  decode.loss_mask: 0.6503  decode.loss_dice: 1.1017  decode.d0.loss_cls: 3.3094  decode.d0.loss_mask: 0.7369  decode.d0.loss_dice: 1.3752  decode.d1.loss_cls: 1.2988  decode.d1.loss_mask: 0.6790  decode.d1.loss_dice: 1.2127  decode.d2.loss_cls: 1.1630  decode.d2.loss_mask: 0.6689  decode.d2.loss_dice: 1.1725  decode.d3.loss_cls: 1.0801  decode.d3.loss_mask: 0.6733  decode.d3.loss_dice: 1.1064  decode.d4.loss_cls: 1.0588  decode.d4.loss_mask: 0.6657  decode.d4.loss_dice: 1.0614  decode.d5.loss_cls: 1.1290  decode.d5.loss_mask: 0.6637  decode.d5.loss_dice: 1.1105  decode.d6.loss_cls: 1.0630  decode.d6.loss_mask: 0.6438  decode.d6.loss_dice: 1.1122  decode.d7.loss_cls: 1.0792  decode.d7.loss_mask: 0.6501  decode.d7.loss_dice: 1.1024  decode.d8.loss_cls: 1.1160  decode.d8.loss_mask: 0.6538  decode.d8.loss_dice: 1.0774
2023/05/24 03:02:06 - mmengine - INFO - Iter(train) [ 71150/160000]  lr: 5.8896e-06  eta: 10:35:23  time: 0.4288  data_time: 0.0103  memory: 4859  grad_norm: 89.3161  loss: 40.6105  decode.loss_cls: 1.4516  decode.loss_mask: 0.7881  decode.loss_dice: 1.4987  decode.d0.loss_cls: 3.3877  decode.d0.loss_mask: 0.8233  decode.d0.loss_dice: 1.6657  decode.d1.loss_cls: 1.5818  decode.d1.loss_mask: 0.8842  decode.d1.loss_dice: 1.6359  decode.d2.loss_cls: 1.5055  decode.d2.loss_mask: 0.8491  decode.d2.loss_dice: 1.5391  decode.d3.loss_cls: 1.5164  decode.d3.loss_mask: 0.8347  decode.d3.loss_dice: 1.5497  decode.d4.loss_cls: 1.5033  decode.d4.loss_mask: 0.8473  decode.d4.loss_dice: 1.5558  decode.d5.loss_cls: 1.4336  decode.d5.loss_mask: 0.8374  decode.d5.loss_dice: 1.5221  decode.d6.loss_cls: 1.5211  decode.d6.loss_mask: 0.7994  decode.d6.loss_dice: 1.5221  decode.d7.loss_cls: 1.4672  decode.d7.loss_mask: 0.8018  decode.d7.loss_dice: 1.5119  decode.d8.loss_cls: 1.4740  decode.d8.loss_mask: 0.8058  decode.d8.loss_dice: 1.4959
2023/05/24 03:02:27 - mmengine - INFO - Iter(train) [ 71200/160000]  lr: 5.8866e-06  eta: 10:35:00  time: 0.4183  data_time: 0.0103  memory: 4865  grad_norm: 87.8704  loss: 34.2763  decode.loss_cls: 1.0985  decode.loss_mask: 0.7268  decode.loss_dice: 1.3485  decode.d0.loss_cls: 2.9989  decode.d0.loss_mask: 0.7471  decode.d0.loss_dice: 1.4827  decode.d1.loss_cls: 1.2496  decode.d1.loss_mask: 0.7354  decode.d1.loss_dice: 1.4004  decode.d2.loss_cls: 1.2653  decode.d2.loss_mask: 0.6862  decode.d2.loss_dice: 1.3388  decode.d3.loss_cls: 1.1986  decode.d3.loss_mask: 0.7303  decode.d3.loss_dice: 1.3284  decode.d4.loss_cls: 1.2262  decode.d4.loss_mask: 0.7079  decode.d4.loss_dice: 1.3237  decode.d5.loss_cls: 1.1313  decode.d5.loss_mask: 0.7035  decode.d5.loss_dice: 1.3547  decode.d6.loss_cls: 1.1144  decode.d6.loss_mask: 0.7236  decode.d6.loss_dice: 1.3460  decode.d7.loss_cls: 1.0976  decode.d7.loss_mask: 0.7080  decode.d7.loss_dice: 1.3302  decode.d8.loss_cls: 1.1442  decode.d8.loss_mask: 0.6973  decode.d8.loss_dice: 1.3324
2023/05/24 03:02:48 - mmengine - INFO - Iter(train) [ 71250/160000]  lr: 5.8836e-06  eta: 10:34:39  time: 0.4157  data_time: 0.0109  memory: 4883  grad_norm: 85.9578  loss: 36.0886  decode.loss_cls: 1.5502  decode.loss_mask: 0.6150  decode.loss_dice: 1.1851  decode.d0.loss_cls: 3.4583  decode.d0.loss_mask: 0.6862  decode.d0.loss_dice: 1.4202  decode.d1.loss_cls: 1.5144  decode.d1.loss_mask: 0.6747  decode.d1.loss_dice: 1.3667  decode.d2.loss_cls: 1.6029  decode.d2.loss_mask: 0.6435  decode.d2.loss_dice: 1.2469  decode.d3.loss_cls: 1.5503  decode.d3.loss_mask: 0.6399  decode.d3.loss_dice: 1.2002  decode.d4.loss_cls: 1.5003  decode.d4.loss_mask: 0.6231  decode.d4.loss_dice: 1.2158  decode.d5.loss_cls: 1.5277  decode.d5.loss_mask: 0.6325  decode.d5.loss_dice: 1.2065  decode.d6.loss_cls: 1.5123  decode.d6.loss_mask: 0.6279  decode.d6.loss_dice: 1.1651  decode.d7.loss_cls: 1.5836  decode.d7.loss_mask: 0.6200  decode.d7.loss_dice: 1.1870  decode.d8.loss_cls: 1.5154  decode.d8.loss_mask: 0.6316  decode.d8.loss_dice: 1.1851
2023/05/24 03:03:11 - mmengine - INFO - Iter(train) [ 71300/160000]  lr: 5.8807e-06  eta: 10:34:19  time: 0.4719  data_time: 0.0098  memory: 4802  grad_norm: 97.7393  loss: 36.3149  decode.loss_cls: 1.2638  decode.loss_mask: 0.7362  decode.loss_dice: 1.3388  decode.d0.loss_cls: 3.3019  decode.d0.loss_mask: 0.7796  decode.d0.loss_dice: 1.4698  decode.d1.loss_cls: 1.4656  decode.d1.loss_mask: 0.7476  decode.d1.loss_dice: 1.4031  decode.d2.loss_cls: 1.3471  decode.d2.loss_mask: 0.7214  decode.d2.loss_dice: 1.3420  decode.d3.loss_cls: 1.3937  decode.d3.loss_mask: 0.7124  decode.d3.loss_dice: 1.3393  decode.d4.loss_cls: 1.3392  decode.d4.loss_mask: 0.7089  decode.d4.loss_dice: 1.3233  decode.d5.loss_cls: 1.3525  decode.d5.loss_mask: 0.7056  decode.d5.loss_dice: 1.3384  decode.d6.loss_cls: 1.3868  decode.d6.loss_mask: 0.6973  decode.d6.loss_dice: 1.3365  decode.d7.loss_cls: 1.3196  decode.d7.loss_mask: 0.7040  decode.d7.loss_dice: 1.3460  decode.d8.loss_cls: 1.2883  decode.d8.loss_mask: 0.7496  decode.d8.loss_dice: 1.3566
2023/05/24 03:03:33 - mmengine - INFO - Iter(train) [ 71350/160000]  lr: 5.8777e-06  eta: 10:33:58  time: 0.4185  data_time: 0.0103  memory: 4836  grad_norm: 106.9577  loss: 41.0014  decode.loss_cls: 1.2074  decode.loss_mask: 0.9630  decode.loss_dice: 1.6401  decode.d0.loss_cls: 3.3497  decode.d0.loss_mask: 0.9524  decode.d0.loss_dice: 1.8353  decode.d1.loss_cls: 1.5130  decode.d1.loss_mask: 0.9218  decode.d1.loss_dice: 1.6408  decode.d2.loss_cls: 1.3255  decode.d2.loss_mask: 0.9562  decode.d2.loss_dice: 1.6852  decode.d3.loss_cls: 1.2454  decode.d3.loss_mask: 0.9945  decode.d3.loss_dice: 1.6700  decode.d4.loss_cls: 1.2747  decode.d4.loss_mask: 0.9333  decode.d4.loss_dice: 1.6633  decode.d5.loss_cls: 1.2265  decode.d5.loss_mask: 0.9306  decode.d5.loss_dice: 1.6636  decode.d6.loss_cls: 1.2336  decode.d6.loss_mask: 0.9450  decode.d6.loss_dice: 1.6605  decode.d7.loss_cls: 1.2048  decode.d7.loss_mask: 0.9510  decode.d7.loss_dice: 1.6415  decode.d8.loss_cls: 1.1737  decode.d8.loss_mask: 0.9624  decode.d8.loss_dice: 1.6366
2023/05/24 03:03:54 - mmengine - INFO - Iter(train) [ 71400/160000]  lr: 5.8747e-06  eta: 10:33:36  time: 0.4153  data_time: 0.0104  memory: 4886  grad_norm: 89.6887  loss: 44.4076  decode.loss_cls: 1.5306  decode.loss_mask: 0.8915  decode.loss_dice: 1.6837  decode.d0.loss_cls: 3.5753  decode.d0.loss_mask: 0.9624  decode.d0.loss_dice: 2.0815  decode.d1.loss_cls: 1.5709  decode.d1.loss_mask: 0.9451  decode.d1.loss_dice: 1.8560  decode.d2.loss_cls: 1.6101  decode.d2.loss_mask: 0.9221  decode.d2.loss_dice: 1.8597  decode.d3.loss_cls: 1.5921  decode.d3.loss_mask: 0.9394  decode.d3.loss_dice: 1.7088  decode.d4.loss_cls: 1.5042  decode.d4.loss_mask: 0.9494  decode.d4.loss_dice: 1.7738  decode.d5.loss_cls: 1.5410  decode.d5.loss_mask: 0.8641  decode.d5.loss_dice: 1.7314  decode.d6.loss_cls: 1.5125  decode.d6.loss_mask: 0.8537  decode.d6.loss_dice: 1.6959  decode.d7.loss_cls: 1.5332  decode.d7.loss_mask: 0.8875  decode.d7.loss_dice: 1.7105  decode.d8.loss_cls: 1.5210  decode.d8.loss_mask: 0.8993  decode.d8.loss_dice: 1.7010
2023/05/24 03:04:16 - mmengine - INFO - Iter(train) [ 71450/160000]  lr: 5.8717e-06  eta: 10:33:15  time: 0.4706  data_time: 0.0099  memory: 4815  grad_norm: 113.9966  loss: 27.3613  decode.loss_cls: 1.1103  decode.loss_mask: 0.5555  decode.loss_dice: 0.9200  decode.d0.loss_cls: 2.6261  decode.d0.loss_mask: 0.6222  decode.d0.loss_dice: 1.0580  decode.d1.loss_cls: 1.1353  decode.d1.loss_mask: 0.5807  decode.d1.loss_dice: 1.0086  decode.d2.loss_cls: 1.0580  decode.d2.loss_mask: 0.5492  decode.d2.loss_dice: 0.9563  decode.d3.loss_cls: 1.1302  decode.d3.loss_mask: 0.5422  decode.d3.loss_dice: 0.8939  decode.d4.loss_cls: 1.0948  decode.d4.loss_mask: 0.5326  decode.d4.loss_dice: 0.9051  decode.d5.loss_cls: 1.0771  decode.d5.loss_mask: 0.5386  decode.d5.loss_dice: 0.8743  decode.d6.loss_cls: 1.0897  decode.d6.loss_mask: 0.5359  decode.d6.loss_dice: 0.9214  decode.d7.loss_cls: 1.0951  decode.d7.loss_mask: 0.5261  decode.d7.loss_dice: 0.9186  decode.d8.loss_cls: 1.0772  decode.d8.loss_mask: 0.5304  decode.d8.loss_dice: 0.8979
2023/05/24 03:04:38 - mmengine - INFO - Iter(train) [ 71500/160000]  lr: 5.8687e-06  eta: 10:32:54  time: 0.4656  data_time: 0.0105  memory: 4822  grad_norm: 93.9917  loss: 44.4996  decode.loss_cls: 1.7028  decode.loss_mask: 0.9095  decode.loss_dice: 1.4692  decode.d0.loss_cls: 3.7572  decode.d0.loss_mask: 0.9497  decode.d0.loss_dice: 1.8055  decode.d1.loss_cls: 1.8715  decode.d1.loss_mask: 0.9997  decode.d1.loss_dice: 1.5873  decode.d2.loss_cls: 1.8101  decode.d2.loss_mask: 0.9706  decode.d2.loss_dice: 1.5512  decode.d3.loss_cls: 1.7887  decode.d3.loss_mask: 0.9338  decode.d3.loss_dice: 1.5216  decode.d4.loss_cls: 1.7516  decode.d4.loss_mask: 0.9382  decode.d4.loss_dice: 1.5531  decode.d5.loss_cls: 1.7115  decode.d5.loss_mask: 0.9410  decode.d5.loss_dice: 1.5544  decode.d6.loss_cls: 1.7461  decode.d6.loss_mask: 0.9202  decode.d6.loss_dice: 1.5157  decode.d7.loss_cls: 1.6970  decode.d7.loss_mask: 0.9471  decode.d7.loss_dice: 1.5061  decode.d8.loss_cls: 1.6806  decode.d8.loss_mask: 0.9156  decode.d8.loss_dice: 1.4932
2023/05/24 03:04:59 - mmengine - INFO - Iter(train) [ 71550/160000]  lr: 5.8657e-06  eta: 10:32:32  time: 0.4130  data_time: 0.0104  memory: 4839  grad_norm: 128.0567  loss: 38.5613  decode.loss_cls: 1.2916  decode.loss_mask: 1.0455  decode.loss_dice: 1.2268  decode.d0.loss_cls: 3.2725  decode.d0.loss_mask: 1.0514  decode.d0.loss_dice: 1.3604  decode.d1.loss_cls: 1.3693  decode.d1.loss_mask: 1.1027  decode.d1.loss_dice: 1.3766  decode.d2.loss_cls: 1.3097  decode.d2.loss_mask: 1.0974  decode.d2.loss_dice: 1.2858  decode.d3.loss_cls: 1.3469  decode.d3.loss_mask: 1.0555  decode.d3.loss_dice: 1.2717  decode.d4.loss_cls: 1.3230  decode.d4.loss_mask: 1.0464  decode.d4.loss_dice: 1.2799  decode.d5.loss_cls: 1.3664  decode.d5.loss_mask: 1.0530  decode.d5.loss_dice: 1.2221  decode.d6.loss_cls: 1.3071  decode.d6.loss_mask: 1.0716  decode.d6.loss_dice: 1.2270  decode.d7.loss_cls: 1.3118  decode.d7.loss_mask: 1.0623  decode.d7.loss_dice: 1.2253  decode.d8.loss_cls: 1.2982  decode.d8.loss_mask: 1.0721  decode.d8.loss_dice: 1.2314
2023/05/24 03:05:20 - mmengine - INFO - Iter(train) [ 71600/160000]  lr: 5.8628e-06  eta: 10:32:10  time: 0.4106  data_time: 0.0108  memory: 4866  grad_norm: 100.5291  loss: 27.0101  decode.loss_cls: 0.8618  decode.loss_mask: 0.5662  decode.loss_dice: 1.0090  decode.d0.loss_cls: 2.7395  decode.d0.loss_mask: 0.6127  decode.d0.loss_dice: 1.1983  decode.d1.loss_cls: 0.9615  decode.d1.loss_mask: 0.5845  decode.d1.loss_dice: 1.0820  decode.d2.loss_cls: 0.9195  decode.d2.loss_mask: 0.5753  decode.d2.loss_dice: 1.0720  decode.d3.loss_cls: 0.8243  decode.d3.loss_mask: 0.5697  decode.d3.loss_dice: 1.0522  decode.d4.loss_cls: 0.8613  decode.d4.loss_mask: 0.5673  decode.d4.loss_dice: 1.0487  decode.d5.loss_cls: 0.8651  decode.d5.loss_mask: 0.5874  decode.d5.loss_dice: 1.0306  decode.d6.loss_cls: 0.8675  decode.d6.loss_mask: 0.5869  decode.d6.loss_dice: 1.0173  decode.d7.loss_cls: 0.8683  decode.d7.loss_mask: 0.5642  decode.d7.loss_dice: 1.0250  decode.d8.loss_cls: 0.8723  decode.d8.loss_mask: 0.5763  decode.d8.loss_dice: 1.0435
2023/05/24 03:05:41 - mmengine - INFO - Iter(train) [ 71650/160000]  lr: 5.8598e-06  eta: 10:31:48  time: 0.4214  data_time: 0.0104  memory: 4822  grad_norm: 87.8787  loss: 34.6363  decode.loss_cls: 1.4245  decode.loss_mask: 0.6947  decode.loss_dice: 1.1095  decode.d0.loss_cls: 3.1485  decode.d0.loss_mask: 0.7245  decode.d0.loss_dice: 1.2418  decode.d1.loss_cls: 1.6019  decode.d1.loss_mask: 0.6928  decode.d1.loss_dice: 1.2447  decode.d2.loss_cls: 1.5227  decode.d2.loss_mask: 0.6812  decode.d2.loss_dice: 1.1588  decode.d3.loss_cls: 1.4727  decode.d3.loss_mask: 0.6819  decode.d3.loss_dice: 1.1139  decode.d4.loss_cls: 1.4526  decode.d4.loss_mask: 0.6814  decode.d4.loss_dice: 1.1200  decode.d5.loss_cls: 1.4055  decode.d5.loss_mask: 0.6831  decode.d5.loss_dice: 1.0892  decode.d6.loss_cls: 1.4482  decode.d6.loss_mask: 0.6825  decode.d6.loss_dice: 1.1085  decode.d7.loss_cls: 1.4489  decode.d7.loss_mask: 0.6911  decode.d7.loss_dice: 1.0894  decode.d8.loss_cls: 1.4473  decode.d8.loss_mask: 0.6766  decode.d8.loss_dice: 1.0981
2023/05/24 03:06:02 - mmengine - INFO - Iter(train) [ 71700/160000]  lr: 5.8568e-06  eta: 10:31:26  time: 0.4560  data_time: 0.0100  memory: 4868  grad_norm: 103.4910  loss: 31.9023  decode.loss_cls: 1.1554  decode.loss_mask: 0.6238  decode.loss_dice: 1.0994  decode.d0.loss_cls: 3.0898  decode.d0.loss_mask: 0.6513  decode.d0.loss_dice: 1.2668  decode.d1.loss_cls: 1.3418  decode.d1.loss_mask: 0.7001  decode.d1.loss_dice: 1.2244  decode.d2.loss_cls: 1.2086  decode.d2.loss_mask: 0.6451  decode.d2.loss_dice: 1.1791  decode.d3.loss_cls: 1.2517  decode.d3.loss_mask: 0.6306  decode.d3.loss_dice: 1.1002  decode.d4.loss_cls: 1.2276  decode.d4.loss_mask: 0.6262  decode.d4.loss_dice: 1.1289  decode.d5.loss_cls: 1.2482  decode.d5.loss_mask: 0.6348  decode.d5.loss_dice: 1.1167  decode.d6.loss_cls: 1.1997  decode.d6.loss_mask: 0.6489  decode.d6.loss_dice: 1.1007  decode.d7.loss_cls: 1.1672  decode.d7.loss_mask: 0.6291  decode.d7.loss_dice: 1.0915  decode.d8.loss_cls: 1.1878  decode.d8.loss_mask: 0.6210  decode.d8.loss_dice: 1.1057
2023/05/24 03:06:25 - mmengine - INFO - Iter(train) [ 71750/160000]  lr: 5.8538e-06  eta: 10:31:07  time: 0.4408  data_time: 0.0101  memory: 4804  grad_norm: 90.9779  loss: 36.6428  decode.loss_cls: 1.5289  decode.loss_mask: 0.7132  decode.loss_dice: 1.1308  decode.d0.loss_cls: 3.3172  decode.d0.loss_mask: 0.7325  decode.d0.loss_dice: 1.3785  decode.d1.loss_cls: 1.7693  decode.d1.loss_mask: 0.7599  decode.d1.loss_dice: 1.2163  decode.d2.loss_cls: 1.6973  decode.d2.loss_mask: 0.7051  decode.d2.loss_dice: 1.1444  decode.d3.loss_cls: 1.6350  decode.d3.loss_mask: 0.7213  decode.d3.loss_dice: 1.1611  decode.d4.loss_cls: 1.5855  decode.d4.loss_mask: 0.7034  decode.d4.loss_dice: 1.1433  decode.d5.loss_cls: 1.5547  decode.d5.loss_mask: 0.7108  decode.d5.loss_dice: 1.1424  decode.d6.loss_cls: 1.4783  decode.d6.loss_mask: 0.7386  decode.d6.loss_dice: 1.2073  decode.d7.loss_cls: 1.5463  decode.d7.loss_mask: 0.7040  decode.d7.loss_dice: 1.1535  decode.d8.loss_cls: 1.4900  decode.d8.loss_mask: 0.7207  decode.d8.loss_dice: 1.1534
2023/05/24 03:06:46 - mmengine - INFO - Iter(train) [ 71800/160000]  lr: 5.8508e-06  eta: 10:30:45  time: 0.4126  data_time: 0.0104  memory: 4899  grad_norm: 97.2850  loss: 41.9333  decode.loss_cls: 1.2821  decode.loss_mask: 0.9411  decode.loss_dice: 1.6549  decode.d0.loss_cls: 3.3582  decode.d0.loss_mask: 1.0001  decode.d0.loss_dice: 1.9741  decode.d1.loss_cls: 1.3317  decode.d1.loss_mask: 1.0082  decode.d1.loss_dice: 1.8322  decode.d2.loss_cls: 1.3638  decode.d2.loss_mask: 0.9559  decode.d2.loss_dice: 1.7470  decode.d3.loss_cls: 1.3158  decode.d3.loss_mask: 0.9224  decode.d3.loss_dice: 1.6926  decode.d4.loss_cls: 1.3101  decode.d4.loss_mask: 0.9586  decode.d4.loss_dice: 1.6960  decode.d5.loss_cls: 1.2916  decode.d5.loss_mask: 0.9769  decode.d5.loss_dice: 1.6879  decode.d6.loss_cls: 1.2621  decode.d6.loss_mask: 0.9538  decode.d6.loss_dice: 1.6717  decode.d7.loss_cls: 1.2789  decode.d7.loss_mask: 0.9361  decode.d7.loss_dice: 1.6601  decode.d8.loss_cls: 1.2530  decode.d8.loss_mask: 0.9542  decode.d8.loss_dice: 1.6621
2023/05/24 03:07:07 - mmengine - INFO - Iter(train) [ 71850/160000]  lr: 5.8478e-06  eta: 10:30:22  time: 0.4106  data_time: 0.0105  memory: 4893  grad_norm: 129.6697  loss: 37.8310  decode.loss_cls: 1.3228  decode.loss_mask: 0.8478  decode.loss_dice: 1.3164  decode.d0.loss_cls: 3.4498  decode.d0.loss_mask: 0.9815  decode.d0.loss_dice: 1.6438  decode.d1.loss_cls: 1.4630  decode.d1.loss_mask: 0.9157  decode.d1.loss_dice: 1.4463  decode.d2.loss_cls: 1.3048  decode.d2.loss_mask: 0.8587  decode.d2.loss_dice: 1.4125  decode.d3.loss_cls: 1.2876  decode.d3.loss_mask: 0.8054  decode.d3.loss_dice: 1.3330  decode.d4.loss_cls: 1.3226  decode.d4.loss_mask: 0.8354  decode.d4.loss_dice: 1.3320  decode.d5.loss_cls: 1.3045  decode.d5.loss_mask: 0.8600  decode.d5.loss_dice: 1.3309  decode.d6.loss_cls: 1.3365  decode.d6.loss_mask: 0.8475  decode.d6.loss_dice: 1.3194  decode.d7.loss_cls: 1.2641  decode.d7.loss_mask: 0.8602  decode.d7.loss_dice: 1.3492  decode.d8.loss_cls: 1.2577  decode.d8.loss_mask: 0.8637  decode.d8.loss_dice: 1.3582
2023/05/24 03:07:28 - mmengine - INFO - Iter(train) [ 71900/160000]  lr: 5.8448e-06  eta: 10:30:00  time: 0.4228  data_time: 0.0104  memory: 4845  grad_norm: 160.0728  loss: 33.6671  decode.loss_cls: 1.0470  decode.loss_mask: 0.7719  decode.loss_dice: 1.2108  decode.d0.loss_cls: 3.2855  decode.d0.loss_mask: 0.7185  decode.d0.loss_dice: 1.3858  decode.d1.loss_cls: 1.2639  decode.d1.loss_mask: 0.8110  decode.d1.loss_dice: 1.3431  decode.d2.loss_cls: 1.2380  decode.d2.loss_mask: 0.7945  decode.d2.loss_dice: 1.2396  decode.d3.loss_cls: 1.2254  decode.d3.loss_mask: 0.7870  decode.d3.loss_dice: 1.1801  decode.d4.loss_cls: 1.1896  decode.d4.loss_mask: 0.7810  decode.d4.loss_dice: 1.1832  decode.d5.loss_cls: 1.1060  decode.d5.loss_mask: 0.7644  decode.d5.loss_dice: 1.1744  decode.d6.loss_cls: 1.0976  decode.d6.loss_mask: 0.7672  decode.d6.loss_dice: 1.1978  decode.d7.loss_cls: 1.0942  decode.d7.loss_mask: 0.7653  decode.d7.loss_dice: 1.1797  decode.d8.loss_cls: 1.1063  decode.d8.loss_mask: 0.7684  decode.d8.loss_dice: 1.1898
2023/05/24 03:07:49 - mmengine - INFO - Iter(train) [ 71950/160000]  lr: 5.8419e-06  eta: 10:29:39  time: 0.4235  data_time: 0.0110  memory: 4882  grad_norm: 96.3555  loss: 31.7109  decode.loss_cls: 1.1236  decode.loss_mask: 0.6155  decode.loss_dice: 1.1603  decode.d0.loss_cls: 3.0256  decode.d0.loss_mask: 0.6194  decode.d0.loss_dice: 1.3385  decode.d1.loss_cls: 1.3166  decode.d1.loss_mask: 0.6314  decode.d1.loss_dice: 1.2490  decode.d2.loss_cls: 1.2372  decode.d2.loss_mask: 0.6171  decode.d2.loss_dice: 1.1545  decode.d3.loss_cls: 1.2237  decode.d3.loss_mask: 0.5989  decode.d3.loss_dice: 1.1449  decode.d4.loss_cls: 1.2105  decode.d4.loss_mask: 0.6020  decode.d4.loss_dice: 1.1107  decode.d5.loss_cls: 1.1311  decode.d5.loss_mask: 0.6587  decode.d5.loss_dice: 1.1593  decode.d6.loss_cls: 1.1634  decode.d6.loss_mask: 0.6309  decode.d6.loss_dice: 1.1245  decode.d7.loss_cls: 1.1742  decode.d7.loss_mask: 0.6329  decode.d7.loss_dice: 1.1250  decode.d8.loss_cls: 1.1594  decode.d8.loss_mask: 0.6246  decode.d8.loss_dice: 1.1475
2023/05/24 03:08:10 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 03:08:10 - mmengine - INFO - Iter(train) [ 72000/160000]  lr: 5.8389e-06  eta: 10:29:17  time: 0.4713  data_time: 0.0100  memory: 4882  grad_norm: 96.5198  loss: 31.1445  decode.loss_cls: 0.9774  decode.loss_mask: 0.7641  decode.loss_dice: 1.0447  decode.d0.loss_cls: 2.9900  decode.d0.loss_mask: 0.7491  decode.d0.loss_dice: 1.2480  decode.d1.loss_cls: 1.1394  decode.d1.loss_mask: 0.7613  decode.d1.loss_dice: 1.1741  decode.d2.loss_cls: 1.1357  decode.d2.loss_mask: 0.7835  decode.d2.loss_dice: 1.1089  decode.d3.loss_cls: 1.0543  decode.d3.loss_mask: 0.7602  decode.d3.loss_dice: 1.0902  decode.d4.loss_cls: 1.1262  decode.d4.loss_mask: 0.7501  decode.d4.loss_dice: 1.0631  decode.d5.loss_cls: 1.1130  decode.d5.loss_mask: 0.7605  decode.d5.loss_dice: 1.0540  decode.d6.loss_cls: 1.0541  decode.d6.loss_mask: 0.7669  decode.d6.loss_dice: 1.0405  decode.d7.loss_cls: 0.9916  decode.d7.loss_mask: 0.7867  decode.d7.loss_dice: 1.0400  decode.d8.loss_cls: 1.0367  decode.d8.loss_mask: 0.7572  decode.d8.loss_dice: 1.0231
2023/05/24 03:08:11 - mmengine - INFO - Saving checkpoint at 72000 iterations
2023/05/24 03:08:37 - mmengine - INFO - Iter(train) [ 72050/160000]  lr: 5.8359e-06  eta: 10:29:02  time: 0.4260  data_time: 0.0101  memory: 4837  grad_norm: 104.7693  loss: 37.5017  decode.loss_cls: 1.3067  decode.loss_mask: 0.7488  decode.loss_dice: 1.3985  decode.d0.loss_cls: 2.9396  decode.d0.loss_mask: 0.8549  decode.d0.loss_dice: 1.6549  decode.d1.loss_cls: 1.4232  decode.d1.loss_mask: 0.8260  decode.d1.loss_dice: 1.4980  decode.d2.loss_cls: 1.3035  decode.d2.loss_mask: 0.8368  decode.d2.loss_dice: 1.5027  decode.d3.loss_cls: 1.3411  decode.d3.loss_mask: 0.8215  decode.d3.loss_dice: 1.4589  decode.d4.loss_cls: 1.2951  decode.d4.loss_mask: 0.7986  decode.d4.loss_dice: 1.4648  decode.d5.loss_cls: 1.2700  decode.d5.loss_mask: 0.7791  decode.d5.loss_dice: 1.4726  decode.d6.loss_cls: 1.3810  decode.d6.loss_mask: 0.7512  decode.d6.loss_dice: 1.3729  decode.d7.loss_cls: 1.3505  decode.d7.loss_mask: 0.7542  decode.d7.loss_dice: 1.4111  decode.d8.loss_cls: 1.3321  decode.d8.loss_mask: 0.7642  decode.d8.loss_dice: 1.3892
2023/05/24 03:08:59 - mmengine - INFO - Iter(train) [ 72100/160000]  lr: 5.8329e-06  eta: 10:28:41  time: 0.4203  data_time: 0.0103  memory: 4815  grad_norm: 99.4445  loss: 37.8531  decode.loss_cls: 1.1229  decode.loss_mask: 0.9856  decode.loss_dice: 1.4325  decode.d0.loss_cls: 3.0453  decode.d0.loss_mask: 1.0142  decode.d0.loss_dice: 1.6084  decode.d1.loss_cls: 1.1796  decode.d1.loss_mask: 1.0246  decode.d1.loss_dice: 1.5325  decode.d2.loss_cls: 1.1779  decode.d2.loss_mask: 1.0029  decode.d2.loss_dice: 1.4863  decode.d3.loss_cls: 1.1630  decode.d3.loss_mask: 1.0326  decode.d3.loss_dice: 1.4392  decode.d4.loss_cls: 1.1311  decode.d4.loss_mask: 1.0073  decode.d4.loss_dice: 1.4603  decode.d5.loss_cls: 1.0851  decode.d5.loss_mask: 0.9931  decode.d5.loss_dice: 1.4161  decode.d6.loss_cls: 1.1100  decode.d6.loss_mask: 0.9934  decode.d6.loss_dice: 1.4222  decode.d7.loss_cls: 1.0603  decode.d7.loss_mask: 0.9830  decode.d7.loss_dice: 1.4342  decode.d8.loss_cls: 1.1070  decode.d8.loss_mask: 0.9689  decode.d8.loss_dice: 1.4334
2023/05/24 03:09:20 - mmengine - INFO - Iter(train) [ 72150/160000]  lr: 5.8299e-06  eta: 10:28:19  time: 0.4274  data_time: 0.0102  memory: 4937  grad_norm: 90.9109  loss: 39.3664  decode.loss_cls: 1.2302  decode.loss_mask: 0.7897  decode.loss_dice: 1.5798  decode.d0.loss_cls: 3.4403  decode.d0.loss_mask: 0.9473  decode.d0.loss_dice: 1.9071  decode.d1.loss_cls: 1.4782  decode.d1.loss_mask: 0.8205  decode.d1.loss_dice: 1.6496  decode.d2.loss_cls: 1.3498  decode.d2.loss_mask: 0.8133  decode.d2.loss_dice: 1.5989  decode.d3.loss_cls: 1.2481  decode.d3.loss_mask: 0.8198  decode.d3.loss_dice: 1.5589  decode.d4.loss_cls: 1.2435  decode.d4.loss_mask: 0.8119  decode.d4.loss_dice: 1.5696  decode.d5.loss_cls: 1.2819  decode.d5.loss_mask: 0.7839  decode.d5.loss_dice: 1.5910  decode.d6.loss_cls: 1.2612  decode.d6.loss_mask: 0.7820  decode.d6.loss_dice: 1.5595  decode.d7.loss_cls: 1.2262  decode.d7.loss_mask: 0.8088  decode.d7.loss_dice: 1.6000  decode.d8.loss_cls: 1.2482  decode.d8.loss_mask: 0.7904  decode.d8.loss_dice: 1.5768
2023/05/24 03:09:42 - mmengine - INFO - Iter(train) [ 72200/160000]  lr: 5.8269e-06  eta: 10:27:58  time: 0.4618  data_time: 0.0102  memory: 4857  grad_norm: 87.2634  loss: 34.4908  decode.loss_cls: 1.0722  decode.loss_mask: 0.8039  decode.loss_dice: 1.2926  decode.d0.loss_cls: 2.8611  decode.d0.loss_mask: 0.8246  decode.d0.loss_dice: 1.4427  decode.d1.loss_cls: 1.1531  decode.d1.loss_mask: 0.8776  decode.d1.loss_dice: 1.4323  decode.d2.loss_cls: 1.1061  decode.d2.loss_mask: 0.8556  decode.d2.loss_dice: 1.3693  decode.d3.loss_cls: 1.1029  decode.d3.loss_mask: 0.8360  decode.d3.loss_dice: 1.3329  decode.d4.loss_cls: 1.0918  decode.d4.loss_mask: 0.8231  decode.d4.loss_dice: 1.3232  decode.d5.loss_cls: 1.0607  decode.d5.loss_mask: 0.8121  decode.d5.loss_dice: 1.3518  decode.d6.loss_cls: 1.0829  decode.d6.loss_mask: 0.8214  decode.d6.loss_dice: 1.3236  decode.d7.loss_cls: 1.0362  decode.d7.loss_mask: 0.8271  decode.d7.loss_dice: 1.3459  decode.d8.loss_cls: 1.0912  decode.d8.loss_mask: 0.8263  decode.d8.loss_dice: 1.3108
2023/05/24 03:10:04 - mmengine - INFO - Iter(train) [ 72250/160000]  lr: 5.8239e-06  eta: 10:27:37  time: 0.4165  data_time: 0.0103  memory: 4879  grad_norm: 87.2827  loss: 33.3170  decode.loss_cls: 1.1874  decode.loss_mask: 0.6560  decode.loss_dice: 1.1901  decode.d0.loss_cls: 3.0459  decode.d0.loss_mask: 0.7806  decode.d0.loss_dice: 1.4563  decode.d1.loss_cls: 1.3153  decode.d1.loss_mask: 0.6912  decode.d1.loss_dice: 1.3651  decode.d2.loss_cls: 1.3609  decode.d2.loss_mask: 0.6702  decode.d2.loss_dice: 1.2625  decode.d3.loss_cls: 1.2345  decode.d3.loss_mask: 0.6669  decode.d3.loss_dice: 1.2154  decode.d4.loss_cls: 1.1878  decode.d4.loss_mask: 0.6551  decode.d4.loss_dice: 1.1997  decode.d5.loss_cls: 1.2007  decode.d5.loss_mask: 0.6459  decode.d5.loss_dice: 1.2058  decode.d6.loss_cls: 1.2557  decode.d6.loss_mask: 0.6396  decode.d6.loss_dice: 1.1714  decode.d7.loss_cls: 1.2205  decode.d7.loss_mask: 0.6381  decode.d7.loss_dice: 1.1688  decode.d8.loss_cls: 1.1930  decode.d8.loss_mask: 0.6587  decode.d8.loss_dice: 1.1782
2023/05/24 03:10:25 - mmengine - INFO - Iter(train) [ 72300/160000]  lr: 5.8210e-06  eta: 10:27:15  time: 0.4208  data_time: 0.0108  memory: 4845  grad_norm: 111.1896  loss: 42.7144  decode.loss_cls: 1.3784  decode.loss_mask: 0.9671  decode.loss_dice: 1.6303  decode.d0.loss_cls: 3.0853  decode.d0.loss_mask: 1.0257  decode.d0.loss_dice: 1.9736  decode.d1.loss_cls: 1.4874  decode.d1.loss_mask: 1.0511  decode.d1.loss_dice: 1.8292  decode.d2.loss_cls: 1.5118  decode.d2.loss_mask: 1.0040  decode.d2.loss_dice: 1.6845  decode.d3.loss_cls: 1.4856  decode.d3.loss_mask: 0.9858  decode.d3.loss_dice: 1.6418  decode.d4.loss_cls: 1.4120  decode.d4.loss_mask: 0.9777  decode.d4.loss_dice: 1.6683  decode.d5.loss_cls: 1.4088  decode.d5.loss_mask: 0.9710  decode.d5.loss_dice: 1.6425  decode.d6.loss_cls: 1.4019  decode.d6.loss_mask: 0.9566  decode.d6.loss_dice: 1.5946  decode.d7.loss_cls: 1.3712  decode.d7.loss_mask: 0.9682  decode.d7.loss_dice: 1.6025  decode.d8.loss_cls: 1.3915  decode.d8.loss_mask: 0.9799  decode.d8.loss_dice: 1.6261
2023/05/24 03:10:46 - mmengine - INFO - Iter(train) [ 72350/160000]  lr: 5.8180e-06  eta: 10:26:53  time: 0.4705  data_time: 0.0105  memory: 4956  grad_norm: 454.4160  loss: 33.2865  decode.loss_cls: 1.1489  decode.loss_mask: 0.6819  decode.loss_dice: 1.2956  decode.d0.loss_cls: 2.8812  decode.d0.loss_mask: 0.6511  decode.d0.loss_dice: 1.5210  decode.d1.loss_cls: 1.1846  decode.d1.loss_mask: 0.7659  decode.d1.loss_dice: 1.3954  decode.d2.loss_cls: 1.1387  decode.d2.loss_mask: 0.6613  decode.d2.loss_dice: 1.3608  decode.d3.loss_cls: 1.1255  decode.d3.loss_mask: 0.6509  decode.d3.loss_dice: 1.3528  decode.d4.loss_cls: 1.1406  decode.d4.loss_mask: 0.5979  decode.d4.loss_dice: 1.3090  decode.d5.loss_cls: 1.1528  decode.d5.loss_mask: 0.6502  decode.d5.loss_dice: 1.3306  decode.d6.loss_cls: 1.1706  decode.d6.loss_mask: 0.6531  decode.d6.loss_dice: 1.2836  decode.d7.loss_cls: 1.1511  decode.d7.loss_mask: 0.6277  decode.d7.loss_dice: 1.3173  decode.d8.loss_cls: 1.1752  decode.d8.loss_mask: 0.6181  decode.d8.loss_dice: 1.2933
2023/05/24 03:11:07 - mmengine - INFO - Iter(train) [ 72400/160000]  lr: 5.8150e-06  eta: 10:26:31  time: 0.4115  data_time: 0.0103  memory: 4863  grad_norm: 102.1534  loss: 39.2978  decode.loss_cls: 1.1978  decode.loss_mask: 0.8705  decode.loss_dice: 1.5807  decode.d0.loss_cls: 2.9640  decode.d0.loss_mask: 0.9554  decode.d0.loss_dice: 1.8579  decode.d1.loss_cls: 1.3247  decode.d1.loss_mask: 0.8965  decode.d1.loss_dice: 1.7801  decode.d2.loss_cls: 1.2272  decode.d2.loss_mask: 0.8706  decode.d2.loss_dice: 1.6506  decode.d3.loss_cls: 1.2718  decode.d3.loss_mask: 0.8555  decode.d3.loss_dice: 1.6336  decode.d4.loss_cls: 1.1937  decode.d4.loss_mask: 0.8629  decode.d4.loss_dice: 1.6285  decode.d5.loss_cls: 1.1895  decode.d5.loss_mask: 0.8656  decode.d5.loss_dice: 1.6164  decode.d6.loss_cls: 1.2034  decode.d6.loss_mask: 0.8587  decode.d6.loss_dice: 1.5860  decode.d7.loss_cls: 1.2171  decode.d7.loss_mask: 0.8720  decode.d7.loss_dice: 1.5883  decode.d8.loss_cls: 1.2518  decode.d8.loss_mask: 0.8615  decode.d8.loss_dice: 1.5652
2023/05/24 03:11:28 - mmengine - INFO - Iter(train) [ 72450/160000]  lr: 5.8120e-06  eta: 10:26:09  time: 0.4286  data_time: 0.0104  memory: 4857  grad_norm: 94.7514  loss: 32.7289  decode.loss_cls: 1.0436  decode.loss_mask: 0.9005  decode.loss_dice: 1.1522  decode.d0.loss_cls: 2.7616  decode.d0.loss_mask: 0.9605  decode.d0.loss_dice: 1.3015  decode.d1.loss_cls: 1.0860  decode.d1.loss_mask: 0.9211  decode.d1.loss_dice: 1.2368  decode.d2.loss_cls: 1.1028  decode.d2.loss_mask: 0.8916  decode.d2.loss_dice: 1.2021  decode.d3.loss_cls: 1.0214  decode.d3.loss_mask: 0.9022  decode.d3.loss_dice: 1.1579  decode.d4.loss_cls: 1.0468  decode.d4.loss_mask: 0.8528  decode.d4.loss_dice: 1.1362  decode.d5.loss_cls: 1.0312  decode.d5.loss_mask: 0.8254  decode.d5.loss_dice: 1.1536  decode.d6.loss_cls: 1.0244  decode.d6.loss_mask: 0.8837  decode.d6.loss_dice: 1.1594  decode.d7.loss_cls: 0.9812  decode.d7.loss_mask: 0.8977  decode.d7.loss_dice: 1.1469  decode.d8.loss_cls: 0.9103  decode.d8.loss_mask: 0.9003  decode.d8.loss_dice: 1.1371
2023/05/24 03:11:49 - mmengine - INFO - Iter(train) [ 72500/160000]  lr: 5.8090e-06  eta: 10:25:47  time: 0.4138  data_time: 0.0103  memory: 4836  grad_norm: 85.3530  loss: 29.5270  decode.loss_cls: 1.0197  decode.loss_mask: 0.6090  decode.loss_dice: 1.0349  decode.d0.loss_cls: 2.9319  decode.d0.loss_mask: 0.6777  decode.d0.loss_dice: 1.2635  decode.d1.loss_cls: 1.2391  decode.d1.loss_mask: 0.6578  decode.d1.loss_dice: 1.1411  decode.d2.loss_cls: 1.0971  decode.d2.loss_mask: 0.6282  decode.d2.loss_dice: 1.0947  decode.d3.loss_cls: 1.0078  decode.d3.loss_mask: 0.6201  decode.d3.loss_dice: 1.0794  decode.d4.loss_cls: 1.0374  decode.d4.loss_mask: 0.6280  decode.d4.loss_dice: 1.0384  decode.d5.loss_cls: 1.0091  decode.d5.loss_mask: 0.6117  decode.d5.loss_dice: 1.0850  decode.d6.loss_cls: 0.9893  decode.d6.loss_mask: 0.6165  decode.d6.loss_dice: 1.0544  decode.d7.loss_cls: 1.0479  decode.d7.loss_mask: 0.6013  decode.d7.loss_dice: 1.0640  decode.d8.loss_cls: 1.0025  decode.d8.loss_mask: 0.6074  decode.d8.loss_dice: 1.0322
2023/05/24 03:12:11 - mmengine - INFO - Iter(train) [ 72550/160000]  lr: 5.8060e-06  eta: 10:25:26  time: 0.4184  data_time: 0.0105  memory: 4829  grad_norm: 86.6631  loss: 32.2843  decode.loss_cls: 1.3437  decode.loss_mask: 0.6200  decode.loss_dice: 0.9865  decode.d0.loss_cls: 3.2083  decode.d0.loss_mask: 0.6543  decode.d0.loss_dice: 1.1811  decode.d1.loss_cls: 1.4814  decode.d1.loss_mask: 0.6467  decode.d1.loss_dice: 1.1104  decode.d2.loss_cls: 1.3786  decode.d2.loss_mask: 0.6304  decode.d2.loss_dice: 1.0573  decode.d3.loss_cls: 1.3103  decode.d3.loss_mask: 0.6463  decode.d3.loss_dice: 1.0603  decode.d4.loss_cls: 1.3230  decode.d4.loss_mask: 0.6422  decode.d4.loss_dice: 1.0269  decode.d5.loss_cls: 1.3878  decode.d5.loss_mask: 0.6123  decode.d5.loss_dice: 1.0309  decode.d6.loss_cls: 1.3933  decode.d6.loss_mask: 0.6260  decode.d6.loss_dice: 1.0060  decode.d7.loss_cls: 1.3601  decode.d7.loss_mask: 0.6177  decode.d7.loss_dice: 0.9810  decode.d8.loss_cls: 1.3669  decode.d8.loss_mask: 0.6136  decode.d8.loss_dice: 0.9812
2023/05/24 03:12:34 - mmengine - INFO - Iter(train) [ 72600/160000]  lr: 5.8030e-06  eta: 10:25:07  time: 0.4427  data_time: 0.0108  memory: 4857  grad_norm: 113.6805  loss: 32.4355  decode.loss_cls: 1.0557  decode.loss_mask: 0.7559  decode.loss_dice: 1.1771  decode.d0.loss_cls: 2.9366  decode.d0.loss_mask: 0.7524  decode.d0.loss_dice: 1.3718  decode.d1.loss_cls: 1.1870  decode.d1.loss_mask: 0.7774  decode.d1.loss_dice: 1.2681  decode.d2.loss_cls: 1.0656  decode.d2.loss_mask: 0.7554  decode.d2.loss_dice: 1.2167  decode.d3.loss_cls: 1.0419  decode.d3.loss_mask: 0.7375  decode.d3.loss_dice: 1.2216  decode.d4.loss_cls: 1.0549  decode.d4.loss_mask: 0.7621  decode.d4.loss_dice: 1.2064  decode.d5.loss_cls: 1.0541  decode.d5.loss_mask: 0.7536  decode.d5.loss_dice: 1.1668  decode.d6.loss_cls: 1.0426  decode.d6.loss_mask: 0.7813  decode.d6.loss_dice: 1.2090  decode.d7.loss_cls: 1.0179  decode.d7.loss_mask: 0.7986  decode.d7.loss_dice: 1.1747  decode.d8.loss_cls: 1.0872  decode.d8.loss_mask: 0.7960  decode.d8.loss_dice: 1.2095
2023/05/24 03:12:55 - mmengine - INFO - Iter(train) [ 72650/160000]  lr: 5.8000e-06  eta: 10:24:45  time: 0.4361  data_time: 0.0105  memory: 4865  grad_norm: 91.1153  loss: 36.0013  decode.loss_cls: 1.0595  decode.loss_mask: 0.8063  decode.loss_dice: 1.3820  decode.d0.loss_cls: 3.4223  decode.d0.loss_mask: 0.8508  decode.d0.loss_dice: 1.6198  decode.d1.loss_cls: 1.2634  decode.d1.loss_mask: 0.8568  decode.d1.loss_dice: 1.5273  decode.d2.loss_cls: 1.1207  decode.d2.loss_mask: 0.8406  decode.d2.loss_dice: 1.4392  decode.d3.loss_cls: 1.0838  decode.d3.loss_mask: 0.8354  decode.d3.loss_dice: 1.4245  decode.d4.loss_cls: 1.0485  decode.d4.loss_mask: 0.8183  decode.d4.loss_dice: 1.4106  decode.d5.loss_cls: 1.0553  decode.d5.loss_mask: 0.8172  decode.d5.loss_dice: 1.4438  decode.d6.loss_cls: 1.0379  decode.d6.loss_mask: 0.8263  decode.d6.loss_dice: 1.4151  decode.d7.loss_cls: 1.0502  decode.d7.loss_mask: 0.8267  decode.d7.loss_dice: 1.4359  decode.d8.loss_cls: 1.0373  decode.d8.loss_mask: 0.8090  decode.d8.loss_dice: 1.4368
2023/05/24 03:13:19 - mmengine - INFO - Iter(train) [ 72700/160000]  lr: 5.7971e-06  eta: 10:24:26  time: 0.4718  data_time: 0.0101  memory: 4836  grad_norm: 99.7262  loss: 27.5549  decode.loss_cls: 0.9499  decode.loss_mask: 0.5514  decode.loss_dice: 0.9830  decode.d0.loss_cls: 2.7387  decode.d0.loss_mask: 0.6541  decode.d0.loss_dice: 1.1363  decode.d1.loss_cls: 1.0694  decode.d1.loss_mask: 0.6371  decode.d1.loss_dice: 1.0848  decode.d2.loss_cls: 1.0484  decode.d2.loss_mask: 0.5930  decode.d2.loss_dice: 1.0066  decode.d3.loss_cls: 1.0494  decode.d3.loss_mask: 0.5507  decode.d3.loss_dice: 0.9677  decode.d4.loss_cls: 0.9823  decode.d4.loss_mask: 0.5709  decode.d4.loss_dice: 1.0190  decode.d5.loss_cls: 0.9341  decode.d5.loss_mask: 0.5690  decode.d5.loss_dice: 1.0285  decode.d6.loss_cls: 0.9312  decode.d6.loss_mask: 0.5817  decode.d6.loss_dice: 0.9995  decode.d7.loss_cls: 0.9160  decode.d7.loss_mask: 0.5500  decode.d7.loss_dice: 0.9857  decode.d8.loss_cls: 0.9295  decode.d8.loss_mask: 0.5497  decode.d8.loss_dice: 0.9873
2023/05/24 03:13:42 - mmengine - INFO - Iter(train) [ 72750/160000]  lr: 5.7941e-06  eta: 10:24:07  time: 0.4707  data_time: 0.0107  memory: 4910  grad_norm: 92.3583  loss: 34.5943  decode.loss_cls: 1.1460  decode.loss_mask: 0.7055  decode.loss_dice: 1.2844  decode.d0.loss_cls: 3.0963  decode.d0.loss_mask: 0.8266  decode.d0.loss_dice: 1.5823  decode.d1.loss_cls: 1.3025  decode.d1.loss_mask: 0.7560  decode.d1.loss_dice: 1.4134  decode.d2.loss_cls: 1.2236  decode.d2.loss_mask: 0.6995  decode.d2.loss_dice: 1.3675  decode.d3.loss_cls: 1.1870  decode.d3.loss_mask: 0.7352  decode.d3.loss_dice: 1.3502  decode.d4.loss_cls: 1.1310  decode.d4.loss_mask: 0.7107  decode.d4.loss_dice: 1.3384  decode.d5.loss_cls: 1.2024  decode.d5.loss_mask: 0.7064  decode.d5.loss_dice: 1.3090  decode.d6.loss_cls: 1.1634  decode.d6.loss_mask: 0.7272  decode.d6.loss_dice: 1.3044  decode.d7.loss_cls: 1.1400  decode.d7.loss_mask: 0.7109  decode.d7.loss_dice: 1.2985  decode.d8.loss_cls: 1.1659  decode.d8.loss_mask: 0.7067  decode.d8.loss_dice: 1.3033
2023/05/24 03:14:04 - mmengine - INFO - Iter(train) [ 72800/160000]  lr: 5.7911e-06  eta: 10:23:46  time: 0.4186  data_time: 0.0109  memory: 4856  grad_norm: 85.3048  loss: 34.5807  decode.loss_cls: 1.1698  decode.loss_mask: 0.8972  decode.loss_dice: 1.1327  decode.d0.loss_cls: 3.2217  decode.d0.loss_mask: 0.8673  decode.d0.loss_dice: 1.2963  decode.d1.loss_cls: 1.3663  decode.d1.loss_mask: 0.9152  decode.d1.loss_dice: 1.2065  decode.d2.loss_cls: 1.1761  decode.d2.loss_mask: 0.9152  decode.d2.loss_dice: 1.2281  decode.d3.loss_cls: 1.1421  decode.d3.loss_mask: 0.9238  decode.d3.loss_dice: 1.1572  decode.d4.loss_cls: 1.1413  decode.d4.loss_mask: 0.9131  decode.d4.loss_dice: 1.1559  decode.d5.loss_cls: 1.2098  decode.d5.loss_mask: 0.9081  decode.d5.loss_dice: 1.1336  decode.d6.loss_cls: 1.1373  decode.d6.loss_mask: 0.8928  decode.d6.loss_dice: 1.1093  decode.d7.loss_cls: 1.1439  decode.d7.loss_mask: 0.8995  decode.d7.loss_dice: 1.1208  decode.d8.loss_cls: 1.1657  decode.d8.loss_mask: 0.9117  decode.d8.loss_dice: 1.1223
2023/05/24 03:14:27 - mmengine - INFO - Iter(train) [ 72850/160000]  lr: 5.7881e-06  eta: 10:23:26  time: 0.4169  data_time: 0.0105  memory: 4829  grad_norm: 145.7534  loss: 27.4010  decode.loss_cls: 0.9203  decode.loss_mask: 0.5814  decode.loss_dice: 1.0163  decode.d0.loss_cls: 2.5366  decode.d0.loss_mask: 0.6091  decode.d0.loss_dice: 1.1097  decode.d1.loss_cls: 0.9865  decode.d1.loss_mask: 0.6021  decode.d1.loss_dice: 1.0469  decode.d2.loss_cls: 0.9743  decode.d2.loss_mask: 0.6043  decode.d2.loss_dice: 1.0028  decode.d3.loss_cls: 1.0132  decode.d3.loss_mask: 0.5793  decode.d3.loss_dice: 1.0012  decode.d4.loss_cls: 0.9880  decode.d4.loss_mask: 0.5940  decode.d4.loss_dice: 1.0054  decode.d5.loss_cls: 0.9626  decode.d5.loss_mask: 0.6025  decode.d5.loss_dice: 0.9966  decode.d6.loss_cls: 0.9372  decode.d6.loss_mask: 0.6222  decode.d6.loss_dice: 1.0056  decode.d7.loss_cls: 0.9496  decode.d7.loss_mask: 0.6150  decode.d7.loss_dice: 1.0028  decode.d8.loss_cls: 0.8317  decode.d8.loss_mask: 0.6509  decode.d8.loss_dice: 1.0528
2023/05/24 03:14:49 - mmengine - INFO - Iter(train) [ 72900/160000]  lr: 5.7851e-06  eta: 10:23:06  time: 0.4672  data_time: 0.0102  memory: 4805  grad_norm: 86.6925  loss: 39.2075  decode.loss_cls: 1.3990  decode.loss_mask: 0.8972  decode.loss_dice: 1.3172  decode.d0.loss_cls: 3.3231  decode.d0.loss_mask: 0.9175  decode.d0.loss_dice: 1.5249  decode.d1.loss_cls: 1.5798  decode.d1.loss_mask: 0.9322  decode.d1.loss_dice: 1.4516  decode.d2.loss_cls: 1.5265  decode.d2.loss_mask: 0.9060  decode.d2.loss_dice: 1.3817  decode.d3.loss_cls: 1.4727  decode.d3.loss_mask: 0.9053  decode.d3.loss_dice: 1.3641  decode.d4.loss_cls: 1.4891  decode.d4.loss_mask: 0.9122  decode.d4.loss_dice: 1.2908  decode.d5.loss_cls: 1.4249  decode.d5.loss_mask: 0.8973  decode.d5.loss_dice: 1.3489  decode.d6.loss_cls: 1.4713  decode.d6.loss_mask: 0.8913  decode.d6.loss_dice: 1.3175  decode.d7.loss_cls: 1.4189  decode.d7.loss_mask: 0.9011  decode.d7.loss_dice: 1.3302  decode.d8.loss_cls: 1.3838  decode.d8.loss_mask: 0.9024  decode.d8.loss_dice: 1.3290
2023/05/24 03:15:11 - mmengine - INFO - Iter(train) [ 72950/160000]  lr: 5.7821e-06  eta: 10:22:44  time: 0.4120  data_time: 0.0103  memory: 4837  grad_norm: 123.6867  loss: 37.6287  decode.loss_cls: 1.4369  decode.loss_mask: 0.8126  decode.loss_dice: 1.2596  decode.d0.loss_cls: 3.3144  decode.d0.loss_mask: 0.8711  decode.d0.loss_dice: 1.4468  decode.d1.loss_cls: 1.4928  decode.d1.loss_mask: 0.8337  decode.d1.loss_dice: 1.3714  decode.d2.loss_cls: 1.5094  decode.d2.loss_mask: 0.8493  decode.d2.loss_dice: 1.2571  decode.d3.loss_cls: 1.5152  decode.d3.loss_mask: 0.8356  decode.d3.loss_dice: 1.2498  decode.d4.loss_cls: 1.4529  decode.d4.loss_mask: 0.8050  decode.d4.loss_dice: 1.2476  decode.d5.loss_cls: 1.4753  decode.d5.loss_mask: 0.8029  decode.d5.loss_dice: 1.2149  decode.d6.loss_cls: 1.4965  decode.d6.loss_mask: 0.8105  decode.d6.loss_dice: 1.2200  decode.d7.loss_cls: 1.4784  decode.d7.loss_mask: 0.8219  decode.d7.loss_dice: 1.2052  decode.d8.loss_cls: 1.4879  decode.d8.loss_mask: 0.8152  decode.d8.loss_dice: 1.2388
2023/05/24 03:15:34 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 03:15:34 - mmengine - INFO - Iter(train) [ 73000/160000]  lr: 5.7791e-06  eta: 10:22:25  time: 0.4729  data_time: 0.0102  memory: 4796  grad_norm: 95.6198  loss: 32.0254  decode.loss_cls: 1.0052  decode.loss_mask: 0.8754  decode.loss_dice: 1.0052  decode.d0.loss_cls: 3.0245  decode.d0.loss_mask: 0.8560  decode.d0.loss_dice: 1.1675  decode.d1.loss_cls: 1.3031  decode.d1.loss_mask: 0.8621  decode.d1.loss_dice: 1.0910  decode.d2.loss_cls: 1.1522  decode.d2.loss_mask: 0.8313  decode.d2.loss_dice: 1.0788  decode.d3.loss_cls: 1.0994  decode.d3.loss_mask: 0.8539  decode.d3.loss_dice: 1.0131  decode.d4.loss_cls: 1.0899  decode.d4.loss_mask: 0.8636  decode.d4.loss_dice: 1.0382  decode.d5.loss_cls: 1.0728  decode.d5.loss_mask: 0.8462  decode.d5.loss_dice: 1.0155  decode.d6.loss_cls: 1.0898  decode.d6.loss_mask: 0.8501  decode.d6.loss_dice: 1.0379  decode.d7.loss_cls: 1.0626  decode.d7.loss_mask: 0.8815  decode.d7.loss_dice: 1.0413  decode.d8.loss_cls: 1.0348  decode.d8.loss_mask: 0.8611  decode.d8.loss_dice: 1.0214
2023/05/24 03:15:34 - mmengine - INFO - Saving checkpoint at 73000 iterations
2023/05/24 03:16:03 - mmengine - INFO - Iter(train) [ 73050/160000]  lr: 5.7761e-06  eta: 10:22:12  time: 0.4655  data_time: 0.0102  memory: 4806  grad_norm: 82.6760  loss: 32.5985  decode.loss_cls: 0.9783  decode.loss_mask: 0.7593  decode.loss_dice: 1.2820  decode.d0.loss_cls: 2.8983  decode.d0.loss_mask: 0.7805  decode.d0.loss_dice: 1.4751  decode.d1.loss_cls: 1.0137  decode.d1.loss_mask: 0.7875  decode.d1.loss_dice: 1.4111  decode.d2.loss_cls: 1.0099  decode.d2.loss_mask: 0.7739  decode.d2.loss_dice: 1.3258  decode.d3.loss_cls: 0.9985  decode.d3.loss_mask: 0.7622  decode.d3.loss_dice: 1.2711  decode.d4.loss_cls: 1.0022  decode.d4.loss_mask: 0.7549  decode.d4.loss_dice: 1.2701  decode.d5.loss_cls: 0.9720  decode.d5.loss_mask: 0.7491  decode.d5.loss_dice: 1.2957  decode.d6.loss_cls: 0.9947  decode.d6.loss_mask: 0.7601  decode.d6.loss_dice: 1.2761  decode.d7.loss_cls: 0.9543  decode.d7.loss_mask: 0.7543  decode.d7.loss_dice: 1.2809  decode.d8.loss_cls: 0.9606  decode.d8.loss_mask: 0.7776  decode.d8.loss_dice: 1.2688
2023/05/24 03:16:23 - mmengine - INFO - Iter(train) [ 73100/160000]  lr: 5.7731e-06  eta: 10:21:50  time: 0.4315  data_time: 0.0101  memory: 4919  grad_norm: 100.1617  loss: 39.0056  decode.loss_cls: 1.4051  decode.loss_mask: 0.8512  decode.loss_dice: 1.4175  decode.d0.loss_cls: 3.3327  decode.d0.loss_mask: 0.8589  decode.d0.loss_dice: 1.5472  decode.d1.loss_cls: 1.4702  decode.d1.loss_mask: 0.8629  decode.d1.loss_dice: 1.5035  decode.d2.loss_cls: 1.3866  decode.d2.loss_mask: 0.8363  decode.d2.loss_dice: 1.4547  decode.d3.loss_cls: 1.5223  decode.d3.loss_mask: 0.8121  decode.d3.loss_dice: 1.3743  decode.d4.loss_cls: 1.4722  decode.d4.loss_mask: 0.8336  decode.d4.loss_dice: 1.4071  decode.d5.loss_cls: 1.4505  decode.d5.loss_mask: 0.8140  decode.d5.loss_dice: 1.4210  decode.d6.loss_cls: 1.4318  decode.d6.loss_mask: 0.8158  decode.d6.loss_dice: 1.4244  decode.d7.loss_cls: 1.3723  decode.d7.loss_mask: 0.8358  decode.d7.loss_dice: 1.4232  decode.d8.loss_cls: 1.4605  decode.d8.loss_mask: 0.8066  decode.d8.loss_dice: 1.4014
2023/05/24 03:16:45 - mmengine - INFO - Iter(train) [ 73150/160000]  lr: 5.7702e-06  eta: 10:21:29  time: 0.4615  data_time: 0.0100  memory: 4839  grad_norm: 163.3498  loss: 44.9380  decode.loss_cls: 1.5464  decode.loss_mask: 1.0938  decode.loss_dice: 1.5520  decode.d0.loss_cls: 3.5413  decode.d0.loss_mask: 1.1061  decode.d0.loss_dice: 1.8051  decode.d1.loss_cls: 1.7114  decode.d1.loss_mask: 1.0952  decode.d1.loss_dice: 1.7763  decode.d2.loss_cls: 1.6603  decode.d2.loss_mask: 1.0674  decode.d2.loss_dice: 1.6812  decode.d3.loss_cls: 1.6414  decode.d3.loss_mask: 1.0616  decode.d3.loss_dice: 1.5838  decode.d4.loss_cls: 1.5866  decode.d4.loss_mask: 1.0667  decode.d4.loss_dice: 1.5932  decode.d5.loss_cls: 1.5704  decode.d5.loss_mask: 1.0832  decode.d5.loss_dice: 1.5948  decode.d6.loss_cls: 1.5529  decode.d6.loss_mask: 1.0743  decode.d6.loss_dice: 1.5461  decode.d7.loss_cls: 1.5223  decode.d7.loss_mask: 1.0754  decode.d7.loss_dice: 1.5617  decode.d8.loss_cls: 1.5488  decode.d8.loss_mask: 1.0971  decode.d8.loss_dice: 1.5414
2023/05/24 03:17:06 - mmengine - INFO - Iter(train) [ 73200/160000]  lr: 5.7672e-06  eta: 10:21:07  time: 0.4206  data_time: 0.0108  memory: 4872  grad_norm: 106.5605  loss: 41.5923  decode.loss_cls: 1.4133  decode.loss_mask: 0.8985  decode.loss_dice: 1.6034  decode.d0.loss_cls: 3.2344  decode.d0.loss_mask: 0.9109  decode.d0.loss_dice: 1.8109  decode.d1.loss_cls: 1.6063  decode.d1.loss_mask: 0.8965  decode.d1.loss_dice: 1.6295  decode.d2.loss_cls: 1.4778  decode.d2.loss_mask: 0.8768  decode.d2.loss_dice: 1.6213  decode.d3.loss_cls: 1.4812  decode.d3.loss_mask: 0.9040  decode.d3.loss_dice: 1.6370  decode.d4.loss_cls: 1.4334  decode.d4.loss_mask: 0.9297  decode.d4.loss_dice: 1.6421  decode.d5.loss_cls: 1.3918  decode.d5.loss_mask: 0.9172  decode.d5.loss_dice: 1.6473  decode.d6.loss_cls: 1.3718  decode.d6.loss_mask: 0.9077  decode.d6.loss_dice: 1.6147  decode.d7.loss_cls: 1.3456  decode.d7.loss_mask: 0.9187  decode.d7.loss_dice: 1.6033  decode.d8.loss_cls: 1.3271  decode.d8.loss_mask: 0.9247  decode.d8.loss_dice: 1.6155
2023/05/24 03:17:27 - mmengine - INFO - Iter(train) [ 73250/160000]  lr: 5.7642e-06  eta: 10:20:45  time: 0.4142  data_time: 0.0106  memory: 4842  grad_norm: 89.1697  loss: 41.1864  decode.loss_cls: 1.5558  decode.loss_mask: 0.7401  decode.loss_dice: 1.5494  decode.d0.loss_cls: 3.6115  decode.d0.loss_mask: 0.7104  decode.d0.loss_dice: 1.7756  decode.d1.loss_cls: 1.5488  decode.d1.loss_mask: 0.7796  decode.d1.loss_dice: 1.6870  decode.d2.loss_cls: 1.5130  decode.d2.loss_mask: 0.7360  decode.d2.loss_dice: 1.6686  decode.d3.loss_cls: 1.5320  decode.d3.loss_mask: 0.7498  decode.d3.loss_dice: 1.6866  decode.d4.loss_cls: 1.5028  decode.d4.loss_mask: 0.7160  decode.d4.loss_dice: 1.6809  decode.d5.loss_cls: 1.5172  decode.d5.loss_mask: 0.6885  decode.d5.loss_dice: 1.5962  decode.d6.loss_cls: 1.5446  decode.d6.loss_mask: 0.7497  decode.d6.loss_dice: 1.5684  decode.d7.loss_cls: 1.5864  decode.d7.loss_mask: 0.7131  decode.d7.loss_dice: 1.5989  decode.d8.loss_cls: 1.5387  decode.d8.loss_mask: 0.7437  decode.d8.loss_dice: 1.5969
2023/05/24 03:17:49 - mmengine - INFO - Iter(train) [ 73300/160000]  lr: 5.7612e-06  eta: 10:20:23  time: 0.4187  data_time: 0.0102  memory: 4862  grad_norm: 91.6559  loss: 26.0604  decode.loss_cls: 0.8899  decode.loss_mask: 0.5157  decode.loss_dice: 0.8919  decode.d0.loss_cls: 2.8055  decode.d0.loss_mask: 0.5950  decode.d0.loss_dice: 1.0585  decode.d1.loss_cls: 1.0507  decode.d1.loss_mask: 0.5482  decode.d1.loss_dice: 0.9888  decode.d2.loss_cls: 0.9645  decode.d2.loss_mask: 0.5442  decode.d2.loss_dice: 0.9868  decode.d3.loss_cls: 0.9768  decode.d3.loss_mask: 0.5278  decode.d3.loss_dice: 0.9198  decode.d4.loss_cls: 0.9646  decode.d4.loss_mask: 0.5178  decode.d4.loss_dice: 0.9401  decode.d5.loss_cls: 0.8940  decode.d5.loss_mask: 0.5130  decode.d5.loss_dice: 0.9101  decode.d6.loss_cls: 0.9158  decode.d6.loss_mask: 0.5088  decode.d6.loss_dice: 0.9124  decode.d7.loss_cls: 0.9170  decode.d7.loss_mask: 0.5094  decode.d7.loss_dice: 0.9280  decode.d8.loss_cls: 0.9131  decode.d8.loss_mask: 0.5148  decode.d8.loss_dice: 0.9373
2023/05/24 03:18:09 - mmengine - INFO - Iter(train) [ 73350/160000]  lr: 5.7582e-06  eta: 10:20:01  time: 0.4222  data_time: 0.0104  memory: 4876  grad_norm: 126.6206  loss: 32.9628  decode.loss_cls: 0.9583  decode.loss_mask: 0.8710  decode.loss_dice: 1.2470  decode.d0.loss_cls: 2.7185  decode.d0.loss_mask: 0.9213  decode.d0.loss_dice: 1.4116  decode.d1.loss_cls: 0.9996  decode.d1.loss_mask: 0.9040  decode.d1.loss_dice: 1.3014  decode.d2.loss_cls: 1.0002  decode.d2.loss_mask: 0.8962  decode.d2.loss_dice: 1.2974  decode.d3.loss_cls: 0.9429  decode.d3.loss_mask: 0.8823  decode.d3.loss_dice: 1.2485  decode.d4.loss_cls: 0.9259  decode.d4.loss_mask: 0.8845  decode.d4.loss_dice: 1.2578  decode.d5.loss_cls: 0.9478  decode.d5.loss_mask: 0.8919  decode.d5.loss_dice: 1.2530  decode.d6.loss_cls: 0.9492  decode.d6.loss_mask: 0.8830  decode.d6.loss_dice: 1.2343  decode.d7.loss_cls: 0.9855  decode.d7.loss_mask: 0.8702  decode.d7.loss_dice: 1.2481  decode.d8.loss_cls: 0.9480  decode.d8.loss_mask: 0.8682  decode.d8.loss_dice: 1.2156
2023/05/24 03:18:31 - mmengine - INFO - Iter(train) [ 73400/160000]  lr: 5.7552e-06  eta: 10:19:39  time: 0.4265  data_time: 0.0103  memory: 4901  grad_norm: 95.8857  loss: 30.8398  decode.loss_cls: 0.9470  decode.loss_mask: 0.6678  decode.loss_dice: 1.1840  decode.d0.loss_cls: 2.8329  decode.d0.loss_mask: 0.7383  decode.d0.loss_dice: 1.3470  decode.d1.loss_cls: 1.0875  decode.d1.loss_mask: 0.6861  decode.d1.loss_dice: 1.2468  decode.d2.loss_cls: 1.0915  decode.d2.loss_mask: 0.6809  decode.d2.loss_dice: 1.1919  decode.d3.loss_cls: 1.0189  decode.d3.loss_mask: 0.6913  decode.d3.loss_dice: 1.1918  decode.d4.loss_cls: 0.9619  decode.d4.loss_mask: 0.6633  decode.d4.loss_dice: 1.2229  decode.d5.loss_cls: 0.9592  decode.d5.loss_mask: 0.6972  decode.d5.loss_dice: 1.2115  decode.d6.loss_cls: 1.0135  decode.d6.loss_mask: 0.6653  decode.d6.loss_dice: 1.1867  decode.d7.loss_cls: 0.9464  decode.d7.loss_mask: 0.6929  decode.d7.loss_dice: 1.2196  decode.d8.loss_cls: 0.9902  decode.d8.loss_mask: 0.6605  decode.d8.loss_dice: 1.1450
2023/05/24 03:18:52 - mmengine - INFO - Iter(train) [ 73450/160000]  lr: 5.7522e-06  eta: 10:19:17  time: 0.4297  data_time: 0.0109  memory: 4829  grad_norm: 100.1513  loss: 38.8552  decode.loss_cls: 1.3457  decode.loss_mask: 0.8096  decode.loss_dice: 1.4262  decode.d0.loss_cls: 3.3640  decode.d0.loss_mask: 0.9111  decode.d0.loss_dice: 1.5917  decode.d1.loss_cls: 1.4182  decode.d1.loss_mask: 0.8865  decode.d1.loss_dice: 1.5726  decode.d2.loss_cls: 1.4219  decode.d2.loss_mask: 0.8400  decode.d2.loss_dice: 1.4798  decode.d3.loss_cls: 1.4137  decode.d3.loss_mask: 0.8391  decode.d3.loss_dice: 1.4316  decode.d4.loss_cls: 1.4073  decode.d4.loss_mask: 0.8146  decode.d4.loss_dice: 1.4154  decode.d5.loss_cls: 1.4300  decode.d5.loss_mask: 0.8246  decode.d5.loss_dice: 1.4320  decode.d6.loss_cls: 1.3601  decode.d6.loss_mask: 0.8064  decode.d6.loss_dice: 1.4235  decode.d7.loss_cls: 1.3755  decode.d7.loss_mask: 0.8063  decode.d7.loss_dice: 1.4257  decode.d8.loss_cls: 1.3636  decode.d8.loss_mask: 0.8166  decode.d8.loss_dice: 1.4021
2023/05/24 03:19:13 - mmengine - INFO - Iter(train) [ 73500/160000]  lr: 5.7492e-06  eta: 10:18:55  time: 0.4136  data_time: 0.0103  memory: 4864  grad_norm: 89.8260  loss: 34.1696  decode.loss_cls: 1.1420  decode.loss_mask: 0.7925  decode.loss_dice: 1.2339  decode.d0.loss_cls: 3.0908  decode.d0.loss_mask: 0.8289  decode.d0.loss_dice: 1.3664  decode.d1.loss_cls: 1.3044  decode.d1.loss_mask: 0.8006  decode.d1.loss_dice: 1.2753  decode.d2.loss_cls: 1.1843  decode.d2.loss_mask: 0.8049  decode.d2.loss_dice: 1.2509  decode.d3.loss_cls: 1.2037  decode.d3.loss_mask: 0.8183  decode.d3.loss_dice: 1.2359  decode.d4.loss_cls: 1.1179  decode.d4.loss_mask: 0.8344  decode.d4.loss_dice: 1.2292  decode.d5.loss_cls: 1.1079  decode.d5.loss_mask: 0.8157  decode.d5.loss_dice: 1.2296  decode.d6.loss_cls: 1.1286  decode.d6.loss_mask: 0.8199  decode.d6.loss_dice: 1.2004  decode.d7.loss_cls: 1.1525  decode.d7.loss_mask: 0.8148  decode.d7.loss_dice: 1.1980  decode.d8.loss_cls: 1.1257  decode.d8.loss_mask: 0.8311  decode.d8.loss_dice: 1.2310
2023/05/24 03:19:35 - mmengine - INFO - Iter(train) [ 73550/160000]  lr: 5.7462e-06  eta: 10:18:34  time: 0.4472  data_time: 0.0105  memory: 4784  grad_norm: 92.6228  loss: 35.1450  decode.loss_cls: 1.3616  decode.loss_mask: 0.6950  decode.loss_dice: 1.1762  decode.d0.loss_cls: 3.2227  decode.d0.loss_mask: 0.7687  decode.d0.loss_dice: 1.3854  decode.d1.loss_cls: 1.6255  decode.d1.loss_mask: 0.7098  decode.d1.loss_dice: 1.2842  decode.d2.loss_cls: 1.5074  decode.d2.loss_mask: 0.7213  decode.d2.loss_dice: 1.2719  decode.d3.loss_cls: 1.4158  decode.d3.loss_mask: 0.6832  decode.d3.loss_dice: 1.1907  decode.d4.loss_cls: 1.3676  decode.d4.loss_mask: 0.6944  decode.d4.loss_dice: 1.1854  decode.d5.loss_cls: 1.3816  decode.d5.loss_mask: 0.6866  decode.d5.loss_dice: 1.1630  decode.d6.loss_cls: 1.3697  decode.d6.loss_mask: 0.6930  decode.d6.loss_dice: 1.1564  decode.d7.loss_cls: 1.3236  decode.d7.loss_mask: 0.6991  decode.d7.loss_dice: 1.1978  decode.d8.loss_cls: 1.3617  decode.d8.loss_mask: 0.6749  decode.d8.loss_dice: 1.1704
2023/05/24 03:19:58 - mmengine - INFO - Iter(train) [ 73600/160000]  lr: 5.7432e-06  eta: 10:18:15  time: 0.4298  data_time: 0.0101  memory: 4945  grad_norm: 85.8022  loss: 49.0979  decode.loss_cls: 1.5617  decode.loss_mask: 0.8393  decode.loss_dice: 2.1289  decode.d0.loss_cls: 3.6490  decode.d0.loss_mask: 0.9728  decode.d0.loss_dice: 2.6376  decode.d1.loss_cls: 1.7116  decode.d1.loss_mask: 0.8750  decode.d1.loss_dice: 2.4018  decode.d2.loss_cls: 1.6940  decode.d2.loss_mask: 0.8252  decode.d2.loss_dice: 2.3001  decode.d3.loss_cls: 1.6868  decode.d3.loss_mask: 0.8328  decode.d3.loss_dice: 2.1993  decode.d4.loss_cls: 1.5601  decode.d4.loss_mask: 0.8239  decode.d4.loss_dice: 2.2198  decode.d5.loss_cls: 1.6138  decode.d5.loss_mask: 0.8332  decode.d5.loss_dice: 2.1139  decode.d6.loss_cls: 1.6078  decode.d6.loss_mask: 0.8172  decode.d6.loss_dice: 2.1085  decode.d7.loss_cls: 1.6073  decode.d7.loss_mask: 0.8228  decode.d7.loss_dice: 2.1318  decode.d8.loss_cls: 1.5777  decode.d8.loss_mask: 0.8315  decode.d8.loss_dice: 2.1126
2023/05/24 03:20:21 - mmengine - INFO - Iter(train) [ 73650/160000]  lr: 5.7402e-06  eta: 10:17:55  time: 0.4235  data_time: 0.0108  memory: 4846  grad_norm: 121.2176  loss: 36.0748  decode.loss_cls: 1.2085  decode.loss_mask: 0.7433  decode.loss_dice: 1.3133  decode.d0.loss_cls: 3.3487  decode.d0.loss_mask: 0.8811  decode.d0.loss_dice: 1.5383  decode.d1.loss_cls: 1.4410  decode.d1.loss_mask: 0.8116  decode.d1.loss_dice: 1.4236  decode.d2.loss_cls: 1.2705  decode.d2.loss_mask: 0.7943  decode.d2.loss_dice: 1.3586  decode.d3.loss_cls: 1.2878  decode.d3.loss_mask: 0.7721  decode.d3.loss_dice: 1.3483  decode.d4.loss_cls: 1.2403  decode.d4.loss_mask: 0.7569  decode.d4.loss_dice: 1.3395  decode.d5.loss_cls: 1.2548  decode.d5.loss_mask: 0.7702  decode.d5.loss_dice: 1.3221  decode.d6.loss_cls: 1.2701  decode.d6.loss_mask: 0.7522  decode.d6.loss_dice: 1.3055  decode.d7.loss_cls: 1.2171  decode.d7.loss_mask: 0.7600  decode.d7.loss_dice: 1.3032  decode.d8.loss_cls: 1.1856  decode.d8.loss_mask: 0.7486  decode.d8.loss_dice: 1.3074
2023/05/24 03:20:44 - mmengine - INFO - Iter(train) [ 73700/160000]  lr: 5.7373e-06  eta: 10:17:35  time: 0.4741  data_time: 0.0106  memory: 4876  grad_norm: 121.9890  loss: 34.1691  decode.loss_cls: 1.2970  decode.loss_mask: 0.7739  decode.loss_dice: 1.1335  decode.d0.loss_cls: 3.0111  decode.d0.loss_mask: 0.8440  decode.d0.loss_dice: 1.3358  decode.d1.loss_cls: 1.2843  decode.d1.loss_mask: 0.8103  decode.d1.loss_dice: 1.2555  decode.d2.loss_cls: 1.2562  decode.d2.loss_mask: 0.7990  decode.d2.loss_dice: 1.2086  decode.d3.loss_cls: 1.2624  decode.d3.loss_mask: 0.8130  decode.d3.loss_dice: 1.2008  decode.d4.loss_cls: 1.2621  decode.d4.loss_mask: 0.7730  decode.d4.loss_dice: 1.1839  decode.d5.loss_cls: 1.2108  decode.d5.loss_mask: 0.7917  decode.d5.loss_dice: 1.1599  decode.d6.loss_cls: 1.2609  decode.d6.loss_mask: 0.7690  decode.d6.loss_dice: 1.1182  decode.d7.loss_cls: 1.2755  decode.d7.loss_mask: 0.7773  decode.d7.loss_dice: 1.1538  decode.d8.loss_cls: 1.2234  decode.d8.loss_mask: 0.7850  decode.d8.loss_dice: 1.1392
2023/05/24 03:21:07 - mmengine - INFO - Iter(train) [ 73750/160000]  lr: 5.7343e-06  eta: 10:17:16  time: 0.4778  data_time: 0.0102  memory: 4875  grad_norm: 106.4255  loss: 31.2103  decode.loss_cls: 1.0297  decode.loss_mask: 0.7138  decode.loss_dice: 1.0339  decode.d0.loss_cls: 3.1549  decode.d0.loss_mask: 0.8745  decode.d0.loss_dice: 1.2774  decode.d1.loss_cls: 1.1778  decode.d1.loss_mask: 0.8327  decode.d1.loss_dice: 1.1593  decode.d2.loss_cls: 1.0868  decode.d2.loss_mask: 0.7725  decode.d2.loss_dice: 1.1156  decode.d3.loss_cls: 1.0496  decode.d3.loss_mask: 0.7658  decode.d3.loss_dice: 1.0754  decode.d4.loss_cls: 1.0630  decode.d4.loss_mask: 0.7714  decode.d4.loss_dice: 1.0910  decode.d5.loss_cls: 1.0423  decode.d5.loss_mask: 0.7463  decode.d5.loss_dice: 1.0431  decode.d6.loss_cls: 1.0483  decode.d6.loss_mask: 0.7071  decode.d6.loss_dice: 1.0109  decode.d7.loss_cls: 1.0262  decode.d7.loss_mask: 0.7101  decode.d7.loss_dice: 1.0397  decode.d8.loss_cls: 1.0144  decode.d8.loss_mask: 0.7299  decode.d8.loss_dice: 1.0469
2023/05/24 03:21:28 - mmengine - INFO - Iter(train) [ 73800/160000]  lr: 5.7313e-06  eta: 10:16:53  time: 0.4083  data_time: 0.0104  memory: 4845  grad_norm: 75.6081  loss: 40.4659  decode.loss_cls: 1.4265  decode.loss_mask: 0.7005  decode.loss_dice: 1.5895  decode.d0.loss_cls: 3.2013  decode.d0.loss_mask: 0.7502  decode.d0.loss_dice: 1.8755  decode.d1.loss_cls: 1.6047  decode.d1.loss_mask: 0.7559  decode.d1.loss_dice: 1.7543  decode.d2.loss_cls: 1.5706  decode.d2.loss_mask: 0.7211  decode.d2.loss_dice: 1.6555  decode.d3.loss_cls: 1.5406  decode.d3.loss_mask: 0.7300  decode.d3.loss_dice: 1.6443  decode.d4.loss_cls: 1.4737  decode.d4.loss_mask: 0.7382  decode.d4.loss_dice: 1.6407  decode.d5.loss_cls: 1.4618  decode.d5.loss_mask: 0.7452  decode.d5.loss_dice: 1.6143  decode.d6.loss_cls: 1.4335  decode.d6.loss_mask: 0.7249  decode.d6.loss_dice: 1.5820  decode.d7.loss_cls: 1.4134  decode.d7.loss_mask: 0.7251  decode.d7.loss_dice: 1.6158  decode.d8.loss_cls: 1.5102  decode.d8.loss_mask: 0.7149  decode.d8.loss_dice: 1.5518
2023/05/24 03:21:49 - mmengine - INFO - Iter(train) [ 73850/160000]  lr: 5.7283e-06  eta: 10:16:31  time: 0.4245  data_time: 0.0104  memory: 4897  grad_norm: 102.3649  loss: 43.4433  decode.loss_cls: 1.4237  decode.loss_mask: 0.7951  decode.loss_dice: 1.7415  decode.d0.loss_cls: 3.5091  decode.d0.loss_mask: 0.9100  decode.d0.loss_dice: 2.0734  decode.d1.loss_cls: 1.6693  decode.d1.loss_mask: 0.8680  decode.d1.loss_dice: 2.0016  decode.d2.loss_cls: 1.5775  decode.d2.loss_mask: 0.8261  decode.d2.loss_dice: 1.8522  decode.d3.loss_cls: 1.5218  decode.d3.loss_mask: 0.8175  decode.d3.loss_dice: 1.7638  decode.d4.loss_cls: 1.4967  decode.d4.loss_mask: 0.8050  decode.d4.loss_dice: 1.7673  decode.d5.loss_cls: 1.5088  decode.d5.loss_mask: 0.8298  decode.d5.loss_dice: 1.7650  decode.d6.loss_cls: 1.4196  decode.d6.loss_mask: 0.8036  decode.d6.loss_dice: 1.7779  decode.d7.loss_cls: 1.4045  decode.d7.loss_mask: 0.8298  decode.d7.loss_dice: 1.7082  decode.d8.loss_cls: 1.3985  decode.d8.loss_mask: 0.8220  decode.d8.loss_dice: 1.7561
2023/05/24 03:22:10 - mmengine - INFO - Iter(train) [ 73900/160000]  lr: 5.7253e-06  eta: 10:16:10  time: 0.4211  data_time: 0.0108  memory: 4829  grad_norm: 94.9517  loss: 36.7166  decode.loss_cls: 1.2219  decode.loss_mask: 0.8074  decode.loss_dice: 1.4383  decode.d0.loss_cls: 2.9236  decode.d0.loss_mask: 0.8867  decode.d0.loss_dice: 1.6525  decode.d1.loss_cls: 1.1902  decode.d1.loss_mask: 0.8546  decode.d1.loss_dice: 1.5187  decode.d2.loss_cls: 1.2127  decode.d2.loss_mask: 0.8257  decode.d2.loss_dice: 1.4804  decode.d3.loss_cls: 1.1213  decode.d3.loss_mask: 0.8522  decode.d3.loss_dice: 1.4807  decode.d4.loss_cls: 1.0978  decode.d4.loss_mask: 0.8485  decode.d4.loss_dice: 1.4968  decode.d5.loss_cls: 1.1018  decode.d5.loss_mask: 0.8496  decode.d5.loss_dice: 1.5126  decode.d6.loss_cls: 1.1625  decode.d6.loss_mask: 0.8254  decode.d6.loss_dice: 1.4662  decode.d7.loss_cls: 1.0928  decode.d7.loss_mask: 0.8566  decode.d7.loss_dice: 1.4952  decode.d8.loss_cls: 1.1380  decode.d8.loss_mask: 0.8364  decode.d8.loss_dice: 1.4696
2023/05/24 03:22:31 - mmengine - INFO - Iter(train) [ 73950/160000]  lr: 5.7223e-06  eta: 10:15:48  time: 0.4321  data_time: 0.0104  memory: 4859  grad_norm: 128.2461  loss: 37.2479  decode.loss_cls: 1.2882  decode.loss_mask: 0.8239  decode.loss_dice: 1.3113  decode.d0.loss_cls: 2.9093  decode.d0.loss_mask: 0.9071  decode.d0.loss_dice: 1.6438  decode.d1.loss_cls: 1.2577  decode.d1.loss_mask: 0.9599  decode.d1.loss_dice: 1.4988  decode.d2.loss_cls: 1.2531  decode.d2.loss_mask: 0.9020  decode.d2.loss_dice: 1.4352  decode.d3.loss_cls: 1.3556  decode.d3.loss_mask: 0.8553  decode.d3.loss_dice: 1.3777  decode.d4.loss_cls: 1.2950  decode.d4.loss_mask: 0.8736  decode.d4.loss_dice: 1.3712  decode.d5.loss_cls: 1.3739  decode.d5.loss_mask: 0.8399  decode.d5.loss_dice: 1.3644  decode.d6.loss_cls: 1.2957  decode.d6.loss_mask: 0.8162  decode.d6.loss_dice: 1.3481  decode.d7.loss_cls: 1.3065  decode.d7.loss_mask: 0.8114  decode.d7.loss_dice: 1.3377  decode.d8.loss_cls: 1.2780  decode.d8.loss_mask: 0.8245  decode.d8.loss_dice: 1.3331
2023/05/24 03:22:53 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 03:22:53 - mmengine - INFO - Iter(train) [ 74000/160000]  lr: 5.7193e-06  eta: 10:15:26  time: 0.4119  data_time: 0.0106  memory: 4901  grad_norm: 90.1024  loss: 31.2440  decode.loss_cls: 1.1891  decode.loss_mask: 0.6098  decode.loss_dice: 1.0806  decode.d0.loss_cls: 2.8821  decode.d0.loss_mask: 0.6124  decode.d0.loss_dice: 1.2725  decode.d1.loss_cls: 1.2782  decode.d1.loss_mask: 0.6390  decode.d1.loss_dice: 1.2058  decode.d2.loss_cls: 1.2895  decode.d2.loss_mask: 0.6281  decode.d2.loss_dice: 1.1301  decode.d3.loss_cls: 1.2430  decode.d3.loss_mask: 0.5911  decode.d3.loss_dice: 1.1228  decode.d4.loss_cls: 1.2322  decode.d4.loss_mask: 0.5819  decode.d4.loss_dice: 1.1259  decode.d5.loss_cls: 1.1287  decode.d5.loss_mask: 0.6035  decode.d5.loss_dice: 1.1491  decode.d6.loss_cls: 1.1893  decode.d6.loss_mask: 0.5913  decode.d6.loss_dice: 1.0730  decode.d7.loss_cls: 1.1745  decode.d7.loss_mask: 0.5925  decode.d7.loss_dice: 1.1226  decode.d8.loss_cls: 1.1915  decode.d8.loss_mask: 0.5871  decode.d8.loss_dice: 1.1268
2023/05/24 03:22:53 - mmengine - INFO - Saving checkpoint at 74000 iterations
2023/05/24 03:23:19 - mmengine - INFO - Iter(train) [ 74050/160000]  lr: 5.7163e-06  eta: 10:15:10  time: 0.4177  data_time: 0.0107  memory: 4837  grad_norm: 131.2133  loss: 35.1749  decode.loss_cls: 1.1837  decode.loss_mask: 0.7517  decode.loss_dice: 1.3031  decode.d0.loss_cls: 3.1282  decode.d0.loss_mask: 0.8152  decode.d0.loss_dice: 1.4487  decode.d1.loss_cls: 1.2154  decode.d1.loss_mask: 0.8272  decode.d1.loss_dice: 1.4422  decode.d2.loss_cls: 1.2286  decode.d2.loss_mask: 0.7592  decode.d2.loss_dice: 1.3955  decode.d3.loss_cls: 1.1729  decode.d3.loss_mask: 0.7777  decode.d3.loss_dice: 1.3487  decode.d4.loss_cls: 1.2349  decode.d4.loss_mask: 0.7426  decode.d4.loss_dice: 1.3308  decode.d5.loss_cls: 1.1485  decode.d5.loss_mask: 0.7799  decode.d5.loss_dice: 1.3561  decode.d6.loss_cls: 1.1672  decode.d6.loss_mask: 0.7698  decode.d6.loss_dice: 1.3237  decode.d7.loss_cls: 1.1727  decode.d7.loss_mask: 0.7468  decode.d7.loss_dice: 1.3297  decode.d8.loss_cls: 1.1703  decode.d8.loss_mask: 0.7714  decode.d8.loss_dice: 1.3323
2023/05/24 03:23:40 - mmengine - INFO - Iter(train) [ 74100/160000]  lr: 5.7133e-06  eta: 10:14:48  time: 0.4218  data_time: 0.0102  memory: 4903  grad_norm: 96.5748  loss: 28.6587  decode.loss_cls: 0.9201  decode.loss_mask: 0.7182  decode.loss_dice: 0.9675  decode.d0.loss_cls: 2.9656  decode.d0.loss_mask: 0.7299  decode.d0.loss_dice: 1.1182  decode.d1.loss_cls: 1.1253  decode.d1.loss_mask: 0.7522  decode.d1.loss_dice: 1.0090  decode.d2.loss_cls: 0.9768  decode.d2.loss_mask: 0.7217  decode.d2.loss_dice: 1.0395  decode.d3.loss_cls: 0.9641  decode.d3.loss_mask: 0.6967  decode.d3.loss_dice: 0.9587  decode.d4.loss_cls: 0.9037  decode.d4.loss_mask: 0.7123  decode.d4.loss_dice: 0.9961  decode.d5.loss_cls: 0.8915  decode.d5.loss_mask: 0.6935  decode.d5.loss_dice: 0.9568  decode.d6.loss_cls: 0.9755  decode.d6.loss_mask: 0.6999  decode.d6.loss_dice: 0.9815  decode.d7.loss_cls: 0.9130  decode.d7.loss_mask: 0.7109  decode.d7.loss_dice: 0.9782  decode.d8.loss_cls: 0.9252  decode.d8.loss_mask: 0.6896  decode.d8.loss_dice: 0.9675
2023/05/24 03:24:01 - mmengine - INFO - Iter(train) [ 74150/160000]  lr: 5.7103e-06  eta: 10:14:26  time: 0.4216  data_time: 0.0104  memory: 4901  grad_norm: 91.3786  loss: 34.7019  decode.loss_cls: 1.0999  decode.loss_mask: 0.6725  decode.loss_dice: 1.4003  decode.d0.loss_cls: 3.3533  decode.d0.loss_mask: 0.6710  decode.d0.loss_dice: 1.6920  decode.d1.loss_cls: 1.1744  decode.d1.loss_mask: 0.6542  decode.d1.loss_dice: 1.5022  decode.d2.loss_cls: 1.1013  decode.d2.loss_mask: 0.6759  decode.d2.loss_dice: 1.5006  decode.d3.loss_cls: 1.1175  decode.d3.loss_mask: 0.6760  decode.d3.loss_dice: 1.4114  decode.d4.loss_cls: 1.1140  decode.d4.loss_mask: 0.6951  decode.d4.loss_dice: 1.4285  decode.d5.loss_cls: 1.1328  decode.d5.loss_mask: 0.6563  decode.d5.loss_dice: 1.4190  decode.d6.loss_cls: 1.0972  decode.d6.loss_mask: 0.6479  decode.d6.loss_dice: 1.4352  decode.d7.loss_cls: 1.1022  decode.d7.loss_mask: 0.6748  decode.d7.loss_dice: 1.4479  decode.d8.loss_cls: 1.0656  decode.d8.loss_mask: 0.6556  decode.d8.loss_dice: 1.4270
2023/05/24 03:24:22 - mmengine - INFO - Iter(train) [ 74200/160000]  lr: 5.7073e-06  eta: 10:14:04  time: 0.4148  data_time: 0.0106  memory: 4927  grad_norm: 93.6197  loss: 43.0545  decode.loss_cls: 1.3314  decode.loss_mask: 0.8488  decode.loss_dice: 1.8045  decode.d0.loss_cls: 3.2482  decode.d0.loss_mask: 0.9553  decode.d0.loss_dice: 2.0807  decode.d1.loss_cls: 1.3718  decode.d1.loss_mask: 0.8764  decode.d1.loss_dice: 1.9901  decode.d2.loss_cls: 1.3702  decode.d2.loss_mask: 0.8800  decode.d2.loss_dice: 1.9538  decode.d3.loss_cls: 1.3527  decode.d3.loss_mask: 0.8831  decode.d3.loss_dice: 1.8908  decode.d4.loss_cls: 1.3897  decode.d4.loss_mask: 0.9336  decode.d4.loss_dice: 1.8851  decode.d5.loss_cls: 1.3218  decode.d5.loss_mask: 0.8540  decode.d5.loss_dice: 1.8781  decode.d6.loss_cls: 1.2719  decode.d6.loss_mask: 0.8401  decode.d6.loss_dice: 1.8248  decode.d7.loss_cls: 1.3201  decode.d7.loss_mask: 0.8423  decode.d7.loss_dice: 1.8303  decode.d8.loss_cls: 1.3686  decode.d8.loss_mask: 0.8390  decode.d8.loss_dice: 1.8176
2023/05/24 03:24:43 - mmengine - INFO - Iter(train) [ 74250/160000]  lr: 5.7043e-06  eta: 10:13:42  time: 0.4185  data_time: 0.0102  memory: 4876  grad_norm: 108.0259  loss: 41.8956  decode.loss_cls: 1.3273  decode.loss_mask: 0.8741  decode.loss_dice: 1.6048  decode.d0.loss_cls: 3.4480  decode.d0.loss_mask: 1.0336  decode.d0.loss_dice: 2.0509  decode.d1.loss_cls: 1.5022  decode.d1.loss_mask: 0.9013  decode.d1.loss_dice: 1.8154  decode.d2.loss_cls: 1.4672  decode.d2.loss_mask: 0.8964  decode.d2.loss_dice: 1.7179  decode.d3.loss_cls: 1.4100  decode.d3.loss_mask: 0.8788  decode.d3.loss_dice: 1.6749  decode.d4.loss_cls: 1.3482  decode.d4.loss_mask: 0.8790  decode.d4.loss_dice: 1.7040  decode.d5.loss_cls: 1.3872  decode.d5.loss_mask: 0.8658  decode.d5.loss_dice: 1.6509  decode.d6.loss_cls: 1.3777  decode.d6.loss_mask: 0.8682  decode.d6.loss_dice: 1.6208  decode.d7.loss_cls: 1.3712  decode.d7.loss_mask: 0.8511  decode.d7.loss_dice: 1.5951  decode.d8.loss_cls: 1.3068  decode.d8.loss_mask: 0.8668  decode.d8.loss_dice: 1.6001
2023/05/24 03:25:04 - mmengine - INFO - Iter(train) [ 74300/160000]  lr: 5.7013e-06  eta: 10:13:20  time: 0.4105  data_time: 0.0107  memory: 4849  grad_norm: 109.1395  loss: 34.9378  decode.loss_cls: 1.1669  decode.loss_mask: 0.8028  decode.loss_dice: 1.2525  decode.d0.loss_cls: 3.0182  decode.d0.loss_mask: 0.8761  decode.d0.loss_dice: 1.4707  decode.d1.loss_cls: 1.2152  decode.d1.loss_mask: 0.8499  decode.d1.loss_dice: 1.4509  decode.d2.loss_cls: 1.2718  decode.d2.loss_mask: 0.7970  decode.d2.loss_dice: 1.3606  decode.d3.loss_cls: 1.1606  decode.d3.loss_mask: 0.8020  decode.d3.loss_dice: 1.3240  decode.d4.loss_cls: 1.1484  decode.d4.loss_mask: 0.7943  decode.d4.loss_dice: 1.3159  decode.d5.loss_cls: 1.1185  decode.d5.loss_mask: 0.8059  decode.d5.loss_dice: 1.3193  decode.d6.loss_cls: 1.1232  decode.d6.loss_mask: 0.8009  decode.d6.loss_dice: 1.2794  decode.d7.loss_cls: 1.1115  decode.d7.loss_mask: 0.8049  decode.d7.loss_dice: 1.2825  decode.d8.loss_cls: 1.1498  decode.d8.loss_mask: 0.7987  decode.d8.loss_dice: 1.2654
2023/05/24 03:25:25 - mmengine - INFO - Iter(train) [ 74350/160000]  lr: 5.6983e-06  eta: 10:12:59  time: 0.4148  data_time: 0.0104  memory: 4908  grad_norm: 119.2823  loss: 40.5357  decode.loss_cls: 1.5443  decode.loss_mask: 0.7692  decode.loss_dice: 1.4675  decode.d0.loss_cls: 3.2930  decode.d0.loss_mask: 0.8923  decode.d0.loss_dice: 1.8447  decode.d1.loss_cls: 1.6966  decode.d1.loss_mask: 0.8243  decode.d1.loss_dice: 1.6056  decode.d2.loss_cls: 1.5844  decode.d2.loss_mask: 0.8023  decode.d2.loss_dice: 1.5270  decode.d3.loss_cls: 1.5443  decode.d3.loss_mask: 0.8009  decode.d3.loss_dice: 1.4662  decode.d4.loss_cls: 1.4909  decode.d4.loss_mask: 0.8081  decode.d4.loss_dice: 1.4824  decode.d5.loss_cls: 1.5372  decode.d5.loss_mask: 0.7545  decode.d5.loss_dice: 1.4443  decode.d6.loss_cls: 1.5235  decode.d6.loss_mask: 0.7652  decode.d6.loss_dice: 1.4755  decode.d7.loss_cls: 1.6011  decode.d7.loss_mask: 0.7411  decode.d7.loss_dice: 1.4485  decode.d8.loss_cls: 1.5559  decode.d8.loss_mask: 0.7701  decode.d8.loss_dice: 1.4748
2023/05/24 03:25:48 - mmengine - INFO - Iter(train) [ 74400/160000]  lr: 5.6954e-06  eta: 10:12:39  time: 0.4699  data_time: 0.0102  memory: 4839  grad_norm: 96.5383  loss: 33.3301  decode.loss_cls: 1.0589  decode.loss_mask: 0.7675  decode.loss_dice: 1.1652  decode.d0.loss_cls: 3.0681  decode.d0.loss_mask: 0.8397  decode.d0.loss_dice: 1.3619  decode.d1.loss_cls: 1.2584  decode.d1.loss_mask: 0.8151  decode.d1.loss_dice: 1.2852  decode.d2.loss_cls: 1.2055  decode.d2.loss_mask: 0.7992  decode.d2.loss_dice: 1.2610  decode.d3.loss_cls: 1.1169  decode.d3.loss_mask: 0.8009  decode.d3.loss_dice: 1.1979  decode.d4.loss_cls: 1.0956  decode.d4.loss_mask: 0.7769  decode.d4.loss_dice: 1.2015  decode.d5.loss_cls: 1.1257  decode.d5.loss_mask: 0.7891  decode.d5.loss_dice: 1.2284  decode.d6.loss_cls: 1.0865  decode.d6.loss_mask: 0.8011  decode.d6.loss_dice: 1.1769  decode.d7.loss_cls: 1.0740  decode.d7.loss_mask: 0.7942  decode.d7.loss_dice: 1.1696  decode.d8.loss_cls: 1.0603  decode.d8.loss_mask: 0.7861  decode.d8.loss_dice: 1.1629
2023/05/24 03:26:11 - mmengine - INFO - Iter(train) [ 74450/160000]  lr: 5.6924e-06  eta: 10:12:19  time: 0.4177  data_time: 0.0106  memory: 4815  grad_norm: 114.5009  loss: 36.9346  decode.loss_cls: 1.3685  decode.loss_mask: 0.8136  decode.loss_dice: 1.3074  decode.d0.loss_cls: 3.1366  decode.d0.loss_mask: 0.8836  decode.d0.loss_dice: 1.5215  decode.d1.loss_cls: 1.4012  decode.d1.loss_mask: 0.8236  decode.d1.loss_dice: 1.3953  decode.d2.loss_cls: 1.3771  decode.d2.loss_mask: 0.8115  decode.d2.loss_dice: 1.3396  decode.d3.loss_cls: 1.3824  decode.d3.loss_mask: 0.8244  decode.d3.loss_dice: 1.3163  decode.d4.loss_cls: 1.3074  decode.d4.loss_mask: 0.8241  decode.d4.loss_dice: 1.3214  decode.d5.loss_cls: 1.3584  decode.d5.loss_mask: 0.7837  decode.d5.loss_dice: 1.2760  decode.d6.loss_cls: 1.3186  decode.d6.loss_mask: 0.8242  decode.d6.loss_dice: 1.2991  decode.d7.loss_cls: 1.3837  decode.d7.loss_mask: 0.7884  decode.d7.loss_dice: 1.2757  decode.d8.loss_cls: 1.3736  decode.d8.loss_mask: 0.7972  decode.d8.loss_dice: 1.3005
2023/05/24 03:26:32 - mmengine - INFO - Iter(train) [ 74500/160000]  lr: 5.6894e-06  eta: 10:11:57  time: 0.4818  data_time: 0.0109  memory: 4918  grad_norm: 116.5927  loss: 44.6570  decode.loss_cls: 1.3602  decode.loss_mask: 0.8975  decode.loss_dice: 1.8643  decode.d0.loss_cls: 3.4892  decode.d0.loss_mask: 0.9471  decode.d0.loss_dice: 2.1517  decode.d1.loss_cls: 1.5633  decode.d1.loss_mask: 0.9328  decode.d1.loss_dice: 1.9755  decode.d2.loss_cls: 1.4913  decode.d2.loss_mask: 0.9140  decode.d2.loss_dice: 1.9447  decode.d3.loss_cls: 1.5096  decode.d3.loss_mask: 0.9228  decode.d3.loss_dice: 1.9035  decode.d4.loss_cls: 1.4179  decode.d4.loss_mask: 0.8873  decode.d4.loss_dice: 1.8675  decode.d5.loss_cls: 1.4648  decode.d5.loss_mask: 0.9006  decode.d5.loss_dice: 1.8601  decode.d6.loss_cls: 1.3845  decode.d6.loss_mask: 0.8926  decode.d6.loss_dice: 1.9181  decode.d7.loss_cls: 1.4048  decode.d7.loss_mask: 0.8622  decode.d7.loss_dice: 1.8298  decode.d8.loss_cls: 1.3674  decode.d8.loss_mask: 0.8890  decode.d8.loss_dice: 1.8432
2023/05/24 03:26:55 - mmengine - INFO - Iter(train) [ 74550/160000]  lr: 5.6864e-06  eta: 10:11:37  time: 0.4137  data_time: 0.0108  memory: 4873  grad_norm: 90.0243  loss: 33.0883  decode.loss_cls: 1.0821  decode.loss_mask: 0.7365  decode.loss_dice: 1.2550  decode.d0.loss_cls: 3.0988  decode.d0.loss_mask: 0.7546  decode.d0.loss_dice: 1.4344  decode.d1.loss_cls: 1.1347  decode.d1.loss_mask: 0.7915  decode.d1.loss_dice: 1.3712  decode.d2.loss_cls: 1.1089  decode.d2.loss_mask: 0.7521  decode.d2.loss_dice: 1.2632  decode.d3.loss_cls: 1.0533  decode.d3.loss_mask: 0.7563  decode.d3.loss_dice: 1.2811  decode.d4.loss_cls: 1.0631  decode.d4.loss_mask: 0.7702  decode.d4.loss_dice: 1.2743  decode.d5.loss_cls: 1.0343  decode.d5.loss_mask: 0.7630  decode.d5.loss_dice: 1.2643  decode.d6.loss_cls: 1.0815  decode.d6.loss_mask: 0.7117  decode.d6.loss_dice: 1.1862  decode.d7.loss_cls: 1.0999  decode.d7.loss_mask: 0.7243  decode.d7.loss_dice: 1.2312  decode.d8.loss_cls: 1.0834  decode.d8.loss_mask: 0.7194  decode.d8.loss_dice: 1.2079
2023/05/24 03:27:15 - mmengine - INFO - Iter(train) [ 74600/160000]  lr: 5.6834e-06  eta: 10:11:14  time: 0.4205  data_time: 0.0104  memory: 4874  grad_norm: 102.1940  loss: 35.9404  decode.loss_cls: 1.1204  decode.loss_mask: 0.8809  decode.loss_dice: 1.3424  decode.d0.loss_cls: 3.1265  decode.d0.loss_mask: 1.0234  decode.d0.loss_dice: 1.5866  decode.d1.loss_cls: 1.0998  decode.d1.loss_mask: 0.9229  decode.d1.loss_dice: 1.4798  decode.d2.loss_cls: 1.0475  decode.d2.loss_mask: 0.9104  decode.d2.loss_dice: 1.3985  decode.d3.loss_cls: 1.0500  decode.d3.loss_mask: 0.9072  decode.d3.loss_dice: 1.3614  decode.d4.loss_cls: 1.0416  decode.d4.loss_mask: 0.9382  decode.d4.loss_dice: 1.3971  decode.d5.loss_cls: 1.0434  decode.d5.loss_mask: 0.8978  decode.d5.loss_dice: 1.3719  decode.d6.loss_cls: 1.1284  decode.d6.loss_mask: 0.8839  decode.d6.loss_dice: 1.3474  decode.d7.loss_cls: 1.0702  decode.d7.loss_mask: 0.9238  decode.d7.loss_dice: 1.3597  decode.d8.loss_cls: 1.0519  decode.d8.loss_mask: 0.8834  decode.d8.loss_dice: 1.3436
2023/05/24 03:27:36 - mmengine - INFO - Iter(train) [ 74650/160000]  lr: 5.6804e-06  eta: 10:10:52  time: 0.4246  data_time: 0.0100  memory: 4802  grad_norm: 98.7723  loss: 35.2018  decode.loss_cls: 1.2937  decode.loss_mask: 0.7373  decode.loss_dice: 1.2318  decode.d0.loss_cls: 3.0440  decode.d0.loss_mask: 0.8215  decode.d0.loss_dice: 1.4311  decode.d1.loss_cls: 1.4020  decode.d1.loss_mask: 0.7906  decode.d1.loss_dice: 1.3582  decode.d2.loss_cls: 1.2628  decode.d2.loss_mask: 0.7662  decode.d2.loss_dice: 1.3220  decode.d3.loss_cls: 1.2915  decode.d3.loss_mask: 0.7468  decode.d3.loss_dice: 1.2288  decode.d4.loss_cls: 1.2759  decode.d4.loss_mask: 0.7660  decode.d4.loss_dice: 1.2643  decode.d5.loss_cls: 1.2608  decode.d5.loss_mask: 0.7577  decode.d5.loss_dice: 1.2428  decode.d6.loss_cls: 1.2826  decode.d6.loss_mask: 0.7626  decode.d6.loss_dice: 1.2600  decode.d7.loss_cls: 1.2706  decode.d7.loss_mask: 0.7755  decode.d7.loss_dice: 1.2583  decode.d8.loss_cls: 1.3070  decode.d8.loss_mask: 0.7502  decode.d8.loss_dice: 1.2390
2023/05/24 03:27:57 - mmengine - INFO - Iter(train) [ 74700/160000]  lr: 5.6774e-06  eta: 10:10:30  time: 0.4204  data_time: 0.0105  memory: 4857  grad_norm: 97.3890  loss: 29.6716  decode.loss_cls: 0.9892  decode.loss_mask: 0.7641  decode.loss_dice: 1.0085  decode.d0.loss_cls: 2.7418  decode.d0.loss_mask: 0.7749  decode.d0.loss_dice: 1.1264  decode.d1.loss_cls: 1.0254  decode.d1.loss_mask: 0.7500  decode.d1.loss_dice: 1.0760  decode.d2.loss_cls: 0.9347  decode.d2.loss_mask: 0.7886  decode.d2.loss_dice: 1.0700  decode.d3.loss_cls: 0.9638  decode.d3.loss_mask: 0.7806  decode.d3.loss_dice: 1.0211  decode.d4.loss_cls: 0.9501  decode.d4.loss_mask: 0.7807  decode.d4.loss_dice: 1.0498  decode.d5.loss_cls: 0.9623  decode.d5.loss_mask: 0.7613  decode.d5.loss_dice: 1.0228  decode.d6.loss_cls: 1.0087  decode.d6.loss_mask: 0.7619  decode.d6.loss_dice: 1.0184  decode.d7.loss_cls: 1.0033  decode.d7.loss_mask: 0.7695  decode.d7.loss_dice: 1.0265  decode.d8.loss_cls: 0.9877  decode.d8.loss_mask: 0.7481  decode.d8.loss_dice: 1.0054
2023/05/24 03:28:19 - mmengine - INFO - Iter(train) [ 74750/160000]  lr: 5.6744e-06  eta: 10:10:09  time: 0.4282  data_time: 0.0105  memory: 4889  grad_norm: 96.4986  loss: 43.5644  decode.loss_cls: 1.3619  decode.loss_mask: 1.0202  decode.loss_dice: 1.6729  decode.d0.loss_cls: 3.5238  decode.d0.loss_mask: 1.0967  decode.d0.loss_dice: 1.9827  decode.d1.loss_cls: 1.4548  decode.d1.loss_mask: 1.0678  decode.d1.loss_dice: 1.7746  decode.d2.loss_cls: 1.4379  decode.d2.loss_mask: 1.0263  decode.d2.loss_dice: 1.7340  decode.d3.loss_cls: 1.3613  decode.d3.loss_mask: 1.0197  decode.d3.loss_dice: 1.6861  decode.d4.loss_cls: 1.3478  decode.d4.loss_mask: 1.0142  decode.d4.loss_dice: 1.6886  decode.d5.loss_cls: 1.3606  decode.d5.loss_mask: 1.0302  decode.d5.loss_dice: 1.7062  decode.d6.loss_cls: 1.3377  decode.d6.loss_mask: 1.0266  decode.d6.loss_dice: 1.6937  decode.d7.loss_cls: 1.3363  decode.d7.loss_mask: 1.0155  decode.d7.loss_dice: 1.7242  decode.d8.loss_cls: 1.3625  decode.d8.loss_mask: 1.0229  decode.d8.loss_dice: 1.6767
2023/05/24 03:28:41 - mmengine - INFO - Iter(train) [ 74800/160000]  lr: 5.6714e-06  eta: 10:09:48  time: 0.4202  data_time: 0.0103  memory: 4911  grad_norm: 82.0732  loss: 31.8004  decode.loss_cls: 0.9506  decode.loss_mask: 0.7681  decode.loss_dice: 1.0982  decode.d0.loss_cls: 2.9909  decode.d0.loss_mask: 0.9572  decode.d0.loss_dice: 1.3026  decode.d1.loss_cls: 1.0910  decode.d1.loss_mask: 0.9300  decode.d1.loss_dice: 1.2593  decode.d2.loss_cls: 1.1078  decode.d2.loss_mask: 0.8391  decode.d2.loss_dice: 1.1523  decode.d3.loss_cls: 1.0422  decode.d3.loss_mask: 0.8669  decode.d3.loss_dice: 1.1352  decode.d4.loss_cls: 1.0402  decode.d4.loss_mask: 0.8030  decode.d4.loss_dice: 1.1276  decode.d5.loss_cls: 1.0022  decode.d5.loss_mask: 0.7697  decode.d5.loss_dice: 1.0769  decode.d6.loss_cls: 1.0126  decode.d6.loss_mask: 0.7817  decode.d6.loss_dice: 1.0885  decode.d7.loss_cls: 0.9458  decode.d7.loss_mask: 0.7718  decode.d7.loss_dice: 1.0928  decode.d8.loss_cls: 0.9475  decode.d8.loss_mask: 0.7777  decode.d8.loss_dice: 1.0710
2023/05/24 03:29:04 - mmengine - INFO - Iter(train) [ 74850/160000]  lr: 5.6684e-06  eta: 10:09:28  time: 0.4424  data_time: 0.0105  memory: 4804  grad_norm: 103.8549  loss: 31.9938  decode.loss_cls: 1.0447  decode.loss_mask: 0.7473  decode.loss_dice: 1.1667  decode.d0.loss_cls: 2.6740  decode.d0.loss_mask: 0.9195  decode.d0.loss_dice: 1.3345  decode.d1.loss_cls: 1.2086  decode.d1.loss_mask: 0.7566  decode.d1.loss_dice: 1.2219  decode.d2.loss_cls: 1.2368  decode.d2.loss_mask: 0.7127  decode.d2.loss_dice: 1.1152  decode.d3.loss_cls: 1.1348  decode.d3.loss_mask: 0.7492  decode.d3.loss_dice: 1.1629  decode.d4.loss_cls: 1.0981  decode.d4.loss_mask: 0.7484  decode.d4.loss_dice: 1.1644  decode.d5.loss_cls: 1.0978  decode.d5.loss_mask: 0.7389  decode.d5.loss_dice: 1.1647  decode.d6.loss_cls: 1.0968  decode.d6.loss_mask: 0.7202  decode.d6.loss_dice: 1.1407  decode.d7.loss_cls: 1.0248  decode.d7.loss_mask: 0.7264  decode.d7.loss_dice: 1.1356  decode.d8.loss_cls: 1.1025  decode.d8.loss_mask: 0.7261  decode.d8.loss_dice: 1.1229
2023/05/24 03:29:25 - mmengine - INFO - Iter(train) [ 74900/160000]  lr: 5.6654e-06  eta: 10:09:06  time: 0.4117  data_time: 0.0103  memory: 4869  grad_norm: 91.8721  loss: 36.8287  decode.loss_cls: 1.4555  decode.loss_mask: 0.7047  decode.loss_dice: 1.2195  decode.d0.loss_cls: 3.3997  decode.d0.loss_mask: 0.7445  decode.d0.loss_dice: 1.4075  decode.d1.loss_cls: 1.5253  decode.d1.loss_mask: 0.8276  decode.d1.loss_dice: 1.2968  decode.d2.loss_cls: 1.4915  decode.d2.loss_mask: 0.8000  decode.d2.loss_dice: 1.2588  decode.d3.loss_cls: 1.4603  decode.d3.loss_mask: 0.7805  decode.d3.loss_dice: 1.2886  decode.d4.loss_cls: 1.4486  decode.d4.loss_mask: 0.7749  decode.d4.loss_dice: 1.2816  decode.d5.loss_cls: 1.4119  decode.d5.loss_mask: 0.7838  decode.d5.loss_dice: 1.2543  decode.d6.loss_cls: 1.4360  decode.d6.loss_mask: 0.7001  decode.d6.loss_dice: 1.2220  decode.d7.loss_cls: 1.4793  decode.d7.loss_mask: 0.7139  decode.d7.loss_dice: 1.2390  decode.d8.loss_cls: 1.5004  decode.d8.loss_mask: 0.6927  decode.d8.loss_dice: 1.2292
2023/05/24 03:29:45 - mmengine - INFO - Iter(train) [ 74950/160000]  lr: 5.6624e-06  eta: 10:08:44  time: 0.4176  data_time: 0.0103  memory: 4829  grad_norm: 89.6073  loss: 38.4963  decode.loss_cls: 1.3800  decode.loss_mask: 0.8202  decode.loss_dice: 1.3949  decode.d0.loss_cls: 3.1918  decode.d0.loss_mask: 0.8387  decode.d0.loss_dice: 1.5442  decode.d1.loss_cls: 1.5785  decode.d1.loss_mask: 0.8418  decode.d1.loss_dice: 1.4783  decode.d2.loss_cls: 1.5189  decode.d2.loss_mask: 0.8104  decode.d2.loss_dice: 1.4219  decode.d3.loss_cls: 1.4004  decode.d3.loss_mask: 0.8513  decode.d3.loss_dice: 1.3767  decode.d4.loss_cls: 1.4217  decode.d4.loss_mask: 0.8231  decode.d4.loss_dice: 1.3772  decode.d5.loss_cls: 1.4279  decode.d5.loss_mask: 0.8250  decode.d5.loss_dice: 1.3854  decode.d6.loss_cls: 1.3793  decode.d6.loss_mask: 0.8131  decode.d6.loss_dice: 1.3961  decode.d7.loss_cls: 1.4452  decode.d7.loss_mask: 0.8184  decode.d7.loss_dice: 1.3509  decode.d8.loss_cls: 1.4003  decode.d8.loss_mask: 0.8331  decode.d8.loss_dice: 1.3515
2023/05/24 03:30:07 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 03:30:07 - mmengine - INFO - Iter(train) [ 75000/160000]  lr: 5.6594e-06  eta: 10:08:22  time: 0.4726  data_time: 0.0100  memory: 4859  grad_norm: 181.1066  loss: 30.8664  decode.loss_cls: 1.1522  decode.loss_mask: 0.6270  decode.loss_dice: 0.9924  decode.d0.loss_cls: 2.9347  decode.d0.loss_mask: 0.6953  decode.d0.loss_dice: 1.2229  decode.d1.loss_cls: 1.3812  decode.d1.loss_mask: 0.7310  decode.d1.loss_dice: 1.1428  decode.d2.loss_cls: 1.2797  decode.d2.loss_mask: 0.6630  decode.d2.loss_dice: 1.0717  decode.d3.loss_cls: 1.2410  decode.d3.loss_mask: 0.6223  decode.d3.loss_dice: 1.0139  decode.d4.loss_cls: 1.1763  decode.d4.loss_mask: 0.6466  decode.d4.loss_dice: 1.0302  decode.d5.loss_cls: 1.1938  decode.d5.loss_mask: 0.6296  decode.d5.loss_dice: 1.0323  decode.d6.loss_cls: 1.1744  decode.d6.loss_mask: 0.6445  decode.d6.loss_dice: 1.0003  decode.d7.loss_cls: 1.1663  decode.d7.loss_mask: 0.6356  decode.d7.loss_dice: 1.0085  decode.d8.loss_cls: 1.1151  decode.d8.loss_mask: 0.6435  decode.d8.loss_dice: 0.9984
2023/05/24 03:30:07 - mmengine - INFO - Saving checkpoint at 75000 iterations
2023/05/24 03:30:17 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0829  data_time: 0.0018  memory: 2167  
2023/05/24 03:30:21 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:44  time: 0.0837  data_time: 0.0019  memory: 2216  
2023/05/24 03:30:25 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:39  time: 0.0789  data_time: 0.0018  memory: 2167  
2023/05/24 03:30:29 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0798  data_time: 0.0018  memory: 2104  
2023/05/24 03:30:33 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0787  data_time: 0.0018  memory: 2831  
2023/05/24 03:30:39 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0922  data_time: 0.0019  memory: 2167  
2023/05/24 03:30:44 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0818  data_time: 0.0019  memory: 2167  
2023/05/24 03:30:48 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0795  data_time: 0.0019  memory: 2167  
2023/05/24 03:30:52 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0794  data_time: 0.0019  memory: 2944  
2023/05/24 03:30:56 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0805  data_time: 0.0019  memory: 2356  
2023/05/24 03:31:00 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0783  data_time: 0.0018  memory: 2217  
2023/05/24 03:31:04 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0777  data_time: 0.0017  memory: 2328  
2023/05/24 03:31:08 - mmengine - INFO - per class results:
2023/05/24 03:31:08 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.63 | 94.05 |
|     bicycle      | 67.92 | 81.78 |
|       car        | 56.41 | 86.14 |
|    motorcycle    |  81.6 | 90.69 |
|     airplane     |  83.6 | 92.32 |
|       bus        | 82.15 |  87.4 |
|      train       | 81.73 | 94.42 |
|      truck       | 52.93 | 69.59 |
|       boat       | 56.92 | 77.88 |
|  traffic light   | 67.88 | 85.25 |
|   fire hydrant   | 86.95 | 94.41 |
|    stop sign     | 90.06 | 93.54 |
|  parking meter   | 59.65 | 86.74 |
|      bench       | 48.81 | 70.61 |
|       bird       | 79.56 |  90.5 |
|       cat        | 84.94 | 92.34 |
|       dog        | 78.48 | 85.67 |
|      horse       | 81.81 | 89.25 |
|      sheep       |  85.8 | 91.87 |
|       cow        | 77.15 | 85.16 |
|     elephant     |  90.0 | 96.16 |
|       bear       |  88.3 | 94.92 |
|      zebra       | 92.38 | 95.49 |
|     giraffe      | 87.03 | 92.93 |
|     backpack     |  35.1 | 61.78 |
|     umbrella     | 77.74 | 85.93 |
|     handbag      | 32.88 | 53.87 |
|       tie        | 11.09 | 13.35 |
|     suitcase     | 77.23 | 89.07 |
|     frisbee      | 72.33 | 88.42 |
|       skis       | 44.27 |  61.6 |
|    snowboard     |  56.2 | 67.87 |
|   sports ball    | 43.13 | 73.59 |
|       kite       | 53.04 | 61.57 |
|   baseball bat   | 53.25 | 66.07 |
|  baseball glove  | 69.96 | 88.06 |
|    skateboard    | 71.35 | 83.31 |
|    surfboard     | 75.09 | 86.09 |
|  tennis racket   |  66.1 |  70.4 |
|      bottle      | 37.15 | 47.31 |
|    wine glass    | 56.29 | 77.08 |
|       cup        |  48.3 | 68.48 |
|       fork       | 22.08 | 25.54 |
|      knife       | 24.78 | 31.01 |
|      spoon       | 29.89 | 53.74 |
|       bowl       | 44.02 | 56.45 |
|      banana      | 64.66 | 82.73 |
|      apple       |  50.8 | 63.52 |
|     sandwich     | 44.29 |  60.8 |
|      orange      | 66.39 | 76.56 |
|     broccoli     | 58.49 | 74.82 |
|      carrot      | 49.21 | 57.33 |
|     hot dog      | 45.04 | 53.76 |
|      pizza       | 69.15 | 81.98 |
|      donut       | 65.74 | 78.18 |
|       cake       | 68.44 | 80.37 |
|      chair       | 43.04 | 61.33 |
|      couch       | 54.14 |  75.5 |
|   potted plant   | 31.59 | 45.36 |
|       bed        | 61.19 | 80.69 |
|   dining table   | 41.27 | 80.24 |
|      toilet      | 77.08 | 93.71 |
|        tv        | 77.56 | 86.03 |
|      laptop      | 69.98 | 80.74 |
|      mouse       |  62.2 | 84.95 |
|      remote      | 54.52 | 72.08 |
|     keyboard     | 63.71 | 81.47 |
|    cell phone    | 67.71 | 82.87 |
|    microwave     |  66.1 | 82.26 |
|       oven       | 55.03 | 81.87 |
|     toaster      | 35.72 | 44.82 |
|       sink       | 53.81 | 72.55 |
|   refrigerator   | 77.69 | 90.08 |
|       book       | 48.56 | 67.63 |
|      clock       |  71.9 | 85.33 |
|       vase       | 56.87 | 82.47 |
|     scissors     | 70.27 | 82.27 |
|    teddy bear    | 73.46 | 85.11 |
|    hair drier    | 38.83 | 39.78 |
|    toothbrush    | 32.55 | 71.08 |
|      banner      | 33.82 | 58.22 |
|     blanket      |  3.29 |  3.86 |
|      branch      | 14.96 | 18.84 |
|      bridge      | 29.36 | 51.24 |
|  building-other  | 52.17 | 76.64 |
|       bush       | 30.19 | 42.91 |
|     cabinet      | 51.11 | 72.43 |
|       cage       | 12.36 | 15.41 |
|    cardboard     | 42.83 | 53.45 |
|      carpet      | 51.15 |  67.4 |
|  ceiling-other   | 63.97 | 79.91 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 18.16 |  24.7 |
|      clouds      | 43.61 | 54.47 |
|     counter      | 27.48 | 43.82 |
|     cupboard     |  0.61 |  0.76 |
|     curtain      | 62.01 | 72.78 |
|    desk-stuff    | 43.24 | 53.28 |
|       dirt       | 40.74 | 65.84 |
|    door-stuff    | 38.29 | 57.78 |
|      fence       | 31.92 | 58.19 |
|   floor-marble   |  0.02 |  0.02 |
|   floor-other    | 20.94 | 26.96 |
|   floor-stone    |  6.95 |  9.19 |
|    floor-tile    | 59.49 |  68.7 |
|    floor-wood    |  59.2 | 74.74 |
|      flower      | 43.48 | 61.14 |
|       fog        |  8.2  |  8.67 |
|    food-other    | 28.86 | 33.46 |
|      fruit       | 36.47 | 62.68 |
| furniture-other  | 15.08 | 18.84 |
|      grass       | 69.87 | 84.69 |
|      gravel      | 29.14 |  36.6 |
|   ground-other   |  3.89 |  5.25 |
|       hill       | 14.84 | 18.02 |
|      house       | 24.25 | 28.65 |
|      leaves      | 19.94 | 24.38 |
|      light       | 35.83 | 51.19 |
|       mat        |  0.0  |  0.0  |
|      metal       | 30.82 | 45.47 |
|   mirror-stuff   | 46.43 | 59.35 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 54.05 | 72.88 |
|       mud        |  0.0  |  0.0  |
|      napkin      |  7.08 |  7.87 |
|       net        | 34.08 | 70.03 |
|      paper       |  27.4 | 37.95 |
|     pavement     | 48.96 | 65.61 |
|      pillow      | 10.96 | 23.47 |
|   plant-other    | 20.33 | 43.31 |
|     plastic      | 18.14 | 23.31 |
|     platform     | 25.84 | 39.08 |
|   playingfield   | 66.18 | 81.53 |
|     railing      |  4.26 |  5.32 |
|     railroad     | 59.76 | 76.92 |
|      river       | 51.87 | 81.09 |
|       road       | 64.54 | 82.93 |
|       rock       | 37.28 |  61.0 |
|       roof       | 11.35 | 13.61 |
|       rug        | 35.35 | 65.08 |
|      salad       |  0.0  |  0.0  |
|       sand       | 60.85 | 68.25 |
|       sea        | 85.33 | 89.82 |
|      shelf       | 33.77 | 44.33 |
|    sky-other     | 69.88 |  87.8 |
|    skyscraper    | 21.39 | 24.69 |
|       snow       | 89.34 |  92.1 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 22.47 | 38.32 |
|      stone       |  3.66 |  6.4  |
|      straw       | 28.42 | 40.72 |
| structural-other |  0.01 |  0.01 |
|      table       | 18.16 | 24.91 |
|       tent       |  6.24 |  8.2  |
|  textile-other   |  7.52 | 12.21 |
|      towel       | 33.64 | 40.65 |
|       tree       | 72.58 | 85.34 |
|    vegetable     | 45.12 | 59.05 |
|    wall-brick    | 47.89 | 58.56 |
|  wall-concrete   | 55.02 | 66.22 |
|    wall-other    | 18.71 | 39.79 |
|    wall-panel    |  0.22 |  0.22 |
|    wall-stone    | 33.11 | 39.81 |
|    wall-tile     | 60.81 | 79.54 |
|    wall-wood     | 36.69 | 61.08 |
|   water-other    | 24.08 |  35.6 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 46.93 |  54.7 |
|   window-other   | 43.46 | 73.12 |
|       wood       | 23.64 | 32.97 |
+------------------+-------+-------+
2023/05/24 03:31:08 - mmengine - INFO - Iter(val) [625/625]    aAcc: 69.9100  mIoU: 45.1900  mAcc: 57.6300  data_time: 0.0021  time: 0.0857
2023/05/24 03:31:29 - mmengine - INFO - Iter(train) [ 75050/160000]  lr: 5.6564e-06  eta: 10:08:03  time: 0.4521  data_time: 0.0103  memory: 4876  grad_norm: 79.7545  loss: 33.8349  decode.loss_cls: 1.0607  decode.loss_mask: 0.8197  decode.loss_dice: 1.2090  decode.d0.loss_cls: 3.2000  decode.d0.loss_mask: 0.8450  decode.d0.loss_dice: 1.2889  decode.d1.loss_cls: 1.2671  decode.d1.loss_mask: 0.8484  decode.d1.loss_dice: 1.3108  decode.d2.loss_cls: 1.1506  decode.d2.loss_mask: 0.7968  decode.d2.loss_dice: 1.2217  decode.d3.loss_cls: 1.1489  decode.d3.loss_mask: 0.8048  decode.d3.loss_dice: 1.2100  decode.d4.loss_cls: 1.2050  decode.d4.loss_mask: 0.7594  decode.d4.loss_dice: 1.1812  decode.d5.loss_cls: 1.2087  decode.d5.loss_mask: 0.7656  decode.d5.loss_dice: 1.1816  decode.d6.loss_cls: 1.1325  decode.d6.loss_mask: 0.7851  decode.d6.loss_dice: 1.1742  decode.d7.loss_cls: 1.1320  decode.d7.loss_mask: 0.7961  decode.d7.loss_dice: 1.2133  decode.d8.loss_cls: 1.1161  decode.d8.loss_mask: 0.8090  decode.d8.loss_dice: 1.1926
2023/05/24 03:31:50 - mmengine - INFO - Iter(train) [ 75100/160000]  lr: 5.6534e-06  eta: 10:07:41  time: 0.4193  data_time: 0.0104  memory: 4940  grad_norm: 97.2961  loss: 36.0431  decode.loss_cls: 1.1686  decode.loss_mask: 0.7413  decode.loss_dice: 1.4019  decode.d0.loss_cls: 3.0701  decode.d0.loss_mask: 0.8103  decode.d0.loss_dice: 1.6502  decode.d1.loss_cls: 1.2131  decode.d1.loss_mask: 0.7851  decode.d1.loss_dice: 1.4868  decode.d2.loss_cls: 1.2629  decode.d2.loss_mask: 0.7433  decode.d2.loss_dice: 1.4567  decode.d3.loss_cls: 1.2410  decode.d3.loss_mask: 0.7368  decode.d3.loss_dice: 1.4237  decode.d4.loss_cls: 1.2380  decode.d4.loss_mask: 0.7539  decode.d4.loss_dice: 1.3797  decode.d5.loss_cls: 1.2442  decode.d5.loss_mask: 0.7668  decode.d5.loss_dice: 1.3954  decode.d6.loss_cls: 1.2399  decode.d6.loss_mask: 0.7376  decode.d6.loss_dice: 1.4142  decode.d7.loss_cls: 1.2151  decode.d7.loss_mask: 0.7464  decode.d7.loss_dice: 1.4090  decode.d8.loss_cls: 1.2061  decode.d8.loss_mask: 0.7388  decode.d8.loss_dice: 1.3661
2023/05/24 03:32:11 - mmengine - INFO - Iter(train) [ 75150/160000]  lr: 5.6504e-06  eta: 10:07:18  time: 0.4115  data_time: 0.0103  memory: 4930  grad_norm: 81.5911  loss: 48.9991  decode.loss_cls: 1.7985  decode.loss_mask: 0.8700  decode.loss_dice: 1.8491  decode.d0.loss_cls: 3.8257  decode.d0.loss_mask: 0.9879  decode.d0.loss_dice: 2.2067  decode.d1.loss_cls: 1.9901  decode.d1.loss_mask: 0.9712  decode.d1.loss_dice: 2.0712  decode.d2.loss_cls: 1.9902  decode.d2.loss_mask: 0.9356  decode.d2.loss_dice: 1.9683  decode.d3.loss_cls: 1.8591  decode.d3.loss_mask: 0.9162  decode.d3.loss_dice: 1.8990  decode.d4.loss_cls: 1.8569  decode.d4.loss_mask: 0.9067  decode.d4.loss_dice: 1.8862  decode.d5.loss_cls: 1.8255  decode.d5.loss_mask: 0.8987  decode.d5.loss_dice: 1.8785  decode.d6.loss_cls: 1.8526  decode.d6.loss_mask: 0.8737  decode.d6.loss_dice: 1.8119  decode.d7.loss_cls: 1.7651  decode.d7.loss_mask: 0.8886  decode.d7.loss_dice: 1.8561  decode.d8.loss_cls: 1.7807  decode.d8.loss_mask: 0.9086  decode.d8.loss_dice: 1.8708
2023/05/24 03:32:32 - mmengine - INFO - Iter(train) [ 75200/160000]  lr: 5.6474e-06  eta: 10:06:57  time: 0.4284  data_time: 0.0103  memory: 4835  grad_norm: 103.8655  loss: 35.0453  decode.loss_cls: 1.1803  decode.loss_mask: 0.7898  decode.loss_dice: 1.2541  decode.d0.loss_cls: 2.9241  decode.d0.loss_mask: 0.8800  decode.d0.loss_dice: 1.4291  decode.d1.loss_cls: 1.3002  decode.d1.loss_mask: 0.8253  decode.d1.loss_dice: 1.3636  decode.d2.loss_cls: 1.1916  decode.d2.loss_mask: 0.8490  decode.d2.loss_dice: 1.3577  decode.d3.loss_cls: 1.2057  decode.d3.loss_mask: 0.8153  decode.d3.loss_dice: 1.3001  decode.d4.loss_cls: 1.2038  decode.d4.loss_mask: 0.7994  decode.d4.loss_dice: 1.3309  decode.d5.loss_cls: 1.1406  decode.d5.loss_mask: 0.8138  decode.d5.loss_dice: 1.3253  decode.d6.loss_cls: 1.1482  decode.d6.loss_mask: 0.8059  decode.d6.loss_dice: 1.3137  decode.d7.loss_cls: 1.1432  decode.d7.loss_mask: 0.8059  decode.d7.loss_dice: 1.3185  decode.d8.loss_cls: 1.1647  decode.d8.loss_mask: 0.7916  decode.d8.loss_dice: 1.2741
2023/05/24 03:32:54 - mmengine - INFO - Iter(train) [ 75250/160000]  lr: 5.6444e-06  eta: 10:06:35  time: 0.4200  data_time: 0.0105  memory: 4920  grad_norm: 89.6169  loss: 30.4033  decode.loss_cls: 1.1712  decode.loss_mask: 0.6213  decode.loss_dice: 0.9767  decode.d0.loss_cls: 2.9225  decode.d0.loss_mask: 0.7295  decode.d0.loss_dice: 1.1343  decode.d1.loss_cls: 1.2428  decode.d1.loss_mask: 0.6569  decode.d1.loss_dice: 1.0831  decode.d2.loss_cls: 1.2394  decode.d2.loss_mask: 0.6425  decode.d2.loss_dice: 1.0103  decode.d3.loss_cls: 1.2135  decode.d3.loss_mask: 0.6537  decode.d3.loss_dice: 0.9956  decode.d4.loss_cls: 1.1741  decode.d4.loss_mask: 0.6343  decode.d4.loss_dice: 0.9935  decode.d5.loss_cls: 1.1724  decode.d5.loss_mask: 0.6490  decode.d5.loss_dice: 1.0077  decode.d6.loss_cls: 1.2293  decode.d6.loss_mask: 0.6556  decode.d6.loss_dice: 0.9654  decode.d7.loss_cls: 1.1745  decode.d7.loss_mask: 0.6567  decode.d7.loss_dice: 0.9734  decode.d8.loss_cls: 1.1971  decode.d8.loss_mask: 0.6470  decode.d8.loss_dice: 0.9797
2023/05/24 03:33:15 - mmengine - INFO - Iter(train) [ 75300/160000]  lr: 5.6414e-06  eta: 10:06:13  time: 0.4236  data_time: 0.0105  memory: 4837  grad_norm: 114.5285  loss: 37.6988  decode.loss_cls: 1.3589  decode.loss_mask: 0.7891  decode.loss_dice: 1.4275  decode.d0.loss_cls: 3.1913  decode.d0.loss_mask: 0.7890  decode.d0.loss_dice: 1.6597  decode.d1.loss_cls: 1.5342  decode.d1.loss_mask: 0.8087  decode.d1.loss_dice: 1.5174  decode.d2.loss_cls: 1.4178  decode.d2.loss_mask: 0.7838  decode.d2.loss_dice: 1.4838  decode.d3.loss_cls: 1.3638  decode.d3.loss_mask: 0.7511  decode.d3.loss_dice: 1.4205  decode.d4.loss_cls: 1.2915  decode.d4.loss_mask: 0.7788  decode.d4.loss_dice: 1.4138  decode.d5.loss_cls: 1.3117  decode.d5.loss_mask: 0.7828  decode.d5.loss_dice: 1.3968  decode.d6.loss_cls: 1.2825  decode.d6.loss_mask: 0.7731  decode.d6.loss_dice: 1.4266  decode.d7.loss_cls: 1.2885  decode.d7.loss_mask: 0.7907  decode.d7.loss_dice: 1.4228  decode.d8.loss_cls: 1.2674  decode.d8.loss_mask: 0.7834  decode.d8.loss_dice: 1.3920
2023/05/24 03:33:36 - mmengine - INFO - Iter(train) [ 75350/160000]  lr: 5.6384e-06  eta: 10:05:51  time: 0.4107  data_time: 0.0106  memory: 4829  grad_norm: 87.0957  loss: 30.1761  decode.loss_cls: 0.9956  decode.loss_mask: 0.7650  decode.loss_dice: 0.9761  decode.d0.loss_cls: 2.9086  decode.d0.loss_mask: 0.7955  decode.d0.loss_dice: 1.1775  decode.d1.loss_cls: 1.1004  decode.d1.loss_mask: 0.8279  decode.d1.loss_dice: 1.0720  decode.d2.loss_cls: 0.9993  decode.d2.loss_mask: 0.8463  decode.d2.loss_dice: 1.0153  decode.d3.loss_cls: 0.9824  decode.d3.loss_mask: 0.8108  decode.d3.loss_dice: 1.0223  decode.d4.loss_cls: 0.9491  decode.d4.loss_mask: 0.8003  decode.d4.loss_dice: 1.0308  decode.d5.loss_cls: 0.9941  decode.d5.loss_mask: 0.7814  decode.d5.loss_dice: 1.0249  decode.d6.loss_cls: 0.9689  decode.d6.loss_mask: 0.7741  decode.d6.loss_dice: 1.0208  decode.d7.loss_cls: 1.0299  decode.d7.loss_mask: 0.7605  decode.d7.loss_dice: 0.9727  decode.d8.loss_cls: 1.0164  decode.d8.loss_mask: 0.7770  decode.d8.loss_dice: 0.9804
2023/05/24 03:33:58 - mmengine - INFO - Iter(train) [ 75400/160000]  lr: 5.6354e-06  eta: 10:05:30  time: 0.4114  data_time: 0.0105  memory: 4848  grad_norm: 96.1314  loss: 34.3197  decode.loss_cls: 1.1911  decode.loss_mask: 0.7868  decode.loss_dice: 1.1393  decode.d0.loss_cls: 3.0282  decode.d0.loss_mask: 0.8323  decode.d0.loss_dice: 1.3856  decode.d1.loss_cls: 1.4725  decode.d1.loss_mask: 0.8512  decode.d1.loss_dice: 1.2306  decode.d2.loss_cls: 1.3230  decode.d2.loss_mask: 0.8061  decode.d2.loss_dice: 1.1754  decode.d3.loss_cls: 1.3098  decode.d3.loss_mask: 0.8057  decode.d3.loss_dice: 1.1409  decode.d4.loss_cls: 1.2786  decode.d4.loss_mask: 0.7920  decode.d4.loss_dice: 1.1343  decode.d5.loss_cls: 1.2116  decode.d5.loss_mask: 0.8291  decode.d5.loss_dice: 1.1654  decode.d6.loss_cls: 1.2268  decode.d6.loss_mask: 0.7881  decode.d6.loss_dice: 1.1399  decode.d7.loss_cls: 1.2544  decode.d7.loss_mask: 0.7776  decode.d7.loss_dice: 1.1324  decode.d8.loss_cls: 1.2186  decode.d8.loss_mask: 0.7660  decode.d8.loss_dice: 1.1261
2023/05/24 03:34:20 - mmengine - INFO - Iter(train) [ 75450/160000]  lr: 5.6324e-06  eta: 10:05:10  time: 0.4693  data_time: 0.0105  memory: 4830  grad_norm: 136.1414  loss: 36.7507  decode.loss_cls: 1.1035  decode.loss_mask: 0.8776  decode.loss_dice: 1.3973  decode.d0.loss_cls: 3.0805  decode.d0.loss_mask: 0.9297  decode.d0.loss_dice: 1.6340  decode.d1.loss_cls: 1.3121  decode.d1.loss_mask: 0.9448  decode.d1.loss_dice: 1.4087  decode.d2.loss_cls: 1.2223  decode.d2.loss_mask: 0.9171  decode.d2.loss_dice: 1.4316  decode.d3.loss_cls: 1.2398  decode.d3.loss_mask: 0.8851  decode.d3.loss_dice: 1.3998  decode.d4.loss_cls: 1.1228  decode.d4.loss_mask: 0.8809  decode.d4.loss_dice: 1.4084  decode.d5.loss_cls: 1.1698  decode.d5.loss_mask: 0.8656  decode.d5.loss_dice: 1.4016  decode.d6.loss_cls: 1.0952  decode.d6.loss_mask: 0.8836  decode.d6.loss_dice: 1.3922  decode.d7.loss_cls: 1.1099  decode.d7.loss_mask: 0.8810  decode.d7.loss_dice: 1.4057  decode.d8.loss_cls: 1.0881  decode.d8.loss_mask: 0.8838  decode.d8.loss_dice: 1.3781
2023/05/24 03:34:42 - mmengine - INFO - Iter(train) [ 75500/160000]  lr: 5.6294e-06  eta: 10:04:48  time: 0.4071  data_time: 0.0101  memory: 4928  grad_norm: 87.1633  loss: 38.5987  decode.loss_cls: 1.2366  decode.loss_mask: 0.8519  decode.loss_dice: 1.4043  decode.d0.loss_cls: 3.2725  decode.d0.loss_mask: 0.9568  decode.d0.loss_dice: 1.6198  decode.d1.loss_cls: 1.3684  decode.d1.loss_mask: 1.0123  decode.d1.loss_dice: 1.6097  decode.d2.loss_cls: 1.2842  decode.d2.loss_mask: 0.9766  decode.d2.loss_dice: 1.5213  decode.d3.loss_cls: 1.3142  decode.d3.loss_mask: 0.9231  decode.d3.loss_dice: 1.4664  decode.d4.loss_cls: 1.2970  decode.d4.loss_mask: 0.9110  decode.d4.loss_dice: 1.4574  decode.d5.loss_cls: 1.2132  decode.d5.loss_mask: 0.9154  decode.d5.loss_dice: 1.4421  decode.d6.loss_cls: 1.2295  decode.d6.loss_mask: 0.8682  decode.d6.loss_dice: 1.4143  decode.d7.loss_cls: 1.2447  decode.d7.loss_mask: 0.8832  decode.d7.loss_dice: 1.4115  decode.d8.loss_cls: 1.2281  decode.d8.loss_mask: 0.8501  decode.d8.loss_dice: 1.4149
2023/05/24 03:35:03 - mmengine - INFO - Iter(train) [ 75550/160000]  lr: 5.6264e-06  eta: 10:04:26  time: 0.4243  data_time: 0.0105  memory: 4857  grad_norm: 101.5658  loss: 33.0815  decode.loss_cls: 1.1713  decode.loss_mask: 0.7955  decode.loss_dice: 1.0843  decode.d0.loss_cls: 2.9631  decode.d0.loss_mask: 0.8211  decode.d0.loss_dice: 1.2959  decode.d1.loss_cls: 1.2566  decode.d1.loss_mask: 0.8360  decode.d1.loss_dice: 1.2002  decode.d2.loss_cls: 1.2596  decode.d2.loss_mask: 0.8630  decode.d2.loss_dice: 1.1590  decode.d3.loss_cls: 1.1540  decode.d3.loss_mask: 0.8083  decode.d3.loss_dice: 1.1011  decode.d4.loss_cls: 1.1981  decode.d4.loss_mask: 0.8042  decode.d4.loss_dice: 1.0928  decode.d5.loss_cls: 1.2431  decode.d5.loss_mask: 0.7358  decode.d5.loss_dice: 1.0763  decode.d6.loss_cls: 1.1594  decode.d6.loss_mask: 0.7691  decode.d6.loss_dice: 1.0896  decode.d7.loss_cls: 1.1545  decode.d7.loss_mask: 0.8224  decode.d7.loss_dice: 1.0953  decode.d8.loss_cls: 1.2210  decode.d8.loss_mask: 0.7855  decode.d8.loss_dice: 1.0653
2023/05/24 03:35:24 - mmengine - INFO - Iter(train) [ 75600/160000]  lr: 5.6234e-06  eta: 10:04:04  time: 0.4286  data_time: 0.0103  memory: 4837  grad_norm: 114.4084  loss: 29.3931  decode.loss_cls: 1.0256  decode.loss_mask: 0.6415  decode.loss_dice: 0.9601  decode.d0.loss_cls: 3.1253  decode.d0.loss_mask: 0.6856  decode.d0.loss_dice: 1.0746  decode.d1.loss_cls: 1.1409  decode.d1.loss_mask: 0.6894  decode.d1.loss_dice: 1.0385  decode.d2.loss_cls: 1.1562  decode.d2.loss_mask: 0.6635  decode.d2.loss_dice: 1.0383  decode.d3.loss_cls: 1.1076  decode.d3.loss_mask: 0.6604  decode.d3.loss_dice: 1.0138  decode.d4.loss_cls: 1.0790  decode.d4.loss_mask: 0.6521  decode.d4.loss_dice: 0.9852  decode.d5.loss_cls: 1.1308  decode.d5.loss_mask: 0.6440  decode.d5.loss_dice: 0.9766  decode.d6.loss_cls: 1.1173  decode.d6.loss_mask: 0.6294  decode.d6.loss_dice: 0.9410  decode.d7.loss_cls: 1.0349  decode.d7.loss_mask: 0.6299  decode.d7.loss_dice: 0.9149  decode.d8.loss_cls: 1.0766  decode.d8.loss_mask: 0.6339  decode.d8.loss_dice: 0.9262
2023/05/24 03:35:45 - mmengine - INFO - Iter(train) [ 75650/160000]  lr: 5.6204e-06  eta: 10:03:43  time: 0.4181  data_time: 0.0106  memory: 4878  grad_norm: 97.1193  loss: 34.9744  decode.loss_cls: 1.0135  decode.loss_mask: 0.8700  decode.loss_dice: 1.2976  decode.d0.loss_cls: 3.0937  decode.d0.loss_mask: 0.9691  decode.d0.loss_dice: 1.5287  decode.d1.loss_cls: 1.2321  decode.d1.loss_mask: 0.8724  decode.d1.loss_dice: 1.3752  decode.d2.loss_cls: 1.0695  decode.d2.loss_mask: 0.8673  decode.d2.loss_dice: 1.3522  decode.d3.loss_cls: 1.0940  decode.d3.loss_mask: 0.8628  decode.d3.loss_dice: 1.3144  decode.d4.loss_cls: 1.0779  decode.d4.loss_mask: 0.8770  decode.d4.loss_dice: 1.3210  decode.d5.loss_cls: 1.0795  decode.d5.loss_mask: 0.8737  decode.d5.loss_dice: 1.2920  decode.d6.loss_cls: 1.0659  decode.d6.loss_mask: 0.8763  decode.d6.loss_dice: 1.2928  decode.d7.loss_cls: 1.0168  decode.d7.loss_mask: 0.8634  decode.d7.loss_dice: 1.3015  decode.d8.loss_cls: 1.0684  decode.d8.loss_mask: 0.8596  decode.d8.loss_dice: 1.2962
2023/05/24 03:36:07 - mmengine - INFO - Iter(train) [ 75700/160000]  lr: 5.6175e-06  eta: 10:03:22  time: 0.4180  data_time: 0.0103  memory: 4860  grad_norm: 106.4700  loss: 34.3141  decode.loss_cls: 0.9923  decode.loss_mask: 0.8615  decode.loss_dice: 1.3117  decode.d0.loss_cls: 3.0732  decode.d0.loss_mask: 0.8727  decode.d0.loss_dice: 1.4241  decode.d1.loss_cls: 1.0957  decode.d1.loss_mask: 0.9221  decode.d1.loss_dice: 1.4462  decode.d2.loss_cls: 1.0360  decode.d2.loss_mask: 0.9192  decode.d2.loss_dice: 1.3697  decode.d3.loss_cls: 0.9672  decode.d3.loss_mask: 0.9261  decode.d3.loss_dice: 1.3273  decode.d4.loss_cls: 0.9561  decode.d4.loss_mask: 0.8505  decode.d4.loss_dice: 1.3226  decode.d5.loss_cls: 0.9291  decode.d5.loss_mask: 0.8714  decode.d5.loss_dice: 1.3459  decode.d6.loss_cls: 1.0079  decode.d6.loss_mask: 0.8934  decode.d6.loss_dice: 1.2895  decode.d7.loss_cls: 0.9771  decode.d7.loss_mask: 0.8727  decode.d7.loss_dice: 1.3149  decode.d8.loss_cls: 0.9688  decode.d8.loss_mask: 0.8635  decode.d8.loss_dice: 1.3059
2023/05/24 03:36:30 - mmengine - INFO - Iter(train) [ 75750/160000]  lr: 5.6145e-06  eta: 10:03:02  time: 0.4193  data_time: 0.0105  memory: 4962  grad_norm: 137.3056  loss: 32.9791  decode.loss_cls: 1.1588  decode.loss_mask: 0.7422  decode.loss_dice: 1.1787  decode.d0.loss_cls: 2.9009  decode.d0.loss_mask: 0.8212  decode.d0.loss_dice: 1.3505  decode.d1.loss_cls: 1.1935  decode.d1.loss_mask: 0.7606  decode.d1.loss_dice: 1.2821  decode.d2.loss_cls: 1.1194  decode.d2.loss_mask: 0.7433  decode.d2.loss_dice: 1.2667  decode.d3.loss_cls: 1.1901  decode.d3.loss_mask: 0.7414  decode.d3.loss_dice: 1.1719  decode.d4.loss_cls: 1.1580  decode.d4.loss_mask: 0.7338  decode.d4.loss_dice: 1.2022  decode.d5.loss_cls: 1.1384  decode.d5.loss_mask: 0.7484  decode.d5.loss_dice: 1.1946  decode.d6.loss_cls: 1.1364  decode.d6.loss_mask: 0.7287  decode.d6.loss_dice: 1.1870  decode.d7.loss_cls: 1.1404  decode.d7.loss_mask: 0.7250  decode.d7.loss_dice: 1.1885  decode.d8.loss_cls: 1.1624  decode.d8.loss_mask: 0.7455  decode.d8.loss_dice: 1.1686
2023/05/24 03:36:51 - mmengine - INFO - Iter(train) [ 75800/160000]  lr: 5.6115e-06  eta: 10:02:40  time: 0.4168  data_time: 0.0103  memory: 4831  grad_norm: 92.7564  loss: 35.1230  decode.loss_cls: 1.2234  decode.loss_mask: 0.7480  decode.loss_dice: 1.2288  decode.d0.loss_cls: 3.3824  decode.d0.loss_mask: 0.7513  decode.d0.loss_dice: 1.4642  decode.d1.loss_cls: 1.4134  decode.d1.loss_mask: 0.7527  decode.d1.loss_dice: 1.3685  decode.d2.loss_cls: 1.2761  decode.d2.loss_mask: 0.7514  decode.d2.loss_dice: 1.3245  decode.d3.loss_cls: 1.2980  decode.d3.loss_mask: 0.7438  decode.d3.loss_dice: 1.2584  decode.d4.loss_cls: 1.2621  decode.d4.loss_mask: 0.7233  decode.d4.loss_dice: 1.2589  decode.d5.loss_cls: 1.2609  decode.d5.loss_mask: 0.7506  decode.d5.loss_dice: 1.2540  decode.d6.loss_cls: 1.2273  decode.d6.loss_mask: 0.7511  decode.d6.loss_dice: 1.2456  decode.d7.loss_cls: 1.2062  decode.d7.loss_mask: 0.7588  decode.d7.loss_dice: 1.2424  decode.d8.loss_cls: 1.2015  decode.d8.loss_mask: 0.7523  decode.d8.loss_dice: 1.2433
2023/05/24 03:37:12 - mmengine - INFO - Iter(train) [ 75850/160000]  lr: 5.6085e-06  eta: 10:02:18  time: 0.4156  data_time: 0.0102  memory: 4869  grad_norm: 82.8677  loss: 33.5560  decode.loss_cls: 1.1071  decode.loss_mask: 0.7331  decode.loss_dice: 1.1518  decode.d0.loss_cls: 3.3816  decode.d0.loss_mask: 0.8392  decode.d0.loss_dice: 1.3541  decode.d1.loss_cls: 1.3092  decode.d1.loss_mask: 0.7978  decode.d1.loss_dice: 1.3282  decode.d2.loss_cls: 1.1896  decode.d2.loss_mask: 0.7729  decode.d2.loss_dice: 1.2726  decode.d3.loss_cls: 1.1825  decode.d3.loss_mask: 0.7549  decode.d3.loss_dice: 1.1646  decode.d4.loss_cls: 1.1647  decode.d4.loss_mask: 0.7524  decode.d4.loss_dice: 1.2028  decode.d5.loss_cls: 1.1032  decode.d5.loss_mask: 0.7336  decode.d5.loss_dice: 1.2085  decode.d6.loss_cls: 1.0904  decode.d6.loss_mask: 0.7380  decode.d6.loss_dice: 1.1864  decode.d7.loss_cls: 1.0998  decode.d7.loss_mask: 0.7340  decode.d7.loss_dice: 1.1569  decode.d8.loss_cls: 1.1433  decode.d8.loss_mask: 0.7411  decode.d8.loss_dice: 1.1617
2023/05/24 03:37:33 - mmengine - INFO - Iter(train) [ 75900/160000]  lr: 5.6055e-06  eta: 10:01:56  time: 0.4183  data_time: 0.0106  memory: 4849  grad_norm: 82.9089  loss: 31.1473  decode.loss_cls: 1.1447  decode.loss_mask: 0.6170  decode.loss_dice: 1.0881  decode.d0.loss_cls: 3.0223  decode.d0.loss_mask: 0.6683  decode.d0.loss_dice: 1.2855  decode.d1.loss_cls: 1.2004  decode.d1.loss_mask: 0.6959  decode.d1.loss_dice: 1.1797  decode.d2.loss_cls: 1.1223  decode.d2.loss_mask: 0.6950  decode.d2.loss_dice: 1.1706  decode.d3.loss_cls: 1.1299  decode.d3.loss_mask: 0.6666  decode.d3.loss_dice: 1.1433  decode.d4.loss_cls: 1.0770  decode.d4.loss_mask: 0.6521  decode.d4.loss_dice: 1.1242  decode.d5.loss_cls: 1.1212  decode.d5.loss_mask: 0.6342  decode.d5.loss_dice: 1.1099  decode.d6.loss_cls: 1.1447  decode.d6.loss_mask: 0.6375  decode.d6.loss_dice: 1.0973  decode.d7.loss_cls: 1.1509  decode.d7.loss_mask: 0.6412  decode.d7.loss_dice: 1.0790  decode.d8.loss_cls: 1.1623  decode.d8.loss_mask: 0.6245  decode.d8.loss_dice: 1.0617
2023/05/24 03:37:54 - mmengine - INFO - Iter(train) [ 75950/160000]  lr: 5.6025e-06  eta: 10:01:33  time: 0.4195  data_time: 0.0101  memory: 4837  grad_norm: 94.9304  loss: 36.3213  decode.loss_cls: 1.2806  decode.loss_mask: 0.7902  decode.loss_dice: 1.2385  decode.d0.loss_cls: 3.1984  decode.d0.loss_mask: 0.8743  decode.d0.loss_dice: 1.4342  decode.d1.loss_cls: 1.3924  decode.d1.loss_mask: 0.8501  decode.d1.loss_dice: 1.3265  decode.d2.loss_cls: 1.2525  decode.d2.loss_mask: 0.8952  decode.d2.loss_dice: 1.3624  decode.d3.loss_cls: 1.2444  decode.d3.loss_mask: 0.9074  decode.d3.loss_dice: 1.3400  decode.d4.loss_cls: 1.1888  decode.d4.loss_mask: 0.8982  decode.d4.loss_dice: 1.3268  decode.d5.loss_cls: 1.2686  decode.d5.loss_mask: 0.8714  decode.d5.loss_dice: 1.2990  decode.d6.loss_cls: 1.2212  decode.d6.loss_mask: 0.8265  decode.d6.loss_dice: 1.2606  decode.d7.loss_cls: 1.2593  decode.d7.loss_mask: 0.8509  decode.d7.loss_dice: 1.2545  decode.d8.loss_cls: 1.2890  decode.d8.loss_mask: 0.8496  decode.d8.loss_dice: 1.2700
2023/05/24 03:38:15 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 03:38:15 - mmengine - INFO - Iter(train) [ 76000/160000]  lr: 5.5995e-06  eta: 10:01:12  time: 0.4262  data_time: 0.0107  memory: 4866  grad_norm: 97.5901  loss: 36.9270  decode.loss_cls: 1.4733  decode.loss_mask: 0.7233  decode.loss_dice: 1.2399  decode.d0.loss_cls: 3.1420  decode.d0.loss_mask: 0.7866  decode.d0.loss_dice: 1.5111  decode.d1.loss_cls: 1.5113  decode.d1.loss_mask: 0.7831  decode.d1.loss_dice: 1.3819  decode.d2.loss_cls: 1.5606  decode.d2.loss_mask: 0.7325  decode.d2.loss_dice: 1.3139  decode.d3.loss_cls: 1.4893  decode.d3.loss_mask: 0.7403  decode.d3.loss_dice: 1.3051  decode.d4.loss_cls: 1.5085  decode.d4.loss_mask: 0.7289  decode.d4.loss_dice: 1.2890  decode.d5.loss_cls: 1.5234  decode.d5.loss_mask: 0.7181  decode.d5.loss_dice: 1.2462  decode.d6.loss_cls: 1.4565  decode.d6.loss_mask: 0.7186  decode.d6.loss_dice: 1.2204  decode.d7.loss_cls: 1.4603  decode.d7.loss_mask: 0.7318  decode.d7.loss_dice: 1.2319  decode.d8.loss_cls: 1.4826  decode.d8.loss_mask: 0.7055  decode.d8.loss_dice: 1.2113
2023/05/24 03:38:15 - mmengine - INFO - Saving checkpoint at 76000 iterations
2023/05/24 03:38:42 - mmengine - INFO - Iter(train) [ 76050/160000]  lr: 5.5965e-06  eta: 10:00:56  time: 0.4189  data_time: 0.0106  memory: 4866  grad_norm: 91.6555  loss: 36.4246  decode.loss_cls: 1.1031  decode.loss_mask: 0.7296  decode.loss_dice: 1.4751  decode.d0.loss_cls: 3.2755  decode.d0.loss_mask: 0.7923  decode.d0.loss_dice: 1.6866  decode.d1.loss_cls: 1.2803  decode.d1.loss_mask: 0.7343  decode.d1.loss_dice: 1.5828  decode.d2.loss_cls: 1.2580  decode.d2.loss_mask: 0.7360  decode.d2.loss_dice: 1.5396  decode.d3.loss_cls: 1.2502  decode.d3.loss_mask: 0.7031  decode.d3.loss_dice: 1.4580  decode.d4.loss_cls: 1.1772  decode.d4.loss_mask: 0.7216  decode.d4.loss_dice: 1.4787  decode.d5.loss_cls: 1.1976  decode.d5.loss_mask: 0.7141  decode.d5.loss_dice: 1.4834  decode.d6.loss_cls: 1.1231  decode.d6.loss_mask: 0.7169  decode.d6.loss_dice: 1.4826  decode.d7.loss_cls: 1.1108  decode.d7.loss_mask: 0.7325  decode.d7.loss_dice: 1.5227  decode.d8.loss_cls: 1.0933  decode.d8.loss_mask: 0.7376  decode.d8.loss_dice: 1.5282
2023/05/24 03:39:03 - mmengine - INFO - Iter(train) [ 76100/160000]  lr: 5.5935e-06  eta: 10:00:34  time: 0.4181  data_time: 0.0105  memory: 4823  grad_norm: 105.7373  loss: 38.8767  decode.loss_cls: 1.3283  decode.loss_mask: 0.8500  decode.loss_dice: 1.4398  decode.d0.loss_cls: 3.1105  decode.d0.loss_mask: 0.8925  decode.d0.loss_dice: 1.7040  decode.d1.loss_cls: 1.4858  decode.d1.loss_mask: 0.9133  decode.d1.loss_dice: 1.5735  decode.d2.loss_cls: 1.4587  decode.d2.loss_mask: 0.8802  decode.d2.loss_dice: 1.5375  decode.d3.loss_cls: 1.4331  decode.d3.loss_mask: 0.8142  decode.d3.loss_dice: 1.4620  decode.d4.loss_cls: 1.3763  decode.d4.loss_mask: 0.8065  decode.d4.loss_dice: 1.4839  decode.d5.loss_cls: 1.3860  decode.d5.loss_mask: 0.8103  decode.d5.loss_dice: 1.4043  decode.d6.loss_cls: 1.3114  decode.d6.loss_mask: 0.8302  decode.d6.loss_dice: 1.4355  decode.d7.loss_cls: 1.3679  decode.d7.loss_mask: 0.8116  decode.d7.loss_dice: 1.4071  decode.d8.loss_cls: 1.3229  decode.d8.loss_mask: 0.8065  decode.d8.loss_dice: 1.4330
2023/05/24 03:39:25 - mmengine - INFO - Iter(train) [ 76150/160000]  lr: 5.5905e-06  eta: 10:00:14  time: 0.4601  data_time: 0.0105  memory: 4872  grad_norm: 84.7847  loss: 35.1156  decode.loss_cls: 1.1008  decode.loss_mask: 0.7247  decode.loss_dice: 1.3498  decode.d0.loss_cls: 3.0950  decode.d0.loss_mask: 0.8382  decode.d0.loss_dice: 1.6193  decode.d1.loss_cls: 1.1943  decode.d1.loss_mask: 0.8348  decode.d1.loss_dice: 1.5193  decode.d2.loss_cls: 1.1725  decode.d2.loss_mask: 0.7831  decode.d2.loss_dice: 1.4233  decode.d3.loss_cls: 1.1621  decode.d3.loss_mask: 0.7453  decode.d3.loss_dice: 1.3638  decode.d4.loss_cls: 1.1672  decode.d4.loss_mask: 0.7326  decode.d4.loss_dice: 1.3825  decode.d5.loss_cls: 1.1399  decode.d5.loss_mask: 0.7484  decode.d5.loss_dice: 1.3712  decode.d6.loss_cls: 1.1567  decode.d6.loss_mask: 0.7339  decode.d6.loss_dice: 1.3307  decode.d7.loss_cls: 1.1358  decode.d7.loss_mask: 0.7349  decode.d7.loss_dice: 1.3333  decode.d8.loss_cls: 1.1535  decode.d8.loss_mask: 0.7429  decode.d8.loss_dice: 1.3257
2023/05/24 03:39:46 - mmengine - INFO - Iter(train) [ 76200/160000]  lr: 5.5875e-06  eta: 9:59:52  time: 0.4050  data_time: 0.0103  memory: 4861  grad_norm: 96.0625  loss: 38.8022  decode.loss_cls: 1.3091  decode.loss_mask: 0.8624  decode.loss_dice: 1.3380  decode.d0.loss_cls: 3.2558  decode.d0.loss_mask: 0.9949  decode.d0.loss_dice: 1.6646  decode.d1.loss_cls: 1.4013  decode.d1.loss_mask: 1.0125  decode.d1.loss_dice: 1.5825  decode.d2.loss_cls: 1.3863  decode.d2.loss_mask: 0.9063  decode.d2.loss_dice: 1.4791  decode.d3.loss_cls: 1.4155  decode.d3.loss_mask: 0.9152  decode.d3.loss_dice: 1.3771  decode.d4.loss_cls: 1.4019  decode.d4.loss_mask: 0.8945  decode.d4.loss_dice: 1.3709  decode.d5.loss_cls: 1.3353  decode.d5.loss_mask: 0.8770  decode.d5.loss_dice: 1.3564  decode.d6.loss_cls: 1.3770  decode.d6.loss_mask: 0.8665  decode.d6.loss_dice: 1.3432  decode.d7.loss_cls: 1.3290  decode.d7.loss_mask: 0.8519  decode.d7.loss_dice: 1.3532  decode.d8.loss_cls: 1.3519  decode.d8.loss_mask: 0.8593  decode.d8.loss_dice: 1.3336
2023/05/24 03:40:07 - mmengine - INFO - Iter(train) [ 76250/160000]  lr: 5.5845e-06  eta: 9:59:30  time: 0.4252  data_time: 0.0102  memory: 4858  grad_norm: 121.5402  loss: 32.1014  decode.loss_cls: 1.1695  decode.loss_mask: 0.6330  decode.loss_dice: 1.0771  decode.d0.loss_cls: 3.2658  decode.d0.loss_mask: 0.6658  decode.d0.loss_dice: 1.3216  decode.d1.loss_cls: 1.4005  decode.d1.loss_mask: 0.6754  decode.d1.loss_dice: 1.2230  decode.d2.loss_cls: 1.3078  decode.d2.loss_mask: 0.6332  decode.d2.loss_dice: 1.1526  decode.d3.loss_cls: 1.2678  decode.d3.loss_mask: 0.5893  decode.d3.loss_dice: 1.1196  decode.d4.loss_cls: 1.2275  decode.d4.loss_mask: 0.6079  decode.d4.loss_dice: 1.0990  decode.d5.loss_cls: 1.2119  decode.d5.loss_mask: 0.6373  decode.d5.loss_dice: 1.0870  decode.d6.loss_cls: 1.1603  decode.d6.loss_mask: 0.6421  decode.d6.loss_dice: 1.0991  decode.d7.loss_cls: 1.2046  decode.d7.loss_mask: 0.6248  decode.d7.loss_dice: 1.1049  decode.d8.loss_cls: 1.1545  decode.d8.loss_mask: 0.6380  decode.d8.loss_dice: 1.1005
2023/05/24 03:40:28 - mmengine - INFO - Iter(train) [ 76300/160000]  lr: 5.5815e-06  eta: 9:59:08  time: 0.4248  data_time: 0.0104  memory: 4845  grad_norm: 210.2873  loss: 39.6951  decode.loss_cls: 1.1756  decode.loss_mask: 0.9274  decode.loss_dice: 1.5098  decode.d0.loss_cls: 3.1255  decode.d0.loss_mask: 0.9989  decode.d0.loss_dice: 1.7401  decode.d1.loss_cls: 1.4220  decode.d1.loss_mask: 1.0194  decode.d1.loss_dice: 1.6652  decode.d2.loss_cls: 1.2927  decode.d2.loss_mask: 0.9930  decode.d2.loss_dice: 1.6828  decode.d3.loss_cls: 1.2158  decode.d3.loss_mask: 1.0028  decode.d3.loss_dice: 1.6243  decode.d4.loss_cls: 1.2340  decode.d4.loss_mask: 0.9427  decode.d4.loss_dice: 1.5608  decode.d5.loss_cls: 1.1538  decode.d5.loss_mask: 0.9585  decode.d5.loss_dice: 1.5726  decode.d6.loss_cls: 1.1978  decode.d6.loss_mask: 0.9389  decode.d6.loss_dice: 1.5224  decode.d7.loss_cls: 1.1612  decode.d7.loss_mask: 0.9282  decode.d7.loss_dice: 1.5075  decode.d8.loss_cls: 1.1777  decode.d8.loss_mask: 0.9467  decode.d8.loss_dice: 1.4969
2023/05/24 03:40:50 - mmengine - INFO - Iter(train) [ 76350/160000]  lr: 5.5785e-06  eta: 9:58:46  time: 0.4210  data_time: 0.0108  memory: 4906  grad_norm: 109.2681  loss: 36.5401  decode.loss_cls: 1.2581  decode.loss_mask: 0.7704  decode.loss_dice: 1.3503  decode.d0.loss_cls: 3.0190  decode.d0.loss_mask: 0.8639  decode.d0.loss_dice: 1.5267  decode.d1.loss_cls: 1.3785  decode.d1.loss_mask: 0.8135  decode.d1.loss_dice: 1.4525  decode.d2.loss_cls: 1.3192  decode.d2.loss_mask: 0.8043  decode.d2.loss_dice: 1.4225  decode.d3.loss_cls: 1.2883  decode.d3.loss_mask: 0.8277  decode.d3.loss_dice: 1.4099  decode.d4.loss_cls: 1.3071  decode.d4.loss_mask: 0.8284  decode.d4.loss_dice: 1.3768  decode.d5.loss_cls: 1.2630  decode.d5.loss_mask: 0.7864  decode.d5.loss_dice: 1.3659  decode.d6.loss_cls: 1.3140  decode.d6.loss_mask: 0.7720  decode.d6.loss_dice: 1.3053  decode.d7.loss_cls: 1.2907  decode.d7.loss_mask: 0.7717  decode.d7.loss_dice: 1.3326  decode.d8.loss_cls: 1.2264  decode.d8.loss_mask: 0.7736  decode.d8.loss_dice: 1.3215
2023/05/24 03:41:11 - mmengine - INFO - Iter(train) [ 76400/160000]  lr: 5.5755e-06  eta: 9:58:24  time: 0.4229  data_time: 0.0105  memory: 4817  grad_norm: 121.4538  loss: 28.6883  decode.loss_cls: 1.0573  decode.loss_mask: 0.6572  decode.loss_dice: 0.9320  decode.d0.loss_cls: 2.8588  decode.d0.loss_mask: 0.6938  decode.d0.loss_dice: 1.0498  decode.d1.loss_cls: 1.0905  decode.d1.loss_mask: 0.6843  decode.d1.loss_dice: 1.0573  decode.d2.loss_cls: 1.0946  decode.d2.loss_mask: 0.6935  decode.d2.loss_dice: 0.9870  decode.d3.loss_cls: 1.0797  decode.d3.loss_mask: 0.6467  decode.d3.loss_dice: 0.9454  decode.d4.loss_cls: 1.0646  decode.d4.loss_mask: 0.6639  decode.d4.loss_dice: 0.9593  decode.d5.loss_cls: 1.0166  decode.d5.loss_mask: 0.6442  decode.d5.loss_dice: 0.9463  decode.d6.loss_cls: 1.0249  decode.d6.loss_mask: 0.6768  decode.d6.loss_dice: 0.9813  decode.d7.loss_cls: 1.0045  decode.d7.loss_mask: 0.6473  decode.d7.loss_dice: 0.9401  decode.d8.loss_cls: 1.0114  decode.d8.loss_mask: 0.6507  decode.d8.loss_dice: 0.9286
2023/05/24 03:41:31 - mmengine - INFO - Iter(train) [ 76450/160000]  lr: 5.5725e-06  eta: 9:58:02  time: 0.4142  data_time: 0.0108  memory: 4857  grad_norm: 95.8434  loss: 35.9116  decode.loss_cls: 1.0319  decode.loss_mask: 0.8056  decode.loss_dice: 1.4861  decode.d0.loss_cls: 2.8881  decode.d0.loss_mask: 0.8584  decode.d0.loss_dice: 1.6942  decode.d1.loss_cls: 1.0898  decode.d1.loss_mask: 0.8371  decode.d1.loss_dice: 1.5849  decode.d2.loss_cls: 1.1026  decode.d2.loss_mask: 0.8388  decode.d2.loss_dice: 1.5123  decode.d3.loss_cls: 1.0616  decode.d3.loss_mask: 0.8263  decode.d3.loss_dice: 1.5501  decode.d4.loss_cls: 1.0524  decode.d4.loss_mask: 0.8167  decode.d4.loss_dice: 1.5257  decode.d5.loss_cls: 1.0145  decode.d5.loss_mask: 0.8176  decode.d5.loss_dice: 1.5332  decode.d6.loss_cls: 0.9582  decode.d6.loss_mask: 0.8095  decode.d6.loss_dice: 1.5107  decode.d7.loss_cls: 0.9738  decode.d7.loss_mask: 0.8224  decode.d7.loss_dice: 1.5689  decode.d8.loss_cls: 1.0062  decode.d8.loss_mask: 0.8155  decode.d8.loss_dice: 1.5183
2023/05/24 03:41:53 - mmengine - INFO - Iter(train) [ 76500/160000]  lr: 5.5694e-06  eta: 9:57:41  time: 0.4726  data_time: 0.0104  memory: 4838  grad_norm: 90.8861  loss: 49.9256  decode.loss_cls: 1.4314  decode.loss_mask: 1.2378  decode.loss_dice: 2.0526  decode.d0.loss_cls: 3.4225  decode.d0.loss_mask: 1.2984  decode.d0.loss_dice: 2.3015  decode.d1.loss_cls: 1.4879  decode.d1.loss_mask: 1.3451  decode.d1.loss_dice: 2.1985  decode.d2.loss_cls: 1.5240  decode.d2.loss_mask: 1.2267  decode.d2.loss_dice: 2.0558  decode.d3.loss_cls: 1.4267  decode.d3.loss_mask: 1.2562  decode.d3.loss_dice: 2.0888  decode.d4.loss_cls: 1.4358  decode.d4.loss_mask: 1.2381  decode.d4.loss_dice: 2.0592  decode.d5.loss_cls: 1.4653  decode.d5.loss_mask: 1.2170  decode.d5.loss_dice: 2.0469  decode.d6.loss_cls: 1.4353  decode.d6.loss_mask: 1.2268  decode.d6.loss_dice: 2.0448  decode.d7.loss_cls: 1.3911  decode.d7.loss_mask: 1.2355  decode.d7.loss_dice: 2.0325  decode.d8.loss_cls: 1.4174  decode.d8.loss_mask: 1.2639  decode.d8.loss_dice: 2.0621
2023/05/24 03:42:16 - mmengine - INFO - Iter(train) [ 76550/160000]  lr: 5.5664e-06  eta: 9:57:20  time: 0.4131  data_time: 0.0105  memory: 4829  grad_norm: 94.8671  loss: 37.1994  decode.loss_cls: 1.5112  decode.loss_mask: 0.7385  decode.loss_dice: 1.1451  decode.d0.loss_cls: 3.3242  decode.d0.loss_mask: 0.8897  decode.d0.loss_dice: 1.4675  decode.d1.loss_cls: 1.6983  decode.d1.loss_mask: 0.8392  decode.d1.loss_dice: 1.3045  decode.d2.loss_cls: 1.5335  decode.d2.loss_mask: 0.7960  decode.d2.loss_dice: 1.2884  decode.d3.loss_cls: 1.5004  decode.d3.loss_mask: 0.7505  decode.d3.loss_dice: 1.2347  decode.d4.loss_cls: 1.5350  decode.d4.loss_mask: 0.7601  decode.d4.loss_dice: 1.2061  decode.d5.loss_cls: 1.5193  decode.d5.loss_mask: 0.7476  decode.d5.loss_dice: 1.1915  decode.d6.loss_cls: 1.5073  decode.d6.loss_mask: 0.7463  decode.d6.loss_dice: 1.1879  decode.d7.loss_cls: 1.4905  decode.d7.loss_mask: 0.7431  decode.d7.loss_dice: 1.1659  decode.d8.loss_cls: 1.5110  decode.d8.loss_mask: 0.7264  decode.d8.loss_dice: 1.1398
2023/05/24 03:42:37 - mmengine - INFO - Iter(train) [ 76600/160000]  lr: 5.5634e-06  eta: 9:56:58  time: 0.4197  data_time: 0.0102  memory: 4890  grad_norm: 95.9639  loss: 43.7209  decode.loss_cls: 1.5536  decode.loss_mask: 0.8300  decode.loss_dice: 1.6766  decode.d0.loss_cls: 4.0096  decode.d0.loss_mask: 0.8763  decode.d0.loss_dice: 1.9083  decode.d1.loss_cls: 1.5914  decode.d1.loss_mask: 0.9296  decode.d1.loss_dice: 1.8460  decode.d2.loss_cls: 1.5068  decode.d2.loss_mask: 0.8328  decode.d2.loss_dice: 1.8326  decode.d3.loss_cls: 1.4778  decode.d3.loss_mask: 0.8772  decode.d3.loss_dice: 1.7392  decode.d4.loss_cls: 1.4355  decode.d4.loss_mask: 0.8575  decode.d4.loss_dice: 1.7392  decode.d5.loss_cls: 1.4766  decode.d5.loss_mask: 0.8567  decode.d5.loss_dice: 1.7364  decode.d6.loss_cls: 1.4925  decode.d6.loss_mask: 0.8339  decode.d6.loss_dice: 1.6737  decode.d7.loss_cls: 1.5465  decode.d7.loss_mask: 0.8338  decode.d7.loss_dice: 1.6713  decode.d8.loss_cls: 1.5683  decode.d8.loss_mask: 0.8294  decode.d8.loss_dice: 1.6819
2023/05/24 03:43:00 - mmengine - INFO - Iter(train) [ 76650/160000]  lr: 5.5604e-06  eta: 9:56:39  time: 0.4709  data_time: 0.0104  memory: 4866  grad_norm: 173.2872  loss: 33.0131  decode.loss_cls: 1.1637  decode.loss_mask: 0.8206  decode.loss_dice: 1.1041  decode.d0.loss_cls: 2.9180  decode.d0.loss_mask: 0.9163  decode.d0.loss_dice: 1.3055  decode.d1.loss_cls: 1.1971  decode.d1.loss_mask: 0.8291  decode.d1.loss_dice: 1.1874  decode.d2.loss_cls: 1.1645  decode.d2.loss_mask: 0.8526  decode.d2.loss_dice: 1.1532  decode.d3.loss_cls: 1.2021  decode.d3.loss_mask: 0.8521  decode.d3.loss_dice: 1.0837  decode.d4.loss_cls: 1.1456  decode.d4.loss_mask: 0.8501  decode.d4.loss_dice: 1.0931  decode.d5.loss_cls: 1.1315  decode.d5.loss_mask: 0.8339  decode.d5.loss_dice: 1.0927  decode.d6.loss_cls: 1.1451  decode.d6.loss_mask: 0.8114  decode.d6.loss_dice: 1.0884  decode.d7.loss_cls: 1.1378  decode.d7.loss_mask: 0.8222  decode.d7.loss_dice: 1.0790  decode.d8.loss_cls: 1.1091  decode.d8.loss_mask: 0.8257  decode.d8.loss_dice: 1.0973
2023/05/24 03:43:22 - mmengine - INFO - Iter(train) [ 76700/160000]  lr: 5.5574e-06  eta: 9:56:18  time: 0.4134  data_time: 0.0107  memory: 4917  grad_norm: 84.1798  loss: 37.0553  decode.loss_cls: 1.1988  decode.loss_mask: 0.6637  decode.loss_dice: 1.6135  decode.d0.loss_cls: 3.0346  decode.d0.loss_mask: 0.7164  decode.d0.loss_dice: 1.8377  decode.d1.loss_cls: 1.2585  decode.d1.loss_mask: 0.7190  decode.d1.loss_dice: 1.7509  decode.d2.loss_cls: 1.1872  decode.d2.loss_mask: 0.6601  decode.d2.loss_dice: 1.6843  decode.d3.loss_cls: 1.1678  decode.d3.loss_mask: 0.6553  decode.d3.loss_dice: 1.6353  decode.d4.loss_cls: 1.1087  decode.d4.loss_mask: 0.6717  decode.d4.loss_dice: 1.6402  decode.d5.loss_cls: 1.1355  decode.d5.loss_mask: 0.6908  decode.d5.loss_dice: 1.6368  decode.d6.loss_cls: 1.1532  decode.d6.loss_mask: 0.6724  decode.d6.loss_dice: 1.6443  decode.d7.loss_cls: 1.1458  decode.d7.loss_mask: 0.6798  decode.d7.loss_dice: 1.6209  decode.d8.loss_cls: 1.1640  decode.d8.loss_mask: 0.6744  decode.d8.loss_dice: 1.6336
2023/05/24 03:43:43 - mmengine - INFO - Iter(train) [ 76750/160000]  lr: 5.5544e-06  eta: 9:55:55  time: 0.4137  data_time: 0.0101  memory: 4867  grad_norm: 96.6595  loss: 41.9804  decode.loss_cls: 1.2841  decode.loss_mask: 0.9477  decode.loss_dice: 1.6786  decode.d0.loss_cls: 3.2344  decode.d0.loss_mask: 1.0389  decode.d0.loss_dice: 1.9665  decode.d1.loss_cls: 1.3088  decode.d1.loss_mask: 1.0314  decode.d1.loss_dice: 1.8664  decode.d2.loss_cls: 1.3104  decode.d2.loss_mask: 0.9933  decode.d2.loss_dice: 1.7595  decode.d3.loss_cls: 1.3412  decode.d3.loss_mask: 0.9741  decode.d3.loss_dice: 1.6999  decode.d4.loss_cls: 1.2570  decode.d4.loss_mask: 0.9729  decode.d4.loss_dice: 1.6921  decode.d5.loss_cls: 1.3156  decode.d5.loss_mask: 0.9764  decode.d5.loss_dice: 1.6932  decode.d6.loss_cls: 1.2744  decode.d6.loss_mask: 0.9737  decode.d6.loss_dice: 1.6534  decode.d7.loss_cls: 1.2552  decode.d7.loss_mask: 0.9539  decode.d7.loss_dice: 1.6545  decode.d8.loss_cls: 1.2860  decode.d8.loss_mask: 0.9441  decode.d8.loss_dice: 1.6429
2023/05/24 03:44:04 - mmengine - INFO - Iter(train) [ 76800/160000]  lr: 5.5514e-06  eta: 9:55:34  time: 0.4415  data_time: 0.0107  memory: 4796  grad_norm: 101.3524  loss: 36.8540  decode.loss_cls: 1.4709  decode.loss_mask: 0.6365  decode.loss_dice: 1.2831  decode.d0.loss_cls: 3.3688  decode.d0.loss_mask: 0.6742  decode.d0.loss_dice: 1.4785  decode.d1.loss_cls: 1.6452  decode.d1.loss_mask: 0.7279  decode.d1.loss_dice: 1.4084  decode.d2.loss_cls: 1.5396  decode.d2.loss_mask: 0.6760  decode.d2.loss_dice: 1.3307  decode.d3.loss_cls: 1.4837  decode.d3.loss_mask: 0.6541  decode.d3.loss_dice: 1.2957  decode.d4.loss_cls: 1.5491  decode.d4.loss_mask: 0.6370  decode.d4.loss_dice: 1.2641  decode.d5.loss_cls: 1.5207  decode.d5.loss_mask: 0.6348  decode.d5.loss_dice: 1.2855  decode.d6.loss_cls: 1.4975  decode.d6.loss_mask: 0.6485  decode.d6.loss_dice: 1.2975  decode.d7.loss_cls: 1.5351  decode.d7.loss_mask: 0.6408  decode.d7.loss_dice: 1.2760  decode.d8.loss_cls: 1.5007  decode.d8.loss_mask: 0.6447  decode.d8.loss_dice: 1.2487
2023/05/24 03:44:26 - mmengine - INFO - Iter(train) [ 76850/160000]  lr: 5.5484e-06  eta: 9:55:13  time: 0.4109  data_time: 0.0109  memory: 4870  grad_norm: 89.5683  loss: 40.8823  decode.loss_cls: 1.2531  decode.loss_mask: 1.1003  decode.loss_dice: 1.5088  decode.d0.loss_cls: 3.1204  decode.d0.loss_mask: 1.0105  decode.d0.loss_dice: 1.7248  decode.d1.loss_cls: 1.4110  decode.d1.loss_mask: 1.0505  decode.d1.loss_dice: 1.6265  decode.d2.loss_cls: 1.3201  decode.d2.loss_mask: 1.1207  decode.d2.loss_dice: 1.5449  decode.d3.loss_cls: 1.2869  decode.d3.loss_mask: 1.0871  decode.d3.loss_dice: 1.5056  decode.d4.loss_cls: 1.2406  decode.d4.loss_mask: 1.0590  decode.d4.loss_dice: 1.5165  decode.d5.loss_cls: 1.2886  decode.d5.loss_mask: 1.0661  decode.d5.loss_dice: 1.4844  decode.d6.loss_cls: 1.2412  decode.d6.loss_mask: 1.0899  decode.d6.loss_dice: 1.4777  decode.d7.loss_cls: 1.2352  decode.d7.loss_mask: 1.0965  decode.d7.loss_dice: 1.5412  decode.d8.loss_cls: 1.2754  decode.d8.loss_mask: 1.0853  decode.d8.loss_dice: 1.5136
2023/05/24 03:44:46 - mmengine - INFO - Iter(train) [ 76900/160000]  lr: 5.5454e-06  eta: 9:54:50  time: 0.4165  data_time: 0.0102  memory: 4824  grad_norm: 84.7433  loss: 35.7787  decode.loss_cls: 1.1941  decode.loss_mask: 0.7247  decode.loss_dice: 1.3295  decode.d0.loss_cls: 3.3604  decode.d0.loss_mask: 0.7822  decode.d0.loss_dice: 1.6509  decode.d1.loss_cls: 1.2497  decode.d1.loss_mask: 0.8435  decode.d1.loss_dice: 1.5107  decode.d2.loss_cls: 1.2644  decode.d2.loss_mask: 0.7206  decode.d2.loss_dice: 1.3928  decode.d3.loss_cls: 1.1769  decode.d3.loss_mask: 0.7304  decode.d3.loss_dice: 1.3722  decode.d4.loss_cls: 1.2169  decode.d4.loss_mask: 0.7430  decode.d4.loss_dice: 1.4027  decode.d5.loss_cls: 1.1808  decode.d5.loss_mask: 0.7528  decode.d5.loss_dice: 1.3712  decode.d6.loss_cls: 1.1742  decode.d6.loss_mask: 0.7310  decode.d6.loss_dice: 1.3431  decode.d7.loss_cls: 1.2156  decode.d7.loss_mask: 0.7324  decode.d7.loss_dice: 1.3678  decode.d8.loss_cls: 1.1437  decode.d8.loss_mask: 0.7335  decode.d8.loss_dice: 1.3667
2023/05/24 03:45:08 - mmengine - INFO - Iter(train) [ 76950/160000]  lr: 5.5424e-06  eta: 9:54:29  time: 0.4788  data_time: 0.0119  memory: 4859  grad_norm: 96.3139  loss: 35.3104  decode.loss_cls: 1.0897  decode.loss_mask: 0.7586  decode.loss_dice: 1.3985  decode.d0.loss_cls: 2.8807  decode.d0.loss_mask: 0.7892  decode.d0.loss_dice: 1.5632  decode.d1.loss_cls: 1.2468  decode.d1.loss_mask: 0.8443  decode.d1.loss_dice: 1.5297  decode.d2.loss_cls: 1.2078  decode.d2.loss_mask: 0.7887  decode.d2.loss_dice: 1.4377  decode.d3.loss_cls: 1.1444  decode.d3.loss_mask: 0.7898  decode.d3.loss_dice: 1.4287  decode.d4.loss_cls: 1.1311  decode.d4.loss_mask: 0.7808  decode.d4.loss_dice: 1.4334  decode.d5.loss_cls: 1.1145  decode.d5.loss_mask: 0.7799  decode.d5.loss_dice: 1.4313  decode.d6.loss_cls: 1.0711  decode.d6.loss_mask: 0.7782  decode.d6.loss_dice: 1.3911  decode.d7.loss_cls: 1.0573  decode.d7.loss_mask: 0.7978  decode.d7.loss_dice: 1.4106  decode.d8.loss_cls: 1.1004  decode.d8.loss_mask: 0.7560  decode.d8.loss_dice: 1.3789
2023/05/24 03:45:29 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 03:45:29 - mmengine - INFO - Iter(train) [ 77000/160000]  lr: 5.5394e-06  eta: 9:54:07  time: 0.4183  data_time: 0.0102  memory: 4900  grad_norm: 137.5155  loss: 30.8652  decode.loss_cls: 1.0873  decode.loss_mask: 0.6533  decode.loss_dice: 1.1113  decode.d0.loss_cls: 3.2954  decode.d0.loss_mask: 0.6891  decode.d0.loss_dice: 1.2543  decode.d1.loss_cls: 1.0718  decode.d1.loss_mask: 0.7016  decode.d1.loss_dice: 1.2918  decode.d2.loss_cls: 1.0231  decode.d2.loss_mask: 0.6514  decode.d2.loss_dice: 1.1538  decode.d3.loss_cls: 1.0007  decode.d3.loss_mask: 0.6491  decode.d3.loss_dice: 1.1358  decode.d4.loss_cls: 1.0901  decode.d4.loss_mask: 0.6359  decode.d4.loss_dice: 1.1099  decode.d5.loss_cls: 1.0551  decode.d5.loss_mask: 0.6331  decode.d5.loss_dice: 1.1134  decode.d6.loss_cls: 1.0632  decode.d6.loss_mask: 0.6547  decode.d6.loss_dice: 1.1118  decode.d7.loss_cls: 1.0544  decode.d7.loss_mask: 0.6591  decode.d7.loss_dice: 1.1106  decode.d8.loss_cls: 1.0261  decode.d8.loss_mask: 0.6510  decode.d8.loss_dice: 1.1270
2023/05/24 03:45:29 - mmengine - INFO - Saving checkpoint at 77000 iterations
2023/05/24 03:45:57 - mmengine - INFO - Iter(train) [ 77050/160000]  lr: 5.5364e-06  eta: 9:53:52  time: 0.4293  data_time: 0.0104  memory: 4868  grad_norm: 91.0331  loss: 37.3685  decode.loss_cls: 1.3389  decode.loss_mask: 0.7542  decode.loss_dice: 1.3984  decode.d0.loss_cls: 3.0285  decode.d0.loss_mask: 0.8230  decode.d0.loss_dice: 1.6389  decode.d1.loss_cls: 1.4111  decode.d1.loss_mask: 0.7523  decode.d1.loss_dice: 1.5068  decode.d2.loss_cls: 1.3699  decode.d2.loss_mask: 0.7682  decode.d2.loss_dice: 1.4700  decode.d3.loss_cls: 1.3637  decode.d3.loss_mask: 0.7399  decode.d3.loss_dice: 1.4413  decode.d4.loss_cls: 1.3652  decode.d4.loss_mask: 0.7479  decode.d4.loss_dice: 1.4418  decode.d5.loss_cls: 1.3539  decode.d5.loss_mask: 0.7361  decode.d5.loss_dice: 1.4340  decode.d6.loss_cls: 1.3179  decode.d6.loss_mask: 0.7350  decode.d6.loss_dice: 1.4217  decode.d7.loss_cls: 1.3351  decode.d7.loss_mask: 0.7324  decode.d7.loss_dice: 1.4357  decode.d8.loss_cls: 1.3216  decode.d8.loss_mask: 0.7557  decode.d8.loss_dice: 1.4294
2023/05/24 03:46:20 - mmengine - INFO - Iter(train) [ 77100/160000]  lr: 5.5334e-06  eta: 9:53:32  time: 0.4337  data_time: 0.0104  memory: 4836  grad_norm: 90.1181  loss: 33.5884  decode.loss_cls: 1.2327  decode.loss_mask: 0.6815  decode.loss_dice: 1.1429  decode.d0.loss_cls: 3.2277  decode.d0.loss_mask: 0.7429  decode.d0.loss_dice: 1.2972  decode.d1.loss_cls: 1.4729  decode.d1.loss_mask: 0.7452  decode.d1.loss_dice: 1.2759  decode.d2.loss_cls: 1.3536  decode.d2.loss_mask: 0.7119  decode.d2.loss_dice: 1.1890  decode.d3.loss_cls: 1.3133  decode.d3.loss_mask: 0.6980  decode.d3.loss_dice: 1.1852  decode.d4.loss_cls: 1.2856  decode.d4.loss_mask: 0.7148  decode.d4.loss_dice: 1.1685  decode.d5.loss_cls: 1.2431  decode.d5.loss_mask: 0.6842  decode.d5.loss_dice: 1.1375  decode.d6.loss_cls: 1.2250  decode.d6.loss_mask: 0.6685  decode.d6.loss_dice: 1.1425  decode.d7.loss_cls: 1.2188  decode.d7.loss_mask: 0.6648  decode.d7.loss_dice: 1.1470  decode.d8.loss_cls: 1.2066  decode.d8.loss_mask: 0.6783  decode.d8.loss_dice: 1.1335
2023/05/24 03:46:41 - mmengine - INFO - Iter(train) [ 77150/160000]  lr: 5.5304e-06  eta: 9:53:11  time: 0.4259  data_time: 0.0104  memory: 4845  grad_norm: 92.6336  loss: 34.6050  decode.loss_cls: 1.1558  decode.loss_mask: 0.7461  decode.loss_dice: 1.2379  decode.d0.loss_cls: 3.1715  decode.d0.loss_mask: 0.8731  decode.d0.loss_dice: 1.5384  decode.d1.loss_cls: 1.1901  decode.d1.loss_mask: 0.8852  decode.d1.loss_dice: 1.3987  decode.d2.loss_cls: 1.1480  decode.d2.loss_mask: 0.8691  decode.d2.loss_dice: 1.3150  decode.d3.loss_cls: 1.1212  decode.d3.loss_mask: 0.8130  decode.d3.loss_dice: 1.2778  decode.d4.loss_cls: 1.0811  decode.d4.loss_mask: 0.8336  decode.d4.loss_dice: 1.2883  decode.d5.loss_cls: 1.0802  decode.d5.loss_mask: 0.8510  decode.d5.loss_dice: 1.2749  decode.d6.loss_cls: 1.1854  decode.d6.loss_mask: 0.7359  decode.d6.loss_dice: 1.2351  decode.d7.loss_cls: 1.0518  decode.d7.loss_mask: 0.8552  decode.d7.loss_dice: 1.2319  decode.d8.loss_cls: 1.0870  decode.d8.loss_mask: 0.8253  decode.d8.loss_dice: 1.2474
2023/05/24 03:47:03 - mmengine - INFO - Iter(train) [ 77200/160000]  lr: 5.5274e-06  eta: 9:52:49  time: 0.4516  data_time: 0.0103  memory: 4884  grad_norm: 112.2516  loss: 36.2782  decode.loss_cls: 1.1557  decode.loss_mask: 0.9119  decode.loss_dice: 1.2470  decode.d0.loss_cls: 3.2986  decode.d0.loss_mask: 0.9655  decode.d0.loss_dice: 1.5160  decode.d1.loss_cls: 1.3193  decode.d1.loss_mask: 0.9702  decode.d1.loss_dice: 1.3698  decode.d2.loss_cls: 1.1675  decode.d2.loss_mask: 0.9318  decode.d2.loss_dice: 1.2895  decode.d3.loss_cls: 1.2321  decode.d3.loss_mask: 0.9139  decode.d3.loss_dice: 1.2387  decode.d4.loss_cls: 1.1725  decode.d4.loss_mask: 0.9104  decode.d4.loss_dice: 1.2883  decode.d5.loss_cls: 1.1503  decode.d5.loss_mask: 0.9312  decode.d5.loss_dice: 1.2736  decode.d6.loss_cls: 1.1662  decode.d6.loss_mask: 0.9074  decode.d6.loss_dice: 1.2664  decode.d7.loss_cls: 1.1828  decode.d7.loss_mask: 0.8999  decode.d7.loss_dice: 1.2483  decode.d8.loss_cls: 1.2022  decode.d8.loss_mask: 0.8974  decode.d8.loss_dice: 1.2538
2023/05/24 03:47:24 - mmengine - INFO - Iter(train) [ 77250/160000]  lr: 5.5244e-06  eta: 9:52:27  time: 0.4184  data_time: 0.0102  memory: 4876  grad_norm: 86.6625  loss: 48.9372  decode.loss_cls: 1.6231  decode.loss_mask: 0.9384  decode.loss_dice: 1.9939  decode.d0.loss_cls: 3.7673  decode.d0.loss_mask: 1.0209  decode.d0.loss_dice: 2.3372  decode.d1.loss_cls: 1.9638  decode.d1.loss_mask: 0.9723  decode.d1.loss_dice: 2.0764  decode.d2.loss_cls: 1.8101  decode.d2.loss_mask: 0.9155  decode.d2.loss_dice: 2.0740  decode.d3.loss_cls: 1.7536  decode.d3.loss_mask: 0.9077  decode.d3.loss_dice: 1.9752  decode.d4.loss_cls: 1.7593  decode.d4.loss_mask: 0.9081  decode.d4.loss_dice: 1.9627  decode.d5.loss_cls: 1.6820  decode.d5.loss_mask: 0.9230  decode.d5.loss_dice: 1.9661  decode.d6.loss_cls: 1.6071  decode.d6.loss_mask: 0.9324  decode.d6.loss_dice: 1.9935  decode.d7.loss_cls: 1.6613  decode.d7.loss_mask: 0.9170  decode.d7.loss_dice: 1.9522  decode.d8.loss_cls: 1.6301  decode.d8.loss_mask: 0.9218  decode.d8.loss_dice: 1.9913
2023/05/24 03:47:44 - mmengine - INFO - Iter(train) [ 77300/160000]  lr: 5.5214e-06  eta: 9:52:05  time: 0.4139  data_time: 0.0106  memory: 4910  grad_norm: 94.8765  loss: 39.7491  decode.loss_cls: 1.3048  decode.loss_mask: 1.0063  decode.loss_dice: 1.3813  decode.d0.loss_cls: 2.9914  decode.d0.loss_mask: 1.0657  decode.d0.loss_dice: 1.7527  decode.d1.loss_cls: 1.3889  decode.d1.loss_mask: 1.0474  decode.d1.loss_dice: 1.5203  decode.d2.loss_cls: 1.3251  decode.d2.loss_mask: 1.0194  decode.d2.loss_dice: 1.4250  decode.d3.loss_cls: 1.2699  decode.d3.loss_mask: 1.0345  decode.d3.loss_dice: 1.4748  decode.d4.loss_cls: 1.2985  decode.d4.loss_mask: 1.0095  decode.d4.loss_dice: 1.4428  decode.d5.loss_cls: 1.3241  decode.d5.loss_mask: 0.9871  decode.d5.loss_dice: 1.4425  decode.d6.loss_cls: 1.3030  decode.d6.loss_mask: 1.0009  decode.d6.loss_dice: 1.4398  decode.d7.loss_cls: 1.3194  decode.d7.loss_mask: 1.0322  decode.d7.loss_dice: 1.4243  decode.d8.loss_cls: 1.3269  decode.d8.loss_mask: 0.9846  decode.d8.loss_dice: 1.4059
2023/05/24 03:48:06 - mmengine - INFO - Iter(train) [ 77350/160000]  lr: 5.5184e-06  eta: 9:51:44  time: 0.4166  data_time: 0.0103  memory: 4845  grad_norm: 89.6060  loss: 32.5190  decode.loss_cls: 1.0869  decode.loss_mask: 0.6853  decode.loss_dice: 1.1813  decode.d0.loss_cls: 3.1146  decode.d0.loss_mask: 0.8366  decode.d0.loss_dice: 1.3848  decode.d1.loss_cls: 1.1616  decode.d1.loss_mask: 0.7750  decode.d1.loss_dice: 1.2859  decode.d2.loss_cls: 1.1008  decode.d2.loss_mask: 0.7068  decode.d2.loss_dice: 1.2443  decode.d3.loss_cls: 1.1005  decode.d3.loss_mask: 0.7135  decode.d3.loss_dice: 1.2194  decode.d4.loss_cls: 1.1002  decode.d4.loss_mask: 0.6985  decode.d4.loss_dice: 1.1954  decode.d5.loss_cls: 1.0922  decode.d5.loss_mask: 0.6898  decode.d5.loss_dice: 1.2258  decode.d6.loss_cls: 1.1199  decode.d6.loss_mask: 0.6887  decode.d6.loss_dice: 1.1912  decode.d7.loss_cls: 1.1032  decode.d7.loss_mask: 0.6901  decode.d7.loss_dice: 1.1902  decode.d8.loss_cls: 1.0721  decode.d8.loss_mask: 0.6912  decode.d8.loss_dice: 1.1730
2023/05/24 03:48:30 - mmengine - INFO - Iter(train) [ 77400/160000]  lr: 5.5154e-06  eta: 9:51:24  time: 0.4741  data_time: 0.0103  memory: 4821  grad_norm: 108.8678  loss: 31.0405  decode.loss_cls: 1.2490  decode.loss_mask: 0.6757  decode.loss_dice: 0.9049  decode.d0.loss_cls: 2.9381  decode.d0.loss_mask: 0.7446  decode.d0.loss_dice: 1.1018  decode.d1.loss_cls: 1.2948  decode.d1.loss_mask: 0.8349  decode.d1.loss_dice: 1.0505  decode.d2.loss_cls: 1.3187  decode.d2.loss_mask: 0.7266  decode.d2.loss_dice: 0.9707  decode.d3.loss_cls: 1.3155  decode.d3.loss_mask: 0.7030  decode.d3.loss_dice: 0.8913  decode.d4.loss_cls: 1.2416  decode.d4.loss_mask: 0.7152  decode.d4.loss_dice: 0.9334  decode.d5.loss_cls: 1.2672  decode.d5.loss_mask: 0.7200  decode.d5.loss_dice: 0.9215  decode.d6.loss_cls: 1.2601  decode.d6.loss_mask: 0.6935  decode.d6.loss_dice: 0.8978  decode.d7.loss_cls: 1.1819  decode.d7.loss_mask: 0.7114  decode.d7.loss_dice: 0.9330  decode.d8.loss_cls: 1.2544  decode.d8.loss_mask: 0.6728  decode.d8.loss_dice: 0.9165
2023/05/24 03:48:51 - mmengine - INFO - Iter(train) [ 77450/160000]  lr: 5.5124e-06  eta: 9:51:03  time: 0.4156  data_time: 0.0107  memory: 4926  grad_norm: 91.8667  loss: 31.4979  decode.loss_cls: 1.1470  decode.loss_mask: 0.6280  decode.loss_dice: 1.1238  decode.d0.loss_cls: 2.8505  decode.d0.loss_mask: 0.7911  decode.d0.loss_dice: 1.3770  decode.d1.loss_cls: 1.2036  decode.d1.loss_mask: 0.6532  decode.d1.loss_dice: 1.2215  decode.d2.loss_cls: 1.2272  decode.d2.loss_mask: 0.6724  decode.d2.loss_dice: 1.2035  decode.d3.loss_cls: 1.1645  decode.d3.loss_mask: 0.6185  decode.d3.loss_dice: 1.1294  decode.d4.loss_cls: 1.1347  decode.d4.loss_mask: 0.6456  decode.d4.loss_dice: 1.1257  decode.d5.loss_cls: 1.1484  decode.d5.loss_mask: 0.6297  decode.d5.loss_dice: 1.1671  decode.d6.loss_cls: 1.1207  decode.d6.loss_mask: 0.6013  decode.d6.loss_dice: 1.1185  decode.d7.loss_cls: 1.1565  decode.d7.loss_mask: 0.5977  decode.d7.loss_dice: 1.1165  decode.d8.loss_cls: 1.1826  decode.d8.loss_mask: 0.6088  decode.d8.loss_dice: 1.1331
2023/05/24 03:49:13 - mmengine - INFO - Iter(train) [ 77500/160000]  lr: 5.5094e-06  eta: 9:50:42  time: 0.4732  data_time: 0.0101  memory: 4847  grad_norm: 233.9186  loss: 43.7172  decode.loss_cls: 1.5554  decode.loss_mask: 0.9339  decode.loss_dice: 1.6536  decode.d0.loss_cls: 3.5217  decode.d0.loss_mask: 1.0233  decode.d0.loss_dice: 1.9006  decode.d1.loss_cls: 1.5870  decode.d1.loss_mask: 0.9599  decode.d1.loss_dice: 1.7506  decode.d2.loss_cls: 1.5662  decode.d2.loss_mask: 0.9266  decode.d2.loss_dice: 1.7023  decode.d3.loss_cls: 1.5415  decode.d3.loss_mask: 0.9057  decode.d3.loss_dice: 1.6460  decode.d4.loss_cls: 1.5197  decode.d4.loss_mask: 0.9430  decode.d4.loss_dice: 1.6715  decode.d5.loss_cls: 1.5278  decode.d5.loss_mask: 0.9335  decode.d5.loss_dice: 1.6631  decode.d6.loss_cls: 1.5603  decode.d6.loss_mask: 0.9425  decode.d6.loss_dice: 1.6462  decode.d7.loss_cls: 1.5252  decode.d7.loss_mask: 0.9262  decode.d7.loss_dice: 1.6187  decode.d8.loss_cls: 1.4807  decode.d8.loss_mask: 0.9540  decode.d8.loss_dice: 1.6305
2023/05/24 03:49:37 - mmengine - INFO - Iter(train) [ 77550/160000]  lr: 5.5064e-06  eta: 9:50:23  time: 0.4737  data_time: 0.0104  memory: 4945  grad_norm: 82.0158  loss: 35.1518  decode.loss_cls: 1.1665  decode.loss_mask: 0.8163  decode.loss_dice: 1.2317  decode.d0.loss_cls: 3.2611  decode.d0.loss_mask: 0.8619  decode.d0.loss_dice: 1.4280  decode.d1.loss_cls: 1.2748  decode.d1.loss_mask: 0.8575  decode.d1.loss_dice: 1.3919  decode.d2.loss_cls: 1.3313  decode.d2.loss_mask: 0.8213  decode.d2.loss_dice: 1.2954  decode.d3.loss_cls: 1.2463  decode.d3.loss_mask: 0.7886  decode.d3.loss_dice: 1.2547  decode.d4.loss_cls: 1.2162  decode.d4.loss_mask: 0.7892  decode.d4.loss_dice: 1.2467  decode.d5.loss_cls: 1.1546  decode.d5.loss_mask: 0.7891  decode.d5.loss_dice: 1.2590  decode.d6.loss_cls: 1.1571  decode.d6.loss_mask: 0.8169  decode.d6.loss_dice: 1.2329  decode.d7.loss_cls: 1.1548  decode.d7.loss_mask: 0.8137  decode.d7.loss_dice: 1.2559  decode.d8.loss_cls: 1.1550  decode.d8.loss_mask: 0.8180  decode.d8.loss_dice: 1.2652
2023/05/24 03:49:59 - mmengine - INFO - Iter(train) [ 77600/160000]  lr: 5.5034e-06  eta: 9:50:02  time: 0.4753  data_time: 0.0105  memory: 4845  grad_norm: 81.1939  loss: 41.4162  decode.loss_cls: 1.3884  decode.loss_mask: 0.9255  decode.loss_dice: 1.5049  decode.d0.loss_cls: 3.4329  decode.d0.loss_mask: 0.9430  decode.d0.loss_dice: 1.6187  decode.d1.loss_cls: 1.5449  decode.d1.loss_mask: 0.9976  decode.d1.loss_dice: 1.5707  decode.d2.loss_cls: 1.5137  decode.d2.loss_mask: 0.9815  decode.d2.loss_dice: 1.4980  decode.d3.loss_cls: 1.5925  decode.d3.loss_mask: 0.9053  decode.d3.loss_dice: 1.4908  decode.d4.loss_cls: 1.5068  decode.d4.loss_mask: 0.9247  decode.d4.loss_dice: 1.4979  decode.d5.loss_cls: 1.5386  decode.d5.loss_mask: 0.8942  decode.d5.loss_dice: 1.4641  decode.d6.loss_cls: 1.5201  decode.d6.loss_mask: 0.9287  decode.d6.loss_dice: 1.4796  decode.d7.loss_cls: 1.5168  decode.d7.loss_mask: 0.9065  decode.d7.loss_dice: 1.4729  decode.d8.loss_cls: 1.4761  decode.d8.loss_mask: 0.9041  decode.d8.loss_dice: 1.4769
2023/05/24 03:50:21 - mmengine - INFO - Iter(train) [ 77650/160000]  lr: 5.5004e-06  eta: 9:49:41  time: 0.4236  data_time: 0.0107  memory: 4824  grad_norm: 109.2131  loss: 45.2233  decode.loss_cls: 1.5899  decode.loss_mask: 1.0815  decode.loss_dice: 1.5757  decode.d0.loss_cls: 3.4494  decode.d0.loss_mask: 1.1734  decode.d0.loss_dice: 1.8034  decode.d1.loss_cls: 1.6178  decode.d1.loss_mask: 1.1877  decode.d1.loss_dice: 1.7067  decode.d2.loss_cls: 1.6253  decode.d2.loss_mask: 1.1389  decode.d2.loss_dice: 1.6448  decode.d3.loss_cls: 1.6003  decode.d3.loss_mask: 1.1044  decode.d3.loss_dice: 1.5989  decode.d4.loss_cls: 1.5175  decode.d4.loss_mask: 1.1454  decode.d4.loss_dice: 1.6030  decode.d5.loss_cls: 1.5890  decode.d5.loss_mask: 1.0955  decode.d5.loss_dice: 1.5936  decode.d6.loss_cls: 1.5934  decode.d6.loss_mask: 1.1001  decode.d6.loss_dice: 1.5740  decode.d7.loss_cls: 1.5602  decode.d7.loss_mask: 1.1143  decode.d7.loss_dice: 1.6051  decode.d8.loss_cls: 1.5489  decode.d8.loss_mask: 1.1128  decode.d8.loss_dice: 1.5726
2023/05/24 03:50:45 - mmengine - INFO - Iter(train) [ 77700/160000]  lr: 5.4974e-06  eta: 9:49:22  time: 0.4792  data_time: 0.0101  memory: 4944  grad_norm: 98.0786  loss: 36.2112  decode.loss_cls: 1.3153  decode.loss_mask: 0.7436  decode.loss_dice: 1.2534  decode.d0.loss_cls: 3.1404  decode.d0.loss_mask: 0.7571  decode.d0.loss_dice: 1.4075  decode.d1.loss_cls: 1.5882  decode.d1.loss_mask: 0.7151  decode.d1.loss_dice: 1.3304  decode.d2.loss_cls: 1.5614  decode.d2.loss_mask: 0.6858  decode.d2.loss_dice: 1.2906  decode.d3.loss_cls: 1.4460  decode.d3.loss_mask: 0.7259  decode.d3.loss_dice: 1.2821  decode.d4.loss_cls: 1.5580  decode.d4.loss_mask: 0.6845  decode.d4.loss_dice: 1.2640  decode.d5.loss_cls: 1.5076  decode.d5.loss_mask: 0.6824  decode.d5.loss_dice: 1.2577  decode.d6.loss_cls: 1.3546  decode.d6.loss_mask: 0.7502  decode.d6.loss_dice: 1.2589  decode.d7.loss_cls: 1.3298  decode.d7.loss_mask: 0.7322  decode.d7.loss_dice: 1.2634  decode.d8.loss_cls: 1.3572  decode.d8.loss_mask: 0.7471  decode.d8.loss_dice: 1.2209
2023/05/24 03:51:07 - mmengine - INFO - Iter(train) [ 77750/160000]  lr: 5.4944e-06  eta: 9:49:01  time: 0.4167  data_time: 0.0105  memory: 4830  grad_norm: 95.2928  loss: 40.4256  decode.loss_cls: 1.4939  decode.loss_mask: 0.8455  decode.loss_dice: 1.4020  decode.d0.loss_cls: 3.3706  decode.d0.loss_mask: 0.9775  decode.d0.loss_dice: 1.7380  decode.d1.loss_cls: 1.6096  decode.d1.loss_mask: 0.8864  decode.d1.loss_dice: 1.5987  decode.d2.loss_cls: 1.4895  decode.d2.loss_mask: 0.8790  decode.d2.loss_dice: 1.5354  decode.d3.loss_cls: 1.4566  decode.d3.loss_mask: 0.8937  decode.d3.loss_dice: 1.4735  decode.d4.loss_cls: 1.4351  decode.d4.loss_mask: 0.8635  decode.d4.loss_dice: 1.4516  decode.d5.loss_cls: 1.4684  decode.d5.loss_mask: 0.8751  decode.d5.loss_dice: 1.4007  decode.d6.loss_cls: 1.4273  decode.d6.loss_mask: 0.8735  decode.d6.loss_dice: 1.4432  decode.d7.loss_cls: 1.4503  decode.d7.loss_mask: 0.8649  decode.d7.loss_dice: 1.4648  decode.d8.loss_cls: 1.4911  decode.d8.loss_mask: 0.8360  decode.d8.loss_dice: 1.4302
2023/05/24 03:51:28 - mmengine - INFO - Iter(train) [ 77800/160000]  lr: 5.4913e-06  eta: 9:48:40  time: 0.4192  data_time: 0.0107  memory: 4845  grad_norm: 100.9432  loss: 33.8026  decode.loss_cls: 1.1114  decode.loss_mask: 0.7642  decode.loss_dice: 1.2072  decode.d0.loss_cls: 3.1886  decode.d0.loss_mask: 0.7645  decode.d0.loss_dice: 1.3743  decode.d1.loss_cls: 1.2597  decode.d1.loss_mask: 0.7794  decode.d1.loss_dice: 1.3187  decode.d2.loss_cls: 1.1919  decode.d2.loss_mask: 0.7451  decode.d2.loss_dice: 1.2524  decode.d3.loss_cls: 1.1689  decode.d3.loss_mask: 0.7521  decode.d3.loss_dice: 1.2377  decode.d4.loss_cls: 1.1427  decode.d4.loss_mask: 0.7644  decode.d4.loss_dice: 1.2453  decode.d5.loss_cls: 1.1566  decode.d5.loss_mask: 0.7785  decode.d5.loss_dice: 1.2294  decode.d6.loss_cls: 1.1729  decode.d6.loss_mask: 0.7513  decode.d6.loss_dice: 1.2162  decode.d7.loss_cls: 1.1409  decode.d7.loss_mask: 0.7574  decode.d7.loss_dice: 1.2093  decode.d8.loss_cls: 1.1425  decode.d8.loss_mask: 0.7724  decode.d8.loss_dice: 1.2066
2023/05/24 03:51:49 - mmengine - INFO - Iter(train) [ 77850/160000]  lr: 5.4883e-06  eta: 9:48:18  time: 0.4244  data_time: 0.0103  memory: 4845  grad_norm: 104.2536  loss: 36.2624  decode.loss_cls: 1.2074  decode.loss_mask: 0.7888  decode.loss_dice: 1.3609  decode.d0.loss_cls: 3.0084  decode.d0.loss_mask: 0.8113  decode.d0.loss_dice: 1.5756  decode.d1.loss_cls: 1.3515  decode.d1.loss_mask: 0.8381  decode.d1.loss_dice: 1.4642  decode.d2.loss_cls: 1.2449  decode.d2.loss_mask: 0.8094  decode.d2.loss_dice: 1.4283  decode.d3.loss_cls: 1.2306  decode.d3.loss_mask: 0.7759  decode.d3.loss_dice: 1.3533  decode.d4.loss_cls: 1.2768  decode.d4.loss_mask: 0.7703  decode.d4.loss_dice: 1.3637  decode.d5.loss_cls: 1.3093  decode.d5.loss_mask: 0.7839  decode.d5.loss_dice: 1.3575  decode.d6.loss_cls: 1.2529  decode.d6.loss_mask: 0.7958  decode.d6.loss_dice: 1.3785  decode.d7.loss_cls: 1.1654  decode.d7.loss_mask: 0.8024  decode.d7.loss_dice: 1.3799  decode.d8.loss_cls: 1.2273  decode.d8.loss_mask: 0.7913  decode.d8.loss_dice: 1.3589
2023/05/24 03:52:10 - mmengine - INFO - Iter(train) [ 77900/160000]  lr: 5.4853e-06  eta: 9:47:56  time: 0.4113  data_time: 0.0103  memory: 4795  grad_norm: 94.6772  loss: 33.7872  decode.loss_cls: 1.1617  decode.loss_mask: 0.8194  decode.loss_dice: 1.1224  decode.d0.loss_cls: 2.9689  decode.d0.loss_mask: 0.8688  decode.d0.loss_dice: 1.3132  decode.d1.loss_cls: 1.2946  decode.d1.loss_mask: 0.8566  decode.d1.loss_dice: 1.2420  decode.d2.loss_cls: 1.1965  decode.d2.loss_mask: 0.8782  decode.d2.loss_dice: 1.1769  decode.d3.loss_cls: 1.1635  decode.d3.loss_mask: 0.8561  decode.d3.loss_dice: 1.1631  decode.d4.loss_cls: 1.1605  decode.d4.loss_mask: 0.8388  decode.d4.loss_dice: 1.1541  decode.d5.loss_cls: 1.1444  decode.d5.loss_mask: 0.8253  decode.d5.loss_dice: 1.1649  decode.d6.loss_cls: 1.1657  decode.d6.loss_mask: 0.8290  decode.d6.loss_dice: 1.1552  decode.d7.loss_cls: 1.1476  decode.d7.loss_mask: 0.8251  decode.d7.loss_dice: 1.1491  decode.d8.loss_cls: 1.2033  decode.d8.loss_mask: 0.8206  decode.d8.loss_dice: 1.1215
2023/05/24 03:52:31 - mmengine - INFO - Iter(train) [ 77950/160000]  lr: 5.4823e-06  eta: 9:47:34  time: 0.4174  data_time: 0.0107  memory: 4928  grad_norm: 105.8866  loss: 30.3147  decode.loss_cls: 0.9878  decode.loss_mask: 0.7215  decode.loss_dice: 1.0083  decode.d0.loss_cls: 3.0459  decode.d0.loss_mask: 0.8131  decode.d0.loss_dice: 1.2303  decode.d1.loss_cls: 1.1477  decode.d1.loss_mask: 0.7457  decode.d1.loss_dice: 1.1161  decode.d2.loss_cls: 1.1114  decode.d2.loss_mask: 0.7001  decode.d2.loss_dice: 1.0340  decode.d3.loss_cls: 1.0067  decode.d3.loss_mask: 0.7439  decode.d3.loss_dice: 1.0840  decode.d4.loss_cls: 1.0141  decode.d4.loss_mask: 0.7236  decode.d4.loss_dice: 1.0502  decode.d5.loss_cls: 0.9979  decode.d5.loss_mask: 0.7161  decode.d5.loss_dice: 1.0477  decode.d6.loss_cls: 0.9983  decode.d6.loss_mask: 0.7235  decode.d6.loss_dice: 1.0146  decode.d7.loss_cls: 1.0039  decode.d7.loss_mask: 0.7363  decode.d7.loss_dice: 1.0217  decode.d8.loss_cls: 0.9979  decode.d8.loss_mask: 0.7399  decode.d8.loss_dice: 1.0323
2023/05/24 03:52:52 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 03:52:52 - mmengine - INFO - Iter(train) [ 78000/160000]  lr: 5.4793e-06  eta: 9:47:11  time: 0.4133  data_time: 0.0103  memory: 4930  grad_norm: 95.8504  loss: 31.4408  decode.loss_cls: 1.0624  decode.loss_mask: 0.7793  decode.loss_dice: 1.0346  decode.d0.loss_cls: 2.7168  decode.d0.loss_mask: 0.8594  decode.d0.loss_dice: 1.2160  decode.d1.loss_cls: 1.1059  decode.d1.loss_mask: 0.8627  decode.d1.loss_dice: 1.1912  decode.d2.loss_cls: 1.1119  decode.d2.loss_mask: 0.8174  decode.d2.loss_dice: 1.1342  decode.d3.loss_cls: 1.1060  decode.d3.loss_mask: 0.8066  decode.d3.loss_dice: 1.1038  decode.d4.loss_cls: 1.0415  decode.d4.loss_mask: 0.8254  decode.d4.loss_dice: 1.0887  decode.d5.loss_cls: 1.0897  decode.d5.loss_mask: 0.7854  decode.d5.loss_dice: 1.0710  decode.d6.loss_cls: 1.0753  decode.d6.loss_mask: 0.7805  decode.d6.loss_dice: 1.0666  decode.d7.loss_cls: 1.0152  decode.d7.loss_mask: 0.7835  decode.d7.loss_dice: 1.0291  decode.d8.loss_cls: 1.0787  decode.d8.loss_mask: 0.7549  decode.d8.loss_dice: 1.0471
2023/05/24 03:52:52 - mmengine - INFO - Saving checkpoint at 78000 iterations
2023/05/24 03:53:19 - mmengine - INFO - Iter(train) [ 78050/160000]  lr: 5.4763e-06  eta: 9:46:55  time: 0.4179  data_time: 0.0103  memory: 4891  grad_norm: 98.8139  loss: 40.6575  decode.loss_cls: 1.6893  decode.loss_mask: 0.8907  decode.loss_dice: 1.2736  decode.d0.loss_cls: 3.5885  decode.d0.loss_mask: 1.0079  decode.d0.loss_dice: 1.4506  decode.d1.loss_cls: 1.6959  decode.d1.loss_mask: 0.9675  decode.d1.loss_dice: 1.4705  decode.d2.loss_cls: 1.6258  decode.d2.loss_mask: 0.9473  decode.d2.loss_dice: 1.3481  decode.d3.loss_cls: 1.6085  decode.d3.loss_mask: 0.9095  decode.d3.loss_dice: 1.3062  decode.d4.loss_cls: 1.6034  decode.d4.loss_mask: 0.9060  decode.d4.loss_dice: 1.3255  decode.d5.loss_cls: 1.5376  decode.d5.loss_mask: 0.9135  decode.d5.loss_dice: 1.2882  decode.d6.loss_cls: 1.5588  decode.d6.loss_mask: 0.9056  decode.d6.loss_dice: 1.2859  decode.d7.loss_cls: 1.5482  decode.d7.loss_mask: 0.9031  decode.d7.loss_dice: 1.3155  decode.d8.loss_cls: 1.6238  decode.d8.loss_mask: 0.8905  decode.d8.loss_dice: 1.2720
2023/05/24 03:53:40 - mmengine - INFO - Iter(train) [ 78100/160000]  lr: 5.4733e-06  eta: 9:46:34  time: 0.4118  data_time: 0.0102  memory: 4782  grad_norm: 94.3849  loss: 26.8826  decode.loss_cls: 0.8698  decode.loss_mask: 0.5783  decode.loss_dice: 1.0097  decode.d0.loss_cls: 2.9079  decode.d0.loss_mask: 0.5570  decode.d0.loss_dice: 1.1568  decode.d1.loss_cls: 1.0390  decode.d1.loss_mask: 0.5770  decode.d1.loss_dice: 1.1312  decode.d2.loss_cls: 0.9449  decode.d2.loss_mask: 0.5287  decode.d2.loss_dice: 1.0388  decode.d3.loss_cls: 0.9762  decode.d3.loss_mask: 0.5145  decode.d3.loss_dice: 0.9878  decode.d4.loss_cls: 0.8954  decode.d4.loss_mask: 0.5093  decode.d4.loss_dice: 0.9909  decode.d5.loss_cls: 0.9194  decode.d5.loss_mask: 0.5349  decode.d5.loss_dice: 0.9735  decode.d6.loss_cls: 0.8766  decode.d6.loss_mask: 0.5402  decode.d6.loss_dice: 1.0119  decode.d7.loss_cls: 0.8817  decode.d7.loss_mask: 0.5384  decode.d7.loss_dice: 0.9794  decode.d8.loss_cls: 0.9158  decode.d8.loss_mask: 0.5399  decode.d8.loss_dice: 0.9579
2023/05/24 03:54:01 - mmengine - INFO - Iter(train) [ 78150/160000]  lr: 5.4703e-06  eta: 9:46:12  time: 0.4205  data_time: 0.0108  memory: 4850  grad_norm: 106.3883  loss: 35.0567  decode.loss_cls: 1.2401  decode.loss_mask: 0.7477  decode.loss_dice: 1.2914  decode.d0.loss_cls: 3.1066  decode.d0.loss_mask: 0.8036  decode.d0.loss_dice: 1.4560  decode.d1.loss_cls: 1.2636  decode.d1.loss_mask: 0.7733  decode.d1.loss_dice: 1.4038  decode.d2.loss_cls: 1.2645  decode.d2.loss_mask: 0.7696  decode.d2.loss_dice: 1.3186  decode.d3.loss_cls: 1.2711  decode.d3.loss_mask: 0.7308  decode.d3.loss_dice: 1.2972  decode.d4.loss_cls: 1.2761  decode.d4.loss_mask: 0.7365  decode.d4.loss_dice: 1.2902  decode.d5.loss_cls: 1.2773  decode.d5.loss_mask: 0.7315  decode.d5.loss_dice: 1.2614  decode.d6.loss_cls: 1.2656  decode.d6.loss_mask: 0.7031  decode.d6.loss_dice: 1.2513  decode.d7.loss_cls: 1.2419  decode.d7.loss_mask: 0.7424  decode.d7.loss_dice: 1.2651  decode.d8.loss_cls: 1.2992  decode.d8.loss_mask: 0.7097  decode.d8.loss_dice: 1.2677
2023/05/24 03:54:22 - mmengine - INFO - Iter(train) [ 78200/160000]  lr: 5.4673e-06  eta: 9:45:49  time: 0.4192  data_time: 0.0102  memory: 4857  grad_norm: 106.9256  loss: 33.4424  decode.loss_cls: 1.1776  decode.loss_mask: 0.7299  decode.loss_dice: 1.1299  decode.d0.loss_cls: 2.9844  decode.d0.loss_mask: 0.8207  decode.d0.loss_dice: 1.3174  decode.d1.loss_cls: 1.2746  decode.d1.loss_mask: 0.8074  decode.d1.loss_dice: 1.3232  decode.d2.loss_cls: 1.2029  decode.d2.loss_mask: 0.7748  decode.d2.loss_dice: 1.2730  decode.d3.loss_cls: 1.1894  decode.d3.loss_mask: 0.7576  decode.d3.loss_dice: 1.2215  decode.d4.loss_cls: 1.1975  decode.d4.loss_mask: 0.7384  decode.d4.loss_dice: 1.1730  decode.d5.loss_cls: 1.2076  decode.d5.loss_mask: 0.7157  decode.d5.loss_dice: 1.1846  decode.d6.loss_cls: 1.2043  decode.d6.loss_mask: 0.7405  decode.d6.loss_dice: 1.1934  decode.d7.loss_cls: 1.1460  decode.d7.loss_mask: 0.7411  decode.d7.loss_dice: 1.1554  decode.d8.loss_cls: 1.1539  decode.d8.loss_mask: 0.7364  decode.d8.loss_dice: 1.1703
2023/05/24 03:54:43 - mmengine - INFO - Iter(train) [ 78250/160000]  lr: 5.4643e-06  eta: 9:45:27  time: 0.4207  data_time: 0.0103  memory: 4821  grad_norm: 137.1626  loss: 41.2862  decode.loss_cls: 1.4687  decode.loss_mask: 0.8200  decode.loss_dice: 1.4388  decode.d0.loss_cls: 3.7269  decode.d0.loss_mask: 0.9771  decode.d0.loss_dice: 1.8109  decode.d1.loss_cls: 1.6667  decode.d1.loss_mask: 0.9201  decode.d1.loss_dice: 1.6080  decode.d2.loss_cls: 1.5888  decode.d2.loss_mask: 0.9384  decode.d2.loss_dice: 1.5066  decode.d3.loss_cls: 1.5662  decode.d3.loss_mask: 0.8591  decode.d3.loss_dice: 1.4454  decode.d4.loss_cls: 1.5016  decode.d4.loss_mask: 0.8644  decode.d4.loss_dice: 1.4456  decode.d5.loss_cls: 1.4948  decode.d5.loss_mask: 0.8616  decode.d5.loss_dice: 1.4456  decode.d6.loss_cls: 1.5161  decode.d6.loss_mask: 0.8234  decode.d6.loss_dice: 1.4313  decode.d7.loss_cls: 1.5076  decode.d7.loss_mask: 0.8434  decode.d7.loss_dice: 1.4374  decode.d8.loss_cls: 1.4881  decode.d8.loss_mask: 0.8544  decode.d8.loss_dice: 1.4291
2023/05/24 03:55:03 - mmengine - INFO - Iter(train) [ 78300/160000]  lr: 5.4613e-06  eta: 9:45:05  time: 0.4127  data_time: 0.0103  memory: 4827  grad_norm: 95.4912  loss: 30.7175  decode.loss_cls: 1.0917  decode.loss_mask: 0.8147  decode.loss_dice: 0.8832  decode.d0.loss_cls: 3.1091  decode.d0.loss_mask: 0.7619  decode.d0.loss_dice: 0.9943  decode.d1.loss_cls: 1.3035  decode.d1.loss_mask: 0.8308  decode.d1.loss_dice: 0.9449  decode.d2.loss_cls: 1.1669  decode.d2.loss_mask: 0.8308  decode.d2.loss_dice: 0.9330  decode.d3.loss_cls: 1.1725  decode.d3.loss_mask: 0.7787  decode.d3.loss_dice: 0.8924  decode.d4.loss_cls: 1.1672  decode.d4.loss_mask: 0.8028  decode.d4.loss_dice: 0.9160  decode.d5.loss_cls: 1.2024  decode.d5.loss_mask: 0.8202  decode.d5.loss_dice: 0.9163  decode.d6.loss_cls: 1.1096  decode.d6.loss_mask: 0.8224  decode.d6.loss_dice: 0.9095  decode.d7.loss_cls: 1.0869  decode.d7.loss_mask: 0.8088  decode.d7.loss_dice: 0.8936  decode.d8.loss_cls: 1.0614  decode.d8.loss_mask: 0.7996  decode.d8.loss_dice: 0.8922
2023/05/24 03:55:25 - mmengine - INFO - Iter(train) [ 78350/160000]  lr: 5.4583e-06  eta: 9:44:43  time: 0.4186  data_time: 0.0105  memory: 4918  grad_norm: 139.1088  loss: 44.4064  decode.loss_cls: 1.6398  decode.loss_mask: 0.9406  decode.loss_dice: 1.5520  decode.d0.loss_cls: 3.3693  decode.d0.loss_mask: 1.0857  decode.d0.loss_dice: 1.8630  decode.d1.loss_cls: 1.7451  decode.d1.loss_mask: 1.0276  decode.d1.loss_dice: 1.7494  decode.d2.loss_cls: 1.6800  decode.d2.loss_mask: 0.9379  decode.d2.loss_dice: 1.6793  decode.d3.loss_cls: 1.6202  decode.d3.loss_mask: 0.9710  decode.d3.loss_dice: 1.5972  decode.d4.loss_cls: 1.6222  decode.d4.loss_mask: 0.9663  decode.d4.loss_dice: 1.6316  decode.d5.loss_cls: 1.6687  decode.d5.loss_mask: 0.9613  decode.d5.loss_dice: 1.5560  decode.d6.loss_cls: 1.6406  decode.d6.loss_mask: 0.9746  decode.d6.loss_dice: 1.5889  decode.d7.loss_cls: 1.6569  decode.d7.loss_mask: 0.9516  decode.d7.loss_dice: 1.5915  decode.d8.loss_cls: 1.6495  decode.d8.loss_mask: 0.9341  decode.d8.loss_dice: 1.5546
2023/05/24 03:55:46 - mmengine - INFO - Iter(train) [ 78400/160000]  lr: 5.4553e-06  eta: 9:44:22  time: 0.4522  data_time: 0.0104  memory: 4844  grad_norm: 115.0362  loss: 38.4208  decode.loss_cls: 1.3092  decode.loss_mask: 0.7653  decode.loss_dice: 1.4202  decode.d0.loss_cls: 3.4033  decode.d0.loss_mask: 0.8525  decode.d0.loss_dice: 1.6802  decode.d1.loss_cls: 1.5786  decode.d1.loss_mask: 0.8381  decode.d1.loss_dice: 1.5325  decode.d2.loss_cls: 1.4595  decode.d2.loss_mask: 0.8182  decode.d2.loss_dice: 1.4681  decode.d3.loss_cls: 1.3959  decode.d3.loss_mask: 0.7714  decode.d3.loss_dice: 1.4205  decode.d4.loss_cls: 1.3264  decode.d4.loss_mask: 0.7790  decode.d4.loss_dice: 1.4452  decode.d5.loss_cls: 1.3856  decode.d5.loss_mask: 0.7640  decode.d5.loss_dice: 1.4045  decode.d6.loss_cls: 1.3638  decode.d6.loss_mask: 0.7691  decode.d6.loss_dice: 1.4197  decode.d7.loss_cls: 1.3418  decode.d7.loss_mask: 0.7787  decode.d7.loss_dice: 1.4038  decode.d8.loss_cls: 1.3134  decode.d8.loss_mask: 0.7757  decode.d8.loss_dice: 1.4366
2023/05/24 03:56:07 - mmengine - INFO - Iter(train) [ 78450/160000]  lr: 5.4523e-06  eta: 9:44:00  time: 0.4217  data_time: 0.0103  memory: 4846  grad_norm: 90.3579  loss: 37.8062  decode.loss_cls: 1.3556  decode.loss_mask: 0.8568  decode.loss_dice: 1.3147  decode.d0.loss_cls: 3.1244  decode.d0.loss_mask: 0.9576  decode.d0.loss_dice: 1.5585  decode.d1.loss_cls: 1.4097  decode.d1.loss_mask: 0.9288  decode.d1.loss_dice: 1.4252  decode.d2.loss_cls: 1.2614  decode.d2.loss_mask: 0.9233  decode.d2.loss_dice: 1.3930  decode.d3.loss_cls: 1.3365  decode.d3.loss_mask: 0.8896  decode.d3.loss_dice: 1.3673  decode.d4.loss_cls: 1.3466  decode.d4.loss_mask: 0.9045  decode.d4.loss_dice: 1.3487  decode.d5.loss_cls: 1.2764  decode.d5.loss_mask: 0.9172  decode.d5.loss_dice: 1.3357  decode.d6.loss_cls: 1.3356  decode.d6.loss_mask: 0.8897  decode.d6.loss_dice: 1.3018  decode.d7.loss_cls: 1.3385  decode.d7.loss_mask: 0.8635  decode.d7.loss_dice: 1.3152  decode.d8.loss_cls: 1.3686  decode.d8.loss_mask: 0.8535  decode.d8.loss_dice: 1.3084
2023/05/24 03:56:28 - mmengine - INFO - Iter(train) [ 78500/160000]  lr: 5.4492e-06  eta: 9:43:38  time: 0.4228  data_time: 0.0108  memory: 4871  grad_norm: 100.6842  loss: 37.0373  decode.loss_cls: 1.4110  decode.loss_mask: 0.7906  decode.loss_dice: 1.1557  decode.d0.loss_cls: 3.4388  decode.d0.loss_mask: 0.8889  decode.d0.loss_dice: 1.3903  decode.d1.loss_cls: 1.5622  decode.d1.loss_mask: 0.8535  decode.d1.loss_dice: 1.3155  decode.d2.loss_cls: 1.5360  decode.d2.loss_mask: 0.8426  decode.d2.loss_dice: 1.2453  decode.d3.loss_cls: 1.5528  decode.d3.loss_mask: 0.8056  decode.d3.loss_dice: 1.2245  decode.d4.loss_cls: 1.4821  decode.d4.loss_mask: 0.7882  decode.d4.loss_dice: 1.2057  decode.d5.loss_cls: 1.4918  decode.d5.loss_mask: 0.7591  decode.d5.loss_dice: 1.1661  decode.d6.loss_cls: 1.4462  decode.d6.loss_mask: 0.7787  decode.d6.loss_dice: 1.1570  decode.d7.loss_cls: 1.3875  decode.d7.loss_mask: 0.7945  decode.d7.loss_dice: 1.1789  decode.d8.loss_cls: 1.4302  decode.d8.loss_mask: 0.7813  decode.d8.loss_dice: 1.1767
2023/05/24 03:56:50 - mmengine - INFO - Iter(train) [ 78550/160000]  lr: 5.4462e-06  eta: 9:43:16  time: 0.4277  data_time: 0.0107  memory: 4819  grad_norm: 134.7616  loss: 41.6424  decode.loss_cls: 1.4069  decode.loss_mask: 0.8693  decode.loss_dice: 1.5160  decode.d0.loss_cls: 3.5094  decode.d0.loss_mask: 1.0087  decode.d0.loss_dice: 1.8397  decode.d1.loss_cls: 1.6371  decode.d1.loss_mask: 0.9164  decode.d1.loss_dice: 1.7012  decode.d2.loss_cls: 1.5217  decode.d2.loss_mask: 0.8619  decode.d2.loss_dice: 1.6349  decode.d3.loss_cls: 1.4107  decode.d3.loss_mask: 0.8646  decode.d3.loss_dice: 1.5477  decode.d4.loss_cls: 1.4454  decode.d4.loss_mask: 0.8542  decode.d4.loss_dice: 1.5702  decode.d5.loss_cls: 1.4464  decode.d5.loss_mask: 0.8751  decode.d5.loss_dice: 1.5611  decode.d6.loss_cls: 1.4750  decode.d6.loss_mask: 0.8724  decode.d6.loss_dice: 1.5764  decode.d7.loss_cls: 1.4245  decode.d7.loss_mask: 0.8912  decode.d7.loss_dice: 1.6049  decode.d8.loss_cls: 1.3995  decode.d8.loss_mask: 0.8574  decode.d8.loss_dice: 1.5424
2023/05/24 03:57:11 - mmengine - INFO - Iter(train) [ 78600/160000]  lr: 5.4432e-06  eta: 9:42:54  time: 0.4167  data_time: 0.0101  memory: 4866  grad_norm: 92.4862  loss: 38.7972  decode.loss_cls: 1.3886  decode.loss_mask: 0.7205  decode.loss_dice: 1.4419  decode.d0.loss_cls: 3.4180  decode.d0.loss_mask: 0.7642  decode.d0.loss_dice: 1.6807  decode.d1.loss_cls: 1.5975  decode.d1.loss_mask: 0.8387  decode.d1.loss_dice: 1.5956  decode.d2.loss_cls: 1.5159  decode.d2.loss_mask: 0.7594  decode.d2.loss_dice: 1.5122  decode.d3.loss_cls: 1.4336  decode.d3.loss_mask: 0.7345  decode.d3.loss_dice: 1.4343  decode.d4.loss_cls: 1.4541  decode.d4.loss_mask: 0.7555  decode.d4.loss_dice: 1.4061  decode.d5.loss_cls: 1.3843  decode.d5.loss_mask: 0.7737  decode.d5.loss_dice: 1.4817  decode.d6.loss_cls: 1.3900  decode.d6.loss_mask: 0.7589  decode.d6.loss_dice: 1.4207  decode.d7.loss_cls: 1.3770  decode.d7.loss_mask: 0.7643  decode.d7.loss_dice: 1.4345  decode.d8.loss_cls: 1.4094  decode.d8.loss_mask: 0.7215  decode.d8.loss_dice: 1.4297
2023/05/24 03:57:32 - mmengine - INFO - Iter(train) [ 78650/160000]  lr: 5.4402e-06  eta: 9:42:33  time: 0.4379  data_time: 0.0103  memory: 4829  grad_norm: 91.3472  loss: 36.9502  decode.loss_cls: 1.2991  decode.loss_mask: 0.9133  decode.loss_dice: 1.2221  decode.d0.loss_cls: 3.0772  decode.d0.loss_mask: 0.9763  decode.d0.loss_dice: 1.4624  decode.d1.loss_cls: 1.4675  decode.d1.loss_mask: 0.9306  decode.d1.loss_dice: 1.3587  decode.d2.loss_cls: 1.3697  decode.d2.loss_mask: 0.9126  decode.d2.loss_dice: 1.2574  decode.d3.loss_cls: 1.3869  decode.d3.loss_mask: 0.9053  decode.d3.loss_dice: 1.2054  decode.d4.loss_cls: 1.3194  decode.d4.loss_mask: 0.9282  decode.d4.loss_dice: 1.2564  decode.d5.loss_cls: 1.2991  decode.d5.loss_mask: 0.8909  decode.d5.loss_dice: 1.2373  decode.d6.loss_cls: 1.2979  decode.d6.loss_mask: 0.8845  decode.d6.loss_dice: 1.2247  decode.d7.loss_cls: 1.2997  decode.d7.loss_mask: 0.9044  decode.d7.loss_dice: 1.2197  decode.d8.loss_cls: 1.2912  decode.d8.loss_mask: 0.9037  decode.d8.loss_dice: 1.2486
2023/05/24 03:57:53 - mmengine - INFO - Iter(train) [ 78700/160000]  lr: 5.4372e-06  eta: 9:42:11  time: 0.4238  data_time: 0.0104  memory: 4804  grad_norm: 110.2179  loss: 34.0117  decode.loss_cls: 1.0153  decode.loss_mask: 0.8796  decode.loss_dice: 1.2672  decode.d0.loss_cls: 2.6828  decode.d0.loss_mask: 0.9719  decode.d0.loss_dice: 1.3835  decode.d1.loss_cls: 1.1748  decode.d1.loss_mask: 0.9674  decode.d1.loss_dice: 1.3591  decode.d2.loss_cls: 1.0558  decode.d2.loss_mask: 0.9063  decode.d2.loss_dice: 1.3154  decode.d3.loss_cls: 0.9678  decode.d3.loss_mask: 0.9145  decode.d3.loss_dice: 1.2873  decode.d4.loss_cls: 1.0523  decode.d4.loss_mask: 0.9050  decode.d4.loss_dice: 1.2790  decode.d5.loss_cls: 0.9801  decode.d5.loss_mask: 0.8793  decode.d5.loss_dice: 1.2650  decode.d6.loss_cls: 1.0163  decode.d6.loss_mask: 0.8875  decode.d6.loss_dice: 1.2560  decode.d7.loss_cls: 1.0001  decode.d7.loss_mask: 0.8949  decode.d7.loss_dice: 1.2777  decode.d8.loss_cls: 1.0154  decode.d8.loss_mask: 0.8875  decode.d8.loss_dice: 1.2667
2023/05/24 03:58:15 - mmengine - INFO - Iter(train) [ 78750/160000]  lr: 5.4342e-06  eta: 9:41:50  time: 0.4747  data_time: 0.0103  memory: 4802  grad_norm: 84.0068  loss: 31.3587  decode.loss_cls: 1.0845  decode.loss_mask: 0.7291  decode.loss_dice: 1.0651  decode.d0.loss_cls: 2.7106  decode.d0.loss_mask: 0.8023  decode.d0.loss_dice: 1.2413  decode.d1.loss_cls: 1.2086  decode.d1.loss_mask: 0.8232  decode.d1.loss_dice: 1.2292  decode.d2.loss_cls: 1.0838  decode.d2.loss_mask: 0.7893  decode.d2.loss_dice: 1.1365  decode.d3.loss_cls: 1.1140  decode.d3.loss_mask: 0.7359  decode.d3.loss_dice: 1.0885  decode.d4.loss_cls: 1.0927  decode.d4.loss_mask: 0.7290  decode.d4.loss_dice: 1.0820  decode.d5.loss_cls: 1.0867  decode.d5.loss_mask: 0.7273  decode.d5.loss_dice: 1.1140  decode.d6.loss_cls: 1.0510  decode.d6.loss_mask: 0.7310  decode.d6.loss_dice: 1.0980  decode.d7.loss_cls: 1.0558  decode.d7.loss_mask: 0.7447  decode.d7.loss_dice: 1.0746  decode.d8.loss_cls: 1.0812  decode.d8.loss_mask: 0.7400  decode.d8.loss_dice: 1.1088
2023/05/24 03:58:38 - mmengine - INFO - Iter(train) [ 78800/160000]  lr: 5.4312e-06  eta: 9:41:30  time: 0.4287  data_time: 0.0104  memory: 4889  grad_norm: 87.7523  loss: 46.5028  decode.loss_cls: 1.5808  decode.loss_mask: 1.0087  decode.loss_dice: 1.6960  decode.d0.loss_cls: 3.5891  decode.d0.loss_mask: 1.1877  decode.d0.loss_dice: 2.1244  decode.d1.loss_cls: 1.6615  decode.d1.loss_mask: 1.0298  decode.d1.loss_dice: 1.8792  decode.d2.loss_cls: 1.6608  decode.d2.loss_mask: 1.0491  decode.d2.loss_dice: 1.8414  decode.d3.loss_cls: 1.6581  decode.d3.loss_mask: 1.0340  decode.d3.loss_dice: 1.8052  decode.d4.loss_cls: 1.6312  decode.d4.loss_mask: 1.0384  decode.d4.loss_dice: 1.7646  decode.d5.loss_cls: 1.6149  decode.d5.loss_mask: 1.0273  decode.d5.loss_dice: 1.7608  decode.d6.loss_cls: 1.5632  decode.d6.loss_mask: 1.0209  decode.d6.loss_dice: 1.7222  decode.d7.loss_cls: 1.5175  decode.d7.loss_mask: 1.0315  decode.d7.loss_dice: 1.7120  decode.d8.loss_cls: 1.5529  decode.d8.loss_mask: 1.0185  decode.d8.loss_dice: 1.7210
2023/05/24 03:59:00 - mmengine - INFO - Iter(train) [ 78850/160000]  lr: 5.4282e-06  eta: 9:41:08  time: 0.4616  data_time: 0.0107  memory: 4845  grad_norm: 80.2247  loss: 31.1261  decode.loss_cls: 0.9687  decode.loss_mask: 0.7676  decode.loss_dice: 1.0943  decode.d0.loss_cls: 2.8170  decode.d0.loss_mask: 0.8423  decode.d0.loss_dice: 1.2451  decode.d1.loss_cls: 1.1939  decode.d1.loss_mask: 0.7932  decode.d1.loss_dice: 1.1561  decode.d2.loss_cls: 1.0702  decode.d2.loss_mask: 0.8131  decode.d2.loss_dice: 1.1037  decode.d3.loss_cls: 1.0230  decode.d3.loss_mask: 0.7837  decode.d3.loss_dice: 1.1235  decode.d4.loss_cls: 1.0278  decode.d4.loss_mask: 0.7992  decode.d4.loss_dice: 1.1014  decode.d5.loss_cls: 1.0149  decode.d5.loss_mask: 0.7891  decode.d5.loss_dice: 1.1079  decode.d6.loss_cls: 0.9645  decode.d6.loss_mask: 0.7672  decode.d6.loss_dice: 1.1015  decode.d7.loss_cls: 0.9892  decode.d7.loss_mask: 0.7691  decode.d7.loss_dice: 1.0795  decode.d8.loss_cls: 0.9820  decode.d8.loss_mask: 0.7608  decode.d8.loss_dice: 1.0766
2023/05/24 03:59:22 - mmengine - INFO - Iter(train) [ 78900/160000]  lr: 5.4252e-06  eta: 9:40:48  time: 0.4145  data_time: 0.0102  memory: 4876  grad_norm: 94.4115  loss: 30.2328  decode.loss_cls: 0.9246  decode.loss_mask: 0.5979  decode.loss_dice: 1.2308  decode.d0.loss_cls: 3.0403  decode.d0.loss_mask: 0.6151  decode.d0.loss_dice: 1.4235  decode.d1.loss_cls: 1.1491  decode.d1.loss_mask: 0.5653  decode.d1.loss_dice: 1.2918  decode.d2.loss_cls: 1.0323  decode.d2.loss_mask: 0.5817  decode.d2.loss_dice: 1.2432  decode.d3.loss_cls: 1.0111  decode.d3.loss_mask: 0.5727  decode.d3.loss_dice: 1.2258  decode.d4.loss_cls: 0.9674  decode.d4.loss_mask: 0.5818  decode.d4.loss_dice: 1.2242  decode.d5.loss_cls: 1.0002  decode.d5.loss_mask: 0.5743  decode.d5.loss_dice: 1.1839  decode.d6.loss_cls: 0.9620  decode.d6.loss_mask: 0.5728  decode.d6.loss_dice: 1.2213  decode.d7.loss_cls: 0.9471  decode.d7.loss_mask: 0.5743  decode.d7.loss_dice: 1.2092  decode.d8.loss_cls: 0.9420  decode.d8.loss_mask: 0.5842  decode.d8.loss_dice: 1.1831
2023/05/24 03:59:43 - mmengine - INFO - Iter(train) [ 78950/160000]  lr: 5.4222e-06  eta: 9:40:26  time: 0.4099  data_time: 0.0101  memory: 4884  grad_norm: 109.1322  loss: 38.0735  decode.loss_cls: 1.2174  decode.loss_mask: 0.8890  decode.loss_dice: 1.4043  decode.d0.loss_cls: 3.1877  decode.d0.loss_mask: 0.8605  decode.d0.loss_dice: 1.5821  decode.d1.loss_cls: 1.4118  decode.d1.loss_mask: 0.9579  decode.d1.loss_dice: 1.5252  decode.d2.loss_cls: 1.2840  decode.d2.loss_mask: 0.9239  decode.d2.loss_dice: 1.4986  decode.d3.loss_cls: 1.2576  decode.d3.loss_mask: 0.9404  decode.d3.loss_dice: 1.4596  decode.d4.loss_cls: 1.2334  decode.d4.loss_mask: 0.8974  decode.d4.loss_dice: 1.4287  decode.d5.loss_cls: 1.1923  decode.d5.loss_mask: 0.8984  decode.d5.loss_dice: 1.4466  decode.d6.loss_cls: 1.2574  decode.d6.loss_mask: 0.8696  decode.d6.loss_dice: 1.4068  decode.d7.loss_cls: 1.2343  decode.d7.loss_mask: 0.8933  decode.d7.loss_dice: 1.3976  decode.d8.loss_cls: 1.2197  decode.d8.loss_mask: 0.8998  decode.d8.loss_dice: 1.3980
2023/05/24 04:00:07 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 04:00:07 - mmengine - INFO - Iter(train) [ 79000/160000]  lr: 5.4191e-06  eta: 9:40:07  time: 0.4706  data_time: 0.0106  memory: 4827  grad_norm: 93.5062  loss: 36.7318  decode.loss_cls: 1.3251  decode.loss_mask: 0.8249  decode.loss_dice: 1.2038  decode.d0.loss_cls: 3.2857  decode.d0.loss_mask: 0.9527  decode.d0.loss_dice: 1.5022  decode.d1.loss_cls: 1.4044  decode.d1.loss_mask: 0.9204  decode.d1.loss_dice: 1.3996  decode.d2.loss_cls: 1.3756  decode.d2.loss_mask: 0.9048  decode.d2.loss_dice: 1.3153  decode.d3.loss_cls: 1.3544  decode.d3.loss_mask: 0.8727  decode.d3.loss_dice: 1.2763  decode.d4.loss_cls: 1.2581  decode.d4.loss_mask: 0.8654  decode.d4.loss_dice: 1.2456  decode.d5.loss_cls: 1.2909  decode.d5.loss_mask: 0.8450  decode.d5.loss_dice: 1.2430  decode.d6.loss_cls: 1.3054  decode.d6.loss_mask: 0.8318  decode.d6.loss_dice: 1.1989  decode.d7.loss_cls: 1.3450  decode.d7.loss_mask: 0.8322  decode.d7.loss_dice: 1.2203  decode.d8.loss_cls: 1.2984  decode.d8.loss_mask: 0.8280  decode.d8.loss_dice: 1.2061
2023/05/24 04:00:07 - mmengine - INFO - Saving checkpoint at 79000 iterations
2023/05/24 04:00:34 - mmengine - INFO - Iter(train) [ 79050/160000]  lr: 5.4161e-06  eta: 9:39:52  time: 0.4714  data_time: 0.0102  memory: 4909  grad_norm: 95.6580  loss: 23.7011  decode.loss_cls: 0.9343  decode.loss_mask: 0.5273  decode.loss_dice: 0.7142  decode.d0.loss_cls: 2.2608  decode.d0.loss_mask: 0.5795  decode.d0.loss_dice: 0.8830  decode.d1.loss_cls: 1.0063  decode.d1.loss_mask: 0.5438  decode.d1.loss_dice: 0.7329  decode.d2.loss_cls: 0.9677  decode.d2.loss_mask: 0.5433  decode.d2.loss_dice: 0.7196  decode.d3.loss_cls: 0.9364  decode.d3.loss_mask: 0.5554  decode.d3.loss_dice: 0.7515  decode.d4.loss_cls: 0.9378  decode.d4.loss_mask: 0.5464  decode.d4.loss_dice: 0.7775  decode.d5.loss_cls: 0.9477  decode.d5.loss_mask: 0.5257  decode.d5.loss_dice: 0.7584  decode.d6.loss_cls: 0.9184  decode.d6.loss_mask: 0.5314  decode.d6.loss_dice: 0.7254  decode.d7.loss_cls: 0.9555  decode.d7.loss_mask: 0.5172  decode.d7.loss_dice: 0.7472  decode.d8.loss_cls: 0.9216  decode.d8.loss_mask: 0.5123  decode.d8.loss_dice: 0.7227
2023/05/24 04:00:56 - mmengine - INFO - Iter(train) [ 79100/160000]  lr: 5.4131e-06  eta: 9:39:30  time: 0.4375  data_time: 0.0107  memory: 4855  grad_norm: 88.7640  loss: 36.4896  decode.loss_cls: 1.2444  decode.loss_mask: 0.7772  decode.loss_dice: 1.2712  decode.d0.loss_cls: 3.1634  decode.d0.loss_mask: 0.8296  decode.d0.loss_dice: 1.4994  decode.d1.loss_cls: 1.3547  decode.d1.loss_mask: 0.8386  decode.d1.loss_dice: 1.4846  decode.d2.loss_cls: 1.4570  decode.d2.loss_mask: 0.8008  decode.d2.loss_dice: 1.3936  decode.d3.loss_cls: 1.3688  decode.d3.loss_mask: 0.7854  decode.d3.loss_dice: 1.3767  decode.d4.loss_cls: 1.2670  decode.d4.loss_mask: 0.7907  decode.d4.loss_dice: 1.3685  decode.d5.loss_cls: 1.2587  decode.d5.loss_mask: 0.7892  decode.d5.loss_dice: 1.3408  decode.d6.loss_cls: 1.2279  decode.d6.loss_mask: 0.7797  decode.d6.loss_dice: 1.3197  decode.d7.loss_cls: 1.2477  decode.d7.loss_mask: 0.7841  decode.d7.loss_dice: 1.2952  decode.d8.loss_cls: 1.2659  decode.d8.loss_mask: 0.7839  decode.d8.loss_dice: 1.3252
2023/05/24 04:01:17 - mmengine - INFO - Iter(train) [ 79150/160000]  lr: 5.4101e-06  eta: 9:39:08  time: 0.4205  data_time: 0.0103  memory: 4845  grad_norm: 89.6943  loss: 39.2595  decode.loss_cls: 1.2876  decode.loss_mask: 0.8356  decode.loss_dice: 1.4696  decode.d0.loss_cls: 3.6741  decode.d0.loss_mask: 0.8993  decode.d0.loss_dice: 1.6505  decode.d1.loss_cls: 1.5229  decode.d1.loss_mask: 0.8519  decode.d1.loss_dice: 1.5657  decode.d2.loss_cls: 1.4205  decode.d2.loss_mask: 0.8430  decode.d2.loss_dice: 1.4765  decode.d3.loss_cls: 1.3620  decode.d3.loss_mask: 0.8400  decode.d3.loss_dice: 1.4566  decode.d4.loss_cls: 1.3323  decode.d4.loss_mask: 0.8186  decode.d4.loss_dice: 1.4332  decode.d5.loss_cls: 1.3778  decode.d5.loss_mask: 0.8232  decode.d5.loss_dice: 1.4300  decode.d6.loss_cls: 1.3603  decode.d6.loss_mask: 0.8385  decode.d6.loss_dice: 1.4556  decode.d7.loss_cls: 1.3730  decode.d7.loss_mask: 0.8329  decode.d7.loss_dice: 1.4339  decode.d8.loss_cls: 1.3193  decode.d8.loss_mask: 0.8386  decode.d8.loss_dice: 1.4364
2023/05/24 04:01:39 - mmengine - INFO - Iter(train) [ 79200/160000]  lr: 5.4071e-06  eta: 9:38:47  time: 0.4806  data_time: 0.0099  memory: 4859  grad_norm: 94.9155  loss: 27.8546  decode.loss_cls: 0.8472  decode.loss_mask: 0.7195  decode.loss_dice: 0.9458  decode.d0.loss_cls: 2.7792  decode.d0.loss_mask: 0.8024  decode.d0.loss_dice: 1.0953  decode.d1.loss_cls: 0.9329  decode.d1.loss_mask: 0.8035  decode.d1.loss_dice: 1.0179  decode.d2.loss_cls: 0.8594  decode.d2.loss_mask: 0.7727  decode.d2.loss_dice: 1.0096  decode.d3.loss_cls: 0.8248  decode.d3.loss_mask: 0.7494  decode.d3.loss_dice: 0.9922  decode.d4.loss_cls: 0.8128  decode.d4.loss_mask: 0.7418  decode.d4.loss_dice: 0.9975  decode.d5.loss_cls: 0.8273  decode.d5.loss_mask: 0.7184  decode.d5.loss_dice: 0.9835  decode.d6.loss_cls: 0.8675  decode.d6.loss_mask: 0.7299  decode.d6.loss_dice: 0.9463  decode.d7.loss_cls: 0.8388  decode.d7.loss_mask: 0.7187  decode.d7.loss_dice: 0.9670  decode.d8.loss_cls: 0.8563  decode.d8.loss_mask: 0.7330  decode.d8.loss_dice: 0.9641
2023/05/24 04:02:00 - mmengine - INFO - Iter(train) [ 79250/160000]  lr: 5.4041e-06  eta: 9:38:25  time: 0.4185  data_time: 0.0107  memory: 4866  grad_norm: 79.5670  loss: 28.5663  decode.loss_cls: 0.9796  decode.loss_mask: 0.6835  decode.loss_dice: 0.8914  decode.d0.loss_cls: 2.9411  decode.d0.loss_mask: 0.7412  decode.d0.loss_dice: 1.0552  decode.d1.loss_cls: 1.1360  decode.d1.loss_mask: 0.7082  decode.d1.loss_dice: 0.9681  decode.d2.loss_cls: 1.1534  decode.d2.loss_mask: 0.6942  decode.d2.loss_dice: 0.9022  decode.d3.loss_cls: 1.0951  decode.d3.loss_mask: 0.7127  decode.d3.loss_dice: 0.8891  decode.d4.loss_cls: 1.0405  decode.d4.loss_mask: 0.7064  decode.d4.loss_dice: 0.8805  decode.d5.loss_cls: 1.0134  decode.d5.loss_mask: 0.7115  decode.d5.loss_dice: 0.8882  decode.d6.loss_cls: 0.9743  decode.d6.loss_mask: 0.7237  decode.d6.loss_dice: 0.8920  decode.d7.loss_cls: 1.0478  decode.d7.loss_mask: 0.6995  decode.d7.loss_dice: 0.8803  decode.d8.loss_cls: 0.9854  decode.d8.loss_mask: 0.6994  decode.d8.loss_dice: 0.8725
2023/05/24 04:02:22 - mmengine - INFO - Iter(train) [ 79300/160000]  lr: 5.4011e-06  eta: 9:38:04  time: 0.4184  data_time: 0.0108  memory: 4929  grad_norm: 91.6477  loss: 33.1857  decode.loss_cls: 1.1819  decode.loss_mask: 0.6729  decode.loss_dice: 1.2018  decode.d0.loss_cls: 3.0978  decode.d0.loss_mask: 0.7427  decode.d0.loss_dice: 1.4887  decode.d1.loss_cls: 1.2357  decode.d1.loss_mask: 0.7588  decode.d1.loss_dice: 1.4078  decode.d2.loss_cls: 1.2380  decode.d2.loss_mask: 0.7163  decode.d2.loss_dice: 1.3504  decode.d3.loss_cls: 1.1197  decode.d3.loss_mask: 0.7023  decode.d3.loss_dice: 1.2279  decode.d4.loss_cls: 1.1675  decode.d4.loss_mask: 0.6789  decode.d4.loss_dice: 1.2077  decode.d5.loss_cls: 1.0529  decode.d5.loss_mask: 0.7036  decode.d5.loss_dice: 1.2256  decode.d6.loss_cls: 1.0968  decode.d6.loss_mask: 0.6748  decode.d6.loss_dice: 1.2133  decode.d7.loss_cls: 1.0933  decode.d7.loss_mask: 0.6751  decode.d7.loss_dice: 1.2435  decode.d8.loss_cls: 1.1055  decode.d8.loss_mask: 0.6771  decode.d8.loss_dice: 1.2274
2023/05/24 04:02:42 - mmengine - INFO - Iter(train) [ 79350/160000]  lr: 5.3981e-06  eta: 9:37:42  time: 0.4215  data_time: 0.0102  memory: 4839  grad_norm: 128.9042  loss: 32.6737  decode.loss_cls: 1.1627  decode.loss_mask: 0.6960  decode.loss_dice: 1.1830  decode.d0.loss_cls: 3.1331  decode.d0.loss_mask: 0.7408  decode.d0.loss_dice: 1.3127  decode.d1.loss_cls: 1.2581  decode.d1.loss_mask: 0.7119  decode.d1.loss_dice: 1.2413  decode.d2.loss_cls: 1.1201  decode.d2.loss_mask: 0.7076  decode.d2.loss_dice: 1.2262  decode.d3.loss_cls: 1.1179  decode.d3.loss_mask: 0.6571  decode.d3.loss_dice: 1.2066  decode.d4.loss_cls: 1.1654  decode.d4.loss_mask: 0.6715  decode.d4.loss_dice: 1.1816  decode.d5.loss_cls: 1.1643  decode.d5.loss_mask: 0.7176  decode.d5.loss_dice: 1.1882  decode.d6.loss_cls: 1.1515  decode.d6.loss_mask: 0.7101  decode.d6.loss_dice: 1.1925  decode.d7.loss_cls: 1.0823  decode.d7.loss_mask: 0.7150  decode.d7.loss_dice: 1.2164  decode.d8.loss_cls: 1.1127  decode.d8.loss_mask: 0.7247  decode.d8.loss_dice: 1.2048
2023/05/24 04:03:03 - mmengine - INFO - Iter(train) [ 79400/160000]  lr: 5.3951e-06  eta: 9:37:20  time: 0.4112  data_time: 0.0103  memory: 4836  grad_norm: 111.9532  loss: 29.2329  decode.loss_cls: 0.9182  decode.loss_mask: 0.6916  decode.loss_dice: 1.0612  decode.d0.loss_cls: 2.7621  decode.d0.loss_mask: 0.6955  decode.d0.loss_dice: 1.2659  decode.d1.loss_cls: 1.0126  decode.d1.loss_mask: 0.7213  decode.d1.loss_dice: 1.1811  decode.d2.loss_cls: 0.9343  decode.d2.loss_mask: 0.6952  decode.d2.loss_dice: 1.1308  decode.d3.loss_cls: 0.9314  decode.d3.loss_mask: 0.7037  decode.d3.loss_dice: 1.0936  decode.d4.loss_cls: 0.9344  decode.d4.loss_mask: 0.7119  decode.d4.loss_dice: 1.0786  decode.d5.loss_cls: 0.9331  decode.d5.loss_mask: 0.7266  decode.d5.loss_dice: 1.0883  decode.d6.loss_cls: 0.8666  decode.d6.loss_mask: 0.7124  decode.d6.loss_dice: 1.0756  decode.d7.loss_cls: 0.8608  decode.d7.loss_mask: 0.7130  decode.d7.loss_dice: 1.0792  decode.d8.loss_cls: 0.8840  decode.d8.loss_mask: 0.7218  decode.d8.loss_dice: 1.0480
2023/05/24 04:03:24 - mmengine - INFO - Iter(train) [ 79450/160000]  lr: 5.3920e-06  eta: 9:36:58  time: 0.4429  data_time: 0.0105  memory: 4836  grad_norm: 107.6028  loss: 34.0685  decode.loss_cls: 1.0009  decode.loss_mask: 0.8002  decode.loss_dice: 1.3274  decode.d0.loss_cls: 3.0371  decode.d0.loss_mask: 0.8573  decode.d0.loss_dice: 1.4490  decode.d1.loss_cls: 1.1182  decode.d1.loss_mask: 0.8772  decode.d1.loss_dice: 1.4408  decode.d2.loss_cls: 1.0300  decode.d2.loss_mask: 0.8489  decode.d2.loss_dice: 1.4228  decode.d3.loss_cls: 1.0838  decode.d3.loss_mask: 0.8131  decode.d3.loss_dice: 1.3265  decode.d4.loss_cls: 0.9942  decode.d4.loss_mask: 0.8018  decode.d4.loss_dice: 1.3292  decode.d5.loss_cls: 0.9716  decode.d5.loss_mask: 0.8188  decode.d5.loss_dice: 1.3505  decode.d6.loss_cls: 0.9692  decode.d6.loss_mask: 0.8057  decode.d6.loss_dice: 1.3428  decode.d7.loss_cls: 0.9841  decode.d7.loss_mask: 0.7964  decode.d7.loss_dice: 1.3301  decode.d8.loss_cls: 0.9856  decode.d8.loss_mask: 0.8093  decode.d8.loss_dice: 1.3459
2023/05/24 04:03:47 - mmengine - INFO - Iter(train) [ 79500/160000]  lr: 5.3890e-06  eta: 9:36:37  time: 0.4392  data_time: 0.0106  memory: 4868  grad_norm: 86.9748  loss: 32.2057  decode.loss_cls: 0.9708  decode.loss_mask: 0.8249  decode.loss_dice: 1.1294  decode.d0.loss_cls: 3.1972  decode.d0.loss_mask: 0.8360  decode.d0.loss_dice: 1.3222  decode.d1.loss_cls: 1.0492  decode.d1.loss_mask: 0.8914  decode.d1.loss_dice: 1.2330  decode.d2.loss_cls: 1.0245  decode.d2.loss_mask: 0.8718  decode.d2.loss_dice: 1.1893  decode.d3.loss_cls: 1.0302  decode.d3.loss_mask: 0.8391  decode.d3.loss_dice: 1.1228  decode.d4.loss_cls: 1.0327  decode.d4.loss_mask: 0.8180  decode.d4.loss_dice: 1.1234  decode.d5.loss_cls: 0.9920  decode.d5.loss_mask: 0.8314  decode.d5.loss_dice: 1.1081  decode.d6.loss_cls: 0.9765  decode.d6.loss_mask: 0.8246  decode.d6.loss_dice: 1.1266  decode.d7.loss_cls: 0.9812  decode.d7.loss_mask: 0.8122  decode.d7.loss_dice: 1.1167  decode.d8.loss_cls: 0.9775  decode.d8.loss_mask: 0.8181  decode.d8.loss_dice: 1.1351
2023/05/24 04:04:09 - mmengine - INFO - Iter(train) [ 79550/160000]  lr: 5.3860e-06  eta: 9:36:17  time: 0.4089  data_time: 0.0102  memory: 4803  grad_norm: 91.6420  loss: 29.7903  decode.loss_cls: 1.1033  decode.loss_mask: 0.6517  decode.loss_dice: 0.9006  decode.d0.loss_cls: 2.9864  decode.d0.loss_mask: 0.7272  decode.d0.loss_dice: 1.1248  decode.d1.loss_cls: 1.2522  decode.d1.loss_mask: 0.7114  decode.d1.loss_dice: 1.0200  decode.d2.loss_cls: 1.1928  decode.d2.loss_mask: 0.6966  decode.d2.loss_dice: 0.9770  decode.d3.loss_cls: 1.1814  decode.d3.loss_mask: 0.6558  decode.d3.loss_dice: 0.9179  decode.d4.loss_cls: 1.2095  decode.d4.loss_mask: 0.6551  decode.d4.loss_dice: 0.9131  decode.d5.loss_cls: 1.1526  decode.d5.loss_mask: 0.6582  decode.d5.loss_dice: 0.9174  decode.d6.loss_cls: 1.1606  decode.d6.loss_mask: 0.6522  decode.d6.loss_dice: 0.8929  decode.d7.loss_cls: 1.1530  decode.d7.loss_mask: 0.6679  decode.d7.loss_dice: 0.9277  decode.d8.loss_cls: 1.1227  decode.d8.loss_mask: 0.6635  decode.d8.loss_dice: 0.9446
2023/05/24 04:04:30 - mmengine - INFO - Iter(train) [ 79600/160000]  lr: 5.3830e-06  eta: 9:35:55  time: 0.4257  data_time: 0.0104  memory: 4926  grad_norm: 90.6311  loss: 28.4746  decode.loss_cls: 1.1181  decode.loss_mask: 0.5559  decode.loss_dice: 0.9276  decode.d0.loss_cls: 2.9958  decode.d0.loss_mask: 0.6099  decode.d0.loss_dice: 1.0977  decode.d1.loss_cls: 1.2266  decode.d1.loss_mask: 0.5902  decode.d1.loss_dice: 1.0129  decode.d2.loss_cls: 1.1678  decode.d2.loss_mask: 0.5671  decode.d2.loss_dice: 0.9960  decode.d3.loss_cls: 1.1464  decode.d3.loss_mask: 0.5337  decode.d3.loss_dice: 0.9360  decode.d4.loss_cls: 1.1160  decode.d4.loss_mask: 0.5545  decode.d4.loss_dice: 0.9511  decode.d5.loss_cls: 1.0965  decode.d5.loss_mask: 0.5604  decode.d5.loss_dice: 0.9082  decode.d6.loss_cls: 1.1443  decode.d6.loss_mask: 0.5519  decode.d6.loss_dice: 0.9117  decode.d7.loss_cls: 1.1398  decode.d7.loss_mask: 0.5464  decode.d7.loss_dice: 0.9307  decode.d8.loss_cls: 1.1130  decode.d8.loss_mask: 0.5570  decode.d8.loss_dice: 0.9115
2023/05/24 04:04:52 - mmengine - INFO - Iter(train) [ 79650/160000]  lr: 5.3800e-06  eta: 9:35:33  time: 0.4587  data_time: 0.0103  memory: 4866  grad_norm: 95.5016  loss: 33.1142  decode.loss_cls: 1.1038  decode.loss_mask: 0.7111  decode.loss_dice: 1.2261  decode.d0.loss_cls: 3.0563  decode.d0.loss_mask: 0.6870  decode.d0.loss_dice: 1.4258  decode.d1.loss_cls: 1.2048  decode.d1.loss_mask: 0.7709  decode.d1.loss_dice: 1.3693  decode.d2.loss_cls: 1.1426  decode.d2.loss_mask: 0.7473  decode.d2.loss_dice: 1.2710  decode.d3.loss_cls: 1.1667  decode.d3.loss_mask: 0.7073  decode.d3.loss_dice: 1.2800  decode.d4.loss_cls: 1.1000  decode.d4.loss_mask: 0.7175  decode.d4.loss_dice: 1.2485  decode.d5.loss_cls: 1.1337  decode.d5.loss_mask: 0.7125  decode.d5.loss_dice: 1.2346  decode.d6.loss_cls: 1.0986  decode.d6.loss_mask: 0.7010  decode.d6.loss_dice: 1.2172  decode.d7.loss_cls: 1.1033  decode.d7.loss_mask: 0.6968  decode.d7.loss_dice: 1.2317  decode.d8.loss_cls: 1.0987  decode.d8.loss_mask: 0.7082  decode.d8.loss_dice: 1.2417
2023/05/24 04:05:15 - mmengine - INFO - Iter(train) [ 79700/160000]  lr: 5.3770e-06  eta: 9:35:13  time: 0.4662  data_time: 0.0105  memory: 4883  grad_norm: 94.7770  loss: 43.7131  decode.loss_cls: 1.4141  decode.loss_mask: 0.9961  decode.loss_dice: 1.6601  decode.d0.loss_cls: 3.4816  decode.d0.loss_mask: 1.0218  decode.d0.loss_dice: 1.9635  decode.d1.loss_cls: 1.5894  decode.d1.loss_mask: 0.9905  decode.d1.loss_dice: 1.7966  decode.d2.loss_cls: 1.5358  decode.d2.loss_mask: 0.9722  decode.d2.loss_dice: 1.7248  decode.d3.loss_cls: 1.5085  decode.d3.loss_mask: 0.9934  decode.d3.loss_dice: 1.6710  decode.d4.loss_cls: 1.4075  decode.d4.loss_mask: 0.9844  decode.d4.loss_dice: 1.6826  decode.d5.loss_cls: 1.4682  decode.d5.loss_mask: 1.0037  decode.d5.loss_dice: 1.6850  decode.d6.loss_cls: 1.4333  decode.d6.loss_mask: 0.9740  decode.d6.loss_dice: 1.6334  decode.d7.loss_cls: 1.4370  decode.d7.loss_mask: 0.9689  decode.d7.loss_dice: 1.6429  decode.d8.loss_cls: 1.4363  decode.d8.loss_mask: 0.9621  decode.d8.loss_dice: 1.6744
2023/05/24 04:05:39 - mmengine - INFO - Iter(train) [ 79750/160000]  lr: 5.3740e-06  eta: 9:34:54  time: 0.4759  data_time: 0.0100  memory: 4877  grad_norm: 112.1082  loss: 29.5811  decode.loss_cls: 1.0233  decode.loss_mask: 0.6780  decode.loss_dice: 0.9789  decode.d0.loss_cls: 2.8202  decode.d0.loss_mask: 0.7454  decode.d0.loss_dice: 1.1539  decode.d1.loss_cls: 1.2025  decode.d1.loss_mask: 0.7575  decode.d1.loss_dice: 1.0434  decode.d2.loss_cls: 1.0989  decode.d2.loss_mask: 0.6991  decode.d2.loss_dice: 1.0450  decode.d3.loss_cls: 1.0557  decode.d3.loss_mask: 0.6787  decode.d3.loss_dice: 1.0337  decode.d4.loss_cls: 1.0318  decode.d4.loss_mask: 0.6831  decode.d4.loss_dice: 1.0303  decode.d5.loss_cls: 0.9871  decode.d5.loss_mask: 0.6846  decode.d5.loss_dice: 1.0521  decode.d6.loss_cls: 1.0221  decode.d6.loss_mask: 0.6841  decode.d6.loss_dice: 1.0025  decode.d7.loss_cls: 1.0140  decode.d7.loss_mask: 0.6754  decode.d7.loss_dice: 1.0087  decode.d8.loss_cls: 1.0324  decode.d8.loss_mask: 0.6605  decode.d8.loss_dice: 0.9983
2023/05/24 04:06:00 - mmengine - INFO - Iter(train) [ 79800/160000]  lr: 5.3710e-06  eta: 9:34:32  time: 0.4314  data_time: 0.0103  memory: 4880  grad_norm: 98.8376  loss: 43.8801  decode.loss_cls: 1.4217  decode.loss_mask: 0.8571  decode.loss_dice: 1.7182  decode.d0.loss_cls: 3.7488  decode.d0.loss_mask: 0.9265  decode.d0.loss_dice: 2.0510  decode.d1.loss_cls: 1.5611  decode.d1.loss_mask: 0.9273  decode.d1.loss_dice: 1.8851  decode.d2.loss_cls: 1.5266  decode.d2.loss_mask: 0.8789  decode.d2.loss_dice: 1.8425  decode.d3.loss_cls: 1.5137  decode.d3.loss_mask: 0.8401  decode.d3.loss_dice: 1.7583  decode.d4.loss_cls: 1.5498  decode.d4.loss_mask: 0.8186  decode.d4.loss_dice: 1.7726  decode.d5.loss_cls: 1.5364  decode.d5.loss_mask: 0.8211  decode.d5.loss_dice: 1.7697  decode.d6.loss_cls: 1.4733  decode.d6.loss_mask: 0.8349  decode.d6.loss_dice: 1.7238  decode.d7.loss_cls: 1.4520  decode.d7.loss_mask: 0.8353  decode.d7.loss_dice: 1.7826  decode.d8.loss_cls: 1.4016  decode.d8.loss_mask: 0.8602  decode.d8.loss_dice: 1.7913
2023/05/24 04:06:21 - mmengine - INFO - Iter(train) [ 79850/160000]  lr: 5.3679e-06  eta: 9:34:10  time: 0.4173  data_time: 0.0107  memory: 4860  grad_norm: 90.3863  loss: 35.7633  decode.loss_cls: 1.2679  decode.loss_mask: 0.8513  decode.loss_dice: 1.2166  decode.d0.loss_cls: 3.2400  decode.d0.loss_mask: 0.8135  decode.d0.loss_dice: 1.3646  decode.d1.loss_cls: 1.4089  decode.d1.loss_mask: 0.8327  decode.d1.loss_dice: 1.3180  decode.d2.loss_cls: 1.4136  decode.d2.loss_mask: 0.8670  decode.d2.loss_dice: 1.2040  decode.d3.loss_cls: 1.3378  decode.d3.loss_mask: 0.8450  decode.d3.loss_dice: 1.2250  decode.d4.loss_cls: 1.3366  decode.d4.loss_mask: 0.8434  decode.d4.loss_dice: 1.1748  decode.d5.loss_cls: 1.3348  decode.d5.loss_mask: 0.8335  decode.d5.loss_dice: 1.1988  decode.d6.loss_cls: 1.3121  decode.d6.loss_mask: 0.8265  decode.d6.loss_dice: 1.1498  decode.d7.loss_cls: 1.2742  decode.d7.loss_mask: 0.8416  decode.d7.loss_dice: 1.1397  decode.d8.loss_cls: 1.2911  decode.d8.loss_mask: 0.8202  decode.d8.loss_dice: 1.1805
2023/05/24 04:06:42 - mmengine - INFO - Iter(train) [ 79900/160000]  lr: 5.3649e-06  eta: 9:33:48  time: 0.4162  data_time: 0.0100  memory: 4890  grad_norm: 90.5143  loss: 26.5435  decode.loss_cls: 0.8440  decode.loss_mask: 0.6155  decode.loss_dice: 0.9580  decode.d0.loss_cls: 2.5358  decode.d0.loss_mask: 0.7020  decode.d0.loss_dice: 1.1059  decode.d1.loss_cls: 0.9432  decode.d1.loss_mask: 0.6624  decode.d1.loss_dice: 1.0537  decode.d2.loss_cls: 0.9247  decode.d2.loss_mask: 0.6542  decode.d2.loss_dice: 1.0208  decode.d3.loss_cls: 0.8511  decode.d3.loss_mask: 0.6165  decode.d3.loss_dice: 0.9815  decode.d4.loss_cls: 0.8357  decode.d4.loss_mask: 0.6104  decode.d4.loss_dice: 0.9641  decode.d5.loss_cls: 0.8082  decode.d5.loss_mask: 0.6182  decode.d5.loss_dice: 0.9982  decode.d6.loss_cls: 0.8348  decode.d6.loss_mask: 0.6367  decode.d6.loss_dice: 0.9808  decode.d7.loss_cls: 0.8182  decode.d7.loss_mask: 0.5960  decode.d7.loss_dice: 0.9727  decode.d8.loss_cls: 0.7941  decode.d8.loss_mask: 0.6335  decode.d8.loss_dice: 0.9726
2023/05/24 04:07:03 - mmengine - INFO - Iter(train) [ 79950/160000]  lr: 5.3619e-06  eta: 9:33:26  time: 0.4128  data_time: 0.0105  memory: 4878  grad_norm: 113.1659  loss: 31.1175  decode.loss_cls: 0.8984  decode.loss_mask: 0.7406  decode.loss_dice: 1.1987  decode.d0.loss_cls: 2.6955  decode.d0.loss_mask: 0.7809  decode.d0.loss_dice: 1.3521  decode.d1.loss_cls: 1.0462  decode.d1.loss_mask: 0.7353  decode.d1.loss_dice: 1.2791  decode.d2.loss_cls: 1.0423  decode.d2.loss_mask: 0.7673  decode.d2.loss_dice: 1.2537  decode.d3.loss_cls: 0.8851  decode.d3.loss_mask: 0.7678  decode.d3.loss_dice: 1.2242  decode.d4.loss_cls: 0.9502  decode.d4.loss_mask: 0.7477  decode.d4.loss_dice: 1.2099  decode.d5.loss_cls: 0.9144  decode.d5.loss_mask: 0.7679  decode.d5.loss_dice: 1.2175  decode.d6.loss_cls: 0.9013  decode.d6.loss_mask: 0.7458  decode.d6.loss_dice: 1.2143  decode.d7.loss_cls: 0.9366  decode.d7.loss_mask: 0.7520  decode.d7.loss_dice: 1.2169  decode.d8.loss_cls: 0.9086  decode.d8.loss_mask: 0.7515  decode.d8.loss_dice: 1.2155
2023/05/24 04:07:23 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 04:07:23 - mmengine - INFO - Iter(train) [ 80000/160000]  lr: 5.3589e-06  eta: 9:33:04  time: 0.4211  data_time: 0.0106  memory: 4894  grad_norm: 91.3434  loss: 35.4837  decode.loss_cls: 1.2830  decode.loss_mask: 0.8732  decode.loss_dice: 1.1161  decode.d0.loss_cls: 3.3171  decode.d0.loss_mask: 0.9232  decode.d0.loss_dice: 1.3304  decode.d1.loss_cls: 1.4937  decode.d1.loss_mask: 0.8919  decode.d1.loss_dice: 1.2407  decode.d2.loss_cls: 1.3243  decode.d2.loss_mask: 0.8737  decode.d2.loss_dice: 1.1900  decode.d3.loss_cls: 1.3132  decode.d3.loss_mask: 0.8638  decode.d3.loss_dice: 1.1636  decode.d4.loss_cls: 1.2555  decode.d4.loss_mask: 0.8786  decode.d4.loss_dice: 1.1809  decode.d5.loss_cls: 1.2381  decode.d5.loss_mask: 0.8825  decode.d5.loss_dice: 1.1587  decode.d6.loss_cls: 1.2633  decode.d6.loss_mask: 0.8305  decode.d6.loss_dice: 1.1405  decode.d7.loss_cls: 1.2179  decode.d7.loss_mask: 0.8483  decode.d7.loss_dice: 1.1475  decode.d8.loss_cls: 1.2686  decode.d8.loss_mask: 0.8499  decode.d8.loss_dice: 1.1250
2023/05/24 04:07:24 - mmengine - INFO - Saving checkpoint at 80000 iterations
2023/05/24 04:07:34 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0783  data_time: 0.0019  memory: 2167  
2023/05/24 04:07:40 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:53  time: 0.2823  data_time: 0.0021  memory: 2216  
2023/05/24 04:07:44 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:46  time: 0.0801  data_time: 0.0017  memory: 2167  
2023/05/24 04:07:48 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:39  time: 0.0793  data_time: 0.0018  memory: 2104  
2023/05/24 04:07:52 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:34  time: 0.0789  data_time: 0.0018  memory: 2831  
2023/05/24 04:07:56 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:28  time: 0.0856  data_time: 0.0018  memory: 2167  
2023/05/24 04:08:01 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0792  data_time: 0.0019  memory: 2167  
2023/05/24 04:08:05 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0794  data_time: 0.0019  memory: 2167  
2023/05/24 04:08:09 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0784  data_time: 0.0018  memory: 2944  
2023/05/24 04:08:13 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0804  data_time: 0.0018  memory: 2356  
2023/05/24 04:08:17 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0811  data_time: 0.0018  memory: 2217  
2023/05/24 04:08:21 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0781  data_time: 0.0017  memory: 2328  
2023/05/24 04:08:25 - mmengine - INFO - per class results:
2023/05/24 04:08:25 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.74 | 93.66 |
|     bicycle      | 67.52 | 83.91 |
|       car        | 59.35 | 81.52 |
|    motorcycle    | 82.43 | 89.47 |
|     airplane     | 82.32 | 88.24 |
|       bus        | 83.22 | 87.69 |
|      train       | 85.18 |  91.7 |
|      truck       | 55.13 | 76.93 |
|       boat       | 59.52 | 79.07 |
|  traffic light   | 67.77 | 83.72 |
|   fire hydrant   | 87.15 |  95.3 |
|    stop sign     | 91.92 | 96.55 |
|  parking meter   | 71.81 | 80.45 |
|      bench       | 50.22 | 69.86 |
|       bird       | 80.14 | 91.16 |
|       cat        |  85.6 | 93.59 |
|       dog        | 80.94 | 89.23 |
|      horse       | 80.33 | 89.38 |
|      sheep       | 86.82 | 95.73 |
|       cow        |  82.5 | 87.68 |
|     elephant     | 89.06 | 95.27 |
|       bear       | 92.28 | 95.42 |
|      zebra       | 92.59 | 96.27 |
|     giraffe      |  87.3 | 93.65 |
|     backpack     | 35.54 | 52.77 |
|     umbrella     | 81.27 | 87.44 |
|     handbag      | 33.09 | 57.39 |
|       tie        |  9.59 | 13.17 |
|     suitcase     | 76.75 |  87.5 |
|     frisbee      | 72.11 | 90.52 |
|       skis       | 43.36 | 62.36 |
|    snowboard     | 53.24 | 73.03 |
|   sports ball    | 56.13 | 75.46 |
|       kite       | 50.82 | 60.83 |
|   baseball bat   | 42.95 | 53.28 |
|  baseball glove  | 70.39 | 87.25 |
|    skateboard    | 76.09 | 89.48 |
|    surfboard     | 73.16 | 88.15 |
|  tennis racket   |  82.2 | 92.69 |
|      bottle      | 44.16 | 60.49 |
|    wine glass    | 54.22 | 70.52 |
|       cup        | 56.36 | 74.38 |
|       fork       | 29.86 | 39.38 |
|      knife       | 26.69 | 34.04 |
|      spoon       | 34.77 |  54.1 |
|       bowl       | 44.14 | 70.96 |
|      banana      | 67.74 | 86.92 |
|      apple       | 54.41 | 67.33 |
|     sandwich     | 35.72 | 43.24 |
|      orange      | 56.07 | 62.82 |
|     broccoli     | 46.94 | 54.75 |
|      carrot      | 44.87 | 47.99 |
|     hot dog      | 43.94 | 54.02 |
|      pizza       | 62.94 | 73.81 |
|      donut       | 67.05 | 83.51 |
|       cake       |  57.0 | 65.34 |
|      chair       |  44.3 | 63.08 |
|      couch       | 53.83 | 78.45 |
|   potted plant   |  31.6 | 49.02 |
|       bed        | 61.97 | 78.92 |
|   dining table   |  42.8 | 81.54 |
|      toilet      | 80.08 | 92.86 |
|        tv        | 75.34 | 85.51 |
|      laptop      | 72.26 | 85.97 |
|      mouse       |  72.3 | 85.09 |
|      remote      | 54.09 | 73.33 |
|     keyboard     | 63.97 | 73.64 |
|    cell phone    |  68.3 | 86.96 |
|    microwave     | 65.27 | 74.86 |
|       oven       | 55.29 |  82.4 |
|     toaster      | 39.83 | 50.24 |
|       sink       | 55.64 | 80.11 |
|   refrigerator   | 76.49 | 91.66 |
|       book       | 47.76 | 70.51 |
|      clock       | 72.38 | 82.63 |
|       vase       | 55.58 | 84.84 |
|     scissors     | 73.61 | 85.49 |
|    teddy bear    | 72.48 | 84.73 |
|    hair drier    | 39.82 | 42.74 |
|    toothbrush    | 31.33 | 76.45 |
|      banner      | 33.26 | 69.11 |
|     blanket      |  3.65 |  4.2  |
|      branch      | 17.35 | 23.94 |
|      bridge      | 34.08 | 42.36 |
|  building-other  | 53.15 | 71.03 |
|       bush       | 31.59 | 43.52 |
|     cabinet      | 48.62 | 67.52 |
|       cage       | 15.11 | 18.03 |
|    cardboard     | 44.47 | 50.07 |
|      carpet      | 53.44 | 69.44 |
|  ceiling-other   | 63.27 | 77.49 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      |  19.5 | 26.74 |
|      clouds      | 48.77 | 65.39 |
|     counter      | 28.37 | 42.39 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 59.17 | 82.15 |
|    desk-stuff    | 41.19 | 56.64 |
|       dirt       | 35.86 | 53.81 |
|    door-stuff    | 37.28 | 63.11 |
|      fence       | 34.79 | 64.07 |
|   floor-marble   |  1.67 |  1.87 |
|   floor-other    | 22.51 | 31.93 |
|   floor-stone    |  1.57 |  1.76 |
|    floor-tile    | 62.52 |  70.8 |
|    floor-wood    | 62.53 | 74.93 |
|      flower      | 45.79 | 63.75 |
|       fog        |  5.14 |  5.25 |
|    food-other    | 16.19 |  18.1 |
|      fruit       | 38.44 | 57.36 |
| furniture-other  | 16.54 | 22.27 |
|      grass       | 70.48 | 84.36 |
|      gravel      | 29.73 | 50.04 |
|   ground-other   |  3.98 |  4.23 |
|       hill       | 14.79 | 18.02 |
|      house       | 28.39 | 37.14 |
|      leaves      | 25.02 | 35.23 |
|      light       | 36.24 | 51.93 |
|       mat        |  0.0  |  0.0  |
|      metal       | 32.23 | 47.83 |
|   mirror-stuff   | 47.74 | 68.75 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 55.06 | 74.77 |
|       mud        |  4.43 |  7.74 |
|      napkin      | 11.77 | 11.91 |
|       net        | 43.27 | 64.68 |
|      paper       |  30.4 | 43.27 |
|     pavement     | 50.97 | 72.81 |
|      pillow      | 12.15 | 17.79 |
|   plant-other    | 19.43 | 28.42 |
|     plastic      | 21.37 | 31.71 |
|     platform     | 24.76 | 32.21 |
|   playingfield   | 66.98 | 83.41 |
|     railing      |  4.69 |  6.25 |
|     railroad     | 58.97 | 72.33 |
|      river       | 24.87 |  29.3 |
|       road       | 64.25 | 80.04 |
|       rock       | 44.83 | 75.39 |
|       roof       | 16.78 | 20.78 |
|       rug        | 33.47 | 50.15 |
|      salad       |  0.0  |  0.0  |
|       sand       | 58.24 | 74.29 |
|       sea        | 83.46 | 92.38 |
|      shelf       | 34.26 | 48.12 |
|    sky-other     | 70.74 | 86.53 |
|    skyscraper    | 38.32 | 48.37 |
|       snow       | 89.49 | 92.35 |
|   solid-other    |  0.26 |  0.26 |
|      stairs      | 22.43 | 38.99 |
|      stone       | 13.06 | 18.96 |
|      straw       | 24.84 | 30.02 |
| structural-other |  0.0  |  0.0  |
|      table       | 16.73 | 21.37 |
|       tent       |  8.42 | 11.67 |
|  textile-other   |  7.72 | 10.84 |
|      towel       | 32.93 | 42.73 |
|       tree       | 72.46 | 87.45 |
|    vegetable     | 34.62 | 44.23 |
|    wall-brick    | 46.06 | 64.28 |
|  wall-concrete   | 59.34 | 81.37 |
|    wall-other    | 17.05 | 24.75 |
|    wall-panel    |  2.96 |  3.39 |
|    wall-stone    | 30.77 | 36.72 |
|    wall-tile     | 65.21 |  82.8 |
|    wall-wood     | 39.26 | 58.22 |
|   water-other    | 25.45 | 48.32 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 48.78 | 54.98 |
|   window-other   | 45.85 | 74.45 |
|       wood       | 24.75 | 38.87 |
+------------------+-------+-------+
2023/05/24 04:08:25 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.7500  mIoU: 45.8700  mAcc: 58.1100  data_time: 0.0021  time: 0.0858
2023/05/24 04:08:25 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_70000.pth is removed
2023/05/24 04:08:29 - mmengine - INFO - The best checkpoint with 45.8700 mIoU at 80000 iter is saved to best_mIoU_iter_80000.pth.
2023/05/24 04:08:50 - mmengine - INFO - Iter(train) [ 80050/160000]  lr: 5.3559e-06  eta: 9:32:47  time: 0.4241  data_time: 0.0103  memory: 4858  grad_norm: 96.2935  loss: 32.8427  decode.loss_cls: 1.1826  decode.loss_mask: 0.6803  decode.loss_dice: 1.1858  decode.d0.loss_cls: 2.6790  decode.d0.loss_mask: 0.7788  decode.d0.loss_dice: 1.4047  decode.d1.loss_cls: 1.3179  decode.d1.loss_mask: 0.6927  decode.d1.loss_dice: 1.2962  decode.d2.loss_cls: 1.3436  decode.d2.loss_mask: 0.6834  decode.d2.loss_dice: 1.2215  decode.d3.loss_cls: 1.3073  decode.d3.loss_mask: 0.6667  decode.d3.loss_dice: 1.1935  decode.d4.loss_cls: 1.1525  decode.d4.loss_mask: 0.6722  decode.d4.loss_dice: 1.2122  decode.d5.loss_cls: 1.2182  decode.d5.loss_mask: 0.6654  decode.d5.loss_dice: 1.1924  decode.d6.loss_cls: 1.1694  decode.d6.loss_mask: 0.6682  decode.d6.loss_dice: 1.1804  decode.d7.loss_cls: 1.1409  decode.d7.loss_mask: 0.6738  decode.d7.loss_dice: 1.2289  decode.d8.loss_cls: 1.1310  decode.d8.loss_mask: 0.6617  decode.d8.loss_dice: 1.2416
2023/05/24 04:09:11 - mmengine - INFO - Iter(train) [ 80100/160000]  lr: 5.3529e-06  eta: 9:32:26  time: 0.4218  data_time: 0.0103  memory: 4886  grad_norm: 87.4190  loss: 28.3733  decode.loss_cls: 0.9551  decode.loss_mask: 0.6842  decode.loss_dice: 0.9094  decode.d0.loss_cls: 2.8470  decode.d0.loss_mask: 0.6968  decode.d0.loss_dice: 1.0584  decode.d1.loss_cls: 1.1586  decode.d1.loss_mask: 0.7212  decode.d1.loss_dice: 1.0337  decode.d2.loss_cls: 1.0791  decode.d2.loss_mask: 0.7022  decode.d2.loss_dice: 0.9673  decode.d3.loss_cls: 1.0307  decode.d3.loss_mask: 0.6907  decode.d3.loss_dice: 0.9545  decode.d4.loss_cls: 0.9473  decode.d4.loss_mask: 0.7183  decode.d4.loss_dice: 0.9601  decode.d5.loss_cls: 1.0030  decode.d5.loss_mask: 0.6954  decode.d5.loss_dice: 0.9265  decode.d6.loss_cls: 0.9498  decode.d6.loss_mask: 0.6983  decode.d6.loss_dice: 0.9152  decode.d7.loss_cls: 0.9804  decode.d7.loss_mask: 0.6593  decode.d7.loss_dice: 0.8950  decode.d8.loss_cls: 0.9486  decode.d8.loss_mask: 0.6789  decode.d8.loss_dice: 0.9084
2023/05/24 04:09:32 - mmengine - INFO - Iter(train) [ 80150/160000]  lr: 5.3499e-06  eta: 9:32:04  time: 0.4236  data_time: 0.0105  memory: 4836  grad_norm: 83.7163  loss: 36.0491  decode.loss_cls: 1.3368  decode.loss_mask: 0.6958  decode.loss_dice: 1.2678  decode.d0.loss_cls: 3.2490  decode.d0.loss_mask: 0.8086  decode.d0.loss_dice: 1.6150  decode.d1.loss_cls: 1.4647  decode.d1.loss_mask: 0.7636  decode.d1.loss_dice: 1.4692  decode.d2.loss_cls: 1.3365  decode.d2.loss_mask: 0.7439  decode.d2.loss_dice: 1.3970  decode.d3.loss_cls: 1.3463  decode.d3.loss_mask: 0.7182  decode.d3.loss_dice: 1.3111  decode.d4.loss_cls: 1.3110  decode.d4.loss_mask: 0.7049  decode.d4.loss_dice: 1.3070  decode.d5.loss_cls: 1.3189  decode.d5.loss_mask: 0.7111  decode.d5.loss_dice: 1.3194  decode.d6.loss_cls: 1.3401  decode.d6.loss_mask: 0.7112  decode.d6.loss_dice: 1.2696  decode.d7.loss_cls: 1.2961  decode.d7.loss_mask: 0.7204  decode.d7.loss_dice: 1.2972  decode.d8.loss_cls: 1.2344  decode.d8.loss_mask: 0.6989  decode.d8.loss_dice: 1.2853
2023/05/24 04:09:53 - mmengine - INFO - Iter(train) [ 80200/160000]  lr: 5.3468e-06  eta: 9:31:42  time: 0.4181  data_time: 0.0104  memory: 4847  grad_norm: 151.0484  loss: 30.7403  decode.loss_cls: 0.9350  decode.loss_mask: 0.7546  decode.loss_dice: 1.0814  decode.d0.loss_cls: 2.9923  decode.d0.loss_mask: 0.7653  decode.d0.loss_dice: 1.2806  decode.d1.loss_cls: 1.0925  decode.d1.loss_mask: 0.7924  decode.d1.loss_dice: 1.1602  decode.d2.loss_cls: 1.0112  decode.d2.loss_mask: 0.7816  decode.d2.loss_dice: 1.1351  decode.d3.loss_cls: 1.0254  decode.d3.loss_mask: 0.7443  decode.d3.loss_dice: 1.0905  decode.d4.loss_cls: 1.0044  decode.d4.loss_mask: 0.7515  decode.d4.loss_dice: 1.0776  decode.d5.loss_cls: 0.9950  decode.d5.loss_mask: 0.7495  decode.d5.loss_dice: 1.0828  decode.d6.loss_cls: 0.9561  decode.d6.loss_mask: 0.7686  decode.d6.loss_dice: 1.0759  decode.d7.loss_cls: 0.9535  decode.d7.loss_mask: 0.7728  decode.d7.loss_dice: 1.0907  decode.d8.loss_cls: 0.9606  decode.d8.loss_mask: 0.7710  decode.d8.loss_dice: 1.0879
2023/05/24 04:10:17 - mmengine - INFO - Iter(train) [ 80250/160000]  lr: 5.3438e-06  eta: 9:31:22  time: 0.4608  data_time: 0.0106  memory: 4836  grad_norm: 113.6477  loss: 39.4287  decode.loss_cls: 1.4196  decode.loss_mask: 0.7785  decode.loss_dice: 1.4392  decode.d0.loss_cls: 3.3058  decode.d0.loss_mask: 0.8413  decode.d0.loss_dice: 1.7116  decode.d1.loss_cls: 1.5044  decode.d1.loss_mask: 0.8175  decode.d1.loss_dice: 1.6338  decode.d2.loss_cls: 1.4969  decode.d2.loss_mask: 0.7979  decode.d2.loss_dice: 1.5293  decode.d3.loss_cls: 1.4555  decode.d3.loss_mask: 0.7829  decode.d3.loss_dice: 1.4789  decode.d4.loss_cls: 1.4415  decode.d4.loss_mask: 0.7984  decode.d4.loss_dice: 1.4617  decode.d5.loss_cls: 1.4477  decode.d5.loss_mask: 0.8117  decode.d5.loss_dice: 1.4671  decode.d6.loss_cls: 1.3923  decode.d6.loss_mask: 0.8105  decode.d6.loss_dice: 1.4698  decode.d7.loss_cls: 1.4437  decode.d7.loss_mask: 0.8030  decode.d7.loss_dice: 1.4220  decode.d8.loss_cls: 1.4218  decode.d8.loss_mask: 0.8044  decode.d8.loss_dice: 1.4400
2023/05/24 04:10:39 - mmengine - INFO - Iter(train) [ 80300/160000]  lr: 5.3408e-06  eta: 9:31:01  time: 0.4746  data_time: 0.0100  memory: 4861  grad_norm: 114.3130  loss: 30.0476  decode.loss_cls: 1.1183  decode.loss_mask: 0.7135  decode.loss_dice: 0.8689  decode.d0.loss_cls: 3.0136  decode.d0.loss_mask: 0.7747  decode.d0.loss_dice: 1.1152  decode.d1.loss_cls: 1.2697  decode.d1.loss_mask: 0.7891  decode.d1.loss_dice: 0.9955  decode.d2.loss_cls: 1.2423  decode.d2.loss_mask: 0.7493  decode.d2.loss_dice: 0.9421  decode.d3.loss_cls: 1.1821  decode.d3.loss_mask: 0.7011  decode.d3.loss_dice: 0.9096  decode.d4.loss_cls: 1.1711  decode.d4.loss_mask: 0.6969  decode.d4.loss_dice: 0.8971  decode.d5.loss_cls: 1.1348  decode.d5.loss_mask: 0.6913  decode.d5.loss_dice: 0.8798  decode.d6.loss_cls: 1.1707  decode.d6.loss_mask: 0.7021  decode.d6.loss_dice: 0.8783  decode.d7.loss_cls: 1.1425  decode.d7.loss_mask: 0.7108  decode.d7.loss_dice: 0.8784  decode.d8.loss_cls: 1.1231  decode.d8.loss_mask: 0.7162  decode.d8.loss_dice: 0.8692
2023/05/24 04:11:01 - mmengine - INFO - Iter(train) [ 80350/160000]  lr: 5.3378e-06  eta: 9:30:40  time: 0.4343  data_time: 0.0107  memory: 4837  grad_norm: 100.8762  loss: 32.8121  decode.loss_cls: 1.2250  decode.loss_mask: 0.5774  decode.loss_dice: 1.1529  decode.d0.loss_cls: 3.1624  decode.d0.loss_mask: 0.6324  decode.d0.loss_dice: 1.4020  decode.d1.loss_cls: 1.2995  decode.d1.loss_mask: 0.6755  decode.d1.loss_dice: 1.2924  decode.d2.loss_cls: 1.2966  decode.d2.loss_mask: 0.6267  decode.d2.loss_dice: 1.3094  decode.d3.loss_cls: 1.2582  decode.d3.loss_mask: 0.5900  decode.d3.loss_dice: 1.2059  decode.d4.loss_cls: 1.2661  decode.d4.loss_mask: 0.5873  decode.d4.loss_dice: 1.1938  decode.d5.loss_cls: 1.3024  decode.d5.loss_mask: 0.5564  decode.d5.loss_dice: 1.1737  decode.d6.loss_cls: 1.2770  decode.d6.loss_mask: 0.5724  decode.d6.loss_dice: 1.1572  decode.d7.loss_cls: 1.2462  decode.d7.loss_mask: 0.5776  decode.d7.loss_dice: 1.1862  decode.d8.loss_cls: 1.2758  decode.d8.loss_mask: 0.5755  decode.d8.loss_dice: 1.1583
2023/05/24 04:11:22 - mmengine - INFO - Iter(train) [ 80400/160000]  lr: 5.3348e-06  eta: 9:30:18  time: 0.4241  data_time: 0.0103  memory: 4824  grad_norm: 93.7340  loss: 43.3596  decode.loss_cls: 1.5013  decode.loss_mask: 0.8341  decode.loss_dice: 1.6553  decode.d0.loss_cls: 3.4754  decode.d0.loss_mask: 0.9248  decode.d0.loss_dice: 1.9062  decode.d1.loss_cls: 1.6524  decode.d1.loss_mask: 0.9047  decode.d1.loss_dice: 1.8381  decode.d2.loss_cls: 1.5115  decode.d2.loss_mask: 0.8720  decode.d2.loss_dice: 1.7459  decode.d3.loss_cls: 1.5413  decode.d3.loss_mask: 0.8748  decode.d3.loss_dice: 1.7286  decode.d4.loss_cls: 1.5615  decode.d4.loss_mask: 0.8751  decode.d4.loss_dice: 1.7112  decode.d5.loss_cls: 1.5568  decode.d5.loss_mask: 0.8407  decode.d5.loss_dice: 1.6761  decode.d6.loss_cls: 1.5539  decode.d6.loss_mask: 0.8419  decode.d6.loss_dice: 1.6578  decode.d7.loss_cls: 1.5450  decode.d7.loss_mask: 0.8504  decode.d7.loss_dice: 1.6920  decode.d8.loss_cls: 1.5118  decode.d8.loss_mask: 0.8422  decode.d8.loss_dice: 1.6768
2023/05/24 04:11:43 - mmengine - INFO - Iter(train) [ 80450/160000]  lr: 5.3318e-06  eta: 9:29:56  time: 0.4108  data_time: 0.0102  memory: 4867  grad_norm: 116.4958  loss: 39.7884  decode.loss_cls: 1.4091  decode.loss_mask: 0.8256  decode.loss_dice: 1.4364  decode.d0.loss_cls: 3.5397  decode.d0.loss_mask: 0.9401  decode.d0.loss_dice: 1.7112  decode.d1.loss_cls: 1.5184  decode.d1.loss_mask: 0.8928  decode.d1.loss_dice: 1.5992  decode.d2.loss_cls: 1.4327  decode.d2.loss_mask: 0.8531  decode.d2.loss_dice: 1.5056  decode.d3.loss_cls: 1.3831  decode.d3.loss_mask: 0.8583  decode.d3.loss_dice: 1.5174  decode.d4.loss_cls: 1.3604  decode.d4.loss_mask: 0.8657  decode.d4.loss_dice: 1.4823  decode.d5.loss_cls: 1.3975  decode.d5.loss_mask: 0.8481  decode.d5.loss_dice: 1.4833  decode.d6.loss_cls: 1.3414  decode.d6.loss_mask: 0.8458  decode.d6.loss_dice: 1.4529  decode.d7.loss_cls: 1.3572  decode.d7.loss_mask: 0.8392  decode.d7.loss_dice: 1.4378  decode.d8.loss_cls: 1.3324  decode.d8.loss_mask: 0.8543  decode.d8.loss_dice: 1.4675
2023/05/24 04:12:04 - mmengine - INFO - Iter(train) [ 80500/160000]  lr: 5.3287e-06  eta: 9:29:34  time: 0.4173  data_time: 0.0106  memory: 4845  grad_norm: 101.8894  loss: 36.2558  decode.loss_cls: 1.1294  decode.loss_mask: 0.9406  decode.loss_dice: 1.2696  decode.d0.loss_cls: 3.0562  decode.d0.loss_mask: 1.0518  decode.d0.loss_dice: 1.4673  decode.d1.loss_cls: 1.1999  decode.d1.loss_mask: 0.9894  decode.d1.loss_dice: 1.3895  decode.d2.loss_cls: 1.1805  decode.d2.loss_mask: 0.9685  decode.d2.loss_dice: 1.3409  decode.d3.loss_cls: 1.1733  decode.d3.loss_mask: 0.9503  decode.d3.loss_dice: 1.3067  decode.d4.loss_cls: 1.1436  decode.d4.loss_mask: 0.9358  decode.d4.loss_dice: 1.2988  decode.d5.loss_cls: 1.1465  decode.d5.loss_mask: 0.9441  decode.d5.loss_dice: 1.3025  decode.d6.loss_cls: 1.1053  decode.d6.loss_mask: 0.9711  decode.d6.loss_dice: 1.2894  decode.d7.loss_cls: 1.1079  decode.d7.loss_mask: 0.9707  decode.d7.loss_dice: 1.2955  decode.d8.loss_cls: 1.1082  decode.d8.loss_mask: 0.9450  decode.d8.loss_dice: 1.2772
2023/05/24 04:12:25 - mmengine - INFO - Iter(train) [ 80550/160000]  lr: 5.3257e-06  eta: 9:29:13  time: 0.4148  data_time: 0.0104  memory: 4830  grad_norm: 110.9986  loss: 34.8725  decode.loss_cls: 1.1201  decode.loss_mask: 0.7002  decode.loss_dice: 1.3330  decode.d0.loss_cls: 3.1687  decode.d0.loss_mask: 0.7370  decode.d0.loss_dice: 1.5699  decode.d1.loss_cls: 1.2344  decode.d1.loss_mask: 0.7430  decode.d1.loss_dice: 1.4852  decode.d2.loss_cls: 1.2071  decode.d2.loss_mask: 0.7399  decode.d2.loss_dice: 1.4337  decode.d3.loss_cls: 1.2202  decode.d3.loss_mask: 0.7258  decode.d3.loss_dice: 1.3963  decode.d4.loss_cls: 1.1642  decode.d4.loss_mask: 0.7339  decode.d4.loss_dice: 1.3832  decode.d5.loss_cls: 1.1157  decode.d5.loss_mask: 0.7468  decode.d5.loss_dice: 1.4054  decode.d6.loss_cls: 1.1279  decode.d6.loss_mask: 0.7375  decode.d6.loss_dice: 1.3120  decode.d7.loss_cls: 1.0999  decode.d7.loss_mask: 0.7353  decode.d7.loss_dice: 1.3435  decode.d8.loss_cls: 1.1061  decode.d8.loss_mask: 0.7282  decode.d8.loss_dice: 1.3185
2023/05/24 04:12:48 - mmengine - INFO - Iter(train) [ 80600/160000]  lr: 5.3227e-06  eta: 9:28:53  time: 0.4732  data_time: 0.0105  memory: 4876  grad_norm: 180.5529  loss: 30.6763  decode.loss_cls: 1.1581  decode.loss_mask: 0.6378  decode.loss_dice: 1.0240  decode.d0.loss_cls: 2.9876  decode.d0.loss_mask: 0.6637  decode.d0.loss_dice: 1.1906  decode.d1.loss_cls: 1.1949  decode.d1.loss_mask: 0.6589  decode.d1.loss_dice: 1.1025  decode.d2.loss_cls: 1.1653  decode.d2.loss_mask: 0.6556  decode.d2.loss_dice: 1.1004  decode.d3.loss_cls: 1.2561  decode.d3.loss_mask: 0.6494  decode.d3.loss_dice: 1.0280  decode.d4.loss_cls: 1.1594  decode.d4.loss_mask: 0.6726  decode.d4.loss_dice: 1.0392  decode.d5.loss_cls: 1.1362  decode.d5.loss_mask: 0.6832  decode.d5.loss_dice: 1.0562  decode.d6.loss_cls: 1.1169  decode.d6.loss_mask: 0.6774  decode.d6.loss_dice: 1.0333  decode.d7.loss_cls: 1.1321  decode.d7.loss_mask: 0.6596  decode.d7.loss_dice: 1.0345  decode.d8.loss_cls: 1.0948  decode.d8.loss_mask: 0.6647  decode.d8.loss_dice: 1.0434
2023/05/24 04:13:12 - mmengine - INFO - Iter(train) [ 80650/160000]  lr: 5.3197e-06  eta: 9:28:33  time: 0.4677  data_time: 0.0101  memory: 4875  grad_norm: 109.1818  loss: 39.5172  decode.loss_cls: 1.3303  decode.loss_mask: 0.8372  decode.loss_dice: 1.4050  decode.d0.loss_cls: 3.7353  decode.d0.loss_mask: 0.9464  decode.d0.loss_dice: 1.7272  decode.d1.loss_cls: 1.4447  decode.d1.loss_mask: 0.9379  decode.d1.loss_dice: 1.6323  decode.d2.loss_cls: 1.3958  decode.d2.loss_mask: 0.8742  decode.d2.loss_dice: 1.4698  decode.d3.loss_cls: 1.3581  decode.d3.loss_mask: 0.8745  decode.d3.loss_dice: 1.4728  decode.d4.loss_cls: 1.3679  decode.d4.loss_mask: 0.8841  decode.d4.loss_dice: 1.4464  decode.d5.loss_cls: 1.3142  decode.d5.loss_mask: 0.8711  decode.d5.loss_dice: 1.4293  decode.d6.loss_cls: 1.3157  decode.d6.loss_mask: 0.8539  decode.d6.loss_dice: 1.4309  decode.d7.loss_cls: 1.3100  decode.d7.loss_mask: 0.8547  decode.d7.loss_dice: 1.4362  decode.d8.loss_cls: 1.3028  decode.d8.loss_mask: 0.8494  decode.d8.loss_dice: 1.4090
2023/05/24 04:13:35 - mmengine - INFO - Iter(train) [ 80700/160000]  lr: 5.3167e-06  eta: 9:28:13  time: 0.4405  data_time: 0.0102  memory: 4842  grad_norm: 85.5239  loss: 36.1225  decode.loss_cls: 1.2959  decode.loss_mask: 0.7960  decode.loss_dice: 1.3031  decode.d0.loss_cls: 2.9846  decode.d0.loss_mask: 0.8435  decode.d0.loss_dice: 1.4596  decode.d1.loss_cls: 1.4015  decode.d1.loss_mask: 0.8198  decode.d1.loss_dice: 1.4449  decode.d2.loss_cls: 1.3689  decode.d2.loss_mask: 0.8254  decode.d2.loss_dice: 1.3677  decode.d3.loss_cls: 1.3798  decode.d3.loss_mask: 0.7727  decode.d3.loss_dice: 1.2972  decode.d4.loss_cls: 1.2750  decode.d4.loss_mask: 0.7870  decode.d4.loss_dice: 1.3196  decode.d5.loss_cls: 1.2421  decode.d5.loss_mask: 0.7838  decode.d5.loss_dice: 1.2881  decode.d6.loss_cls: 1.2681  decode.d6.loss_mask: 0.7964  decode.d6.loss_dice: 1.2992  decode.d7.loss_cls: 1.3055  decode.d7.loss_mask: 0.7839  decode.d7.loss_dice: 1.2745  decode.d8.loss_cls: 1.2521  decode.d8.loss_mask: 0.7889  decode.d8.loss_dice: 1.2976
2023/05/24 04:13:58 - mmengine - INFO - Iter(train) [ 80750/160000]  lr: 5.3137e-06  eta: 9:27:54  time: 0.4726  data_time: 0.0102  memory: 4792  grad_norm: 102.7942  loss: 25.5706  decode.loss_cls: 0.8410  decode.loss_mask: 0.5760  decode.loss_dice: 0.8628  decode.d0.loss_cls: 2.6223  decode.d0.loss_mask: 0.5863  decode.d0.loss_dice: 1.0009  decode.d1.loss_cls: 1.0095  decode.d1.loss_mask: 0.6319  decode.d1.loss_dice: 0.9579  decode.d2.loss_cls: 0.9713  decode.d2.loss_mask: 0.6015  decode.d2.loss_dice: 0.9288  decode.d3.loss_cls: 0.8709  decode.d3.loss_mask: 0.5992  decode.d3.loss_dice: 0.9146  decode.d4.loss_cls: 0.8666  decode.d4.loss_mask: 0.5977  decode.d4.loss_dice: 0.9113  decode.d5.loss_cls: 0.8570  decode.d5.loss_mask: 0.5869  decode.d5.loss_dice: 0.8601  decode.d6.loss_cls: 0.8364  decode.d6.loss_mask: 0.5791  decode.d6.loss_dice: 0.8973  decode.d7.loss_cls: 0.8653  decode.d7.loss_mask: 0.5786  decode.d7.loss_dice: 0.8727  decode.d8.loss_cls: 0.8644  decode.d8.loss_mask: 0.5739  decode.d8.loss_dice: 0.8484
2023/05/24 04:14:20 - mmengine - INFO - Iter(train) [ 80800/160000]  lr: 5.3106e-06  eta: 9:27:32  time: 0.4158  data_time: 0.0108  memory: 4823  grad_norm: 96.9930  loss: 36.3946  decode.loss_cls: 1.1266  decode.loss_mask: 0.9009  decode.loss_dice: 1.3620  decode.d0.loss_cls: 3.0715  decode.d0.loss_mask: 0.8992  decode.d0.loss_dice: 1.6032  decode.d1.loss_cls: 1.2624  decode.d1.loss_mask: 0.8645  decode.d1.loss_dice: 1.4852  decode.d2.loss_cls: 1.2161  decode.d2.loss_mask: 0.9031  decode.d2.loss_dice: 1.4154  decode.d3.loss_cls: 1.1040  decode.d3.loss_mask: 0.9040  decode.d3.loss_dice: 1.3645  decode.d4.loss_cls: 1.1261  decode.d4.loss_mask: 0.9119  decode.d4.loss_dice: 1.3805  decode.d5.loss_cls: 1.1227  decode.d5.loss_mask: 0.8821  decode.d5.loss_dice: 1.3769  decode.d6.loss_cls: 1.1037  decode.d6.loss_mask: 0.8752  decode.d6.loss_dice: 1.3676  decode.d7.loss_cls: 1.1330  decode.d7.loss_mask: 0.8885  decode.d7.loss_dice: 1.3630  decode.d8.loss_cls: 1.1078  decode.d8.loss_mask: 0.9087  decode.d8.loss_dice: 1.3643
2023/05/24 04:14:41 - mmengine - INFO - Iter(train) [ 80850/160000]  lr: 5.3076e-06  eta: 9:27:10  time: 0.4176  data_time: 0.0102  memory: 4829  grad_norm: 89.5489  loss: 31.7065  decode.loss_cls: 1.0545  decode.loss_mask: 0.7453  decode.loss_dice: 1.1179  decode.d0.loss_cls: 2.8602  decode.d0.loss_mask: 0.8266  decode.d0.loss_dice: 1.4041  decode.d1.loss_cls: 1.0366  decode.d1.loss_mask: 0.7971  decode.d1.loss_dice: 1.2938  decode.d2.loss_cls: 1.0049  decode.d2.loss_mask: 0.7588  decode.d2.loss_dice: 1.2065  decode.d3.loss_cls: 1.0394  decode.d3.loss_mask: 0.7679  decode.d3.loss_dice: 1.1411  decode.d4.loss_cls: 1.0167  decode.d4.loss_mask: 0.7658  decode.d4.loss_dice: 1.1626  decode.d5.loss_cls: 1.0313  decode.d5.loss_mask: 0.7602  decode.d5.loss_dice: 1.1882  decode.d6.loss_cls: 1.0040  decode.d6.loss_mask: 0.7655  decode.d6.loss_dice: 1.1516  decode.d7.loss_cls: 0.9891  decode.d7.loss_mask: 0.7587  decode.d7.loss_dice: 1.1580  decode.d8.loss_cls: 1.0288  decode.d8.loss_mask: 0.7402  decode.d8.loss_dice: 1.1313
2023/05/24 04:15:02 - mmengine - INFO - Iter(train) [ 80900/160000]  lr: 5.3046e-06  eta: 9:26:48  time: 0.4282  data_time: 0.0107  memory: 4885  grad_norm: 94.2206  loss: 35.3603  decode.loss_cls: 1.1129  decode.loss_mask: 1.0173  decode.loss_dice: 1.1692  decode.d0.loss_cls: 2.8040  decode.d0.loss_mask: 0.9990  decode.d0.loss_dice: 1.3640  decode.d1.loss_cls: 1.1293  decode.d1.loss_mask: 1.0808  decode.d1.loss_dice: 1.2808  decode.d2.loss_cls: 1.1345  decode.d2.loss_mask: 1.0645  decode.d2.loss_dice: 1.2415  decode.d3.loss_cls: 1.1100  decode.d3.loss_mask: 1.0444  decode.d3.loss_dice: 1.2125  decode.d4.loss_cls: 1.1150  decode.d4.loss_mask: 1.0247  decode.d4.loss_dice: 1.2268  decode.d5.loss_cls: 1.1156  decode.d5.loss_mask: 1.0289  decode.d5.loss_dice: 1.1917  decode.d6.loss_cls: 1.0909  decode.d6.loss_mask: 1.0082  decode.d6.loss_dice: 1.1718  decode.d7.loss_cls: 1.1176  decode.d7.loss_mask: 0.9996  decode.d7.loss_dice: 1.1722  decode.d8.loss_cls: 1.1225  decode.d8.loss_mask: 1.0314  decode.d8.loss_dice: 1.1787
2023/05/24 04:15:23 - mmengine - INFO - Iter(train) [ 80950/160000]  lr: 5.3016e-06  eta: 9:26:26  time: 0.4206  data_time: 0.0104  memory: 4790  grad_norm: 93.0145  loss: 41.7361  decode.loss_cls: 1.5630  decode.loss_mask: 1.0473  decode.loss_dice: 1.3740  decode.d0.loss_cls: 3.3424  decode.d0.loss_mask: 1.1456  decode.d0.loss_dice: 1.6407  decode.d1.loss_cls: 1.6096  decode.d1.loss_mask: 1.0874  decode.d1.loss_dice: 1.4907  decode.d2.loss_cls: 1.4402  decode.d2.loss_mask: 1.0507  decode.d2.loss_dice: 1.4732  decode.d3.loss_cls: 1.4535  decode.d3.loss_mask: 1.0863  decode.d3.loss_dice: 1.4459  decode.d4.loss_cls: 1.4294  decode.d4.loss_mask: 1.0678  decode.d4.loss_dice: 1.4080  decode.d5.loss_cls: 1.4268  decode.d5.loss_mask: 1.0545  decode.d5.loss_dice: 1.4206  decode.d6.loss_cls: 1.4528  decode.d6.loss_mask: 1.0479  decode.d6.loss_dice: 1.3825  decode.d7.loss_cls: 1.4396  decode.d7.loss_mask: 1.0560  decode.d7.loss_dice: 1.4152  decode.d8.loss_cls: 1.4702  decode.d8.loss_mask: 1.0295  decode.d8.loss_dice: 1.3847
2023/05/24 04:15:45 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 04:15:45 - mmengine - INFO - Iter(train) [ 81000/160000]  lr: 5.2986e-06  eta: 9:26:05  time: 0.4216  data_time: 0.0107  memory: 4885  grad_norm: 100.1269  loss: 35.3448  decode.loss_cls: 1.0031  decode.loss_mask: 0.8101  decode.loss_dice: 1.3504  decode.d0.loss_cls: 3.3768  decode.d0.loss_mask: 0.8210  decode.d0.loss_dice: 1.5568  decode.d1.loss_cls: 1.2048  decode.d1.loss_mask: 0.8481  decode.d1.loss_dice: 1.5047  decode.d2.loss_cls: 1.2333  decode.d2.loss_mask: 0.7914  decode.d2.loss_dice: 1.3874  decode.d3.loss_cls: 1.0651  decode.d3.loss_mask: 0.8631  decode.d3.loss_dice: 1.3634  decode.d4.loss_cls: 1.0510  decode.d4.loss_mask: 0.8462  decode.d4.loss_dice: 1.3689  decode.d5.loss_cls: 1.0920  decode.d5.loss_mask: 0.8116  decode.d5.loss_dice: 1.3317  decode.d6.loss_cls: 1.0803  decode.d6.loss_mask: 0.8124  decode.d6.loss_dice: 1.3307  decode.d7.loss_cls: 1.0830  decode.d7.loss_mask: 0.8063  decode.d7.loss_dice: 1.3462  decode.d8.loss_cls: 1.0545  decode.d8.loss_mask: 0.8060  decode.d8.loss_dice: 1.3445
2023/05/24 04:15:45 - mmengine - INFO - Saving checkpoint at 81000 iterations
2023/05/24 04:16:12 - mmengine - INFO - Iter(train) [ 81050/160000]  lr: 5.2956e-06  eta: 9:25:49  time: 0.4197  data_time: 0.0103  memory: 4844  grad_norm: 110.9887  loss: 40.1236  decode.loss_cls: 1.3009  decode.loss_mask: 0.8941  decode.loss_dice: 1.5603  decode.d0.loss_cls: 3.0827  decode.d0.loss_mask: 0.9383  decode.d0.loss_dice: 1.8126  decode.d1.loss_cls: 1.4422  decode.d1.loss_mask: 0.9205  decode.d1.loss_dice: 1.7262  decode.d2.loss_cls: 1.3547  decode.d2.loss_mask: 0.9024  decode.d2.loss_dice: 1.6146  decode.d3.loss_cls: 1.3413  decode.d3.loss_mask: 0.8838  decode.d3.loss_dice: 1.5436  decode.d4.loss_cls: 1.3163  decode.d4.loss_mask: 0.8692  decode.d4.loss_dice: 1.5541  decode.d5.loss_cls: 1.3383  decode.d5.loss_mask: 0.8672  decode.d5.loss_dice: 1.5607  decode.d6.loss_cls: 1.2979  decode.d6.loss_mask: 0.8947  decode.d6.loss_dice: 1.5557  decode.d7.loss_cls: 1.2951  decode.d7.loss_mask: 0.8991  decode.d7.loss_dice: 1.5883  decode.d8.loss_cls: 1.3129  decode.d8.loss_mask: 0.9061  decode.d8.loss_dice: 1.5498
2023/05/24 04:16:33 - mmengine - INFO - Iter(train) [ 81100/160000]  lr: 5.2925e-06  eta: 9:25:28  time: 0.4180  data_time: 0.0106  memory: 4869  grad_norm: 100.3962  loss: 50.7074  decode.loss_cls: 1.7022  decode.loss_mask: 0.9912  decode.loss_dice: 2.0036  decode.d0.loss_cls: 3.9437  decode.d0.loss_mask: 1.0960  decode.d0.loss_dice: 2.3890  decode.d1.loss_cls: 1.8557  decode.d1.loss_mask: 1.0456  decode.d1.loss_dice: 2.2529  decode.d2.loss_cls: 1.7613  decode.d2.loss_mask: 1.0361  decode.d2.loss_dice: 2.1226  decode.d3.loss_cls: 1.7702  decode.d3.loss_mask: 1.0119  decode.d3.loss_dice: 2.0117  decode.d4.loss_cls: 1.7260  decode.d4.loss_mask: 0.9945  decode.d4.loss_dice: 2.0138  decode.d5.loss_cls: 1.7578  decode.d5.loss_mask: 0.9613  decode.d5.loss_dice: 2.0081  decode.d6.loss_cls: 1.8372  decode.d6.loss_mask: 0.9619  decode.d6.loss_dice: 2.0038  decode.d7.loss_cls: 1.7074  decode.d7.loss_mask: 0.9943  decode.d7.loss_dice: 2.0202  decode.d8.loss_cls: 1.7146  decode.d8.loss_mask: 0.9888  decode.d8.loss_dice: 2.0240
2023/05/24 04:16:55 - mmengine - INFO - Iter(train) [ 81150/160000]  lr: 5.2895e-06  eta: 9:25:06  time: 0.4177  data_time: 0.0106  memory: 4875  grad_norm: 108.5194  loss: 35.5391  decode.loss_cls: 1.2714  decode.loss_mask: 0.8779  decode.loss_dice: 1.1598  decode.d0.loss_cls: 3.1417  decode.d0.loss_mask: 0.8930  decode.d0.loss_dice: 1.3350  decode.d1.loss_cls: 1.3643  decode.d1.loss_mask: 0.8962  decode.d1.loss_dice: 1.2502  decode.d2.loss_cls: 1.3309  decode.d2.loss_mask: 0.8992  decode.d2.loss_dice: 1.2566  decode.d3.loss_cls: 1.2449  decode.d3.loss_mask: 0.9074  decode.d3.loss_dice: 1.2110  decode.d4.loss_cls: 1.2961  decode.d4.loss_mask: 0.8829  decode.d4.loss_dice: 1.1785  decode.d5.loss_cls: 1.2221  decode.d5.loss_mask: 0.8539  decode.d5.loss_dice: 1.1716  decode.d6.loss_cls: 1.2864  decode.d6.loss_mask: 0.8864  decode.d6.loss_dice: 1.1804  decode.d7.loss_cls: 1.2217  decode.d7.loss_mask: 0.8829  decode.d7.loss_dice: 1.1863  decode.d8.loss_cls: 1.1908  decode.d8.loss_mask: 0.8948  decode.d8.loss_dice: 1.1649
2023/05/24 04:17:16 - mmengine - INFO - Iter(train) [ 81200/160000]  lr: 5.2865e-06  eta: 9:24:45  time: 0.4777  data_time: 0.0111  memory: 4885  grad_norm: 112.0149  loss: 32.3631  decode.loss_cls: 1.0939  decode.loss_mask: 0.7332  decode.loss_dice: 1.1364  decode.d0.loss_cls: 3.0520  decode.d0.loss_mask: 0.7749  decode.d0.loss_dice: 1.3209  decode.d1.loss_cls: 1.2402  decode.d1.loss_mask: 0.7129  decode.d1.loss_dice: 1.2201  decode.d2.loss_cls: 1.2280  decode.d2.loss_mask: 0.7529  decode.d2.loss_dice: 1.1723  decode.d3.loss_cls: 1.1121  decode.d3.loss_mask: 0.7008  decode.d3.loss_dice: 1.1818  decode.d4.loss_cls: 1.1785  decode.d4.loss_mask: 0.6952  decode.d4.loss_dice: 1.1458  decode.d5.loss_cls: 1.0909  decode.d5.loss_mask: 0.7028  decode.d5.loss_dice: 1.1789  decode.d6.loss_cls: 1.1172  decode.d6.loss_mask: 0.7145  decode.d6.loss_dice: 1.1401  decode.d7.loss_cls: 1.1027  decode.d7.loss_mask: 0.7333  decode.d7.loss_dice: 1.1509  decode.d8.loss_cls: 1.0893  decode.d8.loss_mask: 0.7438  decode.d8.loss_dice: 1.1466
2023/05/24 04:17:39 - mmengine - INFO - Iter(train) [ 81250/160000]  lr: 5.2835e-06  eta: 9:24:24  time: 0.4152  data_time: 0.0109  memory: 4796  grad_norm: 111.8942  loss: 33.1562  decode.loss_cls: 1.2041  decode.loss_mask: 0.7107  decode.loss_dice: 1.0652  decode.d0.loss_cls: 3.3683  decode.d0.loss_mask: 0.8105  decode.d0.loss_dice: 1.2792  decode.d1.loss_cls: 1.3992  decode.d1.loss_mask: 0.7705  decode.d1.loss_dice: 1.2378  decode.d2.loss_cls: 1.3170  decode.d2.loss_mask: 0.7432  decode.d2.loss_dice: 1.1393  decode.d3.loss_cls: 1.2717  decode.d3.loss_mask: 0.7110  decode.d3.loss_dice: 1.0829  decode.d4.loss_cls: 1.2648  decode.d4.loss_mask: 0.7134  decode.d4.loss_dice: 1.0849  decode.d5.loss_cls: 1.1862  decode.d5.loss_mask: 0.7137  decode.d5.loss_dice: 1.0891  decode.d6.loss_cls: 1.1975  decode.d6.loss_mask: 0.7164  decode.d6.loss_dice: 1.0900  decode.d7.loss_cls: 1.2054  decode.d7.loss_mask: 0.7275  decode.d7.loss_dice: 1.0801  decode.d8.loss_cls: 1.1854  decode.d8.loss_mask: 0.7252  decode.d8.loss_dice: 1.0660
2023/05/24 04:18:00 - mmengine - INFO - Iter(train) [ 81300/160000]  lr: 5.2805e-06  eta: 9:24:02  time: 0.4120  data_time: 0.0103  memory: 4828  grad_norm: 83.4963  loss: 24.8276  decode.loss_cls: 0.7871  decode.loss_mask: 0.4974  decode.loss_dice: 0.9453  decode.d0.loss_cls: 2.7027  decode.d0.loss_mask: 0.4675  decode.d0.loss_dice: 1.0517  decode.d1.loss_cls: 0.9925  decode.d1.loss_mask: 0.4907  decode.d1.loss_dice: 0.9644  decode.d2.loss_cls: 0.9161  decode.d2.loss_mask: 0.5126  decode.d2.loss_dice: 0.9194  decode.d3.loss_cls: 0.9042  decode.d3.loss_mask: 0.5011  decode.d3.loss_dice: 0.9204  decode.d4.loss_cls: 0.8597  decode.d4.loss_mask: 0.4968  decode.d4.loss_dice: 0.9201  decode.d5.loss_cls: 0.8213  decode.d5.loss_mask: 0.5091  decode.d5.loss_dice: 0.9466  decode.d6.loss_cls: 0.8269  decode.d6.loss_mask: 0.4870  decode.d6.loss_dice: 0.9301  decode.d7.loss_cls: 0.8100  decode.d7.loss_mask: 0.4917  decode.d7.loss_dice: 0.9274  decode.d8.loss_cls: 0.8186  decode.d8.loss_mask: 0.4846  decode.d8.loss_dice: 0.9249
2023/05/24 04:18:21 - mmengine - INFO - Iter(train) [ 81350/160000]  lr: 5.2774e-06  eta: 9:23:40  time: 0.4170  data_time: 0.0103  memory: 4878  grad_norm: 98.9697  loss: 37.4666  decode.loss_cls: 1.1465  decode.loss_mask: 0.8682  decode.loss_dice: 1.4421  decode.d0.loss_cls: 3.3260  decode.d0.loss_mask: 0.9344  decode.d0.loss_dice: 1.5851  decode.d1.loss_cls: 1.4337  decode.d1.loss_mask: 0.8682  decode.d1.loss_dice: 1.4541  decode.d2.loss_cls: 1.3217  decode.d2.loss_mask: 0.8526  decode.d2.loss_dice: 1.4279  decode.d3.loss_cls: 1.2251  decode.d3.loss_mask: 0.8606  decode.d3.loss_dice: 1.4183  decode.d4.loss_cls: 1.2088  decode.d4.loss_mask: 0.8740  decode.d4.loss_dice: 1.4219  decode.d5.loss_cls: 1.2079  decode.d5.loss_mask: 0.8767  decode.d5.loss_dice: 1.4131  decode.d6.loss_cls: 1.1681  decode.d6.loss_mask: 0.8840  decode.d6.loss_dice: 1.4261  decode.d7.loss_cls: 1.1318  decode.d7.loss_mask: 0.8902  decode.d7.loss_dice: 1.4115  decode.d8.loss_cls: 1.1296  decode.d8.loss_mask: 0.8637  decode.d8.loss_dice: 1.3950
2023/05/24 04:18:42 - mmengine - INFO - Iter(train) [ 81400/160000]  lr: 5.2744e-06  eta: 9:23:18  time: 0.4207  data_time: 0.0101  memory: 4858  grad_norm: 88.5402  loss: 29.3666  decode.loss_cls: 1.1107  decode.loss_mask: 0.5967  decode.loss_dice: 0.9511  decode.d0.loss_cls: 2.8875  decode.d0.loss_mask: 0.6211  decode.d0.loss_dice: 1.1227  decode.d1.loss_cls: 1.2233  decode.d1.loss_mask: 0.6796  decode.d1.loss_dice: 1.1211  decode.d2.loss_cls: 1.1206  decode.d2.loss_mask: 0.6505  decode.d2.loss_dice: 1.0388  decode.d3.loss_cls: 1.0598  decode.d3.loss_mask: 0.7035  decode.d3.loss_dice: 0.9918  decode.d4.loss_cls: 1.0803  decode.d4.loss_mask: 0.6930  decode.d4.loss_dice: 0.9922  decode.d5.loss_cls: 1.1510  decode.d5.loss_mask: 0.5985  decode.d5.loss_dice: 1.0018  decode.d6.loss_cls: 1.1122  decode.d6.loss_mask: 0.5941  decode.d6.loss_dice: 0.9725  decode.d7.loss_cls: 1.0964  decode.d7.loss_mask: 0.6004  decode.d7.loss_dice: 0.9538  decode.d8.loss_cls: 1.1076  decode.d8.loss_mask: 0.5894  decode.d8.loss_dice: 0.9447
2023/05/24 04:19:04 - mmengine - INFO - Iter(train) [ 81450/160000]  lr: 5.2714e-06  eta: 9:22:57  time: 0.4224  data_time: 0.0103  memory: 4857  grad_norm: 86.1640  loss: 30.7395  decode.loss_cls: 1.0862  decode.loss_mask: 0.5584  decode.loss_dice: 1.1856  decode.d0.loss_cls: 3.2620  decode.d0.loss_mask: 0.5708  decode.d0.loss_dice: 1.4542  decode.d1.loss_cls: 1.1185  decode.d1.loss_mask: 0.5917  decode.d1.loss_dice: 1.2890  decode.d2.loss_cls: 1.0710  decode.d2.loss_mask: 0.5531  decode.d2.loss_dice: 1.2289  decode.d3.loss_cls: 1.0488  decode.d3.loss_mask: 0.5418  decode.d3.loss_dice: 1.2006  decode.d4.loss_cls: 1.0407  decode.d4.loss_mask: 0.5447  decode.d4.loss_dice: 1.2086  decode.d5.loss_cls: 1.0497  decode.d5.loss_mask: 0.5725  decode.d5.loss_dice: 1.1980  decode.d6.loss_cls: 1.0058  decode.d6.loss_mask: 0.5606  decode.d6.loss_dice: 1.2032  decode.d7.loss_cls: 1.0197  decode.d7.loss_mask: 0.5696  decode.d7.loss_dice: 1.2064  decode.d8.loss_cls: 1.0232  decode.d8.loss_mask: 0.5653  decode.d8.loss_dice: 1.2111
2023/05/24 04:19:25 - mmengine - INFO - Iter(train) [ 81500/160000]  lr: 5.2684e-06  eta: 9:22:35  time: 0.4160  data_time: 0.0108  memory: 4838  grad_norm: 97.5056  loss: 31.7708  decode.loss_cls: 1.0155  decode.loss_mask: 0.6660  decode.loss_dice: 1.2062  decode.d0.loss_cls: 2.9829  decode.d0.loss_mask: 0.6765  decode.d0.loss_dice: 1.3855  decode.d1.loss_cls: 1.1819  decode.d1.loss_mask: 0.6786  decode.d1.loss_dice: 1.3167  decode.d2.loss_cls: 1.0944  decode.d2.loss_mask: 0.6758  decode.d2.loss_dice: 1.2712  decode.d3.loss_cls: 1.0792  decode.d3.loss_mask: 0.6767  decode.d3.loss_dice: 1.2386  decode.d4.loss_cls: 1.0316  decode.d4.loss_mask: 0.6798  decode.d4.loss_dice: 1.2318  decode.d5.loss_cls: 1.0445  decode.d5.loss_mask: 0.6721  decode.d5.loss_dice: 1.2161  decode.d6.loss_cls: 1.0437  decode.d6.loss_mask: 0.6515  decode.d6.loss_dice: 1.2096  decode.d7.loss_cls: 1.0383  decode.d7.loss_mask: 0.6524  decode.d7.loss_dice: 1.2402  decode.d8.loss_cls: 0.9836  decode.d8.loss_mask: 0.6672  decode.d8.loss_dice: 1.2627
2023/05/24 04:19:46 - mmengine - INFO - Iter(train) [ 81550/160000]  lr: 5.2654e-06  eta: 9:22:13  time: 0.4301  data_time: 0.0104  memory: 4837  grad_norm: 98.3511  loss: 33.3937  decode.loss_cls: 1.0853  decode.loss_mask: 0.6705  decode.loss_dice: 1.2608  decode.d0.loss_cls: 3.2249  decode.d0.loss_mask: 0.7688  decode.d0.loss_dice: 1.4649  decode.d1.loss_cls: 1.2821  decode.d1.loss_mask: 0.6892  decode.d1.loss_dice: 1.3324  decode.d2.loss_cls: 1.2028  decode.d2.loss_mask: 0.7073  decode.d2.loss_dice: 1.3064  decode.d3.loss_cls: 1.1469  decode.d3.loss_mask: 0.6797  decode.d3.loss_dice: 1.2886  decode.d4.loss_cls: 1.1431  decode.d4.loss_mask: 0.6830  decode.d4.loss_dice: 1.2963  decode.d5.loss_cls: 1.0616  decode.d5.loss_mask: 0.6969  decode.d5.loss_dice: 1.2772  decode.d6.loss_cls: 1.0796  decode.d6.loss_mask: 0.6828  decode.d6.loss_dice: 1.2865  decode.d7.loss_cls: 1.0584  decode.d7.loss_mask: 0.6947  decode.d7.loss_dice: 1.2739  decode.d8.loss_cls: 1.0726  decode.d8.loss_mask: 0.6737  decode.d8.loss_dice: 1.3031
2023/05/24 04:20:08 - mmengine - INFO - Iter(train) [ 81600/160000]  lr: 5.2623e-06  eta: 9:21:52  time: 0.4175  data_time: 0.0105  memory: 4835  grad_norm: 96.8092  loss: 32.7947  decode.loss_cls: 1.2241  decode.loss_mask: 0.7415  decode.loss_dice: 1.0333  decode.d0.loss_cls: 2.8008  decode.d0.loss_mask: 0.8188  decode.d0.loss_dice: 1.2612  decode.d1.loss_cls: 1.3928  decode.d1.loss_mask: 0.7721  decode.d1.loss_dice: 1.1879  decode.d2.loss_cls: 1.3533  decode.d2.loss_mask: 0.7479  decode.d2.loss_dice: 1.0786  decode.d3.loss_cls: 1.3289  decode.d3.loss_mask: 0.7197  decode.d3.loss_dice: 1.0523  decode.d4.loss_cls: 1.2925  decode.d4.loss_mask: 0.7387  decode.d4.loss_dice: 1.0512  decode.d5.loss_cls: 1.2713  decode.d5.loss_mask: 0.7354  decode.d5.loss_dice: 1.0642  decode.d6.loss_cls: 1.2450  decode.d6.loss_mask: 0.7479  decode.d6.loss_dice: 1.0471  decode.d7.loss_cls: 1.2776  decode.d7.loss_mask: 0.7598  decode.d7.loss_dice: 1.0224  decode.d8.loss_cls: 1.2566  decode.d8.loss_mask: 0.7381  decode.d8.loss_dice: 1.0333
2023/05/24 04:20:29 - mmengine - INFO - Iter(train) [ 81650/160000]  lr: 5.2593e-06  eta: 9:21:30  time: 0.4267  data_time: 0.0110  memory: 4823  grad_norm: 88.1684  loss: 36.9063  decode.loss_cls: 1.3328  decode.loss_mask: 0.7159  decode.loss_dice: 1.3832  decode.d0.loss_cls: 2.9703  decode.d0.loss_mask: 0.7759  decode.d0.loss_dice: 1.6659  decode.d1.loss_cls: 1.5210  decode.d1.loss_mask: 0.7270  decode.d1.loss_dice: 1.4259  decode.d2.loss_cls: 1.3125  decode.d2.loss_mask: 0.7403  decode.d2.loss_dice: 1.4838  decode.d3.loss_cls: 1.3217  decode.d3.loss_mask: 0.7324  decode.d3.loss_dice: 1.4327  decode.d4.loss_cls: 1.3841  decode.d4.loss_mask: 0.6985  decode.d4.loss_dice: 1.4199  decode.d5.loss_cls: 1.2999  decode.d5.loss_mask: 0.7443  decode.d5.loss_dice: 1.4309  decode.d6.loss_cls: 1.3128  decode.d6.loss_mask: 0.7288  decode.d6.loss_dice: 1.4200  decode.d7.loss_cls: 1.3073  decode.d7.loss_mask: 0.7180  decode.d7.loss_dice: 1.4506  decode.d8.loss_cls: 1.3114  decode.d8.loss_mask: 0.7284  decode.d8.loss_dice: 1.4098
2023/05/24 04:20:51 - mmengine - INFO - Iter(train) [ 81700/160000]  lr: 5.2563e-06  eta: 9:21:09  time: 0.4213  data_time: 0.0108  memory: 4839  grad_norm: 109.1819  loss: 33.3225  decode.loss_cls: 1.1212  decode.loss_mask: 0.7105  decode.loss_dice: 1.1586  decode.d0.loss_cls: 3.3007  decode.d0.loss_mask: 0.7599  decode.d0.loss_dice: 1.4216  decode.d1.loss_cls: 1.3690  decode.d1.loss_mask: 0.7731  decode.d1.loss_dice: 1.2741  decode.d2.loss_cls: 1.2381  decode.d2.loss_mask: 0.7402  decode.d2.loss_dice: 1.2048  decode.d3.loss_cls: 1.1165  decode.d3.loss_mask: 0.7821  decode.d3.loss_dice: 1.1941  decode.d4.loss_cls: 1.1525  decode.d4.loss_mask: 0.7451  decode.d4.loss_dice: 1.1831  decode.d5.loss_cls: 1.1433  decode.d5.loss_mask: 0.7534  decode.d5.loss_dice: 1.1608  decode.d6.loss_cls: 1.1381  decode.d6.loss_mask: 0.7166  decode.d6.loss_dice: 1.1707  decode.d7.loss_cls: 1.1243  decode.d7.loss_mask: 0.7154  decode.d7.loss_dice: 1.1912  decode.d8.loss_cls: 1.0923  decode.d8.loss_mask: 0.7043  decode.d8.loss_dice: 1.1669
2023/05/24 04:21:12 - mmengine - INFO - Iter(train) [ 81750/160000]  lr: 5.2533e-06  eta: 9:20:47  time: 0.4178  data_time: 0.0104  memory: 4906  grad_norm: 92.6710  loss: 42.1641  decode.loss_cls: 1.5384  decode.loss_mask: 0.8275  decode.loss_dice: 1.5808  decode.d0.loss_cls: 3.2761  decode.d0.loss_mask: 0.8552  decode.d0.loss_dice: 1.8562  decode.d1.loss_cls: 1.6408  decode.d1.loss_mask: 0.9102  decode.d1.loss_dice: 1.7604  decode.d2.loss_cls: 1.5567  decode.d2.loss_mask: 0.8493  decode.d2.loss_dice: 1.6786  decode.d3.loss_cls: 1.6137  decode.d3.loss_mask: 0.8169  decode.d3.loss_dice: 1.5629  decode.d4.loss_cls: 1.5186  decode.d4.loss_mask: 0.8370  decode.d4.loss_dice: 1.6095  decode.d5.loss_cls: 1.5946  decode.d5.loss_mask: 0.8465  decode.d5.loss_dice: 1.6058  decode.d6.loss_cls: 1.5285  decode.d6.loss_mask: 0.8298  decode.d6.loss_dice: 1.5878  decode.d7.loss_cls: 1.5264  decode.d7.loss_mask: 0.8312  decode.d7.loss_dice: 1.5558  decode.d8.loss_cls: 1.5472  decode.d8.loss_mask: 0.8353  decode.d8.loss_dice: 1.5864
2023/05/24 04:21:33 - mmengine - INFO - Iter(train) [ 81800/160000]  lr: 5.2503e-06  eta: 9:20:26  time: 0.4138  data_time: 0.0105  memory: 4816  grad_norm: 108.8534  loss: 34.6701  decode.loss_cls: 1.2170  decode.loss_mask: 0.6981  decode.loss_dice: 1.1800  decode.d0.loss_cls: 3.3535  decode.d0.loss_mask: 0.8028  decode.d0.loss_dice: 1.4601  decode.d1.loss_cls: 1.2295  decode.d1.loss_mask: 0.8360  decode.d1.loss_dice: 1.3688  decode.d2.loss_cls: 1.2402  decode.d2.loss_mask: 0.7492  decode.d2.loss_dice: 1.2799  decode.d3.loss_cls: 1.2772  decode.d3.loss_mask: 0.7355  decode.d3.loss_dice: 1.2427  decode.d4.loss_cls: 1.2510  decode.d4.loss_mask: 0.7470  decode.d4.loss_dice: 1.2412  decode.d5.loss_cls: 1.1965  decode.d5.loss_mask: 0.7481  decode.d5.loss_dice: 1.2404  decode.d6.loss_cls: 1.2101  decode.d6.loss_mask: 0.7522  decode.d6.loss_dice: 1.2198  decode.d7.loss_cls: 1.2475  decode.d7.loss_mask: 0.7446  decode.d7.loss_dice: 1.2245  decode.d8.loss_cls: 1.2004  decode.d8.loss_mask: 0.7521  decode.d8.loss_dice: 1.2240
2023/05/24 04:21:54 - mmengine - INFO - Iter(train) [ 81850/160000]  lr: 5.2472e-06  eta: 9:20:04  time: 0.4225  data_time: 0.0103  memory: 4889  grad_norm: 137.7704  loss: 27.5518  decode.loss_cls: 1.0306  decode.loss_mask: 0.6341  decode.loss_dice: 0.9081  decode.d0.loss_cls: 2.7606  decode.d0.loss_mask: 0.5904  decode.d0.loss_dice: 0.9738  decode.d1.loss_cls: 1.1318  decode.d1.loss_mask: 0.6670  decode.d1.loss_dice: 0.9550  decode.d2.loss_cls: 1.0798  decode.d2.loss_mask: 0.5998  decode.d2.loss_dice: 0.9130  decode.d3.loss_cls: 1.0198  decode.d3.loss_mask: 0.6199  decode.d3.loss_dice: 0.9145  decode.d4.loss_cls: 0.9918  decode.d4.loss_mask: 0.6236  decode.d4.loss_dice: 0.9096  decode.d5.loss_cls: 1.0118  decode.d5.loss_mask: 0.6223  decode.d5.loss_dice: 0.8929  decode.d6.loss_cls: 1.0643  decode.d6.loss_mask: 0.6249  decode.d6.loss_dice: 0.9144  decode.d7.loss_cls: 1.0079  decode.d7.loss_mask: 0.6395  decode.d7.loss_dice: 0.9116  decode.d8.loss_cls: 1.0213  decode.d8.loss_mask: 0.6327  decode.d8.loss_dice: 0.8847
2023/05/24 04:22:16 - mmengine - INFO - Iter(train) [ 81900/160000]  lr: 5.2442e-06  eta: 9:19:42  time: 0.4731  data_time: 0.0102  memory: 4877  grad_norm: 82.9996  loss: 37.9027  decode.loss_cls: 1.3225  decode.loss_mask: 0.8913  decode.loss_dice: 1.3131  decode.d0.loss_cls: 3.2528  decode.d0.loss_mask: 0.9309  decode.d0.loss_dice: 1.5395  decode.d1.loss_cls: 1.4065  decode.d1.loss_mask: 0.9160  decode.d1.loss_dice: 1.4165  decode.d2.loss_cls: 1.3469  decode.d2.loss_mask: 0.9068  decode.d2.loss_dice: 1.3576  decode.d3.loss_cls: 1.3059  decode.d3.loss_mask: 0.9140  decode.d3.loss_dice: 1.3638  decode.d4.loss_cls: 1.3037  decode.d4.loss_mask: 0.9044  decode.d4.loss_dice: 1.3413  decode.d5.loss_cls: 1.3101  decode.d5.loss_mask: 0.8923  decode.d5.loss_dice: 1.3670  decode.d6.loss_cls: 1.3398  decode.d6.loss_mask: 0.8765  decode.d6.loss_dice: 1.3242  decode.d7.loss_cls: 1.3674  decode.d7.loss_mask: 0.8702  decode.d7.loss_dice: 1.2833  decode.d8.loss_cls: 1.3446  decode.d8.loss_mask: 0.8888  decode.d8.loss_dice: 1.3050
2023/05/24 04:22:38 - mmengine - INFO - Iter(train) [ 81950/160000]  lr: 5.2412e-06  eta: 9:19:21  time: 0.4193  data_time: 0.0107  memory: 4927  grad_norm: 90.9698  loss: 40.1727  decode.loss_cls: 1.2123  decode.loss_mask: 0.8843  decode.loss_dice: 1.6208  decode.d0.loss_cls: 3.2017  decode.d0.loss_mask: 0.9889  decode.d0.loss_dice: 1.9006  decode.d1.loss_cls: 1.2763  decode.d1.loss_mask: 0.9439  decode.d1.loss_dice: 1.7262  decode.d2.loss_cls: 1.2433  decode.d2.loss_mask: 0.9413  decode.d2.loss_dice: 1.6929  decode.d3.loss_cls: 1.2427  decode.d3.loss_mask: 0.9492  decode.d3.loss_dice: 1.6513  decode.d4.loss_cls: 1.2219  decode.d4.loss_mask: 0.9254  decode.d4.loss_dice: 1.6649  decode.d5.loss_cls: 1.1894  decode.d5.loss_mask: 0.9085  decode.d5.loss_dice: 1.6693  decode.d6.loss_cls: 1.1911  decode.d6.loss_mask: 0.8982  decode.d6.loss_dice: 1.6075  decode.d7.loss_cls: 1.1875  decode.d7.loss_mask: 0.9002  decode.d7.loss_dice: 1.6074  decode.d8.loss_cls: 1.2093  decode.d8.loss_mask: 0.8937  decode.d8.loss_dice: 1.6228
2023/05/24 04:22:59 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 04:22:59 - mmengine - INFO - Iter(train) [ 82000/160000]  lr: 5.2382e-06  eta: 9:18:59  time: 0.4220  data_time: 0.0106  memory: 4817  grad_norm: 113.6634  loss: 33.8446  decode.loss_cls: 1.2110  decode.loss_mask: 0.7916  decode.loss_dice: 1.0734  decode.d0.loss_cls: 3.1432  decode.d0.loss_mask: 0.9312  decode.d0.loss_dice: 1.3490  decode.d1.loss_cls: 1.3867  decode.d1.loss_mask: 0.8770  decode.d1.loss_dice: 1.1982  decode.d2.loss_cls: 1.3160  decode.d2.loss_mask: 0.8457  decode.d2.loss_dice: 1.1635  decode.d3.loss_cls: 1.2276  decode.d3.loss_mask: 0.8026  decode.d3.loss_dice: 1.0948  decode.d4.loss_cls: 1.2073  decode.d4.loss_mask: 0.8084  decode.d4.loss_dice: 1.0739  decode.d5.loss_cls: 1.2103  decode.d5.loss_mask: 0.8268  decode.d5.loss_dice: 1.0821  decode.d6.loss_cls: 1.2298  decode.d6.loss_mask: 0.7888  decode.d6.loss_dice: 1.0778  decode.d7.loss_cls: 1.2072  decode.d7.loss_mask: 0.7831  decode.d7.loss_dice: 1.0784  decode.d8.loss_cls: 1.2080  decode.d8.loss_mask: 0.7868  decode.d8.loss_dice: 1.0644
2023/05/24 04:22:59 - mmengine - INFO - Saving checkpoint at 82000 iterations
2023/05/24 04:23:26 - mmengine - INFO - Iter(train) [ 82050/160000]  lr: 5.2351e-06  eta: 9:18:43  time: 0.4193  data_time: 0.0110  memory: 4866  grad_norm: 84.0998  loss: 45.4221  decode.loss_cls: 1.5196  decode.loss_mask: 0.9258  decode.loss_dice: 1.7845  decode.d0.loss_cls: 3.5642  decode.d0.loss_mask: 1.0181  decode.d0.loss_dice: 2.0868  decode.d1.loss_cls: 1.7488  decode.d1.loss_mask: 0.9129  decode.d1.loss_dice: 1.8781  decode.d2.loss_cls: 1.5987  decode.d2.loss_mask: 0.9714  decode.d2.loss_dice: 1.7967  decode.d3.loss_cls: 1.5922  decode.d3.loss_mask: 0.9286  decode.d3.loss_dice: 1.7821  decode.d4.loss_cls: 1.4556  decode.d4.loss_mask: 1.0193  decode.d4.loss_dice: 1.8071  decode.d5.loss_cls: 1.4983  decode.d5.loss_mask: 0.9985  decode.d5.loss_dice: 1.7366  decode.d6.loss_cls: 1.5619  decode.d6.loss_mask: 0.9716  decode.d6.loss_dice: 1.7762  decode.d7.loss_cls: 1.5950  decode.d7.loss_mask: 0.9577  decode.d7.loss_dice: 1.7109  decode.d8.loss_cls: 1.5582  decode.d8.loss_mask: 0.9214  decode.d8.loss_dice: 1.7455
2023/05/24 04:23:47 - mmengine - INFO - Iter(train) [ 82100/160000]  lr: 5.2321e-06  eta: 9:18:21  time: 0.4243  data_time: 0.0110  memory: 4865  grad_norm: 108.4410  loss: 34.6132  decode.loss_cls: 1.1798  decode.loss_mask: 0.7115  decode.loss_dice: 1.2937  decode.d0.loss_cls: 3.0150  decode.d0.loss_mask: 0.7440  decode.d0.loss_dice: 1.5534  decode.d1.loss_cls: 1.3849  decode.d1.loss_mask: 0.6982  decode.d1.loss_dice: 1.3714  decode.d2.loss_cls: 1.2784  decode.d2.loss_mask: 0.6926  decode.d2.loss_dice: 1.3447  decode.d3.loss_cls: 1.2537  decode.d3.loss_mask: 0.7021  decode.d3.loss_dice: 1.3277  decode.d4.loss_cls: 1.2161  decode.d4.loss_mask: 0.7189  decode.d4.loss_dice: 1.3076  decode.d5.loss_cls: 1.2020  decode.d5.loss_mask: 0.7241  decode.d5.loss_dice: 1.2974  decode.d6.loss_cls: 1.1971  decode.d6.loss_mask: 0.6936  decode.d6.loss_dice: 1.2759  decode.d7.loss_cls: 1.2434  decode.d7.loss_mask: 0.7032  decode.d7.loss_dice: 1.2731  decode.d8.loss_cls: 1.2146  decode.d8.loss_mask: 0.7104  decode.d8.loss_dice: 1.2849
2023/05/24 04:24:09 - mmengine - INFO - Iter(train) [ 82150/160000]  lr: 5.2291e-06  eta: 9:18:00  time: 0.4296  data_time: 0.0103  memory: 4830  grad_norm: 82.0546  loss: 37.0865  decode.loss_cls: 1.3648  decode.loss_mask: 0.8108  decode.loss_dice: 1.2179  decode.d0.loss_cls: 3.4272  decode.d0.loss_mask: 0.9245  decode.d0.loss_dice: 1.5143  decode.d1.loss_cls: 1.4545  decode.d1.loss_mask: 0.8436  decode.d1.loss_dice: 1.3677  decode.d2.loss_cls: 1.4378  decode.d2.loss_mask: 0.8844  decode.d2.loss_dice: 1.2938  decode.d3.loss_cls: 1.3805  decode.d3.loss_mask: 0.8942  decode.d3.loss_dice: 1.2647  decode.d4.loss_cls: 1.3771  decode.d4.loss_mask: 0.8407  decode.d4.loss_dice: 1.2757  decode.d5.loss_cls: 1.3480  decode.d5.loss_mask: 0.8366  decode.d5.loss_dice: 1.2502  decode.d6.loss_cls: 1.3100  decode.d6.loss_mask: 0.8441  decode.d6.loss_dice: 1.2554  decode.d7.loss_cls: 1.3191  decode.d7.loss_mask: 0.7974  decode.d7.loss_dice: 1.2234  decode.d8.loss_cls: 1.2910  decode.d8.loss_mask: 0.8137  decode.d8.loss_dice: 1.2230
2023/05/24 04:24:30 - mmengine - INFO - Iter(train) [ 82200/160000]  lr: 5.2261e-06  eta: 9:17:38  time: 0.4421  data_time: 0.0111  memory: 4821  grad_norm: 75.7755  loss: 32.5648  decode.loss_cls: 1.1823  decode.loss_mask: 0.7647  decode.loss_dice: 1.0666  decode.d0.loss_cls: 2.8123  decode.d0.loss_mask: 0.7969  decode.d0.loss_dice: 1.2582  decode.d1.loss_cls: 1.2295  decode.d1.loss_mask: 0.8143  decode.d1.loss_dice: 1.1563  decode.d2.loss_cls: 1.2144  decode.d2.loss_mask: 0.8039  decode.d2.loss_dice: 1.1647  decode.d3.loss_cls: 1.1637  decode.d3.loss_mask: 0.7897  decode.d3.loss_dice: 1.1214  decode.d4.loss_cls: 1.1354  decode.d4.loss_mask: 0.7809  decode.d4.loss_dice: 1.1483  decode.d5.loss_cls: 1.1982  decode.d5.loss_mask: 0.7657  decode.d5.loss_dice: 1.0922  decode.d6.loss_cls: 1.1945  decode.d6.loss_mask: 0.7633  decode.d6.loss_dice: 1.0918  decode.d7.loss_cls: 1.1596  decode.d7.loss_mask: 0.7884  decode.d7.loss_dice: 1.1206  decode.d8.loss_cls: 1.1228  decode.d8.loss_mask: 0.7869  decode.d8.loss_dice: 1.0773
2023/05/24 04:24:51 - mmengine - INFO - Iter(train) [ 82250/160000]  lr: 5.2231e-06  eta: 9:17:16  time: 0.4216  data_time: 0.0107  memory: 4904  grad_norm: 168.3510  loss: 42.2644  decode.loss_cls: 1.5416  decode.loss_mask: 0.8133  decode.loss_dice: 1.5614  decode.d0.loss_cls: 3.3094  decode.d0.loss_mask: 0.8366  decode.d0.loss_dice: 1.8760  decode.d1.loss_cls: 1.6863  decode.d1.loss_mask: 0.8612  decode.d1.loss_dice: 1.7219  decode.d2.loss_cls: 1.6737  decode.d2.loss_mask: 0.8491  decode.d2.loss_dice: 1.7053  decode.d3.loss_cls: 1.5503  decode.d3.loss_mask: 0.8666  decode.d3.loss_dice: 1.6481  decode.d4.loss_cls: 1.5231  decode.d4.loss_mask: 0.8312  decode.d4.loss_dice: 1.6492  decode.d5.loss_cls: 1.5307  decode.d5.loss_mask: 0.8372  decode.d5.loss_dice: 1.6039  decode.d6.loss_cls: 1.4873  decode.d6.loss_mask: 0.8262  decode.d6.loss_dice: 1.5808  decode.d7.loss_cls: 1.5482  decode.d7.loss_mask: 0.8247  decode.d7.loss_dice: 1.5800  decode.d8.loss_cls: 1.5698  decode.d8.loss_mask: 0.8172  decode.d8.loss_dice: 1.5541
2023/05/24 04:25:15 - mmengine - INFO - Iter(train) [ 82300/160000]  lr: 5.2200e-06  eta: 9:16:57  time: 0.4469  data_time: 0.0105  memory: 4838  grad_norm: 100.9249  loss: 27.9906  decode.loss_cls: 0.8899  decode.loss_mask: 0.7412  decode.loss_dice: 0.9027  decode.d0.loss_cls: 2.9534  decode.d0.loss_mask: 0.8028  decode.d0.loss_dice: 0.9929  decode.d1.loss_cls: 1.0421  decode.d1.loss_mask: 0.7875  decode.d1.loss_dice: 0.9893  decode.d2.loss_cls: 0.9711  decode.d2.loss_mask: 0.7192  decode.d2.loss_dice: 0.9279  decode.d3.loss_cls: 0.9934  decode.d3.loss_mask: 0.7123  decode.d3.loss_dice: 0.9020  decode.d4.loss_cls: 0.9300  decode.d4.loss_mask: 0.7248  decode.d4.loss_dice: 0.9211  decode.d5.loss_cls: 0.9003  decode.d5.loss_mask: 0.7163  decode.d5.loss_dice: 0.9077  decode.d6.loss_cls: 0.9076  decode.d6.loss_mask: 0.7279  decode.d6.loss_dice: 0.8860  decode.d7.loss_cls: 0.9273  decode.d7.loss_mask: 0.7340  decode.d7.loss_dice: 0.8776  decode.d8.loss_cls: 0.8504  decode.d8.loss_mask: 0.7408  decode.d8.loss_dice: 0.9110
2023/05/24 04:25:36 - mmengine - INFO - Iter(train) [ 82350/160000]  lr: 5.2170e-06  eta: 9:16:35  time: 0.4120  data_time: 0.0105  memory: 4875  grad_norm: 107.6199  loss: 44.7685  decode.loss_cls: 1.4788  decode.loss_mask: 0.8767  decode.loss_dice: 1.6563  decode.d0.loss_cls: 3.7459  decode.d0.loss_mask: 1.0860  decode.d0.loss_dice: 2.1175  decode.d1.loss_cls: 1.6865  decode.d1.loss_mask: 1.0048  decode.d1.loss_dice: 1.9437  decode.d2.loss_cls: 1.5006  decode.d2.loss_mask: 0.9881  decode.d2.loss_dice: 1.8291  decode.d3.loss_cls: 1.5481  decode.d3.loss_mask: 0.9205  decode.d3.loss_dice: 1.7321  decode.d4.loss_cls: 1.5841  decode.d4.loss_mask: 0.9004  decode.d4.loss_dice: 1.7016  decode.d5.loss_cls: 1.5211  decode.d5.loss_mask: 0.8860  decode.d5.loss_dice: 1.7271  decode.d6.loss_cls: 1.4752  decode.d6.loss_mask: 0.9084  decode.d6.loss_dice: 1.7646  decode.d7.loss_cls: 1.4900  decode.d7.loss_mask: 0.8930  decode.d7.loss_dice: 1.7275  decode.d8.loss_cls: 1.4952  decode.d8.loss_mask: 0.8801  decode.d8.loss_dice: 1.6997
2023/05/24 04:25:58 - mmengine - INFO - Iter(train) [ 82400/160000]  lr: 5.2140e-06  eta: 9:16:13  time: 0.4210  data_time: 0.0107  memory: 4829  grad_norm: 122.1341  loss: 38.0389  decode.loss_cls: 1.1800  decode.loss_mask: 0.8971  decode.loss_dice: 1.4500  decode.d0.loss_cls: 3.0876  decode.d0.loss_mask: 0.8906  decode.d0.loss_dice: 1.5151  decode.d1.loss_cls: 1.2559  decode.d1.loss_mask: 0.9147  decode.d1.loss_dice: 1.5441  decode.d2.loss_cls: 1.3161  decode.d2.loss_mask: 0.9457  decode.d2.loss_dice: 1.5296  decode.d3.loss_cls: 1.2727  decode.d3.loss_mask: 0.9149  decode.d3.loss_dice: 1.4611  decode.d4.loss_cls: 1.2585  decode.d4.loss_mask: 0.9071  decode.d4.loss_dice: 1.4891  decode.d5.loss_cls: 1.2115  decode.d5.loss_mask: 0.8920  decode.d5.loss_dice: 1.4534  decode.d6.loss_cls: 1.2036  decode.d6.loss_mask: 0.8845  decode.d6.loss_dice: 1.4742  decode.d7.loss_cls: 1.2149  decode.d7.loss_mask: 0.8781  decode.d7.loss_dice: 1.4683  decode.d8.loss_cls: 1.2191  decode.d8.loss_mask: 0.8824  decode.d8.loss_dice: 1.4269
2023/05/24 04:26:19 - mmengine - INFO - Iter(train) [ 82450/160000]  lr: 5.2110e-06  eta: 9:15:51  time: 0.4190  data_time: 0.0104  memory: 4870  grad_norm: 169.9037  loss: 43.4591  decode.loss_cls: 1.3837  decode.loss_mask: 0.9392  decode.loss_dice: 1.7201  decode.d0.loss_cls: 3.3643  decode.d0.loss_mask: 1.0598  decode.d0.loss_dice: 2.0121  decode.d1.loss_cls: 1.3714  decode.d1.loss_mask: 0.9570  decode.d1.loss_dice: 1.9375  decode.d2.loss_cls: 1.4124  decode.d2.loss_mask: 0.9673  decode.d2.loss_dice: 1.8378  decode.d3.loss_cls: 1.4099  decode.d3.loss_mask: 0.9716  decode.d3.loss_dice: 1.7789  decode.d4.loss_cls: 1.4294  decode.d4.loss_mask: 0.9538  decode.d4.loss_dice: 1.8082  decode.d5.loss_cls: 1.4252  decode.d5.loss_mask: 0.9090  decode.d5.loss_dice: 1.7418  decode.d6.loss_cls: 1.4040  decode.d6.loss_mask: 0.9266  decode.d6.loss_dice: 1.7056  decode.d7.loss_cls: 1.3682  decode.d7.loss_mask: 0.9210  decode.d7.loss_dice: 1.7200  decode.d8.loss_cls: 1.3782  decode.d8.loss_mask: 0.9187  decode.d8.loss_dice: 1.7263
2023/05/24 04:26:40 - mmengine - INFO - Iter(train) [ 82500/160000]  lr: 5.2079e-06  eta: 9:15:30  time: 0.4250  data_time: 0.0102  memory: 4861  grad_norm: 110.0810  loss: 31.7128  decode.loss_cls: 1.0874  decode.loss_mask: 0.5997  decode.loss_dice: 1.1846  decode.d0.loss_cls: 3.0105  decode.d0.loss_mask: 0.6598  decode.d0.loss_dice: 1.4017  decode.d1.loss_cls: 1.2269  decode.d1.loss_mask: 0.6485  decode.d1.loss_dice: 1.2760  decode.d2.loss_cls: 1.1340  decode.d2.loss_mask: 0.6328  decode.d2.loss_dice: 1.2059  decode.d3.loss_cls: 1.0867  decode.d3.loss_mask: 0.6382  decode.d3.loss_dice: 1.2616  decode.d4.loss_cls: 1.0907  decode.d4.loss_mask: 0.6292  decode.d4.loss_dice: 1.2490  decode.d5.loss_cls: 1.0829  decode.d5.loss_mask: 0.6256  decode.d5.loss_dice: 1.2256  decode.d6.loss_cls: 1.0746  decode.d6.loss_mask: 0.6295  decode.d6.loss_dice: 1.2438  decode.d7.loss_cls: 1.1038  decode.d7.loss_mask: 0.6133  decode.d7.loss_dice: 1.2288  decode.d8.loss_cls: 1.0306  decode.d8.loss_mask: 0.6242  decode.d8.loss_dice: 1.2069
2023/05/24 04:27:01 - mmengine - INFO - Iter(train) [ 82550/160000]  lr: 5.2049e-06  eta: 9:15:08  time: 0.4158  data_time: 0.0105  memory: 4838  grad_norm: 104.7486  loss: 42.1929  decode.loss_cls: 1.4354  decode.loss_mask: 0.8673  decode.loss_dice: 1.5938  decode.d0.loss_cls: 3.4384  decode.d0.loss_mask: 0.9203  decode.d0.loss_dice: 1.7859  decode.d1.loss_cls: 1.6538  decode.d1.loss_mask: 0.9778  decode.d1.loss_dice: 1.7528  decode.d2.loss_cls: 1.5909  decode.d2.loss_mask: 0.9397  decode.d2.loss_dice: 1.6640  decode.d3.loss_cls: 1.5914  decode.d3.loss_mask: 0.8676  decode.d3.loss_dice: 1.6038  decode.d4.loss_cls: 1.5182  decode.d4.loss_mask: 0.8848  decode.d4.loss_dice: 1.6075  decode.d5.loss_cls: 1.4671  decode.d5.loss_mask: 0.8683  decode.d5.loss_dice: 1.5578  decode.d6.loss_cls: 1.4033  decode.d6.loss_mask: 0.8783  decode.d6.loss_dice: 1.5671  decode.d7.loss_cls: 1.4568  decode.d7.loss_mask: 0.8766  decode.d7.loss_dice: 1.5288  decode.d8.loss_cls: 1.4880  decode.d8.loss_mask: 0.8650  decode.d8.loss_dice: 1.5422
2023/05/24 04:27:23 - mmengine - INFO - Iter(train) [ 82600/160000]  lr: 5.2019e-06  eta: 9:14:47  time: 0.4702  data_time: 0.0104  memory: 4887  grad_norm: 115.0590  loss: 33.5134  decode.loss_cls: 1.1988  decode.loss_mask: 0.7183  decode.loss_dice: 1.1399  decode.d0.loss_cls: 2.9883  decode.d0.loss_mask: 0.7988  decode.d0.loss_dice: 1.3664  decode.d1.loss_cls: 1.3451  decode.d1.loss_mask: 0.7690  decode.d1.loss_dice: 1.2854  decode.d2.loss_cls: 1.2995  decode.d2.loss_mask: 0.7445  decode.d2.loss_dice: 1.2414  decode.d3.loss_cls: 1.2362  decode.d3.loss_mask: 0.7402  decode.d3.loss_dice: 1.1831  decode.d4.loss_cls: 1.2091  decode.d4.loss_mask: 0.7330  decode.d4.loss_dice: 1.1813  decode.d5.loss_cls: 1.1846  decode.d5.loss_mask: 0.7433  decode.d5.loss_dice: 1.1848  decode.d6.loss_cls: 1.2083  decode.d6.loss_mask: 0.7310  decode.d6.loss_dice: 1.1608  decode.d7.loss_cls: 1.1853  decode.d7.loss_mask: 0.7306  decode.d7.loss_dice: 1.1707  decode.d8.loss_cls: 1.1639  decode.d8.loss_mask: 0.7223  decode.d8.loss_dice: 1.1495
2023/05/24 04:27:45 - mmengine - INFO - Iter(train) [ 82650/160000]  lr: 5.1989e-06  eta: 9:14:25  time: 0.4233  data_time: 0.0104  memory: 4889  grad_norm: 116.4648  loss: 34.3493  decode.loss_cls: 1.1170  decode.loss_mask: 0.7321  decode.loss_dice: 1.3146  decode.d0.loss_cls: 3.1743  decode.d0.loss_mask: 0.7083  decode.d0.loss_dice: 1.4609  decode.d1.loss_cls: 1.3167  decode.d1.loss_mask: 0.7339  decode.d1.loss_dice: 1.3727  decode.d2.loss_cls: 1.2194  decode.d2.loss_mask: 0.7294  decode.d2.loss_dice: 1.3915  decode.d3.loss_cls: 1.1719  decode.d3.loss_mask: 0.7295  decode.d3.loss_dice: 1.3453  decode.d4.loss_cls: 1.1532  decode.d4.loss_mask: 0.6990  decode.d4.loss_dice: 1.2917  decode.d5.loss_cls: 1.1776  decode.d5.loss_mask: 0.6852  decode.d5.loss_dice: 1.2866  decode.d6.loss_cls: 1.1761  decode.d6.loss_mask: 0.7142  decode.d6.loss_dice: 1.3218  decode.d7.loss_cls: 1.1220  decode.d7.loss_mask: 0.7570  decode.d7.loss_dice: 1.2944  decode.d8.loss_cls: 1.1388  decode.d8.loss_mask: 0.7430  decode.d8.loss_dice: 1.2710
2023/05/24 04:28:06 - mmengine - INFO - Iter(train) [ 82700/160000]  lr: 5.1958e-06  eta: 9:14:03  time: 0.4216  data_time: 0.0105  memory: 4877  grad_norm: 96.1988  loss: 36.7155  decode.loss_cls: 1.1704  decode.loss_mask: 0.9479  decode.loss_dice: 1.2280  decode.d0.loss_cls: 3.0527  decode.d0.loss_mask: 1.0846  decode.d0.loss_dice: 1.5463  decode.d1.loss_cls: 1.3922  decode.d1.loss_mask: 0.9741  decode.d1.loss_dice: 1.3741  decode.d2.loss_cls: 1.3305  decode.d2.loss_mask: 0.9550  decode.d2.loss_dice: 1.3018  decode.d3.loss_cls: 1.2133  decode.d3.loss_mask: 0.9532  decode.d3.loss_dice: 1.2573  decode.d4.loss_cls: 1.2157  decode.d4.loss_mask: 0.9409  decode.d4.loss_dice: 1.2455  decode.d5.loss_cls: 1.2489  decode.d5.loss_mask: 0.9385  decode.d5.loss_dice: 1.2293  decode.d6.loss_cls: 1.2277  decode.d6.loss_mask: 0.9442  decode.d6.loss_dice: 1.2378  decode.d7.loss_cls: 1.1531  decode.d7.loss_mask: 0.9559  decode.d7.loss_dice: 1.2826  decode.d8.loss_cls: 1.1297  decode.d8.loss_mask: 0.9311  decode.d8.loss_dice: 1.2530
2023/05/24 04:28:27 - mmengine - INFO - Iter(train) [ 82750/160000]  lr: 5.1928e-06  eta: 9:13:42  time: 0.4476  data_time: 0.0111  memory: 4838  grad_norm: 108.3409  loss: 30.5934  decode.loss_cls: 1.0183  decode.loss_mask: 0.7591  decode.loss_dice: 1.0079  decode.d0.loss_cls: 2.9628  decode.d0.loss_mask: 0.7642  decode.d0.loss_dice: 1.1495  decode.d1.loss_cls: 1.1929  decode.d1.loss_mask: 0.7591  decode.d1.loss_dice: 1.1331  decode.d2.loss_cls: 1.1667  decode.d2.loss_mask: 0.7363  decode.d2.loss_dice: 1.0432  decode.d3.loss_cls: 1.0774  decode.d3.loss_mask: 0.7610  decode.d3.loss_dice: 0.9976  decode.d4.loss_cls: 1.0824  decode.d4.loss_mask: 0.7622  decode.d4.loss_dice: 0.9993  decode.d5.loss_cls: 1.0592  decode.d5.loss_mask: 0.7906  decode.d5.loss_dice: 1.0077  decode.d6.loss_cls: 1.0273  decode.d6.loss_mask: 0.7658  decode.d6.loss_dice: 1.0085  decode.d7.loss_cls: 1.0291  decode.d7.loss_mask: 0.7529  decode.d7.loss_dice: 0.9981  decode.d8.loss_cls: 1.0431  decode.d8.loss_mask: 0.7524  decode.d8.loss_dice: 0.9856
2023/05/24 04:28:49 - mmengine - INFO - Iter(train) [ 82800/160000]  lr: 5.1898e-06  eta: 9:13:20  time: 0.4341  data_time: 0.0107  memory: 4832  grad_norm: 94.0356  loss: 34.6282  decode.loss_cls: 1.1820  decode.loss_mask: 0.8223  decode.loss_dice: 1.2564  decode.d0.loss_cls: 3.0357  decode.d0.loss_mask: 0.8820  decode.d0.loss_dice: 1.4136  decode.d1.loss_cls: 1.2748  decode.d1.loss_mask: 0.8162  decode.d1.loss_dice: 1.3369  decode.d2.loss_cls: 1.2112  decode.d2.loss_mask: 0.7820  decode.d2.loss_dice: 1.3064  decode.d3.loss_cls: 1.1658  decode.d3.loss_mask: 0.8115  decode.d3.loss_dice: 1.2391  decode.d4.loss_cls: 1.0992  decode.d4.loss_mask: 0.8270  decode.d4.loss_dice: 1.2580  decode.d5.loss_cls: 1.1214  decode.d5.loss_mask: 0.8322  decode.d5.loss_dice: 1.2526  decode.d6.loss_cls: 1.1586  decode.d6.loss_mask: 0.8055  decode.d6.loss_dice: 1.2707  decode.d7.loss_cls: 1.1188  decode.d7.loss_mask: 0.7992  decode.d7.loss_dice: 1.2582  decode.d8.loss_cls: 1.1701  decode.d8.loss_mask: 0.8232  decode.d8.loss_dice: 1.2977
2023/05/24 04:29:10 - mmengine - INFO - Iter(train) [ 82850/160000]  lr: 5.1868e-06  eta: 9:12:59  time: 0.4270  data_time: 0.0104  memory: 4837  grad_norm: 108.0756  loss: 30.0848  decode.loss_cls: 1.1785  decode.loss_mask: 0.5930  decode.loss_dice: 0.9912  decode.d0.loss_cls: 3.1368  decode.d0.loss_mask: 0.6488  decode.d0.loss_dice: 1.1821  decode.d1.loss_cls: 1.2298  decode.d1.loss_mask: 0.6519  decode.d1.loss_dice: 1.0999  decode.d2.loss_cls: 1.1606  decode.d2.loss_mask: 0.6135  decode.d2.loss_dice: 1.0876  decode.d3.loss_cls: 1.1412  decode.d3.loss_mask: 0.6081  decode.d3.loss_dice: 1.0044  decode.d4.loss_cls: 1.1197  decode.d4.loss_mask: 0.6025  decode.d4.loss_dice: 1.0343  decode.d5.loss_cls: 1.1582  decode.d5.loss_mask: 0.6279  decode.d5.loss_dice: 1.0390  decode.d6.loss_cls: 1.1492  decode.d6.loss_mask: 0.6014  decode.d6.loss_dice: 1.0032  decode.d7.loss_cls: 1.1250  decode.d7.loss_mask: 0.5976  decode.d7.loss_dice: 0.9951  decode.d8.loss_cls: 1.1187  decode.d8.loss_mask: 0.5914  decode.d8.loss_dice: 0.9941
2023/05/24 04:29:31 - mmengine - INFO - Iter(train) [ 82900/160000]  lr: 5.1837e-06  eta: 9:12:37  time: 0.4186  data_time: 0.0107  memory: 4857  grad_norm: 99.9076  loss: 33.6168  decode.loss_cls: 1.2133  decode.loss_mask: 0.7298  decode.loss_dice: 1.1293  decode.d0.loss_cls: 3.1981  decode.d0.loss_mask: 0.8110  decode.d0.loss_dice: 1.3564  decode.d1.loss_cls: 1.3778  decode.d1.loss_mask: 0.7767  decode.d1.loss_dice: 1.2197  decode.d2.loss_cls: 1.2890  decode.d2.loss_mask: 0.7387  decode.d2.loss_dice: 1.1989  decode.d3.loss_cls: 1.1408  decode.d3.loss_mask: 0.7658  decode.d3.loss_dice: 1.1737  decode.d4.loss_cls: 1.2562  decode.d4.loss_mask: 0.7183  decode.d4.loss_dice: 1.1434  decode.d5.loss_cls: 1.2586  decode.d5.loss_mask: 0.7111  decode.d5.loss_dice: 1.1490  decode.d6.loss_cls: 1.2303  decode.d6.loss_mask: 0.7011  decode.d6.loss_dice: 1.1536  decode.d7.loss_cls: 1.2263  decode.d7.loss_mask: 0.7283  decode.d7.loss_dice: 1.1430  decode.d8.loss_cls: 1.2252  decode.d8.loss_mask: 0.7206  decode.d8.loss_dice: 1.1329
2023/05/24 04:29:52 - mmengine - INFO - Iter(train) [ 82950/160000]  lr: 5.1807e-06  eta: 9:12:15  time: 0.4212  data_time: 0.0105  memory: 4876  grad_norm: 95.4405  loss: 34.9212  decode.loss_cls: 1.2933  decode.loss_mask: 0.7034  decode.loss_dice: 1.2534  decode.d0.loss_cls: 3.3713  decode.d0.loss_mask: 0.7339  decode.d0.loss_dice: 1.3254  decode.d1.loss_cls: 1.4846  decode.d1.loss_mask: 0.6950  decode.d1.loss_dice: 1.2788  decode.d2.loss_cls: 1.3689  decode.d2.loss_mask: 0.6709  decode.d2.loss_dice: 1.1990  decode.d3.loss_cls: 1.3950  decode.d3.loss_mask: 0.6771  decode.d3.loss_dice: 1.2216  decode.d4.loss_cls: 1.3919  decode.d4.loss_mask: 0.6448  decode.d4.loss_dice: 1.2207  decode.d5.loss_cls: 1.4378  decode.d5.loss_mask: 0.6302  decode.d5.loss_dice: 1.2222  decode.d6.loss_cls: 1.3629  decode.d6.loss_mask: 0.6645  decode.d6.loss_dice: 1.2262  decode.d7.loss_cls: 1.4234  decode.d7.loss_mask: 0.6519  decode.d7.loss_dice: 1.1819  decode.d8.loss_cls: 1.3291  decode.d8.loss_mask: 0.6881  decode.d8.loss_dice: 1.1740
2023/05/24 04:30:14 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 04:30:14 - mmengine - INFO - Iter(train) [ 83000/160000]  lr: 5.1777e-06  eta: 9:11:53  time: 0.4291  data_time: 0.0104  memory: 4831  grad_norm: 90.0372  loss: 33.8137  decode.loss_cls: 1.1813  decode.loss_mask: 0.7545  decode.loss_dice: 1.1775  decode.d0.loss_cls: 3.0405  decode.d0.loss_mask: 0.8127  decode.d0.loss_dice: 1.3476  decode.d1.loss_cls: 1.4217  decode.d1.loss_mask: 0.7452  decode.d1.loss_dice: 1.2890  decode.d2.loss_cls: 1.3337  decode.d2.loss_mask: 0.7462  decode.d2.loss_dice: 1.2011  decode.d3.loss_cls: 1.2639  decode.d3.loss_mask: 0.7264  decode.d3.loss_dice: 1.1501  decode.d4.loss_cls: 1.2073  decode.d4.loss_mask: 0.7317  decode.d4.loss_dice: 1.1936  decode.d5.loss_cls: 1.2392  decode.d5.loss_mask: 0.7272  decode.d5.loss_dice: 1.1875  decode.d6.loss_cls: 1.2022  decode.d6.loss_mask: 0.7385  decode.d6.loss_dice: 1.1600  decode.d7.loss_cls: 1.2138  decode.d7.loss_mask: 0.7394  decode.d7.loss_dice: 1.1559  decode.d8.loss_cls: 1.2179  decode.d8.loss_mask: 0.7417  decode.d8.loss_dice: 1.1664
2023/05/24 04:30:14 - mmengine - INFO - Saving checkpoint at 83000 iterations
2023/05/24 04:30:40 - mmengine - INFO - Iter(train) [ 83050/160000]  lr: 5.1747e-06  eta: 9:11:36  time: 0.4258  data_time: 0.0105  memory: 4908  grad_norm: 115.1564  loss: 38.5102  decode.loss_cls: 1.3082  decode.loss_mask: 0.8575  decode.loss_dice: 1.4031  decode.d0.loss_cls: 3.2815  decode.d0.loss_mask: 0.8987  decode.d0.loss_dice: 1.6825  decode.d1.loss_cls: 1.4860  decode.d1.loss_mask: 0.8402  decode.d1.loss_dice: 1.5772  decode.d2.loss_cls: 1.3287  decode.d2.loss_mask: 0.8295  decode.d2.loss_dice: 1.5054  decode.d3.loss_cls: 1.3573  decode.d3.loss_mask: 0.8100  decode.d3.loss_dice: 1.4626  decode.d4.loss_cls: 1.3809  decode.d4.loss_mask: 0.8267  decode.d4.loss_dice: 1.4683  decode.d5.loss_cls: 1.3346  decode.d5.loss_mask: 0.7801  decode.d5.loss_dice: 1.4401  decode.d6.loss_cls: 1.2908  decode.d6.loss_mask: 0.8083  decode.d6.loss_dice: 1.4293  decode.d7.loss_cls: 1.3059  decode.d7.loss_mask: 0.8079  decode.d7.loss_dice: 1.4305  decode.d8.loss_cls: 1.3322  decode.d8.loss_mask: 0.8157  decode.d8.loss_dice: 1.4304
2023/05/24 04:31:03 - mmengine - INFO - Iter(train) [ 83100/160000]  lr: 5.1716e-06  eta: 9:11:16  time: 0.4431  data_time: 0.0107  memory: 4836  grad_norm: 142.6386  loss: 30.8421  decode.loss_cls: 1.1568  decode.loss_mask: 0.6612  decode.loss_dice: 1.0194  decode.d0.loss_cls: 2.8563  decode.d0.loss_mask: 0.7381  decode.d0.loss_dice: 1.1692  decode.d1.loss_cls: 1.2658  decode.d1.loss_mask: 0.7327  decode.d1.loss_dice: 1.1672  decode.d2.loss_cls: 1.2107  decode.d2.loss_mask: 0.6779  decode.d2.loss_dice: 1.0694  decode.d3.loss_cls: 1.1236  decode.d3.loss_mask: 0.7014  decode.d3.loss_dice: 1.0613  decode.d4.loss_cls: 1.1263  decode.d4.loss_mask: 0.7021  decode.d4.loss_dice: 1.0635  decode.d5.loss_cls: 1.1091  decode.d5.loss_mask: 0.6889  decode.d5.loss_dice: 1.0501  decode.d6.loss_cls: 1.1459  decode.d6.loss_mask: 0.6528  decode.d6.loss_dice: 1.0344  decode.d7.loss_cls: 1.1565  decode.d7.loss_mask: 0.6536  decode.d7.loss_dice: 1.0180  decode.d8.loss_cls: 1.1701  decode.d8.loss_mask: 0.6535  decode.d8.loss_dice: 1.0060
2023/05/24 04:31:24 - mmengine - INFO - Iter(train) [ 83150/160000]  lr: 5.1686e-06  eta: 9:10:54  time: 0.4278  data_time: 0.0106  memory: 4858  grad_norm: 106.8637  loss: 41.8632  decode.loss_cls: 1.3904  decode.loss_mask: 0.9273  decode.loss_dice: 1.5862  decode.d0.loss_cls: 3.2809  decode.d0.loss_mask: 1.0498  decode.d0.loss_dice: 1.8444  decode.d1.loss_cls: 1.4571  decode.d1.loss_mask: 1.0242  decode.d1.loss_dice: 1.7347  decode.d2.loss_cls: 1.4180  decode.d2.loss_mask: 0.9590  decode.d2.loss_dice: 1.6510  decode.d3.loss_cls: 1.3927  decode.d3.loss_mask: 0.9319  decode.d3.loss_dice: 1.6044  decode.d4.loss_cls: 1.3825  decode.d4.loss_mask: 0.9378  decode.d4.loss_dice: 1.5922  decode.d5.loss_cls: 1.4152  decode.d5.loss_mask: 0.9272  decode.d5.loss_dice: 1.6044  decode.d6.loss_cls: 1.3649  decode.d6.loss_mask: 0.9514  decode.d6.loss_dice: 1.6188  decode.d7.loss_cls: 1.3748  decode.d7.loss_mask: 0.9209  decode.d7.loss_dice: 1.6139  decode.d8.loss_cls: 1.3992  decode.d8.loss_mask: 0.9289  decode.d8.loss_dice: 1.5789
2023/05/24 04:31:46 - mmengine - INFO - Iter(train) [ 83200/160000]  lr: 5.1656e-06  eta: 9:10:33  time: 0.4218  data_time: 0.0106  memory: 4970  grad_norm: 101.8911  loss: 30.8007  decode.loss_cls: 0.9917  decode.loss_mask: 0.7455  decode.loss_dice: 1.0294  decode.d0.loss_cls: 3.0092  decode.d0.loss_mask: 0.8503  decode.d0.loss_dice: 1.2273  decode.d1.loss_cls: 1.0634  decode.d1.loss_mask: 0.8883  decode.d1.loss_dice: 1.1563  decode.d2.loss_cls: 1.0510  decode.d2.loss_mask: 0.8350  decode.d2.loss_dice: 1.1152  decode.d3.loss_cls: 1.0090  decode.d3.loss_mask: 0.7708  decode.d3.loss_dice: 1.0709  decode.d4.loss_cls: 0.9626  decode.d4.loss_mask: 0.7768  decode.d4.loss_dice: 1.0624  decode.d5.loss_cls: 0.9303  decode.d5.loss_mask: 0.7966  decode.d5.loss_dice: 1.0456  decode.d6.loss_cls: 0.9657  decode.d6.loss_mask: 0.7560  decode.d6.loss_dice: 1.0575  decode.d7.loss_cls: 1.0344  decode.d7.loss_mask: 0.7503  decode.d7.loss_dice: 1.0626  decode.d8.loss_cls: 0.9699  decode.d8.loss_mask: 0.7552  decode.d8.loss_dice: 1.0615
2023/05/24 04:32:08 - mmengine - INFO - Iter(train) [ 83250/160000]  lr: 5.1626e-06  eta: 9:10:12  time: 0.4189  data_time: 0.0104  memory: 4877  grad_norm: 109.7339  loss: 34.1779  decode.loss_cls: 1.3061  decode.loss_mask: 0.7880  decode.loss_dice: 1.0611  decode.d0.loss_cls: 3.1194  decode.d0.loss_mask: 0.8539  decode.d0.loss_dice: 1.2080  decode.d1.loss_cls: 1.3343  decode.d1.loss_mask: 0.8336  decode.d1.loss_dice: 1.1499  decode.d2.loss_cls: 1.3029  decode.d2.loss_mask: 0.8284  decode.d2.loss_dice: 1.1016  decode.d3.loss_cls: 1.4454  decode.d3.loss_mask: 0.8010  decode.d3.loss_dice: 1.0491  decode.d4.loss_cls: 1.3779  decode.d4.loss_mask: 0.7964  decode.d4.loss_dice: 1.0471  decode.d5.loss_cls: 1.3913  decode.d5.loss_mask: 0.7926  decode.d5.loss_dice: 1.0460  decode.d6.loss_cls: 1.3816  decode.d6.loss_mask: 0.7884  decode.d6.loss_dice: 1.0626  decode.d7.loss_cls: 1.3311  decode.d7.loss_mask: 0.8002  decode.d7.loss_dice: 1.0664  decode.d8.loss_cls: 1.2727  decode.d8.loss_mask: 0.7977  decode.d8.loss_dice: 1.0430
2023/05/24 04:32:32 - mmengine - INFO - Iter(train) [ 83300/160000]  lr: 5.1595e-06  eta: 9:09:52  time: 0.4731  data_time: 0.0103  memory: 4856  grad_norm: 92.6534  loss: 34.5655  decode.loss_cls: 1.0748  decode.loss_mask: 0.8402  decode.loss_dice: 1.1950  decode.d0.loss_cls: 3.2625  decode.d0.loss_mask: 0.9149  decode.d0.loss_dice: 1.4730  decode.d1.loss_cls: 1.3129  decode.d1.loss_mask: 0.8609  decode.d1.loss_dice: 1.3913  decode.d2.loss_cls: 1.2203  decode.d2.loss_mask: 0.8779  decode.d2.loss_dice: 1.2864  decode.d3.loss_cls: 1.1225  decode.d3.loss_mask: 0.8538  decode.d3.loss_dice: 1.2580  decode.d4.loss_cls: 1.0434  decode.d4.loss_mask: 0.8594  decode.d4.loss_dice: 1.2472  decode.d5.loss_cls: 1.0825  decode.d5.loss_mask: 0.8262  decode.d5.loss_dice: 1.2292  decode.d6.loss_cls: 1.0421  decode.d6.loss_mask: 0.8485  decode.d6.loss_dice: 1.2239  decode.d7.loss_cls: 1.0564  decode.d7.loss_mask: 0.8512  decode.d7.loss_dice: 1.2327  decode.d8.loss_cls: 1.0232  decode.d8.loss_mask: 0.8406  decode.d8.loss_dice: 1.2149
2023/05/24 04:32:55 - mmengine - INFO - Iter(train) [ 83350/160000]  lr: 5.1565e-06  eta: 9:09:33  time: 0.4751  data_time: 0.0104  memory: 4898  grad_norm: 96.3090  loss: 37.2222  decode.loss_cls: 1.3420  decode.loss_mask: 0.7983  decode.loss_dice: 1.3312  decode.d0.loss_cls: 3.1527  decode.d0.loss_mask: 0.7990  decode.d0.loss_dice: 1.5673  decode.d1.loss_cls: 1.5029  decode.d1.loss_mask: 0.7824  decode.d1.loss_dice: 1.4601  decode.d2.loss_cls: 1.5253  decode.d2.loss_mask: 0.7594  decode.d2.loss_dice: 1.3578  decode.d3.loss_cls: 1.3706  decode.d3.loss_mask: 0.7722  decode.d3.loss_dice: 1.3459  decode.d4.loss_cls: 1.3821  decode.d4.loss_mask: 0.7559  decode.d4.loss_dice: 1.3557  decode.d5.loss_cls: 1.3056  decode.d5.loss_mask: 0.7848  decode.d5.loss_dice: 1.3836  decode.d6.loss_cls: 1.3062  decode.d6.loss_mask: 0.7825  decode.d6.loss_dice: 1.3821  decode.d7.loss_cls: 1.3366  decode.d7.loss_mask: 0.7857  decode.d7.loss_dice: 1.3545  decode.d8.loss_cls: 1.3441  decode.d8.loss_mask: 0.7730  decode.d8.loss_dice: 1.3228
2023/05/24 04:33:17 - mmengine - INFO - Iter(train) [ 83400/160000]  lr: 5.1535e-06  eta: 9:09:11  time: 0.4185  data_time: 0.0103  memory: 4857  grad_norm: 85.2740  loss: 42.1463  decode.loss_cls: 1.4905  decode.loss_mask: 0.9141  decode.loss_dice: 1.5211  decode.d0.loss_cls: 3.1328  decode.d0.loss_mask: 0.9523  decode.d0.loss_dice: 1.8579  decode.d1.loss_cls: 1.5724  decode.d1.loss_mask: 0.9456  decode.d1.loss_dice: 1.7702  decode.d2.loss_cls: 1.3991  decode.d2.loss_mask: 0.9766  decode.d2.loss_dice: 1.6610  decode.d3.loss_cls: 1.4417  decode.d3.loss_mask: 0.9464  decode.d3.loss_dice: 1.5921  decode.d4.loss_cls: 1.4326  decode.d4.loss_mask: 0.9271  decode.d4.loss_dice: 1.5982  decode.d5.loss_cls: 1.4551  decode.d5.loss_mask: 0.9286  decode.d5.loss_dice: 1.6382  decode.d6.loss_cls: 1.5026  decode.d6.loss_mask: 0.9348  decode.d6.loss_dice: 1.5815  decode.d7.loss_cls: 1.4888  decode.d7.loss_mask: 0.9328  decode.d7.loss_dice: 1.5540  decode.d8.loss_cls: 1.5329  decode.d8.loss_mask: 0.9252  decode.d8.loss_dice: 1.5401
2023/05/24 04:33:38 - mmengine - INFO - Iter(train) [ 83450/160000]  lr: 5.1504e-06  eta: 9:08:49  time: 0.4231  data_time: 0.0103  memory: 4866  grad_norm: 103.3497  loss: 36.3994  decode.loss_cls: 1.2520  decode.loss_mask: 0.8175  decode.loss_dice: 1.2503  decode.d0.loss_cls: 3.0830  decode.d0.loss_mask: 0.8738  decode.d0.loss_dice: 1.4997  decode.d1.loss_cls: 1.3808  decode.d1.loss_mask: 0.8759  decode.d1.loss_dice: 1.4617  decode.d2.loss_cls: 1.3421  decode.d2.loss_mask: 0.8748  decode.d2.loss_dice: 1.3643  decode.d3.loss_cls: 1.2853  decode.d3.loss_mask: 0.8362  decode.d3.loss_dice: 1.2608  decode.d4.loss_cls: 1.3212  decode.d4.loss_mask: 0.8376  decode.d4.loss_dice: 1.2838  decode.d5.loss_cls: 1.3312  decode.d5.loss_mask: 0.8020  decode.d5.loss_dice: 1.2644  decode.d6.loss_cls: 1.3319  decode.d6.loss_mask: 0.8046  decode.d6.loss_dice: 1.2545  decode.d7.loss_cls: 1.3159  decode.d7.loss_mask: 0.8099  decode.d7.loss_dice: 1.2635  decode.d8.loss_cls: 1.2822  decode.d8.loss_mask: 0.7864  decode.d8.loss_dice: 1.2523
2023/05/24 04:33:59 - mmengine - INFO - Iter(train) [ 83500/160000]  lr: 5.1474e-06  eta: 9:08:27  time: 0.4229  data_time: 0.0104  memory: 4829  grad_norm: 103.7908  loss: 36.7495  decode.loss_cls: 1.3886  decode.loss_mask: 0.6341  decode.loss_dice: 1.2893  decode.d0.loss_cls: 3.4283  decode.d0.loss_mask: 0.6901  decode.d0.loss_dice: 1.5229  decode.d1.loss_cls: 1.6273  decode.d1.loss_mask: 0.6889  decode.d1.loss_dice: 1.4882  decode.d2.loss_cls: 1.4502  decode.d2.loss_mask: 0.6748  decode.d2.loss_dice: 1.4139  decode.d3.loss_cls: 1.4381  decode.d3.loss_mask: 0.6362  decode.d3.loss_dice: 1.3401  decode.d4.loss_cls: 1.4217  decode.d4.loss_mask: 0.6538  decode.d4.loss_dice: 1.3760  decode.d5.loss_cls: 1.4557  decode.d5.loss_mask: 0.6491  decode.d5.loss_dice: 1.3700  decode.d6.loss_cls: 1.4634  decode.d6.loss_mask: 0.6057  decode.d6.loss_dice: 1.3183  decode.d7.loss_cls: 1.3920  decode.d7.loss_mask: 0.6138  decode.d7.loss_dice: 1.3602  decode.d8.loss_cls: 1.4338  decode.d8.loss_mask: 0.6260  decode.d8.loss_dice: 1.2987
2023/05/24 04:34:20 - mmengine - INFO - Iter(train) [ 83550/160000]  lr: 5.1444e-06  eta: 9:08:06  time: 0.4243  data_time: 0.0103  memory: 4841  grad_norm: 91.7026  loss: 36.1201  decode.loss_cls: 1.1738  decode.loss_mask: 0.7489  decode.loss_dice: 1.4496  decode.d0.loss_cls: 2.9869  decode.d0.loss_mask: 0.8590  decode.d0.loss_dice: 1.6378  decode.d1.loss_cls: 1.2280  decode.d1.loss_mask: 0.8045  decode.d1.loss_dice: 1.5431  decode.d2.loss_cls: 1.1942  decode.d2.loss_mask: 0.8145  decode.d2.loss_dice: 1.4630  decode.d3.loss_cls: 1.1780  decode.d3.loss_mask: 0.7878  decode.d3.loss_dice: 1.4201  decode.d4.loss_cls: 1.1682  decode.d4.loss_mask: 0.7794  decode.d4.loss_dice: 1.4392  decode.d5.loss_cls: 1.1554  decode.d5.loss_mask: 0.8009  decode.d5.loss_dice: 1.4650  decode.d6.loss_cls: 1.1508  decode.d6.loss_mask: 0.7769  decode.d6.loss_dice: 1.4579  decode.d7.loss_cls: 1.1056  decode.d7.loss_mask: 0.7899  decode.d7.loss_dice: 1.4383  decode.d8.loss_cls: 1.1007  decode.d8.loss_mask: 0.7730  decode.d8.loss_dice: 1.4299
2023/05/24 04:34:42 - mmengine - INFO - Iter(train) [ 83600/160000]  lr: 5.1414e-06  eta: 9:07:45  time: 0.4805  data_time: 0.0101  memory: 4866  grad_norm: 84.6736  loss: 41.9316  decode.loss_cls: 1.4706  decode.loss_mask: 0.8113  decode.loss_dice: 1.6231  decode.d0.loss_cls: 3.4339  decode.d0.loss_mask: 0.8499  decode.d0.loss_dice: 1.9172  decode.d1.loss_cls: 1.5178  decode.d1.loss_mask: 0.8304  decode.d1.loss_dice: 1.7965  decode.d2.loss_cls: 1.5499  decode.d2.loss_mask: 0.8183  decode.d2.loss_dice: 1.7189  decode.d3.loss_cls: 1.4871  decode.d3.loss_mask: 0.8095  decode.d3.loss_dice: 1.6703  decode.d4.loss_cls: 1.5392  decode.d4.loss_mask: 0.8012  decode.d4.loss_dice: 1.6269  decode.d5.loss_cls: 1.4661  decode.d5.loss_mask: 0.8087  decode.d5.loss_dice: 1.6591  decode.d6.loss_cls: 1.5142  decode.d6.loss_mask: 0.8262  decode.d6.loss_dice: 1.6409  decode.d7.loss_cls: 1.4092  decode.d7.loss_mask: 0.8155  decode.d7.loss_dice: 1.6399  decode.d8.loss_cls: 1.4226  decode.d8.loss_mask: 0.8153  decode.d8.loss_dice: 1.6421
2023/05/24 04:35:06 - mmengine - INFO - Iter(train) [ 83650/160000]  lr: 5.1383e-06  eta: 9:07:25  time: 0.4702  data_time: 0.0104  memory: 4829  grad_norm: 97.9133  loss: 43.1265  decode.loss_cls: 1.6236  decode.loss_mask: 0.8242  decode.loss_dice: 1.5774  decode.d0.loss_cls: 3.8800  decode.d0.loss_mask: 0.9410  decode.d0.loss_dice: 1.7890  decode.d1.loss_cls: 1.7528  decode.d1.loss_mask: 0.8437  decode.d1.loss_dice: 1.7145  decode.d2.loss_cls: 1.6334  decode.d2.loss_mask: 0.8392  decode.d2.loss_dice: 1.6825  decode.d3.loss_cls: 1.5873  decode.d3.loss_mask: 0.8255  decode.d3.loss_dice: 1.6342  decode.d4.loss_cls: 1.6451  decode.d4.loss_mask: 0.8052  decode.d4.loss_dice: 1.6167  decode.d5.loss_cls: 1.5574  decode.d5.loss_mask: 0.8178  decode.d5.loss_dice: 1.6052  decode.d6.loss_cls: 1.5379  decode.d6.loss_mask: 0.8506  decode.d6.loss_dice: 1.5973  decode.d7.loss_cls: 1.5573  decode.d7.loss_mask: 0.8143  decode.d7.loss_dice: 1.5853  decode.d8.loss_cls: 1.5836  decode.d8.loss_mask: 0.8128  decode.d8.loss_dice: 1.5916
2023/05/24 04:35:30 - mmengine - INFO - Iter(train) [ 83700/160000]  lr: 5.1353e-06  eta: 9:07:06  time: 0.4720  data_time: 0.0103  memory: 4829  grad_norm: 92.6787  loss: 32.1695  decode.loss_cls: 1.0358  decode.loss_mask: 0.8372  decode.loss_dice: 1.0747  decode.d0.loss_cls: 2.9979  decode.d0.loss_mask: 0.9272  decode.d0.loss_dice: 1.2619  decode.d1.loss_cls: 1.0716  decode.d1.loss_mask: 0.8430  decode.d1.loss_dice: 1.1373  decode.d2.loss_cls: 1.0904  decode.d2.loss_mask: 0.8753  decode.d2.loss_dice: 1.1216  decode.d3.loss_cls: 1.0293  decode.d3.loss_mask: 0.8549  decode.d3.loss_dice: 1.1279  decode.d4.loss_cls: 1.0657  decode.d4.loss_mask: 0.8635  decode.d4.loss_dice: 1.0990  decode.d5.loss_cls: 1.0240  decode.d5.loss_mask: 0.8791  decode.d5.loss_dice: 1.0804  decode.d6.loss_cls: 1.0213  decode.d6.loss_mask: 0.8572  decode.d6.loss_dice: 1.1006  decode.d7.loss_cls: 0.9700  decode.d7.loss_mask: 0.8548  decode.d7.loss_dice: 1.1065  decode.d8.loss_cls: 1.0370  decode.d8.loss_mask: 0.8434  decode.d8.loss_dice: 1.0809
2023/05/24 04:35:51 - mmengine - INFO - Iter(train) [ 83750/160000]  lr: 5.1323e-06  eta: 9:06:44  time: 0.4641  data_time: 0.0103  memory: 4805  grad_norm: 123.5489  loss: 32.3591  decode.loss_cls: 1.2117  decode.loss_mask: 0.6751  decode.loss_dice: 1.0635  decode.d0.loss_cls: 3.0954  decode.d0.loss_mask: 0.7142  decode.d0.loss_dice: 1.3060  decode.d1.loss_cls: 1.2592  decode.d1.loss_mask: 0.7891  decode.d1.loss_dice: 1.2077  decode.d2.loss_cls: 1.2652  decode.d2.loss_mask: 0.7085  decode.d2.loss_dice: 1.1073  decode.d3.loss_cls: 1.2380  decode.d3.loss_mask: 0.7323  decode.d3.loss_dice: 1.0760  decode.d4.loss_cls: 1.1865  decode.d4.loss_mask: 0.7309  decode.d4.loss_dice: 1.0787  decode.d5.loss_cls: 1.1690  decode.d5.loss_mask: 0.7298  decode.d5.loss_dice: 1.0863  decode.d6.loss_cls: 1.2348  decode.d6.loss_mask: 0.6794  decode.d6.loss_dice: 1.0617  decode.d7.loss_cls: 1.2470  decode.d7.loss_mask: 0.6883  decode.d7.loss_dice: 1.0614  decode.d8.loss_cls: 1.1852  decode.d8.loss_mask: 0.7028  decode.d8.loss_dice: 1.0682
2023/05/24 04:36:12 - mmengine - INFO - Iter(train) [ 83800/160000]  lr: 5.1293e-06  eta: 9:06:22  time: 0.4143  data_time: 0.0106  memory: 4839  grad_norm: 129.8482  loss: 44.4255  decode.loss_cls: 1.5972  decode.loss_mask: 1.0398  decode.loss_dice: 1.5423  decode.d0.loss_cls: 3.3958  decode.d0.loss_mask: 1.1044  decode.d0.loss_dice: 1.8158  decode.d1.loss_cls: 1.6321  decode.d1.loss_mask: 1.0390  decode.d1.loss_dice: 1.7088  decode.d2.loss_cls: 1.6885  decode.d2.loss_mask: 1.0135  decode.d2.loss_dice: 1.6307  decode.d3.loss_cls: 1.6259  decode.d3.loss_mask: 1.0129  decode.d3.loss_dice: 1.6223  decode.d4.loss_cls: 1.6359  decode.d4.loss_mask: 1.0134  decode.d4.loss_dice: 1.5998  decode.d5.loss_cls: 1.5933  decode.d5.loss_mask: 1.0279  decode.d5.loss_dice: 1.6288  decode.d6.loss_cls: 1.6423  decode.d6.loss_mask: 1.0296  decode.d6.loss_dice: 1.5770  decode.d7.loss_cls: 1.5508  decode.d7.loss_mask: 1.0250  decode.d7.loss_dice: 1.5335  decode.d8.loss_cls: 1.5147  decode.d8.loss_mask: 1.0140  decode.d8.loss_dice: 1.5706
2023/05/24 04:36:33 - mmengine - INFO - Iter(train) [ 83850/160000]  lr: 5.1262e-06  eta: 9:06:00  time: 0.4154  data_time: 0.0110  memory: 4822  grad_norm: 90.1410  loss: 32.9278  decode.loss_cls: 1.1090  decode.loss_mask: 0.7212  decode.loss_dice: 1.1093  decode.d0.loss_cls: 3.4844  decode.d0.loss_mask: 0.7831  decode.d0.loss_dice: 1.3653  decode.d1.loss_cls: 1.2001  decode.d1.loss_mask: 0.8118  decode.d1.loss_dice: 1.2410  decode.d2.loss_cls: 1.1332  decode.d2.loss_mask: 0.7973  decode.d2.loss_dice: 1.2312  decode.d3.loss_cls: 1.1724  decode.d3.loss_mask: 0.7682  decode.d3.loss_dice: 1.1700  decode.d4.loss_cls: 1.1350  decode.d4.loss_mask: 0.7806  decode.d4.loss_dice: 1.1660  decode.d5.loss_cls: 1.1169  decode.d5.loss_mask: 0.7345  decode.d5.loss_dice: 1.1377  decode.d6.loss_cls: 1.0963  decode.d6.loss_mask: 0.7120  decode.d6.loss_dice: 1.1114  decode.d7.loss_cls: 1.0923  decode.d7.loss_mask: 0.7211  decode.d7.loss_dice: 1.1155  decode.d8.loss_cls: 1.0763  decode.d8.loss_mask: 0.7151  decode.d8.loss_dice: 1.1197
2023/05/24 04:36:55 - mmengine - INFO - Iter(train) [ 83900/160000]  lr: 5.1232e-06  eta: 9:05:39  time: 0.4667  data_time: 0.0105  memory: 4876  grad_norm: 146.7418  loss: 33.1972  decode.loss_cls: 1.0776  decode.loss_mask: 0.8670  decode.loss_dice: 1.1623  decode.d0.loss_cls: 2.8192  decode.d0.loss_mask: 0.9170  decode.d0.loss_dice: 1.3276  decode.d1.loss_cls: 1.2598  decode.d1.loss_mask: 0.8805  decode.d1.loss_dice: 1.2090  decode.d2.loss_cls: 1.1046  decode.d2.loss_mask: 0.8670  decode.d2.loss_dice: 1.1668  decode.d3.loss_cls: 1.0591  decode.d3.loss_mask: 0.8881  decode.d3.loss_dice: 1.1631  decode.d4.loss_cls: 1.1272  decode.d4.loss_mask: 0.8556  decode.d4.loss_dice: 1.0895  decode.d5.loss_cls: 1.0490  decode.d5.loss_mask: 0.8806  decode.d5.loss_dice: 1.1241  decode.d6.loss_cls: 1.0845  decode.d6.loss_mask: 0.8637  decode.d6.loss_dice: 1.1436  decode.d7.loss_cls: 1.0211  decode.d7.loss_mask: 0.9038  decode.d7.loss_dice: 1.1807  decode.d8.loss_cls: 1.0902  decode.d8.loss_mask: 0.8764  decode.d8.loss_dice: 1.1385
2023/05/24 04:37:18 - mmengine - INFO - Iter(train) [ 83950/160000]  lr: 5.1202e-06  eta: 9:05:19  time: 0.4743  data_time: 0.0103  memory: 4864  grad_norm: 85.3673  loss: 34.2512  decode.loss_cls: 1.1414  decode.loss_mask: 0.8028  decode.loss_dice: 1.2330  decode.d0.loss_cls: 3.1590  decode.d0.loss_mask: 0.9133  decode.d0.loss_dice: 1.3879  decode.d1.loss_cls: 1.2691  decode.d1.loss_mask: 0.8722  decode.d1.loss_dice: 1.3603  decode.d2.loss_cls: 1.0932  decode.d2.loss_mask: 0.8346  decode.d2.loss_dice: 1.2872  decode.d3.loss_cls: 1.0523  decode.d3.loss_mask: 0.8178  decode.d3.loss_dice: 1.2506  decode.d4.loss_cls: 0.9789  decode.d4.loss_mask: 0.8376  decode.d4.loss_dice: 1.2715  decode.d5.loss_cls: 1.0387  decode.d5.loss_mask: 0.8083  decode.d5.loss_dice: 1.2645  decode.d6.loss_cls: 1.1297  decode.d6.loss_mask: 0.8181  decode.d6.loss_dice: 1.2442  decode.d7.loss_cls: 1.1051  decode.d7.loss_mask: 0.8119  decode.d7.loss_dice: 1.2474  decode.d8.loss_cls: 1.1859  decode.d8.loss_mask: 0.8050  decode.d8.loss_dice: 1.2295
2023/05/24 04:37:41 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 04:37:41 - mmengine - INFO - Iter(train) [ 84000/160000]  lr: 5.1171e-06  eta: 9:04:59  time: 0.4644  data_time: 0.0104  memory: 4865  grad_norm: 98.1601  loss: 25.9835  decode.loss_cls: 0.9974  decode.loss_mask: 0.6025  decode.loss_dice: 0.7404  decode.d0.loss_cls: 3.0780  decode.d0.loss_mask: 0.6424  decode.d0.loss_dice: 0.8616  decode.d1.loss_cls: 1.1516  decode.d1.loss_mask: 0.6052  decode.d1.loss_dice: 0.7568  decode.d2.loss_cls: 1.0909  decode.d2.loss_mask: 0.6057  decode.d2.loss_dice: 0.7815  decode.d3.loss_cls: 1.0143  decode.d3.loss_mask: 0.6019  decode.d3.loss_dice: 0.7709  decode.d4.loss_cls: 1.0092  decode.d4.loss_mask: 0.6026  decode.d4.loss_dice: 0.7263  decode.d5.loss_cls: 1.0144  decode.d5.loss_mask: 0.6293  decode.d5.loss_dice: 0.7314  decode.d6.loss_cls: 1.0325  decode.d6.loss_mask: 0.5910  decode.d6.loss_dice: 0.7270  decode.d7.loss_cls: 0.9822  decode.d7.loss_mask: 0.6095  decode.d7.loss_dice: 0.7281  decode.d8.loss_cls: 0.9977  decode.d8.loss_mask: 0.5765  decode.d8.loss_dice: 0.7243
2023/05/24 04:37:41 - mmengine - INFO - Saving checkpoint at 84000 iterations
2023/05/24 04:38:09 - mmengine - INFO - Iter(train) [ 84050/160000]  lr: 5.1141e-06  eta: 9:04:43  time: 0.4312  data_time: 0.0105  memory: 4844  grad_norm: 92.0923  loss: 33.4709  decode.loss_cls: 1.0883  decode.loss_mask: 0.8323  decode.loss_dice: 1.1887  decode.d0.loss_cls: 2.8695  decode.d0.loss_mask: 0.9597  decode.d0.loss_dice: 1.2823  decode.d1.loss_cls: 1.0971  decode.d1.loss_mask: 0.8974  decode.d1.loss_dice: 1.2564  decode.d2.loss_cls: 1.1105  decode.d2.loss_mask: 0.8882  decode.d2.loss_dice: 1.2375  decode.d3.loss_cls: 1.0624  decode.d3.loss_mask: 0.9135  decode.d3.loss_dice: 1.2169  decode.d4.loss_cls: 1.0873  decode.d4.loss_mask: 0.8612  decode.d4.loss_dice: 1.1942  decode.d5.loss_cls: 1.0686  decode.d5.loss_mask: 0.8441  decode.d5.loss_dice: 1.2014  decode.d6.loss_cls: 1.0906  decode.d6.loss_mask: 0.8283  decode.d6.loss_dice: 1.1596  decode.d7.loss_cls: 1.0917  decode.d7.loss_mask: 0.8562  decode.d7.loss_dice: 1.1657  decode.d8.loss_cls: 1.1039  decode.d8.loss_mask: 0.8301  decode.d8.loss_dice: 1.1872
2023/05/24 04:38:30 - mmengine - INFO - Iter(train) [ 84100/160000]  lr: 5.1111e-06  eta: 9:04:21  time: 0.4214  data_time: 0.0104  memory: 4875  grad_norm: 87.2633  loss: 32.9815  decode.loss_cls: 1.1439  decode.loss_mask: 0.8396  decode.loss_dice: 1.1307  decode.d0.loss_cls: 2.9332  decode.d0.loss_mask: 0.8974  decode.d0.loss_dice: 1.3064  decode.d1.loss_cls: 1.3075  decode.d1.loss_mask: 0.7683  decode.d1.loss_dice: 1.1780  decode.d2.loss_cls: 1.2307  decode.d2.loss_mask: 0.7569  decode.d2.loss_dice: 1.0919  decode.d3.loss_cls: 1.1856  decode.d3.loss_mask: 0.7447  decode.d3.loss_dice: 1.1064  decode.d4.loss_cls: 1.1923  decode.d4.loss_mask: 0.7613  decode.d4.loss_dice: 1.1364  decode.d5.loss_cls: 1.1666  decode.d5.loss_mask: 0.7578  decode.d5.loss_dice: 1.1183  decode.d6.loss_cls: 1.1482  decode.d6.loss_mask: 0.8222  decode.d6.loss_dice: 1.1078  decode.d7.loss_cls: 1.1377  decode.d7.loss_mask: 0.8296  decode.d7.loss_dice: 1.1254  decode.d8.loss_cls: 1.1324  decode.d8.loss_mask: 0.8230  decode.d8.loss_dice: 1.1011
2023/05/24 04:38:51 - mmengine - INFO - Iter(train) [ 84150/160000]  lr: 5.1080e-06  eta: 9:03:59  time: 0.4121  data_time: 0.0105  memory: 4829  grad_norm: 106.2433  loss: 36.4398  decode.loss_cls: 1.1945  decode.loss_mask: 0.8024  decode.loss_dice: 1.2891  decode.d0.loss_cls: 3.4518  decode.d0.loss_mask: 0.9724  decode.d0.loss_dice: 1.6804  decode.d1.loss_cls: 1.3929  decode.d1.loss_mask: 0.8405  decode.d1.loss_dice: 1.4493  decode.d2.loss_cls: 1.3310  decode.d2.loss_mask: 0.8223  decode.d2.loss_dice: 1.3344  decode.d3.loss_cls: 1.2267  decode.d3.loss_mask: 0.8039  decode.d3.loss_dice: 1.3201  decode.d4.loss_cls: 1.1799  decode.d4.loss_mask: 0.8163  decode.d4.loss_dice: 1.3206  decode.d5.loss_cls: 1.2538  decode.d5.loss_mask: 0.8023  decode.d5.loss_dice: 1.2827  decode.d6.loss_cls: 1.2056  decode.d6.loss_mask: 0.8072  decode.d6.loss_dice: 1.2898  decode.d7.loss_cls: 1.1864  decode.d7.loss_mask: 0.8068  decode.d7.loss_dice: 1.2850  decode.d8.loss_cls: 1.1785  decode.d8.loss_mask: 0.8160  decode.d8.loss_dice: 1.2972
2023/05/24 04:39:12 - mmengine - INFO - Iter(train) [ 84200/160000]  lr: 5.1050e-06  eta: 9:03:37  time: 0.4086  data_time: 0.0102  memory: 4830  grad_norm: 92.5804  loss: 35.7771  decode.loss_cls: 1.2880  decode.loss_mask: 0.9514  decode.loss_dice: 1.0888  decode.d0.loss_cls: 3.1558  decode.d0.loss_mask: 1.0252  decode.d0.loss_dice: 1.3331  decode.d1.loss_cls: 1.4106  decode.d1.loss_mask: 0.8723  decode.d1.loss_dice: 1.1931  decode.d2.loss_cls: 1.3097  decode.d2.loss_mask: 0.9443  decode.d2.loss_dice: 1.1535  decode.d3.loss_cls: 1.3533  decode.d3.loss_mask: 0.9341  decode.d3.loss_dice: 1.1209  decode.d4.loss_cls: 1.2933  decode.d4.loss_mask: 0.9435  decode.d4.loss_dice: 1.1136  decode.d5.loss_cls: 1.3244  decode.d5.loss_mask: 0.9270  decode.d5.loss_dice: 1.1056  decode.d6.loss_cls: 1.3142  decode.d6.loss_mask: 0.9106  decode.d6.loss_dice: 1.1037  decode.d7.loss_cls: 1.3070  decode.d7.loss_mask: 0.9192  decode.d7.loss_dice: 1.0801  decode.d8.loss_cls: 1.2958  decode.d8.loss_mask: 0.9235  decode.d8.loss_dice: 1.0815
2023/05/24 04:39:34 - mmengine - INFO - Iter(train) [ 84250/160000]  lr: 5.1020e-06  eta: 9:03:16  time: 0.4157  data_time: 0.0106  memory: 4886  grad_norm: 108.2759  loss: 41.2031  decode.loss_cls: 1.3614  decode.loss_mask: 0.9011  decode.loss_dice: 1.5141  decode.d0.loss_cls: 3.3469  decode.d0.loss_mask: 0.9982  decode.d0.loss_dice: 1.8022  decode.d1.loss_cls: 1.5158  decode.d1.loss_mask: 0.9749  decode.d1.loss_dice: 1.7407  decode.d2.loss_cls: 1.5175  decode.d2.loss_mask: 0.9263  decode.d2.loss_dice: 1.6183  decode.d3.loss_cls: 1.4559  decode.d3.loss_mask: 0.9022  decode.d3.loss_dice: 1.5721  decode.d4.loss_cls: 1.3836  decode.d4.loss_mask: 0.9081  decode.d4.loss_dice: 1.5827  decode.d5.loss_cls: 1.3520  decode.d5.loss_mask: 0.8974  decode.d5.loss_dice: 1.5636  decode.d6.loss_cls: 1.3725  decode.d6.loss_mask: 0.8923  decode.d6.loss_dice: 1.5247  decode.d7.loss_cls: 1.3449  decode.d7.loss_mask: 0.9002  decode.d7.loss_dice: 1.5245  decode.d8.loss_cls: 1.3738  decode.d8.loss_mask: 0.8987  decode.d8.loss_dice: 1.5362
2023/05/24 04:39:56 - mmengine - INFO - Iter(train) [ 84300/160000]  lr: 5.0989e-06  eta: 9:02:54  time: 0.4207  data_time: 0.0104  memory: 4846  grad_norm: 109.1115  loss: 36.2109  decode.loss_cls: 1.3593  decode.loss_mask: 0.7638  decode.loss_dice: 1.2493  decode.d0.loss_cls: 3.2901  decode.d0.loss_mask: 0.8274  decode.d0.loss_dice: 1.4190  decode.d1.loss_cls: 1.4297  decode.d1.loss_mask: 0.7830  decode.d1.loss_dice: 1.3441  decode.d2.loss_cls: 1.4454  decode.d2.loss_mask: 0.7216  decode.d2.loss_dice: 1.2915  decode.d3.loss_cls: 1.4122  decode.d3.loss_mask: 0.7140  decode.d3.loss_dice: 1.2177  decode.d4.loss_cls: 1.4346  decode.d4.loss_mask: 0.7448  decode.d4.loss_dice: 1.2149  decode.d5.loss_cls: 1.4038  decode.d5.loss_mask: 0.7499  decode.d5.loss_dice: 1.2399  decode.d6.loss_cls: 1.4004  decode.d6.loss_mask: 0.7366  decode.d6.loss_dice: 1.2461  decode.d7.loss_cls: 1.3622  decode.d7.loss_mask: 0.7504  decode.d7.loss_dice: 1.2680  decode.d8.loss_cls: 1.4008  decode.d8.loss_mask: 0.7684  decode.d8.loss_dice: 1.2221
2023/05/24 04:40:18 - mmengine - INFO - Iter(train) [ 84350/160000]  lr: 5.0959e-06  eta: 9:02:34  time: 0.4418  data_time: 0.0102  memory: 4824  grad_norm: 92.7298  loss: 32.2901  decode.loss_cls: 1.2879  decode.loss_mask: 0.7582  decode.loss_dice: 0.9891  decode.d0.loss_cls: 2.7178  decode.d0.loss_mask: 0.6984  decode.d0.loss_dice: 1.1059  decode.d1.loss_cls: 1.3428  decode.d1.loss_mask: 0.7358  decode.d1.loss_dice: 1.0917  decode.d2.loss_cls: 1.2979  decode.d2.loss_mask: 0.7435  decode.d2.loss_dice: 1.0272  decode.d3.loss_cls: 1.3284  decode.d3.loss_mask: 0.7516  decode.d3.loss_dice: 1.0195  decode.d4.loss_cls: 1.3233  decode.d4.loss_mask: 0.7377  decode.d4.loss_dice: 1.0204  decode.d5.loss_cls: 1.3424  decode.d5.loss_mask: 0.7362  decode.d5.loss_dice: 1.0141  decode.d6.loss_cls: 1.2984  decode.d6.loss_mask: 0.7642  decode.d6.loss_dice: 1.0218  decode.d7.loss_cls: 1.3311  decode.d7.loss_mask: 0.7438  decode.d7.loss_dice: 1.0203  decode.d8.loss_cls: 1.2985  decode.d8.loss_mask: 0.7430  decode.d8.loss_dice: 0.9989
2023/05/24 04:40:39 - mmengine - INFO - Iter(train) [ 84400/160000]  lr: 5.0929e-06  eta: 9:02:12  time: 0.4178  data_time: 0.0106  memory: 4792  grad_norm: 111.8672  loss: 34.5549  decode.loss_cls: 1.2123  decode.loss_mask: 0.8010  decode.loss_dice: 1.1196  decode.d0.loss_cls: 3.1270  decode.d0.loss_mask: 0.8820  decode.d0.loss_dice: 1.3921  decode.d1.loss_cls: 1.3329  decode.d1.loss_mask: 0.8662  decode.d1.loss_dice: 1.3102  decode.d2.loss_cls: 1.3399  decode.d2.loss_mask: 0.8444  decode.d2.loss_dice: 1.2217  decode.d3.loss_cls: 1.2788  decode.d3.loss_mask: 0.8407  decode.d3.loss_dice: 1.1786  decode.d4.loss_cls: 1.2527  decode.d4.loss_mask: 0.8337  decode.d4.loss_dice: 1.1697  decode.d5.loss_cls: 1.2198  decode.d5.loss_mask: 0.8052  decode.d5.loss_dice: 1.1350  decode.d6.loss_cls: 1.2093  decode.d6.loss_mask: 0.8133  decode.d6.loss_dice: 1.1100  decode.d7.loss_cls: 1.2337  decode.d7.loss_mask: 0.8044  decode.d7.loss_dice: 1.0771  decode.d8.loss_cls: 1.2111  decode.d8.loss_mask: 0.8067  decode.d8.loss_dice: 1.1258
2023/05/24 04:41:00 - mmengine - INFO - Iter(train) [ 84450/160000]  lr: 5.0899e-06  eta: 9:01:50  time: 0.4150  data_time: 0.0106  memory: 4872  grad_norm: 99.8125  loss: 40.2022  decode.loss_cls: 1.3645  decode.loss_mask: 0.8542  decode.loss_dice: 1.4647  decode.d0.loss_cls: 3.3999  decode.d0.loss_mask: 1.0170  decode.d0.loss_dice: 1.7757  decode.d1.loss_cls: 1.5916  decode.d1.loss_mask: 0.9617  decode.d1.loss_dice: 1.5793  decode.d2.loss_cls: 1.4476  decode.d2.loss_mask: 0.9108  decode.d2.loss_dice: 1.5466  decode.d3.loss_cls: 1.3800  decode.d3.loss_mask: 0.8841  decode.d3.loss_dice: 1.4896  decode.d4.loss_cls: 1.3967  decode.d4.loss_mask: 0.8933  decode.d4.loss_dice: 1.4859  decode.d5.loss_cls: 1.3476  decode.d5.loss_mask: 0.8705  decode.d5.loss_dice: 1.4485  decode.d6.loss_cls: 1.3734  decode.d6.loss_mask: 0.8684  decode.d6.loss_dice: 1.4953  decode.d7.loss_cls: 1.3562  decode.d7.loss_mask: 0.8570  decode.d7.loss_dice: 1.4627  decode.d8.loss_cls: 1.3227  decode.d8.loss_mask: 0.8960  decode.d8.loss_dice: 1.4609
2023/05/24 04:41:21 - mmengine - INFO - Iter(train) [ 84500/160000]  lr: 5.0868e-06  eta: 9:01:28  time: 0.4232  data_time: 0.0102  memory: 4928  grad_norm: 92.0490  loss: 33.6715  decode.loss_cls: 1.2414  decode.loss_mask: 0.7532  decode.loss_dice: 1.1109  decode.d0.loss_cls: 3.0505  decode.d0.loss_mask: 0.8364  decode.d0.loss_dice: 1.2948  decode.d1.loss_cls: 1.2771  decode.d1.loss_mask: 0.7611  decode.d1.loss_dice: 1.2454  decode.d2.loss_cls: 1.2923  decode.d2.loss_mask: 0.7651  decode.d2.loss_dice: 1.1842  decode.d3.loss_cls: 1.2362  decode.d3.loss_mask: 0.7487  decode.d3.loss_dice: 1.1413  decode.d4.loss_cls: 1.1961  decode.d4.loss_mask: 0.7710  decode.d4.loss_dice: 1.1536  decode.d5.loss_cls: 1.2159  decode.d5.loss_mask: 0.7618  decode.d5.loss_dice: 1.1641  decode.d6.loss_cls: 1.1614  decode.d6.loss_mask: 0.8132  decode.d6.loss_dice: 1.1680  decode.d7.loss_cls: 1.2340  decode.d7.loss_mask: 0.8156  decode.d7.loss_dice: 1.1396  decode.d8.loss_cls: 1.2298  decode.d8.loss_mask: 0.7754  decode.d8.loss_dice: 1.1333
2023/05/24 04:41:42 - mmengine - INFO - Iter(train) [ 84550/160000]  lr: 5.0838e-06  eta: 9:01:06  time: 0.4151  data_time: 0.0101  memory: 4835  grad_norm: 100.3715  loss: 36.1642  decode.loss_cls: 1.2849  decode.loss_mask: 0.7243  decode.loss_dice: 1.3032  decode.d0.loss_cls: 3.3902  decode.d0.loss_mask: 0.7898  decode.d0.loss_dice: 1.5697  decode.d1.loss_cls: 1.4961  decode.d1.loss_mask: 0.7555  decode.d1.loss_dice: 1.3847  decode.d2.loss_cls: 1.3559  decode.d2.loss_mask: 0.7580  decode.d2.loss_dice: 1.3128  decode.d3.loss_cls: 1.3182  decode.d3.loss_mask: 0.7283  decode.d3.loss_dice: 1.2938  decode.d4.loss_cls: 1.2822  decode.d4.loss_mask: 0.7277  decode.d4.loss_dice: 1.3142  decode.d5.loss_cls: 1.3210  decode.d5.loss_mask: 0.7306  decode.d5.loss_dice: 1.2723  decode.d6.loss_cls: 1.3425  decode.d6.loss_mask: 0.7227  decode.d6.loss_dice: 1.2987  decode.d7.loss_cls: 1.3037  decode.d7.loss_mask: 0.7266  decode.d7.loss_dice: 1.3108  decode.d8.loss_cls: 1.2853  decode.d8.loss_mask: 0.7443  decode.d8.loss_dice: 1.3163
2023/05/24 04:42:03 - mmengine - INFO - Iter(train) [ 84600/160000]  lr: 5.0808e-06  eta: 9:00:44  time: 0.4237  data_time: 0.0109  memory: 4843  grad_norm: 99.6104  loss: 34.5380  decode.loss_cls: 1.1598  decode.loss_mask: 0.7613  decode.loss_dice: 1.2622  decode.d0.loss_cls: 2.9828  decode.d0.loss_mask: 0.8312  decode.d0.loss_dice: 1.4683  decode.d1.loss_cls: 1.2950  decode.d1.loss_mask: 0.7646  decode.d1.loss_dice: 1.3574  decode.d2.loss_cls: 1.2661  decode.d2.loss_mask: 0.7745  decode.d2.loss_dice: 1.2494  decode.d3.loss_cls: 1.2696  decode.d3.loss_mask: 0.7644  decode.d3.loss_dice: 1.2605  decode.d4.loss_cls: 1.2410  decode.d4.loss_mask: 0.7660  decode.d4.loss_dice: 1.2585  decode.d5.loss_cls: 1.2102  decode.d5.loss_mask: 0.7621  decode.d5.loss_dice: 1.2407  decode.d6.loss_cls: 1.2247  decode.d6.loss_mask: 0.7630  decode.d6.loss_dice: 1.2098  decode.d7.loss_cls: 1.2072  decode.d7.loss_mask: 0.7560  decode.d7.loss_dice: 1.2322  decode.d8.loss_cls: 1.1840  decode.d8.loss_mask: 0.7731  decode.d8.loss_dice: 1.2422
2023/05/24 04:42:25 - mmengine - INFO - Iter(train) [ 84650/160000]  lr: 5.0777e-06  eta: 9:00:23  time: 0.4192  data_time: 0.0105  memory: 4882  grad_norm: 84.0513  loss: 40.9253  decode.loss_cls: 1.3272  decode.loss_mask: 0.9039  decode.loss_dice: 1.5589  decode.d0.loss_cls: 3.4404  decode.d0.loss_mask: 0.8971  decode.d0.loss_dice: 1.7565  decode.d1.loss_cls: 1.5180  decode.d1.loss_mask: 0.8546  decode.d1.loss_dice: 1.6543  decode.d2.loss_cls: 1.4498  decode.d2.loss_mask: 0.8733  decode.d2.loss_dice: 1.6463  decode.d3.loss_cls: 1.4976  decode.d3.loss_mask: 0.8563  decode.d3.loss_dice: 1.5540  decode.d4.loss_cls: 1.3916  decode.d4.loss_mask: 0.8906  decode.d4.loss_dice: 1.5781  decode.d5.loss_cls: 1.4299  decode.d5.loss_mask: 0.8422  decode.d5.loss_dice: 1.5321  decode.d6.loss_cls: 1.3749  decode.d6.loss_mask: 0.8936  decode.d6.loss_dice: 1.5572  decode.d7.loss_cls: 1.4339  decode.d7.loss_mask: 0.8695  decode.d7.loss_dice: 1.5515  decode.d8.loss_cls: 1.3670  decode.d8.loss_mask: 0.8843  decode.d8.loss_dice: 1.5410
2023/05/24 04:42:46 - mmengine - INFO - Iter(train) [ 84700/160000]  lr: 5.0747e-06  eta: 9:00:01  time: 0.4231  data_time: 0.0106  memory: 4828  grad_norm: 97.6017  loss: 29.6121  decode.loss_cls: 1.0406  decode.loss_mask: 0.6783  decode.loss_dice: 1.0464  decode.d0.loss_cls: 2.5747  decode.d0.loss_mask: 0.7408  decode.d0.loss_dice: 1.1425  decode.d1.loss_cls: 1.1002  decode.d1.loss_mask: 0.6851  decode.d1.loss_dice: 1.0830  decode.d2.loss_cls: 1.0281  decode.d2.loss_mask: 0.7111  decode.d2.loss_dice: 1.1178  decode.d3.loss_cls: 1.0551  decode.d3.loss_mask: 0.6884  decode.d3.loss_dice: 1.0804  decode.d4.loss_cls: 1.1112  decode.d4.loss_mask: 0.6603  decode.d4.loss_dice: 1.0438  decode.d5.loss_cls: 1.0442  decode.d5.loss_mask: 0.6774  decode.d5.loss_dice: 1.0720  decode.d6.loss_cls: 1.0134  decode.d6.loss_mask: 0.6657  decode.d6.loss_dice: 1.0802  decode.d7.loss_cls: 0.9906  decode.d7.loss_mask: 0.6749  decode.d7.loss_dice: 1.0683  decode.d8.loss_cls: 1.0153  decode.d8.loss_mask: 0.6727  decode.d8.loss_dice: 1.0495
2023/05/24 04:43:08 - mmengine - INFO - Iter(train) [ 84750/160000]  lr: 5.0717e-06  eta: 8:59:40  time: 0.4782  data_time: 0.0107  memory: 4889  grad_norm: 117.8115  loss: 34.6748  decode.loss_cls: 1.1349  decode.loss_mask: 0.7980  decode.loss_dice: 1.2203  decode.d0.loss_cls: 3.1149  decode.d0.loss_mask: 0.8916  decode.d0.loss_dice: 1.4223  decode.d1.loss_cls: 1.3110  decode.d1.loss_mask: 0.8244  decode.d1.loss_dice: 1.3419  decode.d2.loss_cls: 1.1846  decode.d2.loss_mask: 0.8390  decode.d2.loss_dice: 1.3487  decode.d3.loss_cls: 1.1163  decode.d3.loss_mask: 0.8697  decode.d3.loss_dice: 1.2914  decode.d4.loss_cls: 1.1514  decode.d4.loss_mask: 0.8494  decode.d4.loss_dice: 1.2601  decode.d5.loss_cls: 1.1113  decode.d5.loss_mask: 0.8225  decode.d5.loss_dice: 1.2850  decode.d6.loss_cls: 1.1316  decode.d6.loss_mask: 0.8212  decode.d6.loss_dice: 1.2437  decode.d7.loss_cls: 1.1242  decode.d7.loss_mask: 0.8123  decode.d7.loss_dice: 1.2427  decode.d8.loss_cls: 1.1027  decode.d8.loss_mask: 0.7944  decode.d8.loss_dice: 1.2131
2023/05/24 04:43:31 - mmengine - INFO - Iter(train) [ 84800/160000]  lr: 5.0686e-06  eta: 8:59:19  time: 0.4268  data_time: 0.0106  memory: 4836  grad_norm: 100.4856  loss: 26.6441  decode.loss_cls: 0.9301  decode.loss_mask: 0.5834  decode.loss_dice: 0.9030  decode.d0.loss_cls: 2.7232  decode.d0.loss_mask: 0.5974  decode.d0.loss_dice: 1.0217  decode.d1.loss_cls: 1.0017  decode.d1.loss_mask: 0.5753  decode.d1.loss_dice: 1.0135  decode.d2.loss_cls: 0.9815  decode.d2.loss_mask: 0.5746  decode.d2.loss_dice: 0.9783  decode.d3.loss_cls: 0.9488  decode.d3.loss_mask: 0.5558  decode.d3.loss_dice: 0.9342  decode.d4.loss_cls: 0.9754  decode.d4.loss_mask: 0.5769  decode.d4.loss_dice: 0.9533  decode.d5.loss_cls: 0.9971  decode.d5.loss_mask: 0.5631  decode.d5.loss_dice: 0.9299  decode.d6.loss_cls: 0.9449  decode.d6.loss_mask: 0.5755  decode.d6.loss_dice: 0.9291  decode.d7.loss_cls: 0.9252  decode.d7.loss_mask: 0.5834  decode.d7.loss_dice: 0.9280  decode.d8.loss_cls: 0.9284  decode.d8.loss_mask: 0.5859  decode.d8.loss_dice: 0.9256
2023/05/24 04:43:52 - mmengine - INFO - Iter(train) [ 84850/160000]  lr: 5.0656e-06  eta: 8:58:57  time: 0.4186  data_time: 0.0105  memory: 4839  grad_norm: 101.7827  loss: 40.2725  decode.loss_cls: 1.4224  decode.loss_mask: 0.7474  decode.loss_dice: 1.5735  decode.d0.loss_cls: 3.3907  decode.d0.loss_mask: 0.8253  decode.d0.loss_dice: 1.7530  decode.d1.loss_cls: 1.5187  decode.d1.loss_mask: 0.7792  decode.d1.loss_dice: 1.6836  decode.d2.loss_cls: 1.4407  decode.d2.loss_mask: 0.7873  decode.d2.loss_dice: 1.6634  decode.d3.loss_cls: 1.4607  decode.d3.loss_mask: 0.7488  decode.d3.loss_dice: 1.5903  decode.d4.loss_cls: 1.4669  decode.d4.loss_mask: 0.7365  decode.d4.loss_dice: 1.5901  decode.d5.loss_cls: 1.5157  decode.d5.loss_mask: 0.7417  decode.d5.loss_dice: 1.6013  decode.d6.loss_cls: 1.4581  decode.d6.loss_mask: 0.7478  decode.d6.loss_dice: 1.5438  decode.d7.loss_cls: 1.4496  decode.d7.loss_mask: 0.7422  decode.d7.loss_dice: 1.5594  decode.d8.loss_cls: 1.4580  decode.d8.loss_mask: 0.7452  decode.d8.loss_dice: 1.5313
2023/05/24 04:44:13 - mmengine - INFO - Iter(train) [ 84900/160000]  lr: 5.0626e-06  eta: 8:58:35  time: 0.4267  data_time: 0.0108  memory: 4890  grad_norm: 92.0159  loss: 25.8361  decode.loss_cls: 0.7772  decode.loss_mask: 0.6248  decode.loss_dice: 0.9259  decode.d0.loss_cls: 2.7829  decode.d0.loss_mask: 0.6087  decode.d0.loss_dice: 1.0275  decode.d1.loss_cls: 0.9630  decode.d1.loss_mask: 0.6272  decode.d1.loss_dice: 0.9652  decode.d2.loss_cls: 0.8830  decode.d2.loss_mask: 0.6218  decode.d2.loss_dice: 0.9520  decode.d3.loss_cls: 0.8630  decode.d3.loss_mask: 0.6024  decode.d3.loss_dice: 0.9058  decode.d4.loss_cls: 0.8432  decode.d4.loss_mask: 0.6346  decode.d4.loss_dice: 0.8981  decode.d5.loss_cls: 0.7908  decode.d5.loss_mask: 0.5908  decode.d5.loss_dice: 0.9413  decode.d6.loss_cls: 0.8229  decode.d6.loss_mask: 0.5888  decode.d6.loss_dice: 0.9185  decode.d7.loss_cls: 0.8117  decode.d7.loss_mask: 0.5881  decode.d7.loss_dice: 0.9219  decode.d8.loss_cls: 0.8169  decode.d8.loss_mask: 0.6204  decode.d8.loss_dice: 0.9179
2023/05/24 04:44:34 - mmengine - INFO - Iter(train) [ 84950/160000]  lr: 5.0595e-06  eta: 8:58:13  time: 0.4191  data_time: 0.0103  memory: 4864  grad_norm: 90.3335  loss: 29.0174  decode.loss_cls: 1.1733  decode.loss_mask: 0.5218  decode.loss_dice: 0.9264  decode.d0.loss_cls: 3.0676  decode.d0.loss_mask: 0.5196  decode.d0.loss_dice: 1.0516  decode.d1.loss_cls: 1.2914  decode.d1.loss_mask: 0.5552  decode.d1.loss_dice: 0.9806  decode.d2.loss_cls: 1.2703  decode.d2.loss_mask: 0.5033  decode.d2.loss_dice: 0.9778  decode.d3.loss_cls: 1.2566  decode.d3.loss_mask: 0.5029  decode.d3.loss_dice: 0.9593  decode.d4.loss_cls: 1.2035  decode.d4.loss_mask: 0.5502  decode.d4.loss_dice: 0.9596  decode.d5.loss_cls: 1.2324  decode.d5.loss_mask: 0.5503  decode.d5.loss_dice: 0.9490  decode.d6.loss_cls: 1.2099  decode.d6.loss_mask: 0.5308  decode.d6.loss_dice: 0.9160  decode.d7.loss_cls: 1.2082  decode.d7.loss_mask: 0.5245  decode.d7.loss_dice: 0.9378  decode.d8.loss_cls: 1.2159  decode.d8.loss_mask: 0.5259  decode.d8.loss_dice: 0.9458
2023/05/24 04:44:55 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 04:44:55 - mmengine - INFO - Iter(train) [ 85000/160000]  lr: 5.0565e-06  eta: 8:57:51  time: 0.4154  data_time: 0.0106  memory: 4846  grad_norm: 115.1610  loss: 33.9557  decode.loss_cls: 1.1358  decode.loss_mask: 0.7091  decode.loss_dice: 1.3329  decode.d0.loss_cls: 2.8255  decode.d0.loss_mask: 0.7469  decode.d0.loss_dice: 1.6102  decode.d1.loss_cls: 1.1374  decode.d1.loss_mask: 0.7504  decode.d1.loss_dice: 1.5104  decode.d2.loss_cls: 1.1626  decode.d2.loss_mask: 0.7039  decode.d2.loss_dice: 1.4374  decode.d3.loss_cls: 1.1129  decode.d3.loss_mask: 0.6792  decode.d3.loss_dice: 1.3793  decode.d4.loss_cls: 1.1100  decode.d4.loss_mask: 0.6786  decode.d4.loss_dice: 1.3834  decode.d5.loss_cls: 1.0857  decode.d5.loss_mask: 0.7268  decode.d5.loss_dice: 1.3870  decode.d6.loss_cls: 1.1271  decode.d6.loss_mask: 0.6777  decode.d6.loss_dice: 1.3026  decode.d7.loss_cls: 1.1058  decode.d7.loss_mask: 0.6634  decode.d7.loss_dice: 1.3310  decode.d8.loss_cls: 1.0979  decode.d8.loss_mask: 0.6853  decode.d8.loss_dice: 1.3594
2023/05/24 04:44:55 - mmengine - INFO - Saving checkpoint at 85000 iterations
2023/05/24 04:45:04 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0776  data_time: 0.0018  memory: 2167  
2023/05/24 04:45:08 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:41  time: 0.0793  data_time: 0.0018  memory: 2216  
2023/05/24 04:45:12 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:38  time: 0.0793  data_time: 0.0018  memory: 2167  
2023/05/24 04:45:16 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0792  data_time: 0.0018  memory: 2104  
2023/05/24 04:45:20 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0805  data_time: 0.0019  memory: 2831  
2023/05/24 04:45:24 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0879  data_time: 0.0018  memory: 2167  
2023/05/24 04:45:28 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0801  data_time: 0.0018  memory: 2167  
2023/05/24 04:45:32 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0807  data_time: 0.0018  memory: 2167  
2023/05/24 04:45:36 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0781  data_time: 0.0018  memory: 2944  
2023/05/24 04:45:43 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.2954  data_time: 0.0020  memory: 2356  
2023/05/24 04:45:47 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.1002  data_time: 0.0022  memory: 2217  
2023/05/24 04:45:51 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0779  data_time: 0.0017  memory: 2328  
2023/05/24 04:45:55 - mmengine - INFO - per class results:
2023/05/24 04:45:55 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.19 | 93.37 |
|     bicycle      | 70.71 | 81.85 |
|       car        | 60.28 | 83.76 |
|    motorcycle    | 82.96 | 89.15 |
|     airplane     | 83.02 | 92.15 |
|       bus        | 82.49 | 88.77 |
|      train       | 82.65 |  94.3 |
|      truck       | 53.83 | 70.33 |
|       boat       | 59.32 | 81.55 |
|  traffic light   | 67.62 |  83.5 |
|   fire hydrant   | 87.47 | 95.19 |
|    stop sign     | 91.37 | 96.99 |
|  parking meter   | 76.14 | 85.08 |
|      bench       | 43.64 |  73.7 |
|       bird       | 80.95 | 89.79 |
|       cat        | 84.24 | 89.96 |
|       dog        | 78.58 | 84.44 |
|      horse       | 77.66 | 89.94 |
|      sheep       | 86.79 | 92.93 |
|       cow        | 81.79 | 88.64 |
|     elephant     | 89.15 | 95.01 |
|       bear       | 91.83 | 95.12 |
|      zebra       | 90.08 | 92.78 |
|     giraffe      | 87.22 | 92.82 |
|     backpack     | 37.03 | 60.12 |
|     umbrella     | 81.21 | 88.03 |
|     handbag      | 32.46 | 53.68 |
|       tie        | 10.28 | 13.68 |
|     suitcase     | 73.74 | 91.91 |
|     frisbee      | 64.77 | 89.45 |
|       skis       | 35.42 |  43.9 |
|    snowboard     | 47.19 | 74.61 |
|   sports ball    | 54.36 | 73.66 |
|       kite       | 65.25 | 80.24 |
|   baseball bat   | 41.55 | 54.97 |
|  baseball glove  | 71.67 | 85.47 |
|    skateboard    | 73.21 | 84.51 |
|    surfboard     | 73.48 | 86.81 |
|  tennis racket   | 80.62 | 88.84 |
|      bottle      | 39.75 | 51.63 |
|    wine glass    | 57.24 | 75.16 |
|       cup        | 51.25 | 67.93 |
|       fork       | 29.81 | 37.03 |
|      knife       | 17.26 |  21.2 |
|      spoon       | 31.16 | 44.82 |
|       bowl       | 41.38 | 63.14 |
|      banana      | 64.51 | 84.97 |
|      apple       |  49.2 | 70.53 |
|     sandwich     | 46.11 |  69.3 |
|      orange      | 53.02 | 55.33 |
|     broccoli     | 48.04 | 56.03 |
|      carrot      | 44.07 |  48.1 |
|     hot dog      | 50.96 | 61.06 |
|      pizza       | 66.96 | 78.64 |
|      donut       | 70.02 | 83.05 |
|       cake       | 58.85 | 73.94 |
|      chair       | 43.74 | 69.17 |
|      couch       | 53.08 | 70.08 |
|   potted plant   | 35.62 | 51.05 |
|       bed        | 61.54 | 84.61 |
|   dining table   | 43.27 | 80.56 |
|      toilet      | 76.59 | 93.68 |
|        tv        | 72.88 | 83.08 |
|      laptop      | 72.13 | 91.97 |
|      mouse       | 74.98 | 85.67 |
|      remote      |  61.8 | 70.89 |
|     keyboard     | 59.11 | 65.61 |
|    cell phone    |  68.4 | 89.39 |
|    microwave     | 61.95 | 76.34 |
|       oven       | 55.74 | 86.59 |
|     toaster      | 43.59 | 53.64 |
|       sink       | 51.94 | 80.71 |
|   refrigerator   | 77.64 | 91.26 |
|       book       | 44.78 | 69.82 |
|      clock       | 70.81 | 84.86 |
|       vase       | 58.68 | 84.66 |
|     scissors     | 65.99 | 90.67 |
|    teddy bear    | 74.15 | 85.32 |
|    hair drier    | 41.85 | 44.01 |
|    toothbrush    | 35.14 | 79.79 |
|      banner      | 22.14 | 72.42 |
|     blanket      |  2.9  |  3.03 |
|      branch      |  19.1 | 22.88 |
|      bridge      | 30.15 |  51.6 |
|  building-other  | 52.62 | 70.04 |
|       bush       | 30.49 | 39.63 |
|     cabinet      | 55.27 | 70.59 |
|       cage       | 24.81 | 61.42 |
|    cardboard     | 41.71 | 54.68 |
|      carpet      | 52.29 | 77.34 |
|  ceiling-other   | 63.39 | 81.47 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 19.17 |  26.6 |
|      clouds      |  47.3 | 64.39 |
|     counter      | 25.69 | 43.29 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 60.28 | 76.03 |
|    desk-stuff    | 47.37 | 65.98 |
|       dirt       | 38.93 | 53.45 |
|    door-stuff    | 37.76 | 54.18 |
|      fence       |  21.5 | 31.97 |
|   floor-marble   |  5.3  |  5.5  |
|   floor-other    | 18.58 | 22.26 |
|   floor-stone    |  0.46 |  0.49 |
|    floor-tile    | 58.39 | 71.51 |
|    floor-wood    | 63.13 | 74.92 |
|      flower      | 47.62 | 69.26 |
|       fog        |  5.1  |  5.21 |
|    food-other    | 18.78 | 21.05 |
|      fruit       | 34.32 | 54.36 |
| furniture-other  |  15.1 | 20.76 |
|      grass       | 68.58 | 85.55 |
|      gravel      | 28.04 | 45.04 |
|   ground-other   |  3.58 |  4.07 |
|       hill       | 17.02 |  20.9 |
|      house       |  21.2 | 23.49 |
|      leaves      | 27.93 | 41.27 |
|      light       | 37.07 | 51.44 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.19 | 45.46 |
|   mirror-stuff   | 45.64 | 58.81 |
|       moss       |  0.0  |  0.0  |
|     mountain     |  51.1 | 64.71 |
|       mud        |  6.4  |  7.14 |
|      napkin      |  1.82 |  1.82 |
|       net        | 46.46 | 57.31 |
|      paper       | 28.77 | 44.83 |
|     pavement     | 50.16 | 71.45 |
|      pillow      |  1.41 |  1.59 |
|   plant-other    | 20.48 | 30.55 |
|     plastic      |  21.1 |  29.4 |
|     platform     | 32.74 | 53.89 |
|   playingfield   | 69.67 | 94.64 |
|     railing      |  8.53 | 24.04 |
|     railroad     | 59.32 | 78.52 |
|      river       | 30.76 | 39.57 |
|       road       |  65.6 | 85.01 |
|       rock       | 21.85 | 29.64 |
|       roof       | 19.44 | 26.31 |
|       rug        | 22.76 | 28.71 |
|      salad       |  0.0  |  0.0  |
|       sand       | 62.27 |  68.5 |
|       sea        | 84.71 | 94.99 |
|      shelf       | 34.07 | 43.79 |
|    sky-other     | 70.58 | 85.86 |
|    skyscraper    | 34.04 | 44.59 |
|       snow       | 89.94 | 94.04 |
|   solid-other    |  0.23 |  0.24 |
|      stairs      | 19.28 | 28.87 |
|      stone       | 21.62 | 56.11 |
|      straw       | 25.05 | 30.15 |
| structural-other |  0.04 |  0.04 |
|      table       | 15.91 | 19.88 |
|       tent       |  8.83 | 14.04 |
|  textile-other   | 10.02 | 16.45 |
|      towel       | 32.82 | 42.91 |
|       tree       | 73.77 | 86.24 |
|    vegetable     | 30.66 | 40.63 |
|    wall-brick    | 48.78 | 65.33 |
|  wall-concrete   | 59.53 | 82.11 |
|    wall-other    | 14.55 | 21.19 |
|    wall-panel    |  0.84 |  0.94 |
|    wall-stone    | 35.85 | 40.54 |
|    wall-tile     | 64.54 | 83.63 |
|    wall-wood     | 39.08 |  58.1 |
|   water-other    | 20.66 |  34.0 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 52.09 | 62.98 |
|   window-other   | 47.38 | 69.98 |
|       wood       | 21.98 | 29.77 |
+------------------+-------+-------+
2023/05/24 04:45:55 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.4900  mIoU: 45.3800  mAcc: 58.0300  data_time: 0.0020  time: 0.0855
2023/05/24 04:46:16 - mmengine - INFO - Iter(train) [ 85050/160000]  lr: 5.0535e-06  eta: 8:57:31  time: 0.4203  data_time: 0.0102  memory: 4828  grad_norm: 121.8654  loss: 37.3427  decode.loss_cls: 1.1897  decode.loss_mask: 0.8385  decode.loss_dice: 1.3995  decode.d0.loss_cls: 3.0425  decode.d0.loss_mask: 0.9271  decode.d0.loss_dice: 1.6496  decode.d1.loss_cls: 1.4275  decode.d1.loss_mask: 0.8516  decode.d1.loss_dice: 1.4783  decode.d2.loss_cls: 1.3127  decode.d2.loss_mask: 0.8870  decode.d2.loss_dice: 1.4919  decode.d3.loss_cls: 1.3076  decode.d3.loss_mask: 0.8474  decode.d3.loss_dice: 1.4096  decode.d4.loss_cls: 1.3383  decode.d4.loss_mask: 0.8374  decode.d4.loss_dice: 1.4124  decode.d5.loss_cls: 1.2725  decode.d5.loss_mask: 0.8512  decode.d5.loss_dice: 1.3701  decode.d6.loss_cls: 1.2515  decode.d6.loss_mask: 0.8313  decode.d6.loss_dice: 1.3790  decode.d7.loss_cls: 1.1720  decode.d7.loss_mask: 0.8212  decode.d7.loss_dice: 1.3784  decode.d8.loss_cls: 1.1974  decode.d8.loss_mask: 0.8176  decode.d8.loss_dice: 1.3519
2023/05/24 04:46:37 - mmengine - INFO - Iter(train) [ 85100/160000]  lr: 5.0504e-06  eta: 8:57:09  time: 0.4269  data_time: 0.0104  memory: 4865  grad_norm: 95.7588  loss: 39.2186  decode.loss_cls: 1.4921  decode.loss_mask: 0.7301  decode.loss_dice: 1.4323  decode.d0.loss_cls: 3.3539  decode.d0.loss_mask: 0.7595  decode.d0.loss_dice: 1.6362  decode.d1.loss_cls: 1.6440  decode.d1.loss_mask: 0.7754  decode.d1.loss_dice: 1.5076  decode.d2.loss_cls: 1.5828  decode.d2.loss_mask: 0.7369  decode.d2.loss_dice: 1.4687  decode.d3.loss_cls: 1.5719  decode.d3.loss_mask: 0.7304  decode.d3.loss_dice: 1.4728  decode.d4.loss_cls: 1.4986  decode.d4.loss_mask: 0.7459  decode.d4.loss_dice: 1.4516  decode.d5.loss_cls: 1.5121  decode.d5.loss_mask: 0.7313  decode.d5.loss_dice: 1.4947  decode.d6.loss_cls: 1.4913  decode.d6.loss_mask: 0.7412  decode.d6.loss_dice: 1.4057  decode.d7.loss_cls: 1.4953  decode.d7.loss_mask: 0.7453  decode.d7.loss_dice: 1.4210  decode.d8.loss_cls: 1.4438  decode.d8.loss_mask: 0.7265  decode.d8.loss_dice: 1.4195
2023/05/24 04:46:59 - mmengine - INFO - Iter(train) [ 85150/160000]  lr: 5.0474e-06  eta: 8:56:48  time: 0.4162  data_time: 0.0106  memory: 4830  grad_norm: 112.5168  loss: 41.7617  decode.loss_cls: 1.4002  decode.loss_mask: 0.8679  decode.loss_dice: 1.6329  decode.d0.loss_cls: 3.4203  decode.d0.loss_mask: 0.9737  decode.d0.loss_dice: 1.8946  decode.d1.loss_cls: 1.5670  decode.d1.loss_mask: 0.8919  decode.d1.loss_dice: 1.7045  decode.d2.loss_cls: 1.4874  decode.d2.loss_mask: 0.9059  decode.d2.loss_dice: 1.6503  decode.d3.loss_cls: 1.4263  decode.d3.loss_mask: 0.9091  decode.d3.loss_dice: 1.6282  decode.d4.loss_cls: 1.3308  decode.d4.loss_mask: 0.9240  decode.d4.loss_dice: 1.6464  decode.d5.loss_cls: 1.3558  decode.d5.loss_mask: 0.9207  decode.d5.loss_dice: 1.6585  decode.d6.loss_cls: 1.3535  decode.d6.loss_mask: 0.8702  decode.d6.loss_dice: 1.6184  decode.d7.loss_cls: 1.3671  decode.d7.loss_mask: 0.8681  decode.d7.loss_dice: 1.6216  decode.d8.loss_cls: 1.3975  decode.d8.loss_mask: 0.8604  decode.d8.loss_dice: 1.6085
2023/05/24 04:47:21 - mmengine - INFO - Iter(train) [ 85200/160000]  lr: 5.0444e-06  eta: 8:56:26  time: 0.4169  data_time: 0.0108  memory: 4845  grad_norm: 79.5914  loss: 31.3214  decode.loss_cls: 0.9228  decode.loss_mask: 0.8184  decode.loss_dice: 1.1109  decode.d0.loss_cls: 2.8300  decode.d0.loss_mask: 0.8200  decode.d0.loss_dice: 1.3367  decode.d1.loss_cls: 1.0581  decode.d1.loss_mask: 0.8442  decode.d1.loss_dice: 1.2218  decode.d2.loss_cls: 0.9875  decode.d2.loss_mask: 0.8140  decode.d2.loss_dice: 1.2013  decode.d3.loss_cls: 0.9631  decode.d3.loss_mask: 0.8145  decode.d3.loss_dice: 1.1206  decode.d4.loss_cls: 0.9450  decode.d4.loss_mask: 0.8469  decode.d4.loss_dice: 1.1547  decode.d5.loss_cls: 0.9360  decode.d5.loss_mask: 0.8099  decode.d5.loss_dice: 1.1525  decode.d6.loss_cls: 0.9470  decode.d6.loss_mask: 0.8235  decode.d6.loss_dice: 1.1206  decode.d7.loss_cls: 0.9212  decode.d7.loss_mask: 0.8271  decode.d7.loss_dice: 1.1247  decode.d8.loss_cls: 0.9315  decode.d8.loss_mask: 0.8014  decode.d8.loss_dice: 1.1155
2023/05/24 04:47:42 - mmengine - INFO - Iter(train) [ 85250/160000]  lr: 5.0413e-06  eta: 8:56:04  time: 0.4117  data_time: 0.0105  memory: 4878  grad_norm: 93.7068  loss: 37.8825  decode.loss_cls: 1.3608  decode.loss_mask: 0.7091  decode.loss_dice: 1.4482  decode.d0.loss_cls: 3.2567  decode.d0.loss_mask: 0.8204  decode.d0.loss_dice: 1.7423  decode.d1.loss_cls: 1.5133  decode.d1.loss_mask: 0.7332  decode.d1.loss_dice: 1.5812  decode.d2.loss_cls: 1.4288  decode.d2.loss_mask: 0.7344  decode.d2.loss_dice: 1.5012  decode.d3.loss_cls: 1.4209  decode.d3.loss_mask: 0.6926  decode.d3.loss_dice: 1.4213  decode.d4.loss_cls: 1.3879  decode.d4.loss_mask: 0.6967  decode.d4.loss_dice: 1.4384  decode.d5.loss_cls: 1.3967  decode.d5.loss_mask: 0.6931  decode.d5.loss_dice: 1.4386  decode.d6.loss_cls: 1.3706  decode.d6.loss_mask: 0.7108  decode.d6.loss_dice: 1.4137  decode.d7.loss_cls: 1.3006  decode.d7.loss_mask: 0.7175  decode.d7.loss_dice: 1.4446  decode.d8.loss_cls: 1.3444  decode.d8.loss_mask: 0.7118  decode.d8.loss_dice: 1.4526
2023/05/24 04:48:02 - mmengine - INFO - Iter(train) [ 85300/160000]  lr: 5.0383e-06  eta: 8:55:42  time: 0.4205  data_time: 0.0104  memory: 4819  grad_norm: 106.2850  loss: 41.3591  decode.loss_cls: 1.3153  decode.loss_mask: 0.9972  decode.loss_dice: 1.5524  decode.d0.loss_cls: 3.2923  decode.d0.loss_mask: 0.9906  decode.d0.loss_dice: 1.7148  decode.d1.loss_cls: 1.4289  decode.d1.loss_mask: 1.0513  decode.d1.loss_dice: 1.7377  decode.d2.loss_cls: 1.4315  decode.d2.loss_mask: 0.9994  decode.d2.loss_dice: 1.5613  decode.d3.loss_cls: 1.4129  decode.d3.loss_mask: 0.9816  decode.d3.loss_dice: 1.5467  decode.d4.loss_cls: 1.3103  decode.d4.loss_mask: 1.0237  decode.d4.loss_dice: 1.5885  decode.d5.loss_cls: 1.3100  decode.d5.loss_mask: 0.9736  decode.d5.loss_dice: 1.5447  decode.d6.loss_cls: 1.4146  decode.d6.loss_mask: 0.9553  decode.d6.loss_dice: 1.5059  decode.d7.loss_cls: 1.3729  decode.d7.loss_mask: 0.9502  decode.d7.loss_dice: 1.5423  decode.d8.loss_cls: 1.3664  decode.d8.loss_mask: 0.9430  decode.d8.loss_dice: 1.5438
2023/05/24 04:48:24 - mmengine - INFO - Iter(train) [ 85350/160000]  lr: 5.0353e-06  eta: 8:55:21  time: 0.4315  data_time: 0.0104  memory: 4836  grad_norm: 98.7133  loss: 28.9548  decode.loss_cls: 1.0183  decode.loss_mask: 0.6448  decode.loss_dice: 1.0303  decode.d0.loss_cls: 2.9110  decode.d0.loss_mask: 0.6643  decode.d0.loss_dice: 1.1200  decode.d1.loss_cls: 1.0417  decode.d1.loss_mask: 0.6704  decode.d1.loss_dice: 1.0727  decode.d2.loss_cls: 1.0217  decode.d2.loss_mask: 0.6436  decode.d2.loss_dice: 1.0344  decode.d3.loss_cls: 0.9781  decode.d3.loss_mask: 0.7025  decode.d3.loss_dice: 1.0523  decode.d4.loss_cls: 0.9394  decode.d4.loss_mask: 0.6884  decode.d4.loss_dice: 1.0715  decode.d5.loss_cls: 0.9469  decode.d5.loss_mask: 0.6957  decode.d5.loss_dice: 1.0618  decode.d6.loss_cls: 1.0074  decode.d6.loss_mask: 0.6461  decode.d6.loss_dice: 1.0404  decode.d7.loss_cls: 0.9879  decode.d7.loss_mask: 0.6188  decode.d7.loss_dice: 1.0355  decode.d8.loss_cls: 0.9873  decode.d8.loss_mask: 0.5931  decode.d8.loss_dice: 1.0283
2023/05/24 04:48:46 - mmengine - INFO - Iter(train) [ 85400/160000]  lr: 5.0322e-06  eta: 8:54:59  time: 0.4291  data_time: 0.0103  memory: 4830  grad_norm: 104.7357  loss: 37.4013  decode.loss_cls: 1.4931  decode.loss_mask: 0.7187  decode.loss_dice: 1.3073  decode.d0.loss_cls: 3.4188  decode.d0.loss_mask: 0.7846  decode.d0.loss_dice: 1.5125  decode.d1.loss_cls: 1.5105  decode.d1.loss_mask: 0.7238  decode.d1.loss_dice: 1.3740  decode.d2.loss_cls: 1.5008  decode.d2.loss_mask: 0.7141  decode.d2.loss_dice: 1.3459  decode.d3.loss_cls: 1.5040  decode.d3.loss_mask: 0.6887  decode.d3.loss_dice: 1.2689  decode.d4.loss_cls: 1.4889  decode.d4.loss_mask: 0.7042  decode.d4.loss_dice: 1.2701  decode.d5.loss_cls: 1.5573  decode.d5.loss_mask: 0.6894  decode.d5.loss_dice: 1.2680  decode.d6.loss_cls: 1.5266  decode.d6.loss_mask: 0.7099  decode.d6.loss_dice: 1.2845  decode.d7.loss_cls: 1.5020  decode.d7.loss_mask: 0.7209  decode.d7.loss_dice: 1.2934  decode.d8.loss_cls: 1.4719  decode.d8.loss_mask: 0.7284  decode.d8.loss_dice: 1.3202
2023/05/24 04:49:07 - mmengine - INFO - Iter(train) [ 85450/160000]  lr: 5.0292e-06  eta: 8:54:38  time: 0.4134  data_time: 0.0103  memory: 4839  grad_norm: 101.2008  loss: 29.5954  decode.loss_cls: 1.0933  decode.loss_mask: 0.7637  decode.loss_dice: 0.9139  decode.d0.loss_cls: 2.5657  decode.d0.loss_mask: 0.8417  decode.d0.loss_dice: 1.0362  decode.d1.loss_cls: 1.1315  decode.d1.loss_mask: 0.7923  decode.d1.loss_dice: 1.0121  decode.d2.loss_cls: 1.0822  decode.d2.loss_mask: 0.7916  decode.d2.loss_dice: 0.9463  decode.d3.loss_cls: 1.1055  decode.d3.loss_mask: 0.7668  decode.d3.loss_dice: 0.9387  decode.d4.loss_cls: 1.1341  decode.d4.loss_mask: 0.7514  decode.d4.loss_dice: 0.9399  decode.d5.loss_cls: 1.0708  decode.d5.loss_mask: 0.7821  decode.d5.loss_dice: 0.9002  decode.d6.loss_cls: 1.0917  decode.d6.loss_mask: 0.7408  decode.d6.loss_dice: 0.9314  decode.d7.loss_cls: 1.1205  decode.d7.loss_mask: 0.7382  decode.d7.loss_dice: 0.8711  decode.d8.loss_cls: 1.1111  decode.d8.loss_mask: 0.7506  decode.d8.loss_dice: 0.8802
2023/05/24 04:49:28 - mmengine - INFO - Iter(train) [ 85500/160000]  lr: 5.0261e-06  eta: 8:54:16  time: 0.4361  data_time: 0.0114  memory: 4839  grad_norm: 89.8607  loss: 38.2704  decode.loss_cls: 1.2990  decode.loss_mask: 0.6680  decode.loss_dice: 1.5687  decode.d0.loss_cls: 3.3724  decode.d0.loss_mask: 0.7855  decode.d0.loss_dice: 1.8848  decode.d1.loss_cls: 1.3474  decode.d1.loss_mask: 0.7456  decode.d1.loss_dice: 1.6528  decode.d2.loss_cls: 1.3075  decode.d2.loss_mask: 0.7095  decode.d2.loss_dice: 1.6664  decode.d3.loss_cls: 1.3335  decode.d3.loss_mask: 0.6974  decode.d3.loss_dice: 1.5498  decode.d4.loss_cls: 1.3695  decode.d4.loss_mask: 0.6976  decode.d4.loss_dice: 1.5470  decode.d5.loss_cls: 1.3545  decode.d5.loss_mask: 0.6885  decode.d5.loss_dice: 1.5355  decode.d6.loss_cls: 1.3203  decode.d6.loss_mask: 0.6747  decode.d6.loss_dice: 1.4897  decode.d7.loss_cls: 1.3264  decode.d7.loss_mask: 0.6838  decode.d7.loss_dice: 1.4996  decode.d8.loss_cls: 1.3191  decode.d8.loss_mask: 0.6708  decode.d8.loss_dice: 1.5051
2023/05/24 04:49:50 - mmengine - INFO - Iter(train) [ 85550/160000]  lr: 5.0231e-06  eta: 8:53:54  time: 0.4174  data_time: 0.0103  memory: 4836  grad_norm: 106.1565  loss: 35.0653  decode.loss_cls: 1.1228  decode.loss_mask: 0.8958  decode.loss_dice: 1.2319  decode.d0.loss_cls: 2.9893  decode.d0.loss_mask: 0.9370  decode.d0.loss_dice: 1.4024  decode.d1.loss_cls: 1.2637  decode.d1.loss_mask: 0.9258  decode.d1.loss_dice: 1.3098  decode.d2.loss_cls: 1.1961  decode.d2.loss_mask: 0.9008  decode.d2.loss_dice: 1.2920  decode.d3.loss_cls: 1.1203  decode.d3.loss_mask: 0.9039  decode.d3.loss_dice: 1.2249  decode.d4.loss_cls: 1.1133  decode.d4.loss_mask: 0.9108  decode.d4.loss_dice: 1.2306  decode.d5.loss_cls: 1.1006  decode.d5.loss_mask: 0.9488  decode.d5.loss_dice: 1.2330  decode.d6.loss_cls: 1.0690  decode.d6.loss_mask: 0.9308  decode.d6.loss_dice: 1.2355  decode.d7.loss_cls: 1.1079  decode.d7.loss_mask: 0.9332  decode.d7.loss_dice: 1.2427  decode.d8.loss_cls: 1.1068  decode.d8.loss_mask: 0.9372  decode.d8.loss_dice: 1.2488
2023/05/24 04:50:11 - mmengine - INFO - Iter(train) [ 85600/160000]  lr: 5.0201e-06  eta: 8:53:33  time: 0.4514  data_time: 0.0107  memory: 4804  grad_norm: 87.5587  loss: 39.8347  decode.loss_cls: 1.4077  decode.loss_mask: 0.7748  decode.loss_dice: 1.4528  decode.d0.loss_cls: 3.3137  decode.d0.loss_mask: 0.8918  decode.d0.loss_dice: 1.7195  decode.d1.loss_cls: 1.5819  decode.d1.loss_mask: 0.8933  decode.d1.loss_dice: 1.6763  decode.d2.loss_cls: 1.4398  decode.d2.loss_mask: 0.8379  decode.d2.loss_dice: 1.5669  decode.d3.loss_cls: 1.4430  decode.d3.loss_mask: 0.8134  decode.d3.loss_dice: 1.5107  decode.d4.loss_cls: 1.4306  decode.d4.loss_mask: 0.8149  decode.d4.loss_dice: 1.5091  decode.d5.loss_cls: 1.4299  decode.d5.loss_mask: 0.7993  decode.d5.loss_dice: 1.4697  decode.d6.loss_cls: 1.4678  decode.d6.loss_mask: 0.8200  decode.d6.loss_dice: 1.4666  decode.d7.loss_cls: 1.3737  decode.d7.loss_mask: 0.8060  decode.d7.loss_dice: 1.4710  decode.d8.loss_cls: 1.3881  decode.d8.loss_mask: 0.8098  decode.d8.loss_dice: 1.4547
2023/05/24 04:50:33 - mmengine - INFO - Iter(train) [ 85650/160000]  lr: 5.0170e-06  eta: 8:53:12  time: 0.4296  data_time: 0.0110  memory: 4865  grad_norm: 105.1482  loss: 40.5280  decode.loss_cls: 1.4442  decode.loss_mask: 0.8632  decode.loss_dice: 1.4260  decode.d0.loss_cls: 3.5709  decode.d0.loss_mask: 0.9972  decode.d0.loss_dice: 1.6605  decode.d1.loss_cls: 1.6216  decode.d1.loss_mask: 0.9411  decode.d1.loss_dice: 1.5473  decode.d2.loss_cls: 1.4950  decode.d2.loss_mask: 0.8838  decode.d2.loss_dice: 1.4948  decode.d3.loss_cls: 1.4508  decode.d3.loss_mask: 0.9217  decode.d3.loss_dice: 1.5029  decode.d4.loss_cls: 1.4177  decode.d4.loss_mask: 0.8799  decode.d4.loss_dice: 1.4715  decode.d5.loss_cls: 1.4382  decode.d5.loss_mask: 0.8530  decode.d5.loss_dice: 1.4559  decode.d6.loss_cls: 1.4148  decode.d6.loss_mask: 0.8584  decode.d6.loss_dice: 1.4499  decode.d7.loss_cls: 1.4335  decode.d7.loss_mask: 0.8743  decode.d7.loss_dice: 1.4196  decode.d8.loss_cls: 1.4456  decode.d8.loss_mask: 0.8780  decode.d8.loss_dice: 1.4168
2023/05/24 04:50:55 - mmengine - INFO - Iter(train) [ 85700/160000]  lr: 5.0140e-06  eta: 8:52:51  time: 0.4726  data_time: 0.0105  memory: 4802  grad_norm: 109.9061  loss: 34.1823  decode.loss_cls: 0.8469  decode.loss_mask: 0.9542  decode.loss_dice: 1.3453  decode.d0.loss_cls: 2.8301  decode.d0.loss_mask: 1.0196  decode.d0.loss_dice: 1.5784  decode.d1.loss_cls: 1.0018  decode.d1.loss_mask: 0.9785  decode.d1.loss_dice: 1.4537  decode.d2.loss_cls: 0.9000  decode.d2.loss_mask: 0.9534  decode.d2.loss_dice: 1.3631  decode.d3.loss_cls: 0.9000  decode.d3.loss_mask: 0.9256  decode.d3.loss_dice: 1.3260  decode.d4.loss_cls: 0.9165  decode.d4.loss_mask: 0.9332  decode.d4.loss_dice: 1.3462  decode.d5.loss_cls: 0.8730  decode.d5.loss_mask: 0.9396  decode.d5.loss_dice: 1.3607  decode.d6.loss_cls: 0.9577  decode.d6.loss_mask: 0.8962  decode.d6.loss_dice: 1.3387  decode.d7.loss_cls: 0.8600  decode.d7.loss_mask: 0.9218  decode.d7.loss_dice: 1.3355  decode.d8.loss_cls: 0.8517  decode.d8.loss_mask: 0.9369  decode.d8.loss_dice: 1.3379
2023/05/24 04:51:19 - mmengine - INFO - Iter(train) [ 85750/160000]  lr: 5.0110e-06  eta: 8:52:31  time: 0.4725  data_time: 0.0103  memory: 4904  grad_norm: 82.8349  loss: 30.4247  decode.loss_cls: 1.0522  decode.loss_mask: 0.6501  decode.loss_dice: 1.0710  decode.d0.loss_cls: 2.8235  decode.d0.loss_mask: 0.7552  decode.d0.loss_dice: 1.2822  decode.d1.loss_cls: 1.1647  decode.d1.loss_mask: 0.7116  decode.d1.loss_dice: 1.1821  decode.d2.loss_cls: 1.1584  decode.d2.loss_mask: 0.6654  decode.d2.loss_dice: 1.1507  decode.d3.loss_cls: 1.0824  decode.d3.loss_mask: 0.6691  decode.d3.loss_dice: 1.1290  decode.d4.loss_cls: 1.0641  decode.d4.loss_mask: 0.6585  decode.d4.loss_dice: 1.0795  decode.d5.loss_cls: 1.0332  decode.d5.loss_mask: 0.6469  decode.d5.loss_dice: 1.0921  decode.d6.loss_cls: 1.0679  decode.d6.loss_mask: 0.6112  decode.d6.loss_dice: 1.0717  decode.d7.loss_cls: 1.0305  decode.d7.loss_mask: 0.6471  decode.d7.loss_dice: 1.1059  decode.d8.loss_cls: 1.0014  decode.d8.loss_mask: 0.6537  decode.d8.loss_dice: 1.1136
2023/05/24 04:51:40 - mmengine - INFO - Iter(train) [ 85800/160000]  lr: 5.0079e-06  eta: 8:52:09  time: 0.4148  data_time: 0.0104  memory: 4885  grad_norm: 97.6286  loss: 44.2597  decode.loss_cls: 1.4721  decode.loss_mask: 0.9567  decode.loss_dice: 1.6941  decode.d0.loss_cls: 3.3433  decode.d0.loss_mask: 1.0801  decode.d0.loss_dice: 1.9704  decode.d1.loss_cls: 1.5711  decode.d1.loss_mask: 1.0028  decode.d1.loss_dice: 1.8483  decode.d2.loss_cls: 1.5768  decode.d2.loss_mask: 0.9406  decode.d2.loss_dice: 1.7638  decode.d3.loss_cls: 1.5821  decode.d3.loss_mask: 0.9584  decode.d3.loss_dice: 1.6986  decode.d4.loss_cls: 1.5394  decode.d4.loss_mask: 0.9700  decode.d4.loss_dice: 1.7061  decode.d5.loss_cls: 1.4869  decode.d5.loss_mask: 0.9816  decode.d5.loss_dice: 1.7100  decode.d6.loss_cls: 1.5201  decode.d6.loss_mask: 0.9447  decode.d6.loss_dice: 1.6898  decode.d7.loss_cls: 1.4991  decode.d7.loss_mask: 0.9425  decode.d7.loss_dice: 1.6794  decode.d8.loss_cls: 1.4933  decode.d8.loss_mask: 0.9580  decode.d8.loss_dice: 1.6797
2023/05/24 04:52:02 - mmengine - INFO - Iter(train) [ 85850/160000]  lr: 5.0049e-06  eta: 8:51:48  time: 0.4737  data_time: 0.0108  memory: 4872  grad_norm: 94.2601  loss: 46.1747  decode.loss_cls: 1.5074  decode.loss_mask: 0.9431  decode.loss_dice: 1.8250  decode.d0.loss_cls: 3.4057  decode.d0.loss_mask: 1.0737  decode.d0.loss_dice: 2.1522  decode.d1.loss_cls: 1.6544  decode.d1.loss_mask: 1.0211  decode.d1.loss_dice: 1.9640  decode.d2.loss_cls: 1.5927  decode.d2.loss_mask: 0.9994  decode.d2.loss_dice: 1.9154  decode.d3.loss_cls: 1.5652  decode.d3.loss_mask: 0.9514  decode.d3.loss_dice: 1.8645  decode.d4.loss_cls: 1.5217  decode.d4.loss_mask: 0.9695  decode.d4.loss_dice: 1.8603  decode.d5.loss_cls: 1.5342  decode.d5.loss_mask: 0.9469  decode.d5.loss_dice: 1.8583  decode.d6.loss_cls: 1.5837  decode.d6.loss_mask: 0.9631  decode.d6.loss_dice: 1.8252  decode.d7.loss_cls: 1.5328  decode.d7.loss_mask: 0.9565  decode.d7.loss_dice: 1.8481  decode.d8.loss_cls: 1.5249  decode.d8.loss_mask: 0.9643  decode.d8.loss_dice: 1.8500
2023/05/24 04:52:23 - mmengine - INFO - Iter(train) [ 85900/160000]  lr: 5.0019e-06  eta: 8:51:26  time: 0.4249  data_time: 0.0104  memory: 4800  grad_norm: 109.8846  loss: 35.9062  decode.loss_cls: 1.3731  decode.loss_mask: 0.7029  decode.loss_dice: 1.3567  decode.d0.loss_cls: 3.0895  decode.d0.loss_mask: 0.7645  decode.d0.loss_dice: 1.4919  decode.d1.loss_cls: 1.4536  decode.d1.loss_mask: 0.7005  decode.d1.loss_dice: 1.3519  decode.d2.loss_cls: 1.4555  decode.d2.loss_mask: 0.6969  decode.d2.loss_dice: 1.3252  decode.d3.loss_cls: 1.3632  decode.d3.loss_mask: 0.7195  decode.d3.loss_dice: 1.3329  decode.d4.loss_cls: 1.2678  decode.d4.loss_mask: 0.7033  decode.d4.loss_dice: 1.3332  decode.d5.loss_cls: 1.3127  decode.d5.loss_mask: 0.6856  decode.d5.loss_dice: 1.3249  decode.d6.loss_cls: 1.3492  decode.d6.loss_mask: 0.7137  decode.d6.loss_dice: 1.3010  decode.d7.loss_cls: 1.3506  decode.d7.loss_mask: 0.6928  decode.d7.loss_dice: 1.3210  decode.d8.loss_cls: 1.3451  decode.d8.loss_mask: 0.7009  decode.d8.loss_dice: 1.3264
2023/05/24 04:52:44 - mmengine - INFO - Iter(train) [ 85950/160000]  lr: 4.9988e-06  eta: 8:51:04  time: 0.4162  data_time: 0.0103  memory: 4925  grad_norm: 104.1902  loss: 30.5128  decode.loss_cls: 1.0892  decode.loss_mask: 0.6940  decode.loss_dice: 1.0570  decode.d0.loss_cls: 2.9016  decode.d0.loss_mask: 0.7167  decode.d0.loss_dice: 1.1980  decode.d1.loss_cls: 1.1660  decode.d1.loss_mask: 0.7230  decode.d1.loss_dice: 1.1615  decode.d2.loss_cls: 1.1336  decode.d2.loss_mask: 0.7039  decode.d2.loss_dice: 1.0773  decode.d3.loss_cls: 1.1491  decode.d3.loss_mask: 0.6867  decode.d3.loss_dice: 1.0234  decode.d4.loss_cls: 1.0916  decode.d4.loss_mask: 0.7300  decode.d4.loss_dice: 1.0318  decode.d5.loss_cls: 1.0872  decode.d5.loss_mask: 0.6943  decode.d5.loss_dice: 1.0293  decode.d6.loss_cls: 1.1119  decode.d6.loss_mask: 0.6718  decode.d6.loss_dice: 1.0279  decode.d7.loss_cls: 1.0808  decode.d7.loss_mask: 0.6663  decode.d7.loss_dice: 1.0211  decode.d8.loss_cls: 1.1029  decode.d8.loss_mask: 0.6705  decode.d8.loss_dice: 1.0141
2023/05/24 04:53:05 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 04:53:05 - mmengine - INFO - Iter(train) [ 86000/160000]  lr: 4.9958e-06  eta: 8:50:42  time: 0.4216  data_time: 0.0102  memory: 4877  grad_norm: 154.3255  loss: 38.6688  decode.loss_cls: 1.2775  decode.loss_mask: 0.7786  decode.loss_dice: 1.4921  decode.d0.loss_cls: 3.4441  decode.d0.loss_mask: 0.8233  decode.d0.loss_dice: 1.7327  decode.d1.loss_cls: 1.5009  decode.d1.loss_mask: 0.8025  decode.d1.loss_dice: 1.6216  decode.d2.loss_cls: 1.4264  decode.d2.loss_mask: 0.8029  decode.d2.loss_dice: 1.5352  decode.d3.loss_cls: 1.2881  decode.d3.loss_mask: 0.7849  decode.d3.loss_dice: 1.5457  decode.d4.loss_cls: 1.2885  decode.d4.loss_mask: 0.7925  decode.d4.loss_dice: 1.4990  decode.d5.loss_cls: 1.2829  decode.d5.loss_mask: 0.7792  decode.d5.loss_dice: 1.5014  decode.d6.loss_cls: 1.2068  decode.d6.loss_mask: 0.7895  decode.d6.loss_dice: 1.5318  decode.d7.loss_cls: 1.3082  decode.d7.loss_mask: 0.7804  decode.d7.loss_dice: 1.4996  decode.d8.loss_cls: 1.2378  decode.d8.loss_mask: 0.7911  decode.d8.loss_dice: 1.5237
2023/05/24 04:53:05 - mmengine - INFO - Saving checkpoint at 86000 iterations
2023/05/24 04:53:32 - mmengine - INFO - Iter(train) [ 86050/160000]  lr: 4.9927e-06  eta: 8:50:25  time: 0.4231  data_time: 0.0106  memory: 4918  grad_norm: 108.4841  loss: 29.4052  decode.loss_cls: 0.9362  decode.loss_mask: 0.6519  decode.loss_dice: 1.0619  decode.d0.loss_cls: 2.9386  decode.d0.loss_mask: 0.7907  decode.d0.loss_dice: 1.1979  decode.d1.loss_cls: 1.1241  decode.d1.loss_mask: 0.6893  decode.d1.loss_dice: 1.1456  decode.d2.loss_cls: 0.9957  decode.d2.loss_mask: 0.6709  decode.d2.loss_dice: 1.0627  decode.d3.loss_cls: 1.0915  decode.d3.loss_mask: 0.6640  decode.d3.loss_dice: 1.0496  decode.d4.loss_cls: 0.9825  decode.d4.loss_mask: 0.6458  decode.d4.loss_dice: 1.0559  decode.d5.loss_cls: 0.9853  decode.d5.loss_mask: 0.6512  decode.d5.loss_dice: 1.0429  decode.d6.loss_cls: 0.9738  decode.d6.loss_mask: 0.6562  decode.d6.loss_dice: 1.0269  decode.d7.loss_cls: 0.9354  decode.d7.loss_mask: 0.6584  decode.d7.loss_dice: 1.0445  decode.d8.loss_cls: 0.9510  decode.d8.loss_mask: 0.6661  decode.d8.loss_dice: 1.0586
2023/05/24 04:53:53 - mmengine - INFO - Iter(train) [ 86100/160000]  lr: 4.9897e-06  eta: 8:50:03  time: 0.4157  data_time: 0.0105  memory: 4919  grad_norm: 133.6609  loss: 41.7617  decode.loss_cls: 1.6229  decode.loss_mask: 0.9138  decode.loss_dice: 1.3109  decode.d0.loss_cls: 3.6712  decode.d0.loss_mask: 0.8498  decode.d0.loss_dice: 1.5648  decode.d1.loss_cls: 1.8095  decode.d1.loss_mask: 0.9780  decode.d1.loss_dice: 1.4729  decode.d2.loss_cls: 1.7121  decode.d2.loss_mask: 0.9276  decode.d2.loss_dice: 1.4436  decode.d3.loss_cls: 1.6547  decode.d3.loss_mask: 0.8837  decode.d3.loss_dice: 1.4055  decode.d4.loss_cls: 1.6377  decode.d4.loss_mask: 0.8984  decode.d4.loss_dice: 1.3933  decode.d5.loss_cls: 1.6834  decode.d5.loss_mask: 0.8903  decode.d5.loss_dice: 1.3858  decode.d6.loss_cls: 1.6657  decode.d6.loss_mask: 0.8794  decode.d6.loss_dice: 1.3466  decode.d7.loss_cls: 1.6772  decode.d7.loss_mask: 0.8868  decode.d7.loss_dice: 1.3075  decode.d8.loss_cls: 1.6182  decode.d8.loss_mask: 0.9109  decode.d8.loss_dice: 1.3593
2023/05/24 04:54:14 - mmengine - INFO - Iter(train) [ 86150/160000]  lr: 4.9867e-06  eta: 8:49:41  time: 0.4353  data_time: 0.0102  memory: 4837  grad_norm: 111.5915  loss: 35.3787  decode.loss_cls: 1.2468  decode.loss_mask: 0.8194  decode.loss_dice: 1.1672  decode.d0.loss_cls: 3.2712  decode.d0.loss_mask: 0.8964  decode.d0.loss_dice: 1.3169  decode.d1.loss_cls: 1.3310  decode.d1.loss_mask: 0.8325  decode.d1.loss_dice: 1.2760  decode.d2.loss_cls: 1.3771  decode.d2.loss_mask: 0.8298  decode.d2.loss_dice: 1.2067  decode.d3.loss_cls: 1.3638  decode.d3.loss_mask: 0.8120  decode.d3.loss_dice: 1.1794  decode.d4.loss_cls: 1.3195  decode.d4.loss_mask: 0.8276  decode.d4.loss_dice: 1.1939  decode.d5.loss_cls: 1.3200  decode.d5.loss_mask: 0.8230  decode.d5.loss_dice: 1.1693  decode.d6.loss_cls: 1.2760  decode.d6.loss_mask: 0.8224  decode.d6.loss_dice: 1.1972  decode.d7.loss_cls: 1.2654  decode.d7.loss_mask: 0.8192  decode.d7.loss_dice: 1.1959  decode.d8.loss_cls: 1.2861  decode.d8.loss_mask: 0.8023  decode.d8.loss_dice: 1.1347
2023/05/24 04:54:37 - mmengine - INFO - Iter(train) [ 86200/160000]  lr: 4.9836e-06  eta: 8:49:21  time: 0.4105  data_time: 0.0105  memory: 4857  grad_norm: 90.9644  loss: 38.8736  decode.loss_cls: 1.3121  decode.loss_mask: 0.7715  decode.loss_dice: 1.5761  decode.d0.loss_cls: 3.1288  decode.d0.loss_mask: 0.8645  decode.d0.loss_dice: 1.8457  decode.d1.loss_cls: 1.4183  decode.d1.loss_mask: 0.8212  decode.d1.loss_dice: 1.6548  decode.d2.loss_cls: 1.3348  decode.d2.loss_mask: 0.7801  decode.d2.loss_dice: 1.6394  decode.d3.loss_cls: 1.2847  decode.d3.loss_mask: 0.7796  decode.d3.loss_dice: 1.6081  decode.d4.loss_cls: 1.2061  decode.d4.loss_mask: 0.7737  decode.d4.loss_dice: 1.6662  decode.d5.loss_cls: 1.2409  decode.d5.loss_mask: 0.7570  decode.d5.loss_dice: 1.5941  decode.d6.loss_cls: 1.2894  decode.d6.loss_mask: 0.7443  decode.d6.loss_dice: 1.5600  decode.d7.loss_cls: 1.3026  decode.d7.loss_mask: 0.7543  decode.d7.loss_dice: 1.5303  decode.d8.loss_cls: 1.2829  decode.d8.loss_mask: 0.7684  decode.d8.loss_dice: 1.5839
2023/05/24 04:54:58 - mmengine - INFO - Iter(train) [ 86250/160000]  lr: 4.9806e-06  eta: 8:48:59  time: 0.4199  data_time: 0.0104  memory: 4845  grad_norm: 104.4123  loss: 37.9281  decode.loss_cls: 1.0877  decode.loss_mask: 0.8106  decode.loss_dice: 1.6051  decode.d0.loss_cls: 3.0081  decode.d0.loss_mask: 0.8331  decode.d0.loss_dice: 1.8242  decode.d1.loss_cls: 1.3371  decode.d1.loss_mask: 0.8053  decode.d1.loss_dice: 1.6843  decode.d2.loss_cls: 1.1723  decode.d2.loss_mask: 0.8109  decode.d2.loss_dice: 1.6735  decode.d3.loss_cls: 1.1454  decode.d3.loss_mask: 0.7937  decode.d3.loss_dice: 1.6610  decode.d4.loss_cls: 1.1635  decode.d4.loss_mask: 0.8042  decode.d4.loss_dice: 1.6354  decode.d5.loss_cls: 1.0802  decode.d5.loss_mask: 0.8255  decode.d5.loss_dice: 1.6074  decode.d6.loss_cls: 1.1056  decode.d6.loss_mask: 0.8112  decode.d6.loss_dice: 1.5992  decode.d7.loss_cls: 1.1111  decode.d7.loss_mask: 0.8091  decode.d7.loss_dice: 1.5933  decode.d8.loss_cls: 1.1376  decode.d8.loss_mask: 0.8045  decode.d8.loss_dice: 1.5881
2023/05/24 04:55:19 - mmengine - INFO - Iter(train) [ 86300/160000]  lr: 4.9775e-06  eta: 8:48:37  time: 0.4162  data_time: 0.0104  memory: 4829  grad_norm: 84.6083  loss: 32.8833  decode.loss_cls: 1.2157  decode.loss_mask: 0.6333  decode.loss_dice: 1.1168  decode.d0.loss_cls: 3.2704  decode.d0.loss_mask: 0.7009  decode.d0.loss_dice: 1.3191  decode.d1.loss_cls: 1.3620  decode.d1.loss_mask: 0.6872  decode.d1.loss_dice: 1.2137  decode.d2.loss_cls: 1.3251  decode.d2.loss_mask: 0.6619  decode.d2.loss_dice: 1.1565  decode.d3.loss_cls: 1.3346  decode.d3.loss_mask: 0.6359  decode.d3.loss_dice: 1.1199  decode.d4.loss_cls: 1.2938  decode.d4.loss_mask: 0.6242  decode.d4.loss_dice: 1.0931  decode.d5.loss_cls: 1.2902  decode.d5.loss_mask: 0.6357  decode.d5.loss_dice: 1.1415  decode.d6.loss_cls: 1.3058  decode.d6.loss_mask: 0.6207  decode.d6.loss_dice: 1.1274  decode.d7.loss_cls: 1.2299  decode.d7.loss_mask: 0.6233  decode.d7.loss_dice: 1.1587  decode.d8.loss_cls: 1.2102  decode.d8.loss_mask: 0.6342  decode.d8.loss_dice: 1.1418
2023/05/24 04:55:40 - mmengine - INFO - Iter(train) [ 86350/160000]  lr: 4.9745e-06  eta: 8:48:15  time: 0.4224  data_time: 0.0102  memory: 4889  grad_norm: 93.8677  loss: 33.7623  decode.loss_cls: 1.2243  decode.loss_mask: 0.6600  decode.loss_dice: 1.2132  decode.d0.loss_cls: 3.1547  decode.d0.loss_mask: 0.6904  decode.d0.loss_dice: 1.4530  decode.d1.loss_cls: 1.4223  decode.d1.loss_mask: 0.7240  decode.d1.loss_dice: 1.2931  decode.d2.loss_cls: 1.3072  decode.d2.loss_mask: 0.6878  decode.d2.loss_dice: 1.2338  decode.d3.loss_cls: 1.2714  decode.d3.loss_mask: 0.6866  decode.d3.loss_dice: 1.2288  decode.d4.loss_cls: 1.2442  decode.d4.loss_mask: 0.6702  decode.d4.loss_dice: 1.2073  decode.d5.loss_cls: 1.2680  decode.d5.loss_mask: 0.6575  decode.d5.loss_dice: 1.2045  decode.d6.loss_cls: 1.2268  decode.d6.loss_mask: 0.6670  decode.d6.loss_dice: 1.2105  decode.d7.loss_cls: 1.1963  decode.d7.loss_mask: 0.6696  decode.d7.loss_dice: 1.1801  decode.d8.loss_cls: 1.2349  decode.d8.loss_mask: 0.6624  decode.d8.loss_dice: 1.2125
2023/05/24 04:56:01 - mmengine - INFO - Iter(train) [ 86400/160000]  lr: 4.9715e-06  eta: 8:47:53  time: 0.4260  data_time: 0.0108  memory: 4889  grad_norm: 83.5764  loss: 38.3462  decode.loss_cls: 1.2693  decode.loss_mask: 0.8153  decode.loss_dice: 1.4603  decode.d0.loss_cls: 3.1640  decode.d0.loss_mask: 0.8578  decode.d0.loss_dice: 1.6207  decode.d1.loss_cls: 1.4392  decode.d1.loss_mask: 0.9120  decode.d1.loss_dice: 1.5968  decode.d2.loss_cls: 1.3745  decode.d2.loss_mask: 0.8692  decode.d2.loss_dice: 1.5589  decode.d3.loss_cls: 1.3402  decode.d3.loss_mask: 0.7987  decode.d3.loss_dice: 1.4799  decode.d4.loss_cls: 1.3078  decode.d4.loss_mask: 0.8344  decode.d4.loss_dice: 1.4692  decode.d5.loss_cls: 1.3190  decode.d5.loss_mask: 0.8107  decode.d5.loss_dice: 1.4248  decode.d6.loss_cls: 1.2599  decode.d6.loss_mask: 0.8212  decode.d6.loss_dice: 1.4276  decode.d7.loss_cls: 1.2681  decode.d7.loss_mask: 0.8138  decode.d7.loss_dice: 1.4682  decode.d8.loss_cls: 1.2873  decode.d8.loss_mask: 0.8037  decode.d8.loss_dice: 1.4737
2023/05/24 04:56:22 - mmengine - INFO - Iter(train) [ 86450/160000]  lr: 4.9684e-06  eta: 8:47:31  time: 0.4086  data_time: 0.0103  memory: 4829  grad_norm: 116.4761  loss: 31.3774  decode.loss_cls: 1.0731  decode.loss_mask: 0.7578  decode.loss_dice: 1.0219  decode.d0.loss_cls: 3.0227  decode.d0.loss_mask: 0.7772  decode.d0.loss_dice: 1.1335  decode.d1.loss_cls: 1.2394  decode.d1.loss_mask: 0.8491  decode.d1.loss_dice: 1.1162  decode.d2.loss_cls: 1.1871  decode.d2.loss_mask: 0.7651  decode.d2.loss_dice: 1.0908  decode.d3.loss_cls: 1.1311  decode.d3.loss_mask: 0.7433  decode.d3.loss_dice: 1.0393  decode.d4.loss_cls: 1.1158  decode.d4.loss_mask: 0.7412  decode.d4.loss_dice: 1.0418  decode.d5.loss_cls: 1.1524  decode.d5.loss_mask: 0.7656  decode.d5.loss_dice: 1.0673  decode.d6.loss_cls: 1.1057  decode.d6.loss_mask: 0.7503  decode.d6.loss_dice: 0.9960  decode.d7.loss_cls: 1.1079  decode.d7.loss_mask: 0.7523  decode.d7.loss_dice: 0.9732  decode.d8.loss_cls: 1.1020  decode.d8.loss_mask: 0.7472  decode.d8.loss_dice: 1.0112
2023/05/24 04:56:45 - mmengine - INFO - Iter(train) [ 86500/160000]  lr: 4.9654e-06  eta: 8:47:11  time: 0.4665  data_time: 0.0102  memory: 4877  grad_norm: 96.4144  loss: 33.9661  decode.loss_cls: 1.1489  decode.loss_mask: 0.9054  decode.loss_dice: 1.1387  decode.d0.loss_cls: 2.7210  decode.d0.loss_mask: 0.9101  decode.d0.loss_dice: 1.2329  decode.d1.loss_cls: 1.2918  decode.d1.loss_mask: 0.8959  decode.d1.loss_dice: 1.1921  decode.d2.loss_cls: 1.2286  decode.d2.loss_mask: 0.9021  decode.d2.loss_dice: 1.1541  decode.d3.loss_cls: 1.2188  decode.d3.loss_mask: 0.8758  decode.d3.loss_dice: 1.1212  decode.d4.loss_cls: 1.2054  decode.d4.loss_mask: 0.8853  decode.d4.loss_dice: 1.1139  decode.d5.loss_cls: 1.2269  decode.d5.loss_mask: 0.8732  decode.d5.loss_dice: 1.1250  decode.d6.loss_cls: 1.1972  decode.d6.loss_mask: 0.8650  decode.d6.loss_dice: 1.1305  decode.d7.loss_cls: 1.2009  decode.d7.loss_mask: 0.8710  decode.d7.loss_dice: 1.1275  decode.d8.loss_cls: 1.2059  decode.d8.loss_mask: 0.8910  decode.d8.loss_dice: 1.1100
2023/05/24 04:57:08 - mmengine - INFO - Iter(train) [ 86550/160000]  lr: 4.9623e-06  eta: 8:46:51  time: 0.4746  data_time: 0.0104  memory: 4878  grad_norm: 93.7988  loss: 33.2992  decode.loss_cls: 1.1316  decode.loss_mask: 0.6847  decode.loss_dice: 1.2221  decode.d0.loss_cls: 3.1014  decode.d0.loss_mask: 0.7330  decode.d0.loss_dice: 1.4578  decode.d1.loss_cls: 1.4123  decode.d1.loss_mask: 0.6930  decode.d1.loss_dice: 1.3176  decode.d2.loss_cls: 1.2358  decode.d2.loss_mask: 0.7096  decode.d2.loss_dice: 1.3056  decode.d3.loss_cls: 1.1564  decode.d3.loss_mask: 0.7115  decode.d3.loss_dice: 1.2889  decode.d4.loss_cls: 1.0720  decode.d4.loss_mask: 0.7135  decode.d4.loss_dice: 1.2985  decode.d5.loss_cls: 1.1080  decode.d5.loss_mask: 0.6963  decode.d5.loss_dice: 1.2432  decode.d6.loss_cls: 1.0820  decode.d6.loss_mask: 0.6898  decode.d6.loss_dice: 1.2128  decode.d7.loss_cls: 1.1034  decode.d7.loss_mask: 0.6822  decode.d7.loss_dice: 1.2188  decode.d8.loss_cls: 1.0801  decode.d8.loss_mask: 0.6818  decode.d8.loss_dice: 1.2555
2023/05/24 04:57:32 - mmengine - INFO - Iter(train) [ 86600/160000]  lr: 4.9593e-06  eta: 8:46:31  time: 0.4602  data_time: 0.0108  memory: 4876  grad_norm: 120.4893  loss: 35.3359  decode.loss_cls: 1.2268  decode.loss_mask: 0.8262  decode.loss_dice: 1.1808  decode.d0.loss_cls: 3.1994  decode.d0.loss_mask: 0.8517  decode.d0.loss_dice: 1.4129  decode.d1.loss_cls: 1.3676  decode.d1.loss_mask: 0.8886  decode.d1.loss_dice: 1.3352  decode.d2.loss_cls: 1.2099  decode.d2.loss_mask: 0.8573  decode.d2.loss_dice: 1.2351  decode.d3.loss_cls: 1.2300  decode.d3.loss_mask: 0.8796  decode.d3.loss_dice: 1.2022  decode.d4.loss_cls: 1.2903  decode.d4.loss_mask: 0.8696  decode.d4.loss_dice: 1.1810  decode.d5.loss_cls: 1.2491  decode.d5.loss_mask: 0.8820  decode.d5.loss_dice: 1.2134  decode.d6.loss_cls: 1.2628  decode.d6.loss_mask: 0.8293  decode.d6.loss_dice: 1.1595  decode.d7.loss_cls: 1.2384  decode.d7.loss_mask: 0.8264  decode.d7.loss_dice: 1.1483  decode.d8.loss_cls: 1.2799  decode.d8.loss_mask: 0.8194  decode.d8.loss_dice: 1.1830
2023/05/24 04:57:53 - mmengine - INFO - Iter(train) [ 86650/160000]  lr: 4.9563e-06  eta: 8:46:09  time: 0.4194  data_time: 0.0106  memory: 4819  grad_norm: 91.6030  loss: 34.0235  decode.loss_cls: 1.1508  decode.loss_mask: 0.7069  decode.loss_dice: 1.2327  decode.d0.loss_cls: 3.3515  decode.d0.loss_mask: 0.8329  decode.d0.loss_dice: 1.4949  decode.d1.loss_cls: 1.2489  decode.d1.loss_mask: 0.7897  decode.d1.loss_dice: 1.3859  decode.d2.loss_cls: 1.1633  decode.d2.loss_mask: 0.7621  decode.d2.loss_dice: 1.3074  decode.d3.loss_cls: 1.1367  decode.d3.loss_mask: 0.7204  decode.d3.loss_dice: 1.2756  decode.d4.loss_cls: 1.1170  decode.d4.loss_mask: 0.7297  decode.d4.loss_dice: 1.2691  decode.d5.loss_cls: 1.1182  decode.d5.loss_mask: 0.7193  decode.d5.loss_dice: 1.2656  decode.d6.loss_cls: 1.1352  decode.d6.loss_mask: 0.7068  decode.d6.loss_dice: 1.2424  decode.d7.loss_cls: 1.1055  decode.d7.loss_mask: 0.7202  decode.d7.loss_dice: 1.2759  decode.d8.loss_cls: 1.1062  decode.d8.loss_mask: 0.7087  decode.d8.loss_dice: 1.2437
2023/05/24 04:58:15 - mmengine - INFO - Iter(train) [ 86700/160000]  lr: 4.9532e-06  eta: 8:45:48  time: 0.4128  data_time: 0.0102  memory: 4916  grad_norm: 102.2114  loss: 36.3809  decode.loss_cls: 1.4278  decode.loss_mask: 0.7025  decode.loss_dice: 1.3019  decode.d0.loss_cls: 3.2616  decode.d0.loss_mask: 0.7230  decode.d0.loss_dice: 1.5030  decode.d1.loss_cls: 1.4504  decode.d1.loss_mask: 0.7370  decode.d1.loss_dice: 1.3998  decode.d2.loss_cls: 1.4415  decode.d2.loss_mask: 0.7269  decode.d2.loss_dice: 1.2989  decode.d3.loss_cls: 1.4313  decode.d3.loss_mask: 0.7108  decode.d3.loss_dice: 1.3188  decode.d4.loss_cls: 1.3727  decode.d4.loss_mask: 0.7025  decode.d4.loss_dice: 1.3335  decode.d5.loss_cls: 1.4087  decode.d5.loss_mask: 0.6875  decode.d5.loss_dice: 1.3052  decode.d6.loss_cls: 1.4050  decode.d6.loss_mask: 0.6910  decode.d6.loss_dice: 1.2739  decode.d7.loss_cls: 1.3747  decode.d7.loss_mask: 0.7062  decode.d7.loss_dice: 1.2891  decode.d8.loss_cls: 1.4292  decode.d8.loss_mask: 0.7056  decode.d8.loss_dice: 1.2610
2023/05/24 04:58:36 - mmengine - INFO - Iter(train) [ 86750/160000]  lr: 4.9502e-06  eta: 8:45:26  time: 0.4219  data_time: 0.0106  memory: 4807  grad_norm: 84.2411  loss: 37.6605  decode.loss_cls: 1.3720  decode.loss_mask: 0.7733  decode.loss_dice: 1.3111  decode.d0.loss_cls: 3.3579  decode.d0.loss_mask: 0.8507  decode.d0.loss_dice: 1.5564  decode.d1.loss_cls: 1.4384  decode.d1.loss_mask: 0.8548  decode.d1.loss_dice: 1.4435  decode.d2.loss_cls: 1.3686  decode.d2.loss_mask: 0.8520  decode.d2.loss_dice: 1.3770  decode.d3.loss_cls: 1.3664  decode.d3.loss_mask: 0.8217  decode.d3.loss_dice: 1.3375  decode.d4.loss_cls: 1.4099  decode.d4.loss_mask: 0.8189  decode.d4.loss_dice: 1.3603  decode.d5.loss_cls: 1.3938  decode.d5.loss_mask: 0.8302  decode.d5.loss_dice: 1.3700  decode.d6.loss_cls: 1.3396  decode.d6.loss_mask: 0.7874  decode.d6.loss_dice: 1.3216  decode.d7.loss_cls: 1.3657  decode.d7.loss_mask: 0.7872  decode.d7.loss_dice: 1.3338  decode.d8.loss_cls: 1.3583  decode.d8.loss_mask: 0.7737  decode.d8.loss_dice: 1.3289
2023/05/24 04:58:57 - mmengine - INFO - Iter(train) [ 86800/160000]  lr: 4.9471e-06  eta: 8:45:05  time: 0.4205  data_time: 0.0103  memory: 4800  grad_norm: 109.4246  loss: 33.7673  decode.loss_cls: 1.1232  decode.loss_mask: 0.8607  decode.loss_dice: 1.2189  decode.d0.loss_cls: 2.9499  decode.d0.loss_mask: 0.8508  decode.d0.loss_dice: 1.4572  decode.d1.loss_cls: 1.3166  decode.d1.loss_mask: 0.8398  decode.d1.loss_dice: 1.3921  decode.d2.loss_cls: 1.1531  decode.d2.loss_mask: 0.8460  decode.d2.loss_dice: 1.2200  decode.d3.loss_cls: 1.0254  decode.d3.loss_mask: 0.8977  decode.d3.loss_dice: 1.1579  decode.d4.loss_cls: 1.0383  decode.d4.loss_mask: 0.8435  decode.d4.loss_dice: 1.1698  decode.d5.loss_cls: 1.0399  decode.d5.loss_mask: 0.8285  decode.d5.loss_dice: 1.1647  decode.d6.loss_cls: 1.0485  decode.d6.loss_mask: 0.8474  decode.d6.loss_dice: 1.1712  decode.d7.loss_cls: 1.0428  decode.d7.loss_mask: 0.8626  decode.d7.loss_dice: 1.1913  decode.d8.loss_cls: 1.0702  decode.d8.loss_mask: 0.8859  decode.d8.loss_dice: 1.2534
2023/05/24 04:59:18 - mmengine - INFO - Iter(train) [ 86850/160000]  lr: 4.9441e-06  eta: 8:44:43  time: 0.4259  data_time: 0.0105  memory: 4821  grad_norm: 109.5035  loss: 31.1570  decode.loss_cls: 1.0230  decode.loss_mask: 0.7935  decode.loss_dice: 1.0960  decode.d0.loss_cls: 2.7588  decode.d0.loss_mask: 0.7648  decode.d0.loss_dice: 1.1947  decode.d1.loss_cls: 1.1871  decode.d1.loss_mask: 0.7586  decode.d1.loss_dice: 1.1662  decode.d2.loss_cls: 1.1132  decode.d2.loss_mask: 0.7517  decode.d2.loss_dice: 1.1315  decode.d3.loss_cls: 1.0882  decode.d3.loss_mask: 0.7388  decode.d3.loss_dice: 1.1065  decode.d4.loss_cls: 1.0250  decode.d4.loss_mask: 0.7550  decode.d4.loss_dice: 1.1358  decode.d5.loss_cls: 1.0165  decode.d5.loss_mask: 0.7554  decode.d5.loss_dice: 1.1022  decode.d6.loss_cls: 1.0053  decode.d6.loss_mask: 0.7789  decode.d6.loss_dice: 1.1009  decode.d7.loss_cls: 1.0042  decode.d7.loss_mask: 0.8007  decode.d7.loss_dice: 1.1140  decode.d8.loss_cls: 1.0379  decode.d8.loss_mask: 0.7579  decode.d8.loss_dice: 1.0949
2023/05/24 04:59:39 - mmengine - INFO - Iter(train) [ 86900/160000]  lr: 4.9411e-06  eta: 8:44:21  time: 0.4165  data_time: 0.0103  memory: 4835  grad_norm: 92.0900  loss: 30.2277  decode.loss_cls: 1.1674  decode.loss_mask: 0.6474  decode.loss_dice: 0.9940  decode.d0.loss_cls: 2.9885  decode.d0.loss_mask: 0.6992  decode.d0.loss_dice: 1.1171  decode.d1.loss_cls: 1.2110  decode.d1.loss_mask: 0.6840  decode.d1.loss_dice: 1.0879  decode.d2.loss_cls: 1.1491  decode.d2.loss_mask: 0.6600  decode.d2.loss_dice: 1.0198  decode.d3.loss_cls: 1.1369  decode.d3.loss_mask: 0.6768  decode.d3.loss_dice: 0.9798  decode.d4.loss_cls: 1.1663  decode.d4.loss_mask: 0.6756  decode.d4.loss_dice: 0.9736  decode.d5.loss_cls: 1.1874  decode.d5.loss_mask: 0.6555  decode.d5.loss_dice: 0.9994  decode.d6.loss_cls: 1.1235  decode.d6.loss_mask: 0.6498  decode.d6.loss_dice: 0.9808  decode.d7.loss_cls: 1.1678  decode.d7.loss_mask: 0.6507  decode.d7.loss_dice: 0.9761  decode.d8.loss_cls: 1.1921  decode.d8.loss_mask: 0.6320  decode.d8.loss_dice: 0.9780
2023/05/24 05:00:01 - mmengine - INFO - Iter(train) [ 86950/160000]  lr: 4.9380e-06  eta: 8:43:59  time: 0.4640  data_time: 0.0104  memory: 4868  grad_norm: 108.8769  loss: 40.3104  decode.loss_cls: 1.4206  decode.loss_mask: 0.7364  decode.loss_dice: 1.5281  decode.d0.loss_cls: 3.3157  decode.d0.loss_mask: 0.8437  decode.d0.loss_dice: 1.7317  decode.d1.loss_cls: 1.8358  decode.d1.loss_mask: 0.8136  decode.d1.loss_dice: 1.6734  decode.d2.loss_cls: 1.5846  decode.d2.loss_mask: 0.7531  decode.d2.loss_dice: 1.6241  decode.d3.loss_cls: 1.5586  decode.d3.loss_mask: 0.7425  decode.d3.loss_dice: 1.5295  decode.d4.loss_cls: 1.5621  decode.d4.loss_mask: 0.7337  decode.d4.loss_dice: 1.5053  decode.d5.loss_cls: 1.5269  decode.d5.loss_mask: 0.7171  decode.d5.loss_dice: 1.5101  decode.d6.loss_cls: 1.4613  decode.d6.loss_mask: 0.7573  decode.d6.loss_dice: 1.5512  decode.d7.loss_cls: 1.4168  decode.d7.loss_mask: 0.7252  decode.d7.loss_dice: 1.5182  decode.d8.loss_cls: 1.4074  decode.d8.loss_mask: 0.7148  decode.d8.loss_dice: 1.5117
2023/05/24 05:00:25 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:00:25 - mmengine - INFO - Iter(train) [ 87000/160000]  lr: 4.9350e-06  eta: 8:43:39  time: 0.4777  data_time: 0.0103  memory: 4786  grad_norm: 92.4647  loss: 35.3017  decode.loss_cls: 1.3309  decode.loss_mask: 0.6527  decode.loss_dice: 1.2157  decode.d0.loss_cls: 3.3499  decode.d0.loss_mask: 0.7512  decode.d0.loss_dice: 1.4303  decode.d1.loss_cls: 1.5561  decode.d1.loss_mask: 0.7015  decode.d1.loss_dice: 1.3562  decode.d2.loss_cls: 1.3990  decode.d2.loss_mask: 0.7190  decode.d2.loss_dice: 1.2923  decode.d3.loss_cls: 1.3729  decode.d3.loss_mask: 0.6780  decode.d3.loss_dice: 1.2373  decode.d4.loss_cls: 1.4627  decode.d4.loss_mask: 0.6625  decode.d4.loss_dice: 1.1874  decode.d5.loss_cls: 1.3859  decode.d5.loss_mask: 0.6780  decode.d5.loss_dice: 1.2399  decode.d6.loss_cls: 1.3650  decode.d6.loss_mask: 0.6635  decode.d6.loss_dice: 1.2044  decode.d7.loss_cls: 1.3406  decode.d7.loss_mask: 0.6576  decode.d7.loss_dice: 1.2404  decode.d8.loss_cls: 1.3132  decode.d8.loss_mask: 0.6518  decode.d8.loss_dice: 1.2055
2023/05/24 05:00:25 - mmengine - INFO - Saving checkpoint at 87000 iterations
2023/05/24 05:00:51 - mmengine - INFO - Iter(train) [ 87050/160000]  lr: 4.9319e-06  eta: 8:43:22  time: 0.4199  data_time: 0.0107  memory: 4845  grad_norm: 76.7412  loss: 35.4372  decode.loss_cls: 1.0604  decode.loss_mask: 0.8509  decode.loss_dice: 1.3879  decode.d0.loss_cls: 2.7981  decode.d0.loss_mask: 0.8540  decode.d0.loss_dice: 1.5672  decode.d1.loss_cls: 1.0050  decode.d1.loss_mask: 0.9444  decode.d1.loss_dice: 1.5431  decode.d2.loss_cls: 1.0172  decode.d2.loss_mask: 0.8844  decode.d2.loss_dice: 1.4913  decode.d3.loss_cls: 1.0403  decode.d3.loss_mask: 0.8646  decode.d3.loss_dice: 1.4283  decode.d4.loss_cls: 1.0030  decode.d4.loss_mask: 0.8872  decode.d4.loss_dice: 1.4516  decode.d5.loss_cls: 1.0250  decode.d5.loss_mask: 0.8700  decode.d5.loss_dice: 1.4395  decode.d6.loss_cls: 0.9373  decode.d6.loss_mask: 0.9047  decode.d6.loss_dice: 1.4789  decode.d7.loss_cls: 1.0044  decode.d7.loss_mask: 0.8946  decode.d7.loss_dice: 1.4424  decode.d8.loss_cls: 1.0625  decode.d8.loss_mask: 0.8651  decode.d8.loss_dice: 1.4337
2023/05/24 05:01:12 - mmengine - INFO - Iter(train) [ 87100/160000]  lr: 4.9289e-06  eta: 8:43:00  time: 0.4310  data_time: 0.0108  memory: 4845  grad_norm: 87.8271  loss: 39.9105  decode.loss_cls: 1.2156  decode.loss_mask: 0.8867  decode.loss_dice: 1.4963  decode.d0.loss_cls: 3.4233  decode.d0.loss_mask: 0.9770  decode.d0.loss_dice: 1.8034  decode.d1.loss_cls: 1.3368  decode.d1.loss_mask: 0.9894  decode.d1.loss_dice: 1.7302  decode.d2.loss_cls: 1.3230  decode.d2.loss_mask: 0.9643  decode.d2.loss_dice: 1.6028  decode.d3.loss_cls: 1.2800  decode.d3.loss_mask: 0.9311  decode.d3.loss_dice: 1.5281  decode.d4.loss_cls: 1.3287  decode.d4.loss_mask: 0.9409  decode.d4.loss_dice: 1.5244  decode.d5.loss_cls: 1.2472  decode.d5.loss_mask: 0.9222  decode.d5.loss_dice: 1.5421  decode.d6.loss_cls: 1.2193  decode.d6.loss_mask: 0.9324  decode.d6.loss_dice: 1.4981  decode.d7.loss_cls: 1.3085  decode.d7.loss_mask: 0.8772  decode.d7.loss_dice: 1.4672  decode.d8.loss_cls: 1.2868  decode.d8.loss_mask: 0.8712  decode.d8.loss_dice: 1.4563
2023/05/24 05:01:34 - mmengine - INFO - Iter(train) [ 87150/160000]  lr: 4.9258e-06  eta: 8:42:39  time: 0.4227  data_time: 0.0109  memory: 4842  grad_norm: 103.0362  loss: 36.0359  decode.loss_cls: 1.3933  decode.loss_mask: 0.7672  decode.loss_dice: 1.1881  decode.d0.loss_cls: 3.0479  decode.d0.loss_mask: 0.8100  decode.d0.loss_dice: 1.3789  decode.d1.loss_cls: 1.5439  decode.d1.loss_mask: 0.7825  decode.d1.loss_dice: 1.2851  decode.d2.loss_cls: 1.4229  decode.d2.loss_mask: 0.8176  decode.d2.loss_dice: 1.2985  decode.d3.loss_cls: 1.4142  decode.d3.loss_mask: 0.7735  decode.d3.loss_dice: 1.2421  decode.d4.loss_cls: 1.3595  decode.d4.loss_mask: 0.7994  decode.d4.loss_dice: 1.2601  decode.d5.loss_cls: 1.3670  decode.d5.loss_mask: 0.7685  decode.d5.loss_dice: 1.2293  decode.d6.loss_cls: 1.3805  decode.d6.loss_mask: 0.7394  decode.d6.loss_dice: 1.2047  decode.d7.loss_cls: 1.3878  decode.d7.loss_mask: 0.7486  decode.d7.loss_dice: 1.2611  decode.d8.loss_cls: 1.4199  decode.d8.loss_mask: 0.7493  decode.d8.loss_dice: 1.1950
2023/05/24 05:01:55 - mmengine - INFO - Iter(train) [ 87200/160000]  lr: 4.9228e-06  eta: 8:42:17  time: 0.4260  data_time: 0.0112  memory: 4867  grad_norm: 98.4142  loss: 41.2728  decode.loss_cls: 1.3673  decode.loss_mask: 0.8582  decode.loss_dice: 1.6277  decode.d0.loss_cls: 3.5104  decode.d0.loss_mask: 0.8877  decode.d0.loss_dice: 1.9467  decode.d1.loss_cls: 1.4503  decode.d1.loss_mask: 0.8840  decode.d1.loss_dice: 1.7648  decode.d2.loss_cls: 1.3263  decode.d2.loss_mask: 0.8856  decode.d2.loss_dice: 1.7105  decode.d3.loss_cls: 1.3688  decode.d3.loss_mask: 0.8636  decode.d3.loss_dice: 1.6492  decode.d4.loss_cls: 1.3872  decode.d4.loss_mask: 0.8510  decode.d4.loss_dice: 1.6652  decode.d5.loss_cls: 1.3540  decode.d5.loss_mask: 0.8499  decode.d5.loss_dice: 1.6618  decode.d6.loss_cls: 1.3640  decode.d6.loss_mask: 0.8277  decode.d6.loss_dice: 1.6120  decode.d7.loss_cls: 1.3458  decode.d7.loss_mask: 0.8407  decode.d7.loss_dice: 1.6220  decode.d8.loss_cls: 1.3304  decode.d8.loss_mask: 0.8411  decode.d8.loss_dice: 1.6187
2023/05/24 05:02:18 - mmengine - INFO - Iter(train) [ 87250/160000]  lr: 4.9198e-06  eta: 8:41:56  time: 0.4439  data_time: 0.0103  memory: 4859  grad_norm: 82.6257  loss: 28.5898  decode.loss_cls: 1.0234  decode.loss_mask: 0.6872  decode.loss_dice: 0.9259  decode.d0.loss_cls: 2.6868  decode.d0.loss_mask: 0.7541  decode.d0.loss_dice: 1.1903  decode.d1.loss_cls: 1.1395  decode.d1.loss_mask: 0.7060  decode.d1.loss_dice: 1.0321  decode.d2.loss_cls: 1.0700  decode.d2.loss_mask: 0.6758  decode.d2.loss_dice: 0.9844  decode.d3.loss_cls: 1.0574  decode.d3.loss_mask: 0.6730  decode.d3.loss_dice: 0.9393  decode.d4.loss_cls: 1.0342  decode.d4.loss_mask: 0.6478  decode.d4.loss_dice: 0.9473  decode.d5.loss_cls: 0.9898  decode.d5.loss_mask: 0.6573  decode.d5.loss_dice: 0.9514  decode.d6.loss_cls: 1.0528  decode.d6.loss_mask: 0.6431  decode.d6.loss_dice: 0.8986  decode.d7.loss_cls: 1.0003  decode.d7.loss_mask: 0.6867  decode.d7.loss_dice: 0.9271  decode.d8.loss_cls: 1.0297  decode.d8.loss_mask: 0.6839  decode.d8.loss_dice: 0.8948
2023/05/24 05:02:39 - mmengine - INFO - Iter(train) [ 87300/160000]  lr: 4.9167e-06  eta: 8:41:34  time: 0.4235  data_time: 0.0103  memory: 4791  grad_norm: 97.2656  loss: 32.8363  decode.loss_cls: 1.1101  decode.loss_mask: 0.7227  decode.loss_dice: 1.1791  decode.d0.loss_cls: 3.0401  decode.d0.loss_mask: 0.7393  decode.d0.loss_dice: 1.3536  decode.d1.loss_cls: 1.3717  decode.d1.loss_mask: 0.7024  decode.d1.loss_dice: 1.2754  decode.d2.loss_cls: 1.2822  decode.d2.loss_mask: 0.7037  decode.d2.loss_dice: 1.2049  decode.d3.loss_cls: 1.2096  decode.d3.loss_mask: 0.7135  decode.d3.loss_dice: 1.1557  decode.d4.loss_cls: 1.1267  decode.d4.loss_mask: 0.7327  decode.d4.loss_dice: 1.1793  decode.d5.loss_cls: 1.1116  decode.d5.loss_mask: 0.7354  decode.d5.loss_dice: 1.1871  decode.d6.loss_cls: 1.1703  decode.d6.loss_mask: 0.6616  decode.d6.loss_dice: 1.1637  decode.d7.loss_cls: 1.2162  decode.d7.loss_mask: 0.6551  decode.d7.loss_dice: 1.1551  decode.d8.loss_cls: 1.0993  decode.d8.loss_mask: 0.6837  decode.d8.loss_dice: 1.1943
2023/05/24 05:03:00 - mmengine - INFO - Iter(train) [ 87350/160000]  lr: 4.9137e-06  eta: 8:41:12  time: 0.4092  data_time: 0.0103  memory: 4886  grad_norm: 95.9547  loss: 41.0028  decode.loss_cls: 1.2774  decode.loss_mask: 0.9458  decode.loss_dice: 1.5797  decode.d0.loss_cls: 3.1568  decode.d0.loss_mask: 0.9167  decode.d0.loss_dice: 1.8153  decode.d1.loss_cls: 1.4303  decode.d1.loss_mask: 0.9502  decode.d1.loss_dice: 1.7162  decode.d2.loss_cls: 1.3897  decode.d2.loss_mask: 0.9689  decode.d2.loss_dice: 1.7083  decode.d3.loss_cls: 1.3309  decode.d3.loss_mask: 0.9168  decode.d3.loss_dice: 1.6223  decode.d4.loss_cls: 1.2901  decode.d4.loss_mask: 0.9646  decode.d4.loss_dice: 1.6303  decode.d5.loss_cls: 1.3138  decode.d5.loss_mask: 0.9448  decode.d5.loss_dice: 1.6069  decode.d6.loss_cls: 1.2853  decode.d6.loss_mask: 0.9585  decode.d6.loss_dice: 1.5695  decode.d7.loss_cls: 1.3210  decode.d7.loss_mask: 0.9451  decode.d7.loss_dice: 1.5904  decode.d8.loss_cls: 1.3231  decode.d8.loss_mask: 0.9337  decode.d8.loss_dice: 1.6003
2023/05/24 05:03:21 - mmengine - INFO - Iter(train) [ 87400/160000]  lr: 4.9106e-06  eta: 8:40:50  time: 0.4266  data_time: 0.0104  memory: 4885  grad_norm: 97.6912  loss: 36.2211  decode.loss_cls: 1.3002  decode.loss_mask: 0.7852  decode.loss_dice: 1.2423  decode.d0.loss_cls: 3.0038  decode.d0.loss_mask: 0.8041  decode.d0.loss_dice: 1.4615  decode.d1.loss_cls: 1.4255  decode.d1.loss_mask: 0.8371  decode.d1.loss_dice: 1.3970  decode.d2.loss_cls: 1.3744  decode.d2.loss_mask: 0.8385  decode.d2.loss_dice: 1.3211  decode.d3.loss_cls: 1.3613  decode.d3.loss_mask: 0.8063  decode.d3.loss_dice: 1.3093  decode.d4.loss_cls: 1.2965  decode.d4.loss_mask: 0.8025  decode.d4.loss_dice: 1.3127  decode.d5.loss_cls: 1.3554  decode.d5.loss_mask: 0.8116  decode.d5.loss_dice: 1.2868  decode.d6.loss_cls: 1.2625  decode.d6.loss_mask: 0.8213  decode.d6.loss_dice: 1.2806  decode.d7.loss_cls: 1.2481  decode.d7.loss_mask: 0.8234  decode.d7.loss_dice: 1.2947  decode.d8.loss_cls: 1.2780  decode.d8.loss_mask: 0.8011  decode.d8.loss_dice: 1.2784
2023/05/24 05:03:42 - mmengine - INFO - Iter(train) [ 87450/160000]  lr: 4.9076e-06  eta: 8:40:28  time: 0.4179  data_time: 0.0102  memory: 4876  grad_norm: 90.4374  loss: 39.4537  decode.loss_cls: 1.3692  decode.loss_mask: 0.8953  decode.loss_dice: 1.3679  decode.d0.loss_cls: 3.3861  decode.d0.loss_mask: 0.9434  decode.d0.loss_dice: 1.6279  decode.d1.loss_cls: 1.4139  decode.d1.loss_mask: 0.9357  decode.d1.loss_dice: 1.5613  decode.d2.loss_cls: 1.4619  decode.d2.loss_mask: 0.8975  decode.d2.loss_dice: 1.4732  decode.d3.loss_cls: 1.4654  decode.d3.loss_mask: 0.8855  decode.d3.loss_dice: 1.4761  decode.d4.loss_cls: 1.3854  decode.d4.loss_mask: 0.8930  decode.d4.loss_dice: 1.4352  decode.d5.loss_cls: 1.3962  decode.d5.loss_mask: 0.8762  decode.d5.loss_dice: 1.4026  decode.d6.loss_cls: 1.3595  decode.d6.loss_mask: 0.9050  decode.d6.loss_dice: 1.3807  decode.d7.loss_cls: 1.3550  decode.d7.loss_mask: 0.8731  decode.d7.loss_dice: 1.3904  decode.d8.loss_cls: 1.3423  decode.d8.loss_mask: 0.9028  decode.d8.loss_dice: 1.3962
2023/05/24 05:04:03 - mmengine - INFO - Iter(train) [ 87500/160000]  lr: 4.9045e-06  eta: 8:40:07  time: 0.4453  data_time: 0.0110  memory: 4821  grad_norm: 97.1047  loss: 39.5514  decode.loss_cls: 1.4758  decode.loss_mask: 0.7274  decode.loss_dice: 1.4414  decode.d0.loss_cls: 3.1926  decode.d0.loss_mask: 0.9629  decode.d0.loss_dice: 1.6734  decode.d1.loss_cls: 1.6770  decode.d1.loss_mask: 0.8500  decode.d1.loss_dice: 1.6238  decode.d2.loss_cls: 1.5880  decode.d2.loss_mask: 0.8044  decode.d2.loss_dice: 1.5268  decode.d3.loss_cls: 1.4825  decode.d3.loss_mask: 0.7393  decode.d3.loss_dice: 1.4749  decode.d4.loss_cls: 1.4436  decode.d4.loss_mask: 0.7838  decode.d4.loss_dice: 1.4899  decode.d5.loss_cls: 1.4653  decode.d5.loss_mask: 0.7941  decode.d5.loss_dice: 1.4735  decode.d6.loss_cls: 1.4382  decode.d6.loss_mask: 0.7745  decode.d6.loss_dice: 1.4694  decode.d7.loss_cls: 1.4395  decode.d7.loss_mask: 0.7235  decode.d7.loss_dice: 1.4271  decode.d8.loss_cls: 1.4713  decode.d8.loss_mask: 0.7182  decode.d8.loss_dice: 1.3993
2023/05/24 05:04:25 - mmengine - INFO - Iter(train) [ 87550/160000]  lr: 4.9015e-06  eta: 8:39:46  time: 0.4399  data_time: 0.0106  memory: 4930  grad_norm: 109.7669  loss: 47.4044  decode.loss_cls: 1.6462  decode.loss_mask: 0.9517  decode.loss_dice: 1.7500  decode.d0.loss_cls: 3.6921  decode.d0.loss_mask: 1.1128  decode.d0.loss_dice: 2.1456  decode.d1.loss_cls: 1.7274  decode.d1.loss_mask: 1.0565  decode.d1.loss_dice: 1.9667  decode.d2.loss_cls: 1.7519  decode.d2.loss_mask: 1.0209  decode.d2.loss_dice: 1.8999  decode.d3.loss_cls: 1.7474  decode.d3.loss_mask: 1.0025  decode.d3.loss_dice: 1.8197  decode.d4.loss_cls: 1.6930  decode.d4.loss_mask: 0.9996  decode.d4.loss_dice: 1.7998  decode.d5.loss_cls: 1.6686  decode.d5.loss_mask: 1.0046  decode.d5.loss_dice: 1.7839  decode.d6.loss_cls: 1.6603  decode.d6.loss_mask: 0.9957  decode.d6.loss_dice: 1.7615  decode.d7.loss_cls: 1.6176  decode.d7.loss_mask: 1.0098  decode.d7.loss_dice: 1.7766  decode.d8.loss_cls: 1.6530  decode.d8.loss_mask: 0.9550  decode.d8.loss_dice: 1.7343
2023/05/24 05:04:46 - mmengine - INFO - Iter(train) [ 87600/160000]  lr: 4.8985e-06  eta: 8:39:24  time: 0.4183  data_time: 0.0103  memory: 4876  grad_norm: 102.2980  loss: 34.2189  decode.loss_cls: 1.0710  decode.loss_mask: 0.8015  decode.loss_dice: 1.2439  decode.d0.loss_cls: 3.0948  decode.d0.loss_mask: 0.8640  decode.d0.loss_dice: 1.4563  decode.d1.loss_cls: 1.2280  decode.d1.loss_mask: 0.8708  decode.d1.loss_dice: 1.3742  decode.d2.loss_cls: 1.1515  decode.d2.loss_mask: 0.7926  decode.d2.loss_dice: 1.3149  decode.d3.loss_cls: 1.0806  decode.d3.loss_mask: 0.7943  decode.d3.loss_dice: 1.2809  decode.d4.loss_cls: 1.0547  decode.d4.loss_mask: 0.8149  decode.d4.loss_dice: 1.2595  decode.d5.loss_cls: 1.1119  decode.d5.loss_mask: 0.7886  decode.d5.loss_dice: 1.2847  decode.d6.loss_cls: 1.0652  decode.d6.loss_mask: 0.8195  decode.d6.loss_dice: 1.2988  decode.d7.loss_cls: 1.0617  decode.d7.loss_mask: 0.8115  decode.d7.loss_dice: 1.2661  decode.d8.loss_cls: 1.0957  decode.d8.loss_mask: 0.8224  decode.d8.loss_dice: 1.2443
2023/05/24 05:05:07 - mmengine - INFO - Iter(train) [ 87650/160000]  lr: 4.8954e-06  eta: 8:39:02  time: 0.4189  data_time: 0.0110  memory: 4900  grad_norm: 101.2767  loss: 41.1858  decode.loss_cls: 1.3332  decode.loss_mask: 0.8510  decode.loss_dice: 1.6513  decode.d0.loss_cls: 3.2915  decode.d0.loss_mask: 0.9298  decode.d0.loss_dice: 1.8070  decode.d1.loss_cls: 1.4183  decode.d1.loss_mask: 0.9695  decode.d1.loss_dice: 1.8005  decode.d2.loss_cls: 1.3954  decode.d2.loss_mask: 0.8795  decode.d2.loss_dice: 1.7229  decode.d3.loss_cls: 1.3830  decode.d3.loss_mask: 0.8837  decode.d3.loss_dice: 1.6536  decode.d4.loss_cls: 1.2307  decode.d4.loss_mask: 0.9264  decode.d4.loss_dice: 1.7086  decode.d5.loss_cls: 1.2747  decode.d5.loss_mask: 0.9134  decode.d5.loss_dice: 1.6695  decode.d6.loss_cls: 1.2466  decode.d6.loss_mask: 0.9107  decode.d6.loss_dice: 1.6303  decode.d7.loss_cls: 1.2664  decode.d7.loss_mask: 0.8985  decode.d7.loss_dice: 1.6729  decode.d8.loss_cls: 1.3263  decode.d8.loss_mask: 0.8880  decode.d8.loss_dice: 1.6528
2023/05/24 05:05:28 - mmengine - INFO - Iter(train) [ 87700/160000]  lr: 4.8924e-06  eta: 8:38:40  time: 0.4186  data_time: 0.0103  memory: 4829  grad_norm: 100.3822  loss: 33.2912  decode.loss_cls: 1.2098  decode.loss_mask: 0.6312  decode.loss_dice: 1.1787  decode.d0.loss_cls: 2.9265  decode.d0.loss_mask: 0.6506  decode.d0.loss_dice: 1.4620  decode.d1.loss_cls: 1.4106  decode.d1.loss_mask: 0.6842  decode.d1.loss_dice: 1.3903  decode.d2.loss_cls: 1.3266  decode.d2.loss_mask: 0.6565  decode.d2.loss_dice: 1.3384  decode.d3.loss_cls: 1.2102  decode.d3.loss_mask: 0.6702  decode.d3.loss_dice: 1.2607  decode.d4.loss_cls: 1.1816  decode.d4.loss_mask: 0.6397  decode.d4.loss_dice: 1.2822  decode.d5.loss_cls: 1.1775  decode.d5.loss_mask: 0.6546  decode.d5.loss_dice: 1.2468  decode.d6.loss_cls: 1.1725  decode.d6.loss_mask: 0.6520  decode.d6.loss_dice: 1.2115  decode.d7.loss_cls: 1.1615  decode.d7.loss_mask: 0.6202  decode.d7.loss_dice: 1.2517  decode.d8.loss_cls: 1.2128  decode.d8.loss_mask: 0.6222  decode.d8.loss_dice: 1.1981
2023/05/24 05:05:49 - mmengine - INFO - Iter(train) [ 87750/160000]  lr: 4.8893e-06  eta: 8:38:18  time: 0.4233  data_time: 0.0106  memory: 4905  grad_norm: 116.5910  loss: 39.7929  decode.loss_cls: 1.2814  decode.loss_mask: 0.8429  decode.loss_dice: 1.5555  decode.d0.loss_cls: 3.1459  decode.d0.loss_mask: 0.8225  decode.d0.loss_dice: 1.8352  decode.d1.loss_cls: 1.4656  decode.d1.loss_mask: 0.8175  decode.d1.loss_dice: 1.7423  decode.d2.loss_cls: 1.3430  decode.d2.loss_mask: 0.7868  decode.d2.loss_dice: 1.6705  decode.d3.loss_cls: 1.3719  decode.d3.loss_mask: 0.8270  decode.d3.loss_dice: 1.5951  decode.d4.loss_cls: 1.3034  decode.d4.loss_mask: 0.7958  decode.d4.loss_dice: 1.6131  decode.d5.loss_cls: 1.3095  decode.d5.loss_mask: 0.8398  decode.d5.loss_dice: 1.6279  decode.d6.loss_cls: 1.3145  decode.d6.loss_mask: 0.8738  decode.d6.loss_dice: 1.5925  decode.d7.loss_cls: 1.2740  decode.d7.loss_mask: 0.8432  decode.d7.loss_dice: 1.5778  decode.d8.loss_cls: 1.2938  decode.d8.loss_mask: 0.8400  decode.d8.loss_dice: 1.5908
2023/05/24 05:06:10 - mmengine - INFO - Iter(train) [ 87800/160000]  lr: 4.8863e-06  eta: 8:37:56  time: 0.4098  data_time: 0.0103  memory: 4884  grad_norm: 94.0489  loss: 31.0987  decode.loss_cls: 1.0339  decode.loss_mask: 0.7794  decode.loss_dice: 1.0930  decode.d0.loss_cls: 2.9844  decode.d0.loss_mask: 0.7815  decode.d0.loss_dice: 1.1282  decode.d1.loss_cls: 1.1273  decode.d1.loss_mask: 0.7693  decode.d1.loss_dice: 1.1181  decode.d2.loss_cls: 1.0440  decode.d2.loss_mask: 0.7636  decode.d2.loss_dice: 1.1135  decode.d3.loss_cls: 1.0229  decode.d3.loss_mask: 0.7749  decode.d3.loss_dice: 1.0978  decode.d4.loss_cls: 0.9824  decode.d4.loss_mask: 0.8159  decode.d4.loss_dice: 1.0886  decode.d5.loss_cls: 0.9932  decode.d5.loss_mask: 0.7859  decode.d5.loss_dice: 1.1088  decode.d6.loss_cls: 1.0527  decode.d6.loss_mask: 0.7762  decode.d6.loss_dice: 1.0719  decode.d7.loss_cls: 0.9989  decode.d7.loss_mask: 0.8020  decode.d7.loss_dice: 1.0834  decode.d8.loss_cls: 1.0407  decode.d8.loss_mask: 0.7648  decode.d8.loss_dice: 1.1012
2023/05/24 05:06:31 - mmengine - INFO - Iter(train) [ 87850/160000]  lr: 4.8832e-06  eta: 8:37:34  time: 0.4135  data_time: 0.0103  memory: 4858  grad_norm: 83.0742  loss: 30.3821  decode.loss_cls: 0.8617  decode.loss_mask: 0.7930  decode.loss_dice: 1.0900  decode.d0.loss_cls: 2.8400  decode.d0.loss_mask: 0.7860  decode.d0.loss_dice: 1.3203  decode.d1.loss_cls: 1.0387  decode.d1.loss_mask: 0.8524  decode.d1.loss_dice: 1.2028  decode.d2.loss_cls: 0.9986  decode.d2.loss_mask: 0.8151  decode.d2.loss_dice: 1.1504  decode.d3.loss_cls: 0.8758  decode.d3.loss_mask: 0.7847  decode.d3.loss_dice: 1.1258  decode.d4.loss_cls: 0.9133  decode.d4.loss_mask: 0.7441  decode.d4.loss_dice: 1.1183  decode.d5.loss_cls: 0.9026  decode.d5.loss_mask: 0.7456  decode.d5.loss_dice: 1.1078  decode.d6.loss_cls: 0.9025  decode.d6.loss_mask: 0.7641  decode.d6.loss_dice: 1.1115  decode.d7.loss_cls: 0.8567  decode.d7.loss_mask: 0.7958  decode.d7.loss_dice: 1.1164  decode.d8.loss_cls: 0.8561  decode.d8.loss_mask: 0.8026  decode.d8.loss_dice: 1.1094
2023/05/24 05:06:52 - mmengine - INFO - Iter(train) [ 87900/160000]  lr: 4.8802e-06  eta: 8:37:12  time: 0.4227  data_time: 0.0104  memory: 4847  grad_norm: 92.0684  loss: 40.3825  decode.loss_cls: 1.3733  decode.loss_mask: 0.9613  decode.loss_dice: 1.4102  decode.d0.loss_cls: 3.1688  decode.d0.loss_mask: 0.9533  decode.d0.loss_dice: 1.7003  decode.d1.loss_cls: 1.4843  decode.d1.loss_mask: 0.9900  decode.d1.loss_dice: 1.5450  decode.d2.loss_cls: 1.4435  decode.d2.loss_mask: 0.9687  decode.d2.loss_dice: 1.4645  decode.d3.loss_cls: 1.4641  decode.d3.loss_mask: 0.9373  decode.d3.loss_dice: 1.4550  decode.d4.loss_cls: 1.4548  decode.d4.loss_mask: 0.9445  decode.d4.loss_dice: 1.4295  decode.d5.loss_cls: 1.4043  decode.d5.loss_mask: 0.9486  decode.d5.loss_dice: 1.4303  decode.d6.loss_cls: 1.4267  decode.d6.loss_mask: 0.9408  decode.d6.loss_dice: 1.4594  decode.d7.loss_cls: 1.4060  decode.d7.loss_mask: 0.9464  decode.d7.loss_dice: 1.4507  decode.d8.loss_cls: 1.4060  decode.d8.loss_mask: 0.9405  decode.d8.loss_dice: 1.4745
2023/05/24 05:07:14 - mmengine - INFO - Iter(train) [ 87950/160000]  lr: 4.8771e-06  eta: 8:36:51  time: 0.4733  data_time: 0.0106  memory: 4833  grad_norm: 95.8437  loss: 37.7187  decode.loss_cls: 1.2460  decode.loss_mask: 0.8345  decode.loss_dice: 1.3434  decode.d0.loss_cls: 3.2044  decode.d0.loss_mask: 0.8956  decode.d0.loss_dice: 1.5822  decode.d1.loss_cls: 1.3311  decode.d1.loss_mask: 0.8944  decode.d1.loss_dice: 1.5228  decode.d2.loss_cls: 1.2659  decode.d2.loss_mask: 0.8706  decode.d2.loss_dice: 1.4360  decode.d3.loss_cls: 1.3381  decode.d3.loss_mask: 0.8572  decode.d3.loss_dice: 1.4154  decode.d4.loss_cls: 1.3704  decode.d4.loss_mask: 0.8125  decode.d4.loss_dice: 1.3759  decode.d5.loss_cls: 1.3420  decode.d5.loss_mask: 0.8461  decode.d5.loss_dice: 1.3615  decode.d6.loss_cls: 1.2991  decode.d6.loss_mask: 0.8717  decode.d6.loss_dice: 1.3679  decode.d7.loss_cls: 1.2685  decode.d7.loss_mask: 0.8848  decode.d7.loss_dice: 1.3752  decode.d8.loss_cls: 1.2862  decode.d8.loss_mask: 0.8508  decode.d8.loss_dice: 1.3686
2023/05/24 05:07:35 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:07:35 - mmengine - INFO - Iter(train) [ 88000/160000]  lr: 4.8741e-06  eta: 8:36:29  time: 0.4176  data_time: 0.0104  memory: 4894  grad_norm: 99.2793  loss: 27.4699  decode.loss_cls: 0.7934  decode.loss_mask: 0.7813  decode.loss_dice: 0.9252  decode.d0.loss_cls: 2.7603  decode.d0.loss_mask: 0.7400  decode.d0.loss_dice: 1.0526  decode.d1.loss_cls: 0.8820  decode.d1.loss_mask: 0.7722  decode.d1.loss_dice: 0.9784  decode.d2.loss_cls: 0.8445  decode.d2.loss_mask: 0.7927  decode.d2.loss_dice: 0.9684  decode.d3.loss_cls: 0.8681  decode.d3.loss_mask: 0.7421  decode.d3.loss_dice: 0.9291  decode.d4.loss_cls: 0.8270  decode.d4.loss_mask: 0.7605  decode.d4.loss_dice: 0.9080  decode.d5.loss_cls: 0.8188  decode.d5.loss_mask: 0.7834  decode.d5.loss_dice: 0.9401  decode.d6.loss_cls: 0.8407  decode.d6.loss_mask: 0.7776  decode.d6.loss_dice: 0.9290  decode.d7.loss_cls: 0.8289  decode.d7.loss_mask: 0.7979  decode.d7.loss_dice: 0.9212  decode.d8.loss_cls: 0.8120  decode.d8.loss_mask: 0.7949  decode.d8.loss_dice: 0.8993
2023/05/24 05:07:35 - mmengine - INFO - Saving checkpoint at 88000 iterations
2023/05/24 05:08:02 - mmengine - INFO - Iter(train) [ 88050/160000]  lr: 4.8710e-06  eta: 8:36:12  time: 0.4132  data_time: 0.0104  memory: 4847  grad_norm: 88.0653  loss: 34.0575  decode.loss_cls: 1.0356  decode.loss_mask: 0.8147  decode.loss_dice: 1.2485  decode.d0.loss_cls: 2.8913  decode.d0.loss_mask: 0.9484  decode.d0.loss_dice: 1.3903  decode.d1.loss_cls: 1.1896  decode.d1.loss_mask: 0.8849  decode.d1.loss_dice: 1.3926  decode.d2.loss_cls: 1.0752  decode.d2.loss_mask: 0.8719  decode.d2.loss_dice: 1.3283  decode.d3.loss_cls: 1.1144  decode.d3.loss_mask: 0.8735  decode.d3.loss_dice: 1.2999  decode.d4.loss_cls: 1.0911  decode.d4.loss_mask: 0.8201  decode.d4.loss_dice: 1.2839  decode.d5.loss_cls: 1.0835  decode.d5.loss_mask: 0.8216  decode.d5.loss_dice: 1.2705  decode.d6.loss_cls: 1.0453  decode.d6.loss_mask: 0.8185  decode.d6.loss_dice: 1.2343  decode.d7.loss_cls: 1.0741  decode.d7.loss_mask: 0.8172  decode.d7.loss_dice: 1.2351  decode.d8.loss_cls: 1.0432  decode.d8.loss_mask: 0.8246  decode.d8.loss_dice: 1.2355
2023/05/24 05:08:23 - mmengine - INFO - Iter(train) [ 88100/160000]  lr: 4.8680e-06  eta: 8:35:50  time: 0.4306  data_time: 0.0105  memory: 4827  grad_norm: 90.6365  loss: 33.2296  decode.loss_cls: 1.2262  decode.loss_mask: 0.6267  decode.loss_dice: 1.1849  decode.d0.loss_cls: 3.0158  decode.d0.loss_mask: 0.7400  decode.d0.loss_dice: 1.3933  decode.d1.loss_cls: 1.4001  decode.d1.loss_mask: 0.6754  decode.d1.loss_dice: 1.2872  decode.d2.loss_cls: 1.3170  decode.d2.loss_mask: 0.6774  decode.d2.loss_dice: 1.2613  decode.d3.loss_cls: 1.3075  decode.d3.loss_mask: 0.6410  decode.d3.loss_dice: 1.1538  decode.d4.loss_cls: 1.2494  decode.d4.loss_mask: 0.6371  decode.d4.loss_dice: 1.1902  decode.d5.loss_cls: 1.2262  decode.d5.loss_mask: 0.6333  decode.d5.loss_dice: 1.2119  decode.d6.loss_cls: 1.3120  decode.d6.loss_mask: 0.6354  decode.d6.loss_dice: 1.1608  decode.d7.loss_cls: 1.2539  decode.d7.loss_mask: 0.6385  decode.d7.loss_dice: 1.1616  decode.d8.loss_cls: 1.1950  decode.d8.loss_mask: 0.6410  decode.d8.loss_dice: 1.1756
2023/05/24 05:08:44 - mmengine - INFO - Iter(train) [ 88150/160000]  lr: 4.8650e-06  eta: 8:35:28  time: 0.4220  data_time: 0.0103  memory: 4847  grad_norm: 120.4451  loss: 31.1037  decode.loss_cls: 1.0412  decode.loss_mask: 0.7947  decode.loss_dice: 1.0163  decode.d0.loss_cls: 2.9520  decode.d0.loss_mask: 0.8531  decode.d0.loss_dice: 1.1746  decode.d1.loss_cls: 1.2243  decode.d1.loss_mask: 0.7898  decode.d1.loss_dice: 1.0942  decode.d2.loss_cls: 1.1210  decode.d2.loss_mask: 0.7862  decode.d2.loss_dice: 1.0901  decode.d3.loss_cls: 1.0809  decode.d3.loss_mask: 0.7551  decode.d3.loss_dice: 1.0562  decode.d4.loss_cls: 1.0802  decode.d4.loss_mask: 0.7741  decode.d4.loss_dice: 1.0557  decode.d5.loss_cls: 1.0732  decode.d5.loss_mask: 0.7747  decode.d5.loss_dice: 1.0375  decode.d6.loss_cls: 0.9950  decode.d6.loss_mask: 0.7823  decode.d6.loss_dice: 1.0223  decode.d7.loss_cls: 1.0074  decode.d7.loss_mask: 0.7807  decode.d7.loss_dice: 1.0521  decode.d8.loss_cls: 1.0043  decode.d8.loss_mask: 0.7937  decode.d8.loss_dice: 1.0408
2023/05/24 05:09:06 - mmengine - INFO - Iter(train) [ 88200/160000]  lr: 4.8619e-06  eta: 8:35:06  time: 0.4221  data_time: 0.0105  memory: 4836  grad_norm: 110.3935  loss: 30.8717  decode.loss_cls: 1.0767  decode.loss_mask: 0.6243  decode.loss_dice: 1.0591  decode.d0.loss_cls: 3.0863  decode.d0.loss_mask: 0.6466  decode.d0.loss_dice: 1.2704  decode.d1.loss_cls: 1.3181  decode.d1.loss_mask: 0.6602  decode.d1.loss_dice: 1.1609  decode.d2.loss_cls: 1.1554  decode.d2.loss_mask: 0.6704  decode.d2.loss_dice: 1.1608  decode.d3.loss_cls: 1.1221  decode.d3.loss_mask: 0.6340  decode.d3.loss_dice: 1.1188  decode.d4.loss_cls: 1.0995  decode.d4.loss_mask: 0.6454  decode.d4.loss_dice: 1.1236  decode.d5.loss_cls: 1.0629  decode.d5.loss_mask: 0.6404  decode.d5.loss_dice: 1.0986  decode.d6.loss_cls: 1.0718  decode.d6.loss_mask: 0.6328  decode.d6.loss_dice: 1.1023  decode.d7.loss_cls: 1.0751  decode.d7.loss_mask: 0.6450  decode.d7.loss_dice: 1.0838  decode.d8.loss_cls: 1.0905  decode.d8.loss_mask: 0.6378  decode.d8.loss_dice: 1.0983
2023/05/24 05:09:27 - mmengine - INFO - Iter(train) [ 88250/160000]  lr: 4.8589e-06  eta: 8:34:44  time: 0.4277  data_time: 0.0112  memory: 4806  grad_norm: 90.2351  loss: 34.1407  decode.loss_cls: 1.1136  decode.loss_mask: 0.7802  decode.loss_dice: 1.2275  decode.d0.loss_cls: 3.1394  decode.d0.loss_mask: 0.9124  decode.d0.loss_dice: 1.4275  decode.d1.loss_cls: 1.2300  decode.d1.loss_mask: 0.8725  decode.d1.loss_dice: 1.3664  decode.d2.loss_cls: 1.1858  decode.d2.loss_mask: 0.8149  decode.d2.loss_dice: 1.2708  decode.d3.loss_cls: 1.1512  decode.d3.loss_mask: 0.8074  decode.d3.loss_dice: 1.2366  decode.d4.loss_cls: 1.1090  decode.d4.loss_mask: 0.8009  decode.d4.loss_dice: 1.2500  decode.d5.loss_cls: 1.1263  decode.d5.loss_mask: 0.7910  decode.d5.loss_dice: 1.2362  decode.d6.loss_cls: 1.1558  decode.d6.loss_mask: 0.7779  decode.d6.loss_dice: 1.1933  decode.d7.loss_cls: 1.0860  decode.d7.loss_mask: 0.7794  decode.d7.loss_dice: 1.2218  decode.d8.loss_cls: 1.0884  decode.d8.loss_mask: 0.7842  decode.d8.loss_dice: 1.2045
2023/05/24 05:09:48 - mmengine - INFO - Iter(train) [ 88300/160000]  lr: 4.8558e-06  eta: 8:34:22  time: 0.4117  data_time: 0.0106  memory: 4845  grad_norm: 93.6097  loss: 36.2070  decode.loss_cls: 1.3360  decode.loss_mask: 0.7920  decode.loss_dice: 1.2577  decode.d0.loss_cls: 3.1276  decode.d0.loss_mask: 0.7799  decode.d0.loss_dice: 1.3478  decode.d1.loss_cls: 1.5013  decode.d1.loss_mask: 0.8174  decode.d1.loss_dice: 1.3494  decode.d2.loss_cls: 1.3887  decode.d2.loss_mask: 0.8103  decode.d2.loss_dice: 1.3011  decode.d3.loss_cls: 1.3673  decode.d3.loss_mask: 0.8218  decode.d3.loss_dice: 1.2562  decode.d4.loss_cls: 1.2886  decode.d4.loss_mask: 0.8105  decode.d4.loss_dice: 1.3182  decode.d5.loss_cls: 1.2914  decode.d5.loss_mask: 0.8040  decode.d5.loss_dice: 1.2530  decode.d6.loss_cls: 1.3547  decode.d6.loss_mask: 0.7765  decode.d6.loss_dice: 1.2646  decode.d7.loss_cls: 1.3141  decode.d7.loss_mask: 0.7925  decode.d7.loss_dice: 1.2866  decode.d8.loss_cls: 1.3275  decode.d8.loss_mask: 0.7955  decode.d8.loss_dice: 1.2746
2023/05/24 05:10:09 - mmengine - INFO - Iter(train) [ 88350/160000]  lr: 4.8528e-06  eta: 8:34:00  time: 0.4186  data_time: 0.0106  memory: 4878  grad_norm: 91.3528  loss: 38.1983  decode.loss_cls: 1.4212  decode.loss_mask: 0.7894  decode.loss_dice: 1.4195  decode.d0.loss_cls: 3.2184  decode.d0.loss_mask: 0.8338  decode.d0.loss_dice: 1.6229  decode.d1.loss_cls: 1.4534  decode.d1.loss_mask: 0.8779  decode.d1.loss_dice: 1.5073  decode.d2.loss_cls: 1.3931  decode.d2.loss_mask: 0.8786  decode.d2.loss_dice: 1.4464  decode.d3.loss_cls: 1.3660  decode.d3.loss_mask: 0.8293  decode.d3.loss_dice: 1.4018  decode.d4.loss_cls: 1.2799  decode.d4.loss_mask: 0.8584  decode.d4.loss_dice: 1.4198  decode.d5.loss_cls: 1.3315  decode.d5.loss_mask: 0.8175  decode.d5.loss_dice: 1.4197  decode.d6.loss_cls: 1.3323  decode.d6.loss_mask: 0.7922  decode.d6.loss_dice: 1.4154  decode.d7.loss_cls: 1.3483  decode.d7.loss_mask: 0.7874  decode.d7.loss_dice: 1.4171  decode.d8.loss_cls: 1.2948  decode.d8.loss_mask: 0.7988  decode.d8.loss_dice: 1.4263
2023/05/24 05:10:31 - mmengine - INFO - Iter(train) [ 88400/160000]  lr: 4.8497e-06  eta: 8:33:40  time: 0.4096  data_time: 0.0103  memory: 4836  grad_norm: 94.5558  loss: 33.0175  decode.loss_cls: 1.3074  decode.loss_mask: 0.6480  decode.loss_dice: 1.0365  decode.d0.loss_cls: 3.0916  decode.d0.loss_mask: 0.7279  decode.d0.loss_dice: 1.2209  decode.d1.loss_cls: 1.3558  decode.d1.loss_mask: 0.7270  decode.d1.loss_dice: 1.2175  decode.d2.loss_cls: 1.3076  decode.d2.loss_mask: 0.7287  decode.d2.loss_dice: 1.0880  decode.d3.loss_cls: 1.3602  decode.d3.loss_mask: 0.6670  decode.d3.loss_dice: 1.0844  decode.d4.loss_cls: 1.3346  decode.d4.loss_mask: 0.7091  decode.d4.loss_dice: 1.0797  decode.d5.loss_cls: 1.3472  decode.d5.loss_mask: 0.7219  decode.d5.loss_dice: 1.0454  decode.d6.loss_cls: 1.3775  decode.d6.loss_mask: 0.6629  decode.d6.loss_dice: 1.0459  decode.d7.loss_cls: 1.3232  decode.d7.loss_mask: 0.7106  decode.d7.loss_dice: 1.0426  decode.d8.loss_cls: 1.3104  decode.d8.loss_mask: 0.7040  decode.d8.loss_dice: 1.0340
2023/05/24 05:10:52 - mmengine - INFO - Iter(train) [ 88450/160000]  lr: 4.8467e-06  eta: 8:33:18  time: 0.4229  data_time: 0.0108  memory: 4845  grad_norm: 95.5422  loss: 35.3842  decode.loss_cls: 1.0851  decode.loss_mask: 0.7409  decode.loss_dice: 1.3285  decode.d0.loss_cls: 3.3891  decode.d0.loss_mask: 0.8091  decode.d0.loss_dice: 1.5881  decode.d1.loss_cls: 1.4006  decode.d1.loss_mask: 0.7878  decode.d1.loss_dice: 1.4611  decode.d2.loss_cls: 1.3048  decode.d2.loss_mask: 0.7352  decode.d2.loss_dice: 1.3938  decode.d3.loss_cls: 1.1787  decode.d3.loss_mask: 0.7395  decode.d3.loss_dice: 1.3721  decode.d4.loss_cls: 1.1641  decode.d4.loss_mask: 0.7424  decode.d4.loss_dice: 1.3876  decode.d5.loss_cls: 1.1593  decode.d5.loss_mask: 0.7373  decode.d5.loss_dice: 1.3550  decode.d6.loss_cls: 1.0620  decode.d6.loss_mask: 0.7450  decode.d6.loss_dice: 1.3532  decode.d7.loss_cls: 1.0703  decode.d7.loss_mask: 0.7558  decode.d7.loss_dice: 1.3581  decode.d8.loss_cls: 1.0837  decode.d8.loss_mask: 0.7375  decode.d8.loss_dice: 1.3585
2023/05/24 05:11:13 - mmengine - INFO - Iter(train) [ 88500/160000]  lr: 4.8436e-06  eta: 8:32:56  time: 0.4214  data_time: 0.0105  memory: 4927  grad_norm: 89.0519  loss: 38.4741  decode.loss_cls: 1.0782  decode.loss_mask: 0.8351  decode.loss_dice: 1.5188  decode.d0.loss_cls: 3.3893  decode.d0.loss_mask: 0.9588  decode.d0.loss_dice: 1.8058  decode.d1.loss_cls: 1.3099  decode.d1.loss_mask: 0.9654  decode.d1.loss_dice: 1.7315  decode.d2.loss_cls: 1.2429  decode.d2.loss_mask: 0.8271  decode.d2.loss_dice: 1.6025  decode.d3.loss_cls: 1.1715  decode.d3.loss_mask: 0.8951  decode.d3.loss_dice: 1.5763  decode.d4.loss_cls: 1.0856  decode.d4.loss_mask: 0.9033  decode.d4.loss_dice: 1.5613  decode.d5.loss_cls: 1.0882  decode.d5.loss_mask: 0.9014  decode.d5.loss_dice: 1.5602  decode.d6.loss_cls: 1.1186  decode.d6.loss_mask: 0.8718  decode.d6.loss_dice: 1.5320  decode.d7.loss_cls: 1.0970  decode.d7.loss_mask: 0.8546  decode.d7.loss_dice: 1.5079  decode.d8.loss_cls: 1.0939  decode.d8.loss_mask: 0.8545  decode.d8.loss_dice: 1.5357
2023/05/24 05:11:35 - mmengine - INFO - Iter(train) [ 88550/160000]  lr: 4.8406e-06  eta: 8:32:34  time: 0.4198  data_time: 0.0106  memory: 4845  grad_norm: 120.3619  loss: 35.4632  decode.loss_cls: 1.1203  decode.loss_mask: 0.8405  decode.loss_dice: 1.2500  decode.d0.loss_cls: 3.1059  decode.d0.loss_mask: 0.8969  decode.d0.loss_dice: 1.5149  decode.d1.loss_cls: 1.3348  decode.d1.loss_mask: 0.8389  decode.d1.loss_dice: 1.4038  decode.d2.loss_cls: 1.2714  decode.d2.loss_mask: 0.8225  decode.d2.loss_dice: 1.3145  decode.d3.loss_cls: 1.2007  decode.d3.loss_mask: 0.8172  decode.d3.loss_dice: 1.3026  decode.d4.loss_cls: 1.1808  decode.d4.loss_mask: 0.8335  decode.d4.loss_dice: 1.3131  decode.d5.loss_cls: 1.1582  decode.d5.loss_mask: 0.8415  decode.d5.loss_dice: 1.3019  decode.d6.loss_cls: 1.0871  decode.d6.loss_mask: 0.8594  decode.d6.loss_dice: 1.3124  decode.d7.loss_cls: 1.0979  decode.d7.loss_mask: 0.8691  decode.d7.loss_dice: 1.2702  decode.d8.loss_cls: 1.1114  decode.d8.loss_mask: 0.8672  decode.d8.loss_dice: 1.3247
2023/05/24 05:11:56 - mmengine - INFO - Iter(train) [ 88600/160000]  lr: 4.8375e-06  eta: 8:32:12  time: 0.4208  data_time: 0.0104  memory: 4775  grad_norm: 99.1513  loss: 28.3321  decode.loss_cls: 0.8234  decode.loss_mask: 0.7863  decode.loss_dice: 0.9153  decode.d0.loss_cls: 2.8450  decode.d0.loss_mask: 0.8137  decode.d0.loss_dice: 0.9773  decode.d1.loss_cls: 1.0536  decode.d1.loss_mask: 0.8223  decode.d1.loss_dice: 1.0244  decode.d2.loss_cls: 0.9257  decode.d2.loss_mask: 0.8393  decode.d2.loss_dice: 0.9743  decode.d3.loss_cls: 0.9383  decode.d3.loss_mask: 0.8009  decode.d3.loss_dice: 0.9464  decode.d4.loss_cls: 0.8823  decode.d4.loss_mask: 0.7989  decode.d4.loss_dice: 0.9598  decode.d5.loss_cls: 0.8798  decode.d5.loss_mask: 0.7874  decode.d5.loss_dice: 0.8944  decode.d6.loss_cls: 0.8795  decode.d6.loss_mask: 0.7880  decode.d6.loss_dice: 0.8974  decode.d7.loss_cls: 0.8506  decode.d7.loss_mask: 0.7793  decode.d7.loss_dice: 0.9086  decode.d8.loss_cls: 0.8576  decode.d8.loss_mask: 0.7776  decode.d8.loss_dice: 0.9048
2023/05/24 05:12:17 - mmengine - INFO - Iter(train) [ 88650/160000]  lr: 4.8345e-06  eta: 8:31:50  time: 0.4254  data_time: 0.0106  memory: 4848  grad_norm: 94.5831  loss: 33.8268  decode.loss_cls: 1.0968  decode.loss_mask: 0.6936  decode.loss_dice: 1.3252  decode.d0.loss_cls: 3.1276  decode.d0.loss_mask: 0.7291  decode.d0.loss_dice: 1.4737  decode.d1.loss_cls: 1.3158  decode.d1.loss_mask: 0.6780  decode.d1.loss_dice: 1.3960  decode.d2.loss_cls: 1.2269  decode.d2.loss_mask: 0.6941  decode.d2.loss_dice: 1.3526  decode.d3.loss_cls: 1.1736  decode.d3.loss_mask: 0.6925  decode.d3.loss_dice: 1.3234  decode.d4.loss_cls: 1.0968  decode.d4.loss_mask: 0.6899  decode.d4.loss_dice: 1.3634  decode.d5.loss_cls: 1.0834  decode.d5.loss_mask: 0.6764  decode.d5.loss_dice: 1.3350  decode.d6.loss_cls: 1.1016  decode.d6.loss_mask: 0.6769  decode.d6.loss_dice: 1.3180  decode.d7.loss_cls: 1.1107  decode.d7.loss_mask: 0.6792  decode.d7.loss_dice: 1.3166  decode.d8.loss_cls: 1.0759  decode.d8.loss_mask: 0.7025  decode.d8.loss_dice: 1.3017
2023/05/24 05:12:38 - mmengine - INFO - Iter(train) [ 88700/160000]  lr: 4.8314e-06  eta: 8:31:29  time: 0.4281  data_time: 0.0107  memory: 4812  grad_norm: 102.4072  loss: 34.2495  decode.loss_cls: 1.2558  decode.loss_mask: 0.6911  decode.loss_dice: 1.2465  decode.d0.loss_cls: 3.0759  decode.d0.loss_mask: 0.7392  decode.d0.loss_dice: 1.4432  decode.d1.loss_cls: 1.3511  decode.d1.loss_mask: 0.7535  decode.d1.loss_dice: 1.3782  decode.d2.loss_cls: 1.1977  decode.d2.loss_mask: 0.7862  decode.d2.loss_dice: 1.3055  decode.d3.loss_cls: 1.1799  decode.d3.loss_mask: 0.7688  decode.d3.loss_dice: 1.2823  decode.d4.loss_cls: 1.2331  decode.d4.loss_mask: 0.6861  decode.d4.loss_dice: 1.2431  decode.d5.loss_cls: 1.2474  decode.d5.loss_mask: 0.6916  decode.d5.loss_dice: 1.2578  decode.d6.loss_cls: 1.2226  decode.d6.loss_mask: 0.6988  decode.d6.loss_dice: 1.2330  decode.d7.loss_cls: 1.1757  decode.d7.loss_mask: 0.7019  decode.d7.loss_dice: 1.2543  decode.d8.loss_cls: 1.2287  decode.d8.loss_mask: 0.6821  decode.d8.loss_dice: 1.2383
2023/05/24 05:12:59 - mmengine - INFO - Iter(train) [ 88750/160000]  lr: 4.8284e-06  eta: 8:31:07  time: 0.4248  data_time: 0.0111  memory: 4829  grad_norm: 81.8946  loss: 38.4714  decode.loss_cls: 1.3676  decode.loss_mask: 0.8219  decode.loss_dice: 1.3786  decode.d0.loss_cls: 3.3584  decode.d0.loss_mask: 0.7972  decode.d0.loss_dice: 1.5835  decode.d1.loss_cls: 1.4480  decode.d1.loss_mask: 0.8092  decode.d1.loss_dice: 1.5146  decode.d2.loss_cls: 1.4509  decode.d2.loss_mask: 0.7895  decode.d2.loss_dice: 1.4809  decode.d3.loss_cls: 1.3596  decode.d3.loss_mask: 0.8097  decode.d3.loss_dice: 1.4402  decode.d4.loss_cls: 1.3591  decode.d4.loss_mask: 0.8058  decode.d4.loss_dice: 1.4381  decode.d5.loss_cls: 1.4181  decode.d5.loss_mask: 0.7914  decode.d5.loss_dice: 1.4130  decode.d6.loss_cls: 1.3831  decode.d6.loss_mask: 0.8076  decode.d6.loss_dice: 1.4167  decode.d7.loss_cls: 1.3824  decode.d7.loss_mask: 0.8064  decode.d7.loss_dice: 1.4132  decode.d8.loss_cls: 1.3889  decode.d8.loss_mask: 0.8218  decode.d8.loss_dice: 1.4161
2023/05/24 05:13:20 - mmengine - INFO - Iter(train) [ 88800/160000]  lr: 4.8253e-06  eta: 8:30:45  time: 0.4219  data_time: 0.0104  memory: 4845  grad_norm: 93.2227  loss: 34.9739  decode.loss_cls: 1.0664  decode.loss_mask: 0.7766  decode.loss_dice: 1.3226  decode.d0.loss_cls: 2.9611  decode.d0.loss_mask: 0.9498  decode.d0.loss_dice: 1.5789  decode.d1.loss_cls: 1.1618  decode.d1.loss_mask: 0.8978  decode.d1.loss_dice: 1.4691  decode.d2.loss_cls: 1.1581  decode.d2.loss_mask: 0.8221  decode.d2.loss_dice: 1.4319  decode.d3.loss_cls: 1.1049  decode.d3.loss_mask: 0.8005  decode.d3.loss_dice: 1.3570  decode.d4.loss_cls: 1.0819  decode.d4.loss_mask: 0.7805  decode.d4.loss_dice: 1.3395  decode.d5.loss_cls: 1.1064  decode.d5.loss_mask: 0.7746  decode.d5.loss_dice: 1.3518  decode.d6.loss_cls: 1.1361  decode.d6.loss_mask: 0.7953  decode.d6.loss_dice: 1.3269  decode.d7.loss_cls: 1.1261  decode.d7.loss_mask: 0.7920  decode.d7.loss_dice: 1.3079  decode.d8.loss_cls: 1.0837  decode.d8.loss_mask: 0.7845  decode.d8.loss_dice: 1.3279
2023/05/24 05:13:43 - mmengine - INFO - Iter(train) [ 88850/160000]  lr: 4.8223e-06  eta: 8:30:24  time: 0.4502  data_time: 0.0105  memory: 4835  grad_norm: 105.4136  loss: 39.1105  decode.loss_cls: 1.4001  decode.loss_mask: 0.7770  decode.loss_dice: 1.5142  decode.d0.loss_cls: 3.0783  decode.d0.loss_mask: 0.8457  decode.d0.loss_dice: 1.6390  decode.d1.loss_cls: 1.4655  decode.d1.loss_mask: 0.8791  decode.d1.loss_dice: 1.6292  decode.d2.loss_cls: 1.4517  decode.d2.loss_mask: 0.8499  decode.d2.loss_dice: 1.5433  decode.d3.loss_cls: 1.4733  decode.d3.loss_mask: 0.7887  decode.d3.loss_dice: 1.5036  decode.d4.loss_cls: 1.4018  decode.d4.loss_mask: 0.7825  decode.d4.loss_dice: 1.5010  decode.d5.loss_cls: 1.3760  decode.d5.loss_mask: 0.7819  decode.d5.loss_dice: 1.5089  decode.d6.loss_cls: 1.4280  decode.d6.loss_mask: 0.7750  decode.d6.loss_dice: 1.4436  decode.d7.loss_cls: 1.3815  decode.d7.loss_mask: 0.7766  decode.d7.loss_dice: 1.4661  decode.d8.loss_cls: 1.3670  decode.d8.loss_mask: 0.7846  decode.d8.loss_dice: 1.4974
2023/05/24 05:14:04 - mmengine - INFO - Iter(train) [ 88900/160000]  lr: 4.8192e-06  eta: 8:30:02  time: 0.4152  data_time: 0.0103  memory: 4821  grad_norm: 89.6730  loss: 43.3741  decode.loss_cls: 1.3139  decode.loss_mask: 0.9622  decode.loss_dice: 1.7730  decode.d0.loss_cls: 3.4561  decode.d0.loss_mask: 0.9952  decode.d0.loss_dice: 2.0103  decode.d1.loss_cls: 1.4420  decode.d1.loss_mask: 0.9873  decode.d1.loss_dice: 1.9378  decode.d2.loss_cls: 1.4168  decode.d2.loss_mask: 0.9260  decode.d2.loss_dice: 1.8567  decode.d3.loss_cls: 1.4080  decode.d3.loss_mask: 0.9332  decode.d3.loss_dice: 1.7902  decode.d4.loss_cls: 1.3028  decode.d4.loss_mask: 0.9218  decode.d4.loss_dice: 1.8045  decode.d5.loss_cls: 1.2592  decode.d5.loss_mask: 0.9279  decode.d5.loss_dice: 1.8469  decode.d6.loss_cls: 1.3102  decode.d6.loss_mask: 0.9315  decode.d6.loss_dice: 1.7637  decode.d7.loss_cls: 1.2847  decode.d7.loss_mask: 0.9152  decode.d7.loss_dice: 1.8143  decode.d8.loss_cls: 1.3241  decode.d8.loss_mask: 0.9411  decode.d8.loss_dice: 1.8173
2023/05/24 05:14:26 - mmengine - INFO - Iter(train) [ 88950/160000]  lr: 4.8162e-06  eta: 8:29:41  time: 0.4251  data_time: 0.0105  memory: 4907  grad_norm: 130.0671  loss: 42.4282  decode.loss_cls: 1.4591  decode.loss_mask: 0.9151  decode.loss_dice: 1.5835  decode.d0.loss_cls: 3.4549  decode.d0.loss_mask: 0.9636  decode.d0.loss_dice: 1.7457  decode.d1.loss_cls: 1.6087  decode.d1.loss_mask: 1.0086  decode.d1.loss_dice: 1.7368  decode.d2.loss_cls: 1.5336  decode.d2.loss_mask: 0.9103  decode.d2.loss_dice: 1.6853  decode.d3.loss_cls: 1.5389  decode.d3.loss_mask: 0.9293  decode.d3.loss_dice: 1.6381  decode.d4.loss_cls: 1.4330  decode.d4.loss_mask: 0.9373  decode.d4.loss_dice: 1.6468  decode.d5.loss_cls: 1.4607  decode.d5.loss_mask: 0.8919  decode.d5.loss_dice: 1.5833  decode.d6.loss_cls: 1.4248  decode.d6.loss_mask: 0.9334  decode.d6.loss_dice: 1.5944  decode.d7.loss_cls: 1.4599  decode.d7.loss_mask: 0.8965  decode.d7.loss_dice: 1.5584  decode.d8.loss_cls: 1.4334  decode.d8.loss_mask: 0.9011  decode.d8.loss_dice: 1.5618
2023/05/24 05:14:46 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:14:47 - mmengine - INFO - Iter(train) [ 89000/160000]  lr: 4.8131e-06  eta: 8:29:19  time: 0.4133  data_time: 0.0103  memory: 4844  grad_norm: 87.1139  loss: 31.8160  decode.loss_cls: 1.0580  decode.loss_mask: 0.7260  decode.loss_dice: 1.1482  decode.d0.loss_cls: 3.0060  decode.d0.loss_mask: 0.7112  decode.d0.loss_dice: 1.3046  decode.d1.loss_cls: 1.0866  decode.d1.loss_mask: 0.7281  decode.d1.loss_dice: 1.2237  decode.d2.loss_cls: 1.1751  decode.d2.loss_mask: 0.6869  decode.d2.loss_dice: 1.1717  decode.d3.loss_cls: 1.1169  decode.d3.loss_mask: 0.6716  decode.d3.loss_dice: 1.1645  decode.d4.loss_cls: 1.1323  decode.d4.loss_mask: 0.6782  decode.d4.loss_dice: 1.1578  decode.d5.loss_cls: 1.1270  decode.d5.loss_mask: 0.6790  decode.d5.loss_dice: 1.1445  decode.d6.loss_cls: 1.0851  decode.d6.loss_mask: 0.7189  decode.d6.loss_dice: 1.1273  decode.d7.loss_cls: 1.1138  decode.d7.loss_mask: 0.7173  decode.d7.loss_dice: 1.1722  decode.d8.loss_cls: 1.1194  decode.d8.loss_mask: 0.7205  decode.d8.loss_dice: 1.1436
2023/05/24 05:14:47 - mmengine - INFO - Saving checkpoint at 89000 iterations
2023/05/24 05:15:13 - mmengine - INFO - Iter(train) [ 89050/160000]  lr: 4.8101e-06  eta: 8:29:01  time: 0.4205  data_time: 0.0106  memory: 4821  grad_norm: 110.4738  loss: 37.1228  decode.loss_cls: 1.1346  decode.loss_mask: 0.8514  decode.loss_dice: 1.4295  decode.d0.loss_cls: 3.0837  decode.d0.loss_mask: 0.9332  decode.d0.loss_dice: 1.5374  decode.d1.loss_cls: 1.2536  decode.d1.loss_mask: 0.8995  decode.d1.loss_dice: 1.5105  decode.d2.loss_cls: 1.1888  decode.d2.loss_mask: 0.8863  decode.d2.loss_dice: 1.4402  decode.d3.loss_cls: 1.2309  decode.d3.loss_mask: 0.8341  decode.d3.loss_dice: 1.4487  decode.d4.loss_cls: 1.2115  decode.d4.loss_mask: 0.8636  decode.d4.loss_dice: 1.4304  decode.d5.loss_cls: 1.1866  decode.d5.loss_mask: 0.8314  decode.d5.loss_dice: 1.4111  decode.d6.loss_cls: 1.2262  decode.d6.loss_mask: 0.8518  decode.d6.loss_dice: 1.4482  decode.d7.loss_cls: 1.2091  decode.d7.loss_mask: 0.8604  decode.d7.loss_dice: 1.4455  decode.d8.loss_cls: 1.1646  decode.d8.loss_mask: 0.8541  decode.d8.loss_dice: 1.4655
2023/05/24 05:15:34 - mmengine - INFO - Iter(train) [ 89100/160000]  lr: 4.8070e-06  eta: 8:28:39  time: 0.4149  data_time: 0.0104  memory: 4875  grad_norm: 91.0843  loss: 33.8451  decode.loss_cls: 1.2780  decode.loss_mask: 0.7507  decode.loss_dice: 1.0835  decode.d0.loss_cls: 3.1520  decode.d0.loss_mask: 0.7792  decode.d0.loss_dice: 1.3704  decode.d1.loss_cls: 1.3850  decode.d1.loss_mask: 0.7855  decode.d1.loss_dice: 1.2610  decode.d2.loss_cls: 1.2423  decode.d2.loss_mask: 0.7288  decode.d2.loss_dice: 1.2008  decode.d3.loss_cls: 1.3107  decode.d3.loss_mask: 0.7365  decode.d3.loss_dice: 1.1323  decode.d4.loss_cls: 1.2702  decode.d4.loss_mask: 0.7666  decode.d4.loss_dice: 1.1567  decode.d5.loss_cls: 1.1738  decode.d5.loss_mask: 0.7706  decode.d5.loss_dice: 1.1249  decode.d6.loss_cls: 1.2362  decode.d6.loss_mask: 0.7603  decode.d6.loss_dice: 1.1020  decode.d7.loss_cls: 1.3062  decode.d7.loss_mask: 0.7524  decode.d7.loss_dice: 1.0979  decode.d8.loss_cls: 1.3045  decode.d8.loss_mask: 0.7389  decode.d8.loss_dice: 1.0870
2023/05/24 05:15:55 - mmengine - INFO - Iter(train) [ 89150/160000]  lr: 4.8040e-06  eta: 8:28:17  time: 0.4211  data_time: 0.0104  memory: 4784  grad_norm: 98.0495  loss: 33.7276  decode.loss_cls: 1.3876  decode.loss_mask: 0.7084  decode.loss_dice: 1.0886  decode.d0.loss_cls: 2.9670  decode.d0.loss_mask: 0.7693  decode.d0.loss_dice: 1.2580  decode.d1.loss_cls: 1.4664  decode.d1.loss_mask: 0.7262  decode.d1.loss_dice: 1.1476  decode.d2.loss_cls: 1.3673  decode.d2.loss_mask: 0.6823  decode.d2.loss_dice: 1.1158  decode.d3.loss_cls: 1.3783  decode.d3.loss_mask: 0.6965  decode.d3.loss_dice: 1.0850  decode.d4.loss_cls: 1.3551  decode.d4.loss_mask: 0.7010  decode.d4.loss_dice: 1.0983  decode.d5.loss_cls: 1.3776  decode.d5.loss_mask: 0.6890  decode.d5.loss_dice: 1.1085  decode.d6.loss_cls: 1.4536  decode.d6.loss_mask: 0.7150  decode.d6.loss_dice: 1.0566  decode.d7.loss_cls: 1.3987  decode.d7.loss_mask: 0.7174  decode.d7.loss_dice: 1.0741  decode.d8.loss_cls: 1.3264  decode.d8.loss_mask: 0.7173  decode.d8.loss_dice: 1.0949
2023/05/24 05:16:16 - mmengine - INFO - Iter(train) [ 89200/160000]  lr: 4.8009e-06  eta: 8:27:55  time: 0.4134  data_time: 0.0101  memory: 4868  grad_norm: 96.3307  loss: 37.0243  decode.loss_cls: 1.1453  decode.loss_mask: 0.8343  decode.loss_dice: 1.3652  decode.d0.loss_cls: 3.5558  decode.d0.loss_mask: 0.8609  decode.d0.loss_dice: 1.5367  decode.d1.loss_cls: 1.3327  decode.d1.loss_mask: 0.8654  decode.d1.loss_dice: 1.4817  decode.d2.loss_cls: 1.3202  decode.d2.loss_mask: 0.8463  decode.d2.loss_dice: 1.4358  decode.d3.loss_cls: 1.2623  decode.d3.loss_mask: 0.8191  decode.d3.loss_dice: 1.4008  decode.d4.loss_cls: 1.1832  decode.d4.loss_mask: 0.8410  decode.d4.loss_dice: 1.4105  decode.d5.loss_cls: 1.1587  decode.d5.loss_mask: 0.8346  decode.d5.loss_dice: 1.4354  decode.d6.loss_cls: 1.2030  decode.d6.loss_mask: 0.8110  decode.d6.loss_dice: 1.3398  decode.d7.loss_cls: 1.1266  decode.d7.loss_mask: 0.8426  decode.d7.loss_dice: 1.3830  decode.d8.loss_cls: 1.1362  decode.d8.loss_mask: 0.8548  decode.d8.loss_dice: 1.4015
2023/05/24 05:16:37 - mmengine - INFO - Iter(train) [ 89250/160000]  lr: 4.7979e-06  eta: 8:27:34  time: 0.4449  data_time: 0.0103  memory: 4825  grad_norm: 123.9702  loss: 34.8316  decode.loss_cls: 1.2692  decode.loss_mask: 0.8719  decode.loss_dice: 1.1240  decode.d0.loss_cls: 3.0740  decode.d0.loss_mask: 0.9245  decode.d0.loss_dice: 1.3024  decode.d1.loss_cls: 1.2537  decode.d1.loss_mask: 0.9488  decode.d1.loss_dice: 1.1905  decode.d2.loss_cls: 1.2616  decode.d2.loss_mask: 0.9411  decode.d2.loss_dice: 1.2122  decode.d3.loss_cls: 1.2199  decode.d3.loss_mask: 0.8702  decode.d3.loss_dice: 1.1389  decode.d4.loss_cls: 1.2162  decode.d4.loss_mask: 0.9284  decode.d4.loss_dice: 1.1696  decode.d5.loss_cls: 1.2130  decode.d5.loss_mask: 0.8829  decode.d5.loss_dice: 1.1584  decode.d6.loss_cls: 1.1771  decode.d6.loss_mask: 0.8630  decode.d6.loss_dice: 1.1345  decode.d7.loss_cls: 1.2371  decode.d7.loss_mask: 0.8582  decode.d7.loss_dice: 1.1443  decode.d8.loss_cls: 1.2064  decode.d8.loss_mask: 0.8859  decode.d8.loss_dice: 1.1537
2023/05/24 05:16:58 - mmengine - INFO - Iter(train) [ 89300/160000]  lr: 4.7948e-06  eta: 8:27:11  time: 0.4119  data_time: 0.0106  memory: 4893  grad_norm: 88.8537  loss: 38.7409  decode.loss_cls: 1.4016  decode.loss_mask: 0.7612  decode.loss_dice: 1.3665  decode.d0.loss_cls: 3.5575  decode.d0.loss_mask: 0.8896  decode.d0.loss_dice: 1.7444  decode.d1.loss_cls: 1.4681  decode.d1.loss_mask: 0.8719  decode.d1.loss_dice: 1.5459  decode.d2.loss_cls: 1.4186  decode.d2.loss_mask: 0.8105  decode.d2.loss_dice: 1.4707  decode.d3.loss_cls: 1.3659  decode.d3.loss_mask: 0.8440  decode.d3.loss_dice: 1.4428  decode.d4.loss_cls: 1.3347  decode.d4.loss_mask: 0.8163  decode.d4.loss_dice: 1.4375  decode.d5.loss_cls: 1.3909  decode.d5.loss_mask: 0.7666  decode.d5.loss_dice: 1.4083  decode.d6.loss_cls: 1.3779  decode.d6.loss_mask: 0.7952  decode.d6.loss_dice: 1.3753  decode.d7.loss_cls: 1.3733  decode.d7.loss_mask: 0.7709  decode.d7.loss_dice: 1.3922  decode.d8.loss_cls: 1.3932  decode.d8.loss_mask: 0.7637  decode.d8.loss_dice: 1.3858
2023/05/24 05:17:18 - mmengine - INFO - Iter(train) [ 89350/160000]  lr: 4.7918e-06  eta: 8:26:49  time: 0.4085  data_time: 0.0103  memory: 4812  grad_norm: 95.8188  loss: 34.9338  decode.loss_cls: 1.0822  decode.loss_mask: 0.6420  decode.loss_dice: 1.4409  decode.d0.loss_cls: 3.3041  decode.d0.loss_mask: 0.6797  decode.d0.loss_dice: 1.6377  decode.d1.loss_cls: 1.2752  decode.d1.loss_mask: 0.6573  decode.d1.loss_dice: 1.5637  decode.d2.loss_cls: 1.2317  decode.d2.loss_mask: 0.6314  decode.d2.loss_dice: 1.5032  decode.d3.loss_cls: 1.1378  decode.d3.loss_mask: 0.6889  decode.d3.loss_dice: 1.4975  decode.d4.loss_cls: 1.1456  decode.d4.loss_mask: 0.6469  decode.d4.loss_dice: 1.4570  decode.d5.loss_cls: 1.1163  decode.d5.loss_mask: 0.6360  decode.d5.loss_dice: 1.4358  decode.d6.loss_cls: 1.1073  decode.d6.loss_mask: 0.6439  decode.d6.loss_dice: 1.4255  decode.d7.loss_cls: 1.1213  decode.d7.loss_mask: 0.6261  decode.d7.loss_dice: 1.4098  decode.d8.loss_cls: 1.0938  decode.d8.loss_mask: 0.6398  decode.d8.loss_dice: 1.4553
2023/05/24 05:17:42 - mmengine - INFO - Iter(train) [ 89400/160000]  lr: 4.7887e-06  eta: 8:26:29  time: 0.4746  data_time: 0.0104  memory: 4837  grad_norm: 109.5442  loss: 34.3998  decode.loss_cls: 1.3419  decode.loss_mask: 0.6016  decode.loss_dice: 1.2014  decode.d0.loss_cls: 3.1698  decode.d0.loss_mask: 0.6713  decode.d0.loss_dice: 1.4755  decode.d1.loss_cls: 1.4796  decode.d1.loss_mask: 0.6254  decode.d1.loss_dice: 1.3649  decode.d2.loss_cls: 1.4347  decode.d2.loss_mask: 0.6181  decode.d2.loss_dice: 1.2620  decode.d3.loss_cls: 1.4194  decode.d3.loss_mask: 0.6086  decode.d3.loss_dice: 1.2253  decode.d4.loss_cls: 1.4040  decode.d4.loss_mask: 0.6054  decode.d4.loss_dice: 1.2471  decode.d5.loss_cls: 1.3890  decode.d5.loss_mask: 0.6000  decode.d5.loss_dice: 1.2119  decode.d6.loss_cls: 1.3787  decode.d6.loss_mask: 0.5853  decode.d6.loss_dice: 1.1993  decode.d7.loss_cls: 1.3202  decode.d7.loss_mask: 0.6024  decode.d7.loss_dice: 1.2273  decode.d8.loss_cls: 1.3204  decode.d8.loss_mask: 0.5953  decode.d8.loss_dice: 1.2143
2023/05/24 05:18:03 - mmengine - INFO - Iter(train) [ 89450/160000]  lr: 4.7857e-06  eta: 8:26:08  time: 0.4221  data_time: 0.0106  memory: 4879  grad_norm: 96.7556  loss: 46.4012  decode.loss_cls: 1.5508  decode.loss_mask: 0.9442  decode.loss_dice: 1.8652  decode.d0.loss_cls: 3.3653  decode.d0.loss_mask: 0.9795  decode.d0.loss_dice: 2.1040  decode.d1.loss_cls: 1.7269  decode.d1.loss_mask: 0.9874  decode.d1.loss_dice: 2.0230  decode.d2.loss_cls: 1.7617  decode.d2.loss_mask: 0.9801  decode.d2.loss_dice: 1.8587  decode.d3.loss_cls: 1.6806  decode.d3.loss_mask: 0.9368  decode.d3.loss_dice: 1.8383  decode.d4.loss_cls: 1.5659  decode.d4.loss_mask: 0.9708  decode.d4.loss_dice: 1.8947  decode.d5.loss_cls: 1.5159  decode.d5.loss_mask: 1.0003  decode.d5.loss_dice: 1.8741  decode.d6.loss_cls: 1.5295  decode.d6.loss_mask: 0.9598  decode.d6.loss_dice: 1.8904  decode.d7.loss_cls: 1.4685  decode.d7.loss_mask: 0.9439  decode.d7.loss_dice: 1.8778  decode.d8.loss_cls: 1.4917  decode.d8.loss_mask: 0.9440  decode.d8.loss_dice: 1.8713
2023/05/24 05:18:25 - mmengine - INFO - Iter(train) [ 89500/160000]  lr: 4.7826e-06  eta: 8:25:46  time: 0.4452  data_time: 0.0101  memory: 4823  grad_norm: 147.8509  loss: 30.3924  decode.loss_cls: 1.0488  decode.loss_mask: 0.6937  decode.loss_dice: 1.0452  decode.d0.loss_cls: 2.9599  decode.d0.loss_mask: 0.7239  decode.d0.loss_dice: 1.1479  decode.d1.loss_cls: 1.2139  decode.d1.loss_mask: 0.7171  decode.d1.loss_dice: 1.1239  decode.d2.loss_cls: 1.1458  decode.d2.loss_mask: 0.7038  decode.d2.loss_dice: 1.0775  decode.d3.loss_cls: 1.1175  decode.d3.loss_mask: 0.7039  decode.d3.loss_dice: 1.0378  decode.d4.loss_cls: 1.0180  decode.d4.loss_mask: 0.6921  decode.d4.loss_dice: 1.0693  decode.d5.loss_cls: 1.0351  decode.d5.loss_mask: 0.7060  decode.d5.loss_dice: 1.0654  decode.d6.loss_cls: 1.0777  decode.d6.loss_mask: 0.6849  decode.d6.loss_dice: 1.0296  decode.d7.loss_cls: 1.0225  decode.d7.loss_mask: 0.6878  decode.d7.loss_dice: 1.0558  decode.d8.loss_cls: 1.0616  decode.d8.loss_mask: 0.6874  decode.d8.loss_dice: 1.0385
2023/05/24 05:18:48 - mmengine - INFO - Iter(train) [ 89550/160000]  lr: 4.7796e-06  eta: 8:25:26  time: 0.4752  data_time: 0.0103  memory: 4832  grad_norm: 90.9011  loss: 33.5524  decode.loss_cls: 1.1419  decode.loss_mask: 0.6488  decode.loss_dice: 1.2467  decode.d0.loss_cls: 2.9891  decode.d0.loss_mask: 0.6941  decode.d0.loss_dice: 1.4490  decode.d1.loss_cls: 1.2582  decode.d1.loss_mask: 0.6572  decode.d1.loss_dice: 1.3428  decode.d2.loss_cls: 1.2754  decode.d2.loss_mask: 0.7014  decode.d2.loss_dice: 1.3000  decode.d3.loss_cls: 1.2256  decode.d3.loss_mask: 0.7017  decode.d3.loss_dice: 1.2976  decode.d4.loss_cls: 1.1719  decode.d4.loss_mask: 0.6967  decode.d4.loss_dice: 1.3219  decode.d5.loss_cls: 1.1590  decode.d5.loss_mask: 0.6918  decode.d5.loss_dice: 1.2869  decode.d6.loss_cls: 1.1444  decode.d6.loss_mask: 0.7022  decode.d6.loss_dice: 1.2613  decode.d7.loss_cls: 1.0971  decode.d7.loss_mask: 0.6927  decode.d7.loss_dice: 1.2801  decode.d8.loss_cls: 1.1741  decode.d8.loss_mask: 0.6947  decode.d8.loss_dice: 1.2481
2023/05/24 05:19:11 - mmengine - INFO - Iter(train) [ 89600/160000]  lr: 4.7765e-06  eta: 8:25:05  time: 0.4170  data_time: 0.0107  memory: 4815  grad_norm: 91.9849  loss: 32.4022  decode.loss_cls: 1.0437  decode.loss_mask: 0.7342  decode.loss_dice: 1.1972  decode.d0.loss_cls: 2.9155  decode.d0.loss_mask: 0.8182  decode.d0.loss_dice: 1.3878  decode.d1.loss_cls: 1.0526  decode.d1.loss_mask: 0.7982  decode.d1.loss_dice: 1.3270  decode.d2.loss_cls: 1.0482  decode.d2.loss_mask: 0.7335  decode.d2.loss_dice: 1.2313  decode.d3.loss_cls: 1.1021  decode.d3.loss_mask: 0.7385  decode.d3.loss_dice: 1.2181  decode.d4.loss_cls: 1.0659  decode.d4.loss_mask: 0.7440  decode.d4.loss_dice: 1.2165  decode.d5.loss_cls: 1.0935  decode.d5.loss_mask: 0.7525  decode.d5.loss_dice: 1.2155  decode.d6.loss_cls: 1.0360  decode.d6.loss_mask: 0.7456  decode.d6.loss_dice: 1.2043  decode.d7.loss_cls: 1.0571  decode.d7.loss_mask: 0.7282  decode.d7.loss_dice: 1.2026  decode.d8.loss_cls: 1.0638  decode.d8.loss_mask: 0.7326  decode.d8.loss_dice: 1.1982
2023/05/24 05:19:32 - mmengine - INFO - Iter(train) [ 89650/160000]  lr: 4.7734e-06  eta: 8:24:43  time: 0.4227  data_time: 0.0105  memory: 4807  grad_norm: 103.2912  loss: 39.8977  decode.loss_cls: 1.5396  decode.loss_mask: 0.6706  decode.loss_dice: 1.4771  decode.d0.loss_cls: 3.3300  decode.d0.loss_mask: 0.8056  decode.d0.loss_dice: 1.8134  decode.d1.loss_cls: 1.7300  decode.d1.loss_mask: 0.7828  decode.d1.loss_dice: 1.5769  decode.d2.loss_cls: 1.6088  decode.d2.loss_mask: 0.7196  decode.d2.loss_dice: 1.5937  decode.d3.loss_cls: 1.5265  decode.d3.loss_mask: 0.7128  decode.d3.loss_dice: 1.5304  decode.d4.loss_cls: 1.4814  decode.d4.loss_mask: 0.6973  decode.d4.loss_dice: 1.5332  decode.d5.loss_cls: 1.4535  decode.d5.loss_mask: 0.6990  decode.d5.loss_dice: 1.5591  decode.d6.loss_cls: 1.5088  decode.d6.loss_mask: 0.6843  decode.d6.loss_dice: 1.4972  decode.d7.loss_cls: 1.5735  decode.d7.loss_mask: 0.6703  decode.d7.loss_dice: 1.4893  decode.d8.loss_cls: 1.5126  decode.d8.loss_mask: 0.6850  decode.d8.loss_dice: 1.4354
2023/05/24 05:19:53 - mmengine - INFO - Iter(train) [ 89700/160000]  lr: 4.7704e-06  eta: 8:24:22  time: 0.4164  data_time: 0.0105  memory: 4870  grad_norm: 95.6961  loss: 33.2159  decode.loss_cls: 1.1710  decode.loss_mask: 0.6541  decode.loss_dice: 1.2105  decode.d0.loss_cls: 2.7835  decode.d0.loss_mask: 0.7593  decode.d0.loss_dice: 1.4607  decode.d1.loss_cls: 1.2374  decode.d1.loss_mask: 0.7610  decode.d1.loss_dice: 1.3566  decode.d2.loss_cls: 1.2592  decode.d2.loss_mask: 0.7187  decode.d2.loss_dice: 1.2932  decode.d3.loss_cls: 1.2635  decode.d3.loss_mask: 0.6838  decode.d3.loss_dice: 1.2454  decode.d4.loss_cls: 1.2428  decode.d4.loss_mask: 0.6307  decode.d4.loss_dice: 1.2536  decode.d5.loss_cls: 1.1944  decode.d5.loss_mask: 0.6650  decode.d5.loss_dice: 1.2367  decode.d6.loss_cls: 1.1914  decode.d6.loss_mask: 0.6438  decode.d6.loss_dice: 1.2072  decode.d7.loss_cls: 1.1944  decode.d7.loss_mask: 0.6337  decode.d7.loss_dice: 1.1951  decode.d8.loss_cls: 1.1789  decode.d8.loss_mask: 0.6603  decode.d8.loss_dice: 1.2299
2023/05/24 05:20:15 - mmengine - INFO - Iter(train) [ 89750/160000]  lr: 4.7673e-06  eta: 8:24:00  time: 0.4195  data_time: 0.0102  memory: 4839  grad_norm: 91.2776  loss: 31.3668  decode.loss_cls: 1.0729  decode.loss_mask: 0.6803  decode.loss_dice: 1.0558  decode.d0.loss_cls: 2.9352  decode.d0.loss_mask: 0.7090  decode.d0.loss_dice: 1.3114  decode.d1.loss_cls: 1.2131  decode.d1.loss_mask: 0.7149  decode.d1.loss_dice: 1.1949  decode.d2.loss_cls: 1.1297  decode.d2.loss_mask: 0.7418  decode.d2.loss_dice: 1.1461  decode.d3.loss_cls: 1.1683  decode.d3.loss_mask: 0.7039  decode.d3.loss_dice: 1.1820  decode.d4.loss_cls: 1.0943  decode.d4.loss_mask: 0.7189  decode.d4.loss_dice: 1.1266  decode.d5.loss_cls: 1.0668  decode.d5.loss_mask: 0.7052  decode.d5.loss_dice: 1.0988  decode.d6.loss_cls: 1.0596  decode.d6.loss_mask: 0.7182  decode.d6.loss_dice: 1.0739  decode.d7.loss_cls: 1.0601  decode.d7.loss_mask: 0.6899  decode.d7.loss_dice: 1.0778  decode.d8.loss_cls: 1.0867  decode.d8.loss_mask: 0.6887  decode.d8.loss_dice: 1.1420
2023/05/24 05:20:36 - mmengine - INFO - Iter(train) [ 89800/160000]  lr: 4.7643e-06  eta: 8:23:38  time: 0.4221  data_time: 0.0104  memory: 4863  grad_norm: 84.8494  loss: 24.7003  decode.loss_cls: 0.8689  decode.loss_mask: 0.5381  decode.loss_dice: 0.7514  decode.d0.loss_cls: 2.7819  decode.d0.loss_mask: 0.6303  decode.d0.loss_dice: 0.9422  decode.d1.loss_cls: 1.0397  decode.d1.loss_mask: 0.5697  decode.d1.loss_dice: 0.8414  decode.d2.loss_cls: 0.9469  decode.d2.loss_mask: 0.5554  decode.d2.loss_dice: 0.8096  decode.d3.loss_cls: 0.8730  decode.d3.loss_mask: 0.5541  decode.d3.loss_dice: 0.8261  decode.d4.loss_cls: 0.8905  decode.d4.loss_mask: 0.5596  decode.d4.loss_dice: 0.8113  decode.d5.loss_cls: 0.9660  decode.d5.loss_mask: 0.5652  decode.d5.loss_dice: 0.8178  decode.d6.loss_cls: 0.8799  decode.d6.loss_mask: 0.5489  decode.d6.loss_dice: 0.7741  decode.d7.loss_cls: 0.8641  decode.d7.loss_mask: 0.5438  decode.d7.loss_dice: 0.7665  decode.d8.loss_cls: 0.8692  decode.d8.loss_mask: 0.5409  decode.d8.loss_dice: 0.7738
2023/05/24 05:20:57 - mmengine - INFO - Iter(train) [ 89850/160000]  lr: 4.7612e-06  eta: 8:23:17  time: 0.4175  data_time: 0.0104  memory: 4827  grad_norm: 137.7876  loss: 36.9172  decode.loss_cls: 1.1372  decode.loss_mask: 0.8903  decode.loss_dice: 1.3571  decode.d0.loss_cls: 2.9573  decode.d0.loss_mask: 1.0153  decode.d0.loss_dice: 1.6207  decode.d1.loss_cls: 1.2732  decode.d1.loss_mask: 1.0007  decode.d1.loss_dice: 1.4678  decode.d2.loss_cls: 1.2373  decode.d2.loss_mask: 0.9363  decode.d2.loss_dice: 1.4254  decode.d3.loss_cls: 1.2159  decode.d3.loss_mask: 0.9050  decode.d3.loss_dice: 1.4021  decode.d4.loss_cls: 1.1410  decode.d4.loss_mask: 0.9225  decode.d4.loss_dice: 1.3931  decode.d5.loss_cls: 1.1133  decode.d5.loss_mask: 0.9127  decode.d5.loss_dice: 1.3973  decode.d6.loss_cls: 1.2079  decode.d6.loss_mask: 0.8538  decode.d6.loss_dice: 1.3584  decode.d7.loss_cls: 1.1302  decode.d7.loss_mask: 0.8899  decode.d7.loss_dice: 1.3526  decode.d8.loss_cls: 1.0994  decode.d8.loss_mask: 0.9194  decode.d8.loss_dice: 1.3842
2023/05/24 05:21:18 - mmengine - INFO - Iter(train) [ 89900/160000]  lr: 4.7582e-06  eta: 8:22:55  time: 0.4198  data_time: 0.0108  memory: 4830  grad_norm: 108.4244  loss: 42.6603  decode.loss_cls: 1.3522  decode.loss_mask: 1.0027  decode.loss_dice: 1.5797  decode.d0.loss_cls: 3.3387  decode.d0.loss_mask: 1.0970  decode.d0.loss_dice: 1.8881  decode.d1.loss_cls: 1.4639  decode.d1.loss_mask: 1.0448  decode.d1.loss_dice: 1.7958  decode.d2.loss_cls: 1.3509  decode.d2.loss_mask: 1.0490  decode.d2.loss_dice: 1.7491  decode.d3.loss_cls: 1.4373  decode.d3.loss_mask: 1.0121  decode.d3.loss_dice: 1.6759  decode.d4.loss_cls: 1.3444  decode.d4.loss_mask: 1.0403  decode.d4.loss_dice: 1.6554  decode.d5.loss_cls: 1.3853  decode.d5.loss_mask: 1.0115  decode.d5.loss_dice: 1.5819  decode.d6.loss_cls: 1.2959  decode.d6.loss_mask: 1.0149  decode.d6.loss_dice: 1.6359  decode.d7.loss_cls: 1.3323  decode.d7.loss_mask: 1.0066  decode.d7.loss_dice: 1.6081  decode.d8.loss_cls: 1.3081  decode.d8.loss_mask: 1.0002  decode.d8.loss_dice: 1.6024
2023/05/24 05:21:41 - mmengine - INFO - Iter(train) [ 89950/160000]  lr: 4.7551e-06  eta: 8:22:34  time: 0.4705  data_time: 0.0101  memory: 4889  grad_norm: 111.1645  loss: 38.3326  decode.loss_cls: 1.1759  decode.loss_mask: 0.7698  decode.loss_dice: 1.5837  decode.d0.loss_cls: 3.2932  decode.d0.loss_mask: 0.7971  decode.d0.loss_dice: 1.8029  decode.d1.loss_cls: 1.3585  decode.d1.loss_mask: 0.7920  decode.d1.loss_dice: 1.6505  decode.d2.loss_cls: 1.2447  decode.d2.loss_mask: 0.8046  decode.d2.loss_dice: 1.6605  decode.d3.loss_cls: 1.2226  decode.d3.loss_mask: 0.7606  decode.d3.loss_dice: 1.6011  decode.d4.loss_cls: 1.2612  decode.d4.loss_mask: 0.7629  decode.d4.loss_dice: 1.6052  decode.d5.loss_cls: 1.2603  decode.d5.loss_mask: 0.7743  decode.d5.loss_dice: 1.5538  decode.d6.loss_cls: 1.2362  decode.d6.loss_mask: 0.7637  decode.d6.loss_dice: 1.5865  decode.d7.loss_cls: 1.2071  decode.d7.loss_mask: 0.7619  decode.d7.loss_dice: 1.5587  decode.d8.loss_cls: 1.1571  decode.d8.loss_mask: 0.7602  decode.d8.loss_dice: 1.5657
2023/05/24 05:22:04 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:22:04 - mmengine - INFO - Iter(train) [ 90000/160000]  lr: 4.7521e-06  eta: 8:22:14  time: 0.4821  data_time: 0.0106  memory: 4857  grad_norm: 96.9413  loss: 34.1364  decode.loss_cls: 1.2529  decode.loss_mask: 0.6975  decode.loss_dice: 1.2040  decode.d0.loss_cls: 3.1239  decode.d0.loss_mask: 0.7677  decode.d0.loss_dice: 1.4154  decode.d1.loss_cls: 1.2914  decode.d1.loss_mask: 0.7735  decode.d1.loss_dice: 1.3557  decode.d2.loss_cls: 1.2482  decode.d2.loss_mask: 0.7572  decode.d2.loss_dice: 1.3134  decode.d3.loss_cls: 1.2473  decode.d3.loss_mask: 0.7208  decode.d3.loss_dice: 1.2576  decode.d4.loss_cls: 1.2001  decode.d4.loss_mask: 0.7054  decode.d4.loss_dice: 1.2479  decode.d5.loss_cls: 1.2089  decode.d5.loss_mask: 0.7122  decode.d5.loss_dice: 1.2381  decode.d6.loss_cls: 1.1629  decode.d6.loss_mask: 0.7112  decode.d6.loss_dice: 1.2338  decode.d7.loss_cls: 1.2338  decode.d7.loss_mask: 0.7019  decode.d7.loss_dice: 1.2250  decode.d8.loss_cls: 1.2326  decode.d8.loss_mask: 0.6866  decode.d8.loss_dice: 1.2094
2023/05/24 05:22:04 - mmengine - INFO - Saving checkpoint at 90000 iterations
2023/05/24 05:22:14 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0799  data_time: 0.0031  memory: 2167  
2023/05/24 05:22:19 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0899  data_time: 0.0019  memory: 2216  
2023/05/24 05:22:23 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:40  time: 0.0999  data_time: 0.0021  memory: 2167  
2023/05/24 05:22:27 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0792  data_time: 0.0018  memory: 2104  
2023/05/24 05:22:31 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0790  data_time: 0.0018  memory: 2831  
2023/05/24 05:22:35 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0782  data_time: 0.0017  memory: 2167  
2023/05/24 05:22:39 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0793  data_time: 0.0017  memory: 2167  
2023/05/24 05:22:46 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0867  data_time: 0.0020  memory: 2167  
2023/05/24 05:22:50 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0877  data_time: 0.0018  memory: 2944  
2023/05/24 05:22:54 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0789  data_time: 0.0018  memory: 2356  
2023/05/24 05:22:58 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0851  data_time: 0.0018  memory: 2217  
2023/05/24 05:23:02 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0796  data_time: 0.0018  memory: 2328  
2023/05/24 05:23:06 - mmengine - INFO - per class results:
2023/05/24 05:23:06 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.15 | 93.62 |
|     bicycle      | 69.58 | 83.86 |
|       car        | 59.47 | 87.13 |
|    motorcycle    | 83.17 | 90.95 |
|     airplane     | 81.79 | 93.33 |
|       bus        |  80.4 | 88.67 |
|      train       | 83.31 | 92.51 |
|      truck       | 48.72 | 60.13 |
|       boat       | 55.86 |  78.6 |
|  traffic light   | 66.78 | 86.23 |
|   fire hydrant   |  87.0 | 95.67 |
|    stop sign     | 91.28 |  97.2 |
|  parking meter   | 76.58 | 86.06 |
|      bench       | 48.56 | 66.42 |
|       bird       | 80.29 | 91.34 |
|       cat        | 86.26 | 94.26 |
|       dog        | 81.04 | 89.97 |
|      horse       | 77.54 | 89.79 |
|      sheep       | 85.31 | 92.93 |
|       cow        | 82.12 | 89.44 |
|     elephant     | 89.21 | 95.29 |
|       bear       |  92.6 | 95.46 |
|      zebra       | 90.35 | 94.22 |
|     giraffe      | 87.24 | 93.89 |
|     backpack     | 35.16 |  55.4 |
|     umbrella     | 78.72 | 89.41 |
|     handbag      | 33.45 |  56.8 |
|       tie        | 11.37 | 22.71 |
|     suitcase     | 77.71 | 93.74 |
|     frisbee      | 73.19 | 90.12 |
|       skis       | 43.54 | 65.12 |
|    snowboard     | 42.15 | 51.55 |
|   sports ball    | 54.74 | 74.54 |
|       kite       | 56.23 | 73.28 |
|   baseball bat   | 42.88 | 51.78 |
|  baseball glove  | 71.35 | 87.71 |
|    skateboard    | 76.57 | 88.98 |
|    surfboard     | 68.03 | 87.68 |
|  tennis racket   | 80.76 | 91.16 |
|      bottle      | 44.85 | 60.95 |
|    wine glass    | 56.03 | 83.06 |
|       cup        | 52.46 | 79.07 |
|       fork       | 42.05 | 56.07 |
|      knife       | 35.69 | 47.35 |
|      spoon       | 34.61 | 61.68 |
|       bowl       | 46.37 | 71.97 |
|      banana      | 67.28 | 90.34 |
|      apple       |  53.0 | 71.73 |
|     sandwich     | 41.81 | 57.09 |
|      orange      | 65.13 |  76.2 |
|     broccoli     | 54.17 | 65.09 |
|      carrot      | 54.03 | 63.38 |
|     hot dog      | 51.12 | 63.23 |
|      pizza       | 71.67 | 83.75 |
|      donut       | 69.47 | 86.41 |
|       cake       | 68.47 | 79.85 |
|      chair       | 45.31 | 64.36 |
|      couch       | 56.18 | 80.45 |
|   potted plant   | 30.22 | 49.89 |
|       bed        | 62.45 | 77.16 |
|   dining table   | 44.41 | 75.77 |
|      toilet      | 79.85 | 94.15 |
|        tv        | 73.89 | 83.73 |
|      laptop      | 72.24 | 87.81 |
|      mouse       | 66.43 |  90.1 |
|      remote      | 49.59 | 74.04 |
|     keyboard     | 60.89 | 75.22 |
|    cell phone    | 71.15 | 89.17 |
|    microwave     | 63.37 | 75.29 |
|       oven       |  57.2 | 80.51 |
|     toaster      | 39.64 | 54.48 |
|       sink       | 56.93 | 78.93 |
|   refrigerator   |  78.7 | 90.29 |
|       book       | 46.12 | 67.34 |
|      clock       | 74.34 | 85.22 |
|       vase       | 56.21 | 84.02 |
|     scissors     | 78.45 | 93.31 |
|    teddy bear    | 74.32 | 87.19 |
|    hair drier    | 44.58 |  46.1 |
|    toothbrush    | 29.51 | 67.64 |
|      banner      | 40.29 | 62.87 |
|     blanket      |  9.35 | 11.78 |
|      branch      | 20.17 | 32.17 |
|      bridge      | 33.23 | 40.96 |
|  building-other  | 53.25 | 71.89 |
|       bush       | 32.22 | 50.17 |
|     cabinet      | 49.21 | 72.54 |
|       cage       | 22.16 | 46.33 |
|    cardboard     |  42.6 | 53.91 |
|      carpet      |  52.3 | 68.88 |
|  ceiling-other   | 63.78 | 83.51 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 20.74 | 27.98 |
|      clouds      | 41.66 | 51.59 |
|     counter      | 29.43 | 48.49 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      |  61.8 | 76.23 |
|    desk-stuff    | 42.66 |  65.1 |
|       dirt       | 40.41 | 58.39 |
|    door-stuff    | 36.15 | 60.35 |
|      fence       | 26.64 | 42.32 |
|   floor-marble   |  6.61 |  9.39 |
|   floor-other    | 20.86 | 28.27 |
|   floor-stone    |  6.5  |  7.56 |
|    floor-tile    | 59.13 | 73.85 |
|    floor-wood    |  59.2 | 70.96 |
|      flower      |  38.9 | 57.71 |
|       fog        |  5.35 |  5.69 |
|    food-other    | 23.15 | 27.24 |
|      fruit       | 36.57 |  50.1 |
| furniture-other  | 17.77 | 24.09 |
|      grass       | 70.02 |  81.7 |
|      gravel      | 26.24 | 37.68 |
|   ground-other   |  0.17 |  0.19 |
|       hill       | 13.63 | 16.06 |
|      house       | 25.11 | 30.75 |
|      leaves      | 27.58 | 43.38 |
|      light       | 36.83 | 54.87 |
|       mat        |  0.0  |  0.0  |
|      metal       |  32.6 | 51.94 |
|   mirror-stuff   | 42.48 | 74.75 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 51.99 | 76.05 |
|       mud        |  3.92 |  7.0  |
|      napkin      |  7.73 |  7.75 |
|       net        | 44.29 | 61.08 |
|      paper       | 30.13 | 45.77 |
|     pavement     | 51.32 | 72.15 |
|      pillow      |  9.55 | 12.38 |
|   plant-other    | 19.22 | 27.49 |
|     plastic      | 18.31 | 24.57 |
|     platform     | 26.04 | 41.87 |
|   playingfield   | 69.93 | 90.08 |
|     railing      |  4.91 |  6.91 |
|     railroad     | 61.03 | 79.81 |
|      river       | 53.28 | 69.25 |
|       road       | 65.58 | 79.39 |
|       rock       | 29.23 | 40.29 |
|       roof       | 11.42 | 14.47 |
|       rug        |  33.3 | 52.51 |
|      salad       |  0.15 |  0.19 |
|       sand       | 60.82 |  68.7 |
|       sea        | 85.58 | 90.73 |
|      shelf       | 32.03 | 44.43 |
|    sky-other     | 69.71 | 89.19 |
|    skyscraper    | 33.57 |  41.7 |
|       snow       |  87.8 | 92.04 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 20.54 | 32.76 |
|      stone       | 15.01 | 36.79 |
|      straw       | 34.55 | 53.72 |
| structural-other |  0.0  |  0.0  |
|      table       | 18.27 | 24.19 |
|       tent       |  7.33 |  8.78 |
|  textile-other   | 12.15 | 20.19 |
|      towel       | 31.26 |  41.5 |
|       tree       | 73.12 | 85.36 |
|    vegetable     | 35.91 | 50.23 |
|    wall-brick    |  45.0 | 64.18 |
|  wall-concrete   | 59.78 | 80.11 |
|    wall-other    | 17.16 |  26.4 |
|    wall-panel    |  0.67 |  0.76 |
|    wall-stone    | 29.19 | 36.54 |
|    wall-tile     | 65.21 | 82.81 |
|    wall-wood     | 39.17 | 51.24 |
|   water-other    | 28.21 | 47.04 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 49.67 | 60.77 |
|   window-other   | 44.86 | 71.86 |
|       wood       | 26.12 | 37.76 |
+------------------+-------+-------+
2023/05/24 05:23:06 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.8200  mIoU: 46.3000  mAcc: 59.5100  data_time: 0.0021  time: 0.0862
2023/05/24 05:23:06 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_80000.pth is removed
2023/05/24 05:23:10 - mmengine - INFO - The best checkpoint with 46.3000 mIoU at 90000 iter is saved to best_mIoU_iter_90000.pth.
2023/05/24 05:23:31 - mmengine - INFO - Iter(train) [ 90050/160000]  lr: 4.7490e-06  eta: 8:21:57  time: 0.4300  data_time: 0.0110  memory: 4823  grad_norm: 93.9107  loss: 31.3146  decode.loss_cls: 1.1995  decode.loss_mask: 0.6052  decode.loss_dice: 1.0568  decode.d0.loss_cls: 3.1431  decode.d0.loss_mask: 0.6197  decode.d0.loss_dice: 1.2445  decode.d1.loss_cls: 1.4212  decode.d1.loss_mask: 0.6480  decode.d1.loss_dice: 1.1569  decode.d2.loss_cls: 1.1609  decode.d2.loss_mask: 0.6782  decode.d2.loss_dice: 1.1255  decode.d3.loss_cls: 1.1406  decode.d3.loss_mask: 0.6777  decode.d3.loss_dice: 1.0987  decode.d4.loss_cls: 1.1297  decode.d4.loss_mask: 0.6739  decode.d4.loss_dice: 1.1078  decode.d5.loss_cls: 1.1414  decode.d5.loss_mask: 0.6645  decode.d5.loss_dice: 1.0772  decode.d6.loss_cls: 1.1358  decode.d6.loss_mask: 0.6074  decode.d6.loss_dice: 1.0742  decode.d7.loss_cls: 1.1558  decode.d7.loss_mask: 0.6096  decode.d7.loss_dice: 1.0779  decode.d8.loss_cls: 1.1814  decode.d8.loss_mask: 0.6134  decode.d8.loss_dice: 1.0876
2023/05/24 05:23:52 - mmengine - INFO - Iter(train) [ 90100/160000]  lr: 4.7460e-06  eta: 8:21:35  time: 0.4165  data_time: 0.0104  memory: 4843  grad_norm: 88.8225  loss: 37.0707  decode.loss_cls: 1.2405  decode.loss_mask: 0.9205  decode.loss_dice: 1.2669  decode.d0.loss_cls: 3.1791  decode.d0.loss_mask: 0.8872  decode.d0.loss_dice: 1.5123  decode.d1.loss_cls: 1.3481  decode.d1.loss_mask: 0.9906  decode.d1.loss_dice: 1.4661  decode.d2.loss_cls: 1.2306  decode.d2.loss_mask: 0.9544  decode.d2.loss_dice: 1.3782  decode.d3.loss_cls: 1.2026  decode.d3.loss_mask: 0.9128  decode.d3.loss_dice: 1.3389  decode.d4.loss_cls: 1.2019  decode.d4.loss_mask: 0.9466  decode.d4.loss_dice: 1.3458  decode.d5.loss_cls: 1.2022  decode.d5.loss_mask: 0.9152  decode.d5.loss_dice: 1.3047  decode.d6.loss_cls: 1.1928  decode.d6.loss_mask: 0.9367  decode.d6.loss_dice: 1.3223  decode.d7.loss_cls: 1.1640  decode.d7.loss_mask: 0.9487  decode.d7.loss_dice: 1.2945  decode.d8.loss_cls: 1.1995  decode.d8.loss_mask: 0.9431  decode.d8.loss_dice: 1.3237
2023/05/24 05:24:13 - mmengine - INFO - Iter(train) [ 90150/160000]  lr: 4.7429e-06  eta: 8:21:13  time: 0.4107  data_time: 0.0102  memory: 4857  grad_norm: 88.7942  loss: 35.1794  decode.loss_cls: 1.3060  decode.loss_mask: 0.7398  decode.loss_dice: 1.0916  decode.d0.loss_cls: 3.2661  decode.d0.loss_mask: 0.9228  decode.d0.loss_dice: 1.3391  decode.d1.loss_cls: 1.4785  decode.d1.loss_mask: 0.8389  decode.d1.loss_dice: 1.2715  decode.d2.loss_cls: 1.3979  decode.d2.loss_mask: 0.8241  decode.d2.loss_dice: 1.2105  decode.d3.loss_cls: 1.4071  decode.d3.loss_mask: 0.7658  decode.d3.loss_dice: 1.1606  decode.d4.loss_cls: 1.3654  decode.d4.loss_mask: 0.7865  decode.d4.loss_dice: 1.1383  decode.d5.loss_cls: 1.3231  decode.d5.loss_mask: 0.7936  decode.d5.loss_dice: 1.1543  decode.d6.loss_cls: 1.3570  decode.d6.loss_mask: 0.7659  decode.d6.loss_dice: 1.0923  decode.d7.loss_cls: 1.3272  decode.d7.loss_mask: 0.7636  decode.d7.loss_dice: 1.1183  decode.d8.loss_cls: 1.3165  decode.d8.loss_mask: 0.7606  decode.d8.loss_dice: 1.0966
2023/05/24 05:24:34 - mmengine - INFO - Iter(train) [ 90200/160000]  lr: 4.7398e-06  eta: 8:20:51  time: 0.4240  data_time: 0.0104  memory: 4971  grad_norm: 92.3282  loss: 44.9462  decode.loss_cls: 1.7840  decode.loss_mask: 0.8366  decode.loss_dice: 1.6294  decode.d0.loss_cls: 3.5140  decode.d0.loss_mask: 0.9835  decode.d0.loss_dice: 1.9757  decode.d1.loss_cls: 1.7959  decode.d1.loss_mask: 0.8783  decode.d1.loss_dice: 1.8114  decode.d2.loss_cls: 1.6853  decode.d2.loss_mask: 0.9000  decode.d2.loss_dice: 1.6969  decode.d3.loss_cls: 1.6857  decode.d3.loss_mask: 0.8576  decode.d3.loss_dice: 1.7272  decode.d4.loss_cls: 1.6945  decode.d4.loss_mask: 0.8672  decode.d4.loss_dice: 1.6997  decode.d5.loss_cls: 1.7079  decode.d5.loss_mask: 0.8633  decode.d5.loss_dice: 1.6609  decode.d6.loss_cls: 1.7622  decode.d6.loss_mask: 0.8407  decode.d6.loss_dice: 1.6453  decode.d7.loss_cls: 1.7580  decode.d7.loss_mask: 0.8400  decode.d7.loss_dice: 1.6320  decode.d8.loss_cls: 1.7609  decode.d8.loss_mask: 0.8273  decode.d8.loss_dice: 1.6247
2023/05/24 05:24:56 - mmengine - INFO - Iter(train) [ 90250/160000]  lr: 4.7368e-06  eta: 8:20:29  time: 0.4760  data_time: 0.0108  memory: 4900  grad_norm: 94.3435  loss: 36.0847  decode.loss_cls: 1.2584  decode.loss_mask: 0.7831  decode.loss_dice: 1.2395  decode.d0.loss_cls: 3.3539  decode.d0.loss_mask: 0.7889  decode.d0.loss_dice: 1.4915  decode.d1.loss_cls: 1.3393  decode.d1.loss_mask: 0.8253  decode.d1.loss_dice: 1.4287  decode.d2.loss_cls: 1.2978  decode.d2.loss_mask: 0.8324  decode.d2.loss_dice: 1.3409  decode.d3.loss_cls: 1.2752  decode.d3.loss_mask: 0.7874  decode.d3.loss_dice: 1.2777  decode.d4.loss_cls: 1.2860  decode.d4.loss_mask: 0.8001  decode.d4.loss_dice: 1.2854  decode.d5.loss_cls: 1.2709  decode.d5.loss_mask: 0.7823  decode.d5.loss_dice: 1.2632  decode.d6.loss_cls: 1.3020  decode.d6.loss_mask: 0.7877  decode.d6.loss_dice: 1.2597  decode.d7.loss_cls: 1.2919  decode.d7.loss_mask: 0.7924  decode.d7.loss_dice: 1.2771  decode.d8.loss_cls: 1.2692  decode.d8.loss_mask: 0.8128  decode.d8.loss_dice: 1.2840
2023/05/24 05:25:19 - mmengine - INFO - Iter(train) [ 90300/160000]  lr: 4.7337e-06  eta: 8:20:09  time: 0.4237  data_time: 0.0109  memory: 4846  grad_norm: 117.0877  loss: 30.1718  decode.loss_cls: 0.8262  decode.loss_mask: 0.7229  decode.loss_dice: 1.1452  decode.d0.loss_cls: 2.8387  decode.d0.loss_mask: 0.7596  decode.d0.loss_dice: 1.3338  decode.d1.loss_cls: 0.9773  decode.d1.loss_mask: 0.7737  decode.d1.loss_dice: 1.2587  decode.d2.loss_cls: 0.9447  decode.d2.loss_mask: 0.7210  decode.d2.loss_dice: 1.2145  decode.d3.loss_cls: 0.9670  decode.d3.loss_mask: 0.7116  decode.d3.loss_dice: 1.1872  decode.d4.loss_cls: 0.9266  decode.d4.loss_mask: 0.7197  decode.d4.loss_dice: 1.1932  decode.d5.loss_cls: 0.9080  decode.d5.loss_mask: 0.6907  decode.d5.loss_dice: 1.1856  decode.d6.loss_cls: 0.8952  decode.d6.loss_mask: 0.6904  decode.d6.loss_dice: 1.1349  decode.d7.loss_cls: 0.8706  decode.d7.loss_mask: 0.6952  decode.d7.loss_dice: 1.1677  decode.d8.loss_cls: 0.8266  decode.d8.loss_mask: 0.7189  decode.d8.loss_dice: 1.1662
2023/05/24 05:25:40 - mmengine - INFO - Iter(train) [ 90350/160000]  lr: 4.7307e-06  eta: 8:19:47  time: 0.4165  data_time: 0.0103  memory: 4800  grad_norm: 93.1930  loss: 33.8126  decode.loss_cls: 1.1968  decode.loss_mask: 0.6141  decode.loss_dice: 1.2507  decode.d0.loss_cls: 3.1570  decode.d0.loss_mask: 0.6484  decode.d0.loss_dice: 1.4455  decode.d1.loss_cls: 1.4316  decode.d1.loss_mask: 0.6121  decode.d1.loss_dice: 1.3541  decode.d2.loss_cls: 1.3203  decode.d2.loss_mask: 0.6441  decode.d2.loss_dice: 1.2969  decode.d3.loss_cls: 1.2291  decode.d3.loss_mask: 0.6120  decode.d3.loss_dice: 1.2752  decode.d4.loss_cls: 1.2362  decode.d4.loss_mask: 0.6081  decode.d4.loss_dice: 1.2767  decode.d5.loss_cls: 1.2326  decode.d5.loss_mask: 0.5944  decode.d5.loss_dice: 1.2676  decode.d6.loss_cls: 1.3037  decode.d6.loss_mask: 0.6095  decode.d6.loss_dice: 1.2947  decode.d7.loss_cls: 1.2205  decode.d7.loss_mask: 0.6198  decode.d7.loss_dice: 1.3300  decode.d8.loss_cls: 1.2245  decode.d8.loss_mask: 0.6042  decode.d8.loss_dice: 1.3024
2023/05/24 05:26:01 - mmengine - INFO - Iter(train) [ 90400/160000]  lr: 4.7276e-06  eta: 8:19:25  time: 0.4222  data_time: 0.0104  memory: 4846  grad_norm: 99.8808  loss: 30.5263  decode.loss_cls: 1.0429  decode.loss_mask: 0.7757  decode.loss_dice: 1.0181  decode.d0.loss_cls: 2.8954  decode.d0.loss_mask: 0.7680  decode.d0.loss_dice: 1.1366  decode.d1.loss_cls: 1.1265  decode.d1.loss_mask: 0.7654  decode.d1.loss_dice: 1.0929  decode.d2.loss_cls: 1.0791  decode.d2.loss_mask: 0.7798  decode.d2.loss_dice: 1.0314  decode.d3.loss_cls: 1.0823  decode.d3.loss_mask: 0.7452  decode.d3.loss_dice: 1.0243  decode.d4.loss_cls: 0.9955  decode.d4.loss_mask: 0.8011  decode.d4.loss_dice: 1.0576  decode.d5.loss_cls: 1.0730  decode.d5.loss_mask: 0.7780  decode.d5.loss_dice: 1.0152  decode.d6.loss_cls: 1.0774  decode.d6.loss_mask: 0.7625  decode.d6.loss_dice: 1.0047  decode.d7.loss_cls: 1.0405  decode.d7.loss_mask: 0.7681  decode.d7.loss_dice: 0.9888  decode.d8.loss_cls: 1.0417  decode.d8.loss_mask: 0.7555  decode.d8.loss_dice: 1.0030
2023/05/24 05:26:23 - mmengine - INFO - Iter(train) [ 90450/160000]  lr: 4.7246e-06  eta: 8:19:04  time: 0.4212  data_time: 0.0111  memory: 4845  grad_norm: 134.2858  loss: 31.8779  decode.loss_cls: 1.2108  decode.loss_mask: 0.6689  decode.loss_dice: 1.0456  decode.d0.loss_cls: 3.0394  decode.d0.loss_mask: 0.7322  decode.d0.loss_dice: 1.2242  decode.d1.loss_cls: 1.2834  decode.d1.loss_mask: 0.6947  decode.d1.loss_dice: 1.1204  decode.d2.loss_cls: 1.2589  decode.d2.loss_mask: 0.7158  decode.d2.loss_dice: 1.1232  decode.d3.loss_cls: 1.2460  decode.d3.loss_mask: 0.6778  decode.d3.loss_dice: 1.1053  decode.d4.loss_cls: 1.2300  decode.d4.loss_mask: 0.6885  decode.d4.loss_dice: 1.0515  decode.d5.loss_cls: 1.1608  decode.d5.loss_mask: 0.7107  decode.d5.loss_dice: 1.1005  decode.d6.loss_cls: 1.1884  decode.d6.loss_mask: 0.6787  decode.d6.loss_dice: 1.0550  decode.d7.loss_cls: 1.1966  decode.d7.loss_mask: 0.6700  decode.d7.loss_dice: 1.0326  decode.d8.loss_cls: 1.2224  decode.d8.loss_mask: 0.6814  decode.d8.loss_dice: 1.0643
2023/05/24 05:26:44 - mmengine - INFO - Iter(train) [ 90500/160000]  lr: 4.7215e-06  eta: 8:18:42  time: 0.4199  data_time: 0.0109  memory: 4883  grad_norm: 179.8594  loss: 32.8677  decode.loss_cls: 1.1043  decode.loss_mask: 0.7402  decode.loss_dice: 1.1671  decode.d0.loss_cls: 2.9549  decode.d0.loss_mask: 0.8546  decode.d0.loss_dice: 1.3494  decode.d1.loss_cls: 1.1833  decode.d1.loss_mask: 0.7922  decode.d1.loss_dice: 1.3096  decode.d2.loss_cls: 1.2543  decode.d2.loss_mask: 0.7564  decode.d2.loss_dice: 1.2056  decode.d3.loss_cls: 1.1615  decode.d3.loss_mask: 0.7358  decode.d3.loss_dice: 1.1739  decode.d4.loss_cls: 1.1400  decode.d4.loss_mask: 0.7413  decode.d4.loss_dice: 1.1752  decode.d5.loss_cls: 1.1484  decode.d5.loss_mask: 0.7369  decode.d5.loss_dice: 1.1620  decode.d6.loss_cls: 1.1049  decode.d6.loss_mask: 0.7345  decode.d6.loss_dice: 1.1420  decode.d7.loss_cls: 1.1146  decode.d7.loss_mask: 0.7564  decode.d7.loss_dice: 1.1715  decode.d8.loss_cls: 1.0803  decode.d8.loss_mask: 0.7524  decode.d8.loss_dice: 1.1643
2023/05/24 05:27:06 - mmengine - INFO - Iter(train) [ 90550/160000]  lr: 4.7185e-06  eta: 8:18:21  time: 0.4835  data_time: 0.0105  memory: 4867  grad_norm: 94.3605  loss: 31.6581  decode.loss_cls: 1.0828  decode.loss_mask: 0.7948  decode.loss_dice: 1.0190  decode.d0.loss_cls: 2.9043  decode.d0.loss_mask: 0.7980  decode.d0.loss_dice: 1.1620  decode.d1.loss_cls: 1.3606  decode.d1.loss_mask: 0.8011  decode.d1.loss_dice: 1.1250  decode.d2.loss_cls: 1.2122  decode.d2.loss_mask: 0.8024  decode.d2.loss_dice: 1.0597  decode.d3.loss_cls: 1.1982  decode.d3.loss_mask: 0.7762  decode.d3.loss_dice: 1.0202  decode.d4.loss_cls: 1.1225  decode.d4.loss_mask: 0.7747  decode.d4.loss_dice: 1.0114  decode.d5.loss_cls: 1.1270  decode.d5.loss_mask: 0.7833  decode.d5.loss_dice: 1.0493  decode.d6.loss_cls: 1.1082  decode.d6.loss_mask: 0.7743  decode.d6.loss_dice: 1.0199  decode.d7.loss_cls: 1.0895  decode.d7.loss_mask: 0.7823  decode.d7.loss_dice: 1.0316  decode.d8.loss_cls: 1.1009  decode.d8.loss_mask: 0.7602  decode.d8.loss_dice: 1.0064
2023/05/24 05:27:27 - mmengine - INFO - Iter(train) [ 90600/160000]  lr: 4.7154e-06  eta: 8:17:59  time: 0.4155  data_time: 0.0106  memory: 4851  grad_norm: 91.1266  loss: 27.5838  decode.loss_cls: 1.0070  decode.loss_mask: 0.6817  decode.loss_dice: 0.8896  decode.d0.loss_cls: 2.9307  decode.d0.loss_mask: 0.6734  decode.d0.loss_dice: 0.9615  decode.d1.loss_cls: 1.2139  decode.d1.loss_mask: 0.6748  decode.d1.loss_dice: 0.8928  decode.d2.loss_cls: 1.1193  decode.d2.loss_mask: 0.6395  decode.d2.loss_dice: 0.8758  decode.d3.loss_cls: 1.0523  decode.d3.loss_mask: 0.6399  decode.d3.loss_dice: 0.8667  decode.d4.loss_cls: 0.9853  decode.d4.loss_mask: 0.6344  decode.d4.loss_dice: 0.8936  decode.d5.loss_cls: 0.9819  decode.d5.loss_mask: 0.6719  decode.d5.loss_dice: 0.8235  decode.d6.loss_cls: 1.0149  decode.d6.loss_mask: 0.6273  decode.d6.loss_dice: 0.8537  decode.d7.loss_cls: 0.9822  decode.d7.loss_mask: 0.6566  decode.d7.loss_dice: 0.8341  decode.d8.loss_cls: 1.0031  decode.d8.loss_mask: 0.6501  decode.d8.loss_dice: 0.8522
2023/05/24 05:27:48 - mmengine - INFO - Iter(train) [ 90650/160000]  lr: 4.7123e-06  eta: 8:17:37  time: 0.4384  data_time: 0.0107  memory: 4877  grad_norm: 133.3346  loss: 37.5881  decode.loss_cls: 1.2353  decode.loss_mask: 0.8024  decode.loss_dice: 1.4360  decode.d0.loss_cls: 3.1936  decode.d0.loss_mask: 0.8730  decode.d0.loss_dice: 1.7176  decode.d1.loss_cls: 1.2463  decode.d1.loss_mask: 0.8262  decode.d1.loss_dice: 1.6315  decode.d2.loss_cls: 1.2144  decode.d2.loss_mask: 0.8042  decode.d2.loss_dice: 1.5178  decode.d3.loss_cls: 1.2078  decode.d3.loss_mask: 0.7978  decode.d3.loss_dice: 1.4665  decode.d4.loss_cls: 1.1763  decode.d4.loss_mask: 0.7969  decode.d4.loss_dice: 1.4772  decode.d5.loss_cls: 1.2158  decode.d5.loss_mask: 0.8235  decode.d5.loss_dice: 1.5393  decode.d6.loss_cls: 1.2248  decode.d6.loss_mask: 0.8071  decode.d6.loss_dice: 1.4898  decode.d7.loss_cls: 1.2515  decode.d7.loss_mask: 0.7948  decode.d7.loss_dice: 1.4905  decode.d8.loss_cls: 1.2285  decode.d8.loss_mask: 0.8007  decode.d8.loss_dice: 1.5010
2023/05/24 05:28:09 - mmengine - INFO - Iter(train) [ 90700/160000]  lr: 4.7093e-06  eta: 8:17:16  time: 0.4219  data_time: 0.0101  memory: 4847  grad_norm: 80.9594  loss: 29.3479  decode.loss_cls: 0.9693  decode.loss_mask: 0.6621  decode.loss_dice: 1.0079  decode.d0.loss_cls: 2.9809  decode.d0.loss_mask: 0.7470  decode.d0.loss_dice: 1.1907  decode.d1.loss_cls: 1.1451  decode.d1.loss_mask: 0.6820  decode.d1.loss_dice: 1.1026  decode.d2.loss_cls: 1.1091  decode.d2.loss_mask: 0.6548  decode.d2.loss_dice: 1.0324  decode.d3.loss_cls: 1.0349  decode.d3.loss_mask: 0.6782  decode.d3.loss_dice: 1.0523  decode.d4.loss_cls: 0.9694  decode.d4.loss_mask: 0.6746  decode.d4.loss_dice: 1.0756  decode.d5.loss_cls: 0.9542  decode.d5.loss_mask: 0.6818  decode.d5.loss_dice: 1.0460  decode.d6.loss_cls: 0.9616  decode.d6.loss_mask: 0.6787  decode.d6.loss_dice: 1.0220  decode.d7.loss_cls: 0.9520  decode.d7.loss_mask: 0.6816  decode.d7.loss_dice: 1.0257  decode.d8.loss_cls: 0.9239  decode.d8.loss_mask: 0.6608  decode.d8.loss_dice: 0.9907
2023/05/24 05:28:30 - mmengine - INFO - Iter(train) [ 90750/160000]  lr: 4.7062e-06  eta: 8:16:54  time: 0.4197  data_time: 0.0104  memory: 4784  grad_norm: 120.9720  loss: 32.0659  decode.loss_cls: 1.1555  decode.loss_mask: 0.7385  decode.loss_dice: 0.9835  decode.d0.loss_cls: 3.2985  decode.d0.loss_mask: 0.8167  decode.d0.loss_dice: 1.2883  decode.d1.loss_cls: 1.3957  decode.d1.loss_mask: 0.7628  decode.d1.loss_dice: 1.0710  decode.d2.loss_cls: 1.2778  decode.d2.loss_mask: 0.7302  decode.d2.loss_dice: 1.0062  decode.d3.loss_cls: 1.1947  decode.d3.loss_mask: 0.7683  decode.d3.loss_dice: 0.9750  decode.d4.loss_cls: 1.1925  decode.d4.loss_mask: 0.7551  decode.d4.loss_dice: 1.0073  decode.d5.loss_cls: 1.2024  decode.d5.loss_mask: 0.7613  decode.d5.loss_dice: 1.0015  decode.d6.loss_cls: 1.1763  decode.d6.loss_mask: 0.7381  decode.d6.loss_dice: 0.9735  decode.d7.loss_cls: 1.1939  decode.d7.loss_mask: 0.7332  decode.d7.loss_dice: 0.9816  decode.d8.loss_cls: 1.1681  decode.d8.loss_mask: 0.7488  decode.d8.loss_dice: 0.9697
2023/05/24 05:28:53 - mmengine - INFO - Iter(train) [ 90800/160000]  lr: 4.7032e-06  eta: 8:16:33  time: 0.4245  data_time: 0.0105  memory: 4816  grad_norm: 105.9971  loss: 30.9881  decode.loss_cls: 1.0277  decode.loss_mask: 0.5655  decode.loss_dice: 1.2991  decode.d0.loss_cls: 2.7634  decode.d0.loss_mask: 0.6013  decode.d0.loss_dice: 1.4118  decode.d1.loss_cls: 1.1134  decode.d1.loss_mask: 0.5972  decode.d1.loss_dice: 1.3510  decode.d2.loss_cls: 1.0360  decode.d2.loss_mask: 0.5951  decode.d2.loss_dice: 1.3151  decode.d3.loss_cls: 1.0153  decode.d3.loss_mask: 0.5864  decode.d3.loss_dice: 1.2650  decode.d4.loss_cls: 1.0687  decode.d4.loss_mask: 0.5821  decode.d4.loss_dice: 1.2841  decode.d5.loss_cls: 1.0733  decode.d5.loss_mask: 0.5768  decode.d5.loss_dice: 1.2819  decode.d6.loss_cls: 1.0027  decode.d6.loss_mask: 0.5775  decode.d6.loss_dice: 1.2631  decode.d7.loss_cls: 1.0429  decode.d7.loss_mask: 0.5799  decode.d7.loss_dice: 1.3104  decode.d8.loss_cls: 0.9687  decode.d8.loss_mask: 0.5799  decode.d8.loss_dice: 1.2530
2023/05/24 05:29:15 - mmengine - INFO - Iter(train) [ 90850/160000]  lr: 4.7001e-06  eta: 8:16:11  time: 0.4705  data_time: 0.0103  memory: 4869  grad_norm: 107.6772  loss: 28.9796  decode.loss_cls: 1.0573  decode.loss_mask: 0.5565  decode.loss_dice: 1.0165  decode.d0.loss_cls: 2.9802  decode.d0.loss_mask: 0.6391  decode.d0.loss_dice: 1.2531  decode.d1.loss_cls: 1.1818  decode.d1.loss_mask: 0.6001  decode.d1.loss_dice: 1.1278  decode.d2.loss_cls: 1.0818  decode.d2.loss_mask: 0.5680  decode.d2.loss_dice: 1.0946  decode.d3.loss_cls: 1.0819  decode.d3.loss_mask: 0.5710  decode.d3.loss_dice: 1.0688  decode.d4.loss_cls: 1.0307  decode.d4.loss_mask: 0.5550  decode.d4.loss_dice: 1.0468  decode.d5.loss_cls: 1.0380  decode.d5.loss_mask: 0.5612  decode.d5.loss_dice: 1.0572  decode.d6.loss_cls: 1.0096  decode.d6.loss_mask: 0.5635  decode.d6.loss_dice: 1.0252  decode.d7.loss_cls: 1.0098  decode.d7.loss_mask: 0.5603  decode.d7.loss_dice: 1.0388  decode.d8.loss_cls: 1.0037  decode.d8.loss_mask: 0.5789  decode.d8.loss_dice: 1.0225
2023/05/24 05:29:36 - mmengine - INFO - Iter(train) [ 90900/160000]  lr: 4.6970e-06  eta: 8:15:50  time: 0.4179  data_time: 0.0105  memory: 4848  grad_norm: 115.9456  loss: 34.2918  decode.loss_cls: 1.1278  decode.loss_mask: 0.8010  decode.loss_dice: 1.3164  decode.d0.loss_cls: 2.8211  decode.d0.loss_mask: 0.7927  decode.d0.loss_dice: 1.4694  decode.d1.loss_cls: 1.1251  decode.d1.loss_mask: 0.7921  decode.d1.loss_dice: 1.3975  decode.d2.loss_cls: 1.0891  decode.d2.loss_mask: 0.8306  decode.d2.loss_dice: 1.3493  decode.d3.loss_cls: 1.1330  decode.d3.loss_mask: 0.7574  decode.d3.loss_dice: 1.3028  decode.d4.loss_cls: 1.1340  decode.d4.loss_mask: 0.7692  decode.d4.loss_dice: 1.3445  decode.d5.loss_cls: 1.1254  decode.d5.loss_mask: 0.7647  decode.d5.loss_dice: 1.3032  decode.d6.loss_cls: 1.1806  decode.d6.loss_mask: 0.7467  decode.d6.loss_dice: 1.2879  decode.d7.loss_cls: 1.1116  decode.d7.loss_mask: 0.7873  decode.d7.loss_dice: 1.3387  decode.d8.loss_cls: 1.1593  decode.d8.loss_mask: 0.7854  decode.d8.loss_dice: 1.3483
2023/05/24 05:29:57 - mmengine - INFO - Iter(train) [ 90950/160000]  lr: 4.6940e-06  eta: 8:15:28  time: 0.4270  data_time: 0.0104  memory: 4951  grad_norm: 112.6609  loss: 38.4784  decode.loss_cls: 1.0798  decode.loss_mask: 0.9266  decode.loss_dice: 1.5017  decode.d0.loss_cls: 3.0869  decode.d0.loss_mask: 1.0172  decode.d0.loss_dice: 1.8188  decode.d1.loss_cls: 1.2031  decode.d1.loss_mask: 1.0234  decode.d1.loss_dice: 1.6300  decode.d2.loss_cls: 1.1963  decode.d2.loss_mask: 0.9837  decode.d2.loss_dice: 1.5258  decode.d3.loss_cls: 1.2313  decode.d3.loss_mask: 0.9227  decode.d3.loss_dice: 1.4665  decode.d4.loss_cls: 1.2095  decode.d4.loss_mask: 0.9439  decode.d4.loss_dice: 1.4719  decode.d5.loss_cls: 1.1680  decode.d5.loss_mask: 0.9238  decode.d5.loss_dice: 1.4849  decode.d6.loss_cls: 1.1053  decode.d6.loss_mask: 0.9610  decode.d6.loss_dice: 1.4705  decode.d7.loss_cls: 1.1340  decode.d7.loss_mask: 0.9381  decode.d7.loss_dice: 1.4825  decode.d8.loss_cls: 1.1474  decode.d8.loss_mask: 0.9214  decode.d8.loss_dice: 1.5024
2023/05/24 05:30:19 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:30:19 - mmengine - INFO - Iter(train) [ 91000/160000]  lr: 4.6909e-06  eta: 8:15:06  time: 0.4297  data_time: 0.0104  memory: 4910  grad_norm: 104.9347  loss: 33.1869  decode.loss_cls: 1.0955  decode.loss_mask: 0.7465  decode.loss_dice: 1.2030  decode.d0.loss_cls: 2.9394  decode.d0.loss_mask: 0.8204  decode.d0.loss_dice: 1.4153  decode.d1.loss_cls: 1.2729  decode.d1.loss_mask: 0.8020  decode.d1.loss_dice: 1.2873  decode.d2.loss_cls: 1.1029  decode.d2.loss_mask: 0.8026  decode.d2.loss_dice: 1.2956  decode.d3.loss_cls: 1.1220  decode.d3.loss_mask: 0.7392  decode.d3.loss_dice: 1.2186  decode.d4.loss_cls: 1.0843  decode.d4.loss_mask: 0.7293  decode.d4.loss_dice: 1.2137  decode.d5.loss_cls: 1.1093  decode.d5.loss_mask: 0.7521  decode.d5.loss_dice: 1.2408  decode.d6.loss_cls: 1.1311  decode.d6.loss_mask: 0.7420  decode.d6.loss_dice: 1.2318  decode.d7.loss_cls: 1.1184  decode.d7.loss_mask: 0.7338  decode.d7.loss_dice: 1.1988  decode.d8.loss_cls: 1.1073  decode.d8.loss_mask: 0.7467  decode.d8.loss_dice: 1.1843
2023/05/24 05:30:19 - mmengine - INFO - Saving checkpoint at 91000 iterations
2023/05/24 05:30:45 - mmengine - INFO - Iter(train) [ 91050/160000]  lr: 4.6879e-06  eta: 8:14:49  time: 0.4199  data_time: 0.0103  memory: 4901  grad_norm: 88.7763  loss: 33.8832  decode.loss_cls: 1.1836  decode.loss_mask: 0.6925  decode.loss_dice: 1.1814  decode.d0.loss_cls: 3.0110  decode.d0.loss_mask: 0.8151  decode.d0.loss_dice: 1.4181  decode.d1.loss_cls: 1.2704  decode.d1.loss_mask: 0.7360  decode.d1.loss_dice: 1.3252  decode.d2.loss_cls: 1.3529  decode.d2.loss_mask: 0.7051  decode.d2.loss_dice: 1.2475  decode.d3.loss_cls: 1.2497  decode.d3.loss_mask: 0.7107  decode.d3.loss_dice: 1.2558  decode.d4.loss_cls: 1.2099  decode.d4.loss_mask: 0.7378  decode.d4.loss_dice: 1.2506  decode.d5.loss_cls: 1.2467  decode.d5.loss_mask: 0.7312  decode.d5.loss_dice: 1.2375  decode.d6.loss_cls: 1.2059  decode.d6.loss_mask: 0.7037  decode.d6.loss_dice: 1.2168  decode.d7.loss_cls: 1.1979  decode.d7.loss_mask: 0.7043  decode.d7.loss_dice: 1.1691  decode.d8.loss_cls: 1.2066  decode.d8.loss_mask: 0.7025  decode.d8.loss_dice: 1.2081
2023/05/24 05:31:07 - mmengine - INFO - Iter(train) [ 91100/160000]  lr: 4.6848e-06  eta: 8:14:27  time: 0.4298  data_time: 0.0103  memory: 4844  grad_norm: 86.1310  loss: 32.6283  decode.loss_cls: 0.9351  decode.loss_mask: 0.8056  decode.loss_dice: 1.2620  decode.d0.loss_cls: 2.9836  decode.d0.loss_mask: 0.8602  decode.d0.loss_dice: 1.4623  decode.d1.loss_cls: 1.1046  decode.d1.loss_mask: 0.8429  decode.d1.loss_dice: 1.3420  decode.d2.loss_cls: 1.0011  decode.d2.loss_mask: 0.7759  decode.d2.loss_dice: 1.2468  decode.d3.loss_cls: 0.9222  decode.d3.loss_mask: 0.7976  decode.d3.loss_dice: 1.2674  decode.d4.loss_cls: 0.9742  decode.d4.loss_mask: 0.7822  decode.d4.loss_dice: 1.2069  decode.d5.loss_cls: 0.9793  decode.d5.loss_mask: 0.8101  decode.d5.loss_dice: 1.2165  decode.d6.loss_cls: 0.9884  decode.d6.loss_mask: 0.8064  decode.d6.loss_dice: 1.2616  decode.d7.loss_cls: 0.9533  decode.d7.loss_mask: 0.7939  decode.d7.loss_dice: 1.2672  decode.d8.loss_cls: 0.9508  decode.d8.loss_mask: 0.7965  decode.d8.loss_dice: 1.2319
2023/05/24 05:31:28 - mmengine - INFO - Iter(train) [ 91150/160000]  lr: 4.6817e-06  eta: 8:14:06  time: 0.4713  data_time: 0.0105  memory: 4890  grad_norm: 94.3509  loss: 46.0090  decode.loss_cls: 1.7481  decode.loss_mask: 0.9387  decode.loss_dice: 1.5752  decode.d0.loss_cls: 3.8030  decode.d0.loss_mask: 1.0377  decode.d0.loss_dice: 1.8434  decode.d1.loss_cls: 2.0382  decode.d1.loss_mask: 0.9957  decode.d1.loss_dice: 1.7348  decode.d2.loss_cls: 1.7911  decode.d2.loss_mask: 1.0095  decode.d2.loss_dice: 1.6697  decode.d3.loss_cls: 1.7544  decode.d3.loss_mask: 0.9704  decode.d3.loss_dice: 1.6249  decode.d4.loss_cls: 1.8376  decode.d4.loss_mask: 0.9534  decode.d4.loss_dice: 1.6320  decode.d5.loss_cls: 1.7512  decode.d5.loss_mask: 0.9443  decode.d5.loss_dice: 1.6156  decode.d6.loss_cls: 1.7233  decode.d6.loss_mask: 0.9328  decode.d6.loss_dice: 1.6343  decode.d7.loss_cls: 1.6899  decode.d7.loss_mask: 0.9366  decode.d7.loss_dice: 1.6204  decode.d8.loss_cls: 1.6624  decode.d8.loss_mask: 0.9476  decode.d8.loss_dice: 1.5930
2023/05/24 05:31:51 - mmengine - INFO - Iter(train) [ 91200/160000]  lr: 4.6787e-06  eta: 8:13:45  time: 0.4231  data_time: 0.0104  memory: 4901  grad_norm: 91.3763  loss: 38.4343  decode.loss_cls: 1.3764  decode.loss_mask: 0.7043  decode.loss_dice: 1.5153  decode.d0.loss_cls: 3.3523  decode.d0.loss_mask: 0.7378  decode.d0.loss_dice: 1.7319  decode.d1.loss_cls: 1.4521  decode.d1.loss_mask: 0.7199  decode.d1.loss_dice: 1.6178  decode.d2.loss_cls: 1.4373  decode.d2.loss_mask: 0.7168  decode.d2.loss_dice: 1.5251  decode.d3.loss_cls: 1.3685  decode.d3.loss_mask: 0.7033  decode.d3.loss_dice: 1.5032  decode.d4.loss_cls: 1.3662  decode.d4.loss_mask: 0.6992  decode.d4.loss_dice: 1.5125  decode.d5.loss_cls: 1.4071  decode.d5.loss_mask: 0.7397  decode.d5.loss_dice: 1.5357  decode.d6.loss_cls: 1.3938  decode.d6.loss_mask: 0.6956  decode.d6.loss_dice: 1.5127  decode.d7.loss_cls: 1.3135  decode.d7.loss_mask: 0.7292  decode.d7.loss_dice: 1.5206  decode.d8.loss_cls: 1.2793  decode.d8.loss_mask: 0.7230  decode.d8.loss_dice: 1.5444
2023/05/24 05:32:13 - mmengine - INFO - Iter(train) [ 91250/160000]  lr: 4.6756e-06  eta: 8:13:24  time: 0.4714  data_time: 0.0106  memory: 4857  grad_norm: 94.8279  loss: 27.0426  decode.loss_cls: 0.9542  decode.loss_mask: 0.5431  decode.loss_dice: 0.9402  decode.d0.loss_cls: 2.8702  decode.d0.loss_mask: 0.5461  decode.d0.loss_dice: 1.0752  decode.d1.loss_cls: 1.0808  decode.d1.loss_mask: 0.5573  decode.d1.loss_dice: 1.0178  decode.d2.loss_cls: 0.9905  decode.d2.loss_mask: 0.5582  decode.d2.loss_dice: 0.9542  decode.d3.loss_cls: 1.0078  decode.d3.loss_mask: 0.5536  decode.d3.loss_dice: 0.9506  decode.d4.loss_cls: 0.9896  decode.d4.loss_mask: 0.5570  decode.d4.loss_dice: 0.9719  decode.d5.loss_cls: 0.9956  decode.d5.loss_mask: 0.5440  decode.d5.loss_dice: 0.9544  decode.d6.loss_cls: 0.9998  decode.d6.loss_mask: 0.5344  decode.d6.loss_dice: 0.9629  decode.d7.loss_cls: 0.9905  decode.d7.loss_mask: 0.5399  decode.d7.loss_dice: 0.9308  decode.d8.loss_cls: 1.0118  decode.d8.loss_mask: 0.5160  decode.d8.loss_dice: 0.9441
2023/05/24 05:32:34 - mmengine - INFO - Iter(train) [ 91300/160000]  lr: 4.6726e-06  eta: 8:13:02  time: 0.4236  data_time: 0.0105  memory: 4908  grad_norm: 109.4201  loss: 39.2166  decode.loss_cls: 1.1960  decode.loss_mask: 0.9116  decode.loss_dice: 1.5286  decode.d0.loss_cls: 3.2196  decode.d0.loss_mask: 0.9023  decode.d0.loss_dice: 1.7425  decode.d1.loss_cls: 1.4194  decode.d1.loss_mask: 0.9630  decode.d1.loss_dice: 1.6446  decode.d2.loss_cls: 1.2954  decode.d2.loss_mask: 0.9483  decode.d2.loss_dice: 1.5953  decode.d3.loss_cls: 1.1603  decode.d3.loss_mask: 0.9344  decode.d3.loss_dice: 1.5945  decode.d4.loss_cls: 1.2134  decode.d4.loss_mask: 0.9317  decode.d4.loss_dice: 1.5757  decode.d5.loss_cls: 1.1551  decode.d5.loss_mask: 0.9116  decode.d5.loss_dice: 1.5721  decode.d6.loss_cls: 1.1504  decode.d6.loss_mask: 0.9090  decode.d6.loss_dice: 1.5365  decode.d7.loss_cls: 1.1654  decode.d7.loss_mask: 0.9077  decode.d7.loss_dice: 1.5191  decode.d8.loss_cls: 1.1764  decode.d8.loss_mask: 0.8999  decode.d8.loss_dice: 1.5367
2023/05/24 05:32:55 - mmengine - INFO - Iter(train) [ 91350/160000]  lr: 4.6695e-06  eta: 8:12:40  time: 0.4210  data_time: 0.0104  memory: 4828  grad_norm: 88.9377  loss: 33.7176  decode.loss_cls: 1.0065  decode.loss_mask: 0.8038  decode.loss_dice: 1.2873  decode.d0.loss_cls: 2.9839  decode.d0.loss_mask: 0.8553  decode.d0.loss_dice: 1.4409  decode.d1.loss_cls: 1.1636  decode.d1.loss_mask: 0.8044  decode.d1.loss_dice: 1.3566  decode.d2.loss_cls: 1.0982  decode.d2.loss_mask: 0.8196  decode.d2.loss_dice: 1.3480  decode.d3.loss_cls: 1.0976  decode.d3.loss_mask: 0.7859  decode.d3.loss_dice: 1.2711  decode.d4.loss_cls: 1.0582  decode.d4.loss_mask: 0.8158  decode.d4.loss_dice: 1.3009  decode.d5.loss_cls: 1.0657  decode.d5.loss_mask: 0.7762  decode.d5.loss_dice: 1.3057  decode.d6.loss_cls: 1.0154  decode.d6.loss_mask: 0.7850  decode.d6.loss_dice: 1.3000  decode.d7.loss_cls: 0.9936  decode.d7.loss_mask: 0.8085  decode.d7.loss_dice: 1.2749  decode.d8.loss_cls: 1.0084  decode.d8.loss_mask: 0.8053  decode.d8.loss_dice: 1.2813
2023/05/24 05:33:16 - mmengine - INFO - Iter(train) [ 91400/160000]  lr: 4.6664e-06  eta: 8:12:18  time: 0.4158  data_time: 0.0111  memory: 4859  grad_norm: 95.5897  loss: 41.5969  decode.loss_cls: 1.3079  decode.loss_mask: 0.8683  decode.loss_dice: 1.7521  decode.d0.loss_cls: 3.3912  decode.d0.loss_mask: 0.9582  decode.d0.loss_dice: 1.9445  decode.d1.loss_cls: 1.2923  decode.d1.loss_mask: 0.9088  decode.d1.loss_dice: 1.8821  decode.d2.loss_cls: 1.3314  decode.d2.loss_mask: 0.9034  decode.d2.loss_dice: 1.7819  decode.d3.loss_cls: 1.3316  decode.d3.loss_mask: 0.8917  decode.d3.loss_dice: 1.6954  decode.d4.loss_cls: 1.2885  decode.d4.loss_mask: 0.8713  decode.d4.loss_dice: 1.6869  decode.d5.loss_cls: 1.3145  decode.d5.loss_mask: 0.8607  decode.d5.loss_dice: 1.7203  decode.d6.loss_cls: 1.2658  decode.d6.loss_mask: 0.9051  decode.d6.loss_dice: 1.6980  decode.d7.loss_cls: 1.2779  decode.d7.loss_mask: 0.8696  decode.d7.loss_dice: 1.7365  decode.d8.loss_cls: 1.2400  decode.d8.loss_mask: 0.8764  decode.d8.loss_dice: 1.7445
2023/05/24 05:33:37 - mmengine - INFO - Iter(train) [ 91450/160000]  lr: 4.6634e-06  eta: 8:11:56  time: 0.4226  data_time: 0.0103  memory: 4889  grad_norm: 94.4996  loss: 38.8328  decode.loss_cls: 1.3306  decode.loss_mask: 0.8301  decode.loss_dice: 1.4098  decode.d0.loss_cls: 3.4611  decode.d0.loss_mask: 0.7995  decode.d0.loss_dice: 1.6267  decode.d1.loss_cls: 1.5417  decode.d1.loss_mask: 0.8152  decode.d1.loss_dice: 1.5092  decode.d2.loss_cls: 1.4432  decode.d2.loss_mask: 0.8164  decode.d2.loss_dice: 1.4496  decode.d3.loss_cls: 1.3370  decode.d3.loss_mask: 0.8489  decode.d3.loss_dice: 1.4569  decode.d4.loss_cls: 1.3605  decode.d4.loss_mask: 0.8502  decode.d4.loss_dice: 1.4077  decode.d5.loss_cls: 1.4270  decode.d5.loss_mask: 0.8327  decode.d5.loss_dice: 1.3955  decode.d6.loss_cls: 1.4174  decode.d6.loss_mask: 0.8228  decode.d6.loss_dice: 1.3895  decode.d7.loss_cls: 1.4450  decode.d7.loss_mask: 0.8193  decode.d7.loss_dice: 1.3496  decode.d8.loss_cls: 1.3801  decode.d8.loss_mask: 0.8350  decode.d8.loss_dice: 1.4248
2023/05/24 05:33:59 - mmengine - INFO - Iter(train) [ 91500/160000]  lr: 4.6603e-06  eta: 8:11:35  time: 0.4311  data_time: 0.0112  memory: 4849  grad_norm: 104.0045  loss: 31.6820  decode.loss_cls: 1.1870  decode.loss_mask: 0.7137  decode.loss_dice: 0.9293  decode.d0.loss_cls: 3.3572  decode.d0.loss_mask: 0.8345  decode.d0.loss_dice: 1.1730  decode.d1.loss_cls: 1.4305  decode.d1.loss_mask: 0.7721  decode.d1.loss_dice: 1.0953  decode.d2.loss_cls: 1.2482  decode.d2.loss_mask: 0.7527  decode.d2.loss_dice: 1.0316  decode.d3.loss_cls: 1.2218  decode.d3.loss_mask: 0.7120  decode.d3.loss_dice: 0.9760  decode.d4.loss_cls: 1.2452  decode.d4.loss_mask: 0.6870  decode.d4.loss_dice: 0.9550  decode.d5.loss_cls: 1.2087  decode.d5.loss_mask: 0.6789  decode.d5.loss_dice: 0.9372  decode.d6.loss_cls: 1.2095  decode.d6.loss_mask: 0.6868  decode.d6.loss_dice: 0.9675  decode.d7.loss_cls: 1.1983  decode.d7.loss_mask: 0.6908  decode.d7.loss_dice: 0.9470  decode.d8.loss_cls: 1.1916  decode.d8.loss_mask: 0.6938  decode.d8.loss_dice: 0.9496
2023/05/24 05:34:20 - mmengine - INFO - Iter(train) [ 91550/160000]  lr: 4.6573e-06  eta: 8:11:13  time: 0.4235  data_time: 0.0105  memory: 4867  grad_norm: 105.2757  loss: 43.1337  decode.loss_cls: 1.4094  decode.loss_mask: 0.9064  decode.loss_dice: 1.6886  decode.d0.loss_cls: 3.1556  decode.d0.loss_mask: 1.0099  decode.d0.loss_dice: 1.9867  decode.d1.loss_cls: 1.6094  decode.d1.loss_mask: 0.9646  decode.d1.loss_dice: 1.9562  decode.d2.loss_cls: 1.4751  decode.d2.loss_mask: 0.9315  decode.d2.loss_dice: 1.8228  decode.d3.loss_cls: 1.4377  decode.d3.loss_mask: 0.8951  decode.d3.loss_dice: 1.7303  decode.d4.loss_cls: 1.3958  decode.d4.loss_mask: 0.9073  decode.d4.loss_dice: 1.7490  decode.d5.loss_cls: 1.4004  decode.d5.loss_mask: 0.9289  decode.d5.loss_dice: 1.7528  decode.d6.loss_cls: 1.4009  decode.d6.loss_mask: 0.8954  decode.d6.loss_dice: 1.6976  decode.d7.loss_cls: 1.3847  decode.d7.loss_mask: 0.9083  decode.d7.loss_dice: 1.6955  decode.d8.loss_cls: 1.3222  decode.d8.loss_mask: 0.9423  decode.d8.loss_dice: 1.7735
2023/05/24 05:34:44 - mmengine - INFO - Iter(train) [ 91600/160000]  lr: 4.6542e-06  eta: 8:10:53  time: 0.4810  data_time: 0.0102  memory: 4824  grad_norm: 120.4233  loss: 25.1342  decode.loss_cls: 0.8641  decode.loss_mask: 0.5542  decode.loss_dice: 0.8267  decode.d0.loss_cls: 2.5836  decode.d0.loss_mask: 0.6190  decode.d0.loss_dice: 0.9761  decode.d1.loss_cls: 1.0400  decode.d1.loss_mask: 0.6539  decode.d1.loss_dice: 0.9335  decode.d2.loss_cls: 0.9072  decode.d2.loss_mask: 0.6078  decode.d2.loss_dice: 0.8997  decode.d3.loss_cls: 0.9400  decode.d3.loss_mask: 0.5852  decode.d3.loss_dice: 0.8425  decode.d4.loss_cls: 0.8800  decode.d4.loss_mask: 0.5574  decode.d4.loss_dice: 0.8312  decode.d5.loss_cls: 0.8517  decode.d5.loss_mask: 0.5565  decode.d5.loss_dice: 0.8352  decode.d6.loss_cls: 0.8615  decode.d6.loss_mask: 0.5822  decode.d6.loss_dice: 0.8699  decode.d7.loss_cls: 0.8718  decode.d7.loss_mask: 0.5688  decode.d7.loss_dice: 0.8450  decode.d8.loss_cls: 0.8157  decode.d8.loss_mask: 0.5590  decode.d8.loss_dice: 0.8145
2023/05/24 05:35:08 - mmengine - INFO - Iter(train) [ 91650/160000]  lr: 4.6511e-06  eta: 8:10:33  time: 0.4799  data_time: 0.0102  memory: 4837  grad_norm: 86.2755  loss: 38.9144  decode.loss_cls: 1.2104  decode.loss_mask: 0.9060  decode.loss_dice: 1.5184  decode.d0.loss_cls: 3.1866  decode.d0.loss_mask: 0.9003  decode.d0.loss_dice: 1.7205  decode.d1.loss_cls: 1.2691  decode.d1.loss_mask: 0.9195  decode.d1.loss_dice: 1.6617  decode.d2.loss_cls: 1.2445  decode.d2.loss_mask: 0.8672  decode.d2.loss_dice: 1.5879  decode.d3.loss_cls: 1.2099  decode.d3.loss_mask: 0.9087  decode.d3.loss_dice: 1.5919  decode.d4.loss_cls: 1.2091  decode.d4.loss_mask: 0.8863  decode.d4.loss_dice: 1.5895  decode.d5.loss_cls: 1.2115  decode.d5.loss_mask: 0.8881  decode.d5.loss_dice: 1.5847  decode.d6.loss_cls: 1.2602  decode.d6.loss_mask: 0.8954  decode.d6.loss_dice: 1.4925  decode.d7.loss_cls: 1.1541  decode.d7.loss_mask: 0.9261  decode.d7.loss_dice: 1.5077  decode.d8.loss_cls: 1.2040  decode.d8.loss_mask: 0.8983  decode.d8.loss_dice: 1.5044
2023/05/24 05:35:31 - mmengine - INFO - Iter(train) [ 91700/160000]  lr: 4.6481e-06  eta: 8:10:13  time: 0.4795  data_time: 0.0105  memory: 4890  grad_norm: 87.9221  loss: 41.6138  decode.loss_cls: 1.3781  decode.loss_mask: 0.8417  decode.loss_dice: 1.6679  decode.d0.loss_cls: 3.5108  decode.d0.loss_mask: 0.8684  decode.d0.loss_dice: 1.8860  decode.d1.loss_cls: 1.5385  decode.d1.loss_mask: 0.8580  decode.d1.loss_dice: 1.7429  decode.d2.loss_cls: 1.4977  decode.d2.loss_mask: 0.8658  decode.d2.loss_dice: 1.7202  decode.d3.loss_cls: 1.3813  decode.d3.loss_mask: 0.8305  decode.d3.loss_dice: 1.6655  decode.d4.loss_cls: 1.3803  decode.d4.loss_mask: 0.8283  decode.d4.loss_dice: 1.6900  decode.d5.loss_cls: 1.3696  decode.d5.loss_mask: 0.8389  decode.d5.loss_dice: 1.7017  decode.d6.loss_cls: 1.4010  decode.d6.loss_mask: 0.8421  decode.d6.loss_dice: 1.6373  decode.d7.loss_cls: 1.3167  decode.d7.loss_mask: 0.8414  decode.d7.loss_dice: 1.6655  decode.d8.loss_cls: 1.3863  decode.d8.loss_mask: 0.8320  decode.d8.loss_dice: 1.6295
2023/05/24 05:35:53 - mmengine - INFO - Iter(train) [ 91750/160000]  lr: 4.6450e-06  eta: 8:09:52  time: 0.4185  data_time: 0.0105  memory: 4868  grad_norm: 100.1651  loss: 38.7935  decode.loss_cls: 1.2030  decode.loss_mask: 0.8266  decode.loss_dice: 1.4457  decode.d0.loss_cls: 3.4007  decode.d0.loss_mask: 0.9775  decode.d0.loss_dice: 1.6743  decode.d1.loss_cls: 1.3027  decode.d1.loss_mask: 0.9800  decode.d1.loss_dice: 1.5956  decode.d2.loss_cls: 1.3347  decode.d2.loss_mask: 0.9329  decode.d2.loss_dice: 1.5274  decode.d3.loss_cls: 1.3075  decode.d3.loss_mask: 0.8761  decode.d3.loss_dice: 1.4734  decode.d4.loss_cls: 1.2219  decode.d4.loss_mask: 0.9161  decode.d4.loss_dice: 1.4875  decode.d5.loss_cls: 1.2582  decode.d5.loss_mask: 0.8899  decode.d5.loss_dice: 1.4859  decode.d6.loss_cls: 1.2094  decode.d6.loss_mask: 0.8958  decode.d6.loss_dice: 1.5059  decode.d7.loss_cls: 1.2458  decode.d7.loss_mask: 0.8510  decode.d7.loss_dice: 1.4574  decode.d8.loss_cls: 1.2041  decode.d8.loss_mask: 0.8451  decode.d8.loss_dice: 1.4613
2023/05/24 05:36:15 - mmengine - INFO - Iter(train) [ 91800/160000]  lr: 4.6419e-06  eta: 8:09:31  time: 0.4292  data_time: 0.0103  memory: 4865  grad_norm: 91.3024  loss: 35.9297  decode.loss_cls: 1.2740  decode.loss_mask: 0.8604  decode.loss_dice: 1.2043  decode.d0.loss_cls: 3.1540  decode.d0.loss_mask: 0.9389  decode.d0.loss_dice: 1.3826  decode.d1.loss_cls: 1.2752  decode.d1.loss_mask: 0.9060  decode.d1.loss_dice: 1.3146  decode.d2.loss_cls: 1.2104  decode.d2.loss_mask: 0.9239  decode.d2.loss_dice: 1.2388  decode.d3.loss_cls: 1.3338  decode.d3.loss_mask: 0.9078  decode.d3.loss_dice: 1.2451  decode.d4.loss_cls: 1.2203  decode.d4.loss_mask: 0.9353  decode.d4.loss_dice: 1.2182  decode.d5.loss_cls: 1.2776  decode.d5.loss_mask: 0.9082  decode.d5.loss_dice: 1.2031  decode.d6.loss_cls: 1.2497  decode.d6.loss_mask: 0.8999  decode.d6.loss_dice: 1.2039  decode.d7.loss_cls: 1.2593  decode.d7.loss_mask: 0.8766  decode.d7.loss_dice: 1.2180  decode.d8.loss_cls: 1.2276  decode.d8.loss_mask: 0.8672  decode.d8.loss_dice: 1.1948
2023/05/24 05:36:37 - mmengine - INFO - Iter(train) [ 91850/160000]  lr: 4.6389e-06  eta: 8:09:09  time: 0.4286  data_time: 0.0103  memory: 4805  grad_norm: 105.3038  loss: 39.0865  decode.loss_cls: 1.4204  decode.loss_mask: 0.7568  decode.loss_dice: 1.4767  decode.d0.loss_cls: 3.2992  decode.d0.loss_mask: 0.8230  decode.d0.loss_dice: 1.8075  decode.d1.loss_cls: 1.4387  decode.d1.loss_mask: 0.8149  decode.d1.loss_dice: 1.5960  decode.d2.loss_cls: 1.3786  decode.d2.loss_mask: 0.7972  decode.d2.loss_dice: 1.5742  decode.d3.loss_cls: 1.3386  decode.d3.loss_mask: 0.8042  decode.d3.loss_dice: 1.5550  decode.d4.loss_cls: 1.3137  decode.d4.loss_mask: 0.7864  decode.d4.loss_dice: 1.5785  decode.d5.loss_cls: 1.3206  decode.d5.loss_mask: 0.7785  decode.d5.loss_dice: 1.5513  decode.d6.loss_cls: 1.3780  decode.d6.loss_mask: 0.7502  decode.d6.loss_dice: 1.4776  decode.d7.loss_cls: 1.3203  decode.d7.loss_mask: 0.7552  decode.d7.loss_dice: 1.5288  decode.d8.loss_cls: 1.3848  decode.d8.loss_mask: 0.7634  decode.d8.loss_dice: 1.5181
2023/05/24 05:36:58 - mmengine - INFO - Iter(train) [ 91900/160000]  lr: 4.6358e-06  eta: 8:08:47  time: 0.4265  data_time: 0.0107  memory: 4844  grad_norm: 101.6554  loss: 29.7162  decode.loss_cls: 0.8950  decode.loss_mask: 0.8025  decode.loss_dice: 1.0257  decode.d0.loss_cls: 2.7025  decode.d0.loss_mask: 0.8131  decode.d0.loss_dice: 1.1720  decode.d1.loss_cls: 1.0586  decode.d1.loss_mask: 0.8559  decode.d1.loss_dice: 1.1371  decode.d2.loss_cls: 1.0376  decode.d2.loss_mask: 0.8008  decode.d2.loss_dice: 0.9975  decode.d3.loss_cls: 0.9462  decode.d3.loss_mask: 0.8041  decode.d3.loss_dice: 1.0207  decode.d4.loss_cls: 0.9282  decode.d4.loss_mask: 0.7853  decode.d4.loss_dice: 1.0010  decode.d5.loss_cls: 0.9555  decode.d5.loss_mask: 0.7884  decode.d5.loss_dice: 1.0197  decode.d6.loss_cls: 0.9239  decode.d6.loss_mask: 0.8142  decode.d6.loss_dice: 1.0076  decode.d7.loss_cls: 0.9061  decode.d7.loss_mask: 0.7855  decode.d7.loss_dice: 0.9885  decode.d8.loss_cls: 0.9110  decode.d8.loss_mask: 0.8013  decode.d8.loss_dice: 1.0309
2023/05/24 05:37:19 - mmengine - INFO - Iter(train) [ 91950/160000]  lr: 4.6328e-06  eta: 8:08:26  time: 0.4500  data_time: 0.0107  memory: 4867  grad_norm: 89.9289  loss: 32.8194  decode.loss_cls: 0.8874  decode.loss_mask: 0.9647  decode.loss_dice: 1.1822  decode.d0.loss_cls: 2.7320  decode.d0.loss_mask: 0.9910  decode.d0.loss_dice: 1.2733  decode.d1.loss_cls: 1.0041  decode.d1.loss_mask: 0.9875  decode.d1.loss_dice: 1.2138  decode.d2.loss_cls: 0.9442  decode.d2.loss_mask: 0.9668  decode.d2.loss_dice: 1.1859  decode.d3.loss_cls: 0.9422  decode.d3.loss_mask: 0.9771  decode.d3.loss_dice: 1.1718  decode.d4.loss_cls: 0.9182  decode.d4.loss_mask: 0.9824  decode.d4.loss_dice: 1.1912  decode.d5.loss_cls: 0.9427  decode.d5.loss_mask: 0.9970  decode.d5.loss_dice: 1.1883  decode.d6.loss_cls: 0.9272  decode.d6.loss_mask: 0.9771  decode.d6.loss_dice: 1.1533  decode.d7.loss_cls: 0.9111  decode.d7.loss_mask: 1.0002  decode.d7.loss_dice: 1.1706  decode.d8.loss_cls: 0.9002  decode.d8.loss_mask: 0.9675  decode.d8.loss_dice: 1.1685
2023/05/24 05:37:40 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:37:40 - mmengine - INFO - Iter(train) [ 92000/160000]  lr: 4.6297e-06  eta: 8:08:04  time: 0.4153  data_time: 0.0103  memory: 4919  grad_norm: 119.1762  loss: 48.7857  decode.loss_cls: 1.4581  decode.loss_mask: 1.1765  decode.loss_dice: 1.9356  decode.d0.loss_cls: 3.5088  decode.d0.loss_mask: 1.2196  decode.d0.loss_dice: 2.3732  decode.d1.loss_cls: 1.6002  decode.d1.loss_mask: 1.1901  decode.d1.loss_dice: 2.1740  decode.d2.loss_cls: 1.5676  decode.d2.loss_mask: 1.0988  decode.d2.loss_dice: 2.0561  decode.d3.loss_cls: 1.5335  decode.d3.loss_mask: 1.1258  decode.d3.loss_dice: 1.9826  decode.d4.loss_cls: 1.5059  decode.d4.loss_mask: 1.1418  decode.d4.loss_dice: 1.9921  decode.d5.loss_cls: 1.5002  decode.d5.loss_mask: 1.1439  decode.d5.loss_dice: 1.9578  decode.d6.loss_cls: 1.5119  decode.d6.loss_mask: 1.0744  decode.d6.loss_dice: 1.9265  decode.d7.loss_cls: 1.4696  decode.d7.loss_mask: 1.0920  decode.d7.loss_dice: 1.9406  decode.d8.loss_cls: 1.4677  decode.d8.loss_mask: 1.1146  decode.d8.loss_dice: 1.9460
2023/05/24 05:37:41 - mmengine - INFO - Saving checkpoint at 92000 iterations
2023/05/24 05:38:07 - mmengine - INFO - Iter(train) [ 92050/160000]  lr: 4.6266e-06  eta: 8:07:46  time: 0.4148  data_time: 0.0103  memory: 4845  grad_norm: 92.4709  loss: 37.8835  decode.loss_cls: 1.3103  decode.loss_mask: 0.7805  decode.loss_dice: 1.3754  decode.d0.loss_cls: 3.0699  decode.d0.loss_mask: 0.9809  decode.d0.loss_dice: 1.5854  decode.d1.loss_cls: 1.5335  decode.d1.loss_mask: 0.8898  decode.d1.loss_dice: 1.4363  decode.d2.loss_cls: 1.4810  decode.d2.loss_mask: 0.8302  decode.d2.loss_dice: 1.3933  decode.d3.loss_cls: 1.3974  decode.d3.loss_mask: 0.7761  decode.d3.loss_dice: 1.3896  decode.d4.loss_cls: 1.4338  decode.d4.loss_mask: 0.7725  decode.d4.loss_dice: 1.3845  decode.d5.loss_cls: 1.4327  decode.d5.loss_mask: 0.7682  decode.d5.loss_dice: 1.3609  decode.d6.loss_cls: 1.3415  decode.d6.loss_mask: 0.7761  decode.d6.loss_dice: 1.3780  decode.d7.loss_cls: 1.3280  decode.d7.loss_mask: 0.7765  decode.d7.loss_dice: 1.3734  decode.d8.loss_cls: 1.3881  decode.d8.loss_mask: 0.7657  decode.d8.loss_dice: 1.3740
2023/05/24 05:38:28 - mmengine - INFO - Iter(train) [ 92100/160000]  lr: 4.6236e-06  eta: 8:07:24  time: 0.4172  data_time: 0.0104  memory: 4868  grad_norm: 125.3359  loss: 43.7875  decode.loss_cls: 1.5322  decode.loss_mask: 0.9887  decode.loss_dice: 1.5937  decode.d0.loss_cls: 3.4941  decode.d0.loss_mask: 1.0171  decode.d0.loss_dice: 1.9031  decode.d1.loss_cls: 1.5276  decode.d1.loss_mask: 1.1005  decode.d1.loss_dice: 1.7055  decode.d2.loss_cls: 1.5685  decode.d2.loss_mask: 0.9654  decode.d2.loss_dice: 1.5895  decode.d3.loss_cls: 1.5799  decode.d3.loss_mask: 0.9205  decode.d3.loss_dice: 1.5690  decode.d4.loss_cls: 1.5694  decode.d4.loss_mask: 0.9485  decode.d4.loss_dice: 1.5898  decode.d5.loss_cls: 1.5606  decode.d5.loss_mask: 0.9771  decode.d5.loss_dice: 1.6091  decode.d6.loss_cls: 1.5834  decode.d6.loss_mask: 0.9639  decode.d6.loss_dice: 1.6144  decode.d7.loss_cls: 1.5815  decode.d7.loss_mask: 0.9674  decode.d7.loss_dice: 1.6022  decode.d8.loss_cls: 1.5638  decode.d8.loss_mask: 0.9865  decode.d8.loss_dice: 1.6144
2023/05/24 05:38:50 - mmengine - INFO - Iter(train) [ 92150/160000]  lr: 4.6205e-06  eta: 8:07:03  time: 0.4194  data_time: 0.0107  memory: 4837  grad_norm: 101.6830  loss: 34.5339  decode.loss_cls: 1.1752  decode.loss_mask: 0.8246  decode.loss_dice: 1.2537  decode.d0.loss_cls: 2.9580  decode.d0.loss_mask: 0.8855  decode.d0.loss_dice: 1.3905  decode.d1.loss_cls: 1.3529  decode.d1.loss_mask: 0.7681  decode.d1.loss_dice: 1.2819  decode.d2.loss_cls: 1.2063  decode.d2.loss_mask: 0.8182  decode.d2.loss_dice: 1.2897  decode.d3.loss_cls: 1.1998  decode.d3.loss_mask: 0.7907  decode.d3.loss_dice: 1.1998  decode.d4.loss_cls: 1.1665  decode.d4.loss_mask: 0.7889  decode.d4.loss_dice: 1.2419  decode.d5.loss_cls: 1.2395  decode.d5.loss_mask: 0.7828  decode.d5.loss_dice: 1.2392  decode.d6.loss_cls: 1.1828  decode.d6.loss_mask: 0.8071  decode.d6.loss_dice: 1.2445  decode.d7.loss_cls: 1.1494  decode.d7.loss_mask: 0.8173  decode.d7.loss_dice: 1.2414  decode.d8.loss_cls: 1.1395  decode.d8.loss_mask: 0.8296  decode.d8.loss_dice: 1.2687
2023/05/24 05:39:12 - mmengine - INFO - Iter(train) [ 92200/160000]  lr: 4.6174e-06  eta: 8:06:42  time: 0.4248  data_time: 0.0102  memory: 4867  grad_norm: 99.1302  loss: 35.9552  decode.loss_cls: 1.4439  decode.loss_mask: 0.6808  decode.loss_dice: 1.2256  decode.d0.loss_cls: 3.2587  decode.d0.loss_mask: 0.8101  decode.d0.loss_dice: 1.3885  decode.d1.loss_cls: 1.6068  decode.d1.loss_mask: 0.7209  decode.d1.loss_dice: 1.2528  decode.d2.loss_cls: 1.4997  decode.d2.loss_mask: 0.7180  decode.d2.loss_dice: 1.2111  decode.d3.loss_cls: 1.5070  decode.d3.loss_mask: 0.6851  decode.d3.loss_dice: 1.2009  decode.d4.loss_cls: 1.5541  decode.d4.loss_mask: 0.6900  decode.d4.loss_dice: 1.1936  decode.d5.loss_cls: 1.3656  decode.d5.loss_mask: 0.7058  decode.d5.loss_dice: 1.2346  decode.d6.loss_cls: 1.4446  decode.d6.loss_mask: 0.7093  decode.d6.loss_dice: 1.2006  decode.d7.loss_cls: 1.4705  decode.d7.loss_mask: 0.6847  decode.d7.loss_dice: 1.1839  decode.d8.loss_cls: 1.4464  decode.d8.loss_mask: 0.6755  decode.d8.loss_dice: 1.1860
2023/05/24 05:39:34 - mmengine - INFO - Iter(train) [ 92250/160000]  lr: 4.6144e-06  eta: 8:06:20  time: 0.4810  data_time: 0.0110  memory: 4857  grad_norm: 90.1936  loss: 27.8805  decode.loss_cls: 1.0151  decode.loss_mask: 0.6330  decode.loss_dice: 0.8770  decode.d0.loss_cls: 2.9055  decode.d0.loss_mask: 0.6823  decode.d0.loss_dice: 1.0372  decode.d1.loss_cls: 1.1234  decode.d1.loss_mask: 0.6848  decode.d1.loss_dice: 0.9880  decode.d2.loss_cls: 1.0849  decode.d2.loss_mask: 0.6704  decode.d2.loss_dice: 0.9368  decode.d3.loss_cls: 1.0316  decode.d3.loss_mask: 0.6585  decode.d3.loss_dice: 0.9032  decode.d4.loss_cls: 0.9820  decode.d4.loss_mask: 0.6706  decode.d4.loss_dice: 0.9035  decode.d5.loss_cls: 1.0172  decode.d5.loss_mask: 0.6406  decode.d5.loss_dice: 0.8749  decode.d6.loss_cls: 1.0188  decode.d6.loss_mask: 0.6422  decode.d6.loss_dice: 0.8667  decode.d7.loss_cls: 0.9762  decode.d7.loss_mask: 0.6538  decode.d7.loss_dice: 0.8784  decode.d8.loss_cls: 1.0281  decode.d8.loss_mask: 0.6251  decode.d8.loss_dice: 0.8708
2023/05/24 05:39:55 - mmengine - INFO - Iter(train) [ 92300/160000]  lr: 4.6113e-06  eta: 8:05:59  time: 0.4169  data_time: 0.0107  memory: 4803  grad_norm: 95.3164  loss: 32.9430  decode.loss_cls: 1.2090  decode.loss_mask: 0.8174  decode.loss_dice: 0.9610  decode.d0.loss_cls: 3.1679  decode.d0.loss_mask: 0.9424  decode.d0.loss_dice: 1.1123  decode.d1.loss_cls: 1.3835  decode.d1.loss_mask: 0.8845  decode.d1.loss_dice: 1.1146  decode.d2.loss_cls: 1.2219  decode.d2.loss_mask: 0.8700  decode.d2.loss_dice: 1.0663  decode.d3.loss_cls: 1.1815  decode.d3.loss_mask: 0.8472  decode.d3.loss_dice: 1.0139  decode.d4.loss_cls: 1.1874  decode.d4.loss_mask: 0.8448  decode.d4.loss_dice: 1.0076  decode.d5.loss_cls: 1.1926  decode.d5.loss_mask: 0.8493  decode.d5.loss_dice: 1.0184  decode.d6.loss_cls: 1.1824  decode.d6.loss_mask: 0.8497  decode.d6.loss_dice: 1.0244  decode.d7.loss_cls: 1.1314  decode.d7.loss_mask: 0.8382  decode.d7.loss_dice: 0.9997  decode.d8.loss_cls: 1.1943  decode.d8.loss_mask: 0.8324  decode.d8.loss_dice: 0.9973
2023/05/24 05:40:18 - mmengine - INFO - Iter(train) [ 92350/160000]  lr: 4.6082e-06  eta: 8:05:38  time: 0.4718  data_time: 0.0103  memory: 4845  grad_norm: 112.9257  loss: 29.5699  decode.loss_cls: 1.0216  decode.loss_mask: 0.6195  decode.loss_dice: 1.0382  decode.d0.loss_cls: 3.0726  decode.d0.loss_mask: 0.6499  decode.d0.loss_dice: 1.1512  decode.d1.loss_cls: 1.1488  decode.d1.loss_mask: 0.6461  decode.d1.loss_dice: 1.1515  decode.d2.loss_cls: 1.0955  decode.d2.loss_mask: 0.6336  decode.d2.loss_dice: 1.0979  decode.d3.loss_cls: 1.0482  decode.d3.loss_mask: 0.6398  decode.d3.loss_dice: 1.0451  decode.d4.loss_cls: 1.0943  decode.d4.loss_mask: 0.6301  decode.d4.loss_dice: 1.0296  decode.d5.loss_cls: 1.0739  decode.d5.loss_mask: 0.6202  decode.d5.loss_dice: 0.9986  decode.d6.loss_cls: 1.0582  decode.d6.loss_mask: 0.6172  decode.d6.loss_dice: 1.0464  decode.d7.loss_cls: 1.0224  decode.d7.loss_mask: 0.6166  decode.d7.loss_dice: 1.0291  decode.d8.loss_cls: 1.0134  decode.d8.loss_mask: 0.6180  decode.d8.loss_dice: 1.0423
2023/05/24 05:40:39 - mmengine - INFO - Iter(train) [ 92400/160000]  lr: 4.6052e-06  eta: 8:05:16  time: 0.4206  data_time: 0.0106  memory: 4942  grad_norm: 95.0661  loss: 36.6262  decode.loss_cls: 1.2704  decode.loss_mask: 0.8614  decode.loss_dice: 1.1970  decode.d0.loss_cls: 3.3578  decode.d0.loss_mask: 0.8867  decode.d0.loss_dice: 1.4741  decode.d1.loss_cls: 1.6222  decode.d1.loss_mask: 0.8506  decode.d1.loss_dice: 1.2781  decode.d2.loss_cls: 1.4998  decode.d2.loss_mask: 0.8470  decode.d2.loss_dice: 1.2129  decode.d3.loss_cls: 1.3809  decode.d3.loss_mask: 0.8428  decode.d3.loss_dice: 1.1837  decode.d4.loss_cls: 1.3531  decode.d4.loss_mask: 0.8549  decode.d4.loss_dice: 1.1826  decode.d5.loss_cls: 1.3466  decode.d5.loss_mask: 0.8693  decode.d5.loss_dice: 1.2055  decode.d6.loss_cls: 1.3513  decode.d6.loss_mask: 0.8067  decode.d6.loss_dice: 1.2094  decode.d7.loss_cls: 1.3283  decode.d7.loss_mask: 0.8096  decode.d7.loss_dice: 1.1931  decode.d8.loss_cls: 1.2963  decode.d8.loss_mask: 0.8640  decode.d8.loss_dice: 1.1898
2023/05/24 05:41:00 - mmengine - INFO - Iter(train) [ 92450/160000]  lr: 4.6021e-06  eta: 8:04:55  time: 0.4243  data_time: 0.0110  memory: 4885  grad_norm: 95.1073  loss: 37.6572  decode.loss_cls: 1.1662  decode.loss_mask: 0.9631  decode.loss_dice: 1.4368  decode.d0.loss_cls: 2.9468  decode.d0.loss_mask: 1.1029  decode.d0.loss_dice: 1.6656  decode.d1.loss_cls: 1.1657  decode.d1.loss_mask: 0.9948  decode.d1.loss_dice: 1.5673  decode.d2.loss_cls: 1.1105  decode.d2.loss_mask: 0.9614  decode.d2.loss_dice: 1.5015  decode.d3.loss_cls: 1.0768  decode.d3.loss_mask: 0.9679  decode.d3.loss_dice: 1.4929  decode.d4.loss_cls: 1.0548  decode.d4.loss_mask: 0.9550  decode.d4.loss_dice: 1.4831  decode.d5.loss_cls: 1.0677  decode.d5.loss_mask: 0.9683  decode.d5.loss_dice: 1.4608  decode.d6.loss_cls: 1.1219  decode.d6.loss_mask: 0.9474  decode.d6.loss_dice: 1.4175  decode.d7.loss_cls: 1.1329  decode.d7.loss_mask: 0.9540  decode.d7.loss_dice: 1.4541  decode.d8.loss_cls: 1.1360  decode.d8.loss_mask: 0.9526  decode.d8.loss_dice: 1.4314
2023/05/24 05:41:21 - mmengine - INFO - Iter(train) [ 92500/160000]  lr: 4.5990e-06  eta: 8:04:33  time: 0.4163  data_time: 0.0106  memory: 4886  grad_norm: 112.1121  loss: 40.3373  decode.loss_cls: 1.2629  decode.loss_mask: 0.8491  decode.loss_dice: 1.5802  decode.d0.loss_cls: 3.2881  decode.d0.loss_mask: 0.9282  decode.d0.loss_dice: 1.8803  decode.d1.loss_cls: 1.3795  decode.d1.loss_mask: 0.9359  decode.d1.loss_dice: 1.7572  decode.d2.loss_cls: 1.2639  decode.d2.loss_mask: 0.9319  decode.d2.loss_dice: 1.7157  decode.d3.loss_cls: 1.3383  decode.d3.loss_mask: 0.8776  decode.d3.loss_dice: 1.6093  decode.d4.loss_cls: 1.3142  decode.d4.loss_mask: 0.8682  decode.d4.loss_dice: 1.5912  decode.d5.loss_cls: 1.3007  decode.d5.loss_mask: 0.8827  decode.d5.loss_dice: 1.6236  decode.d6.loss_cls: 1.3168  decode.d6.loss_mask: 0.8505  decode.d6.loss_dice: 1.5936  decode.d7.loss_cls: 1.3299  decode.d7.loss_mask: 0.8332  decode.d7.loss_dice: 1.5636  decode.d8.loss_cls: 1.2691  decode.d8.loss_mask: 0.8500  decode.d8.loss_dice: 1.5519
2023/05/24 05:41:42 - mmengine - INFO - Iter(train) [ 92550/160000]  lr: 4.5960e-06  eta: 8:04:11  time: 0.4147  data_time: 0.0103  memory: 4836  grad_norm: 93.2764  loss: 32.3854  decode.loss_cls: 0.8872  decode.loss_mask: 0.8615  decode.loss_dice: 1.2571  decode.d0.loss_cls: 2.9618  decode.d0.loss_mask: 0.8740  decode.d0.loss_dice: 1.3642  decode.d1.loss_cls: 0.9448  decode.d1.loss_mask: 0.8991  decode.d1.loss_dice: 1.3060  decode.d2.loss_cls: 0.9679  decode.d2.loss_mask: 0.8862  decode.d2.loss_dice: 1.2875  decode.d3.loss_cls: 0.9691  decode.d3.loss_mask: 0.8044  decode.d3.loss_dice: 1.2416  decode.d4.loss_cls: 0.9567  decode.d4.loss_mask: 0.7985  decode.d4.loss_dice: 1.2317  decode.d5.loss_cls: 0.9774  decode.d5.loss_mask: 0.7892  decode.d5.loss_dice: 1.2222  decode.d6.loss_cls: 0.9420  decode.d6.loss_mask: 0.8186  decode.d6.loss_dice: 1.1872  decode.d7.loss_cls: 0.8800  decode.d7.loss_mask: 0.8678  decode.d7.loss_dice: 1.2143  decode.d8.loss_cls: 0.8830  decode.d8.loss_mask: 0.8775  decode.d8.loss_dice: 1.2267
2023/05/24 05:42:04 - mmengine - INFO - Iter(train) [ 92600/160000]  lr: 4.5929e-06  eta: 8:03:49  time: 0.4240  data_time: 0.0104  memory: 4878  grad_norm: 84.6083  loss: 33.9913  decode.loss_cls: 1.1682  decode.loss_mask: 0.6939  decode.loss_dice: 1.2370  decode.d0.loss_cls: 3.1056  decode.d0.loss_mask: 0.8394  decode.d0.loss_dice: 1.4516  decode.d1.loss_cls: 1.3227  decode.d1.loss_mask: 0.7511  decode.d1.loss_dice: 1.3801  decode.d2.loss_cls: 1.2184  decode.d2.loss_mask: 0.7276  decode.d2.loss_dice: 1.2958  decode.d3.loss_cls: 1.2196  decode.d3.loss_mask: 0.6937  decode.d3.loss_dice: 1.2787  decode.d4.loss_cls: 1.2200  decode.d4.loss_mask: 0.6860  decode.d4.loss_dice: 1.2881  decode.d5.loss_cls: 1.1619  decode.d5.loss_mask: 0.7118  decode.d5.loss_dice: 1.2810  decode.d6.loss_cls: 1.1414  decode.d6.loss_mask: 0.6979  decode.d6.loss_dice: 1.2502  decode.d7.loss_cls: 1.1547  decode.d7.loss_mask: 0.6943  decode.d7.loss_dice: 1.2461  decode.d8.loss_cls: 1.1721  decode.d8.loss_mask: 0.6908  decode.d8.loss_dice: 1.2114
2023/05/24 05:42:26 - mmengine - INFO - Iter(train) [ 92650/160000]  lr: 4.5898e-06  eta: 8:03:28  time: 0.4738  data_time: 0.0104  memory: 4941  grad_norm: 101.3973  loss: 46.9707  decode.loss_cls: 1.4571  decode.loss_mask: 1.0120  decode.loss_dice: 1.8878  decode.d0.loss_cls: 3.4567  decode.d0.loss_mask: 1.1487  decode.d0.loss_dice: 2.2909  decode.d1.loss_cls: 1.6909  decode.d1.loss_mask: 1.0176  decode.d1.loss_dice: 1.9761  decode.d2.loss_cls: 1.6584  decode.d2.loss_mask: 1.0029  decode.d2.loss_dice: 1.9596  decode.d3.loss_cls: 1.5993  decode.d3.loss_mask: 0.9609  decode.d3.loss_dice: 1.9163  decode.d4.loss_cls: 1.4678  decode.d4.loss_mask: 1.0305  decode.d4.loss_dice: 1.8645  decode.d5.loss_cls: 1.5158  decode.d5.loss_mask: 1.0057  decode.d5.loss_dice: 1.8929  decode.d6.loss_cls: 1.5307  decode.d6.loss_mask: 0.9748  decode.d6.loss_dice: 1.8605  decode.d7.loss_cls: 1.4524  decode.d7.loss_mask: 1.0184  decode.d7.loss_dice: 1.8909  decode.d8.loss_cls: 1.5537  decode.d8.loss_mask: 0.9894  decode.d8.loss_dice: 1.8876
2023/05/24 05:42:50 - mmengine - INFO - Iter(train) [ 92700/160000]  lr: 4.5868e-06  eta: 8:03:08  time: 0.4893  data_time: 0.0104  memory: 4798  grad_norm: 82.8301  loss: 34.6787  decode.loss_cls: 1.0400  decode.loss_mask: 0.8293  decode.loss_dice: 1.3127  decode.d0.loss_cls: 2.9819  decode.d0.loss_mask: 0.8601  decode.d0.loss_dice: 1.4809  decode.d1.loss_cls: 1.1492  decode.d1.loss_mask: 0.8438  decode.d1.loss_dice: 1.4640  decode.d2.loss_cls: 1.1240  decode.d2.loss_mask: 0.8186  decode.d2.loss_dice: 1.4149  decode.d3.loss_cls: 1.1193  decode.d3.loss_mask: 0.8344  decode.d3.loss_dice: 1.3144  decode.d4.loss_cls: 1.1232  decode.d4.loss_mask: 0.8272  decode.d4.loss_dice: 1.3075  decode.d5.loss_cls: 1.0936  decode.d5.loss_mask: 0.8241  decode.d5.loss_dice: 1.3058  decode.d6.loss_cls: 1.0316  decode.d6.loss_mask: 0.8417  decode.d6.loss_dice: 1.3200  decode.d7.loss_cls: 1.0269  decode.d7.loss_mask: 0.8397  decode.d7.loss_dice: 1.3369  decode.d8.loss_cls: 1.0328  decode.d8.loss_mask: 0.8252  decode.d8.loss_dice: 1.3550
2023/05/24 05:43:13 - mmengine - INFO - Iter(train) [ 92750/160000]  lr: 4.5837e-06  eta: 8:02:48  time: 0.4701  data_time: 0.0103  memory: 4877  grad_norm: 89.3137  loss: 49.1216  decode.loss_cls: 1.5594  decode.loss_mask: 1.0575  decode.loss_dice: 1.8738  decode.d0.loss_cls: 3.7961  decode.d0.loss_mask: 1.2220  decode.d0.loss_dice: 2.3059  decode.d1.loss_cls: 1.8344  decode.d1.loss_mask: 1.1570  decode.d1.loss_dice: 2.1694  decode.d2.loss_cls: 1.6795  decode.d2.loss_mask: 1.1577  decode.d2.loss_dice: 2.0172  decode.d3.loss_cls: 1.5947  decode.d3.loss_mask: 1.1244  decode.d3.loss_dice: 1.8980  decode.d4.loss_cls: 1.5554  decode.d4.loss_mask: 1.1173  decode.d4.loss_dice: 1.9327  decode.d5.loss_cls: 1.5398  decode.d5.loss_mask: 1.0872  decode.d5.loss_dice: 1.8767  decode.d6.loss_cls: 1.5904  decode.d6.loss_mask: 1.0859  decode.d6.loss_dice: 1.9034  decode.d7.loss_cls: 1.5729  decode.d7.loss_mask: 1.0644  decode.d7.loss_dice: 1.8657  decode.d8.loss_cls: 1.6007  decode.d8.loss_mask: 1.0703  decode.d8.loss_dice: 1.8120
2023/05/24 05:43:36 - mmengine - INFO - Iter(train) [ 92800/160000]  lr: 4.5806e-06  eta: 8:02:27  time: 0.4260  data_time: 0.0105  memory: 4845  grad_norm: 103.2931  loss: 33.4683  decode.loss_cls: 1.1740  decode.loss_mask: 0.8376  decode.loss_dice: 1.1080  decode.d0.loss_cls: 3.0091  decode.d0.loss_mask: 0.9191  decode.d0.loss_dice: 1.2951  decode.d1.loss_cls: 1.2677  decode.d1.loss_mask: 0.8865  decode.d1.loss_dice: 1.1631  decode.d2.loss_cls: 1.1598  decode.d2.loss_mask: 0.8463  decode.d2.loss_dice: 1.1309  decode.d3.loss_cls: 1.1695  decode.d3.loss_mask: 0.9046  decode.d3.loss_dice: 1.1220  decode.d4.loss_cls: 1.1816  decode.d4.loss_mask: 0.8838  decode.d4.loss_dice: 1.1213  decode.d5.loss_cls: 1.1096  decode.d5.loss_mask: 0.8751  decode.d5.loss_dice: 1.1282  decode.d6.loss_cls: 1.1270  decode.d6.loss_mask: 0.8288  decode.d6.loss_dice: 1.1142  decode.d7.loss_cls: 1.1258  decode.d7.loss_mask: 0.8244  decode.d7.loss_dice: 1.1279  decode.d8.loss_cls: 1.0930  decode.d8.loss_mask: 0.8176  decode.d8.loss_dice: 1.1167
2023/05/24 05:43:57 - mmengine - INFO - Iter(train) [ 92850/160000]  lr: 4.5776e-06  eta: 8:02:05  time: 0.4117  data_time: 0.0103  memory: 4858  grad_norm: 88.4690  loss: 32.8241  decode.loss_cls: 1.2148  decode.loss_mask: 0.6081  decode.loss_dice: 1.1923  decode.d0.loss_cls: 2.9132  decode.d0.loss_mask: 0.7331  decode.d0.loss_dice: 1.3783  decode.d1.loss_cls: 1.2717  decode.d1.loss_mask: 0.6397  decode.d1.loss_dice: 1.3032  decode.d2.loss_cls: 1.2670  decode.d2.loss_mask: 0.6408  decode.d2.loss_dice: 1.2249  decode.d3.loss_cls: 1.2814  decode.d3.loss_mask: 0.6487  decode.d3.loss_dice: 1.2037  decode.d4.loss_cls: 1.1962  decode.d4.loss_mask: 0.6811  decode.d4.loss_dice: 1.2227  decode.d5.loss_cls: 1.2199  decode.d5.loss_mask: 0.6534  decode.d5.loss_dice: 1.1953  decode.d6.loss_cls: 1.2091  decode.d6.loss_mask: 0.6441  decode.d6.loss_dice: 1.1915  decode.d7.loss_cls: 1.2276  decode.d7.loss_mask: 0.6419  decode.d7.loss_dice: 1.1866  decode.d8.loss_cls: 1.1757  decode.d8.loss_mask: 0.6445  decode.d8.loss_dice: 1.2135
2023/05/24 05:44:18 - mmengine - INFO - Iter(train) [ 92900/160000]  lr: 4.5745e-06  eta: 8:01:43  time: 0.4271  data_time: 0.0103  memory: 4918  grad_norm: 107.7300  loss: 44.7615  decode.loss_cls: 1.4856  decode.loss_mask: 0.7741  decode.loss_dice: 1.8897  decode.d0.loss_cls: 3.3294  decode.d0.loss_mask: 0.8248  decode.d0.loss_dice: 2.1901  decode.d1.loss_cls: 1.6925  decode.d1.loss_mask: 0.8065  decode.d1.loss_dice: 2.0457  decode.d2.loss_cls: 1.6043  decode.d2.loss_mask: 0.7700  decode.d2.loss_dice: 1.9797  decode.d3.loss_cls: 1.6048  decode.d3.loss_mask: 0.7721  decode.d3.loss_dice: 1.9242  decode.d4.loss_cls: 1.5469  decode.d4.loss_mask: 0.7810  decode.d4.loss_dice: 1.9213  decode.d5.loss_cls: 1.5816  decode.d5.loss_mask: 0.7613  decode.d5.loss_dice: 1.9004  decode.d6.loss_cls: 1.4998  decode.d6.loss_mask: 0.7821  decode.d6.loss_dice: 1.8741  decode.d7.loss_cls: 1.5357  decode.d7.loss_mask: 0.7762  decode.d7.loss_dice: 1.8822  decode.d8.loss_cls: 1.5567  decode.d8.loss_mask: 0.7720  decode.d8.loss_dice: 1.8968
2023/05/24 05:44:39 - mmengine - INFO - Iter(train) [ 92950/160000]  lr: 4.5714e-06  eta: 8:01:22  time: 0.4153  data_time: 0.0106  memory: 4867  grad_norm: 94.6944  loss: 27.9430  decode.loss_cls: 0.8202  decode.loss_mask: 0.7336  decode.loss_dice: 0.9737  decode.d0.loss_cls: 2.7017  decode.d0.loss_mask: 0.8604  decode.d0.loss_dice: 1.0554  decode.d1.loss_cls: 1.0074  decode.d1.loss_mask: 0.7483  decode.d1.loss_dice: 1.0658  decode.d2.loss_cls: 0.9643  decode.d2.loss_mask: 0.7196  decode.d2.loss_dice: 0.9847  decode.d3.loss_cls: 0.8951  decode.d3.loss_mask: 0.7324  decode.d3.loss_dice: 0.9579  decode.d4.loss_cls: 0.8919  decode.d4.loss_mask: 0.7246  decode.d4.loss_dice: 0.9768  decode.d5.loss_cls: 0.9136  decode.d5.loss_mask: 0.7133  decode.d5.loss_dice: 0.9647  decode.d6.loss_cls: 0.8569  decode.d6.loss_mask: 0.7273  decode.d6.loss_dice: 0.9373  decode.d7.loss_cls: 0.8137  decode.d7.loss_mask: 0.7314  decode.d7.loss_dice: 0.9510  decode.d8.loss_cls: 0.8347  decode.d8.loss_mask: 0.7316  decode.d8.loss_dice: 0.9534
2023/05/24 05:45:00 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:45:00 - mmengine - INFO - Iter(train) [ 93000/160000]  lr: 4.5684e-06  eta: 8:01:00  time: 0.4288  data_time: 0.0107  memory: 4957  grad_norm: 97.6409  loss: 41.1413  decode.loss_cls: 1.4227  decode.loss_mask: 0.8368  decode.loss_dice: 1.5948  decode.d0.loss_cls: 3.2734  decode.d0.loss_mask: 0.8573  decode.d0.loss_dice: 1.8603  decode.d1.loss_cls: 1.5991  decode.d1.loss_mask: 0.8512  decode.d1.loss_dice: 1.7482  decode.d2.loss_cls: 1.5863  decode.d2.loss_mask: 0.8329  decode.d2.loss_dice: 1.6612  decode.d3.loss_cls: 1.4522  decode.d3.loss_mask: 0.8479  decode.d3.loss_dice: 1.6019  decode.d4.loss_cls: 1.3568  decode.d4.loss_mask: 0.8704  decode.d4.loss_dice: 1.5835  decode.d5.loss_cls: 1.3963  decode.d5.loss_mask: 0.8215  decode.d5.loss_dice: 1.6015  decode.d6.loss_cls: 1.3927  decode.d6.loss_mask: 0.8220  decode.d6.loss_dice: 1.5573  decode.d7.loss_cls: 1.4546  decode.d7.loss_mask: 0.8107  decode.d7.loss_dice: 1.5836  decode.d8.loss_cls: 1.4166  decode.d8.loss_mask: 0.8411  decode.d8.loss_dice: 1.6063
2023/05/24 05:45:00 - mmengine - INFO - Saving checkpoint at 93000 iterations
2023/05/24 05:45:27 - mmengine - INFO - Iter(train) [ 93050/160000]  lr: 4.5653e-06  eta: 8:00:42  time: 0.4258  data_time: 0.0106  memory: 4888  grad_norm: 93.4603  loss: 42.3674  decode.loss_cls: 1.3686  decode.loss_mask: 0.8813  decode.loss_dice: 1.6372  decode.d0.loss_cls: 3.3467  decode.d0.loss_mask: 0.9498  decode.d0.loss_dice: 1.9237  decode.d1.loss_cls: 1.5713  decode.d1.loss_mask: 0.9077  decode.d1.loss_dice: 1.8055  decode.d2.loss_cls: 1.5208  decode.d2.loss_mask: 0.8914  decode.d2.loss_dice: 1.7184  decode.d3.loss_cls: 1.4653  decode.d3.loss_mask: 0.8756  decode.d3.loss_dice: 1.7039  decode.d4.loss_cls: 1.4442  decode.d4.loss_mask: 0.8736  decode.d4.loss_dice: 1.7077  decode.d5.loss_cls: 1.4372  decode.d5.loss_mask: 0.8659  decode.d5.loss_dice: 1.6555  decode.d6.loss_cls: 1.4031  decode.d6.loss_mask: 0.8879  decode.d6.loss_dice: 1.6438  decode.d7.loss_cls: 1.4029  decode.d7.loss_mask: 0.8947  decode.d7.loss_dice: 1.6648  decode.d8.loss_cls: 1.3921  decode.d8.loss_mask: 0.8715  decode.d8.loss_dice: 1.6554
2023/05/24 05:45:48 - mmengine - INFO - Iter(train) [ 93100/160000]  lr: 4.5622e-06  eta: 8:00:20  time: 0.4273  data_time: 0.0112  memory: 4840  grad_norm: 90.5197  loss: 38.2660  decode.loss_cls: 1.2818  decode.loss_mask: 0.8796  decode.loss_dice: 1.3910  decode.d0.loss_cls: 3.2327  decode.d0.loss_mask: 0.8826  decode.d0.loss_dice: 1.5231  decode.d1.loss_cls: 1.3481  decode.d1.loss_mask: 0.9247  decode.d1.loss_dice: 1.4953  decode.d2.loss_cls: 1.3528  decode.d2.loss_mask: 0.8998  decode.d2.loss_dice: 1.4574  decode.d3.loss_cls: 1.3798  decode.d3.loss_mask: 0.8934  decode.d3.loss_dice: 1.4278  decode.d4.loss_cls: 1.3290  decode.d4.loss_mask: 0.9113  decode.d4.loss_dice: 1.3832  decode.d5.loss_cls: 1.3265  decode.d5.loss_mask: 0.8962  decode.d5.loss_dice: 1.3963  decode.d6.loss_cls: 1.2656  decode.d6.loss_mask: 0.8905  decode.d6.loss_dice: 1.3822  decode.d7.loss_cls: 1.2864  decode.d7.loss_mask: 0.8829  decode.d7.loss_dice: 1.3669  decode.d8.loss_cls: 1.3070  decode.d8.loss_mask: 0.8757  decode.d8.loss_dice: 1.3964
2023/05/24 05:46:10 - mmengine - INFO - Iter(train) [ 93150/160000]  lr: 4.5592e-06  eta: 7:59:59  time: 0.4256  data_time: 0.0105  memory: 4876  grad_norm: 93.3744  loss: 37.6449  decode.loss_cls: 1.5184  decode.loss_mask: 0.7737  decode.loss_dice: 1.2720  decode.d0.loss_cls: 3.0892  decode.d0.loss_mask: 0.8420  decode.d0.loss_dice: 1.5154  decode.d1.loss_cls: 1.5620  decode.d1.loss_mask: 0.8033  decode.d1.loss_dice: 1.3383  decode.d2.loss_cls: 1.5780  decode.d2.loss_mask: 0.7856  decode.d2.loss_dice: 1.3130  decode.d3.loss_cls: 1.5173  decode.d3.loss_mask: 0.7427  decode.d3.loss_dice: 1.2841  decode.d4.loss_cls: 1.4972  decode.d4.loss_mask: 0.7371  decode.d4.loss_dice: 1.2882  decode.d5.loss_cls: 1.4582  decode.d5.loss_mask: 0.7795  decode.d5.loss_dice: 1.2799  decode.d6.loss_cls: 1.4586  decode.d6.loss_mask: 0.7653  decode.d6.loss_dice: 1.2866  decode.d7.loss_cls: 1.4749  decode.d7.loss_mask: 0.7728  decode.d7.loss_dice: 1.3120  decode.d8.loss_cls: 1.5355  decode.d8.loss_mask: 0.7788  decode.d8.loss_dice: 1.2851
2023/05/24 05:46:31 - mmengine - INFO - Iter(train) [ 93200/160000]  lr: 4.5561e-06  eta: 7:59:37  time: 0.4275  data_time: 0.0106  memory: 4835  grad_norm: 118.8318  loss: 40.6129  decode.loss_cls: 1.4043  decode.loss_mask: 0.8423  decode.loss_dice: 1.4595  decode.d0.loss_cls: 3.3856  decode.d0.loss_mask: 0.8990  decode.d0.loss_dice: 1.8376  decode.d1.loss_cls: 1.5680  decode.d1.loss_mask: 0.8987  decode.d1.loss_dice: 1.6589  decode.d2.loss_cls: 1.5109  decode.d2.loss_mask: 0.8926  decode.d2.loss_dice: 1.5727  decode.d3.loss_cls: 1.4432  decode.d3.loss_mask: 0.8893  decode.d3.loss_dice: 1.4825  decode.d4.loss_cls: 1.4665  decode.d4.loss_mask: 0.8626  decode.d4.loss_dice: 1.5147  decode.d5.loss_cls: 1.4447  decode.d5.loss_mask: 0.8639  decode.d5.loss_dice: 1.4906  decode.d6.loss_cls: 1.4720  decode.d6.loss_mask: 0.8494  decode.d6.loss_dice: 1.4835  decode.d7.loss_cls: 1.3626  decode.d7.loss_mask: 0.8463  decode.d7.loss_dice: 1.4914  decode.d8.loss_cls: 1.4282  decode.d8.loss_mask: 0.8465  decode.d8.loss_dice: 1.4450
2023/05/24 05:46:52 - mmengine - INFO - Iter(train) [ 93250/160000]  lr: 4.5530e-06  eta: 7:59:15  time: 0.4207  data_time: 0.0104  memory: 4901  grad_norm: 91.4925  loss: 34.8658  decode.loss_cls: 1.1199  decode.loss_mask: 0.8000  decode.loss_dice: 1.2693  decode.d0.loss_cls: 3.1502  decode.d0.loss_mask: 0.9426  decode.d0.loss_dice: 1.5875  decode.d1.loss_cls: 1.2598  decode.d1.loss_mask: 0.8536  decode.d1.loss_dice: 1.4212  decode.d2.loss_cls: 1.1922  decode.d2.loss_mask: 0.8137  decode.d2.loss_dice: 1.3200  decode.d3.loss_cls: 1.1057  decode.d3.loss_mask: 0.8105  decode.d3.loss_dice: 1.2720  decode.d4.loss_cls: 1.1079  decode.d4.loss_mask: 0.7830  decode.d4.loss_dice: 1.2806  decode.d5.loss_cls: 1.0451  decode.d5.loss_mask: 0.8058  decode.d5.loss_dice: 1.3130  decode.d6.loss_cls: 1.1544  decode.d6.loss_mask: 0.7791  decode.d6.loss_dice: 1.2792  decode.d7.loss_cls: 1.1035  decode.d7.loss_mask: 0.7928  decode.d7.loss_dice: 1.2846  decode.d8.loss_cls: 1.1279  decode.d8.loss_mask: 0.7913  decode.d8.loss_dice: 1.2991
2023/05/24 05:47:13 - mmengine - INFO - Iter(train) [ 93300/160000]  lr: 4.5500e-06  eta: 7:58:53  time: 0.4215  data_time: 0.0103  memory: 4835  grad_norm: 117.8983  loss: 32.4196  decode.loss_cls: 0.9244  decode.loss_mask: 0.7111  decode.loss_dice: 1.2770  decode.d0.loss_cls: 3.0717  decode.d0.loss_mask: 0.7951  decode.d0.loss_dice: 1.4413  decode.d1.loss_cls: 1.0369  decode.d1.loss_mask: 0.7816  decode.d1.loss_dice: 1.3958  decode.d2.loss_cls: 1.0142  decode.d2.loss_mask: 0.7660  decode.d2.loss_dice: 1.3374  decode.d3.loss_cls: 1.0250  decode.d3.loss_mask: 0.7394  decode.d3.loss_dice: 1.2928  decode.d4.loss_cls: 0.9142  decode.d4.loss_mask: 0.7606  decode.d4.loss_dice: 1.3002  decode.d5.loss_cls: 0.9137  decode.d5.loss_mask: 0.7548  decode.d5.loss_dice: 1.2919  decode.d6.loss_cls: 0.9366  decode.d6.loss_mask: 0.7609  decode.d6.loss_dice: 1.3012  decode.d7.loss_cls: 0.8830  decode.d7.loss_mask: 0.7568  decode.d7.loss_dice: 1.2922  decode.d8.loss_cls: 0.9004  decode.d8.loss_mask: 0.7552  decode.d8.loss_dice: 1.2883
2023/05/24 05:47:34 - mmengine - INFO - Iter(train) [ 93350/160000]  lr: 4.5469e-06  eta: 7:58:31  time: 0.4208  data_time: 0.0109  memory: 4816  grad_norm: 118.5324  loss: 33.2106  decode.loss_cls: 1.1285  decode.loss_mask: 0.7509  decode.loss_dice: 1.1740  decode.d0.loss_cls: 2.9390  decode.d0.loss_mask: 0.7479  decode.d0.loss_dice: 1.4375  decode.d1.loss_cls: 1.2122  decode.d1.loss_mask: 0.7317  decode.d1.loss_dice: 1.3777  decode.d2.loss_cls: 1.1758  decode.d2.loss_mask: 0.7304  decode.d2.loss_dice: 1.2163  decode.d3.loss_cls: 1.1143  decode.d3.loss_mask: 0.7564  decode.d3.loss_dice: 1.2767  decode.d4.loss_cls: 1.1078  decode.d4.loss_mask: 0.7563  decode.d4.loss_dice: 1.2452  decode.d5.loss_cls: 1.1481  decode.d5.loss_mask: 0.7373  decode.d5.loss_dice: 1.2069  decode.d6.loss_cls: 1.1521  decode.d6.loss_mask: 0.7577  decode.d6.loss_dice: 1.1868  decode.d7.loss_cls: 1.1274  decode.d7.loss_mask: 0.7612  decode.d7.loss_dice: 1.1716  decode.d8.loss_cls: 1.1269  decode.d8.loss_mask: 0.7614  decode.d8.loss_dice: 1.1947
2023/05/24 05:47:56 - mmengine - INFO - Iter(train) [ 93400/160000]  lr: 4.5438e-06  eta: 7:58:10  time: 0.4431  data_time: 0.0111  memory: 4880  grad_norm: 90.1716  loss: 38.9557  decode.loss_cls: 1.2935  decode.loss_mask: 0.9366  decode.loss_dice: 1.3785  decode.d0.loss_cls: 3.0137  decode.d0.loss_mask: 0.9599  decode.d0.loss_dice: 1.6411  decode.d1.loss_cls: 1.2643  decode.d1.loss_mask: 1.0152  decode.d1.loss_dice: 1.5551  decode.d2.loss_cls: 1.3545  decode.d2.loss_mask: 1.0086  decode.d2.loss_dice: 1.4895  decode.d3.loss_cls: 1.3361  decode.d3.loss_mask: 0.9690  decode.d3.loss_dice: 1.4279  decode.d4.loss_cls: 1.3244  decode.d4.loss_mask: 0.9733  decode.d4.loss_dice: 1.4026  decode.d5.loss_cls: 1.2635  decode.d5.loss_mask: 0.9969  decode.d5.loss_dice: 1.4404  decode.d6.loss_cls: 1.2199  decode.d6.loss_mask: 0.9943  decode.d6.loss_dice: 1.3999  decode.d7.loss_cls: 1.2115  decode.d7.loss_mask: 1.0144  decode.d7.loss_dice: 1.4262  decode.d8.loss_cls: 1.2557  decode.d8.loss_mask: 0.9916  decode.d8.loss_dice: 1.3977
2023/05/24 05:48:20 - mmengine - INFO - Iter(train) [ 93450/160000]  lr: 4.5408e-06  eta: 7:57:50  time: 0.4807  data_time: 0.0106  memory: 4952  grad_norm: 111.0030  loss: 29.8019  decode.loss_cls: 1.0684  decode.loss_mask: 0.6535  decode.loss_dice: 0.9709  decode.d0.loss_cls: 2.9985  decode.d0.loss_mask: 0.7007  decode.d0.loss_dice: 1.0905  decode.d1.loss_cls: 1.1340  decode.d1.loss_mask: 0.7559  decode.d1.loss_dice: 1.1401  decode.d2.loss_cls: 1.0677  decode.d2.loss_mask: 0.7339  decode.d2.loss_dice: 1.0591  decode.d3.loss_cls: 1.1375  decode.d3.loss_mask: 0.6773  decode.d3.loss_dice: 0.9775  decode.d4.loss_cls: 1.0785  decode.d4.loss_mask: 0.6918  decode.d4.loss_dice: 1.0107  decode.d5.loss_cls: 1.0052  decode.d5.loss_mask: 0.7094  decode.d5.loss_dice: 1.0150  decode.d6.loss_cls: 1.0580  decode.d6.loss_mask: 0.6904  decode.d6.loss_dice: 0.9602  decode.d7.loss_cls: 1.0606  decode.d7.loss_mask: 0.6710  decode.d7.loss_dice: 0.9696  decode.d8.loss_cls: 1.0572  decode.d8.loss_mask: 0.6696  decode.d8.loss_dice: 0.9895
2023/05/24 05:48:42 - mmengine - INFO - Iter(train) [ 93500/160000]  lr: 4.5377e-06  eta: 7:57:29  time: 0.4160  data_time: 0.0105  memory: 4975  grad_norm: 93.6549  loss: 37.4158  decode.loss_cls: 1.3609  decode.loss_mask: 0.8619  decode.loss_dice: 1.2704  decode.d0.loss_cls: 3.1508  decode.d0.loss_mask: 0.9314  decode.d0.loss_dice: 1.4754  decode.d1.loss_cls: 1.6013  decode.d1.loss_mask: 0.8688  decode.d1.loss_dice: 1.2915  decode.d2.loss_cls: 1.3858  decode.d2.loss_mask: 0.8413  decode.d2.loss_dice: 1.3184  decode.d3.loss_cls: 1.4709  decode.d3.loss_mask: 0.8196  decode.d3.loss_dice: 1.2707  decode.d4.loss_cls: 1.4167  decode.d4.loss_mask: 0.8177  decode.d4.loss_dice: 1.3110  decode.d5.loss_cls: 1.4250  decode.d5.loss_mask: 0.8087  decode.d5.loss_dice: 1.2830  decode.d6.loss_cls: 1.4278  decode.d6.loss_mask: 0.7952  decode.d6.loss_dice: 1.2763  decode.d7.loss_cls: 1.4185  decode.d7.loss_mask: 0.8099  decode.d7.loss_dice: 1.2493  decode.d8.loss_cls: 1.4097  decode.d8.loss_mask: 0.8119  decode.d8.loss_dice: 1.2359
2023/05/24 05:49:04 - mmengine - INFO - Iter(train) [ 93550/160000]  lr: 4.5346e-06  eta: 7:57:07  time: 0.4326  data_time: 0.0104  memory: 4805  grad_norm: 89.7321  loss: 47.0585  decode.loss_cls: 1.8025  decode.loss_mask: 0.9446  decode.loss_dice: 1.6605  decode.d0.loss_cls: 3.5993  decode.d0.loss_mask: 1.0674  decode.d0.loss_dice: 1.9910  decode.d1.loss_cls: 1.9747  decode.d1.loss_mask: 1.0169  decode.d1.loss_dice: 1.8429  decode.d2.loss_cls: 1.7611  decode.d2.loss_mask: 1.0050  decode.d2.loss_dice: 1.8087  decode.d3.loss_cls: 1.7999  decode.d3.loss_mask: 0.9477  decode.d3.loss_dice: 1.7313  decode.d4.loss_cls: 1.8119  decode.d4.loss_mask: 0.9697  decode.d4.loss_dice: 1.7209  decode.d5.loss_cls: 1.8124  decode.d5.loss_mask: 0.9445  decode.d5.loss_dice: 1.7101  decode.d6.loss_cls: 1.8228  decode.d6.loss_mask: 0.8980  decode.d6.loss_dice: 1.6464  decode.d7.loss_cls: 1.8326  decode.d7.loss_mask: 0.8962  decode.d7.loss_dice: 1.6685  decode.d8.loss_cls: 1.7917  decode.d8.loss_mask: 0.9211  decode.d8.loss_dice: 1.6581
2023/05/24 05:49:27 - mmengine - INFO - Iter(train) [ 93600/160000]  lr: 4.5315e-06  eta: 7:56:47  time: 0.4158  data_time: 0.0106  memory: 4865  grad_norm: 115.9589  loss: 44.9002  decode.loss_cls: 1.3938  decode.loss_mask: 1.1107  decode.loss_dice: 1.7447  decode.d0.loss_cls: 3.4112  decode.d0.loss_mask: 1.1706  decode.d0.loss_dice: 2.0762  decode.d1.loss_cls: 1.3880  decode.d1.loss_mask: 1.1079  decode.d1.loss_dice: 1.8710  decode.d2.loss_cls: 1.3327  decode.d2.loss_mask: 1.0588  decode.d2.loss_dice: 1.8894  decode.d3.loss_cls: 1.4331  decode.d3.loss_mask: 1.0281  decode.d3.loss_dice: 1.8064  decode.d4.loss_cls: 1.3371  decode.d4.loss_mask: 1.0813  decode.d4.loss_dice: 1.8424  decode.d5.loss_cls: 1.3208  decode.d5.loss_mask: 1.0655  decode.d5.loss_dice: 1.7788  decode.d6.loss_cls: 1.3853  decode.d6.loss_mask: 1.0943  decode.d6.loss_dice: 1.7726  decode.d7.loss_cls: 1.3772  decode.d7.loss_mask: 1.0455  decode.d7.loss_dice: 1.7857  decode.d8.loss_cls: 1.3542  decode.d8.loss_mask: 1.0715  decode.d8.loss_dice: 1.7654
2023/05/24 05:49:48 - mmengine - INFO - Iter(train) [ 93650/160000]  lr: 4.5285e-06  eta: 7:56:25  time: 0.4122  data_time: 0.0104  memory: 4873  grad_norm: 105.0477  loss: 38.7977  decode.loss_cls: 1.0404  decode.loss_mask: 1.0576  decode.loss_dice: 1.4805  decode.d0.loss_cls: 3.0196  decode.d0.loss_mask: 1.1548  decode.d0.loss_dice: 1.7420  decode.d1.loss_cls: 1.1618  decode.d1.loss_mask: 1.0778  decode.d1.loss_dice: 1.6390  decode.d2.loss_cls: 1.1224  decode.d2.loss_mask: 1.0902  decode.d2.loss_dice: 1.5771  decode.d3.loss_cls: 1.1580  decode.d3.loss_mask: 1.0592  decode.d3.loss_dice: 1.4744  decode.d4.loss_cls: 1.1238  decode.d4.loss_mask: 1.0334  decode.d4.loss_dice: 1.4827  decode.d5.loss_cls: 1.0992  decode.d5.loss_mask: 1.0494  decode.d5.loss_dice: 1.4906  decode.d6.loss_cls: 1.0280  decode.d6.loss_mask: 1.0512  decode.d6.loss_dice: 1.4901  decode.d7.loss_cls: 1.0024  decode.d7.loss_mask: 1.0406  decode.d7.loss_dice: 1.5212  decode.d8.loss_cls: 1.0188  decode.d8.loss_mask: 1.0214  decode.d8.loss_dice: 1.4902
2023/05/24 05:50:09 - mmengine - INFO - Iter(train) [ 93700/160000]  lr: 4.5254e-06  eta: 7:56:03  time: 0.4145  data_time: 0.0101  memory: 4858  grad_norm: 103.1342  loss: 28.7162  decode.loss_cls: 1.0057  decode.loss_mask: 0.6893  decode.loss_dice: 0.9829  decode.d0.loss_cls: 2.6792  decode.d0.loss_mask: 0.6778  decode.d0.loss_dice: 1.1076  decode.d1.loss_cls: 1.1648  decode.d1.loss_mask: 0.6861  decode.d1.loss_dice: 1.0371  decode.d2.loss_cls: 1.0172  decode.d2.loss_mask: 0.7021  decode.d2.loss_dice: 0.9791  decode.d3.loss_cls: 1.0259  decode.d3.loss_mask: 0.6626  decode.d3.loss_dice: 0.9755  decode.d4.loss_cls: 0.9978  decode.d4.loss_mask: 0.6623  decode.d4.loss_dice: 0.9716  decode.d5.loss_cls: 0.9981  decode.d5.loss_mask: 0.6467  decode.d5.loss_dice: 1.0176  decode.d6.loss_cls: 1.0468  decode.d6.loss_mask: 0.6890  decode.d6.loss_dice: 0.9723  decode.d7.loss_cls: 1.0126  decode.d7.loss_mask: 0.6870  decode.d7.loss_dice: 0.9932  decode.d8.loss_cls: 0.9728  decode.d8.loss_mask: 0.6851  decode.d8.loss_dice: 0.9702
2023/05/24 05:50:30 - mmengine - INFO - Iter(train) [ 93750/160000]  lr: 4.5223e-06  eta: 7:55:41  time: 0.4348  data_time: 0.0105  memory: 4828  grad_norm: 106.9143  loss: 42.1546  decode.loss_cls: 1.3771  decode.loss_mask: 0.8372  decode.loss_dice: 1.7651  decode.d0.loss_cls: 3.1894  decode.d0.loss_mask: 0.8257  decode.d0.loss_dice: 1.9095  decode.d1.loss_cls: 1.5177  decode.d1.loss_mask: 0.8039  decode.d1.loss_dice: 1.8663  decode.d2.loss_cls: 1.4592  decode.d2.loss_mask: 0.8348  decode.d2.loss_dice: 1.7874  decode.d3.loss_cls: 1.3917  decode.d3.loss_mask: 0.8442  decode.d3.loss_dice: 1.7859  decode.d4.loss_cls: 1.3137  decode.d4.loss_mask: 0.8487  decode.d4.loss_dice: 1.8100  decode.d5.loss_cls: 1.3536  decode.d5.loss_mask: 0.8208  decode.d5.loss_dice: 1.7858  decode.d6.loss_cls: 1.4513  decode.d6.loss_mask: 0.8266  decode.d6.loss_dice: 1.7695  decode.d7.loss_cls: 1.5197  decode.d7.loss_mask: 0.7616  decode.d7.loss_dice: 1.7581  decode.d8.loss_cls: 1.3412  decode.d8.loss_mask: 0.8127  decode.d8.loss_dice: 1.7859
2023/05/24 05:50:51 - mmengine - INFO - Iter(train) [ 93800/160000]  lr: 4.5193e-06  eta: 7:55:19  time: 0.4163  data_time: 0.0104  memory: 4942  grad_norm: 129.0497  loss: 38.6450  decode.loss_cls: 1.2779  decode.loss_mask: 0.8271  decode.loss_dice: 1.4599  decode.d0.loss_cls: 3.2269  decode.d0.loss_mask: 0.8958  decode.d0.loss_dice: 1.6929  decode.d1.loss_cls: 1.4112  decode.d1.loss_mask: 0.8813  decode.d1.loss_dice: 1.5637  decode.d2.loss_cls: 1.3936  decode.d2.loss_mask: 0.8808  decode.d2.loss_dice: 1.5400  decode.d3.loss_cls: 1.3170  decode.d3.loss_mask: 0.8218  decode.d3.loss_dice: 1.4774  decode.d4.loss_cls: 1.2918  decode.d4.loss_mask: 0.8539  decode.d4.loss_dice: 1.5339  decode.d5.loss_cls: 1.2648  decode.d5.loss_mask: 0.8282  decode.d5.loss_dice: 1.5274  decode.d6.loss_cls: 1.2583  decode.d6.loss_mask: 0.8203  decode.d6.loss_dice: 1.4675  decode.d7.loss_cls: 1.2463  decode.d7.loss_mask: 0.8271  decode.d7.loss_dice: 1.4781  decode.d8.loss_cls: 1.2484  decode.d8.loss_mask: 0.8275  decode.d8.loss_dice: 1.5044
2023/05/24 05:51:12 - mmengine - INFO - Iter(train) [ 93850/160000]  lr: 4.5162e-06  eta: 7:54:58  time: 0.4167  data_time: 0.0102  memory: 4863  grad_norm: 104.8994  loss: 31.2586  decode.loss_cls: 1.0048  decode.loss_mask: 0.6571  decode.loss_dice: 1.1158  decode.d0.loss_cls: 3.2478  decode.d0.loss_mask: 0.7432  decode.d0.loss_dice: 1.3613  decode.d1.loss_cls: 1.1448  decode.d1.loss_mask: 0.7056  decode.d1.loss_dice: 1.2583  decode.d2.loss_cls: 1.1174  decode.d2.loss_mask: 0.6706  decode.d2.loss_dice: 1.2330  decode.d3.loss_cls: 1.0763  decode.d3.loss_mask: 0.6524  decode.d3.loss_dice: 1.1266  decode.d4.loss_cls: 1.0953  decode.d4.loss_mask: 0.6533  decode.d4.loss_dice: 1.1621  decode.d5.loss_cls: 1.0297  decode.d5.loss_mask: 0.6674  decode.d5.loss_dice: 1.1413  decode.d6.loss_cls: 1.0612  decode.d6.loss_mask: 0.6450  decode.d6.loss_dice: 1.1143  decode.d7.loss_cls: 1.0473  decode.d7.loss_mask: 0.6440  decode.d7.loss_dice: 1.1102  decode.d8.loss_cls: 0.9869  decode.d8.loss_mask: 0.6572  decode.d8.loss_dice: 1.1284
2023/05/24 05:51:33 - mmengine - INFO - Iter(train) [ 93900/160000]  lr: 4.5131e-06  eta: 7:54:36  time: 0.4136  data_time: 0.0106  memory: 4859  grad_norm: 100.3280  loss: 30.5478  decode.loss_cls: 0.9745  decode.loss_mask: 0.7388  decode.loss_dice: 1.0485  decode.d0.loss_cls: 2.9209  decode.d0.loss_mask: 0.7971  decode.d0.loss_dice: 1.2288  decode.d1.loss_cls: 1.1221  decode.d1.loss_mask: 0.7800  decode.d1.loss_dice: 1.1467  decode.d2.loss_cls: 1.0819  decode.d2.loss_mask: 0.7837  decode.d2.loss_dice: 1.0814  decode.d3.loss_cls: 1.0082  decode.d3.loss_mask: 0.7567  decode.d3.loss_dice: 1.0423  decode.d4.loss_cls: 0.9566  decode.d4.loss_mask: 0.7430  decode.d4.loss_dice: 1.0662  decode.d5.loss_cls: 0.9997  decode.d5.loss_mask: 0.7588  decode.d5.loss_dice: 1.0582  decode.d6.loss_cls: 1.0567  decode.d6.loss_mask: 0.7273  decode.d6.loss_dice: 1.0526  decode.d7.loss_cls: 1.0162  decode.d7.loss_mask: 0.7213  decode.d7.loss_dice: 1.0531  decode.d8.loss_cls: 1.0225  decode.d8.loss_mask: 0.7438  decode.d8.loss_dice: 1.0601
2023/05/24 05:51:54 - mmengine - INFO - Iter(train) [ 93950/160000]  lr: 4.5100e-06  eta: 7:54:14  time: 0.4156  data_time: 0.0106  memory: 4790  grad_norm: 91.6464  loss: 32.1056  decode.loss_cls: 1.1259  decode.loss_mask: 0.7100  decode.loss_dice: 1.1221  decode.d0.loss_cls: 2.8754  decode.d0.loss_mask: 0.7353  decode.d0.loss_dice: 1.3046  decode.d1.loss_cls: 1.2265  decode.d1.loss_mask: 0.7625  decode.d1.loss_dice: 1.2350  decode.d2.loss_cls: 1.1894  decode.d2.loss_mask: 0.7128  decode.d2.loss_dice: 1.1786  decode.d3.loss_cls: 1.1156  decode.d3.loss_mask: 0.7194  decode.d3.loss_dice: 1.1573  decode.d4.loss_cls: 1.1924  decode.d4.loss_mask: 0.7188  decode.d4.loss_dice: 1.1444  decode.d5.loss_cls: 1.1149  decode.d5.loss_mask: 0.7150  decode.d5.loss_dice: 1.1578  decode.d6.loss_cls: 1.1460  decode.d6.loss_mask: 0.6941  decode.d6.loss_dice: 1.1234  decode.d7.loss_cls: 1.1430  decode.d7.loss_mask: 0.7056  decode.d7.loss_dice: 1.1325  decode.d8.loss_cls: 1.1241  decode.d8.loss_mask: 0.7104  decode.d8.loss_dice: 1.1126
2023/05/24 05:52:15 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:52:15 - mmengine - INFO - Iter(train) [ 94000/160000]  lr: 4.5070e-06  eta: 7:53:52  time: 0.4162  data_time: 0.0103  memory: 4857  grad_norm: 96.7626  loss: 31.5784  decode.loss_cls: 1.0195  decode.loss_mask: 0.7730  decode.loss_dice: 1.1127  decode.d0.loss_cls: 2.8161  decode.d0.loss_mask: 0.9316  decode.d0.loss_dice: 1.3248  decode.d1.loss_cls: 1.0350  decode.d1.loss_mask: 0.8361  decode.d1.loss_dice: 1.1979  decode.d2.loss_cls: 1.0139  decode.d2.loss_mask: 0.8110  decode.d2.loss_dice: 1.1529  decode.d3.loss_cls: 1.0543  decode.d3.loss_mask: 0.7709  decode.d3.loss_dice: 1.1297  decode.d4.loss_cls: 1.0259  decode.d4.loss_mask: 0.7818  decode.d4.loss_dice: 1.1481  decode.d5.loss_cls: 1.0329  decode.d5.loss_mask: 0.7839  decode.d5.loss_dice: 1.1262  decode.d6.loss_cls: 1.0054  decode.d6.loss_mask: 0.7815  decode.d6.loss_dice: 1.1311  decode.d7.loss_cls: 1.0115  decode.d7.loss_mask: 0.7864  decode.d7.loss_dice: 1.0996  decode.d8.loss_cls: 1.0010  decode.d8.loss_mask: 0.7824  decode.d8.loss_dice: 1.1015
2023/05/24 05:52:15 - mmengine - INFO - Saving checkpoint at 94000 iterations
2023/05/24 05:52:42 - mmengine - INFO - Iter(train) [ 94050/160000]  lr: 4.5039e-06  eta: 7:53:34  time: 0.4157  data_time: 0.0109  memory: 4845  grad_norm: 108.5669  loss: 30.1222  decode.loss_cls: 0.9355  decode.loss_mask: 0.6905  decode.loss_dice: 1.1281  decode.d0.loss_cls: 2.8432  decode.d0.loss_mask: 0.6387  decode.d0.loss_dice: 1.2427  decode.d1.loss_cls: 1.0616  decode.d1.loss_mask: 0.6726  decode.d1.loss_dice: 1.2114  decode.d2.loss_cls: 0.9533  decode.d2.loss_mask: 0.7294  decode.d2.loss_dice: 1.1908  decode.d3.loss_cls: 1.0223  decode.d3.loss_mask: 0.6793  decode.d3.loss_dice: 1.1676  decode.d4.loss_cls: 0.9515  decode.d4.loss_mask: 0.6923  decode.d4.loss_dice: 1.1624  decode.d5.loss_cls: 0.9568  decode.d5.loss_mask: 0.6795  decode.d5.loss_dice: 1.1253  decode.d6.loss_cls: 0.9615  decode.d6.loss_mask: 0.6812  decode.d6.loss_dice: 1.1104  decode.d7.loss_cls: 0.9731  decode.d7.loss_mask: 0.6970  decode.d7.loss_dice: 1.1571  decode.d8.loss_cls: 0.9606  decode.d8.loss_mask: 0.7053  decode.d8.loss_dice: 1.1409
2023/05/24 05:53:04 - mmengine - INFO - Iter(train) [ 94100/160000]  lr: 4.5008e-06  eta: 7:53:12  time: 0.4200  data_time: 0.0104  memory: 4937  grad_norm: 96.3909  loss: 36.6192  decode.loss_cls: 1.2183  decode.loss_mask: 0.8011  decode.loss_dice: 1.3452  decode.d0.loss_cls: 3.3203  decode.d0.loss_mask: 0.8325  decode.d0.loss_dice: 1.6081  decode.d1.loss_cls: 1.3240  decode.d1.loss_mask: 0.8348  decode.d1.loss_dice: 1.4738  decode.d2.loss_cls: 1.2598  decode.d2.loss_mask: 0.7975  decode.d2.loss_dice: 1.3596  decode.d3.loss_cls: 1.2209  decode.d3.loss_mask: 0.8280  decode.d3.loss_dice: 1.3501  decode.d4.loss_cls: 1.2636  decode.d4.loss_mask: 0.7884  decode.d4.loss_dice: 1.3577  decode.d5.loss_cls: 1.2462  decode.d5.loss_mask: 0.8222  decode.d5.loss_dice: 1.3716  decode.d6.loss_cls: 1.2388  decode.d6.loss_mask: 0.8253  decode.d6.loss_dice: 1.3440  decode.d7.loss_cls: 1.2224  decode.d7.loss_mask: 0.8108  decode.d7.loss_dice: 1.3569  decode.d8.loss_cls: 1.2166  decode.d8.loss_mask: 0.8136  decode.d8.loss_dice: 1.3674
2023/05/24 05:53:25 - mmengine - INFO - Iter(train) [ 94150/160000]  lr: 4.4977e-06  eta: 7:52:50  time: 0.4294  data_time: 0.0105  memory: 4875  grad_norm: 99.2990  loss: 31.6114  decode.loss_cls: 1.0880  decode.loss_mask: 0.6632  decode.loss_dice: 1.1641  decode.d0.loss_cls: 2.9638  decode.d0.loss_mask: 0.7224  decode.d0.loss_dice: 1.3268  decode.d1.loss_cls: 1.0943  decode.d1.loss_mask: 0.6912  decode.d1.loss_dice: 1.2918  decode.d2.loss_cls: 1.1107  decode.d2.loss_mask: 0.6819  decode.d2.loss_dice: 1.2216  decode.d3.loss_cls: 1.0972  decode.d3.loss_mask: 0.6621  decode.d3.loss_dice: 1.1938  decode.d4.loss_cls: 1.0120  decode.d4.loss_mask: 0.6856  decode.d4.loss_dice: 1.2252  decode.d5.loss_cls: 1.0398  decode.d5.loss_mask: 0.6838  decode.d5.loss_dice: 1.2258  decode.d6.loss_cls: 1.0702  decode.d6.loss_mask: 0.6663  decode.d6.loss_dice: 1.1809  decode.d7.loss_cls: 1.0669  decode.d7.loss_mask: 0.6874  decode.d7.loss_dice: 1.1756  decode.d8.loss_cls: 1.0791  decode.d8.loss_mask: 0.6659  decode.d8.loss_dice: 1.1741
2023/05/24 05:53:46 - mmengine - INFO - Iter(train) [ 94200/160000]  lr: 4.4947e-06  eta: 7:52:28  time: 0.4194  data_time: 0.0104  memory: 4871  grad_norm: 93.2916  loss: 30.7459  decode.loss_cls: 1.1241  decode.loss_mask: 0.7269  decode.loss_dice: 0.9626  decode.d0.loss_cls: 2.9240  decode.d0.loss_mask: 0.8247  decode.d0.loss_dice: 1.1686  decode.d1.loss_cls: 1.2522  decode.d1.loss_mask: 0.7173  decode.d1.loss_dice: 1.0405  decode.d2.loss_cls: 1.1996  decode.d2.loss_mask: 0.7144  decode.d2.loss_dice: 1.0003  decode.d3.loss_cls: 1.1924  decode.d3.loss_mask: 0.6995  decode.d3.loss_dice: 0.9455  decode.d4.loss_cls: 1.1990  decode.d4.loss_mask: 0.6840  decode.d4.loss_dice: 0.9678  decode.d5.loss_cls: 1.1616  decode.d5.loss_mask: 0.7109  decode.d5.loss_dice: 0.9806  decode.d6.loss_cls: 1.1817  decode.d6.loss_mask: 0.6956  decode.d6.loss_dice: 0.9562  decode.d7.loss_cls: 1.1680  decode.d7.loss_mask: 0.7209  decode.d7.loss_dice: 0.9604  decode.d8.loss_cls: 1.1986  decode.d8.loss_mask: 0.7023  decode.d8.loss_dice: 0.9655
2023/05/24 05:54:07 - mmengine - INFO - Iter(train) [ 94250/160000]  lr: 4.4916e-06  eta: 7:52:07  time: 0.4207  data_time: 0.0103  memory: 4816  grad_norm: 94.8582  loss: 43.7089  decode.loss_cls: 1.4046  decode.loss_mask: 0.8079  decode.loss_dice: 1.8890  decode.d0.loss_cls: 3.6193  decode.d0.loss_mask: 0.8954  decode.d0.loss_dice: 2.1022  decode.d1.loss_cls: 1.5654  decode.d1.loss_mask: 0.9101  decode.d1.loss_dice: 1.9618  decode.d2.loss_cls: 1.4293  decode.d2.loss_mask: 0.8735  decode.d2.loss_dice: 1.9229  decode.d3.loss_cls: 1.3742  decode.d3.loss_mask: 0.8415  decode.d3.loss_dice: 1.8588  decode.d4.loss_cls: 1.3713  decode.d4.loss_mask: 0.8355  decode.d4.loss_dice: 1.8518  decode.d5.loss_cls: 1.3543  decode.d5.loss_mask: 0.8547  decode.d5.loss_dice: 1.8983  decode.d6.loss_cls: 1.3545  decode.d6.loss_mask: 0.8509  decode.d6.loss_dice: 1.8140  decode.d7.loss_cls: 1.3665  decode.d7.loss_mask: 0.8338  decode.d7.loss_dice: 1.8485  decode.d8.loss_cls: 1.3792  decode.d8.loss_mask: 0.8250  decode.d8.loss_dice: 1.8148
2023/05/24 05:54:28 - mmengine - INFO - Iter(train) [ 94300/160000]  lr: 4.4885e-06  eta: 7:51:45  time: 0.4214  data_time: 0.0109  memory: 4890  grad_norm: 91.2803  loss: 32.2533  decode.loss_cls: 1.0637  decode.loss_mask: 0.7354  decode.loss_dice: 1.1435  decode.d0.loss_cls: 2.9436  decode.d0.loss_mask: 0.7403  decode.d0.loss_dice: 1.3482  decode.d1.loss_cls: 1.1990  decode.d1.loss_mask: 0.7427  decode.d1.loss_dice: 1.2611  decode.d2.loss_cls: 1.1322  decode.d2.loss_mask: 0.7293  decode.d2.loss_dice: 1.1867  decode.d3.loss_cls: 1.1414  decode.d3.loss_mask: 0.7457  decode.d3.loss_dice: 1.1397  decode.d4.loss_cls: 1.1052  decode.d4.loss_mask: 0.7431  decode.d4.loss_dice: 1.1698  decode.d5.loss_cls: 1.1266  decode.d5.loss_mask: 0.7102  decode.d5.loss_dice: 1.1582  decode.d6.loss_cls: 1.1152  decode.d6.loss_mask: 0.7422  decode.d6.loss_dice: 1.1758  decode.d7.loss_cls: 1.1468  decode.d7.loss_mask: 0.7126  decode.d7.loss_dice: 1.1223  decode.d8.loss_cls: 1.0745  decode.d8.loss_mask: 0.7293  decode.d8.loss_dice: 1.1692
2023/05/24 05:54:50 - mmengine - INFO - Iter(train) [ 94350/160000]  lr: 4.4854e-06  eta: 7:51:24  time: 0.4211  data_time: 0.0104  memory: 4889  grad_norm: 86.8618  loss: 33.4584  decode.loss_cls: 0.9603  decode.loss_mask: 0.7556  decode.loss_dice: 1.3291  decode.d0.loss_cls: 3.1252  decode.d0.loss_mask: 0.7934  decode.d0.loss_dice: 1.4619  decode.d1.loss_cls: 1.1083  decode.d1.loss_mask: 0.7968  decode.d1.loss_dice: 1.4635  decode.d2.loss_cls: 1.0269  decode.d2.loss_mask: 0.8247  decode.d2.loss_dice: 1.4173  decode.d3.loss_cls: 0.9961  decode.d3.loss_mask: 0.7554  decode.d3.loss_dice: 1.3522  decode.d4.loss_cls: 0.9688  decode.d4.loss_mask: 0.7609  decode.d4.loss_dice: 1.3571  decode.d5.loss_cls: 0.9145  decode.d5.loss_mask: 0.7712  decode.d5.loss_dice: 1.3711  decode.d6.loss_cls: 0.9436  decode.d6.loss_mask: 0.7563  decode.d6.loss_dice: 1.3315  decode.d7.loss_cls: 0.9345  decode.d7.loss_mask: 0.7658  decode.d7.loss_dice: 1.3531  decode.d8.loss_cls: 0.9419  decode.d8.loss_mask: 0.7641  decode.d8.loss_dice: 1.3573
2023/05/24 05:55:12 - mmengine - INFO - Iter(train) [ 94400/160000]  lr: 4.4824e-06  eta: 7:51:02  time: 0.4239  data_time: 0.0110  memory: 4945  grad_norm: 85.4882  loss: 42.0803  decode.loss_cls: 1.2775  decode.loss_mask: 0.9201  decode.loss_dice: 1.6032  decode.d0.loss_cls: 3.5773  decode.d0.loss_mask: 1.0184  decode.d0.loss_dice: 1.9184  decode.d1.loss_cls: 1.5172  decode.d1.loss_mask: 0.9973  decode.d1.loss_dice: 1.8093  decode.d2.loss_cls: 1.3453  decode.d2.loss_mask: 0.9851  decode.d2.loss_dice: 1.6779  decode.d3.loss_cls: 1.2968  decode.d3.loss_mask: 0.9460  decode.d3.loss_dice: 1.6893  decode.d4.loss_cls: 1.3032  decode.d4.loss_mask: 0.9564  decode.d4.loss_dice: 1.6978  decode.d5.loss_cls: 1.3207  decode.d5.loss_mask: 0.9557  decode.d5.loss_dice: 1.6703  decode.d6.loss_cls: 1.3238  decode.d6.loss_mask: 0.9470  decode.d6.loss_dice: 1.6249  decode.d7.loss_cls: 1.3068  decode.d7.loss_mask: 0.9575  decode.d7.loss_dice: 1.6028  decode.d8.loss_cls: 1.3026  decode.d8.loss_mask: 0.9210  decode.d8.loss_dice: 1.6110
2023/05/24 05:55:33 - mmengine - INFO - Iter(train) [ 94450/160000]  lr: 4.4793e-06  eta: 7:50:40  time: 0.4133  data_time: 0.0105  memory: 4915  grad_norm: 85.9633  loss: 39.2405  decode.loss_cls: 1.2670  decode.loss_mask: 0.8707  decode.loss_dice: 1.4499  decode.d0.loss_cls: 3.2143  decode.d0.loss_mask: 0.9368  decode.d0.loss_dice: 1.6606  decode.d1.loss_cls: 1.3256  decode.d1.loss_mask: 1.0347  decode.d1.loss_dice: 1.5788  decode.d2.loss_cls: 1.3699  decode.d2.loss_mask: 0.9804  decode.d2.loss_dice: 1.4942  decode.d3.loss_cls: 1.3531  decode.d3.loss_mask: 0.9337  decode.d3.loss_dice: 1.4369  decode.d4.loss_cls: 1.3010  decode.d4.loss_mask: 0.9247  decode.d4.loss_dice: 1.4912  decode.d5.loss_cls: 1.2839  decode.d5.loss_mask: 0.9588  decode.d5.loss_dice: 1.4679  decode.d6.loss_cls: 1.3003  decode.d6.loss_mask: 0.9193  decode.d6.loss_dice: 1.4372  decode.d7.loss_cls: 1.2843  decode.d7.loss_mask: 0.8938  decode.d7.loss_dice: 1.4544  decode.d8.loss_cls: 1.2419  decode.d8.loss_mask: 0.9023  decode.d8.loss_dice: 1.4729
2023/05/24 05:55:54 - mmengine - INFO - Iter(train) [ 94500/160000]  lr: 4.4762e-06  eta: 7:50:18  time: 0.4192  data_time: 0.0104  memory: 4805  grad_norm: 94.7451  loss: 33.6410  decode.loss_cls: 1.2519  decode.loss_mask: 0.6758  decode.loss_dice: 1.1142  decode.d0.loss_cls: 3.4437  decode.d0.loss_mask: 0.7610  decode.d0.loss_dice: 1.4969  decode.d1.loss_cls: 1.3041  decode.d1.loss_mask: 0.7203  decode.d1.loss_dice: 1.3270  decode.d2.loss_cls: 1.2946  decode.d2.loss_mask: 0.6914  decode.d2.loss_dice: 1.2179  decode.d3.loss_cls: 1.2324  decode.d3.loss_mask: 0.6785  decode.d3.loss_dice: 1.1906  decode.d4.loss_cls: 1.2297  decode.d4.loss_mask: 0.6812  decode.d4.loss_dice: 1.1852  decode.d5.loss_cls: 1.2330  decode.d5.loss_mask: 0.6770  decode.d5.loss_dice: 1.1797  decode.d6.loss_cls: 1.2191  decode.d6.loss_mask: 0.6598  decode.d6.loss_dice: 1.1704  decode.d7.loss_cls: 1.2002  decode.d7.loss_mask: 0.6513  decode.d7.loss_dice: 1.1597  decode.d8.loss_cls: 1.2313  decode.d8.loss_mask: 0.6419  decode.d8.loss_dice: 1.1214
2023/05/24 05:56:16 - mmengine - INFO - Iter(train) [ 94550/160000]  lr: 4.4731e-06  eta: 7:49:57  time: 0.4763  data_time: 0.0102  memory: 4869  grad_norm: 120.9033  loss: 42.6686  decode.loss_cls: 1.5135  decode.loss_mask: 0.7889  decode.loss_dice: 1.6492  decode.d0.loss_cls: 3.5638  decode.d0.loss_mask: 0.7830  decode.d0.loss_dice: 1.9163  decode.d1.loss_cls: 1.7921  decode.d1.loss_mask: 0.7806  decode.d1.loss_dice: 1.7127  decode.d2.loss_cls: 1.6621  decode.d2.loss_mask: 0.8213  decode.d2.loss_dice: 1.6834  decode.d3.loss_cls: 1.5484  decode.d3.loss_mask: 0.8208  decode.d3.loss_dice: 1.6176  decode.d4.loss_cls: 1.5665  decode.d4.loss_mask: 0.8058  decode.d4.loss_dice: 1.6563  decode.d5.loss_cls: 1.5820  decode.d5.loss_mask: 0.7579  decode.d5.loss_dice: 1.6641  decode.d6.loss_cls: 1.5418  decode.d6.loss_mask: 0.7846  decode.d6.loss_dice: 1.6683  decode.d7.loss_cls: 1.5215  decode.d7.loss_mask: 0.8055  decode.d7.loss_dice: 1.6312  decode.d8.loss_cls: 1.5501  decode.d8.loss_mask: 0.8013  decode.d8.loss_dice: 1.6779
2023/05/24 05:56:37 - mmengine - INFO - Iter(train) [ 94600/160000]  lr: 4.4701e-06  eta: 7:49:35  time: 0.4173  data_time: 0.0103  memory: 4907  grad_norm: 133.5452  loss: 38.9538  decode.loss_cls: 1.2715  decode.loss_mask: 0.9713  decode.loss_dice: 1.3776  decode.d0.loss_cls: 3.1410  decode.d0.loss_mask: 0.9757  decode.d0.loss_dice: 1.5524  decode.d1.loss_cls: 1.2986  decode.d1.loss_mask: 1.0229  decode.d1.loss_dice: 1.4490  decode.d2.loss_cls: 1.3722  decode.d2.loss_mask: 0.9685  decode.d2.loss_dice: 1.4111  decode.d3.loss_cls: 1.3978  decode.d3.loss_mask: 0.9770  decode.d3.loss_dice: 1.4034  decode.d4.loss_cls: 1.3120  decode.d4.loss_mask: 1.0138  decode.d4.loss_dice: 1.3857  decode.d5.loss_cls: 1.3635  decode.d5.loss_mask: 1.0045  decode.d5.loss_dice: 1.3493  decode.d6.loss_cls: 1.3183  decode.d6.loss_mask: 0.9628  decode.d6.loss_dice: 1.3686  decode.d7.loss_cls: 1.2981  decode.d7.loss_mask: 0.9913  decode.d7.loss_dice: 1.3508  decode.d8.loss_cls: 1.2607  decode.d8.loss_mask: 1.0136  decode.d8.loss_dice: 1.3707
2023/05/24 05:56:58 - mmengine - INFO - Iter(train) [ 94650/160000]  lr: 4.4670e-06  eta: 7:49:14  time: 0.4345  data_time: 0.0109  memory: 4835  grad_norm: 84.5848  loss: 43.2431  decode.loss_cls: 1.2242  decode.loss_mask: 1.0334  decode.loss_dice: 1.6989  decode.d0.loss_cls: 3.4738  decode.d0.loss_mask: 1.0798  decode.d0.loss_dice: 2.0088  decode.d1.loss_cls: 1.5094  decode.d1.loss_mask: 1.0022  decode.d1.loss_dice: 1.8086  decode.d2.loss_cls: 1.4432  decode.d2.loss_mask: 1.0078  decode.d2.loss_dice: 1.7451  decode.d3.loss_cls: 1.4011  decode.d3.loss_mask: 1.0361  decode.d3.loss_dice: 1.7058  decode.d4.loss_cls: 1.3747  decode.d4.loss_mask: 1.0439  decode.d4.loss_dice: 1.7152  decode.d5.loss_cls: 1.2954  decode.d5.loss_mask: 1.0239  decode.d5.loss_dice: 1.7045  decode.d6.loss_cls: 1.2600  decode.d6.loss_mask: 1.0257  decode.d6.loss_dice: 1.6975  decode.d7.loss_cls: 1.2687  decode.d7.loss_mask: 0.9851  decode.d7.loss_dice: 1.7037  decode.d8.loss_cls: 1.2615  decode.d8.loss_mask: 1.0188  decode.d8.loss_dice: 1.6863
2023/05/24 05:57:20 - mmengine - INFO - Iter(train) [ 94700/160000]  lr: 4.4639e-06  eta: 7:48:52  time: 0.4296  data_time: 0.0104  memory: 4846  grad_norm: 89.3247  loss: 39.3067  decode.loss_cls: 1.3590  decode.loss_mask: 0.8731  decode.loss_dice: 1.4677  decode.d0.loss_cls: 3.1195  decode.d0.loss_mask: 0.9314  decode.d0.loss_dice: 1.6858  decode.d1.loss_cls: 1.4494  decode.d1.loss_mask: 0.8974  decode.d1.loss_dice: 1.5682  decode.d2.loss_cls: 1.3431  decode.d2.loss_mask: 0.9015  decode.d2.loss_dice: 1.5729  decode.d3.loss_cls: 1.2883  decode.d3.loss_mask: 0.8838  decode.d3.loss_dice: 1.5353  decode.d4.loss_cls: 1.2703  decode.d4.loss_mask: 0.9118  decode.d4.loss_dice: 1.5343  decode.d5.loss_cls: 1.2616  decode.d5.loss_mask: 0.9092  decode.d5.loss_dice: 1.5051  decode.d6.loss_cls: 1.3689  decode.d6.loss_mask: 0.8596  decode.d6.loss_dice: 1.4447  decode.d7.loss_cls: 1.2718  decode.d7.loss_mask: 0.8687  decode.d7.loss_dice: 1.5110  decode.d8.loss_cls: 1.3400  decode.d8.loss_mask: 0.8836  decode.d8.loss_dice: 1.4895
2023/05/24 05:57:42 - mmengine - INFO - Iter(train) [ 94750/160000]  lr: 4.4608e-06  eta: 7:48:31  time: 0.4203  data_time: 0.0103  memory: 4828  grad_norm: 120.7908  loss: 32.6321  decode.loss_cls: 1.2710  decode.loss_mask: 0.7113  decode.loss_dice: 1.0241  decode.d0.loss_cls: 3.1129  decode.d0.loss_mask: 0.8189  decode.d0.loss_dice: 1.2183  decode.d1.loss_cls: 1.4011  decode.d1.loss_mask: 0.7971  decode.d1.loss_dice: 1.1566  decode.d2.loss_cls: 1.2836  decode.d2.loss_mask: 0.7398  decode.d2.loss_dice: 1.0813  decode.d3.loss_cls: 1.2487  decode.d3.loss_mask: 0.7496  decode.d3.loss_dice: 1.0595  decode.d4.loss_cls: 1.2251  decode.d4.loss_mask: 0.7609  decode.d4.loss_dice: 1.0778  decode.d5.loss_cls: 1.2192  decode.d5.loss_mask: 0.7527  decode.d5.loss_dice: 1.0698  decode.d6.loss_cls: 1.2085  decode.d6.loss_mask: 0.7223  decode.d6.loss_dice: 1.0346  decode.d7.loss_cls: 1.1808  decode.d7.loss_mask: 0.7157  decode.d7.loss_dice: 1.0520  decode.d8.loss_cls: 1.1876  decode.d8.loss_mask: 0.7185  decode.d8.loss_dice: 1.0326
2023/05/24 05:58:03 - mmengine - INFO - Iter(train) [ 94800/160000]  lr: 4.4578e-06  eta: 7:48:09  time: 0.4240  data_time: 0.0104  memory: 4821  grad_norm: 94.6538  loss: 39.8843  decode.loss_cls: 1.3709  decode.loss_mask: 0.7982  decode.loss_dice: 1.4950  decode.d0.loss_cls: 3.2703  decode.d0.loss_mask: 0.9082  decode.d0.loss_dice: 1.7493  decode.d1.loss_cls: 1.5244  decode.d1.loss_mask: 0.8693  decode.d1.loss_dice: 1.6463  decode.d2.loss_cls: 1.5459  decode.d2.loss_mask: 0.8025  decode.d2.loss_dice: 1.5265  decode.d3.loss_cls: 1.4252  decode.d3.loss_mask: 0.8178  decode.d3.loss_dice: 1.5512  decode.d4.loss_cls: 1.4367  decode.d4.loss_mask: 0.8181  decode.d4.loss_dice: 1.5077  decode.d5.loss_cls: 1.4193  decode.d5.loss_mask: 0.7944  decode.d5.loss_dice: 1.4750  decode.d6.loss_cls: 1.4200  decode.d6.loss_mask: 0.7907  decode.d6.loss_dice: 1.4699  decode.d7.loss_cls: 1.4182  decode.d7.loss_mask: 0.7909  decode.d7.loss_dice: 1.5141  decode.d8.loss_cls: 1.4213  decode.d8.loss_mask: 0.8015  decode.d8.loss_dice: 1.5053
2023/05/24 05:58:25 - mmengine - INFO - Iter(train) [ 94850/160000]  lr: 4.4547e-06  eta: 7:47:47  time: 0.4158  data_time: 0.0106  memory: 4960  grad_norm: 109.8548  loss: 34.4127  decode.loss_cls: 1.1579  decode.loss_mask: 0.7660  decode.loss_dice: 1.2115  decode.d0.loss_cls: 2.9710  decode.d0.loss_mask: 0.8074  decode.d0.loss_dice: 1.4403  decode.d1.loss_cls: 1.4383  decode.d1.loss_mask: 0.7711  decode.d1.loss_dice: 1.3067  decode.d2.loss_cls: 1.2686  decode.d2.loss_mask: 0.7569  decode.d2.loss_dice: 1.2613  decode.d3.loss_cls: 1.1641  decode.d3.loss_mask: 0.8205  decode.d3.loss_dice: 1.2716  decode.d4.loss_cls: 1.2084  decode.d4.loss_mask: 0.7785  decode.d4.loss_dice: 1.2468  decode.d5.loss_cls: 1.2076  decode.d5.loss_mask: 0.7834  decode.d5.loss_dice: 1.2309  decode.d6.loss_cls: 1.1699  decode.d6.loss_mask: 0.7662  decode.d6.loss_dice: 1.2132  decode.d7.loss_cls: 1.2430  decode.d7.loss_mask: 0.7675  decode.d7.loss_dice: 1.2285  decode.d8.loss_cls: 1.1760  decode.d8.loss_mask: 0.7623  decode.d8.loss_dice: 1.2174
2023/05/24 05:58:45 - mmengine - INFO - Iter(train) [ 94900/160000]  lr: 4.4516e-06  eta: 7:47:25  time: 0.4347  data_time: 0.0104  memory: 4821  grad_norm: 99.7013  loss: 29.2246  decode.loss_cls: 0.9958  decode.loss_mask: 0.7341  decode.loss_dice: 0.9789  decode.d0.loss_cls: 2.8727  decode.d0.loss_mask: 0.7472  decode.d0.loss_dice: 1.0267  decode.d1.loss_cls: 1.0450  decode.d1.loss_mask: 0.8044  decode.d1.loss_dice: 1.0407  decode.d2.loss_cls: 1.0106  decode.d2.loss_mask: 0.7523  decode.d2.loss_dice: 1.0118  decode.d3.loss_cls: 0.9954  decode.d3.loss_mask: 0.7632  decode.d3.loss_dice: 0.9996  decode.d4.loss_cls: 0.9460  decode.d4.loss_mask: 0.7526  decode.d4.loss_dice: 0.9835  decode.d5.loss_cls: 1.0025  decode.d5.loss_mask: 0.7248  decode.d5.loss_dice: 0.9699  decode.d6.loss_cls: 0.9845  decode.d6.loss_mask: 0.7266  decode.d6.loss_dice: 0.9799  decode.d7.loss_cls: 0.9893  decode.d7.loss_mask: 0.7211  decode.d7.loss_dice: 0.9665  decode.d8.loss_cls: 0.9784  decode.d8.loss_mask: 0.7226  decode.d8.loss_dice: 0.9982
2023/05/24 05:59:07 - mmengine - INFO - Iter(train) [ 94950/160000]  lr: 4.4485e-06  eta: 7:47:04  time: 0.4236  data_time: 0.0108  memory: 4895  grad_norm: 100.6129  loss: 35.6146  decode.loss_cls: 1.1775  decode.loss_mask: 0.7557  decode.loss_dice: 1.3552  decode.d0.loss_cls: 2.9840  decode.d0.loss_mask: 0.8690  decode.d0.loss_dice: 1.5373  decode.d1.loss_cls: 1.2714  decode.d1.loss_mask: 0.8087  decode.d1.loss_dice: 1.4209  decode.d2.loss_cls: 1.3179  decode.d2.loss_mask: 0.8029  decode.d2.loss_dice: 1.3854  decode.d3.loss_cls: 1.2682  decode.d3.loss_mask: 0.7394  decode.d3.loss_dice: 1.3495  decode.d4.loss_cls: 1.2228  decode.d4.loss_mask: 0.7532  decode.d4.loss_dice: 1.3606  decode.d5.loss_cls: 1.1890  decode.d5.loss_mask: 0.7912  decode.d5.loss_dice: 1.3885  decode.d6.loss_cls: 1.2185  decode.d6.loss_mask: 0.7463  decode.d6.loss_dice: 1.3211  decode.d7.loss_cls: 1.2396  decode.d7.loss_mask: 0.7274  decode.d7.loss_dice: 1.3295  decode.d8.loss_cls: 1.1911  decode.d8.loss_mask: 0.7530  decode.d8.loss_dice: 1.3399
2023/05/24 05:59:28 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 05:59:28 - mmengine - INFO - Iter(train) [ 95000/160000]  lr: 4.4455e-06  eta: 7:46:42  time: 0.4307  data_time: 0.0104  memory: 4829  grad_norm: 108.3462  loss: 36.8708  decode.loss_cls: 1.2430  decode.loss_mask: 0.8699  decode.loss_dice: 1.2769  decode.d0.loss_cls: 2.8818  decode.d0.loss_mask: 0.9832  decode.d0.loss_dice: 1.5708  decode.d1.loss_cls: 1.2297  decode.d1.loss_mask: 0.9590  decode.d1.loss_dice: 1.4485  decode.d2.loss_cls: 1.3499  decode.d2.loss_mask: 0.8997  decode.d2.loss_dice: 1.3420  decode.d3.loss_cls: 1.3375  decode.d3.loss_mask: 0.8941  decode.d3.loss_dice: 1.2842  decode.d4.loss_cls: 1.3071  decode.d4.loss_mask: 0.9081  decode.d4.loss_dice: 1.3073  decode.d5.loss_cls: 1.3987  decode.d5.loss_mask: 0.8627  decode.d5.loss_dice: 1.2956  decode.d6.loss_cls: 1.2696  decode.d6.loss_mask: 0.9013  decode.d6.loss_dice: 1.2646  decode.d7.loss_cls: 1.2482  decode.d7.loss_mask: 0.8981  decode.d7.loss_dice: 1.2522  decode.d8.loss_cls: 1.2327  decode.d8.loss_mask: 0.8791  decode.d8.loss_dice: 1.2753
2023/05/24 05:59:28 - mmengine - INFO - Saving checkpoint at 95000 iterations
2023/05/24 05:59:40 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:01:11  time: 0.0901  data_time: 0.0019  memory: 2167  
2023/05/24 05:59:45 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:54  time: 0.0878  data_time: 0.0019  memory: 2216  
2023/05/24 05:59:49 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:46  time: 0.0791  data_time: 0.0018  memory: 2167  
2023/05/24 05:59:53 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:39  time: 0.0827  data_time: 0.0023  memory: 2104  
2023/05/24 05:59:57 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:34  time: 0.0841  data_time: 0.0019  memory: 2831  
2023/05/24 06:00:01 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0785  data_time: 0.0017  memory: 2167  
2023/05/24 06:00:05 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0795  data_time: 0.0016  memory: 2167  
2023/05/24 06:00:09 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0799  data_time: 0.0017  memory: 2167  
2023/05/24 06:00:13 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0789  data_time: 0.0017  memory: 2944  
2023/05/24 06:00:17 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0916  data_time: 0.0020  memory: 2356  
2023/05/24 06:00:22 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0790  data_time: 0.0018  memory: 2217  
2023/05/24 06:00:26 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0776  data_time: 0.0017  memory: 2328  
2023/05/24 06:00:30 - mmengine - INFO - per class results:
2023/05/24 06:00:30 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.98 | 92.77 |
|     bicycle      |  69.0 | 83.75 |
|       car        | 60.35 | 85.88 |
|    motorcycle    | 83.13 | 89.43 |
|     airplane     | 83.68 | 91.73 |
|       bus        | 80.32 | 87.61 |
|      train       | 81.63 | 93.01 |
|      truck       | 54.07 | 67.59 |
|       boat       |  58.8 | 77.89 |
|  traffic light   | 65.96 | 82.73 |
|   fire hydrant   | 84.96 | 94.43 |
|    stop sign     | 89.99 | 96.85 |
|  parking meter   | 75.79 | 81.08 |
|      bench       | 45.83 | 73.06 |
|       bird       | 81.44 | 89.91 |
|       cat        |  86.5 |  92.9 |
|       dog        | 80.31 | 88.16 |
|      horse       | 77.85 | 89.62 |
|      sheep       | 87.36 | 94.81 |
|       cow        | 82.74 | 87.63 |
|     elephant     | 89.75 | 94.93 |
|       bear       | 92.46 | 94.96 |
|      zebra       | 90.09 | 92.81 |
|     giraffe      | 86.98 |  92.5 |
|     backpack     | 30.47 |  66.4 |
|     umbrella     | 80.65 | 88.12 |
|     handbag      | 34.39 | 52.87 |
|       tie        |  7.43 | 25.21 |
|     suitcase     |  78.0 | 91.35 |
|     frisbee      | 77.21 | 89.64 |
|       skis       | 45.14 | 61.42 |
|    snowboard     | 55.82 |  67.0 |
|   sports ball    | 50.16 | 74.11 |
|       kite       | 59.45 | 71.56 |
|   baseball bat   | 52.53 | 65.38 |
|  baseball glove  |  71.5 | 84.95 |
|    skateboard    | 75.47 | 83.69 |
|    surfboard     | 73.79 | 87.22 |
|  tennis racket   | 83.85 |  90.1 |
|      bottle      | 48.85 | 68.27 |
|    wine glass    | 57.19 | 75.79 |
|       cup        | 56.67 | 79.32 |
|       fork       | 40.63 | 51.88 |
|      knife       | 31.13 | 40.59 |
|      spoon       |  31.5 | 47.24 |
|       bowl       | 48.28 | 67.24 |
|      banana      | 67.87 | 89.27 |
|      apple       | 49.45 | 72.78 |
|     sandwich     | 45.73 | 65.45 |
|      orange      | 62.53 | 67.92 |
|     broccoli     | 59.82 | 75.35 |
|      carrot      | 50.16 | 57.61 |
|     hot dog      | 47.27 | 55.73 |
|      pizza       | 71.13 | 87.51 |
|      donut       | 67.29 | 81.97 |
|       cake       | 56.76 | 74.68 |
|      chair       | 44.79 | 64.58 |
|      couch       | 52.71 | 74.53 |
|   potted plant   |  30.8 | 39.51 |
|       bed        | 63.49 | 78.52 |
|   dining table   | 43.95 |  74.6 |
|      toilet      | 80.52 | 92.69 |
|        tv        | 72.29 | 83.46 |
|      laptop      | 72.32 | 88.01 |
|      mouse       | 74.09 | 88.54 |
|      remote      | 61.11 | 73.02 |
|     keyboard     | 61.84 | 82.58 |
|    cell phone    | 69.73 | 85.94 |
|    microwave     | 63.83 | 75.86 |
|       oven       |  55.9 | 84.68 |
|     toaster      |  42.4 | 54.26 |
|       sink       | 56.88 |  78.8 |
|   refrigerator   |  76.8 | 90.31 |
|       book       | 48.89 | 64.86 |
|      clock       |  72.8 | 82.78 |
|       vase       | 56.09 | 83.77 |
|     scissors     | 79.35 | 91.35 |
|    teddy bear    | 73.58 | 84.01 |
|    hair drier    | 46.68 | 50.02 |
|    toothbrush    | 42.94 | 67.08 |
|      banner      |  26.1 |  40.5 |
|     blanket      |  5.94 |  7.16 |
|      branch      | 17.15 | 20.79 |
|      bridge      | 30.68 | 55.12 |
|  building-other  |  51.0 | 70.97 |
|       bush       | 28.08 | 36.82 |
|     cabinet      | 54.12 | 69.12 |
|       cage       | 16.95 | 24.28 |
|    cardboard     | 44.23 | 59.73 |
|      carpet      | 52.61 | 72.33 |
|  ceiling-other   | 62.55 | 76.03 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 20.11 | 30.19 |
|      clouds      | 50.31 | 71.09 |
|     counter      | 26.46 | 45.11 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 65.55 | 78.13 |
|    desk-stuff    | 46.17 | 63.34 |
|       dirt       | 40.58 | 57.71 |
|    door-stuff    |  37.4 | 56.97 |
|      fence       |  29.8 |  54.8 |
|   floor-marble   |  8.49 | 10.36 |
|   floor-other    | 17.65 | 22.33 |
|   floor-stone    |  5.35 |  6.66 |
|    floor-tile    | 58.94 | 71.55 |
|    floor-wood    | 61.27 | 78.16 |
|      flower      | 47.96 | 79.84 |
|       fog        |  5.18 |  5.31 |
|    food-other    |  30.2 | 39.32 |
|      fruit       | 35.55 | 46.35 |
| furniture-other  | 17.14 | 25.32 |
|      grass       | 69.03 | 81.91 |
|      gravel      | 25.59 | 32.25 |
|   ground-other   |  0.83 |  0.9  |
|       hill       | 22.19 | 36.13 |
|      house       | 25.33 | 32.68 |
|      leaves      | 26.49 | 35.92 |
|      light       | 36.61 | 51.99 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.83 | 45.36 |
|   mirror-stuff   | 45.56 | 60.51 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 51.46 | 68.45 |
|       mud        |  0.0  |  0.0  |
|      napkin      | 11.68 | 12.26 |
|       net        | 43.35 | 60.61 |
|      paper       | 28.75 | 39.16 |
|     pavement     | 51.78 | 73.86 |
|      pillow      | 12.43 | 15.84 |
|   plant-other    | 17.34 |  24.5 |
|     plastic      |  17.1 | 21.18 |
|     platform     | 27.38 | 39.14 |
|   playingfield   | 69.47 | 89.68 |
|     railing      |  7.13 | 11.73 |
|     railroad     | 60.57 | 81.83 |
|      river       | 43.77 | 59.19 |
|       road       |  66.1 | 81.47 |
|       rock       | 32.45 |  44.2 |
|       roof       | 18.36 | 23.93 |
|       rug        | 36.21 | 52.67 |
|      salad       |  0.0  |  0.0  |
|       sand       | 61.11 | 73.05 |
|       sea        | 86.04 | 92.84 |
|      shelf       | 33.22 |  46.2 |
|    sky-other     | 70.26 | 83.86 |
|    skyscraper    | 33.95 | 50.76 |
|       snow       | 88.89 | 93.69 |
|   solid-other    |  0.01 |  0.01 |
|      stairs      | 25.76 | 43.02 |
|      stone       |  15.1 | 34.25 |
|      straw       | 30.65 |  58.2 |
| structural-other |  0.23 |  0.24 |
|      table       | 19.95 | 28.04 |
|       tent       |  8.93 | 13.57 |
|  textile-other   |  9.94 | 15.88 |
|      towel       | 32.14 | 39.12 |
|       tree       | 72.58 | 87.93 |
|    vegetable     | 37.46 | 49.99 |
|    wall-brick    | 50.97 | 62.85 |
|  wall-concrete   | 59.24 |  82.1 |
|    wall-other    | 16.63 | 25.88 |
|    wall-panel    |  6.48 |  8.75 |
|    wall-stone    | 33.67 | 41.66 |
|    wall-tile     | 63.97 | 84.83 |
|    wall-wood     | 39.56 |  59.9 |
|   water-other    | 19.65 | 32.07 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 50.11 | 58.71 |
|   window-other   | 46.13 | 66.47 |
|       wood       | 23.95 | 36.94 |
+------------------+-------+-------+
2023/05/24 06:00:30 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.8900  mIoU: 46.7600  mAcc: 59.2500  data_time: 0.0020  time: 0.0855
2023/05/24 06:00:30 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_90000.pth is removed
2023/05/24 06:00:33 - mmengine - INFO - The best checkpoint with 46.7600 mIoU at 95000 iter is saved to best_mIoU_iter_95000.pth.
2023/05/24 06:00:54 - mmengine - INFO - Iter(train) [ 95050/160000]  lr: 4.4424e-06  eta: 7:46:24  time: 0.4187  data_time: 0.0105  memory: 4858  grad_norm: 94.9056  loss: 41.4181  decode.loss_cls: 1.3400  decode.loss_mask: 1.0017  decode.loss_dice: 1.5199  decode.d0.loss_cls: 3.2315  decode.d0.loss_mask: 1.0548  decode.d0.loss_dice: 1.7638  decode.d1.loss_cls: 1.4522  decode.d1.loss_mask: 0.9997  decode.d1.loss_dice: 1.6047  decode.d2.loss_cls: 1.3137  decode.d2.loss_mask: 1.0155  decode.d2.loss_dice: 1.6168  decode.d3.loss_cls: 1.3964  decode.d3.loss_mask: 1.0474  decode.d3.loss_dice: 1.5732  decode.d4.loss_cls: 1.3856  decode.d4.loss_mask: 1.0140  decode.d4.loss_dice: 1.5543  decode.d5.loss_cls: 1.3682  decode.d5.loss_mask: 0.9828  decode.d5.loss_dice: 1.5370  decode.d6.loss_cls: 1.3280  decode.d6.loss_mask: 0.9780  decode.d6.loss_dice: 1.5177  decode.d7.loss_cls: 1.3627  decode.d7.loss_mask: 1.0047  decode.d7.loss_dice: 1.5667  decode.d8.loss_cls: 1.3465  decode.d8.loss_mask: 1.0262  decode.d8.loss_dice: 1.5145
2023/05/24 06:01:15 - mmengine - INFO - Iter(train) [ 95100/160000]  lr: 4.4393e-06  eta: 7:46:02  time: 0.4174  data_time: 0.0105  memory: 4829  grad_norm: 83.0327  loss: 31.6722  decode.loss_cls: 1.0321  decode.loss_mask: 0.6378  decode.loss_dice: 1.2496  decode.d0.loss_cls: 3.0042  decode.d0.loss_mask: 0.6812  decode.d0.loss_dice: 1.4344  decode.d1.loss_cls: 1.1943  decode.d1.loss_mask: 0.6644  decode.d1.loss_dice: 1.3563  decode.d2.loss_cls: 1.0367  decode.d2.loss_mask: 0.6831  decode.d2.loss_dice: 1.3168  decode.d3.loss_cls: 1.0028  decode.d3.loss_mask: 0.6427  decode.d3.loss_dice: 1.2592  decode.d4.loss_cls: 0.9642  decode.d4.loss_mask: 0.6328  decode.d4.loss_dice: 1.2874  decode.d5.loss_cls: 1.0471  decode.d5.loss_mask: 0.6338  decode.d5.loss_dice: 1.2063  decode.d6.loss_cls: 1.0342  decode.d6.loss_mask: 0.6383  decode.d6.loss_dice: 1.2480  decode.d7.loss_cls: 0.9983  decode.d7.loss_mask: 0.6366  decode.d7.loss_dice: 1.2450  decode.d8.loss_cls: 1.0422  decode.d8.loss_mask: 0.6411  decode.d8.loss_dice: 1.2213
2023/05/24 06:01:36 - mmengine - INFO - Iter(train) [ 95150/160000]  lr: 4.4362e-06  eta: 7:45:40  time: 0.4149  data_time: 0.0105  memory: 4826  grad_norm: 82.9500  loss: 33.0421  decode.loss_cls: 1.3050  decode.loss_mask: 0.6880  decode.loss_dice: 1.0507  decode.d0.loss_cls: 3.1724  decode.d0.loss_mask: 0.7897  decode.d0.loss_dice: 1.2449  decode.d1.loss_cls: 1.4206  decode.d1.loss_mask: 0.7172  decode.d1.loss_dice: 1.1479  decode.d2.loss_cls: 1.4128  decode.d2.loss_mask: 0.6672  decode.d2.loss_dice: 1.0445  decode.d3.loss_cls: 1.3244  decode.d3.loss_mask: 0.6965  decode.d3.loss_dice: 1.0537  decode.d4.loss_cls: 1.3197  decode.d4.loss_mask: 0.6846  decode.d4.loss_dice: 1.0170  decode.d5.loss_cls: 1.3631  decode.d5.loss_mask: 0.6713  decode.d5.loss_dice: 0.9987  decode.d6.loss_cls: 1.3662  decode.d6.loss_mask: 0.6780  decode.d6.loss_dice: 1.0530  decode.d7.loss_cls: 1.3894  decode.d7.loss_mask: 0.6797  decode.d7.loss_dice: 1.0271  decode.d8.loss_cls: 1.2889  decode.d8.loss_mask: 0.6873  decode.d8.loss_dice: 1.0822
2023/05/24 06:01:57 - mmengine - INFO - Iter(train) [ 95200/160000]  lr: 4.4331e-06  eta: 7:45:18  time: 0.4285  data_time: 0.0105  memory: 4820  grad_norm: 102.5931  loss: 31.8707  decode.loss_cls: 0.9679  decode.loss_mask: 0.8026  decode.loss_dice: 1.0753  decode.d0.loss_cls: 3.0430  decode.d0.loss_mask: 0.9435  decode.d0.loss_dice: 1.3795  decode.d1.loss_cls: 1.1130  decode.d1.loss_mask: 0.8422  decode.d1.loss_dice: 1.2067  decode.d2.loss_cls: 1.0666  decode.d2.loss_mask: 0.8196  decode.d2.loss_dice: 1.2031  decode.d3.loss_cls: 0.9859  decode.d3.loss_mask: 0.8261  decode.d3.loss_dice: 1.1176  decode.d4.loss_cls: 0.9797  decode.d4.loss_mask: 0.8231  decode.d4.loss_dice: 1.1160  decode.d5.loss_cls: 0.9759  decode.d5.loss_mask: 0.8248  decode.d5.loss_dice: 1.1100  decode.d6.loss_cls: 0.9515  decode.d6.loss_mask: 0.8185  decode.d6.loss_dice: 1.1105  decode.d7.loss_cls: 0.9615  decode.d7.loss_mask: 0.8116  decode.d7.loss_dice: 1.0931  decode.d8.loss_cls: 0.9602  decode.d8.loss_mask: 0.8111  decode.d8.loss_dice: 1.1307
2023/05/24 06:02:19 - mmengine - INFO - Iter(train) [ 95250/160000]  lr: 4.4301e-06  eta: 7:44:57  time: 0.4221  data_time: 0.0104  memory: 4821  grad_norm: 95.0663  loss: 23.3379  decode.loss_cls: 0.7573  decode.loss_mask: 0.6295  decode.loss_dice: 0.6939  decode.d0.loss_cls: 2.4137  decode.d0.loss_mask: 0.6804  decode.d0.loss_dice: 0.8161  decode.d1.loss_cls: 0.8879  decode.d1.loss_mask: 0.6661  decode.d1.loss_dice: 0.7589  decode.d2.loss_cls: 0.8167  decode.d2.loss_mask: 0.6242  decode.d2.loss_dice: 0.7069  decode.d3.loss_cls: 0.7927  decode.d3.loss_mask: 0.6716  decode.d3.loss_dice: 0.7445  decode.d4.loss_cls: 0.7921  decode.d4.loss_mask: 0.6580  decode.d4.loss_dice: 0.7413  decode.d5.loss_cls: 0.7670  decode.d5.loss_mask: 0.6524  decode.d5.loss_dice: 0.7122  decode.d6.loss_cls: 0.8148  decode.d6.loss_mask: 0.6252  decode.d6.loss_dice: 0.7040  decode.d7.loss_cls: 0.7381  decode.d7.loss_mask: 0.6540  decode.d7.loss_dice: 0.7152  decode.d8.loss_cls: 0.7786  decode.d8.loss_mask: 0.6254  decode.d8.loss_dice: 0.6992
2023/05/24 06:02:40 - mmengine - INFO - Iter(train) [ 95300/160000]  lr: 4.4270e-06  eta: 7:44:35  time: 0.4203  data_time: 0.0111  memory: 4835  grad_norm: 97.6732  loss: 40.3212  decode.loss_cls: 1.4715  decode.loss_mask: 0.7891  decode.loss_dice: 1.5136  decode.d0.loss_cls: 3.3188  decode.d0.loss_mask: 0.8253  decode.d0.loss_dice: 1.6444  decode.d1.loss_cls: 1.5846  decode.d1.loss_mask: 0.8069  decode.d1.loss_dice: 1.5613  decode.d2.loss_cls: 1.6258  decode.d2.loss_mask: 0.8216  decode.d2.loss_dice: 1.5504  decode.d3.loss_cls: 1.5310  decode.d3.loss_mask: 0.8002  decode.d3.loss_dice: 1.4879  decode.d4.loss_cls: 1.4921  decode.d4.loss_mask: 0.7913  decode.d4.loss_dice: 1.4971  decode.d5.loss_cls: 1.4700  decode.d5.loss_mask: 0.7851  decode.d5.loss_dice: 1.5353  decode.d6.loss_cls: 1.4615  decode.d6.loss_mask: 0.8099  decode.d6.loss_dice: 1.5241  decode.d7.loss_cls: 1.5366  decode.d7.loss_mask: 0.8002  decode.d7.loss_dice: 1.4918  decode.d8.loss_cls: 1.4520  decode.d8.loss_mask: 0.8038  decode.d8.loss_dice: 1.5378
2023/05/24 06:03:01 - mmengine - INFO - Iter(train) [ 95350/160000]  lr: 4.4239e-06  eta: 7:44:13  time: 0.4173  data_time: 0.0110  memory: 4822  grad_norm: 75.4086  loss: 27.9964  decode.loss_cls: 0.9565  decode.loss_mask: 0.6118  decode.loss_dice: 1.0068  decode.d0.loss_cls: 2.8308  decode.d0.loss_mask: 0.6349  decode.d0.loss_dice: 1.0796  decode.d1.loss_cls: 1.0261  decode.d1.loss_mask: 0.6352  decode.d1.loss_dice: 1.1117  decode.d2.loss_cls: 1.0177  decode.d2.loss_mask: 0.6202  decode.d2.loss_dice: 1.0323  decode.d3.loss_cls: 0.9656  decode.d3.loss_mask: 0.6331  decode.d3.loss_dice: 1.0506  decode.d4.loss_cls: 0.9409  decode.d4.loss_mask: 0.5990  decode.d4.loss_dice: 0.9742  decode.d5.loss_cls: 0.9243  decode.d5.loss_mask: 0.6015  decode.d5.loss_dice: 0.9741  decode.d6.loss_cls: 0.9781  decode.d6.loss_mask: 0.6134  decode.d6.loss_dice: 1.0315  decode.d7.loss_cls: 0.9330  decode.d7.loss_mask: 0.5977  decode.d7.loss_dice: 1.0206  decode.d8.loss_cls: 0.9629  decode.d8.loss_mask: 0.6089  decode.d8.loss_dice: 1.0232
2023/05/24 06:03:24 - mmengine - INFO - Iter(train) [ 95400/160000]  lr: 4.4208e-06  eta: 7:43:52  time: 0.4746  data_time: 0.0104  memory: 4806  grad_norm: 97.2855  loss: 38.2319  decode.loss_cls: 1.2546  decode.loss_mask: 0.8054  decode.loss_dice: 1.3829  decode.d0.loss_cls: 3.3140  decode.d0.loss_mask: 0.9234  decode.d0.loss_dice: 1.7057  decode.d1.loss_cls: 1.5096  decode.d1.loss_mask: 0.9115  decode.d1.loss_dice: 1.5573  decode.d2.loss_cls: 1.4626  decode.d2.loss_mask: 0.8591  decode.d2.loss_dice: 1.4692  decode.d3.loss_cls: 1.3976  decode.d3.loss_mask: 0.7890  decode.d3.loss_dice: 1.3877  decode.d4.loss_cls: 1.3291  decode.d4.loss_mask: 0.7999  decode.d4.loss_dice: 1.4135  decode.d5.loss_cls: 1.3251  decode.d5.loss_mask: 0.8100  decode.d5.loss_dice: 1.4143  decode.d6.loss_cls: 1.3198  decode.d6.loss_mask: 0.7872  decode.d6.loss_dice: 1.3736  decode.d7.loss_cls: 1.3300  decode.d7.loss_mask: 0.7899  decode.d7.loss_dice: 1.3857  decode.d8.loss_cls: 1.2339  decode.d8.loss_mask: 0.8102  decode.d8.loss_dice: 1.3800
2023/05/24 06:03:45 - mmengine - INFO - Iter(train) [ 95450/160000]  lr: 4.4177e-06  eta: 7:43:30  time: 0.4236  data_time: 0.0103  memory: 4804  grad_norm: 104.3807  loss: 33.0280  decode.loss_cls: 1.0365  decode.loss_mask: 0.8522  decode.loss_dice: 1.1377  decode.d0.loss_cls: 3.1388  decode.d0.loss_mask: 0.9258  decode.d0.loss_dice: 1.3499  decode.d1.loss_cls: 1.1489  decode.d1.loss_mask: 0.8804  decode.d1.loss_dice: 1.2584  decode.d2.loss_cls: 1.0364  decode.d2.loss_mask: 0.8530  decode.d2.loss_dice: 1.2331  decode.d3.loss_cls: 1.0441  decode.d3.loss_mask: 0.8337  decode.d3.loss_dice: 1.1740  decode.d4.loss_cls: 0.9807  decode.d4.loss_mask: 0.8804  decode.d4.loss_dice: 1.1791  decode.d5.loss_cls: 0.9831  decode.d5.loss_mask: 0.8588  decode.d5.loss_dice: 1.1872  decode.d6.loss_cls: 0.9857  decode.d6.loss_mask: 0.8422  decode.d6.loss_dice: 1.1636  decode.d7.loss_cls: 1.0342  decode.d7.loss_mask: 0.8440  decode.d7.loss_dice: 1.1406  decode.d8.loss_cls: 0.9837  decode.d8.loss_mask: 0.8717  decode.d8.loss_dice: 1.1900
2023/05/24 06:04:07 - mmengine - INFO - Iter(train) [ 95500/160000]  lr: 4.4147e-06  eta: 7:43:09  time: 0.4210  data_time: 0.0105  memory: 4876  grad_norm: 134.2653  loss: 33.3572  decode.loss_cls: 1.2047  decode.loss_mask: 0.7697  decode.loss_dice: 1.0704  decode.d0.loss_cls: 3.1222  decode.d0.loss_mask: 0.8026  decode.d0.loss_dice: 1.2307  decode.d1.loss_cls: 1.3926  decode.d1.loss_mask: 0.8182  decode.d1.loss_dice: 1.1443  decode.d2.loss_cls: 1.3366  decode.d2.loss_mask: 0.8057  decode.d2.loss_dice: 1.0951  decode.d3.loss_cls: 1.2903  decode.d3.loss_mask: 0.7772  decode.d3.loss_dice: 1.0841  decode.d4.loss_cls: 1.2739  decode.d4.loss_mask: 0.7914  decode.d4.loss_dice: 1.0758  decode.d5.loss_cls: 1.2262  decode.d5.loss_mask: 0.7856  decode.d5.loss_dice: 1.0679  decode.d6.loss_cls: 1.2694  decode.d6.loss_mask: 0.7534  decode.d6.loss_dice: 1.0647  decode.d7.loss_cls: 1.2048  decode.d7.loss_mask: 0.7763  decode.d7.loss_dice: 1.0556  decode.d8.loss_cls: 1.2125  decode.d8.loss_mask: 0.7910  decode.d8.loss_dice: 1.0642
2023/05/24 06:04:28 - mmengine - INFO - Iter(train) [ 95550/160000]  lr: 4.4116e-06  eta: 7:42:47  time: 0.4131  data_time: 0.0105  memory: 4821  grad_norm: 92.4903  loss: 31.7732  decode.loss_cls: 0.8662  decode.loss_mask: 0.8269  decode.loss_dice: 1.2282  decode.d0.loss_cls: 2.9070  decode.d0.loss_mask: 0.8847  decode.d0.loss_dice: 1.3112  decode.d1.loss_cls: 0.9632  decode.d1.loss_mask: 0.8199  decode.d1.loss_dice: 1.2788  decode.d2.loss_cls: 0.9201  decode.d2.loss_mask: 0.8161  decode.d2.loss_dice: 1.2365  decode.d3.loss_cls: 0.9660  decode.d3.loss_mask: 0.8161  decode.d3.loss_dice: 1.2418  decode.d4.loss_cls: 0.9432  decode.d4.loss_mask: 0.8381  decode.d4.loss_dice: 1.2103  decode.d5.loss_cls: 0.8862  decode.d5.loss_mask: 0.8307  decode.d5.loss_dice: 1.2091  decode.d6.loss_cls: 0.9034  decode.d6.loss_mask: 0.8275  decode.d6.loss_dice: 1.1943  decode.d7.loss_cls: 0.9208  decode.d7.loss_mask: 0.8139  decode.d7.loss_dice: 1.2070  decode.d8.loss_cls: 0.8699  decode.d8.loss_mask: 0.8211  decode.d8.loss_dice: 1.2148
2023/05/24 06:04:49 - mmengine - INFO - Iter(train) [ 95600/160000]  lr: 4.4085e-06  eta: 7:42:26  time: 0.4246  data_time: 0.0109  memory: 4870  grad_norm: 101.8283  loss: 33.4476  decode.loss_cls: 1.0763  decode.loss_mask: 0.7385  decode.loss_dice: 1.2527  decode.d0.loss_cls: 2.9772  decode.d0.loss_mask: 0.7511  decode.d0.loss_dice: 1.4173  decode.d1.loss_cls: 1.1670  decode.d1.loss_mask: 0.7840  decode.d1.loss_dice: 1.3961  decode.d2.loss_cls: 1.2012  decode.d2.loss_mask: 0.7234  decode.d2.loss_dice: 1.2859  decode.d3.loss_cls: 1.1928  decode.d3.loss_mask: 0.7234  decode.d3.loss_dice: 1.2507  decode.d4.loss_cls: 1.1815  decode.d4.loss_mask: 0.7210  decode.d4.loss_dice: 1.2490  decode.d5.loss_cls: 1.1235  decode.d5.loss_mask: 0.7208  decode.d5.loss_dice: 1.2473  decode.d6.loss_cls: 1.1406  decode.d6.loss_mask: 0.7347  decode.d6.loss_dice: 1.2233  decode.d7.loss_cls: 1.1254  decode.d7.loss_mask: 0.7376  decode.d7.loss_dice: 1.2341  decode.d8.loss_cls: 1.1144  decode.d8.loss_mask: 0.7471  decode.d8.loss_dice: 1.2099
2023/05/24 06:05:10 - mmengine - INFO - Iter(train) [ 95650/160000]  lr: 4.4054e-06  eta: 7:42:04  time: 0.4233  data_time: 0.0105  memory: 4809  grad_norm: 98.6742  loss: 32.4009  decode.loss_cls: 1.1578  decode.loss_mask: 0.6960  decode.loss_dice: 1.1314  decode.d0.loss_cls: 3.0364  decode.d0.loss_mask: 0.7380  decode.d0.loss_dice: 1.3663  decode.d1.loss_cls: 1.2258  decode.d1.loss_mask: 0.7205  decode.d1.loss_dice: 1.1999  decode.d2.loss_cls: 1.2324  decode.d2.loss_mask: 0.7126  decode.d2.loss_dice: 1.1914  decode.d3.loss_cls: 1.2379  decode.d3.loss_mask: 0.6724  decode.d3.loss_dice: 1.0939  decode.d4.loss_cls: 1.1915  decode.d4.loss_mask: 0.6806  decode.d4.loss_dice: 1.1606  decode.d5.loss_cls: 1.2178  decode.d5.loss_mask: 0.6793  decode.d5.loss_dice: 1.1137  decode.d6.loss_cls: 1.1992  decode.d6.loss_mask: 0.6710  decode.d6.loss_dice: 1.0893  decode.d7.loss_cls: 1.1968  decode.d7.loss_mask: 0.6760  decode.d7.loss_dice: 1.1257  decode.d8.loss_cls: 1.2104  decode.d8.loss_mask: 0.6704  decode.d8.loss_dice: 1.1059
2023/05/24 06:05:32 - mmengine - INFO - Iter(train) [ 95700/160000]  lr: 4.4023e-06  eta: 7:41:42  time: 0.4294  data_time: 0.0110  memory: 4963  grad_norm: 108.9737  loss: 32.6662  decode.loss_cls: 1.0915  decode.loss_mask: 0.6545  decode.loss_dice: 1.2692  decode.d0.loss_cls: 2.8112  decode.d0.loss_mask: 0.7095  decode.d0.loss_dice: 1.4459  decode.d1.loss_cls: 1.2630  decode.d1.loss_mask: 0.7304  decode.d1.loss_dice: 1.3696  decode.d2.loss_cls: 1.1953  decode.d2.loss_mask: 0.6957  decode.d2.loss_dice: 1.3515  decode.d3.loss_cls: 1.1096  decode.d3.loss_mask: 0.6740  decode.d3.loss_dice: 1.2784  decode.d4.loss_cls: 1.0743  decode.d4.loss_mask: 0.6580  decode.d4.loss_dice: 1.2628  decode.d5.loss_cls: 1.0972  decode.d5.loss_mask: 0.6522  decode.d5.loss_dice: 1.2624  decode.d6.loss_cls: 1.0853  decode.d6.loss_mask: 0.6531  decode.d6.loss_dice: 1.2498  decode.d7.loss_cls: 1.0734  decode.d7.loss_mask: 0.6511  decode.d7.loss_dice: 1.2545  decode.d8.loss_cls: 1.1511  decode.d8.loss_mask: 0.6575  decode.d8.loss_dice: 1.2341
2023/05/24 06:05:54 - mmengine - INFO - Iter(train) [ 95750/160000]  lr: 4.3993e-06  eta: 7:41:21  time: 0.4164  data_time: 0.0105  memory: 4888  grad_norm: 101.7525  loss: 33.3120  decode.loss_cls: 0.9716  decode.loss_mask: 0.7663  decode.loss_dice: 1.2454  decode.d0.loss_cls: 3.2295  decode.d0.loss_mask: 0.8385  decode.d0.loss_dice: 1.5568  decode.d1.loss_cls: 1.2209  decode.d1.loss_mask: 0.7823  decode.d1.loss_dice: 1.3842  decode.d2.loss_cls: 1.1018  decode.d2.loss_mask: 0.7636  decode.d2.loss_dice: 1.3431  decode.d3.loss_cls: 1.0332  decode.d3.loss_mask: 0.7560  decode.d3.loss_dice: 1.2905  decode.d4.loss_cls: 1.0367  decode.d4.loss_mask: 0.7771  decode.d4.loss_dice: 1.2999  decode.d5.loss_cls: 1.0167  decode.d5.loss_mask: 0.7871  decode.d5.loss_dice: 1.2572  decode.d6.loss_cls: 0.9295  decode.d6.loss_mask: 0.7582  decode.d6.loss_dice: 1.2609  decode.d7.loss_cls: 0.9342  decode.d7.loss_mask: 0.7559  decode.d7.loss_dice: 1.2616  decode.d8.loss_cls: 0.9444  decode.d8.loss_mask: 0.7462  decode.d8.loss_dice: 1.2630
2023/05/24 06:06:15 - mmengine - INFO - Iter(train) [ 95800/160000]  lr: 4.3962e-06  eta: 7:40:59  time: 0.4149  data_time: 0.0110  memory: 4904  grad_norm: 101.8863  loss: 36.2548  decode.loss_cls: 1.3636  decode.loss_mask: 0.8113  decode.loss_dice: 1.1504  decode.d0.loss_cls: 3.2284  decode.d0.loss_mask: 0.9333  decode.d0.loss_dice: 1.4217  decode.d1.loss_cls: 1.5095  decode.d1.loss_mask: 0.9232  decode.d1.loss_dice: 1.2756  decode.d2.loss_cls: 1.3472  decode.d2.loss_mask: 0.8960  decode.d2.loss_dice: 1.2562  decode.d3.loss_cls: 1.3563  decode.d3.loss_mask: 0.8233  decode.d3.loss_dice: 1.1459  decode.d4.loss_cls: 1.3810  decode.d4.loss_mask: 0.8249  decode.d4.loss_dice: 1.1559  decode.d5.loss_cls: 1.3737  decode.d5.loss_mask: 0.8379  decode.d5.loss_dice: 1.1612  decode.d6.loss_cls: 1.3417  decode.d6.loss_mask: 0.8362  decode.d6.loss_dice: 1.2041  decode.d7.loss_cls: 1.3180  decode.d7.loss_mask: 0.8384  decode.d7.loss_dice: 1.1859  decode.d8.loss_cls: 1.3546  decode.d8.loss_mask: 0.8239  decode.d8.loss_dice: 1.1755
2023/05/24 06:06:37 - mmengine - INFO - Iter(train) [ 95850/160000]  lr: 4.3931e-06  eta: 7:40:38  time: 0.4737  data_time: 0.0102  memory: 4873  grad_norm: 110.7288  loss: 31.0703  decode.loss_cls: 0.9779  decode.loss_mask: 0.7029  decode.loss_dice: 1.0952  decode.d0.loss_cls: 3.2030  decode.d0.loss_mask: 0.6987  decode.d0.loss_dice: 1.2433  decode.d1.loss_cls: 1.1352  decode.d1.loss_mask: 0.7378  decode.d1.loss_dice: 1.2123  decode.d2.loss_cls: 1.1073  decode.d2.loss_mask: 0.7287  decode.d2.loss_dice: 1.1770  decode.d3.loss_cls: 1.0413  decode.d3.loss_mask: 0.7143  decode.d3.loss_dice: 1.1412  decode.d4.loss_cls: 0.9798  decode.d4.loss_mask: 0.7108  decode.d4.loss_dice: 1.1425  decode.d5.loss_cls: 1.0353  decode.d5.loss_mask: 0.7057  decode.d5.loss_dice: 1.1285  decode.d6.loss_cls: 1.0168  decode.d6.loss_mask: 0.6979  decode.d6.loss_dice: 1.1095  decode.d7.loss_cls: 1.0047  decode.d7.loss_mask: 0.7105  decode.d7.loss_dice: 1.1116  decode.d8.loss_cls: 0.9875  decode.d8.loss_mask: 0.7064  decode.d8.loss_dice: 1.1069
2023/05/24 06:06:58 - mmengine - INFO - Iter(train) [ 95900/160000]  lr: 4.3900e-06  eta: 7:40:16  time: 0.4209  data_time: 0.0114  memory: 4866  grad_norm: 85.1744  loss: 41.3627  decode.loss_cls: 1.2489  decode.loss_mask: 0.8967  decode.loss_dice: 1.6360  decode.d0.loss_cls: 3.4023  decode.d0.loss_mask: 1.0137  decode.d0.loss_dice: 1.9668  decode.d1.loss_cls: 1.4853  decode.d1.loss_mask: 0.9562  decode.d1.loss_dice: 1.7922  decode.d2.loss_cls: 1.3036  decode.d2.loss_mask: 0.9326  decode.d2.loss_dice: 1.7479  decode.d3.loss_cls: 1.3024  decode.d3.loss_mask: 0.9667  decode.d3.loss_dice: 1.6744  decode.d4.loss_cls: 1.2549  decode.d4.loss_mask: 0.9394  decode.d4.loss_dice: 1.6617  decode.d5.loss_cls: 1.2204  decode.d5.loss_mask: 0.9367  decode.d5.loss_dice: 1.6845  decode.d6.loss_cls: 1.1887  decode.d6.loss_mask: 0.9394  decode.d6.loss_dice: 1.6817  decode.d7.loss_cls: 1.2138  decode.d7.loss_mask: 0.8981  decode.d7.loss_dice: 1.6506  decode.d8.loss_cls: 1.2797  decode.d8.loss_mask: 0.8805  decode.d8.loss_dice: 1.6069
2023/05/24 06:07:19 - mmengine - INFO - Iter(train) [ 95950/160000]  lr: 4.3869e-06  eta: 7:39:54  time: 0.4117  data_time: 0.0104  memory: 4856  grad_norm: 88.4783  loss: 36.6831  decode.loss_cls: 1.3437  decode.loss_mask: 0.7942  decode.loss_dice: 1.2352  decode.d0.loss_cls: 3.4099  decode.d0.loss_mask: 0.8520  decode.d0.loss_dice: 1.4708  decode.d1.loss_cls: 1.4733  decode.d1.loss_mask: 0.8463  decode.d1.loss_dice: 1.3375  decode.d2.loss_cls: 1.4287  decode.d2.loss_mask: 0.8363  decode.d2.loss_dice: 1.2931  decode.d3.loss_cls: 1.4134  decode.d3.loss_mask: 0.8012  decode.d3.loss_dice: 1.2608  decode.d4.loss_cls: 1.3389  decode.d4.loss_mask: 0.8051  decode.d4.loss_dice: 1.2678  decode.d5.loss_cls: 1.3329  decode.d5.loss_mask: 0.7936  decode.d5.loss_dice: 1.2530  decode.d6.loss_cls: 1.3116  decode.d6.loss_mask: 0.8057  decode.d6.loss_dice: 1.2375  decode.d7.loss_cls: 1.3148  decode.d7.loss_mask: 0.7923  decode.d7.loss_dice: 1.2552  decode.d8.loss_cls: 1.3172  decode.d8.loss_mask: 0.8138  decode.d8.loss_dice: 1.2473
2023/05/24 06:07:40 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 06:07:40 - mmengine - INFO - Iter(train) [ 96000/160000]  lr: 4.3839e-06  eta: 7:39:32  time: 0.4174  data_time: 0.0103  memory: 4844  grad_norm: 98.5386  loss: 30.8882  decode.loss_cls: 1.0554  decode.loss_mask: 0.7062  decode.loss_dice: 1.1088  decode.d0.loss_cls: 2.8793  decode.d0.loss_mask: 0.7880  decode.d0.loss_dice: 1.2178  decode.d1.loss_cls: 1.1273  decode.d1.loss_mask: 0.7375  decode.d1.loss_dice: 1.1499  decode.d2.loss_cls: 1.1301  decode.d2.loss_mask: 0.7349  decode.d2.loss_dice: 1.1308  decode.d3.loss_cls: 1.1391  decode.d3.loss_mask: 0.6980  decode.d3.loss_dice: 1.0699  decode.d4.loss_cls: 1.0619  decode.d4.loss_mask: 0.7058  decode.d4.loss_dice: 1.0942  decode.d5.loss_cls: 1.0983  decode.d5.loss_mask: 0.6802  decode.d5.loss_dice: 1.0869  decode.d6.loss_cls: 1.0422  decode.d6.loss_mask: 0.6951  decode.d6.loss_dice: 1.0884  decode.d7.loss_cls: 1.0809  decode.d7.loss_mask: 0.6805  decode.d7.loss_dice: 1.0676  decode.d8.loss_cls: 1.0089  decode.d8.loss_mask: 0.7173  decode.d8.loss_dice: 1.1070
2023/05/24 06:07:40 - mmengine - INFO - Saving checkpoint at 96000 iterations
2023/05/24 06:08:07 - mmengine - INFO - Iter(train) [ 96050/160000]  lr: 4.3808e-06  eta: 7:39:14  time: 0.4263  data_time: 0.0106  memory: 4845  grad_norm: 86.6761  loss: 40.3180  decode.loss_cls: 1.2696  decode.loss_mask: 0.8706  decode.loss_dice: 1.5772  decode.d0.loss_cls: 3.0309  decode.d0.loss_mask: 0.9725  decode.d0.loss_dice: 1.8990  decode.d1.loss_cls: 1.3565  decode.d1.loss_mask: 0.9402  decode.d1.loss_dice: 1.7703  decode.d2.loss_cls: 1.3597  decode.d2.loss_mask: 0.9042  decode.d2.loss_dice: 1.6721  decode.d3.loss_cls: 1.3246  decode.d3.loss_mask: 0.9064  decode.d3.loss_dice: 1.6253  decode.d4.loss_cls: 1.2727  decode.d4.loss_mask: 0.8938  decode.d4.loss_dice: 1.6382  decode.d5.loss_cls: 1.3085  decode.d5.loss_mask: 0.8897  decode.d5.loss_dice: 1.6524  decode.d6.loss_cls: 1.2473  decode.d6.loss_mask: 0.8784  decode.d6.loss_dice: 1.6219  decode.d7.loss_cls: 1.2333  decode.d7.loss_mask: 0.8820  decode.d7.loss_dice: 1.6087  decode.d8.loss_cls: 1.2479  decode.d8.loss_mask: 0.8732  decode.d8.loss_dice: 1.5908
2023/05/24 06:08:28 - mmengine - INFO - Iter(train) [ 96100/160000]  lr: 4.3777e-06  eta: 7:38:52  time: 0.4292  data_time: 0.0104  memory: 4884  grad_norm: 110.6887  loss: 36.1971  decode.loss_cls: 1.3392  decode.loss_mask: 0.6657  decode.loss_dice: 1.2828  decode.d0.loss_cls: 3.3173  decode.d0.loss_mask: 0.7653  decode.d0.loss_dice: 1.4731  decode.d1.loss_cls: 1.4194  decode.d1.loss_mask: 0.7240  decode.d1.loss_dice: 1.4620  decode.d2.loss_cls: 1.4064  decode.d2.loss_mask: 0.6710  decode.d2.loss_dice: 1.4012  decode.d3.loss_cls: 1.3755  decode.d3.loss_mask: 0.6711  decode.d3.loss_dice: 1.3365  decode.d4.loss_cls: 1.3908  decode.d4.loss_mask: 0.6610  decode.d4.loss_dice: 1.3599  decode.d5.loss_cls: 1.4450  decode.d5.loss_mask: 0.6579  decode.d5.loss_dice: 1.2964  decode.d6.loss_cls: 1.4734  decode.d6.loss_mask: 0.6552  decode.d6.loss_dice: 1.2928  decode.d7.loss_cls: 1.3844  decode.d7.loss_mask: 0.6646  decode.d7.loss_dice: 1.2673  decode.d8.loss_cls: 1.3074  decode.d8.loss_mask: 0.6888  decode.d8.loss_dice: 1.3419
2023/05/24 06:08:49 - mmengine - INFO - Iter(train) [ 96150/160000]  lr: 4.3746e-06  eta: 7:38:30  time: 0.4149  data_time: 0.0105  memory: 4867  grad_norm: 100.7420  loss: 32.3311  decode.loss_cls: 1.1893  decode.loss_mask: 0.6540  decode.loss_dice: 1.0971  decode.d0.loss_cls: 2.7943  decode.d0.loss_mask: 0.7332  decode.d0.loss_dice: 1.2652  decode.d1.loss_cls: 1.2865  decode.d1.loss_mask: 0.7118  decode.d1.loss_dice: 1.2031  decode.d2.loss_cls: 1.2521  decode.d2.loss_mask: 0.6935  decode.d2.loss_dice: 1.1571  decode.d3.loss_cls: 1.2670  decode.d3.loss_mask: 0.6633  decode.d3.loss_dice: 1.1326  decode.d4.loss_cls: 1.3287  decode.d4.loss_mask: 0.6426  decode.d4.loss_dice: 1.1265  decode.d5.loss_cls: 1.2954  decode.d5.loss_mask: 0.6447  decode.d5.loss_dice: 1.1531  decode.d6.loss_cls: 1.2584  decode.d6.loss_mask: 0.6571  decode.d6.loss_dice: 1.1021  decode.d7.loss_cls: 1.2559  decode.d7.loss_mask: 0.6628  decode.d7.loss_dice: 1.1331  decode.d8.loss_cls: 1.2142  decode.d8.loss_mask: 0.6606  decode.d8.loss_dice: 1.0960
2023/05/24 06:09:10 - mmengine - INFO - Iter(train) [ 96200/160000]  lr: 4.3715e-06  eta: 7:38:09  time: 0.4269  data_time: 0.0103  memory: 4859  grad_norm: 102.8822  loss: 43.6256  decode.loss_cls: 1.4041  decode.loss_mask: 1.0023  decode.loss_dice: 1.6704  decode.d0.loss_cls: 3.3408  decode.d0.loss_mask: 1.1353  decode.d0.loss_dice: 1.9090  decode.d1.loss_cls: 1.4257  decode.d1.loss_mask: 1.0680  decode.d1.loss_dice: 1.7742  decode.d2.loss_cls: 1.3800  decode.d2.loss_mask: 1.0676  decode.d2.loss_dice: 1.7524  decode.d3.loss_cls: 1.4178  decode.d3.loss_mask: 0.9604  decode.d3.loss_dice: 1.6933  decode.d4.loss_cls: 1.3905  decode.d4.loss_mask: 1.0118  decode.d4.loss_dice: 1.7130  decode.d5.loss_cls: 1.4388  decode.d5.loss_mask: 1.0090  decode.d5.loss_dice: 1.6937  decode.d6.loss_cls: 1.4068  decode.d6.loss_mask: 1.0264  decode.d6.loss_dice: 1.6689  decode.d7.loss_cls: 1.4540  decode.d7.loss_mask: 1.0198  decode.d7.loss_dice: 1.6671  decode.d8.loss_cls: 1.4335  decode.d8.loss_mask: 1.0203  decode.d8.loss_dice: 1.6707
2023/05/24 06:09:33 - mmengine - INFO - Iter(train) [ 96250/160000]  lr: 4.3684e-06  eta: 7:37:48  time: 0.4319  data_time: 0.0104  memory: 4916  grad_norm: 93.6827  loss: 36.9892  decode.loss_cls: 1.2545  decode.loss_mask: 0.7321  decode.loss_dice: 1.3849  decode.d0.loss_cls: 3.3596  decode.d0.loss_mask: 0.7371  decode.d0.loss_dice: 1.6450  decode.d1.loss_cls: 1.3528  decode.d1.loss_mask: 0.7982  decode.d1.loss_dice: 1.5204  decode.d2.loss_cls: 1.3791  decode.d2.loss_mask: 0.7117  decode.d2.loss_dice: 1.4385  decode.d3.loss_cls: 1.2890  decode.d3.loss_mask: 0.7325  decode.d3.loss_dice: 1.4106  decode.d4.loss_cls: 1.3045  decode.d4.loss_mask: 0.7179  decode.d4.loss_dice: 1.4226  decode.d5.loss_cls: 1.3611  decode.d5.loss_mask: 0.7094  decode.d5.loss_dice: 1.3914  decode.d6.loss_cls: 1.3143  decode.d6.loss_mask: 0.7204  decode.d6.loss_dice: 1.4113  decode.d7.loss_cls: 1.3211  decode.d7.loss_mask: 0.7280  decode.d7.loss_dice: 1.3948  decode.d8.loss_cls: 1.3328  decode.d8.loss_mask: 0.7399  decode.d8.loss_dice: 1.3739
2023/05/24 06:09:54 - mmengine - INFO - Iter(train) [ 96300/160000]  lr: 4.3654e-06  eta: 7:37:26  time: 0.4256  data_time: 0.0109  memory: 4868  grad_norm: 100.9063  loss: 37.8121  decode.loss_cls: 1.3745  decode.loss_mask: 0.8793  decode.loss_dice: 1.2365  decode.d0.loss_cls: 3.2047  decode.d0.loss_mask: 0.8994  decode.d0.loss_dice: 1.4935  decode.d1.loss_cls: 1.4678  decode.d1.loss_mask: 0.9565  decode.d1.loss_dice: 1.3408  decode.d2.loss_cls: 1.4405  decode.d2.loss_mask: 0.9108  decode.d2.loss_dice: 1.2903  decode.d3.loss_cls: 1.4230  decode.d3.loss_mask: 0.9068  decode.d3.loss_dice: 1.2911  decode.d4.loss_cls: 1.4105  decode.d4.loss_mask: 0.9043  decode.d4.loss_dice: 1.2695  decode.d5.loss_cls: 1.3630  decode.d5.loss_mask: 0.9128  decode.d5.loss_dice: 1.2724  decode.d6.loss_cls: 1.3914  decode.d6.loss_mask: 0.8971  decode.d6.loss_dice: 1.2676  decode.d7.loss_cls: 1.3440  decode.d7.loss_mask: 0.8899  decode.d7.loss_dice: 1.2926  decode.d8.loss_cls: 1.3400  decode.d8.loss_mask: 0.8844  decode.d8.loss_dice: 1.2571
2023/05/24 06:10:16 - mmengine - INFO - Iter(train) [ 96350/160000]  lr: 4.3623e-06  eta: 7:37:05  time: 0.4579  data_time: 0.0109  memory: 4837  grad_norm: 217.3264  loss: 36.4467  decode.loss_cls: 1.0421  decode.loss_mask: 0.8522  decode.loss_dice: 1.4105  decode.d0.loss_cls: 3.2016  decode.d0.loss_mask: 0.9590  decode.d0.loss_dice: 1.7254  decode.d1.loss_cls: 1.2609  decode.d1.loss_mask: 0.9051  decode.d1.loss_dice: 1.5274  decode.d2.loss_cls: 1.1662  decode.d2.loss_mask: 0.8326  decode.d2.loss_dice: 1.4248  decode.d3.loss_cls: 1.1356  decode.d3.loss_mask: 0.8590  decode.d3.loss_dice: 1.4443  decode.d4.loss_cls: 1.0828  decode.d4.loss_mask: 0.8610  decode.d4.loss_dice: 1.4554  decode.d5.loss_cls: 1.0664  decode.d5.loss_mask: 0.8562  decode.d5.loss_dice: 1.4054  decode.d6.loss_cls: 1.0392  decode.d6.loss_mask: 0.8645  decode.d6.loss_dice: 1.4259  decode.d7.loss_cls: 1.0590  decode.d7.loss_mask: 0.8471  decode.d7.loss_dice: 1.4070  decode.d8.loss_cls: 1.0947  decode.d8.loss_mask: 0.8337  decode.d8.loss_dice: 1.4017
2023/05/24 06:10:38 - mmengine - INFO - Iter(train) [ 96400/160000]  lr: 4.3592e-06  eta: 7:36:44  time: 0.4200  data_time: 0.0103  memory: 4830  grad_norm: 125.9717  loss: 35.8439  decode.loss_cls: 1.3666  decode.loss_mask: 0.8171  decode.loss_dice: 1.1903  decode.d0.loss_cls: 3.0993  decode.d0.loss_mask: 0.9279  decode.d0.loss_dice: 1.3913  decode.d1.loss_cls: 1.3604  decode.d1.loss_mask: 0.8412  decode.d1.loss_dice: 1.3062  decode.d2.loss_cls: 1.3279  decode.d2.loss_mask: 0.8237  decode.d2.loss_dice: 1.2727  decode.d3.loss_cls: 1.3239  decode.d3.loss_mask: 0.8244  decode.d3.loss_dice: 1.2148  decode.d4.loss_cls: 1.3163  decode.d4.loss_mask: 0.8256  decode.d4.loss_dice: 1.1751  decode.d5.loss_cls: 1.4201  decode.d5.loss_mask: 0.8083  decode.d5.loss_dice: 1.1442  decode.d6.loss_cls: 1.3242  decode.d6.loss_mask: 0.8113  decode.d6.loss_dice: 1.1980  decode.d7.loss_cls: 1.3456  decode.d7.loss_mask: 0.8186  decode.d7.loss_dice: 1.2011  decode.d8.loss_cls: 1.3698  decode.d8.loss_mask: 0.8127  decode.d8.loss_dice: 1.1853
2023/05/24 06:11:00 - mmengine - INFO - Iter(train) [ 96450/160000]  lr: 4.3561e-06  eta: 7:36:22  time: 0.4386  data_time: 0.0107  memory: 4863  grad_norm: 89.4457  loss: 34.2954  decode.loss_cls: 0.8472  decode.loss_mask: 0.8823  decode.loss_dice: 1.4074  decode.d0.loss_cls: 2.9659  decode.d0.loss_mask: 0.8646  decode.d0.loss_dice: 1.5148  decode.d1.loss_cls: 0.9767  decode.d1.loss_mask: 0.8936  decode.d1.loss_dice: 1.4817  decode.d2.loss_cls: 0.9080  decode.d2.loss_mask: 0.9188  decode.d2.loss_dice: 1.4889  decode.d3.loss_cls: 0.9622  decode.d3.loss_mask: 0.8671  decode.d3.loss_dice: 1.4094  decode.d4.loss_cls: 0.9599  decode.d4.loss_mask: 0.8755  decode.d4.loss_dice: 1.4500  decode.d5.loss_cls: 0.8909  decode.d5.loss_mask: 0.8864  decode.d5.loss_dice: 1.3996  decode.d6.loss_cls: 0.9058  decode.d6.loss_mask: 0.9000  decode.d6.loss_dice: 1.3937  decode.d7.loss_cls: 0.8488  decode.d7.loss_mask: 0.8962  decode.d7.loss_dice: 1.3644  decode.d8.loss_cls: 0.8295  decode.d8.loss_mask: 0.8983  decode.d8.loss_dice: 1.4075
2023/05/24 06:11:21 - mmengine - INFO - Iter(train) [ 96500/160000]  lr: 4.3530e-06  eta: 7:36:00  time: 0.4282  data_time: 0.0111  memory: 4896  grad_norm: 146.5851  loss: 38.1793  decode.loss_cls: 1.4350  decode.loss_mask: 0.9226  decode.loss_dice: 1.2151  decode.d0.loss_cls: 3.2706  decode.d0.loss_mask: 0.9380  decode.d0.loss_dice: 1.3482  decode.d1.loss_cls: 1.5898  decode.d1.loss_mask: 0.9286  decode.d1.loss_dice: 1.2669  decode.d2.loss_cls: 1.5294  decode.d2.loss_mask: 0.9549  decode.d2.loss_dice: 1.2389  decode.d3.loss_cls: 1.4998  decode.d3.loss_mask: 0.9254  decode.d3.loss_dice: 1.2097  decode.d4.loss_cls: 1.4565  decode.d4.loss_mask: 0.9299  decode.d4.loss_dice: 1.2190  decode.d5.loss_cls: 1.4038  decode.d5.loss_mask: 0.9605  decode.d5.loss_dice: 1.2701  decode.d6.loss_cls: 1.4619  decode.d6.loss_mask: 0.9452  decode.d6.loss_dice: 1.2194  decode.d7.loss_cls: 1.3970  decode.d7.loss_mask: 0.9469  decode.d7.loss_dice: 1.1710  decode.d8.loss_cls: 1.4052  decode.d8.loss_mask: 0.9448  decode.d8.loss_dice: 1.1750
2023/05/24 06:11:42 - mmengine - INFO - Iter(train) [ 96550/160000]  lr: 4.3499e-06  eta: 7:35:38  time: 0.4193  data_time: 0.0107  memory: 4868  grad_norm: 98.7299  loss: 32.4790  decode.loss_cls: 1.0528  decode.loss_mask: 0.7728  decode.loss_dice: 1.1957  decode.d0.loss_cls: 2.7992  decode.d0.loss_mask: 0.8270  decode.d0.loss_dice: 1.4063  decode.d1.loss_cls: 1.0358  decode.d1.loss_mask: 0.7793  decode.d1.loss_dice: 1.3304  decode.d2.loss_cls: 1.1297  decode.d2.loss_mask: 0.7597  decode.d2.loss_dice: 1.2597  decode.d3.loss_cls: 1.0094  decode.d3.loss_mask: 0.8026  decode.d3.loss_dice: 1.2506  decode.d4.loss_cls: 1.0176  decode.d4.loss_mask: 0.7769  decode.d4.loss_dice: 1.2239  decode.d5.loss_cls: 1.0017  decode.d5.loss_mask: 0.7855  decode.d5.loss_dice: 1.2579  decode.d6.loss_cls: 1.0452  decode.d6.loss_mask: 0.7841  decode.d6.loss_dice: 1.2152  decode.d7.loss_cls: 0.9806  decode.d7.loss_mask: 0.7634  decode.d7.loss_dice: 1.2237  decode.d8.loss_cls: 0.9927  decode.d8.loss_mask: 0.7706  decode.d8.loss_dice: 1.2293
2023/05/24 06:12:03 - mmengine - INFO - Iter(train) [ 96600/160000]  lr: 4.3469e-06  eta: 7:35:17  time: 0.4249  data_time: 0.0106  memory: 4835  grad_norm: 105.3226  loss: 42.4954  decode.loss_cls: 1.4784  decode.loss_mask: 0.8765  decode.loss_dice: 1.5731  decode.d0.loss_cls: 3.4945  decode.d0.loss_mask: 0.9866  decode.d0.loss_dice: 1.8965  decode.d1.loss_cls: 1.5118  decode.d1.loss_mask: 1.0001  decode.d1.loss_dice: 1.7240  decode.d2.loss_cls: 1.4298  decode.d2.loss_mask: 0.9474  decode.d2.loss_dice: 1.6520  decode.d3.loss_cls: 1.4049  decode.d3.loss_mask: 0.9378  decode.d3.loss_dice: 1.6718  decode.d4.loss_cls: 1.4619  decode.d4.loss_mask: 0.9078  decode.d4.loss_dice: 1.6038  decode.d5.loss_cls: 1.5589  decode.d5.loss_mask: 0.8955  decode.d5.loss_dice: 1.5994  decode.d6.loss_cls: 1.4960  decode.d6.loss_mask: 0.8984  decode.d6.loss_dice: 1.5829  decode.d7.loss_cls: 1.5203  decode.d7.loss_mask: 0.8815  decode.d7.loss_dice: 1.5502  decode.d8.loss_cls: 1.4829  decode.d8.loss_mask: 0.8671  decode.d8.loss_dice: 1.6035
2023/05/24 06:12:24 - mmengine - INFO - Iter(train) [ 96650/160000]  lr: 4.3438e-06  eta: 7:34:55  time: 0.4139  data_time: 0.0104  memory: 4910  grad_norm: 107.4998  loss: 34.5628  decode.loss_cls: 1.1242  decode.loss_mask: 0.5469  decode.loss_dice: 1.4428  decode.d0.loss_cls: 3.3555  decode.d0.loss_mask: 0.5608  decode.d0.loss_dice: 1.6366  decode.d1.loss_cls: 1.4808  decode.d1.loss_mask: 0.5489  decode.d1.loss_dice: 1.5397  decode.d2.loss_cls: 1.3946  decode.d2.loss_mask: 0.5362  decode.d2.loss_dice: 1.5155  decode.d3.loss_cls: 1.1871  decode.d3.loss_mask: 0.5386  decode.d3.loss_dice: 1.4076  decode.d4.loss_cls: 1.3040  decode.d4.loss_mask: 0.5364  decode.d4.loss_dice: 1.4422  decode.d5.loss_cls: 1.1652  decode.d5.loss_mask: 0.5461  decode.d5.loss_dice: 1.4538  decode.d6.loss_cls: 1.0887  decode.d6.loss_mask: 0.5498  decode.d6.loss_dice: 1.4457  decode.d7.loss_cls: 1.1207  decode.d7.loss_mask: 0.5446  decode.d7.loss_dice: 1.4264  decode.d8.loss_cls: 1.1785  decode.d8.loss_mask: 0.5396  decode.d8.loss_dice: 1.4053
2023/05/24 06:12:45 - mmengine - INFO - Iter(train) [ 96700/160000]  lr: 4.3407e-06  eta: 7:34:33  time: 0.4203  data_time: 0.0110  memory: 4879  grad_norm: 98.7908  loss: 32.1132  decode.loss_cls: 0.8259  decode.loss_mask: 0.7562  decode.loss_dice: 1.3317  decode.d0.loss_cls: 2.8316  decode.d0.loss_mask: 0.8484  decode.d0.loss_dice: 1.4747  decode.d1.loss_cls: 0.9427  decode.d1.loss_mask: 0.8316  decode.d1.loss_dice: 1.3619  decode.d2.loss_cls: 0.8900  decode.d2.loss_mask: 0.7931  decode.d2.loss_dice: 1.3583  decode.d3.loss_cls: 0.8508  decode.d3.loss_mask: 0.7986  decode.d3.loss_dice: 1.3675  decode.d4.loss_cls: 0.8439  decode.d4.loss_mask: 0.7908  decode.d4.loss_dice: 1.3429  decode.d5.loss_cls: 0.9300  decode.d5.loss_mask: 0.7956  decode.d5.loss_dice: 1.3102  decode.d6.loss_cls: 0.8693  decode.d6.loss_mask: 0.7796  decode.d6.loss_dice: 1.3022  decode.d7.loss_cls: 0.8574  decode.d7.loss_mask: 0.7923  decode.d7.loss_dice: 1.3119  decode.d8.loss_cls: 0.8166  decode.d8.loss_mask: 0.7764  decode.d8.loss_dice: 1.3310
2023/05/24 06:13:07 - mmengine - INFO - Iter(train) [ 96750/160000]  lr: 4.3376e-06  eta: 7:34:11  time: 0.4258  data_time: 0.0111  memory: 4845  grad_norm: 94.7839  loss: 33.5048  decode.loss_cls: 1.1730  decode.loss_mask: 0.7121  decode.loss_dice: 1.2048  decode.d0.loss_cls: 3.1414  decode.d0.loss_mask: 0.7264  decode.d0.loss_dice: 1.3418  decode.d1.loss_cls: 1.3986  decode.d1.loss_mask: 0.7245  decode.d1.loss_dice: 1.2463  decode.d2.loss_cls: 1.2829  decode.d2.loss_mask: 0.7317  decode.d2.loss_dice: 1.2330  decode.d3.loss_cls: 1.2227  decode.d3.loss_mask: 0.7226  decode.d3.loss_dice: 1.2000  decode.d4.loss_cls: 1.1760  decode.d4.loss_mask: 0.7246  decode.d4.loss_dice: 1.2147  decode.d5.loss_cls: 1.2170  decode.d5.loss_mask: 0.7063  decode.d5.loss_dice: 1.1849  decode.d6.loss_cls: 1.2029  decode.d6.loss_mask: 0.7072  decode.d6.loss_dice: 1.1995  decode.d7.loss_cls: 1.1352  decode.d7.loss_mask: 0.7052  decode.d7.loss_dice: 1.2099  decode.d8.loss_cls: 1.1566  decode.d8.loss_mask: 0.7050  decode.d8.loss_dice: 1.1976
2023/05/24 06:13:28 - mmengine - INFO - Iter(train) [ 96800/160000]  lr: 4.3345e-06  eta: 7:33:50  time: 0.4280  data_time: 0.0108  memory: 4858  grad_norm: 109.3428  loss: 39.9884  decode.loss_cls: 1.4551  decode.loss_mask: 0.8693  decode.loss_dice: 1.4611  decode.d0.loss_cls: 3.0534  decode.d0.loss_mask: 0.8479  decode.d0.loss_dice: 1.6066  decode.d1.loss_cls: 1.5218  decode.d1.loss_mask: 0.8579  decode.d1.loss_dice: 1.5055  decode.d2.loss_cls: 1.4958  decode.d2.loss_mask: 0.8390  decode.d2.loss_dice: 1.4765  decode.d3.loss_cls: 1.5588  decode.d3.loss_mask: 0.8438  decode.d3.loss_dice: 1.4785  decode.d4.loss_cls: 1.5681  decode.d4.loss_mask: 0.8608  decode.d4.loss_dice: 1.4646  decode.d5.loss_cls: 1.5081  decode.d5.loss_mask: 0.8518  decode.d5.loss_dice: 1.4752  decode.d6.loss_cls: 1.4948  decode.d6.loss_mask: 0.8443  decode.d6.loss_dice: 1.4508  decode.d7.loss_cls: 1.4999  decode.d7.loss_mask: 0.8671  decode.d7.loss_dice: 1.4582  decode.d8.loss_cls: 1.4818  decode.d8.loss_mask: 0.8567  decode.d8.loss_dice: 1.4354
2023/05/24 06:13:50 - mmengine - INFO - Iter(train) [ 96850/160000]  lr: 4.3314e-06  eta: 7:33:28  time: 0.4358  data_time: 0.0108  memory: 4883  grad_norm: 103.0689  loss: 29.8292  decode.loss_cls: 1.0065  decode.loss_mask: 0.5892  decode.loss_dice: 1.1430  decode.d0.loss_cls: 2.9481  decode.d0.loss_mask: 0.6201  decode.d0.loss_dice: 1.2388  decode.d1.loss_cls: 1.1372  decode.d1.loss_mask: 0.6688  decode.d1.loss_dice: 1.2228  decode.d2.loss_cls: 1.0212  decode.d2.loss_mask: 0.6435  decode.d2.loss_dice: 1.1791  decode.d3.loss_cls: 1.0400  decode.d3.loss_mask: 0.5730  decode.d3.loss_dice: 1.2081  decode.d4.loss_cls: 0.9731  decode.d4.loss_mask: 0.6162  decode.d4.loss_dice: 1.1911  decode.d5.loss_cls: 0.9878  decode.d5.loss_mask: 0.5677  decode.d5.loss_dice: 1.1740  decode.d6.loss_cls: 0.9959  decode.d6.loss_mask: 0.5687  decode.d6.loss_dice: 1.1388  decode.d7.loss_cls: 0.9555  decode.d7.loss_mask: 0.5705  decode.d7.loss_dice: 1.1355  decode.d8.loss_cls: 0.9839  decode.d8.loss_mask: 0.5991  decode.d8.loss_dice: 1.1321
2023/05/24 06:14:12 - mmengine - INFO - Iter(train) [ 96900/160000]  lr: 4.3283e-06  eta: 7:33:07  time: 0.4788  data_time: 0.0108  memory: 4894  grad_norm: 106.8287  loss: 32.1729  decode.loss_cls: 1.1323  decode.loss_mask: 0.7034  decode.loss_dice: 1.1228  decode.d0.loss_cls: 3.1313  decode.d0.loss_mask: 0.6923  decode.d0.loss_dice: 1.2736  decode.d1.loss_cls: 1.3239  decode.d1.loss_mask: 0.7614  decode.d1.loss_dice: 1.2183  decode.d2.loss_cls: 1.1910  decode.d2.loss_mask: 0.7181  decode.d2.loss_dice: 1.1513  decode.d3.loss_cls: 1.1304  decode.d3.loss_mask: 0.7076  decode.d3.loss_dice: 1.1295  decode.d4.loss_cls: 1.1679  decode.d4.loss_mask: 0.7018  decode.d4.loss_dice: 1.1310  decode.d5.loss_cls: 1.1247  decode.d5.loss_mask: 0.7177  decode.d5.loss_dice: 1.1481  decode.d6.loss_cls: 1.0793  decode.d6.loss_mask: 0.7388  decode.d6.loss_dice: 1.1356  decode.d7.loss_cls: 1.0973  decode.d7.loss_mask: 0.7112  decode.d7.loss_dice: 1.1064  decode.d8.loss_cls: 1.1164  decode.d8.loss_mask: 0.7039  decode.d8.loss_dice: 1.1056
2023/05/24 06:14:33 - mmengine - INFO - Iter(train) [ 96950/160000]  lr: 4.3252e-06  eta: 7:32:45  time: 0.4167  data_time: 0.0106  memory: 4835  grad_norm: 86.6716  loss: 34.6665  decode.loss_cls: 1.1980  decode.loss_mask: 0.7157  decode.loss_dice: 1.2861  decode.d0.loss_cls: 3.2089  decode.d0.loss_mask: 0.7269  decode.d0.loss_dice: 1.4807  decode.d1.loss_cls: 1.4140  decode.d1.loss_mask: 0.7758  decode.d1.loss_dice: 1.3898  decode.d2.loss_cls: 1.3513  decode.d2.loss_mask: 0.7599  decode.d2.loss_dice: 1.3661  decode.d3.loss_cls: 1.1949  decode.d3.loss_mask: 0.7171  decode.d3.loss_dice: 1.2940  decode.d4.loss_cls: 1.1152  decode.d4.loss_mask: 0.7449  decode.d4.loss_dice: 1.2875  decode.d5.loss_cls: 1.1306  decode.d5.loss_mask: 0.7289  decode.d5.loss_dice: 1.3026  decode.d6.loss_cls: 1.1831  decode.d6.loss_mask: 0.7162  decode.d6.loss_dice: 1.2792  decode.d7.loss_cls: 1.1601  decode.d7.loss_mask: 0.7196  decode.d7.loss_dice: 1.2604  decode.d8.loss_cls: 1.1860  decode.d8.loss_mask: 0.7192  decode.d8.loss_dice: 1.2538
2023/05/24 06:14:54 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 06:14:54 - mmengine - INFO - Iter(train) [ 97000/160000]  lr: 4.3222e-06  eta: 7:32:23  time: 0.4220  data_time: 0.0109  memory: 4822  grad_norm: 91.2209  loss: 32.1469  decode.loss_cls: 1.0742  decode.loss_mask: 0.6687  decode.loss_dice: 1.1640  decode.d0.loss_cls: 3.0089  decode.d0.loss_mask: 0.7511  decode.d0.loss_dice: 1.4118  decode.d1.loss_cls: 1.1354  decode.d1.loss_mask: 0.7547  decode.d1.loss_dice: 1.3671  decode.d2.loss_cls: 1.0327  decode.d2.loss_mask: 0.7439  decode.d2.loss_dice: 1.2794  decode.d3.loss_cls: 1.0919  decode.d3.loss_mask: 0.7083  decode.d3.loss_dice: 1.2415  decode.d4.loss_cls: 1.0194  decode.d4.loss_mask: 0.7114  decode.d4.loss_dice: 1.2059  decode.d5.loss_cls: 1.0621  decode.d5.loss_mask: 0.7125  decode.d5.loss_dice: 1.2233  decode.d6.loss_cls: 1.0474  decode.d6.loss_mask: 0.7044  decode.d6.loss_dice: 1.1740  decode.d7.loss_cls: 1.0884  decode.d7.loss_mask: 0.6743  decode.d7.loss_dice: 1.1727  decode.d8.loss_cls: 1.0531  decode.d8.loss_mask: 0.6769  decode.d8.loss_dice: 1.1877
2023/05/24 06:14:55 - mmengine - INFO - Saving checkpoint at 97000 iterations
2023/05/24 06:15:21 - mmengine - INFO - Iter(train) [ 97050/160000]  lr: 4.3191e-06  eta: 7:32:05  time: 0.4197  data_time: 0.0103  memory: 4877  grad_norm: 95.1054  loss: 42.4216  decode.loss_cls: 1.5770  decode.loss_mask: 0.7939  decode.loss_dice: 1.5713  decode.d0.loss_cls: 3.5032  decode.d0.loss_mask: 0.8572  decode.d0.loss_dice: 1.8502  decode.d1.loss_cls: 1.7344  decode.d1.loss_mask: 0.8653  decode.d1.loss_dice: 1.7429  decode.d2.loss_cls: 1.5796  decode.d2.loss_mask: 0.8004  decode.d2.loss_dice: 1.6851  decode.d3.loss_cls: 1.6511  decode.d3.loss_mask: 0.7707  decode.d3.loss_dice: 1.6075  decode.d4.loss_cls: 1.5886  decode.d4.loss_mask: 0.7788  decode.d4.loss_dice: 1.6245  decode.d5.loss_cls: 1.5268  decode.d5.loss_mask: 0.8019  decode.d5.loss_dice: 1.6312  decode.d6.loss_cls: 1.6170  decode.d6.loss_mask: 0.7709  decode.d6.loss_dice: 1.5812  decode.d7.loss_cls: 1.6270  decode.d7.loss_mask: 0.7758  decode.d7.loss_dice: 1.5541  decode.d8.loss_cls: 1.6164  decode.d8.loss_mask: 0.7858  decode.d8.loss_dice: 1.5516
2023/05/24 06:15:42 - mmengine - INFO - Iter(train) [ 97100/160000]  lr: 4.3160e-06  eta: 7:31:43  time: 0.4128  data_time: 0.0103  memory: 4877  grad_norm: 102.2949  loss: 41.4151  decode.loss_cls: 1.5429  decode.loss_mask: 0.9745  decode.loss_dice: 1.3311  decode.d0.loss_cls: 3.4368  decode.d0.loss_mask: 1.0986  decode.d0.loss_dice: 1.6324  decode.d1.loss_cls: 1.7979  decode.d1.loss_mask: 0.9579  decode.d1.loss_dice: 1.4397  decode.d2.loss_cls: 1.6874  decode.d2.loss_mask: 0.9779  decode.d2.loss_dice: 1.4118  decode.d3.loss_cls: 1.6476  decode.d3.loss_mask: 0.8993  decode.d3.loss_dice: 1.3426  decode.d4.loss_cls: 1.5738  decode.d4.loss_mask: 0.9332  decode.d4.loss_dice: 1.3604  decode.d5.loss_cls: 1.5346  decode.d5.loss_mask: 0.9535  decode.d5.loss_dice: 1.3604  decode.d6.loss_cls: 1.5386  decode.d6.loss_mask: 0.9315  decode.d6.loss_dice: 1.3277  decode.d7.loss_cls: 1.5374  decode.d7.loss_mask: 0.9553  decode.d7.loss_dice: 1.3587  decode.d8.loss_cls: 1.5774  decode.d8.loss_mask: 0.9417  decode.d8.loss_dice: 1.3523
2023/05/24 06:16:03 - mmengine - INFO - Iter(train) [ 97150/160000]  lr: 4.3129e-06  eta: 7:31:21  time: 0.4212  data_time: 0.0104  memory: 4928  grad_norm: 82.0478  loss: 42.1604  decode.loss_cls: 1.2292  decode.loss_mask: 0.9127  decode.loss_dice: 1.7446  decode.d0.loss_cls: 3.4112  decode.d0.loss_mask: 0.9057  decode.d0.loss_dice: 2.0489  decode.d1.loss_cls: 1.4238  decode.d1.loss_mask: 0.9437  decode.d1.loss_dice: 1.9096  decode.d2.loss_cls: 1.2641  decode.d2.loss_mask: 0.9110  decode.d2.loss_dice: 1.8543  decode.d3.loss_cls: 1.2493  decode.d3.loss_mask: 0.9180  decode.d3.loss_dice: 1.8042  decode.d4.loss_cls: 1.2430  decode.d4.loss_mask: 0.8947  decode.d4.loss_dice: 1.8270  decode.d5.loss_cls: 1.2195  decode.d5.loss_mask: 0.9094  decode.d5.loss_dice: 1.8166  decode.d6.loss_cls: 1.2356  decode.d6.loss_mask: 0.9463  decode.d6.loss_dice: 1.7855  decode.d7.loss_cls: 1.1869  decode.d7.loss_mask: 0.9495  decode.d7.loss_dice: 1.7837  decode.d8.loss_cls: 1.1513  decode.d8.loss_mask: 0.9281  decode.d8.loss_dice: 1.7530
2023/05/24 06:16:25 - mmengine - INFO - Iter(train) [ 97200/160000]  lr: 4.3098e-06  eta: 7:31:00  time: 0.4766  data_time: 0.0103  memory: 4831  grad_norm: 91.4379  loss: 34.7314  decode.loss_cls: 1.0725  decode.loss_mask: 0.8691  decode.loss_dice: 1.2810  decode.d0.loss_cls: 2.9989  decode.d0.loss_mask: 0.8753  decode.d0.loss_dice: 1.3541  decode.d1.loss_cls: 1.1684  decode.d1.loss_mask: 0.9118  decode.d1.loss_dice: 1.3759  decode.d2.loss_cls: 1.1158  decode.d2.loss_mask: 0.8998  decode.d2.loss_dice: 1.3119  decode.d3.loss_cls: 1.1105  decode.d3.loss_mask: 0.8686  decode.d3.loss_dice: 1.2869  decode.d4.loss_cls: 1.0784  decode.d4.loss_mask: 0.9064  decode.d4.loss_dice: 1.2960  decode.d5.loss_cls: 1.1036  decode.d5.loss_mask: 0.8363  decode.d5.loss_dice: 1.2984  decode.d6.loss_cls: 1.1258  decode.d6.loss_mask: 0.8377  decode.d6.loss_dice: 1.2967  decode.d7.loss_cls: 1.1017  decode.d7.loss_mask: 0.8401  decode.d7.loss_dice: 1.2521  decode.d8.loss_cls: 1.1682  decode.d8.loss_mask: 0.8372  decode.d8.loss_dice: 1.2523
2023/05/24 06:16:47 - mmengine - INFO - Iter(train) [ 97250/160000]  lr: 4.3067e-06  eta: 7:30:39  time: 0.4284  data_time: 0.0103  memory: 4928  grad_norm: 100.8533  loss: 42.1829  decode.loss_cls: 1.4990  decode.loss_mask: 0.8772  decode.loss_dice: 1.5325  decode.d0.loss_cls: 3.3583  decode.d0.loss_mask: 0.9485  decode.d0.loss_dice: 1.7240  decode.d1.loss_cls: 1.6379  decode.d1.loss_mask: 0.9354  decode.d1.loss_dice: 1.7201  decode.d2.loss_cls: 1.5782  decode.d2.loss_mask: 0.9163  decode.d2.loss_dice: 1.6506  decode.d3.loss_cls: 1.5673  decode.d3.loss_mask: 0.9359  decode.d3.loss_dice: 1.5804  decode.d4.loss_cls: 1.4893  decode.d4.loss_mask: 0.9088  decode.d4.loss_dice: 1.5945  decode.d5.loss_cls: 1.5083  decode.d5.loss_mask: 0.8817  decode.d5.loss_dice: 1.5910  decode.d6.loss_cls: 1.4565  decode.d6.loss_mask: 0.9133  decode.d6.loss_dice: 1.5802  decode.d7.loss_cls: 1.4506  decode.d7.loss_mask: 0.9035  decode.d7.loss_dice: 1.5296  decode.d8.loss_cls: 1.5079  decode.d8.loss_mask: 0.8926  decode.d8.loss_dice: 1.5136
2023/05/24 06:17:09 - mmengine - INFO - Iter(train) [ 97300/160000]  lr: 4.3036e-06  eta: 7:30:17  time: 0.4501  data_time: 0.0103  memory: 4835  grad_norm: 94.4428  loss: 38.1513  decode.loss_cls: 1.4759  decode.loss_mask: 0.7846  decode.loss_dice: 1.2629  decode.d0.loss_cls: 3.3706  decode.d0.loss_mask: 0.8277  decode.d0.loss_dice: 1.4545  decode.d1.loss_cls: 1.5645  decode.d1.loss_mask: 0.8022  decode.d1.loss_dice: 1.3707  decode.d2.loss_cls: 1.6140  decode.d2.loss_mask: 0.7757  decode.d2.loss_dice: 1.3133  decode.d3.loss_cls: 1.4688  decode.d3.loss_mask: 0.8079  decode.d3.loss_dice: 1.2908  decode.d4.loss_cls: 1.4768  decode.d4.loss_mask: 0.8086  decode.d4.loss_dice: 1.2824  decode.d5.loss_cls: 1.5152  decode.d5.loss_mask: 0.8066  decode.d5.loss_dice: 1.3069  decode.d6.loss_cls: 1.5189  decode.d6.loss_mask: 0.7971  decode.d6.loss_dice: 1.2956  decode.d7.loss_cls: 1.5038  decode.d7.loss_mask: 0.8047  decode.d7.loss_dice: 1.2931  decode.d8.loss_cls: 1.4958  decode.d8.loss_mask: 0.8075  decode.d8.loss_dice: 1.2539
2023/05/24 06:17:33 - mmengine - INFO - Iter(train) [ 97350/160000]  lr: 4.3005e-06  eta: 7:29:57  time: 0.4798  data_time: 0.0104  memory: 4812  grad_norm: 127.1503  loss: 35.3821  decode.loss_cls: 1.2102  decode.loss_mask: 0.7412  decode.loss_dice: 1.3380  decode.d0.loss_cls: 3.1425  decode.d0.loss_mask: 0.7586  decode.d0.loss_dice: 1.5117  decode.d1.loss_cls: 1.3836  decode.d1.loss_mask: 0.7759  decode.d1.loss_dice: 1.4076  decode.d2.loss_cls: 1.2665  decode.d2.loss_mask: 0.7718  decode.d2.loss_dice: 1.3754  decode.d3.loss_cls: 1.1751  decode.d3.loss_mask: 0.7569  decode.d3.loss_dice: 1.3432  decode.d4.loss_cls: 1.1754  decode.d4.loss_mask: 0.7519  decode.d4.loss_dice: 1.3461  decode.d5.loss_cls: 1.2034  decode.d5.loss_mask: 0.7636  decode.d5.loss_dice: 1.3408  decode.d6.loss_cls: 1.1886  decode.d6.loss_mask: 0.7426  decode.d6.loss_dice: 1.3661  decode.d7.loss_cls: 1.1976  decode.d7.loss_mask: 0.7554  decode.d7.loss_dice: 1.3186  decode.d8.loss_cls: 1.2245  decode.d8.loss_mask: 0.7236  decode.d8.loss_dice: 1.3258
2023/05/24 06:17:54 - mmengine - INFO - Iter(train) [ 97400/160000]  lr: 4.2975e-06  eta: 7:29:36  time: 0.4242  data_time: 0.0108  memory: 4857  grad_norm: 97.8959  loss: 32.8042  decode.loss_cls: 1.1100  decode.loss_mask: 0.8334  decode.loss_dice: 1.0375  decode.d0.loss_cls: 3.0759  decode.d0.loss_mask: 0.8901  decode.d0.loss_dice: 1.2406  decode.d1.loss_cls: 1.3701  decode.d1.loss_mask: 0.8183  decode.d1.loss_dice: 1.1423  decode.d2.loss_cls: 1.2929  decode.d2.loss_mask: 0.8222  decode.d2.loss_dice: 1.0625  decode.d3.loss_cls: 1.2114  decode.d3.loss_mask: 0.8336  decode.d3.loss_dice: 1.0521  decode.d4.loss_cls: 1.1520  decode.d4.loss_mask: 0.8183  decode.d4.loss_dice: 1.0647  decode.d5.loss_cls: 1.1780  decode.d5.loss_mask: 0.8002  decode.d5.loss_dice: 1.0450  decode.d6.loss_cls: 1.1179  decode.d6.loss_mask: 0.8241  decode.d6.loss_dice: 1.0448  decode.d7.loss_cls: 1.1217  decode.d7.loss_mask: 0.8301  decode.d7.loss_dice: 1.0483  decode.d8.loss_cls: 1.1137  decode.d8.loss_mask: 0.8146  decode.d8.loss_dice: 1.0378
2023/05/24 06:18:15 - mmengine - INFO - Iter(train) [ 97450/160000]  lr: 4.2944e-06  eta: 7:29:14  time: 0.4165  data_time: 0.0108  memory: 4833  grad_norm: 94.9709  loss: 40.1252  decode.loss_cls: 1.4419  decode.loss_mask: 0.7278  decode.loss_dice: 1.5225  decode.d0.loss_cls: 3.1523  decode.d0.loss_mask: 0.8698  decode.d0.loss_dice: 1.8960  decode.d1.loss_cls: 1.5852  decode.d1.loss_mask: 0.8210  decode.d1.loss_dice: 1.6547  decode.d2.loss_cls: 1.3926  decode.d2.loss_mask: 0.8066  decode.d2.loss_dice: 1.6453  decode.d3.loss_cls: 1.3980  decode.d3.loss_mask: 0.8090  decode.d3.loss_dice: 1.6000  decode.d4.loss_cls: 1.5022  decode.d4.loss_mask: 0.7743  decode.d4.loss_dice: 1.5916  decode.d5.loss_cls: 1.4734  decode.d5.loss_mask: 0.7446  decode.d5.loss_dice: 1.5324  decode.d6.loss_cls: 1.4384  decode.d6.loss_mask: 0.7542  decode.d6.loss_dice: 1.5417  decode.d7.loss_cls: 1.3739  decode.d7.loss_mask: 0.7725  decode.d7.loss_dice: 1.5612  decode.d8.loss_cls: 1.4397  decode.d8.loss_mask: 0.7550  decode.d8.loss_dice: 1.5475
2023/05/24 06:18:36 - mmengine - INFO - Iter(train) [ 97500/160000]  lr: 4.2913e-06  eta: 7:28:52  time: 0.4186  data_time: 0.0104  memory: 4857  grad_norm: 108.1122  loss: 30.6100  decode.loss_cls: 1.0300  decode.loss_mask: 0.6751  decode.loss_dice: 1.1064  decode.d0.loss_cls: 2.9879  decode.d0.loss_mask: 0.7234  decode.d0.loss_dice: 1.2177  decode.d1.loss_cls: 1.0898  decode.d1.loss_mask: 0.7131  decode.d1.loss_dice: 1.1939  decode.d2.loss_cls: 1.1134  decode.d2.loss_mask: 0.7340  decode.d2.loss_dice: 1.1437  decode.d3.loss_cls: 1.0902  decode.d3.loss_mask: 0.6885  decode.d3.loss_dice: 1.0800  decode.d4.loss_cls: 1.0414  decode.d4.loss_mask: 0.7089  decode.d4.loss_dice: 1.0786  decode.d5.loss_cls: 1.0811  decode.d5.loss_mask: 0.6919  decode.d5.loss_dice: 1.0725  decode.d6.loss_cls: 1.0695  decode.d6.loss_mask: 0.6545  decode.d6.loss_dice: 1.0946  decode.d7.loss_cls: 0.9919  decode.d7.loss_mask: 0.6906  decode.d7.loss_dice: 1.0684  decode.d8.loss_cls: 1.0249  decode.d8.loss_mask: 0.6564  decode.d8.loss_dice: 1.0980
2023/05/24 06:18:57 - mmengine - INFO - Iter(train) [ 97550/160000]  lr: 4.2882e-06  eta: 7:28:30  time: 0.4246  data_time: 0.0105  memory: 4857  grad_norm: 97.5744  loss: 34.2443  decode.loss_cls: 1.2442  decode.loss_mask: 0.7877  decode.loss_dice: 1.1094  decode.d0.loss_cls: 3.1847  decode.d0.loss_mask: 0.8313  decode.d0.loss_dice: 1.2493  decode.d1.loss_cls: 1.3503  decode.d1.loss_mask: 0.8341  decode.d1.loss_dice: 1.2306  decode.d2.loss_cls: 1.2960  decode.d2.loss_mask: 0.8531  decode.d2.loss_dice: 1.1825  decode.d3.loss_cls: 1.3027  decode.d3.loss_mask: 0.7765  decode.d3.loss_dice: 1.1415  decode.d4.loss_cls: 1.2846  decode.d4.loss_mask: 0.7990  decode.d4.loss_dice: 1.1398  decode.d5.loss_cls: 1.2299  decode.d5.loss_mask: 0.8057  decode.d5.loss_dice: 1.1285  decode.d6.loss_cls: 1.2608  decode.d6.loss_mask: 0.7567  decode.d6.loss_dice: 1.1066  decode.d7.loss_cls: 1.2663  decode.d7.loss_mask: 0.7829  decode.d7.loss_dice: 1.1090  decode.d8.loss_cls: 1.2712  decode.d8.loss_mask: 0.7926  decode.d8.loss_dice: 1.1367
2023/05/24 06:19:18 - mmengine - INFO - Iter(train) [ 97600/160000]  lr: 4.2851e-06  eta: 7:28:08  time: 0.4222  data_time: 0.0104  memory: 4899  grad_norm: 94.9752  loss: 37.9044  decode.loss_cls: 1.2947  decode.loss_mask: 0.9071  decode.loss_dice: 1.3124  decode.d0.loss_cls: 3.1558  decode.d0.loss_mask: 0.9950  decode.d0.loss_dice: 1.5496  decode.d1.loss_cls: 1.3501  decode.d1.loss_mask: 1.0211  decode.d1.loss_dice: 1.4537  decode.d2.loss_cls: 1.3543  decode.d2.loss_mask: 0.9304  decode.d2.loss_dice: 1.3907  decode.d3.loss_cls: 1.2721  decode.d3.loss_mask: 0.9674  decode.d3.loss_dice: 1.3186  decode.d4.loss_cls: 1.2172  decode.d4.loss_mask: 0.9529  decode.d4.loss_dice: 1.3414  decode.d5.loss_cls: 1.2049  decode.d5.loss_mask: 0.9663  decode.d5.loss_dice: 1.3388  decode.d6.loss_cls: 1.2923  decode.d6.loss_mask: 0.9154  decode.d6.loss_dice: 1.3185  decode.d7.loss_cls: 1.2980  decode.d7.loss_mask: 0.9304  decode.d7.loss_dice: 1.3088  decode.d8.loss_cls: 1.3053  decode.d8.loss_mask: 0.9224  decode.d8.loss_dice: 1.3188
2023/05/24 06:19:39 - mmengine - INFO - Iter(train) [ 97650/160000]  lr: 4.2820e-06  eta: 7:27:46  time: 0.4235  data_time: 0.0105  memory: 4857  grad_norm: 92.5047  loss: 33.0825  decode.loss_cls: 1.0959  decode.loss_mask: 0.7030  decode.loss_dice: 1.2164  decode.d0.loss_cls: 3.1088  decode.d0.loss_mask: 0.7205  decode.d0.loss_dice: 1.3630  decode.d1.loss_cls: 1.2823  decode.d1.loss_mask: 0.7396  decode.d1.loss_dice: 1.3248  decode.d2.loss_cls: 1.1744  decode.d2.loss_mask: 0.6900  decode.d2.loss_dice: 1.2365  decode.d3.loss_cls: 1.2026  decode.d3.loss_mask: 0.7128  decode.d3.loss_dice: 1.2026  decode.d4.loss_cls: 1.1563  decode.d4.loss_mask: 0.6990  decode.d4.loss_dice: 1.2150  decode.d5.loss_cls: 1.1531  decode.d5.loss_mask: 0.6890  decode.d5.loss_dice: 1.2034  decode.d6.loss_cls: 1.1092  decode.d6.loss_mask: 0.7359  decode.d6.loss_dice: 1.2143  decode.d7.loss_cls: 1.1471  decode.d7.loss_mask: 0.7086  decode.d7.loss_dice: 1.2016  decode.d8.loss_cls: 1.1557  decode.d8.loss_mask: 0.7092  decode.d8.loss_dice: 1.2120
2023/05/24 06:20:01 - mmengine - INFO - Iter(train) [ 97700/160000]  lr: 4.2789e-06  eta: 7:27:25  time: 0.4246  data_time: 0.0103  memory: 4844  grad_norm: 105.9706  loss: 32.2733  decode.loss_cls: 1.2649  decode.loss_mask: 0.7211  decode.loss_dice: 0.9705  decode.d0.loss_cls: 3.0294  decode.d0.loss_mask: 0.7924  decode.d0.loss_dice: 1.1791  decode.d1.loss_cls: 1.3545  decode.d1.loss_mask: 0.7598  decode.d1.loss_dice: 1.1332  decode.d2.loss_cls: 1.3649  decode.d2.loss_mask: 0.7268  decode.d2.loss_dice: 1.0716  decode.d3.loss_cls: 1.2987  decode.d3.loss_mask: 0.7374  decode.d3.loss_dice: 1.0115  decode.d4.loss_cls: 1.2760  decode.d4.loss_mask: 0.7276  decode.d4.loss_dice: 0.9895  decode.d5.loss_cls: 1.2466  decode.d5.loss_mask: 0.7221  decode.d5.loss_dice: 1.0133  decode.d6.loss_cls: 1.2598  decode.d6.loss_mask: 0.7160  decode.d6.loss_dice: 0.9877  decode.d7.loss_cls: 1.2575  decode.d7.loss_mask: 0.7009  decode.d7.loss_dice: 0.9767  decode.d8.loss_cls: 1.2657  decode.d8.loss_mask: 0.7270  decode.d8.loss_dice: 0.9910
2023/05/24 06:20:22 - mmengine - INFO - Iter(train) [ 97750/160000]  lr: 4.2758e-06  eta: 7:27:03  time: 0.4232  data_time: 0.0104  memory: 4868  grad_norm: 101.3865  loss: 33.7191  decode.loss_cls: 1.1548  decode.loss_mask: 0.7570  decode.loss_dice: 1.1664  decode.d0.loss_cls: 2.9926  decode.d0.loss_mask: 0.7996  decode.d0.loss_dice: 1.3284  decode.d1.loss_cls: 1.1924  decode.d1.loss_mask: 0.8396  decode.d1.loss_dice: 1.3146  decode.d2.loss_cls: 1.2150  decode.d2.loss_mask: 0.8187  decode.d2.loss_dice: 1.2372  decode.d3.loss_cls: 1.2604  decode.d3.loss_mask: 0.7828  decode.d3.loss_dice: 1.1958  decode.d4.loss_cls: 1.2104  decode.d4.loss_mask: 0.7787  decode.d4.loss_dice: 1.2159  decode.d5.loss_cls: 1.1262  decode.d5.loss_mask: 0.7881  decode.d5.loss_dice: 1.2080  decode.d6.loss_cls: 1.1267  decode.d6.loss_mask: 0.7822  decode.d6.loss_dice: 1.2029  decode.d7.loss_cls: 1.1446  decode.d7.loss_mask: 0.7684  decode.d7.loss_dice: 1.1956  decode.d8.loss_cls: 1.1096  decode.d8.loss_mask: 0.7911  decode.d8.loss_dice: 1.2154
2023/05/24 06:20:43 - mmengine - INFO - Iter(train) [ 97800/160000]  lr: 4.2727e-06  eta: 7:26:41  time: 0.4343  data_time: 0.0106  memory: 4788  grad_norm: 99.0046  loss: 31.6878  decode.loss_cls: 1.0538  decode.loss_mask: 0.6658  decode.loss_dice: 1.1712  decode.d0.loss_cls: 2.8313  decode.d0.loss_mask: 0.7970  decode.d0.loss_dice: 1.3558  decode.d1.loss_cls: 1.2519  decode.d1.loss_mask: 0.6944  decode.d1.loss_dice: 1.2369  decode.d2.loss_cls: 1.2728  decode.d2.loss_mask: 0.6512  decode.d2.loss_dice: 1.1977  decode.d3.loss_cls: 1.2303  decode.d3.loss_mask: 0.6397  decode.d3.loss_dice: 1.1251  decode.d4.loss_cls: 1.1224  decode.d4.loss_mask: 0.6523  decode.d4.loss_dice: 1.1580  decode.d5.loss_cls: 1.0902  decode.d5.loss_mask: 0.6545  decode.d5.loss_dice: 1.1477  decode.d6.loss_cls: 1.0930  decode.d6.loss_mask: 0.6711  decode.d6.loss_dice: 1.1662  decode.d7.loss_cls: 1.0554  decode.d7.loss_mask: 0.6657  decode.d7.loss_dice: 1.1414  decode.d8.loss_cls: 1.0841  decode.d8.loss_mask: 0.6495  decode.d8.loss_dice: 1.1617
2023/05/24 06:21:07 - mmengine - INFO - Iter(train) [ 97850/160000]  lr: 4.2696e-06  eta: 7:26:21  time: 0.4424  data_time: 0.0102  memory: 4857  grad_norm: 105.5755  loss: 30.0136  decode.loss_cls: 1.0029  decode.loss_mask: 0.5096  decode.loss_dice: 1.1851  decode.d0.loss_cls: 2.8540  decode.d0.loss_mask: 0.5798  decode.d0.loss_dice: 1.4257  decode.d1.loss_cls: 1.1561  decode.d1.loss_mask: 0.5426  decode.d1.loss_dice: 1.3064  decode.d2.loss_cls: 1.1696  decode.d2.loss_mask: 0.4881  decode.d2.loss_dice: 1.2310  decode.d3.loss_cls: 1.0685  decode.d3.loss_mask: 0.5213  decode.d3.loss_dice: 1.2319  decode.d4.loss_cls: 1.0634  decode.d4.loss_mask: 0.4916  decode.d4.loss_dice: 1.2009  decode.d5.loss_cls: 1.0710  decode.d5.loss_mask: 0.4881  decode.d5.loss_dice: 1.2239  decode.d6.loss_cls: 1.0156  decode.d6.loss_mask: 0.5087  decode.d6.loss_dice: 1.2321  decode.d7.loss_cls: 1.0186  decode.d7.loss_mask: 0.5050  decode.d7.loss_dice: 1.2175  decode.d8.loss_cls: 1.0058  decode.d8.loss_mask: 0.5083  decode.d8.loss_dice: 1.1903
2023/05/24 06:21:28 - mmengine - INFO - Iter(train) [ 97900/160000]  lr: 4.2666e-06  eta: 7:25:59  time: 0.4209  data_time: 0.0105  memory: 4824  grad_norm: 93.4986  loss: 31.7587  decode.loss_cls: 1.1918  decode.loss_mask: 0.5661  decode.loss_dice: 1.0789  decode.d0.loss_cls: 3.3903  decode.d0.loss_mask: 0.6368  decode.d0.loss_dice: 1.3467  decode.d1.loss_cls: 1.3721  decode.d1.loss_mask: 0.6149  decode.d1.loss_dice: 1.2129  decode.d2.loss_cls: 1.2828  decode.d2.loss_mask: 0.6076  decode.d2.loss_dice: 1.1816  decode.d3.loss_cls: 1.1846  decode.d3.loss_mask: 0.5774  decode.d3.loss_dice: 1.1098  decode.d4.loss_cls: 1.2058  decode.d4.loss_mask: 0.5779  decode.d4.loss_dice: 1.0988  decode.d5.loss_cls: 1.2579  decode.d5.loss_mask: 0.5711  decode.d5.loss_dice: 1.1495  decode.d6.loss_cls: 1.2045  decode.d6.loss_mask: 0.5681  decode.d6.loss_dice: 1.0886  decode.d7.loss_cls: 1.1901  decode.d7.loss_mask: 0.5615  decode.d7.loss_dice: 1.0932  decode.d8.loss_cls: 1.1939  decode.d8.loss_mask: 0.5575  decode.d8.loss_dice: 1.0859
2023/05/24 06:21:50 - mmengine - INFO - Iter(train) [ 97950/160000]  lr: 4.2635e-06  eta: 7:25:38  time: 0.4159  data_time: 0.0104  memory: 4860  grad_norm: 86.1418  loss: 26.6005  decode.loss_cls: 0.8140  decode.loss_mask: 0.6206  decode.loss_dice: 1.0010  decode.d0.loss_cls: 2.5932  decode.d0.loss_mask: 0.6534  decode.d0.loss_dice: 1.1126  decode.d1.loss_cls: 0.9043  decode.d1.loss_mask: 0.6455  decode.d1.loss_dice: 1.0980  decode.d2.loss_cls: 0.9247  decode.d2.loss_mask: 0.6017  decode.d2.loss_dice: 1.0490  decode.d3.loss_cls: 0.8878  decode.d3.loss_mask: 0.5917  decode.d3.loss_dice: 0.9965  decode.d4.loss_cls: 0.8492  decode.d4.loss_mask: 0.5932  decode.d4.loss_dice: 1.0030  decode.d5.loss_cls: 0.8655  decode.d5.loss_mask: 0.5868  decode.d5.loss_dice: 0.9802  decode.d6.loss_cls: 0.8507  decode.d6.loss_mask: 0.5936  decode.d6.loss_dice: 0.9796  decode.d7.loss_cls: 0.7896  decode.d7.loss_mask: 0.6124  decode.d7.loss_dice: 0.9827  decode.d8.loss_cls: 0.8410  decode.d8.loss_mask: 0.5842  decode.d8.loss_dice: 0.9946
2023/05/24 06:22:11 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 06:22:11 - mmengine - INFO - Iter(train) [ 98000/160000]  lr: 4.2604e-06  eta: 7:25:16  time: 0.4671  data_time: 0.0102  memory: 4877  grad_norm: 119.6731  loss: 33.8854  decode.loss_cls: 1.2927  decode.loss_mask: 0.7196  decode.loss_dice: 1.1288  decode.d0.loss_cls: 3.1199  decode.d0.loss_mask: 0.7427  decode.d0.loss_dice: 1.3253  decode.d1.loss_cls: 1.3604  decode.d1.loss_mask: 0.7709  decode.d1.loss_dice: 1.2465  decode.d2.loss_cls: 1.3209  decode.d2.loss_mask: 0.7316  decode.d2.loss_dice: 1.1899  decode.d3.loss_cls: 1.3257  decode.d3.loss_mask: 0.7093  decode.d3.loss_dice: 1.1559  decode.d4.loss_cls: 1.3176  decode.d4.loss_mask: 0.6982  decode.d4.loss_dice: 1.1631  decode.d5.loss_cls: 1.3600  decode.d5.loss_mask: 0.6847  decode.d5.loss_dice: 1.1226  decode.d6.loss_cls: 1.2261  decode.d6.loss_mask: 0.7288  decode.d6.loss_dice: 1.1733  decode.d7.loss_cls: 1.2761  decode.d7.loss_mask: 0.7339  decode.d7.loss_dice: 1.1505  decode.d8.loss_cls: 1.2913  decode.d8.loss_mask: 0.7050  decode.d8.loss_dice: 1.1141
2023/05/24 06:22:11 - mmengine - INFO - Saving checkpoint at 98000 iterations
2023/05/24 06:22:41 - mmengine - INFO - Iter(train) [ 98050/160000]  lr: 4.2573e-06  eta: 7:25:00  time: 0.4601  data_time: 0.0107  memory: 4899  grad_norm: 122.5567  loss: 32.6666  decode.loss_cls: 0.9482  decode.loss_mask: 0.8114  decode.loss_dice: 1.2075  decode.d0.loss_cls: 3.1432  decode.d0.loss_mask: 0.8584  decode.d0.loss_dice: 1.3680  decode.d1.loss_cls: 1.0923  decode.d1.loss_mask: 0.8725  decode.d1.loss_dice: 1.2553  decode.d2.loss_cls: 1.0101  decode.d2.loss_mask: 0.8490  decode.d2.loss_dice: 1.2395  decode.d3.loss_cls: 1.0048  decode.d3.loss_mask: 0.8289  decode.d3.loss_dice: 1.1998  decode.d4.loss_cls: 0.9760  decode.d4.loss_mask: 0.8190  decode.d4.loss_dice: 1.2377  decode.d5.loss_cls: 0.9687  decode.d5.loss_mask: 0.8298  decode.d5.loss_dice: 1.2195  decode.d6.loss_cls: 0.9001  decode.d6.loss_mask: 0.8379  decode.d6.loss_dice: 1.2301  decode.d7.loss_cls: 0.8719  decode.d7.loss_mask: 0.8421  decode.d7.loss_dice: 1.2583  decode.d8.loss_cls: 0.9186  decode.d8.loss_mask: 0.8402  decode.d8.loss_dice: 1.2280
2023/05/24 06:23:02 - mmengine - INFO - Iter(train) [ 98100/160000]  lr: 4.2542e-06  eta: 7:24:38  time: 0.4148  data_time: 0.0104  memory: 4868  grad_norm: 113.5712  loss: 44.9462  decode.loss_cls: 1.6455  decode.loss_mask: 0.9153  decode.loss_dice: 1.5507  decode.d0.loss_cls: 3.5833  decode.d0.loss_mask: 1.0294  decode.d0.loss_dice: 1.8932  decode.d1.loss_cls: 1.7767  decode.d1.loss_mask: 1.0244  decode.d1.loss_dice: 1.7875  decode.d2.loss_cls: 1.7015  decode.d2.loss_mask: 1.0098  decode.d2.loss_dice: 1.6674  decode.d3.loss_cls: 1.6684  decode.d3.loss_mask: 0.9661  decode.d3.loss_dice: 1.6184  decode.d4.loss_cls: 1.6439  decode.d4.loss_mask: 0.9543  decode.d4.loss_dice: 1.6151  decode.d5.loss_cls: 1.6939  decode.d5.loss_mask: 0.9717  decode.d5.loss_dice: 1.6241  decode.d6.loss_cls: 1.7034  decode.d6.loss_mask: 0.9499  decode.d6.loss_dice: 1.5716  decode.d7.loss_cls: 1.7212  decode.d7.loss_mask: 0.9416  decode.d7.loss_dice: 1.5958  decode.d8.loss_cls: 1.6320  decode.d8.loss_mask: 0.9391  decode.d8.loss_dice: 1.5507
2023/05/24 06:23:22 - mmengine - INFO - Iter(train) [ 98150/160000]  lr: 4.2511e-06  eta: 7:24:16  time: 0.4167  data_time: 0.0112  memory: 4876  grad_norm: 96.5407  loss: 40.5020  decode.loss_cls: 1.1630  decode.loss_mask: 0.8462  decode.loss_dice: 1.6726  decode.d0.loss_cls: 3.1486  decode.d0.loss_mask: 0.8940  decode.d0.loss_dice: 1.9946  decode.d1.loss_cls: 1.3872  decode.d1.loss_mask: 0.8583  decode.d1.loss_dice: 1.8804  decode.d2.loss_cls: 1.2462  decode.d2.loss_mask: 0.8518  decode.d2.loss_dice: 1.8058  decode.d3.loss_cls: 1.2988  decode.d3.loss_mask: 0.8014  decode.d3.loss_dice: 1.7187  decode.d4.loss_cls: 1.2481  decode.d4.loss_mask: 0.8182  decode.d4.loss_dice: 1.7477  decode.d5.loss_cls: 1.2597  decode.d5.loss_mask: 0.8731  decode.d5.loss_dice: 1.7214  decode.d6.loss_cls: 1.1753  decode.d6.loss_mask: 0.8791  decode.d6.loss_dice: 1.7022  decode.d7.loss_cls: 1.2170  decode.d7.loss_mask: 0.8178  decode.d7.loss_dice: 1.6987  decode.d8.loss_cls: 1.2356  decode.d8.loss_mask: 0.8432  decode.d8.loss_dice: 1.6973
2023/05/24 06:23:44 - mmengine - INFO - Iter(train) [ 98200/160000]  lr: 4.2480e-06  eta: 7:23:54  time: 0.4234  data_time: 0.0106  memory: 4802  grad_norm: 122.3935  loss: 30.7932  decode.loss_cls: 1.0148  decode.loss_mask: 0.6340  decode.loss_dice: 1.1234  decode.d0.loss_cls: 3.1214  decode.d0.loss_mask: 0.7221  decode.d0.loss_dice: 1.3655  decode.d1.loss_cls: 1.1102  decode.d1.loss_mask: 0.6863  decode.d1.loss_dice: 1.2340  decode.d2.loss_cls: 1.0518  decode.d2.loss_mask: 0.6568  decode.d2.loss_dice: 1.1464  decode.d3.loss_cls: 1.0296  decode.d3.loss_mask: 0.6586  decode.d3.loss_dice: 1.1686  decode.d4.loss_cls: 1.0012  decode.d4.loss_mask: 0.6502  decode.d4.loss_dice: 1.1743  decode.d5.loss_cls: 1.0208  decode.d5.loss_mask: 0.6405  decode.d5.loss_dice: 1.1661  decode.d6.loss_cls: 1.0132  decode.d6.loss_mask: 0.6382  decode.d6.loss_dice: 1.1474  decode.d7.loss_cls: 1.0416  decode.d7.loss_mask: 0.6400  decode.d7.loss_dice: 1.1470  decode.d8.loss_cls: 1.0452  decode.d8.loss_mask: 0.6326  decode.d8.loss_dice: 1.1113
2023/05/24 06:24:05 - mmengine - INFO - Iter(train) [ 98250/160000]  lr: 4.2449e-06  eta: 7:23:32  time: 0.4241  data_time: 0.0104  memory: 4839  grad_norm: 129.9890  loss: 36.9163  decode.loss_cls: 1.3752  decode.loss_mask: 0.7811  decode.loss_dice: 1.2625  decode.d0.loss_cls: 3.4463  decode.d0.loss_mask: 0.7989  decode.d0.loss_dice: 1.4407  decode.d1.loss_cls: 1.4981  decode.d1.loss_mask: 0.8110  decode.d1.loss_dice: 1.2970  decode.d2.loss_cls: 1.4450  decode.d2.loss_mask: 0.7990  decode.d2.loss_dice: 1.3091  decode.d3.loss_cls: 1.4887  decode.d3.loss_mask: 0.7790  decode.d3.loss_dice: 1.2642  decode.d4.loss_cls: 1.4104  decode.d4.loss_mask: 0.7810  decode.d4.loss_dice: 1.2746  decode.d5.loss_cls: 1.3915  decode.d5.loss_mask: 0.7755  decode.d5.loss_dice: 1.2817  decode.d6.loss_cls: 1.3684  decode.d6.loss_mask: 0.7931  decode.d6.loss_dice: 1.2694  decode.d7.loss_cls: 1.3294  decode.d7.loss_mask: 0.7932  decode.d7.loss_dice: 1.2758  decode.d8.loss_cls: 1.3305  decode.d8.loss_mask: 0.7785  decode.d8.loss_dice: 1.2674
2023/05/24 06:24:26 - mmengine - INFO - Iter(train) [ 98300/160000]  lr: 4.2418e-06  eta: 7:23:10  time: 0.4232  data_time: 0.0109  memory: 4780  grad_norm: 97.7542  loss: 35.3034  decode.loss_cls: 1.3638  decode.loss_mask: 0.5326  decode.loss_dice: 1.3197  decode.d0.loss_cls: 3.0598  decode.d0.loss_mask: 0.6252  decode.d0.loss_dice: 1.5558  decode.d1.loss_cls: 1.4637  decode.d1.loss_mask: 0.6434  decode.d1.loss_dice: 1.4552  decode.d2.loss_cls: 1.4944  decode.d2.loss_mask: 0.5709  decode.d2.loss_dice: 1.3307  decode.d3.loss_cls: 1.4478  decode.d3.loss_mask: 0.6134  decode.d3.loss_dice: 1.3629  decode.d4.loss_cls: 1.4101  decode.d4.loss_mask: 0.6114  decode.d4.loss_dice: 1.3809  decode.d5.loss_cls: 1.4212  decode.d5.loss_mask: 0.5659  decode.d5.loss_dice: 1.3239  decode.d6.loss_cls: 1.3988  decode.d6.loss_mask: 0.5424  decode.d6.loss_dice: 1.3279  decode.d7.loss_cls: 1.3781  decode.d7.loss_mask: 0.5629  decode.d7.loss_dice: 1.3076  decode.d8.loss_cls: 1.3953  decode.d8.loss_mask: 0.5318  decode.d8.loss_dice: 1.3057
2023/05/24 06:24:48 - mmengine - INFO - Iter(train) [ 98350/160000]  lr: 4.2387e-06  eta: 7:22:49  time: 0.4345  data_time: 0.0106  memory: 4929  grad_norm: 88.7393  loss: 35.5333  decode.loss_cls: 1.2966  decode.loss_mask: 0.8193  decode.loss_dice: 1.1509  decode.d0.loss_cls: 3.3977  decode.d0.loss_mask: 0.8973  decode.d0.loss_dice: 1.4016  decode.d1.loss_cls: 1.4580  decode.d1.loss_mask: 0.8310  decode.d1.loss_dice: 1.2462  decode.d2.loss_cls: 1.3964  decode.d2.loss_mask: 0.8073  decode.d2.loss_dice: 1.2023  decode.d3.loss_cls: 1.2828  decode.d3.loss_mask: 0.8181  decode.d3.loss_dice: 1.1562  decode.d4.loss_cls: 1.3108  decode.d4.loss_mask: 0.8003  decode.d4.loss_dice: 1.1674  decode.d5.loss_cls: 1.2796  decode.d5.loss_mask: 0.8004  decode.d5.loss_dice: 1.1898  decode.d6.loss_cls: 1.3230  decode.d6.loss_mask: 0.7756  decode.d6.loss_dice: 1.1798  decode.d7.loss_cls: 1.3090  decode.d7.loss_mask: 0.7890  decode.d7.loss_dice: 1.1702  decode.d8.loss_cls: 1.3248  decode.d8.loss_mask: 0.7944  decode.d8.loss_dice: 1.1575
2023/05/24 06:25:10 - mmengine - INFO - Iter(train) [ 98400/160000]  lr: 4.2356e-06  eta: 7:22:28  time: 0.4763  data_time: 0.0102  memory: 4859  grad_norm: 110.0710  loss: 47.1692  decode.loss_cls: 1.5742  decode.loss_mask: 1.0392  decode.loss_dice: 1.7237  decode.d0.loss_cls: 3.7180  decode.d0.loss_mask: 1.1057  decode.d0.loss_dice: 2.1483  decode.d1.loss_cls: 1.7210  decode.d1.loss_mask: 1.1040  decode.d1.loss_dice: 1.8861  decode.d2.loss_cls: 1.6853  decode.d2.loss_mask: 1.0468  decode.d2.loss_dice: 1.8299  decode.d3.loss_cls: 1.6486  decode.d3.loss_mask: 1.0800  decode.d3.loss_dice: 1.7779  decode.d4.loss_cls: 1.5640  decode.d4.loss_mask: 1.0913  decode.d4.loss_dice: 1.7707  decode.d5.loss_cls: 1.6486  decode.d5.loss_mask: 1.0575  decode.d5.loss_dice: 1.7535  decode.d6.loss_cls: 1.5740  decode.d6.loss_mask: 1.0809  decode.d6.loss_dice: 1.7466  decode.d7.loss_cls: 1.5744  decode.d7.loss_mask: 1.0812  decode.d7.loss_dice: 1.7585  decode.d8.loss_cls: 1.5325  decode.d8.loss_mask: 1.0749  decode.d8.loss_dice: 1.7717
2023/05/24 06:25:33 - mmengine - INFO - Iter(train) [ 98450/160000]  lr: 4.2325e-06  eta: 7:22:07  time: 0.4293  data_time: 0.0104  memory: 4822  grad_norm: 93.9785  loss: 31.8196  decode.loss_cls: 1.0877  decode.loss_mask: 0.7039  decode.loss_dice: 1.0622  decode.d0.loss_cls: 3.0898  decode.d0.loss_mask: 0.7523  decode.d0.loss_dice: 1.2118  decode.d1.loss_cls: 1.2487  decode.d1.loss_mask: 0.7484  decode.d1.loss_dice: 1.1856  decode.d2.loss_cls: 1.2577  decode.d2.loss_mask: 0.7775  decode.d2.loss_dice: 1.1168  decode.d3.loss_cls: 1.1917  decode.d3.loss_mask: 0.7417  decode.d3.loss_dice: 1.1059  decode.d4.loss_cls: 1.1081  decode.d4.loss_mask: 0.7392  decode.d4.loss_dice: 1.0904  decode.d5.loss_cls: 1.1147  decode.d5.loss_mask: 0.7146  decode.d5.loss_dice: 1.0883  decode.d6.loss_cls: 1.1420  decode.d6.loss_mask: 0.7067  decode.d6.loss_dice: 1.0697  decode.d7.loss_cls: 1.1051  decode.d7.loss_mask: 0.7153  decode.d7.loss_dice: 1.0677  decode.d8.loss_cls: 1.1149  decode.d8.loss_mask: 0.7085  decode.d8.loss_dice: 1.0528
2023/05/24 06:25:55 - mmengine - INFO - Iter(train) [ 98500/160000]  lr: 4.2294e-06  eta: 7:21:46  time: 0.4365  data_time: 0.0109  memory: 4856  grad_norm: 96.0578  loss: 34.8912  decode.loss_cls: 1.1476  decode.loss_mask: 0.7311  decode.loss_dice: 1.3247  decode.d0.loss_cls: 3.1613  decode.d0.loss_mask: 0.7285  decode.d0.loss_dice: 1.5122  decode.d1.loss_cls: 1.2885  decode.d1.loss_mask: 0.7476  decode.d1.loss_dice: 1.4970  decode.d2.loss_cls: 1.2652  decode.d2.loss_mask: 0.7469  decode.d2.loss_dice: 1.4174  decode.d3.loss_cls: 1.1742  decode.d3.loss_mask: 0.7192  decode.d3.loss_dice: 1.3269  decode.d4.loss_cls: 1.1885  decode.d4.loss_mask: 0.7271  decode.d4.loss_dice: 1.3590  decode.d5.loss_cls: 1.1924  decode.d5.loss_mask: 0.7230  decode.d5.loss_dice: 1.3366  decode.d6.loss_cls: 1.1715  decode.d6.loss_mask: 0.7263  decode.d6.loss_dice: 1.3081  decode.d7.loss_cls: 1.1300  decode.d7.loss_mask: 0.7229  decode.d7.loss_dice: 1.3199  decode.d8.loss_cls: 1.1377  decode.d8.loss_mask: 0.7262  decode.d8.loss_dice: 1.3338
2023/05/24 06:26:17 - mmengine - INFO - Iter(train) [ 98550/160000]  lr: 4.2263e-06  eta: 7:21:25  time: 0.4259  data_time: 0.0105  memory: 4836  grad_norm: 123.9694  loss: 38.8943  decode.loss_cls: 1.1651  decode.loss_mask: 0.8898  decode.loss_dice: 1.5076  decode.d0.loss_cls: 3.2764  decode.d0.loss_mask: 0.9046  decode.d0.loss_dice: 1.7633  decode.d1.loss_cls: 1.3489  decode.d1.loss_mask: 0.9124  decode.d1.loss_dice: 1.6520  decode.d2.loss_cls: 1.3280  decode.d2.loss_mask: 0.8797  decode.d2.loss_dice: 1.5681  decode.d3.loss_cls: 1.2421  decode.d3.loss_mask: 0.8600  decode.d3.loss_dice: 1.5461  decode.d4.loss_cls: 1.1815  decode.d4.loss_mask: 0.8568  decode.d4.loss_dice: 1.5683  decode.d5.loss_cls: 1.2412  decode.d5.loss_mask: 0.8541  decode.d5.loss_dice: 1.5380  decode.d6.loss_cls: 1.2369  decode.d6.loss_mask: 0.8624  decode.d6.loss_dice: 1.5090  decode.d7.loss_cls: 1.1648  decode.d7.loss_mask: 0.8937  decode.d7.loss_dice: 1.5578  decode.d8.loss_cls: 1.1913  decode.d8.loss_mask: 0.8781  decode.d8.loss_dice: 1.5162
2023/05/24 06:26:38 - mmengine - INFO - Iter(train) [ 98600/160000]  lr: 4.2232e-06  eta: 7:21:03  time: 0.4183  data_time: 0.0109  memory: 4871  grad_norm: 104.5781  loss: 28.0919  decode.loss_cls: 0.9947  decode.loss_mask: 0.6387  decode.loss_dice: 0.9376  decode.d0.loss_cls: 2.8877  decode.d0.loss_mask: 0.6653  decode.d0.loss_dice: 1.0630  decode.d1.loss_cls: 1.0908  decode.d1.loss_mask: 0.6573  decode.d1.loss_dice: 0.9883  decode.d2.loss_cls: 1.0156  decode.d2.loss_mask: 0.6740  decode.d2.loss_dice: 0.9462  decode.d3.loss_cls: 0.9601  decode.d3.loss_mask: 0.6903  decode.d3.loss_dice: 0.9413  decode.d4.loss_cls: 0.9939  decode.d4.loss_mask: 0.6560  decode.d4.loss_dice: 0.9408  decode.d5.loss_cls: 0.9678  decode.d5.loss_mask: 0.7059  decode.d5.loss_dice: 0.9622  decode.d6.loss_cls: 0.9507  decode.d6.loss_mask: 0.6764  decode.d6.loss_dice: 0.9368  decode.d7.loss_cls: 0.9164  decode.d7.loss_mask: 0.7028  decode.d7.loss_dice: 0.9597  decode.d8.loss_cls: 0.9536  decode.d8.loss_mask: 0.6740  decode.d8.loss_dice: 0.9444
2023/05/24 06:27:00 - mmengine - INFO - Iter(train) [ 98650/160000]  lr: 4.2201e-06  eta: 7:20:41  time: 0.4207  data_time: 0.0105  memory: 4821  grad_norm: 86.7148  loss: 31.2940  decode.loss_cls: 1.2454  decode.loss_mask: 0.6639  decode.loss_dice: 0.9918  decode.d0.loss_cls: 2.9131  decode.d0.loss_mask: 0.7365  decode.d0.loss_dice: 1.1624  decode.d1.loss_cls: 1.3660  decode.d1.loss_mask: 0.7086  decode.d1.loss_dice: 1.0624  decode.d2.loss_cls: 1.3299  decode.d2.loss_mask: 0.6680  decode.d2.loss_dice: 1.0175  decode.d3.loss_cls: 1.2979  decode.d3.loss_mask: 0.6408  decode.d3.loss_dice: 0.9792  decode.d4.loss_cls: 1.2290  decode.d4.loss_mask: 0.6454  decode.d4.loss_dice: 0.9816  decode.d5.loss_cls: 1.2432  decode.d5.loss_mask: 0.6657  decode.d5.loss_dice: 1.0011  decode.d6.loss_cls: 1.2516  decode.d6.loss_mask: 0.6636  decode.d6.loss_dice: 0.9792  decode.d7.loss_cls: 1.2765  decode.d7.loss_mask: 0.6648  decode.d7.loss_dice: 0.9652  decode.d8.loss_cls: 1.2972  decode.d8.loss_mask: 0.6790  decode.d8.loss_dice: 0.9677
2023/05/24 06:27:21 - mmengine - INFO - Iter(train) [ 98700/160000]  lr: 4.2171e-06  eta: 7:20:19  time: 0.4240  data_time: 0.0105  memory: 4849  grad_norm: 107.2996  loss: 29.6526  decode.loss_cls: 0.9082  decode.loss_mask: 0.8090  decode.loss_dice: 1.0652  decode.d0.loss_cls: 2.6355  decode.d0.loss_mask: 0.8191  decode.d0.loss_dice: 1.2029  decode.d1.loss_cls: 0.9280  decode.d1.loss_mask: 0.8119  decode.d1.loss_dice: 1.1277  decode.d2.loss_cls: 0.8791  decode.d2.loss_mask: 0.7864  decode.d2.loss_dice: 1.0757  decode.d3.loss_cls: 0.9018  decode.d3.loss_mask: 0.7886  decode.d3.loss_dice: 1.0671  decode.d4.loss_cls: 0.9341  decode.d4.loss_mask: 0.7919  decode.d4.loss_dice: 1.0714  decode.d5.loss_cls: 0.8356  decode.d5.loss_mask: 0.8252  decode.d5.loss_dice: 1.0706  decode.d6.loss_cls: 0.8802  decode.d6.loss_mask: 0.8257  decode.d6.loss_dice: 1.0687  decode.d7.loss_cls: 0.8434  decode.d7.loss_mask: 0.8244  decode.d7.loss_dice: 1.0861  decode.d8.loss_cls: 0.8785  decode.d8.loss_mask: 0.8209  decode.d8.loss_dice: 1.0900
2023/05/24 06:27:42 - mmengine - INFO - Iter(train) [ 98750/160000]  lr: 4.2140e-06  eta: 7:19:57  time: 0.4201  data_time: 0.0102  memory: 4837  grad_norm: 95.7778  loss: 38.8295  decode.loss_cls: 1.2131  decode.loss_mask: 0.8753  decode.loss_dice: 1.4868  decode.d0.loss_cls: 3.2391  decode.d0.loss_mask: 0.8974  decode.d0.loss_dice: 1.7296  decode.d1.loss_cls: 1.3341  decode.d1.loss_mask: 0.8943  decode.d1.loss_dice: 1.6286  decode.d2.loss_cls: 1.2601  decode.d2.loss_mask: 0.9054  decode.d2.loss_dice: 1.5960  decode.d3.loss_cls: 1.2012  decode.d3.loss_mask: 0.9390  decode.d3.loss_dice: 1.5606  decode.d4.loss_cls: 1.2107  decode.d4.loss_mask: 0.8835  decode.d4.loss_dice: 1.5183  decode.d5.loss_cls: 1.2501  decode.d5.loss_mask: 0.8552  decode.d5.loss_dice: 1.5472  decode.d6.loss_cls: 1.2741  decode.d6.loss_mask: 0.8334  decode.d6.loss_dice: 1.4911  decode.d7.loss_cls: 1.2720  decode.d7.loss_mask: 0.8209  decode.d7.loss_dice: 1.5062  decode.d8.loss_cls: 1.2623  decode.d8.loss_mask: 0.8300  decode.d8.loss_dice: 1.5141
2023/05/24 06:28:03 - mmengine - INFO - Iter(train) [ 98800/160000]  lr: 4.2109e-06  eta: 7:19:35  time: 0.4311  data_time: 0.0110  memory: 4836  grad_norm: 102.4812  loss: 37.8259  decode.loss_cls: 1.5078  decode.loss_mask: 0.8835  decode.loss_dice: 1.1069  decode.d0.loss_cls: 3.2598  decode.d0.loss_mask: 0.9466  decode.d0.loss_dice: 1.3785  decode.d1.loss_cls: 1.6033  decode.d1.loss_mask: 0.9386  decode.d1.loss_dice: 1.2737  decode.d2.loss_cls: 1.5863  decode.d2.loss_mask: 0.9114  decode.d2.loss_dice: 1.1433  decode.d3.loss_cls: 1.5223  decode.d3.loss_mask: 0.9127  decode.d3.loss_dice: 1.1515  decode.d4.loss_cls: 1.5053  decode.d4.loss_mask: 0.8967  decode.d4.loss_dice: 1.1573  decode.d5.loss_cls: 1.4953  decode.d5.loss_mask: 0.8977  decode.d5.loss_dice: 1.1280  decode.d6.loss_cls: 1.5615  decode.d6.loss_mask: 0.8727  decode.d6.loss_dice: 1.1114  decode.d7.loss_cls: 1.5456  decode.d7.loss_mask: 0.8873  decode.d7.loss_dice: 1.1229  decode.d8.loss_cls: 1.5139  decode.d8.loss_mask: 0.8947  decode.d8.loss_dice: 1.1095
2023/05/24 06:28:25 - mmengine - INFO - Iter(train) [ 98850/160000]  lr: 4.2078e-06  eta: 7:19:14  time: 0.4252  data_time: 0.0115  memory: 4872  grad_norm: 96.7686  loss: 35.9406  decode.loss_cls: 1.1742  decode.loss_mask: 0.7852  decode.loss_dice: 1.3018  decode.d0.loss_cls: 3.2946  decode.d0.loss_mask: 0.8336  decode.d0.loss_dice: 1.4590  decode.d1.loss_cls: 1.4342  decode.d1.loss_mask: 0.8533  decode.d1.loss_dice: 1.4033  decode.d2.loss_cls: 1.2433  decode.d2.loss_mask: 0.8048  decode.d2.loss_dice: 1.3661  decode.d3.loss_cls: 1.3180  decode.d3.loss_mask: 0.8103  decode.d3.loss_dice: 1.3326  decode.d4.loss_cls: 1.2728  decode.d4.loss_mask: 0.8019  decode.d4.loss_dice: 1.2959  decode.d5.loss_cls: 1.1906  decode.d5.loss_mask: 0.7821  decode.d5.loss_dice: 1.2669  decode.d6.loss_cls: 1.3291  decode.d6.loss_mask: 0.7669  decode.d6.loss_dice: 1.2783  decode.d7.loss_cls: 1.2733  decode.d7.loss_mask: 0.7654  decode.d7.loss_dice: 1.2869  decode.d8.loss_cls: 1.1328  decode.d8.loss_mask: 0.7690  decode.d8.loss_dice: 1.3147
2023/05/24 06:28:46 - mmengine - INFO - Iter(train) [ 98900/160000]  lr: 4.2047e-06  eta: 7:18:52  time: 0.4188  data_time: 0.0104  memory: 4943  grad_norm: 113.2027  loss: 28.0447  decode.loss_cls: 0.9232  decode.loss_mask: 0.6642  decode.loss_dice: 0.9581  decode.d0.loss_cls: 3.0029  decode.d0.loss_mask: 0.6657  decode.d0.loss_dice: 1.1187  decode.d1.loss_cls: 0.9544  decode.d1.loss_mask: 0.7077  decode.d1.loss_dice: 1.0853  decode.d2.loss_cls: 1.0136  decode.d2.loss_mask: 0.6570  decode.d2.loss_dice: 0.9946  decode.d3.loss_cls: 0.9311  decode.d3.loss_mask: 0.6809  decode.d3.loss_dice: 0.9613  decode.d4.loss_cls: 0.9637  decode.d4.loss_mask: 0.6759  decode.d4.loss_dice: 0.9921  decode.d5.loss_cls: 0.9034  decode.d5.loss_mask: 0.6598  decode.d5.loss_dice: 0.9668  decode.d6.loss_cls: 0.8897  decode.d6.loss_mask: 0.6457  decode.d6.loss_dice: 0.9831  decode.d7.loss_cls: 0.8761  decode.d7.loss_mask: 0.6469  decode.d7.loss_dice: 0.9799  decode.d8.loss_cls: 0.9509  decode.d8.loss_mask: 0.6395  decode.d8.loss_dice: 0.9526
2023/05/24 06:29:07 - mmengine - INFO - Iter(train) [ 98950/160000]  lr: 4.2016e-06  eta: 7:18:31  time: 0.4274  data_time: 0.0104  memory: 4875  grad_norm: 93.8432  loss: 35.1332  decode.loss_cls: 1.1058  decode.loss_mask: 0.8909  decode.loss_dice: 1.1994  decode.d0.loss_cls: 3.3029  decode.d0.loss_mask: 0.9538  decode.d0.loss_dice: 1.4501  decode.d1.loss_cls: 1.3545  decode.d1.loss_mask: 0.8999  decode.d1.loss_dice: 1.2697  decode.d2.loss_cls: 1.2016  decode.d2.loss_mask: 0.8905  decode.d2.loss_dice: 1.2381  decode.d3.loss_cls: 1.1905  decode.d3.loss_mask: 0.8767  decode.d3.loss_dice: 1.2066  decode.d4.loss_cls: 1.1827  decode.d4.loss_mask: 0.8741  decode.d4.loss_dice: 1.1542  decode.d5.loss_cls: 1.1371  decode.d5.loss_mask: 0.8877  decode.d5.loss_dice: 1.1747  decode.d6.loss_cls: 1.1392  decode.d6.loss_mask: 0.8880  decode.d6.loss_dice: 1.1850  decode.d7.loss_cls: 1.1202  decode.d7.loss_mask: 0.8893  decode.d7.loss_dice: 1.2177  decode.d8.loss_cls: 1.1522  decode.d8.loss_mask: 0.8800  decode.d8.loss_dice: 1.2203
2023/05/24 06:29:29 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 06:29:29 - mmengine - INFO - Iter(train) [ 99000/160000]  lr: 4.1985e-06  eta: 7:18:09  time: 0.4294  data_time: 0.0104  memory: 4836  grad_norm: 84.2239  loss: 39.7231  decode.loss_cls: 1.3011  decode.loss_mask: 0.8745  decode.loss_dice: 1.5488  decode.d0.loss_cls: 3.3018  decode.d0.loss_mask: 0.8743  decode.d0.loss_dice: 1.7727  decode.d1.loss_cls: 1.3395  decode.d1.loss_mask: 0.9360  decode.d1.loss_dice: 1.6458  decode.d2.loss_cls: 1.2540  decode.d2.loss_mask: 0.9388  decode.d2.loss_dice: 1.6569  decode.d3.loss_cls: 1.3961  decode.d3.loss_mask: 0.8873  decode.d3.loss_dice: 1.5060  decode.d4.loss_cls: 1.2866  decode.d4.loss_mask: 0.8902  decode.d4.loss_dice: 1.5537  decode.d5.loss_cls: 1.2861  decode.d5.loss_mask: 0.8734  decode.d5.loss_dice: 1.5473  decode.d6.loss_cls: 1.2926  decode.d6.loss_mask: 0.8836  decode.d6.loss_dice: 1.5287  decode.d7.loss_cls: 1.2622  decode.d7.loss_mask: 0.8628  decode.d7.loss_dice: 1.5169  decode.d8.loss_cls: 1.2953  decode.d8.loss_mask: 0.8641  decode.d8.loss_dice: 1.5459
2023/05/24 06:29:29 - mmengine - INFO - Saving checkpoint at 99000 iterations
2023/05/24 06:29:56 - mmengine - INFO - Iter(train) [ 99050/160000]  lr: 4.1954e-06  eta: 7:17:51  time: 0.4156  data_time: 0.0110  memory: 4857  grad_norm: 88.5154  loss: 36.1839  decode.loss_cls: 1.1516  decode.loss_mask: 0.7639  decode.loss_dice: 1.4268  decode.d0.loss_cls: 3.0839  decode.d0.loss_mask: 0.7803  decode.d0.loss_dice: 1.5498  decode.d1.loss_cls: 1.2263  decode.d1.loss_mask: 0.8059  decode.d1.loss_dice: 1.5421  decode.d2.loss_cls: 1.1798  decode.d2.loss_mask: 0.8150  decode.d2.loss_dice: 1.5239  decode.d3.loss_cls: 1.2374  decode.d3.loss_mask: 0.7897  decode.d3.loss_dice: 1.4391  decode.d4.loss_cls: 1.1735  decode.d4.loss_mask: 0.8047  decode.d4.loss_dice: 1.4497  decode.d5.loss_cls: 1.2122  decode.d5.loss_mask: 0.7583  decode.d5.loss_dice: 1.4343  decode.d6.loss_cls: 1.1885  decode.d6.loss_mask: 0.7719  decode.d6.loss_dice: 1.3902  decode.d7.loss_cls: 1.1409  decode.d7.loss_mask: 0.7699  decode.d7.loss_dice: 1.4242  decode.d8.loss_cls: 1.1910  decode.d8.loss_mask: 0.7573  decode.d8.loss_dice: 1.4018
2023/05/24 06:30:17 - mmengine - INFO - Iter(train) [ 99100/160000]  lr: 4.1923e-06  eta: 7:17:29  time: 0.4654  data_time: 0.0106  memory: 4839  grad_norm: 112.2801  loss: 45.1869  decode.loss_cls: 1.4940  decode.loss_mask: 0.9930  decode.loss_dice: 1.6682  decode.d0.loss_cls: 3.5715  decode.d0.loss_mask: 1.0254  decode.d0.loss_dice: 2.0051  decode.d1.loss_cls: 1.6959  decode.d1.loss_mask: 1.0759  decode.d1.loss_dice: 1.9187  decode.d2.loss_cls: 1.6036  decode.d2.loss_mask: 1.0321  decode.d2.loss_dice: 1.8048  decode.d3.loss_cls: 1.5240  decode.d3.loss_mask: 0.9771  decode.d3.loss_dice: 1.7287  decode.d4.loss_cls: 1.5229  decode.d4.loss_mask: 0.9704  decode.d4.loss_dice: 1.7305  decode.d5.loss_cls: 1.4742  decode.d5.loss_mask: 0.9798  decode.d5.loss_dice: 1.7022  decode.d6.loss_cls: 1.5200  decode.d6.loss_mask: 1.0005  decode.d6.loss_dice: 1.6907  decode.d7.loss_cls: 1.5477  decode.d7.loss_mask: 1.0151  decode.d7.loss_dice: 1.7086  decode.d8.loss_cls: 1.5015  decode.d8.loss_mask: 1.0037  decode.d8.loss_dice: 1.7007
2023/05/24 06:30:39 - mmengine - INFO - Iter(train) [ 99150/160000]  lr: 4.1892e-06  eta: 7:17:08  time: 0.4202  data_time: 0.0107  memory: 4840  grad_norm: 95.5783  loss: 40.0089  decode.loss_cls: 1.6313  decode.loss_mask: 0.7263  decode.loss_dice: 1.3301  decode.d0.loss_cls: 3.6172  decode.d0.loss_mask: 0.8174  decode.d0.loss_dice: 1.5994  decode.d1.loss_cls: 1.6344  decode.d1.loss_mask: 0.8390  decode.d1.loss_dice: 1.5213  decode.d2.loss_cls: 1.6379  decode.d2.loss_mask: 0.7925  decode.d2.loss_dice: 1.4364  decode.d3.loss_cls: 1.6076  decode.d3.loss_mask: 0.8024  decode.d3.loss_dice: 1.3563  decode.d4.loss_cls: 1.5636  decode.d4.loss_mask: 0.8867  decode.d4.loss_dice: 1.4285  decode.d5.loss_cls: 1.6122  decode.d5.loss_mask: 0.8148  decode.d5.loss_dice: 1.3717  decode.d6.loss_cls: 1.5996  decode.d6.loss_mask: 0.7740  decode.d6.loss_dice: 1.3435  decode.d7.loss_cls: 1.6194  decode.d7.loss_mask: 0.7353  decode.d7.loss_dice: 1.3075  decode.d8.loss_cls: 1.5351  decode.d8.loss_mask: 0.7565  decode.d8.loss_dice: 1.3112
2023/05/24 06:31:00 - mmengine - INFO - Iter(train) [ 99200/160000]  lr: 4.1861e-06  eta: 7:16:46  time: 0.4191  data_time: 0.0105  memory: 4804  grad_norm: 129.6514  loss: 33.2778  decode.loss_cls: 1.0133  decode.loss_mask: 0.8642  decode.loss_dice: 1.1497  decode.d0.loss_cls: 3.0124  decode.d0.loss_mask: 0.8938  decode.d0.loss_dice: 1.3640  decode.d1.loss_cls: 1.1573  decode.d1.loss_mask: 0.8788  decode.d1.loss_dice: 1.2515  decode.d2.loss_cls: 1.0609  decode.d2.loss_mask: 0.9017  decode.d2.loss_dice: 1.2016  decode.d3.loss_cls: 1.1307  decode.d3.loss_mask: 0.9147  decode.d3.loss_dice: 1.1829  decode.d4.loss_cls: 1.0697  decode.d4.loss_mask: 0.8975  decode.d4.loss_dice: 1.1794  decode.d5.loss_cls: 1.0190  decode.d5.loss_mask: 0.8755  decode.d5.loss_dice: 1.1805  decode.d6.loss_cls: 1.0610  decode.d6.loss_mask: 0.8140  decode.d6.loss_dice: 1.1359  decode.d7.loss_cls: 1.0208  decode.d7.loss_mask: 0.8622  decode.d7.loss_dice: 1.1491  decode.d8.loss_cls: 1.0362  decode.d8.loss_mask: 0.8506  decode.d8.loss_dice: 1.1489
2023/05/24 06:31:22 - mmengine - INFO - Iter(train) [ 99250/160000]  lr: 4.1830e-06  eta: 7:16:25  time: 0.4196  data_time: 0.0104  memory: 4830  grad_norm: 132.3887  loss: 33.2030  decode.loss_cls: 1.0840  decode.loss_mask: 0.7559  decode.loss_dice: 1.1516  decode.d0.loss_cls: 3.1220  decode.d0.loss_mask: 0.8161  decode.d0.loss_dice: 1.3709  decode.d1.loss_cls: 1.2926  decode.d1.loss_mask: 0.7655  decode.d1.loss_dice: 1.2763  decode.d2.loss_cls: 1.1949  decode.d2.loss_mask: 0.7661  decode.d2.loss_dice: 1.2034  decode.d3.loss_cls: 1.1909  decode.d3.loss_mask: 0.7721  decode.d3.loss_dice: 1.1717  decode.d4.loss_cls: 1.1002  decode.d4.loss_mask: 0.7621  decode.d4.loss_dice: 1.1970  decode.d5.loss_cls: 1.1658  decode.d5.loss_mask: 0.7409  decode.d5.loss_dice: 1.1768  decode.d6.loss_cls: 1.1370  decode.d6.loss_mask: 0.7428  decode.d6.loss_dice: 1.1630  decode.d7.loss_cls: 1.1057  decode.d7.loss_mask: 0.7562  decode.d7.loss_dice: 1.1519  decode.d8.loss_cls: 1.1476  decode.d8.loss_mask: 0.7584  decode.d8.loss_dice: 1.1638
2023/05/24 06:31:43 - mmengine - INFO - Iter(train) [ 99300/160000]  lr: 4.1799e-06  eta: 7:16:03  time: 0.4177  data_time: 0.0104  memory: 4858  grad_norm: 102.3808  loss: 30.9147  decode.loss_cls: 1.0623  decode.loss_mask: 0.5788  decode.loss_dice: 1.1510  decode.d0.loss_cls: 3.0936  decode.d0.loss_mask: 0.6712  decode.d0.loss_dice: 1.3218  decode.d1.loss_cls: 1.1127  decode.d1.loss_mask: 0.6450  decode.d1.loss_dice: 1.2808  decode.d2.loss_cls: 1.0636  decode.d2.loss_mask: 0.6367  decode.d2.loss_dice: 1.2776  decode.d3.loss_cls: 1.0533  decode.d3.loss_mask: 0.6179  decode.d3.loss_dice: 1.2037  decode.d4.loss_cls: 0.9959  decode.d4.loss_mask: 0.6125  decode.d4.loss_dice: 1.2013  decode.d5.loss_cls: 1.0777  decode.d5.loss_mask: 0.6103  decode.d5.loss_dice: 1.1782  decode.d6.loss_cls: 1.0934  decode.d6.loss_mask: 0.5717  decode.d6.loss_dice: 1.1350  decode.d7.loss_cls: 1.0453  decode.d7.loss_mask: 0.5681  decode.d7.loss_dice: 1.1582  decode.d8.loss_cls: 1.0606  decode.d8.loss_mask: 0.6252  decode.d8.loss_dice: 1.2114
2023/05/24 06:32:05 - mmengine - INFO - Iter(train) [ 99350/160000]  lr: 4.1768e-06  eta: 7:15:41  time: 0.4814  data_time: 0.0107  memory: 4845  grad_norm: 91.3026  loss: 34.4793  decode.loss_cls: 1.1640  decode.loss_mask: 0.7333  decode.loss_dice: 1.2767  decode.d0.loss_cls: 3.0488  decode.d0.loss_mask: 0.7580  decode.d0.loss_dice: 1.4822  decode.d1.loss_cls: 1.3341  decode.d1.loss_mask: 0.7430  decode.d1.loss_dice: 1.3946  decode.d2.loss_cls: 1.2603  decode.d2.loss_mask: 0.7502  decode.d2.loss_dice: 1.3369  decode.d3.loss_cls: 1.2333  decode.d3.loss_mask: 0.7349  decode.d3.loss_dice: 1.2816  decode.d4.loss_cls: 1.1850  decode.d4.loss_mask: 0.7295  decode.d4.loss_dice: 1.2803  decode.d5.loss_cls: 1.1456  decode.d5.loss_mask: 0.7429  decode.d5.loss_dice: 1.3172  decode.d6.loss_cls: 1.1688  decode.d6.loss_mask: 0.7228  decode.d6.loss_dice: 1.2808  decode.d7.loss_cls: 1.1401  decode.d7.loss_mask: 0.7213  decode.d7.loss_dice: 1.3036  decode.d8.loss_cls: 1.1672  decode.d8.loss_mask: 0.7502  decode.d8.loss_dice: 1.2919
2023/05/24 06:32:27 - mmengine - INFO - Iter(train) [ 99400/160000]  lr: 4.1737e-06  eta: 7:15:20  time: 0.4241  data_time: 0.0107  memory: 4899  grad_norm: 110.3908  loss: 38.2082  decode.loss_cls: 1.2651  decode.loss_mask: 0.8811  decode.loss_dice: 1.3334  decode.d0.loss_cls: 3.3016  decode.d0.loss_mask: 0.9053  decode.d0.loss_dice: 1.5781  decode.d1.loss_cls: 1.4696  decode.d1.loss_mask: 0.8977  decode.d1.loss_dice: 1.5138  decode.d2.loss_cls: 1.3803  decode.d2.loss_mask: 0.8625  decode.d2.loss_dice: 1.4489  decode.d3.loss_cls: 1.3858  decode.d3.loss_mask: 0.8528  decode.d3.loss_dice: 1.3834  decode.d4.loss_cls: 1.3730  decode.d4.loss_mask: 0.8649  decode.d4.loss_dice: 1.4068  decode.d5.loss_cls: 1.3195  decode.d5.loss_mask: 0.8397  decode.d5.loss_dice: 1.3930  decode.d6.loss_cls: 1.3127  decode.d6.loss_mask: 0.8587  decode.d6.loss_dice: 1.3745  decode.d7.loss_cls: 1.2335  decode.d7.loss_mask: 0.8915  decode.d7.loss_dice: 1.3604  decode.d8.loss_cls: 1.2995  decode.d8.loss_mask: 0.8859  decode.d8.loss_dice: 1.3354
2023/05/24 06:32:48 - mmengine - INFO - Iter(train) [ 99450/160000]  lr: 4.1706e-06  eta: 7:14:58  time: 0.4150  data_time: 0.0107  memory: 4858  grad_norm: 84.6101  loss: 31.6758  decode.loss_cls: 1.0274  decode.loss_mask: 0.6871  decode.loss_dice: 1.1946  decode.d0.loss_cls: 2.8132  decode.d0.loss_mask: 0.8330  decode.d0.loss_dice: 1.3936  decode.d1.loss_cls: 1.1786  decode.d1.loss_mask: 0.7339  decode.d1.loss_dice: 1.2772  decode.d2.loss_cls: 1.0650  decode.d2.loss_mask: 0.7184  decode.d2.loss_dice: 1.2445  decode.d3.loss_cls: 1.0127  decode.d3.loss_mask: 0.7270  decode.d3.loss_dice: 1.2147  decode.d4.loss_cls: 1.0300  decode.d4.loss_mask: 0.7193  decode.d4.loss_dice: 1.2070  decode.d5.loss_cls: 1.0263  decode.d5.loss_mask: 0.6981  decode.d5.loss_dice: 1.2090  decode.d6.loss_cls: 1.0027  decode.d6.loss_mask: 0.6752  decode.d6.loss_dice: 1.1783  decode.d7.loss_cls: 1.0370  decode.d7.loss_mask: 0.6919  decode.d7.loss_dice: 1.1935  decode.d8.loss_cls: 1.0211  decode.d8.loss_mask: 0.6781  decode.d8.loss_dice: 1.1876
2023/05/24 06:33:09 - mmengine - INFO - Iter(train) [ 99500/160000]  lr: 4.1675e-06  eta: 7:14:37  time: 0.4174  data_time: 0.0103  memory: 4835  grad_norm: 90.5641  loss: 27.3623  decode.loss_cls: 0.8827  decode.loss_mask: 0.6415  decode.loss_dice: 0.9343  decode.d0.loss_cls: 3.0467  decode.d0.loss_mask: 0.6766  decode.d0.loss_dice: 0.9977  decode.d1.loss_cls: 1.0094  decode.d1.loss_mask: 0.6872  decode.d1.loss_dice: 1.0246  decode.d2.loss_cls: 0.9589  decode.d2.loss_mask: 0.6455  decode.d2.loss_dice: 0.9317  decode.d3.loss_cls: 0.9180  decode.d3.loss_mask: 0.6519  decode.d3.loss_dice: 0.8978  decode.d4.loss_cls: 0.9259  decode.d4.loss_mask: 0.6479  decode.d4.loss_dice: 0.9519  decode.d5.loss_cls: 0.8993  decode.d5.loss_mask: 0.6474  decode.d5.loss_dice: 0.9196  decode.d6.loss_cls: 0.9169  decode.d6.loss_mask: 0.6456  decode.d6.loss_dice: 0.9419  decode.d7.loss_cls: 0.8838  decode.d7.loss_mask: 0.6509  decode.d7.loss_dice: 0.9328  decode.d8.loss_cls: 0.8775  decode.d8.loss_mask: 0.6489  decode.d8.loss_dice: 0.9674
2023/05/24 06:33:32 - mmengine - INFO - Iter(train) [ 99550/160000]  lr: 4.1644e-06  eta: 7:14:16  time: 0.4398  data_time: 0.0103  memory: 4843  grad_norm: 100.8494  loss: 35.7718  decode.loss_cls: 1.1699  decode.loss_mask: 0.7320  decode.loss_dice: 1.3014  decode.d0.loss_cls: 3.4793  decode.d0.loss_mask: 0.8541  decode.d0.loss_dice: 1.5254  decode.d1.loss_cls: 1.4148  decode.d1.loss_mask: 0.7898  decode.d1.loss_dice: 1.4068  decode.d2.loss_cls: 1.2640  decode.d2.loss_mask: 0.7757  decode.d2.loss_dice: 1.3804  decode.d3.loss_cls: 1.2561  decode.d3.loss_mask: 0.7659  decode.d3.loss_dice: 1.3272  decode.d4.loss_cls: 1.2597  decode.d4.loss_mask: 0.7693  decode.d4.loss_dice: 1.3342  decode.d5.loss_cls: 1.2468  decode.d5.loss_mask: 0.7445  decode.d5.loss_dice: 1.3303  decode.d6.loss_cls: 1.1980  decode.d6.loss_mask: 0.7396  decode.d6.loss_dice: 1.2988  decode.d7.loss_cls: 1.1768  decode.d7.loss_mask: 0.7435  decode.d7.loss_dice: 1.2613  decode.d8.loss_cls: 1.1692  decode.d8.loss_mask: 0.7395  decode.d8.loss_dice: 1.3175
2023/05/24 06:33:53 - mmengine - INFO - Iter(train) [ 99600/160000]  lr: 4.1613e-06  eta: 7:13:54  time: 0.4231  data_time: 0.0104  memory: 4829  grad_norm: 96.2034  loss: 37.2882  decode.loss_cls: 1.1615  decode.loss_mask: 0.8099  decode.loss_dice: 1.3857  decode.d0.loss_cls: 3.2507  decode.d0.loss_mask: 0.9239  decode.d0.loss_dice: 1.6828  decode.d1.loss_cls: 1.2365  decode.d1.loss_mask: 0.9202  decode.d1.loss_dice: 1.5263  decode.d2.loss_cls: 1.2239  decode.d2.loss_mask: 0.8902  decode.d2.loss_dice: 1.4901  decode.d3.loss_cls: 1.1936  decode.d3.loss_mask: 0.8663  decode.d3.loss_dice: 1.4421  decode.d4.loss_cls: 1.2084  decode.d4.loss_mask: 0.8595  decode.d4.loss_dice: 1.4504  decode.d5.loss_cls: 1.2296  decode.d5.loss_mask: 0.8391  decode.d5.loss_dice: 1.4169  decode.d6.loss_cls: 1.1891  decode.d6.loss_mask: 0.8340  decode.d6.loss_dice: 1.4287  decode.d7.loss_cls: 1.1681  decode.d7.loss_mask: 0.8331  decode.d7.loss_dice: 1.4213  decode.d8.loss_cls: 1.1586  decode.d8.loss_mask: 0.8410  decode.d8.loss_dice: 1.4066
2023/05/24 06:34:15 - mmengine - INFO - Iter(train) [ 99650/160000]  lr: 4.1582e-06  eta: 7:13:32  time: 0.4169  data_time: 0.0105  memory: 4897  grad_norm: 93.2151  loss: 29.7523  decode.loss_cls: 1.2371  decode.loss_mask: 0.5492  decode.loss_dice: 0.9411  decode.d0.loss_cls: 2.8300  decode.d0.loss_mask: 0.6142  decode.d0.loss_dice: 1.1265  decode.d1.loss_cls: 1.3368  decode.d1.loss_mask: 0.5911  decode.d1.loss_dice: 1.0494  decode.d2.loss_cls: 1.3127  decode.d2.loss_mask: 0.5947  decode.d2.loss_dice: 1.0451  decode.d3.loss_cls: 1.2517  decode.d3.loss_mask: 0.5694  decode.d3.loss_dice: 0.9645  decode.d4.loss_cls: 1.2730  decode.d4.loss_mask: 0.5772  decode.d4.loss_dice: 0.9835  decode.d5.loss_cls: 1.2277  decode.d5.loss_mask: 0.5611  decode.d5.loss_dice: 0.9255  decode.d6.loss_cls: 1.2416  decode.d6.loss_mask: 0.5564  decode.d6.loss_dice: 0.9140  decode.d7.loss_cls: 1.2361  decode.d7.loss_mask: 0.5718  decode.d7.loss_dice: 0.9222  decode.d8.loss_cls: 1.2472  decode.d8.loss_mask: 0.5556  decode.d8.loss_dice: 0.9462
2023/05/24 06:34:36 - mmengine - INFO - Iter(train) [ 99700/160000]  lr: 4.1551e-06  eta: 7:13:11  time: 0.4494  data_time: 0.0105  memory: 4970  grad_norm: 106.7359  loss: 36.5283  decode.loss_cls: 1.0695  decode.loss_mask: 0.8690  decode.loss_dice: 1.3548  decode.d0.loss_cls: 3.2539  decode.d0.loss_mask: 0.9730  decode.d0.loss_dice: 1.6736  decode.d1.loss_cls: 1.2174  decode.d1.loss_mask: 0.9610  decode.d1.loss_dice: 1.5580  decode.d2.loss_cls: 1.1384  decode.d2.loss_mask: 0.9190  decode.d2.loss_dice: 1.4421  decode.d3.loss_cls: 1.1308  decode.d3.loss_mask: 0.8990  decode.d3.loss_dice: 1.3815  decode.d4.loss_cls: 1.0921  decode.d4.loss_mask: 0.8909  decode.d4.loss_dice: 1.3771  decode.d5.loss_cls: 1.0734  decode.d5.loss_mask: 0.8828  decode.d5.loss_dice: 1.3335  decode.d6.loss_cls: 1.0283  decode.d6.loss_mask: 0.9286  decode.d6.loss_dice: 1.3804  decode.d7.loss_cls: 1.0645  decode.d7.loss_mask: 0.8921  decode.d7.loss_dice: 1.3845  decode.d8.loss_cls: 1.0919  decode.d8.loss_mask: 0.9003  decode.d8.loss_dice: 1.3667
2023/05/24 06:35:00 - mmengine - INFO - Iter(train) [ 99750/160000]  lr: 4.1520e-06  eta: 7:12:50  time: 0.4753  data_time: 0.0103  memory: 4915  grad_norm: 105.1234  loss: 40.1570  decode.loss_cls: 1.2697  decode.loss_mask: 0.8896  decode.loss_dice: 1.5402  decode.d0.loss_cls: 3.4011  decode.d0.loss_mask: 0.9926  decode.d0.loss_dice: 1.8208  decode.d1.loss_cls: 1.3679  decode.d1.loss_mask: 0.9539  decode.d1.loss_dice: 1.7030  decode.d2.loss_cls: 1.3193  decode.d2.loss_mask: 0.9440  decode.d2.loss_dice: 1.5967  decode.d3.loss_cls: 1.3323  decode.d3.loss_mask: 0.9044  decode.d3.loss_dice: 1.5741  decode.d4.loss_cls: 1.3485  decode.d4.loss_mask: 0.8988  decode.d4.loss_dice: 1.5319  decode.d5.loss_cls: 1.2553  decode.d5.loss_mask: 0.8991  decode.d5.loss_dice: 1.5351  decode.d6.loss_cls: 1.3215  decode.d6.loss_mask: 0.8997  decode.d6.loss_dice: 1.5295  decode.d7.loss_cls: 1.2122  decode.d7.loss_mask: 0.9160  decode.d7.loss_dice: 1.5437  decode.d8.loss_cls: 1.2179  decode.d8.loss_mask: 0.9011  decode.d8.loss_dice: 1.5369
2023/05/24 06:35:22 - mmengine - INFO - Iter(train) [ 99800/160000]  lr: 4.1489e-06  eta: 7:12:29  time: 0.4095  data_time: 0.0103  memory: 4866  grad_norm: 93.6399  loss: 43.6159  decode.loss_cls: 1.6878  decode.loss_mask: 0.8315  decode.loss_dice: 1.6031  decode.d0.loss_cls: 3.4429  decode.d0.loss_mask: 0.8943  decode.d0.loss_dice: 1.7754  decode.d1.loss_cls: 1.8438  decode.d1.loss_mask: 0.8770  decode.d1.loss_dice: 1.6611  decode.d2.loss_cls: 1.7849  decode.d2.loss_mask: 0.8875  decode.d2.loss_dice: 1.6617  decode.d3.loss_cls: 1.7504  decode.d3.loss_mask: 0.8197  decode.d3.loss_dice: 1.5931  decode.d4.loss_cls: 1.6162  decode.d4.loss_mask: 0.8697  decode.d4.loss_dice: 1.6283  decode.d5.loss_cls: 1.6552  decode.d5.loss_mask: 0.8582  decode.d5.loss_dice: 1.5802  decode.d6.loss_cls: 1.6446  decode.d6.loss_mask: 0.8504  decode.d6.loss_dice: 1.6067  decode.d7.loss_cls: 1.6479  decode.d7.loss_mask: 0.8472  decode.d7.loss_dice: 1.5936  decode.d8.loss_cls: 1.6712  decode.d8.loss_mask: 0.8346  decode.d8.loss_dice: 1.5979
2023/05/24 06:35:43 - mmengine - INFO - Iter(train) [ 99850/160000]  lr: 4.1458e-06  eta: 7:12:07  time: 0.4141  data_time: 0.0105  memory: 4841  grad_norm: 92.2885  loss: 34.6611  decode.loss_cls: 1.1544  decode.loss_mask: 0.8176  decode.loss_dice: 1.1432  decode.d0.loss_cls: 3.2173  decode.d0.loss_mask: 0.8827  decode.d0.loss_dice: 1.3876  decode.d1.loss_cls: 1.3075  decode.d1.loss_mask: 0.8503  decode.d1.loss_dice: 1.3211  decode.d2.loss_cls: 1.3198  decode.d2.loss_mask: 0.8276  decode.d2.loss_dice: 1.2084  decode.d3.loss_cls: 1.3211  decode.d3.loss_mask: 0.8128  decode.d3.loss_dice: 1.1499  decode.d4.loss_cls: 1.2622  decode.d4.loss_mask: 0.8119  decode.d4.loss_dice: 1.1727  decode.d5.loss_cls: 1.2489  decode.d5.loss_mask: 0.8129  decode.d5.loss_dice: 1.1288  decode.d6.loss_cls: 1.1889  decode.d6.loss_mask: 0.8815  decode.d6.loss_dice: 1.1523  decode.d7.loss_cls: 1.1880  decode.d7.loss_mask: 0.8220  decode.d7.loss_dice: 1.1486  decode.d8.loss_cls: 1.1521  decode.d8.loss_mask: 0.8177  decode.d8.loss_dice: 1.1513
2023/05/24 06:36:04 - mmengine - INFO - Iter(train) [ 99900/160000]  lr: 4.1427e-06  eta: 7:11:45  time: 0.4204  data_time: 0.0108  memory: 4804  grad_norm: 95.9774  loss: 33.7507  decode.loss_cls: 1.2063  decode.loss_mask: 0.7557  decode.loss_dice: 1.1435  decode.d0.loss_cls: 3.1231  decode.d0.loss_mask: 0.8199  decode.d0.loss_dice: 1.3860  decode.d1.loss_cls: 1.3710  decode.d1.loss_mask: 0.7632  decode.d1.loss_dice: 1.2338  decode.d2.loss_cls: 1.2191  decode.d2.loss_mask: 0.7963  decode.d2.loss_dice: 1.2245  decode.d3.loss_cls: 1.2224  decode.d3.loss_mask: 0.7710  decode.d3.loss_dice: 1.1670  decode.d4.loss_cls: 1.1670  decode.d4.loss_mask: 0.7749  decode.d4.loss_dice: 1.1484  decode.d5.loss_cls: 1.1732  decode.d5.loss_mask: 0.7658  decode.d5.loss_dice: 1.1639  decode.d6.loss_cls: 1.2336  decode.d6.loss_mask: 0.7611  decode.d6.loss_dice: 1.1121  decode.d7.loss_cls: 1.2167  decode.d7.loss_mask: 0.7713  decode.d7.loss_dice: 1.1498  decode.d8.loss_cls: 1.2264  decode.d8.loss_mask: 0.7646  decode.d8.loss_dice: 1.1187
2023/05/24 06:36:25 - mmengine - INFO - Iter(train) [ 99950/160000]  lr: 4.1396e-06  eta: 7:11:24  time: 0.4149  data_time: 0.0105  memory: 4896  grad_norm: 97.4297  loss: 34.7634  decode.loss_cls: 1.1173  decode.loss_mask: 0.8033  decode.loss_dice: 1.2292  decode.d0.loss_cls: 3.3029  decode.d0.loss_mask: 0.8324  decode.d0.loss_dice: 1.4254  decode.d1.loss_cls: 1.3341  decode.d1.loss_mask: 0.8246  decode.d1.loss_dice: 1.3335  decode.d2.loss_cls: 1.2322  decode.d2.loss_mask: 0.7927  decode.d2.loss_dice: 1.2536  decode.d3.loss_cls: 1.2388  decode.d3.loss_mask: 0.7777  decode.d3.loss_dice: 1.2464  decode.d4.loss_cls: 1.2046  decode.d4.loss_mask: 0.7589  decode.d4.loss_dice: 1.2274  decode.d5.loss_cls: 1.2398  decode.d5.loss_mask: 0.7884  decode.d5.loss_dice: 1.2386  decode.d6.loss_cls: 1.1788  decode.d6.loss_mask: 0.7837  decode.d6.loss_dice: 1.2375  decode.d7.loss_cls: 1.1869  decode.d7.loss_mask: 0.7926  decode.d7.loss_dice: 1.2343  decode.d8.loss_cls: 1.1510  decode.d8.loss_mask: 0.7878  decode.d8.loss_dice: 1.2090
2023/05/24 06:36:47 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 06:36:47 - mmengine - INFO - Iter(train) [100000/160000]  lr: 4.1365e-06  eta: 7:11:03  time: 0.4741  data_time: 0.0103  memory: 4814  grad_norm: 99.2923  loss: 26.9794  decode.loss_cls: 0.8703  decode.loss_mask: 0.6389  decode.loss_dice: 0.9054  decode.d0.loss_cls: 2.8104  decode.d0.loss_mask: 0.7059  decode.d0.loss_dice: 1.0465  decode.d1.loss_cls: 0.9861  decode.d1.loss_mask: 0.6978  decode.d1.loss_dice: 0.9407  decode.d2.loss_cls: 0.9465  decode.d2.loss_mask: 0.6755  decode.d2.loss_dice: 0.9409  decode.d3.loss_cls: 0.9272  decode.d3.loss_mask: 0.6379  decode.d3.loss_dice: 0.9188  decode.d4.loss_cls: 0.9320  decode.d4.loss_mask: 0.6354  decode.d4.loss_dice: 0.9222  decode.d5.loss_cls: 0.9610  decode.d5.loss_mask: 0.6569  decode.d5.loss_dice: 0.9296  decode.d6.loss_cls: 0.8969  decode.d6.loss_mask: 0.6390  decode.d6.loss_dice: 0.9327  decode.d7.loss_cls: 0.8688  decode.d7.loss_mask: 0.6420  decode.d7.loss_dice: 0.8976  decode.d8.loss_cls: 0.8758  decode.d8.loss_mask: 0.6408  decode.d8.loss_dice: 0.8999
2023/05/24 06:36:48 - mmengine - INFO - Saving checkpoint at 100000 iterations
2023/05/24 06:36:57 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:48  time: 0.0780  data_time: 0.0017  memory: 2167  
2023/05/24 06:37:01 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0791  data_time: 0.0018  memory: 2216  
2023/05/24 06:37:05 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:38  time: 0.0804  data_time: 0.0017  memory: 2167  
2023/05/24 06:37:09 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0935  data_time: 0.0018  memory: 2104  
2023/05/24 06:37:13 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0785  data_time: 0.0018  memory: 2831  
2023/05/24 06:37:17 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0792  data_time: 0.0020  memory: 2167  
2023/05/24 06:37:21 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0980  data_time: 0.0023  memory: 2167  
2023/05/24 06:37:25 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0849  data_time: 0.0020  memory: 2167  
2023/05/24 06:37:29 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0795  data_time: 0.0019  memory: 2944  
2023/05/24 06:37:33 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0790  data_time: 0.0018  memory: 2356  
2023/05/24 06:37:37 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0786  data_time: 0.0018  memory: 2217  
2023/05/24 06:37:44 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.3311  data_time: 0.0018  memory: 2328  
2023/05/24 06:37:48 - mmengine - INFO - per class results:
2023/05/24 06:37:48 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      |  86.2 | 93.55 |
|     bicycle      | 68.92 | 83.43 |
|       car        | 59.93 | 85.49 |
|    motorcycle    |  82.8 | 89.73 |
|     airplane     | 81.63 | 92.18 |
|       bus        | 80.69 | 86.98 |
|      train       |  78.5 | 94.98 |
|      truck       | 55.98 | 73.65 |
|       boat       | 58.85 | 83.28 |
|  traffic light   | 67.65 | 81.94 |
|   fire hydrant   |  87.3 | 94.78 |
|    stop sign     | 92.58 | 96.39 |
|  parking meter   | 72.36 | 80.39 |
|      bench       | 49.74 | 70.61 |
|       bird       | 81.52 | 90.79 |
|       cat        | 85.33 |  91.9 |
|       dog        | 79.34 | 86.26 |
|      horse       | 77.95 | 88.74 |
|      sheep       | 85.66 | 92.29 |
|       cow        | 81.09 | 88.97 |
|     elephant     | 89.76 | 94.59 |
|       bear       | 92.15 | 94.97 |
|      zebra       | 89.91 | 93.42 |
|     giraffe      | 87.29 | 92.65 |
|     backpack     | 34.05 | 62.22 |
|     umbrella     |  80.9 | 87.73 |
|     handbag      | 32.02 | 57.01 |
|       tie        | 13.07 | 18.16 |
|     suitcase     | 75.14 | 91.73 |
|     frisbee      | 74.93 | 91.53 |
|       skis       | 47.07 | 66.37 |
|    snowboard     | 60.66 | 74.12 |
|   sports ball    | 53.25 | 73.62 |
|       kite       |  57.0 | 73.57 |
|   baseball bat   | 52.86 | 64.12 |
|  baseball glove  | 73.66 | 86.27 |
|    skateboard    | 76.31 | 83.79 |
|    surfboard     | 70.74 | 86.97 |
|  tennis racket   | 83.73 | 89.16 |
|      bottle      | 47.99 | 64.01 |
|    wine glass    | 56.51 | 81.82 |
|       cup        | 54.01 | 80.32 |
|       fork       | 45.25 | 59.23 |
|      knife       | 34.47 | 44.45 |
|      spoon       | 33.63 | 51.01 |
|       bowl       | 48.34 | 72.59 |
|      banana      | 66.57 | 88.53 |
|      apple       | 48.12 |  71.4 |
|     sandwich     | 44.16 |  63.0 |
|      orange      | 59.98 | 64.16 |
|     broccoli     | 56.22 | 69.51 |
|      carrot      | 50.22 | 56.83 |
|     hot dog      | 48.87 | 57.52 |
|      pizza       |  73.1 | 87.75 |
|      donut       | 69.62 | 86.53 |
|       cake       | 67.08 | 81.95 |
|      chair       | 44.45 | 60.01 |
|      couch       |  56.2 | 80.01 |
|   potted plant   |  35.4 |  54.1 |
|       bed        | 64.61 | 85.79 |
|   dining table   | 44.36 | 74.13 |
|      toilet      | 81.04 | 93.23 |
|        tv        |  73.5 | 85.11 |
|      laptop      | 73.08 | 90.73 |
|      mouse       |  72.3 | 90.44 |
|      remote      | 60.91 | 75.94 |
|     keyboard     | 59.54 | 70.12 |
|    cell phone    | 71.56 | 89.16 |
|    microwave     |  63.4 |  75.8 |
|       oven       | 55.62 | 84.91 |
|     toaster      | 43.98 | 54.32 |
|       sink       | 58.75 | 76.62 |
|   refrigerator   | 75.97 | 91.66 |
|       book       | 48.16 | 68.34 |
|      clock       | 73.06 | 85.05 |
|       vase       | 57.49 | 83.36 |
|     scissors     | 73.92 | 91.69 |
|    teddy bear    | 73.37 | 85.25 |
|    hair drier    | 44.81 | 46.56 |
|    toothbrush    | 35.13 | 74.18 |
|      banner      | 30.45 | 65.37 |
|     blanket      |  1.19 |  1.24 |
|      branch      | 19.14 | 26.91 |
|      bridge      | 32.03 | 48.82 |
|  building-other  | 52.27 | 73.46 |
|       bush       | 30.76 | 41.93 |
|     cabinet      | 50.54 | 62.98 |
|       cage       |  19.1 | 28.94 |
|    cardboard     |  42.1 | 50.26 |
|      carpet      | 51.76 | 66.65 |
|  ceiling-other   | 64.73 | 81.35 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 20.01 | 28.03 |
|      clouds      | 40.86 | 49.69 |
|     counter      | 27.04 | 42.18 |
|     cupboard     |  5.28 |  8.65 |
|     curtain      | 65.05 | 75.84 |
|    desk-stuff    | 45.31 |  58.6 |
|       dirt       | 40.47 | 59.86 |
|    door-stuff    | 39.09 | 61.15 |
|      fence       | 30.11 | 51.96 |
|   floor-marble   |  7.09 |  8.46 |
|   floor-other    | 23.89 | 33.71 |
|   floor-stone    |  2.87 |  3.32 |
|    floor-tile    | 60.59 | 68.78 |
|    floor-wood    | 63.32 | 74.39 |
|      flower      | 43.68 | 59.42 |
|       fog        |  9.31 | 10.42 |
|    food-other    | 28.75 |  33.9 |
|      fruit       | 36.27 | 55.82 |
| furniture-other  | 17.44 | 26.41 |
|      grass       | 69.63 | 81.44 |
|      gravel      | 29.29 | 41.18 |
|   ground-other   |  1.46 |  1.98 |
|       hill       | 17.28 | 22.65 |
|      house       | 25.12 | 28.84 |
|      leaves      | 25.17 | 33.81 |
|      light       | 37.22 | 52.51 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.71 | 47.31 |
|   mirror-stuff   | 51.74 | 71.26 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 51.95 |  74.1 |
|       mud        |  5.58 |  7.48 |
|      napkin      | 12.52 | 12.85 |
|       net        | 37.46 | 70.58 |
|      paper       | 31.04 | 48.95 |
|     pavement     | 50.15 |  67.4 |
|      pillow      |  8.82 | 10.49 |
|   plant-other    | 17.86 | 39.02 |
|     plastic      | 21.04 | 30.37 |
|     platform     |  30.2 | 53.92 |
|   playingfield   | 70.16 | 91.63 |
|     railing      |  2.93 |  3.52 |
|     railroad     | 60.89 | 76.54 |
|      river       | 49.48 |  66.4 |
|       road       | 65.14 | 81.62 |
|       rock       |  31.9 | 43.58 |
|       roof       | 12.19 | 15.86 |
|       rug        | 37.33 |  58.4 |
|      salad       |  0.0  |  0.0  |
|       sand       | 62.26 |  73.1 |
|       sea        | 84.08 | 88.13 |
|      shelf       | 33.22 | 43.99 |
|    sky-other     | 69.91 | 89.38 |
|    skyscraper    | 34.28 | 51.11 |
|       snow       | 89.41 | 93.12 |
|   solid-other    |  0.05 |  0.05 |
|      stairs      | 21.46 | 33.03 |
|      stone       | 24.23 | 55.21 |
|      straw       | 23.57 | 31.95 |
| structural-other |  0.01 |  0.01 |
|      table       | 20.23 | 28.16 |
|       tent       |  9.84 | 13.65 |
|  textile-other   | 12.49 | 20.41 |
|      towel       | 34.86 | 43.86 |
|       tree       | 73.86 | 85.45 |
|    vegetable     | 35.32 | 47.15 |
|    wall-brick    | 49.31 | 60.14 |
|  wall-concrete   |  60.8 | 78.45 |
|    wall-other    | 17.98 | 28.96 |
|    wall-panel    |  6.52 |  7.73 |
|    wall-stone    | 32.36 | 38.88 |
|    wall-tile     | 64.87 |  80.5 |
|    wall-wood     | 41.29 | 52.82 |
|   water-other    | 26.62 | 49.66 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 49.25 | 58.43 |
|   window-other   | 45.77 | 72.05 |
|       wood       | 23.19 | 37.36 |
+------------------+-------+-------+
2023/05/24 06:37:48 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.9000  mIoU: 46.9900  mAcc: 59.8300  data_time: 0.0020  time: 0.0858
2023/05/24 06:37:48 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_95000.pth is removed
2023/05/24 06:37:51 - mmengine - INFO - The best checkpoint with 46.9900 mIoU at 100000 iter is saved to best_mIoU_iter_100000.pth.
2023/05/24 06:38:13 - mmengine - INFO - Iter(train) [100050/160000]  lr: 4.1334e-06  eta: 7:10:44  time: 0.4201  data_time: 0.0105  memory: 4875  grad_norm: 103.7388  loss: 31.6895  decode.loss_cls: 1.0079  decode.loss_mask: 0.7396  decode.loss_dice: 1.2136  decode.d0.loss_cls: 2.7382  decode.d0.loss_mask: 0.8230  decode.d0.loss_dice: 1.3604  decode.d1.loss_cls: 1.0784  decode.d1.loss_mask: 0.7699  decode.d1.loss_dice: 1.3085  decode.d2.loss_cls: 1.1037  decode.d2.loss_mask: 0.7688  decode.d2.loss_dice: 1.2544  decode.d3.loss_cls: 0.9965  decode.d3.loss_mask: 0.7474  decode.d3.loss_dice: 1.1963  decode.d4.loss_cls: 1.0112  decode.d4.loss_mask: 0.7493  decode.d4.loss_dice: 1.2209  decode.d5.loss_cls: 0.9880  decode.d5.loss_mask: 0.7515  decode.d5.loss_dice: 1.1913  decode.d6.loss_cls: 0.9622  decode.d6.loss_mask: 0.7368  decode.d6.loss_dice: 1.1924  decode.d7.loss_cls: 0.9659  decode.d7.loss_mask: 0.7365  decode.d7.loss_dice: 1.1691  decode.d8.loss_cls: 0.9629  decode.d8.loss_mask: 0.7480  decode.d8.loss_dice: 1.1968
2023/05/24 06:38:35 - mmengine - INFO - Iter(train) [100100/160000]  lr: 4.1303e-06  eta: 7:10:23  time: 0.4239  data_time: 0.0107  memory: 4867  grad_norm: 91.7644  loss: 32.2298  decode.loss_cls: 1.0331  decode.loss_mask: 0.7041  decode.loss_dice: 1.1971  decode.d0.loss_cls: 3.0575  decode.d0.loss_mask: 0.7787  decode.d0.loss_dice: 1.3870  decode.d1.loss_cls: 1.2252  decode.d1.loss_mask: 0.7437  decode.d1.loss_dice: 1.3077  decode.d2.loss_cls: 1.1714  decode.d2.loss_mask: 0.7168  decode.d2.loss_dice: 1.2437  decode.d3.loss_cls: 1.0875  decode.d3.loss_mask: 0.6840  decode.d3.loss_dice: 1.2067  decode.d4.loss_cls: 1.0722  decode.d4.loss_mask: 0.6922  decode.d4.loss_dice: 1.2025  decode.d5.loss_cls: 1.0803  decode.d5.loss_mask: 0.6843  decode.d5.loss_dice: 1.1906  decode.d6.loss_cls: 1.0176  decode.d6.loss_mask: 0.6939  decode.d6.loss_dice: 1.1942  decode.d7.loss_cls: 1.0160  decode.d7.loss_mask: 0.6927  decode.d7.loss_dice: 1.1882  decode.d8.loss_cls: 1.0401  decode.d8.loss_mask: 0.7049  decode.d8.loss_dice: 1.2160
2023/05/24 06:38:58 - mmengine - INFO - Iter(train) [100150/160000]  lr: 4.1272e-06  eta: 7:10:02  time: 0.4577  data_time: 0.0103  memory: 4874  grad_norm: 103.6232  loss: 41.4329  decode.loss_cls: 1.3888  decode.loss_mask: 0.8907  decode.loss_dice: 1.5046  decode.d0.loss_cls: 3.2249  decode.d0.loss_mask: 1.0352  decode.d0.loss_dice: 1.8620  decode.d1.loss_cls: 1.4957  decode.d1.loss_mask: 0.9787  decode.d1.loss_dice: 1.6520  decode.d2.loss_cls: 1.5026  decode.d2.loss_mask: 0.9335  decode.d2.loss_dice: 1.5736  decode.d3.loss_cls: 1.4740  decode.d3.loss_mask: 0.9361  decode.d3.loss_dice: 1.5444  decode.d4.loss_cls: 1.5093  decode.d4.loss_mask: 0.9119  decode.d4.loss_dice: 1.5410  decode.d5.loss_cls: 1.4911  decode.d5.loss_mask: 0.8730  decode.d5.loss_dice: 1.5255  decode.d6.loss_cls: 1.4773  decode.d6.loss_mask: 0.8922  decode.d6.loss_dice: 1.5138  decode.d7.loss_cls: 1.4075  decode.d7.loss_mask: 0.9058  decode.d7.loss_dice: 1.5293  decode.d8.loss_cls: 1.4597  decode.d8.loss_mask: 0.8917  decode.d8.loss_dice: 1.5069
2023/05/24 06:39:20 - mmengine - INFO - Iter(train) [100200/160000]  lr: 4.1241e-06  eta: 7:09:41  time: 0.4248  data_time: 0.0105  memory: 4836  grad_norm: 118.8297  loss: 47.7462  decode.loss_cls: 1.8036  decode.loss_mask: 0.8846  decode.loss_dice: 1.7698  decode.d0.loss_cls: 3.8952  decode.d0.loss_mask: 0.9856  decode.d0.loss_dice: 2.0794  decode.d1.loss_cls: 2.0017  decode.d1.loss_mask: 0.9168  decode.d1.loss_dice: 1.9780  decode.d2.loss_cls: 1.8470  decode.d2.loss_mask: 0.9375  decode.d2.loss_dice: 1.8825  decode.d3.loss_cls: 1.8817  decode.d3.loss_mask: 0.8927  decode.d3.loss_dice: 1.7980  decode.d4.loss_cls: 1.8111  decode.d4.loss_mask: 0.9036  decode.d4.loss_dice: 1.8045  decode.d5.loss_cls: 1.8008  decode.d5.loss_mask: 0.8961  decode.d5.loss_dice: 1.7635  decode.d6.loss_cls: 1.7315  decode.d6.loss_mask: 0.8940  decode.d6.loss_dice: 1.7823  decode.d7.loss_cls: 1.7607  decode.d7.loss_mask: 0.8774  decode.d7.loss_dice: 1.7522  decode.d8.loss_cls: 1.7826  decode.d8.loss_mask: 0.8733  decode.d8.loss_dice: 1.7585
2023/05/24 06:39:41 - mmengine - INFO - Iter(train) [100250/160000]  lr: 4.1210e-06  eta: 7:09:19  time: 0.4148  data_time: 0.0102  memory: 4822  grad_norm: 82.8438  loss: 28.4026  decode.loss_cls: 1.0286  decode.loss_mask: 0.6108  decode.loss_dice: 0.9081  decode.d0.loss_cls: 3.1474  decode.d0.loss_mask: 0.6194  decode.d0.loss_dice: 0.9947  decode.d1.loss_cls: 1.2436  decode.d1.loss_mask: 0.6465  decode.d1.loss_dice: 0.9641  decode.d2.loss_cls: 1.0938  decode.d2.loss_mask: 0.6503  decode.d2.loss_dice: 0.9627  decode.d3.loss_cls: 0.9958  decode.d3.loss_mask: 0.6509  decode.d3.loss_dice: 0.9501  decode.d4.loss_cls: 1.0392  decode.d4.loss_mask: 0.6192  decode.d4.loss_dice: 0.9563  decode.d5.loss_cls: 1.0390  decode.d5.loss_mask: 0.6230  decode.d5.loss_dice: 0.9380  decode.d6.loss_cls: 1.0287  decode.d6.loss_mask: 0.6178  decode.d6.loss_dice: 0.9386  decode.d7.loss_cls: 1.0547  decode.d7.loss_mask: 0.6062  decode.d7.loss_dice: 0.9133  decode.d8.loss_cls: 1.0289  decode.d8.loss_mask: 0.6247  decode.d8.loss_dice: 0.9082
2023/05/24 06:40:02 - mmengine - INFO - Iter(train) [100300/160000]  lr: 4.1179e-06  eta: 7:08:57  time: 0.4217  data_time: 0.0103  memory: 4921  grad_norm: 180.2274  loss: 35.1491  decode.loss_cls: 0.9958  decode.loss_mask: 0.8795  decode.loss_dice: 1.3520  decode.d0.loss_cls: 3.0329  decode.d0.loss_mask: 0.8965  decode.d0.loss_dice: 1.5458  decode.d1.loss_cls: 1.1278  decode.d1.loss_mask: 0.8633  decode.d1.loss_dice: 1.4293  decode.d2.loss_cls: 1.1325  decode.d2.loss_mask: 0.8829  decode.d2.loss_dice: 1.3844  decode.d3.loss_cls: 1.1595  decode.d3.loss_mask: 0.8712  decode.d3.loss_dice: 1.3577  decode.d4.loss_cls: 1.0629  decode.d4.loss_mask: 0.8900  decode.d4.loss_dice: 1.3685  decode.d5.loss_cls: 1.0880  decode.d5.loss_mask: 0.8661  decode.d5.loss_dice: 1.3273  decode.d6.loss_cls: 0.9836  decode.d6.loss_mask: 0.8678  decode.d6.loss_dice: 1.3365  decode.d7.loss_cls: 1.0019  decode.d7.loss_mask: 0.8773  decode.d7.loss_dice: 1.3036  decode.d8.loss_cls: 1.0299  decode.d8.loss_mask: 0.8897  decode.d8.loss_dice: 1.3449
2023/05/24 06:40:23 - mmengine - INFO - Iter(train) [100350/160000]  lr: 4.1148e-06  eta: 7:08:35  time: 0.4180  data_time: 0.0108  memory: 4824  grad_norm: 92.8524  loss: 36.5362  decode.loss_cls: 1.4415  decode.loss_mask: 0.7412  decode.loss_dice: 1.2561  decode.d0.loss_cls: 3.1276  decode.d0.loss_mask: 0.8551  decode.d0.loss_dice: 1.5358  decode.d1.loss_cls: 1.5459  decode.d1.loss_mask: 0.7556  decode.d1.loss_dice: 1.3605  decode.d2.loss_cls: 1.5076  decode.d2.loss_mask: 0.7000  decode.d2.loss_dice: 1.2475  decode.d3.loss_cls: 1.4246  decode.d3.loss_mask: 0.6893  decode.d3.loss_dice: 1.2921  decode.d4.loss_cls: 1.4746  decode.d4.loss_mask: 0.7356  decode.d4.loss_dice: 1.2643  decode.d5.loss_cls: 1.4285  decode.d5.loss_mask: 0.7297  decode.d5.loss_dice: 1.2731  decode.d6.loss_cls: 1.3960  decode.d6.loss_mask: 0.7393  decode.d6.loss_dice: 1.2384  decode.d7.loss_cls: 1.4214  decode.d7.loss_mask: 0.7321  decode.d7.loss_dice: 1.2111  decode.d8.loss_cls: 1.4090  decode.d8.loss_mask: 0.7409  decode.d8.loss_dice: 1.2619
2023/05/24 06:40:44 - mmengine - INFO - Iter(train) [100400/160000]  lr: 4.1116e-06  eta: 7:08:14  time: 0.4245  data_time: 0.0106  memory: 4858  grad_norm: 102.9381  loss: 39.1373  decode.loss_cls: 1.4647  decode.loss_mask: 0.7967  decode.loss_dice: 1.3519  decode.d0.loss_cls: 3.3922  decode.d0.loss_mask: 0.9197  decode.d0.loss_dice: 1.7025  decode.d1.loss_cls: 1.5145  decode.d1.loss_mask: 0.8991  decode.d1.loss_dice: 1.4856  decode.d2.loss_cls: 1.4739  decode.d2.loss_mask: 0.8596  decode.d2.loss_dice: 1.4733  decode.d3.loss_cls: 1.4532  decode.d3.loss_mask: 0.8319  decode.d3.loss_dice: 1.4223  decode.d4.loss_cls: 1.4753  decode.d4.loss_mask: 0.8109  decode.d4.loss_dice: 1.4318  decode.d5.loss_cls: 1.4759  decode.d5.loss_mask: 0.7841  decode.d5.loss_dice: 1.4012  decode.d6.loss_cls: 1.4238  decode.d6.loss_mask: 0.7710  decode.d6.loss_dice: 1.3753  decode.d7.loss_cls: 1.4572  decode.d7.loss_mask: 0.7719  decode.d7.loss_dice: 1.3447  decode.d8.loss_cls: 1.4090  decode.d8.loss_mask: 0.7904  decode.d8.loss_dice: 1.3740
2023/05/24 06:41:06 - mmengine - INFO - Iter(train) [100450/160000]  lr: 4.1085e-06  eta: 7:07:52  time: 0.4722  data_time: 0.0103  memory: 4885  grad_norm: 120.2164  loss: 39.9846  decode.loss_cls: 1.4521  decode.loss_mask: 0.7663  decode.loss_dice: 1.4386  decode.d0.loss_cls: 3.4215  decode.d0.loss_mask: 0.8761  decode.d0.loss_dice: 1.6835  decode.d1.loss_cls: 1.5926  decode.d1.loss_mask: 0.8328  decode.d1.loss_dice: 1.5700  decode.d2.loss_cls: 1.4866  decode.d2.loss_mask: 0.8452  decode.d2.loss_dice: 1.5400  decode.d3.loss_cls: 1.5545  decode.d3.loss_mask: 0.8156  decode.d3.loss_dice: 1.4848  decode.d4.loss_cls: 1.4517  decode.d4.loss_mask: 0.8123  decode.d4.loss_dice: 1.5057  decode.d5.loss_cls: 1.4588  decode.d5.loss_mask: 0.7758  decode.d5.loss_dice: 1.4683  decode.d6.loss_cls: 1.4601  decode.d6.loss_mask: 0.7925  decode.d6.loss_dice: 1.4537  decode.d7.loss_cls: 1.5197  decode.d7.loss_mask: 0.7839  decode.d7.loss_dice: 1.4295  decode.d8.loss_cls: 1.4816  decode.d8.loss_mask: 0.7883  decode.d8.loss_dice: 1.4424
2023/05/24 06:41:30 - mmengine - INFO - Iter(train) [100500/160000]  lr: 4.1054e-06  eta: 7:07:32  time: 0.4721  data_time: 0.0110  memory: 4804  grad_norm: 89.2927  loss: 39.2247  decode.loss_cls: 1.2857  decode.loss_mask: 0.8122  decode.loss_dice: 1.4791  decode.d0.loss_cls: 3.5064  decode.d0.loss_mask: 0.9277  decode.d0.loss_dice: 1.7215  decode.d1.loss_cls: 1.3565  decode.d1.loss_mask: 0.9120  decode.d1.loss_dice: 1.6153  decode.d2.loss_cls: 1.2957  decode.d2.loss_mask: 0.8778  decode.d2.loss_dice: 1.5576  decode.d3.loss_cls: 1.3109  decode.d3.loss_mask: 0.8203  decode.d3.loss_dice: 1.5604  decode.d4.loss_cls: 1.2604  decode.d4.loss_mask: 0.8427  decode.d4.loss_dice: 1.5412  decode.d5.loss_cls: 1.3305  decode.d5.loss_mask: 0.8255  decode.d5.loss_dice: 1.5325  decode.d6.loss_cls: 1.2782  decode.d6.loss_mask: 0.8238  decode.d6.loss_dice: 1.5327  decode.d7.loss_cls: 1.3061  decode.d7.loss_mask: 0.8162  decode.d7.loss_dice: 1.4899  decode.d8.loss_cls: 1.3021  decode.d8.loss_mask: 0.8066  decode.d8.loss_dice: 1.4972
2023/05/24 06:41:51 - mmengine - INFO - Iter(train) [100550/160000]  lr: 4.1023e-06  eta: 7:07:10  time: 0.4204  data_time: 0.0104  memory: 4847  grad_norm: 106.4084  loss: 34.6466  decode.loss_cls: 1.1776  decode.loss_mask: 0.7264  decode.loss_dice: 1.3051  decode.d0.loss_cls: 3.1588  decode.d0.loss_mask: 0.7314  decode.d0.loss_dice: 1.4997  decode.d1.loss_cls: 1.3939  decode.d1.loss_mask: 0.7584  decode.d1.loss_dice: 1.3635  decode.d2.loss_cls: 1.2737  decode.d2.loss_mask: 0.7183  decode.d2.loss_dice: 1.3090  decode.d3.loss_cls: 1.2248  decode.d3.loss_mask: 0.6985  decode.d3.loss_dice: 1.3100  decode.d4.loss_cls: 1.1822  decode.d4.loss_mask: 0.6818  decode.d4.loss_dice: 1.3123  decode.d5.loss_cls: 1.1711  decode.d5.loss_mask: 0.6900  decode.d5.loss_dice: 1.3159  decode.d6.loss_cls: 1.2067  decode.d6.loss_mask: 0.7105  decode.d6.loss_dice: 1.3222  decode.d7.loss_cls: 1.1961  decode.d7.loss_mask: 0.7120  decode.d7.loss_dice: 1.3084  decode.d8.loss_cls: 1.1548  decode.d8.loss_mask: 0.7164  decode.d8.loss_dice: 1.3171
2023/05/24 06:42:13 - mmengine - INFO - Iter(train) [100600/160000]  lr: 4.0992e-06  eta: 7:06:49  time: 0.4186  data_time: 0.0103  memory: 4882  grad_norm: 108.9068  loss: 42.1591  decode.loss_cls: 1.4231  decode.loss_mask: 0.7962  decode.loss_dice: 1.6517  decode.d0.loss_cls: 3.6317  decode.d0.loss_mask: 0.8496  decode.d0.loss_dice: 1.9289  decode.d1.loss_cls: 1.6169  decode.d1.loss_mask: 0.7879  decode.d1.loss_dice: 1.8323  decode.d2.loss_cls: 1.5429  decode.d2.loss_mask: 0.7960  decode.d2.loss_dice: 1.7262  decode.d3.loss_cls: 1.4607  decode.d3.loss_mask: 0.7874  decode.d3.loss_dice: 1.7048  decode.d4.loss_cls: 1.4391  decode.d4.loss_mask: 0.8095  decode.d4.loss_dice: 1.7148  decode.d5.loss_cls: 1.4012  decode.d5.loss_mask: 0.8079  decode.d5.loss_dice: 1.7315  decode.d6.loss_cls: 1.3973  decode.d6.loss_mask: 0.8139  decode.d6.loss_dice: 1.6737  decode.d7.loss_cls: 1.4155  decode.d7.loss_mask: 0.8268  decode.d7.loss_dice: 1.6664  decode.d8.loss_cls: 1.4269  decode.d8.loss_mask: 0.8011  decode.d8.loss_dice: 1.6973
2023/05/24 06:42:34 - mmengine - INFO - Iter(train) [100650/160000]  lr: 4.0961e-06  eta: 7:06:27  time: 0.4187  data_time: 0.0115  memory: 4982  grad_norm: 79.4044  loss: 36.2227  decode.loss_cls: 1.2993  decode.loss_mask: 0.6782  decode.loss_dice: 1.3160  decode.d0.loss_cls: 3.4361  decode.d0.loss_mask: 0.7327  decode.d0.loss_dice: 1.5411  decode.d1.loss_cls: 1.4519  decode.d1.loss_mask: 0.7221  decode.d1.loss_dice: 1.4461  decode.d2.loss_cls: 1.3688  decode.d2.loss_mask: 0.6887  decode.d2.loss_dice: 1.4223  decode.d3.loss_cls: 1.3763  decode.d3.loss_mask: 0.6949  decode.d3.loss_dice: 1.3611  decode.d4.loss_cls: 1.3575  decode.d4.loss_mask: 0.6814  decode.d4.loss_dice: 1.3262  decode.d5.loss_cls: 1.3660  decode.d5.loss_mask: 0.7020  decode.d5.loss_dice: 1.3408  decode.d6.loss_cls: 1.3299  decode.d6.loss_mask: 0.6714  decode.d6.loss_dice: 1.3109  decode.d7.loss_cls: 1.3061  decode.d7.loss_mask: 0.6698  decode.d7.loss_dice: 1.3330  decode.d8.loss_cls: 1.3153  decode.d8.loss_mask: 0.6763  decode.d8.loss_dice: 1.3002
2023/05/24 06:42:55 - mmengine - INFO - Iter(train) [100700/160000]  lr: 4.0930e-06  eta: 7:06:05  time: 0.4187  data_time: 0.0104  memory: 4901  grad_norm: 108.2588  loss: 40.3661  decode.loss_cls: 1.2744  decode.loss_mask: 0.9909  decode.loss_dice: 1.5260  decode.d0.loss_cls: 3.2539  decode.d0.loss_mask: 1.0261  decode.d0.loss_dice: 1.7219  decode.d1.loss_cls: 1.3459  decode.d1.loss_mask: 0.9994  decode.d1.loss_dice: 1.6426  decode.d2.loss_cls: 1.3227  decode.d2.loss_mask: 0.9772  decode.d2.loss_dice: 1.5512  decode.d3.loss_cls: 1.3459  decode.d3.loss_mask: 0.9444  decode.d3.loss_dice: 1.5218  decode.d4.loss_cls: 1.2817  decode.d4.loss_mask: 0.9692  decode.d4.loss_dice: 1.5234  decode.d5.loss_cls: 1.2974  decode.d5.loss_mask: 0.9629  decode.d5.loss_dice: 1.5419  decode.d6.loss_cls: 1.2798  decode.d6.loss_mask: 0.9680  decode.d6.loss_dice: 1.5446  decode.d7.loss_cls: 1.2734  decode.d7.loss_mask: 0.9803  decode.d7.loss_dice: 1.5367  decode.d8.loss_cls: 1.2359  decode.d8.loss_mask: 0.9869  decode.d8.loss_dice: 1.5396
2023/05/24 06:43:16 - mmengine - INFO - Iter(train) [100750/160000]  lr: 4.0899e-06  eta: 7:05:43  time: 0.4176  data_time: 0.0106  memory: 4835  grad_norm: 89.0978  loss: 32.7945  decode.loss_cls: 1.1017  decode.loss_mask: 0.6863  decode.loss_dice: 1.1688  decode.d0.loss_cls: 3.1085  decode.d0.loss_mask: 0.7567  decode.d0.loss_dice: 1.3816  decode.d1.loss_cls: 1.2652  decode.d1.loss_mask: 0.7292  decode.d1.loss_dice: 1.3072  decode.d2.loss_cls: 1.2309  decode.d2.loss_mask: 0.6816  decode.d2.loss_dice: 1.2023  decode.d3.loss_cls: 1.1569  decode.d3.loss_mask: 0.7035  decode.d3.loss_dice: 1.1939  decode.d4.loss_cls: 1.1615  decode.d4.loss_mask: 0.6942  decode.d4.loss_dice: 1.1871  decode.d5.loss_cls: 1.2132  decode.d5.loss_mask: 0.6705  decode.d5.loss_dice: 1.2131  decode.d6.loss_cls: 1.1866  decode.d6.loss_mask: 0.6849  decode.d6.loss_dice: 1.1441  decode.d7.loss_cls: 1.1458  decode.d7.loss_mask: 0.6779  decode.d7.loss_dice: 1.1542  decode.d8.loss_cls: 1.1085  decode.d8.loss_mask: 0.7228  decode.d8.loss_dice: 1.1559
2023/05/24 06:43:37 - mmengine - INFO - Iter(train) [100800/160000]  lr: 4.0868e-06  eta: 7:05:21  time: 0.4202  data_time: 0.0103  memory: 4866  grad_norm: 96.7514  loss: 31.3235  decode.loss_cls: 0.9639  decode.loss_mask: 0.7340  decode.loss_dice: 1.1219  decode.d0.loss_cls: 2.8747  decode.d0.loss_mask: 0.7568  decode.d0.loss_dice: 1.3820  decode.d1.loss_cls: 1.1213  decode.d1.loss_mask: 0.8409  decode.d1.loss_dice: 1.2981  decode.d2.loss_cls: 1.1054  decode.d2.loss_mask: 0.7654  decode.d2.loss_dice: 1.2036  decode.d3.loss_cls: 0.9899  decode.d3.loss_mask: 0.7688  decode.d3.loss_dice: 1.1689  decode.d4.loss_cls: 1.0180  decode.d4.loss_mask: 0.7429  decode.d4.loss_dice: 1.1272  decode.d5.loss_cls: 0.9934  decode.d5.loss_mask: 0.7310  decode.d5.loss_dice: 1.1039  decode.d6.loss_cls: 0.9868  decode.d6.loss_mask: 0.7428  decode.d6.loss_dice: 1.1298  decode.d7.loss_cls: 0.9552  decode.d7.loss_mask: 0.7339  decode.d7.loss_dice: 1.1321  decode.d8.loss_cls: 0.9589  decode.d8.loss_mask: 0.7396  decode.d8.loss_dice: 1.1325
2023/05/24 06:43:59 - mmengine - INFO - Iter(train) [100850/160000]  lr: 4.0837e-06  eta: 7:05:00  time: 0.4327  data_time: 0.0105  memory: 4863  grad_norm: 106.5977  loss: 32.9590  decode.loss_cls: 1.2362  decode.loss_mask: 0.6924  decode.loss_dice: 1.0547  decode.d0.loss_cls: 3.0500  decode.d0.loss_mask: 0.8456  decode.d0.loss_dice: 1.3265  decode.d1.loss_cls: 1.2116  decode.d1.loss_mask: 0.7851  decode.d1.loss_dice: 1.1736  decode.d2.loss_cls: 1.2204  decode.d2.loss_mask: 0.7842  decode.d2.loss_dice: 1.1512  decode.d3.loss_cls: 1.2385  decode.d3.loss_mask: 0.7763  decode.d3.loss_dice: 1.1199  decode.d4.loss_cls: 1.2248  decode.d4.loss_mask: 0.7876  decode.d4.loss_dice: 1.1139  decode.d5.loss_cls: 1.2278  decode.d5.loss_mask: 0.7770  decode.d5.loss_dice: 1.0970  decode.d6.loss_cls: 1.2448  decode.d6.loss_mask: 0.7122  decode.d6.loss_dice: 1.0686  decode.d7.loss_cls: 1.2167  decode.d7.loss_mask: 0.7292  decode.d7.loss_dice: 1.0924  decode.d8.loss_cls: 1.2242  decode.d8.loss_mask: 0.7143  decode.d8.loss_dice: 1.0622
2023/05/24 06:44:20 - mmengine - INFO - Iter(train) [100900/160000]  lr: 4.0806e-06  eta: 7:04:38  time: 0.4271  data_time: 0.0105  memory: 4839  grad_norm: 113.9977  loss: 38.7404  decode.loss_cls: 1.1587  decode.loss_mask: 0.8788  decode.loss_dice: 1.5591  decode.d0.loss_cls: 3.0828  decode.d0.loss_mask: 0.8281  decode.d0.loss_dice: 1.7768  decode.d1.loss_cls: 1.2951  decode.d1.loss_mask: 0.8930  decode.d1.loss_dice: 1.6859  decode.d2.loss_cls: 1.2526  decode.d2.loss_mask: 0.8978  decode.d2.loss_dice: 1.6197  decode.d3.loss_cls: 1.2458  decode.d3.loss_mask: 0.8834  decode.d3.loss_dice: 1.5851  decode.d4.loss_cls: 1.2021  decode.d4.loss_mask: 0.8731  decode.d4.loss_dice: 1.5722  decode.d5.loss_cls: 1.1852  decode.d5.loss_mask: 0.8747  decode.d5.loss_dice: 1.5765  decode.d6.loss_cls: 1.1777  decode.d6.loss_mask: 0.8796  decode.d6.loss_dice: 1.5586  decode.d7.loss_cls: 1.1386  decode.d7.loss_mask: 0.8862  decode.d7.loss_dice: 1.5555  decode.d8.loss_cls: 1.1786  decode.d8.loss_mask: 0.8866  decode.d8.loss_dice: 1.5527
2023/05/24 06:44:41 - mmengine - INFO - Iter(train) [100950/160000]  lr: 4.0775e-06  eta: 7:04:16  time: 0.4161  data_time: 0.0103  memory: 4844  grad_norm: 94.3899  loss: 26.3595  decode.loss_cls: 0.9791  decode.loss_mask: 0.5815  decode.loss_dice: 0.8930  decode.d0.loss_cls: 2.5140  decode.d0.loss_mask: 0.6348  decode.d0.loss_dice: 0.9786  decode.d1.loss_cls: 0.9298  decode.d1.loss_mask: 0.6015  decode.d1.loss_dice: 0.9477  decode.d2.loss_cls: 0.9960  decode.d2.loss_mask: 0.5696  decode.d2.loss_dice: 0.9275  decode.d3.loss_cls: 0.9811  decode.d3.loss_mask: 0.6078  decode.d3.loss_dice: 0.9188  decode.d4.loss_cls: 0.9782  decode.d4.loss_mask: 0.5993  decode.d4.loss_dice: 0.8919  decode.d5.loss_cls: 0.9594  decode.d5.loss_mask: 0.5787  decode.d5.loss_dice: 0.9119  decode.d6.loss_cls: 1.0107  decode.d6.loss_mask: 0.5834  decode.d6.loss_dice: 0.8946  decode.d7.loss_cls: 0.9552  decode.d7.loss_mask: 0.5996  decode.d7.loss_dice: 0.8992  decode.d8.loss_cls: 0.9368  decode.d8.loss_mask: 0.6087  decode.d8.loss_dice: 0.8913
2023/05/24 06:45:02 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 06:45:02 - mmengine - INFO - Iter(train) [101000/160000]  lr: 4.0744e-06  eta: 7:03:54  time: 0.4182  data_time: 0.0110  memory: 4804  grad_norm: 89.9630  loss: 37.4544  decode.loss_cls: 1.2969  decode.loss_mask: 0.8515  decode.loss_dice: 1.2806  decode.d0.loss_cls: 3.4547  decode.d0.loss_mask: 0.8996  decode.d0.loss_dice: 1.4933  decode.d1.loss_cls: 1.3800  decode.d1.loss_mask: 0.9027  decode.d1.loss_dice: 1.3776  decode.d2.loss_cls: 1.2806  decode.d2.loss_mask: 0.9152  decode.d2.loss_dice: 1.3795  decode.d3.loss_cls: 1.3537  decode.d3.loss_mask: 0.8680  decode.d3.loss_dice: 1.3055  decode.d4.loss_cls: 1.2635  decode.d4.loss_mask: 0.8603  decode.d4.loss_dice: 1.3184  decode.d5.loss_cls: 1.2817  decode.d5.loss_mask: 0.8890  decode.d5.loss_dice: 1.3030  decode.d6.loss_cls: 1.3533  decode.d6.loss_mask: 0.8732  decode.d6.loss_dice: 1.3162  decode.d7.loss_cls: 1.2758  decode.d7.loss_mask: 0.8979  decode.d7.loss_dice: 1.2887  decode.d8.loss_cls: 1.3378  decode.d8.loss_mask: 0.8706  decode.d8.loss_dice: 1.2858
2023/05/24 06:45:02 - mmengine - INFO - Saving checkpoint at 101000 iterations
2023/05/24 06:45:28 - mmengine - INFO - Iter(train) [101050/160000]  lr: 4.0713e-06  eta: 7:03:35  time: 0.4225  data_time: 0.0106  memory: 4895  grad_norm: 95.9436  loss: 41.9101  decode.loss_cls: 1.4285  decode.loss_mask: 0.9337  decode.loss_dice: 1.4802  decode.d0.loss_cls: 3.3007  decode.d0.loss_mask: 1.0615  decode.d0.loss_dice: 1.8375  decode.d1.loss_cls: 1.5839  decode.d1.loss_mask: 1.0322  decode.d1.loss_dice: 1.6616  decode.d2.loss_cls: 1.5010  decode.d2.loss_mask: 1.0211  decode.d2.loss_dice: 1.6053  decode.d3.loss_cls: 1.4732  decode.d3.loss_mask: 1.0063  decode.d3.loss_dice: 1.5279  decode.d4.loss_cls: 1.4410  decode.d4.loss_mask: 1.0130  decode.d4.loss_dice: 1.5453  decode.d5.loss_cls: 1.4723  decode.d5.loss_mask: 0.9410  decode.d5.loss_dice: 1.4852  decode.d6.loss_cls: 1.4150  decode.d6.loss_mask: 0.9398  decode.d6.loss_dice: 1.4880  decode.d7.loss_cls: 1.4522  decode.d7.loss_mask: 0.9367  decode.d7.loss_dice: 1.4718  decode.d8.loss_cls: 1.4436  decode.d8.loss_mask: 0.9307  decode.d8.loss_dice: 1.4799
2023/05/24 06:45:51 - mmengine - INFO - Iter(train) [101100/160000]  lr: 4.0682e-06  eta: 7:03:15  time: 0.4232  data_time: 0.0105  memory: 4807  grad_norm: 113.7245  loss: 37.6407  decode.loss_cls: 1.2703  decode.loss_mask: 0.7746  decode.loss_dice: 1.4328  decode.d0.loss_cls: 2.9640  decode.d0.loss_mask: 0.8402  decode.d0.loss_dice: 1.6431  decode.d1.loss_cls: 1.3412  decode.d1.loss_mask: 0.8107  decode.d1.loss_dice: 1.5704  decode.d2.loss_cls: 1.3807  decode.d2.loss_mask: 0.7693  decode.d2.loss_dice: 1.5113  decode.d3.loss_cls: 1.3902  decode.d3.loss_mask: 0.7816  decode.d3.loss_dice: 1.4667  decode.d4.loss_cls: 1.3129  decode.d4.loss_mask: 0.7735  decode.d4.loss_dice: 1.4824  decode.d5.loss_cls: 1.3060  decode.d5.loss_mask: 0.7650  decode.d5.loss_dice: 1.5150  decode.d6.loss_cls: 1.2937  decode.d6.loss_mask: 0.7595  decode.d6.loss_dice: 1.4726  decode.d7.loss_cls: 1.2828  decode.d7.loss_mask: 0.7591  decode.d7.loss_dice: 1.4671  decode.d8.loss_cls: 1.2825  decode.d8.loss_mask: 0.7451  decode.d8.loss_dice: 1.4761
2023/05/24 06:46:13 - mmengine - INFO - Iter(train) [101150/160000]  lr: 4.0651e-06  eta: 7:02:53  time: 0.4705  data_time: 0.0104  memory: 4845  grad_norm: 98.6540  loss: 32.2965  decode.loss_cls: 0.9446  decode.loss_mask: 0.6979  decode.loss_dice: 1.2235  decode.d0.loss_cls: 3.1660  decode.d0.loss_mask: 0.7717  decode.d0.loss_dice: 1.5103  decode.d1.loss_cls: 1.0359  decode.d1.loss_mask: 0.8202  decode.d1.loss_dice: 1.4062  decode.d2.loss_cls: 0.9768  decode.d2.loss_mask: 0.7756  decode.d2.loss_dice: 1.3286  decode.d3.loss_cls: 0.9837  decode.d3.loss_mask: 0.7220  decode.d3.loss_dice: 1.2694  decode.d4.loss_cls: 0.9706  decode.d4.loss_mask: 0.7116  decode.d4.loss_dice: 1.2493  decode.d5.loss_cls: 0.9646  decode.d5.loss_mask: 0.7107  decode.d5.loss_dice: 1.2520  decode.d6.loss_cls: 0.9858  decode.d6.loss_mask: 0.7107  decode.d6.loss_dice: 1.2501  decode.d7.loss_cls: 0.9732  decode.d7.loss_mask: 0.7219  decode.d7.loss_dice: 1.2621  decode.d8.loss_cls: 0.9136  decode.d8.loss_mask: 0.7289  decode.d8.loss_dice: 1.2589
2023/05/24 06:46:35 - mmengine - INFO - Iter(train) [101200/160000]  lr: 4.0619e-06  eta: 7:02:32  time: 0.4203  data_time: 0.0105  memory: 4837  grad_norm: 114.8507  loss: 44.0014  decode.loss_cls: 1.5289  decode.loss_mask: 0.9136  decode.loss_dice: 1.5909  decode.d0.loss_cls: 3.5722  decode.d0.loss_mask: 0.9860  decode.d0.loss_dice: 1.9469  decode.d1.loss_cls: 1.8031  decode.d1.loss_mask: 0.9344  decode.d1.loss_dice: 1.7011  decode.d2.loss_cls: 1.6584  decode.d2.loss_mask: 0.9151  decode.d2.loss_dice: 1.6714  decode.d3.loss_cls: 1.6088  decode.d3.loss_mask: 0.9250  decode.d3.loss_dice: 1.6039  decode.d4.loss_cls: 1.6261  decode.d4.loss_mask: 0.9385  decode.d4.loss_dice: 1.6466  decode.d5.loss_cls: 1.5764  decode.d5.loss_mask: 0.9291  decode.d5.loss_dice: 1.6244  decode.d6.loss_cls: 1.5187  decode.d6.loss_mask: 0.9339  decode.d6.loss_dice: 1.6230  decode.d7.loss_cls: 1.5892  decode.d7.loss_mask: 0.9315  decode.d7.loss_dice: 1.6152  decode.d8.loss_cls: 1.5303  decode.d8.loss_mask: 0.9516  decode.d8.loss_dice: 1.6073
2023/05/24 06:46:57 - mmengine - INFO - Iter(train) [101250/160000]  lr: 4.0588e-06  eta: 7:02:11  time: 0.4264  data_time: 0.0105  memory: 4869  grad_norm: 103.2705  loss: 37.6926  decode.loss_cls: 1.2501  decode.loss_mask: 0.7849  decode.loss_dice: 1.4624  decode.d0.loss_cls: 3.2489  decode.d0.loss_mask: 0.8317  decode.d0.loss_dice: 1.7106  decode.d1.loss_cls: 1.3175  decode.d1.loss_mask: 0.8081  decode.d1.loss_dice: 1.5938  decode.d2.loss_cls: 1.2333  decode.d2.loss_mask: 0.8089  decode.d2.loss_dice: 1.5764  decode.d3.loss_cls: 1.2443  decode.d3.loss_mask: 0.7935  decode.d3.loss_dice: 1.5079  decode.d4.loss_cls: 1.3000  decode.d4.loss_mask: 0.7729  decode.d4.loss_dice: 1.4689  decode.d5.loss_cls: 1.2846  decode.d5.loss_mask: 0.7726  decode.d5.loss_dice: 1.4728  decode.d6.loss_cls: 1.2578  decode.d6.loss_mask: 0.7768  decode.d6.loss_dice: 1.4543  decode.d7.loss_cls: 1.2423  decode.d7.loss_mask: 0.7838  decode.d7.loss_dice: 1.4576  decode.d8.loss_cls: 1.2107  decode.d8.loss_mask: 0.7880  decode.d8.loss_dice: 1.4771
2023/05/24 06:47:19 - mmengine - INFO - Iter(train) [101300/160000]  lr: 4.0557e-06  eta: 7:01:49  time: 0.4203  data_time: 0.0106  memory: 4886  grad_norm: 101.0536  loss: 45.6544  decode.loss_cls: 1.5313  decode.loss_mask: 0.8671  decode.loss_dice: 1.8498  decode.d0.loss_cls: 3.2601  decode.d0.loss_mask: 0.9879  decode.d0.loss_dice: 2.1373  decode.d1.loss_cls: 1.7066  decode.d1.loss_mask: 0.9350  decode.d1.loss_dice: 2.0618  decode.d2.loss_cls: 1.5920  decode.d2.loss_mask: 0.9072  decode.d2.loss_dice: 1.8920  decode.d3.loss_cls: 1.5455  decode.d3.loss_mask: 0.8771  decode.d3.loss_dice: 1.8937  decode.d4.loss_cls: 1.5360  decode.d4.loss_mask: 0.8796  decode.d4.loss_dice: 1.9420  decode.d5.loss_cls: 1.5461  decode.d5.loss_mask: 0.9244  decode.d5.loss_dice: 1.9201  decode.d6.loss_cls: 1.5446  decode.d6.loss_mask: 0.8896  decode.d6.loss_dice: 1.8756  decode.d7.loss_cls: 1.4863  decode.d7.loss_mask: 0.8842  decode.d7.loss_dice: 1.9207  decode.d8.loss_cls: 1.5191  decode.d8.loss_mask: 0.8680  decode.d8.loss_dice: 1.8735
2023/05/24 06:47:40 - mmengine - INFO - Iter(train) [101350/160000]  lr: 4.0526e-06  eta: 7:01:27  time: 0.4194  data_time: 0.0103  memory: 4845  grad_norm: 122.2550  loss: 39.1856  decode.loss_cls: 1.3153  decode.loss_mask: 0.7909  decode.loss_dice: 1.4512  decode.d0.loss_cls: 3.6535  decode.d0.loss_mask: 0.8741  decode.d0.loss_dice: 1.7002  decode.d1.loss_cls: 1.4317  decode.d1.loss_mask: 0.8898  decode.d1.loss_dice: 1.5622  decode.d2.loss_cls: 1.3173  decode.d2.loss_mask: 0.9270  decode.d2.loss_dice: 1.5405  decode.d3.loss_cls: 1.3675  decode.d3.loss_mask: 0.8602  decode.d3.loss_dice: 1.4769  decode.d4.loss_cls: 1.3185  decode.d4.loss_mask: 0.8521  decode.d4.loss_dice: 1.4958  decode.d5.loss_cls: 1.2763  decode.d5.loss_mask: 0.8340  decode.d5.loss_dice: 1.4760  decode.d6.loss_cls: 1.3909  decode.d6.loss_mask: 0.8181  decode.d6.loss_dice: 1.4369  decode.d7.loss_cls: 1.2904  decode.d7.loss_mask: 0.8254  decode.d7.loss_dice: 1.4573  decode.d8.loss_cls: 1.3277  decode.d8.loss_mask: 0.8203  decode.d8.loss_dice: 1.4076
2023/05/24 06:48:01 - mmengine - INFO - Iter(train) [101400/160000]  lr: 4.0495e-06  eta: 7:01:06  time: 0.4171  data_time: 0.0108  memory: 4873  grad_norm: 87.5437  loss: 37.5653  decode.loss_cls: 1.2688  decode.loss_mask: 0.8255  decode.loss_dice: 1.3410  decode.d0.loss_cls: 3.2700  decode.d0.loss_mask: 0.8782  decode.d0.loss_dice: 1.6065  decode.d1.loss_cls: 1.4261  decode.d1.loss_mask: 0.8670  decode.d1.loss_dice: 1.4801  decode.d2.loss_cls: 1.3962  decode.d2.loss_mask: 0.9302  decode.d2.loss_dice: 1.4233  decode.d3.loss_cls: 1.3758  decode.d3.loss_mask: 0.8485  decode.d3.loss_dice: 1.3590  decode.d4.loss_cls: 1.3017  decode.d4.loss_mask: 0.8652  decode.d4.loss_dice: 1.3615  decode.d5.loss_cls: 1.2981  decode.d5.loss_mask: 0.8484  decode.d5.loss_dice: 1.3405  decode.d6.loss_cls: 1.2926  decode.d6.loss_mask: 0.8386  decode.d6.loss_dice: 1.3022  decode.d7.loss_cls: 1.2741  decode.d7.loss_mask: 0.8346  decode.d7.loss_dice: 1.3238  decode.d8.loss_cls: 1.2346  decode.d8.loss_mask: 0.8320  decode.d8.loss_dice: 1.3212
2023/05/24 06:48:23 - mmengine - INFO - Iter(train) [101450/160000]  lr: 4.0464e-06  eta: 7:00:44  time: 0.4164  data_time: 0.0112  memory: 4982  grad_norm: 135.8680  loss: 32.2192  decode.loss_cls: 0.8673  decode.loss_mask: 0.6943  decode.loss_dice: 1.3739  decode.d0.loss_cls: 2.8036  decode.d0.loss_mask: 0.7020  decode.d0.loss_dice: 1.5702  decode.d1.loss_cls: 0.9766  decode.d1.loss_mask: 0.7433  decode.d1.loss_dice: 1.4597  decode.d2.loss_cls: 0.9340  decode.d2.loss_mask: 0.7157  decode.d2.loss_dice: 1.4371  decode.d3.loss_cls: 0.9451  decode.d3.loss_mask: 0.6912  decode.d3.loss_dice: 1.4034  decode.d4.loss_cls: 0.9011  decode.d4.loss_mask: 0.6752  decode.d4.loss_dice: 1.3703  decode.d5.loss_cls: 0.8758  decode.d5.loss_mask: 0.6712  decode.d5.loss_dice: 1.3972  decode.d6.loss_cls: 0.9731  decode.d6.loss_mask: 0.6868  decode.d6.loss_dice: 1.3363  decode.d7.loss_cls: 0.9746  decode.d7.loss_mask: 0.6996  decode.d7.loss_dice: 1.3543  decode.d8.loss_cls: 0.9467  decode.d8.loss_mask: 0.6778  decode.d8.loss_dice: 1.3618
2023/05/24 06:48:44 - mmengine - INFO - Iter(train) [101500/160000]  lr: 4.0433e-06  eta: 7:00:22  time: 0.4148  data_time: 0.0106  memory: 4847  grad_norm: 155.6483  loss: 42.7575  decode.loss_cls: 1.7501  decode.loss_mask: 0.8160  decode.loss_dice: 1.4602  decode.d0.loss_cls: 3.4640  decode.d0.loss_mask: 0.8335  decode.d0.loss_dice: 1.7588  decode.d1.loss_cls: 1.7923  decode.d1.loss_mask: 0.8352  decode.d1.loss_dice: 1.5992  decode.d2.loss_cls: 1.7320  decode.d2.loss_mask: 0.8250  decode.d2.loss_dice: 1.5641  decode.d3.loss_cls: 1.8094  decode.d3.loss_mask: 0.7946  decode.d3.loss_dice: 1.4625  decode.d4.loss_cls: 1.7771  decode.d4.loss_mask: 0.7795  decode.d4.loss_dice: 1.4976  decode.d5.loss_cls: 1.7737  decode.d5.loss_mask: 0.7868  decode.d5.loss_dice: 1.4964  decode.d6.loss_cls: 1.8150  decode.d6.loss_mask: 0.7988  decode.d6.loss_dice: 1.4506  decode.d7.loss_cls: 1.6998  decode.d7.loss_mask: 0.8220  decode.d7.loss_dice: 1.4969  decode.d8.loss_cls: 1.7456  decode.d8.loss_mask: 0.8439  decode.d8.loss_dice: 1.4768
2023/05/24 06:49:05 - mmengine - INFO - Iter(train) [101550/160000]  lr: 4.0402e-06  eta: 7:00:01  time: 0.4384  data_time: 0.0107  memory: 4861  grad_norm: 97.2838  loss: 41.8486  decode.loss_cls: 1.5523  decode.loss_mask: 0.8085  decode.loss_dice: 1.5177  decode.d0.loss_cls: 3.3796  decode.d0.loss_mask: 0.9702  decode.d0.loss_dice: 1.7210  decode.d1.loss_cls: 1.6945  decode.d1.loss_mask: 0.9294  decode.d1.loss_dice: 1.6749  decode.d2.loss_cls: 1.6797  decode.d2.loss_mask: 0.8728  decode.d2.loss_dice: 1.6334  decode.d3.loss_cls: 1.6533  decode.d3.loss_mask: 0.7818  decode.d3.loss_dice: 1.5541  decode.d4.loss_cls: 1.5864  decode.d4.loss_mask: 0.7653  decode.d4.loss_dice: 1.5466  decode.d5.loss_cls: 1.6004  decode.d5.loss_mask: 0.7803  decode.d5.loss_dice: 1.5329  decode.d6.loss_cls: 1.5499  decode.d6.loss_mask: 0.7870  decode.d6.loss_dice: 1.5337  decode.d7.loss_cls: 1.5806  decode.d7.loss_mask: 0.7935  decode.d7.loss_dice: 1.5169  decode.d8.loss_cls: 1.5099  decode.d8.loss_mask: 0.8061  decode.d8.loss_dice: 1.5358
2023/05/24 06:49:27 - mmengine - INFO - Iter(train) [101600/160000]  lr: 4.0371e-06  eta: 6:59:39  time: 0.4301  data_time: 0.0106  memory: 4906  grad_norm: 102.7160  loss: 45.0110  decode.loss_cls: 1.5212  decode.loss_mask: 0.8813  decode.loss_dice: 1.7839  decode.d0.loss_cls: 3.3480  decode.d0.loss_mask: 0.8970  decode.d0.loss_dice: 2.0350  decode.d1.loss_cls: 1.6633  decode.d1.loss_mask: 0.8951  decode.d1.loss_dice: 1.9456  decode.d2.loss_cls: 1.6145  decode.d2.loss_mask: 0.8937  decode.d2.loss_dice: 1.8481  decode.d3.loss_cls: 1.6375  decode.d3.loss_mask: 0.8955  decode.d3.loss_dice: 1.8114  decode.d4.loss_cls: 1.6429  decode.d4.loss_mask: 0.8835  decode.d4.loss_dice: 1.8314  decode.d5.loss_cls: 1.5770  decode.d5.loss_mask: 0.8790  decode.d5.loss_dice: 1.7815  decode.d6.loss_cls: 1.5698  decode.d6.loss_mask: 0.8721  decode.d6.loss_dice: 1.7780  decode.d7.loss_cls: 1.6202  decode.d7.loss_mask: 0.8829  decode.d7.loss_dice: 1.8125  decode.d8.loss_cls: 1.5039  decode.d8.loss_mask: 0.8733  decode.d8.loss_dice: 1.8320
2023/05/24 06:49:48 - mmengine - INFO - Iter(train) [101650/160000]  lr: 4.0340e-06  eta: 6:59:17  time: 0.4233  data_time: 0.0104  memory: 4838  grad_norm: 99.2825  loss: 30.7707  decode.loss_cls: 1.0515  decode.loss_mask: 0.6433  decode.loss_dice: 1.1138  decode.d0.loss_cls: 3.0756  decode.d0.loss_mask: 0.7433  decode.d0.loss_dice: 1.3206  decode.d1.loss_cls: 1.1432  decode.d1.loss_mask: 0.6869  decode.d1.loss_dice: 1.1785  decode.d2.loss_cls: 1.1311  decode.d2.loss_mask: 0.6362  decode.d2.loss_dice: 1.1265  decode.d3.loss_cls: 1.0930  decode.d3.loss_mask: 0.6409  decode.d3.loss_dice: 1.1316  decode.d4.loss_cls: 1.0559  decode.d4.loss_mask: 0.6438  decode.d4.loss_dice: 1.1139  decode.d5.loss_cls: 1.0648  decode.d5.loss_mask: 0.6487  decode.d5.loss_dice: 1.0997  decode.d6.loss_cls: 1.1087  decode.d6.loss_mask: 0.6240  decode.d6.loss_dice: 1.0780  decode.d7.loss_cls: 1.0626  decode.d7.loss_mask: 0.6344  decode.d7.loss_dice: 1.1175  decode.d8.loss_cls: 1.0624  decode.d8.loss_mask: 0.6380  decode.d8.loss_dice: 1.1022
2023/05/24 06:50:09 - mmengine - INFO - Iter(train) [101700/160000]  lr: 4.0308e-06  eta: 6:58:55  time: 0.4326  data_time: 0.0108  memory: 4910  grad_norm: 125.1646  loss: 38.9635  decode.loss_cls: 1.3746  decode.loss_mask: 0.8544  decode.loss_dice: 1.4346  decode.d0.loss_cls: 3.3149  decode.d0.loss_mask: 0.8853  decode.d0.loss_dice: 1.7086  decode.d1.loss_cls: 1.4552  decode.d1.loss_mask: 0.8923  decode.d1.loss_dice: 1.5946  decode.d2.loss_cls: 1.3858  decode.d2.loss_mask: 0.8695  decode.d2.loss_dice: 1.5284  decode.d3.loss_cls: 1.3781  decode.d3.loss_mask: 0.8570  decode.d3.loss_dice: 1.4305  decode.d4.loss_cls: 1.3511  decode.d4.loss_mask: 0.8486  decode.d4.loss_dice: 1.4386  decode.d5.loss_cls: 1.3105  decode.d5.loss_mask: 0.8294  decode.d5.loss_dice: 1.4380  decode.d6.loss_cls: 1.2908  decode.d6.loss_mask: 0.8445  decode.d6.loss_dice: 1.4455  decode.d7.loss_cls: 1.3706  decode.d7.loss_mask: 0.8409  decode.d7.loss_dice: 1.4217  decode.d8.loss_cls: 1.2862  decode.d8.loss_mask: 0.8432  decode.d8.loss_dice: 1.4400
2023/05/24 06:50:32 - mmengine - INFO - Iter(train) [101750/160000]  lr: 4.0277e-06  eta: 6:58:34  time: 0.4226  data_time: 0.0104  memory: 4824  grad_norm: 94.0964  loss: 35.4487  decode.loss_cls: 1.2297  decode.loss_mask: 0.7610  decode.loss_dice: 1.2770  decode.d0.loss_cls: 2.9240  decode.d0.loss_mask: 0.7350  decode.d0.loss_dice: 1.4622  decode.d1.loss_cls: 1.3571  decode.d1.loss_mask: 0.8149  decode.d1.loss_dice: 1.4017  decode.d2.loss_cls: 1.3170  decode.d2.loss_mask: 0.8129  decode.d2.loss_dice: 1.3432  decode.d3.loss_cls: 1.3149  decode.d3.loss_mask: 0.8117  decode.d3.loss_dice: 1.3324  decode.d4.loss_cls: 1.1989  decode.d4.loss_mask: 0.8294  decode.d4.loss_dice: 1.3441  decode.d5.loss_cls: 1.2792  decode.d5.loss_mask: 0.7898  decode.d5.loss_dice: 1.3241  decode.d6.loss_cls: 1.1939  decode.d6.loss_mask: 0.7713  decode.d6.loss_dice: 1.2999  decode.d7.loss_cls: 1.2184  decode.d7.loss_mask: 0.7523  decode.d7.loss_dice: 1.2808  decode.d8.loss_cls: 1.2340  decode.d8.loss_mask: 0.7595  decode.d8.loss_dice: 1.2786
2023/05/24 06:50:55 - mmengine - INFO - Iter(train) [101800/160000]  lr: 4.0246e-06  eta: 6:58:14  time: 0.4837  data_time: 0.0106  memory: 4837  grad_norm: 89.6261  loss: 34.6625  decode.loss_cls: 1.1755  decode.loss_mask: 0.7355  decode.loss_dice: 1.1966  decode.d0.loss_cls: 3.5904  decode.d0.loss_mask: 0.8810  decode.d0.loss_dice: 1.4123  decode.d1.loss_cls: 1.2991  decode.d1.loss_mask: 0.7949  decode.d1.loss_dice: 1.3273  decode.d2.loss_cls: 1.2640  decode.d2.loss_mask: 0.7609  decode.d2.loss_dice: 1.2610  decode.d3.loss_cls: 1.2121  decode.d3.loss_mask: 0.7681  decode.d3.loss_dice: 1.2232  decode.d4.loss_cls: 1.2505  decode.d4.loss_mask: 0.7300  decode.d4.loss_dice: 1.2215  decode.d5.loss_cls: 1.2409  decode.d5.loss_mask: 0.7396  decode.d5.loss_dice: 1.2072  decode.d6.loss_cls: 1.1867  decode.d6.loss_mask: 0.7317  decode.d6.loss_dice: 1.1991  decode.d7.loss_cls: 1.2384  decode.d7.loss_mask: 0.7325  decode.d7.loss_dice: 1.1822  decode.d8.loss_cls: 1.1843  decode.d8.loss_mask: 0.7290  decode.d8.loss_dice: 1.1871
2023/05/24 06:51:18 - mmengine - INFO - Iter(train) [101850/160000]  lr: 4.0215e-06  eta: 6:57:53  time: 0.4183  data_time: 0.0104  memory: 4845  grad_norm: 84.3531  loss: 28.2364  decode.loss_cls: 0.8795  decode.loss_mask: 0.7669  decode.loss_dice: 0.9685  decode.d0.loss_cls: 2.7018  decode.d0.loss_mask: 0.8266  decode.d0.loss_dice: 1.1169  decode.d1.loss_cls: 0.9678  decode.d1.loss_mask: 0.7871  decode.d1.loss_dice: 1.0372  decode.d2.loss_cls: 0.8798  decode.d2.loss_mask: 0.7824  decode.d2.loss_dice: 1.0203  decode.d3.loss_cls: 0.9162  decode.d3.loss_mask: 0.7505  decode.d3.loss_dice: 0.9638  decode.d4.loss_cls: 0.8961  decode.d4.loss_mask: 0.7427  decode.d4.loss_dice: 0.9705  decode.d5.loss_cls: 0.8859  decode.d5.loss_mask: 0.7177  decode.d5.loss_dice: 0.9580  decode.d6.loss_cls: 0.8140  decode.d6.loss_mask: 0.7910  decode.d6.loss_dice: 0.9407  decode.d7.loss_cls: 0.8287  decode.d7.loss_mask: 0.7923  decode.d7.loss_dice: 0.9682  decode.d8.loss_cls: 0.8702  decode.d8.loss_mask: 0.7483  decode.d8.loss_dice: 0.9470
2023/05/24 06:51:39 - mmengine - INFO - Iter(train) [101900/160000]  lr: 4.0184e-06  eta: 6:57:31  time: 0.4209  data_time: 0.0102  memory: 4847  grad_norm: 85.7933  loss: 31.3334  decode.loss_cls: 1.1260  decode.loss_mask: 0.6637  decode.loss_dice: 1.0284  decode.d0.loss_cls: 2.9333  decode.d0.loss_mask: 0.7271  decode.d0.loss_dice: 1.2971  decode.d1.loss_cls: 1.2730  decode.d1.loss_mask: 0.7329  decode.d1.loss_dice: 1.2144  decode.d2.loss_cls: 1.1816  decode.d2.loss_mask: 0.7300  decode.d2.loss_dice: 1.1364  decode.d3.loss_cls: 1.1168  decode.d3.loss_mask: 0.6846  decode.d3.loss_dice: 1.0553  decode.d4.loss_cls: 1.1346  decode.d4.loss_mask: 0.7143  decode.d4.loss_dice: 1.0649  decode.d5.loss_cls: 1.1823  decode.d5.loss_mask: 0.7107  decode.d5.loss_dice: 1.0360  decode.d6.loss_cls: 1.1259  decode.d6.loss_mask: 0.6787  decode.d6.loss_dice: 1.0137  decode.d7.loss_cls: 1.2047  decode.d7.loss_mask: 0.6684  decode.d7.loss_dice: 1.0284  decode.d8.loss_cls: 1.1507  decode.d8.loss_mask: 0.6926  decode.d8.loss_dice: 1.0270
2023/05/24 06:52:00 - mmengine - INFO - Iter(train) [101950/160000]  lr: 4.0153e-06  eta: 6:57:09  time: 0.4114  data_time: 0.0104  memory: 4857  grad_norm: 110.9312  loss: 32.6128  decode.loss_cls: 1.0320  decode.loss_mask: 0.6765  decode.loss_dice: 1.2220  decode.d0.loss_cls: 3.2705  decode.d0.loss_mask: 0.7293  decode.d0.loss_dice: 1.4788  decode.d1.loss_cls: 1.1517  decode.d1.loss_mask: 0.6981  decode.d1.loss_dice: 1.3571  decode.d2.loss_cls: 1.0733  decode.d2.loss_mask: 0.6885  decode.d2.loss_dice: 1.3079  decode.d3.loss_cls: 1.0442  decode.d3.loss_mask: 0.6887  decode.d3.loss_dice: 1.2632  decode.d4.loss_cls: 1.0250  decode.d4.loss_mask: 0.6922  decode.d4.loss_dice: 1.2893  decode.d5.loss_cls: 1.0828  decode.d5.loss_mask: 0.6751  decode.d5.loss_dice: 1.2496  decode.d6.loss_cls: 1.0745  decode.d6.loss_mask: 0.6793  decode.d6.loss_dice: 1.2287  decode.d7.loss_cls: 1.0384  decode.d7.loss_mask: 0.6746  decode.d7.loss_dice: 1.2221  decode.d8.loss_cls: 1.0899  decode.d8.loss_mask: 0.6806  decode.d8.loss_dice: 1.2288
2023/05/24 06:52:21 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 06:52:21 - mmengine - INFO - Iter(train) [102000/160000]  lr: 4.0122e-06  eta: 6:56:48  time: 0.4239  data_time: 0.0107  memory: 4837  grad_norm: 99.4166  loss: 33.6282  decode.loss_cls: 1.2844  decode.loss_mask: 0.7377  decode.loss_dice: 1.0867  decode.d0.loss_cls: 3.1571  decode.d0.loss_mask: 0.8010  decode.d0.loss_dice: 1.2815  decode.d1.loss_cls: 1.3737  decode.d1.loss_mask: 0.7510  decode.d1.loss_dice: 1.1850  decode.d2.loss_cls: 1.3090  decode.d2.loss_mask: 0.7584  decode.d2.loss_dice: 1.1669  decode.d3.loss_cls: 1.2932  decode.d3.loss_mask: 0.7627  decode.d3.loss_dice: 1.1520  decode.d4.loss_cls: 1.2160  decode.d4.loss_mask: 0.7485  decode.d4.loss_dice: 1.1394  decode.d5.loss_cls: 1.2531  decode.d5.loss_mask: 0.7332  decode.d5.loss_dice: 1.1246  decode.d6.loss_cls: 1.2972  decode.d6.loss_mask: 0.7016  decode.d6.loss_dice: 1.0895  decode.d7.loss_cls: 1.3008  decode.d7.loss_mask: 0.7226  decode.d7.loss_dice: 1.0948  decode.d8.loss_cls: 1.2767  decode.d8.loss_mask: 0.7428  decode.d8.loss_dice: 1.0869
2023/05/24 06:52:21 - mmengine - INFO - Saving checkpoint at 102000 iterations
2023/05/24 06:52:48 - mmengine - INFO - Iter(train) [102050/160000]  lr: 4.0091e-06  eta: 6:56:29  time: 0.4294  data_time: 0.0106  memory: 4866  grad_norm: 115.1929  loss: 27.6533  decode.loss_cls: 0.7576  decode.loss_mask: 0.6619  decode.loss_dice: 1.0685  decode.d0.loss_cls: 2.6729  decode.d0.loss_mask: 0.7217  decode.d0.loss_dice: 1.2551  decode.d1.loss_cls: 0.8955  decode.d1.loss_mask: 0.6865  decode.d1.loss_dice: 1.1214  decode.d2.loss_cls: 0.8589  decode.d2.loss_mask: 0.6655  decode.d2.loss_dice: 1.1102  decode.d3.loss_cls: 0.8371  decode.d3.loss_mask: 0.6730  decode.d3.loss_dice: 1.0733  decode.d4.loss_cls: 0.8002  decode.d4.loss_mask: 0.6695  decode.d4.loss_dice: 1.1043  decode.d5.loss_cls: 0.7448  decode.d5.loss_mask: 0.6706  decode.d5.loss_dice: 1.1075  decode.d6.loss_cls: 0.7997  decode.d6.loss_mask: 0.6694  decode.d6.loss_dice: 1.0806  decode.d7.loss_cls: 0.7577  decode.d7.loss_mask: 0.6596  decode.d7.loss_dice: 1.0489  decode.d8.loss_cls: 0.7628  decode.d8.loss_mask: 0.6672  decode.d8.loss_dice: 1.0515
2023/05/24 06:53:10 - mmengine - INFO - Iter(train) [102100/160000]  lr: 4.0059e-06  eta: 6:56:08  time: 0.4247  data_time: 0.0105  memory: 4884  grad_norm: 89.9879  loss: 30.5639  decode.loss_cls: 1.0317  decode.loss_mask: 0.6322  decode.loss_dice: 1.1402  decode.d0.loss_cls: 2.9653  decode.d0.loss_mask: 0.6161  decode.d0.loss_dice: 1.2655  decode.d1.loss_cls: 1.1314  decode.d1.loss_mask: 0.6373  decode.d1.loss_dice: 1.2327  decode.d2.loss_cls: 1.0579  decode.d2.loss_mask: 0.6172  decode.d2.loss_dice: 1.1925  decode.d3.loss_cls: 1.0542  decode.d3.loss_mask: 0.6461  decode.d3.loss_dice: 1.1416  decode.d4.loss_cls: 1.0226  decode.d4.loss_mask: 0.6350  decode.d4.loss_dice: 1.2008  decode.d5.loss_cls: 1.0488  decode.d5.loss_mask: 0.6350  decode.d5.loss_dice: 1.2101  decode.d6.loss_cls: 0.9920  decode.d6.loss_mask: 0.6382  decode.d6.loss_dice: 1.1677  decode.d7.loss_cls: 1.0336  decode.d7.loss_mask: 0.6339  decode.d7.loss_dice: 1.1726  decode.d8.loss_cls: 0.9397  decode.d8.loss_mask: 0.6840  decode.d8.loss_dice: 1.1880
2023/05/24 06:53:32 - mmengine - INFO - Iter(train) [102150/160000]  lr: 4.0028e-06  eta: 6:55:46  time: 0.4753  data_time: 0.0107  memory: 4886  grad_norm: 92.6119  loss: 27.6198  decode.loss_cls: 0.9947  decode.loss_mask: 0.5659  decode.loss_dice: 0.8687  decode.d0.loss_cls: 2.9317  decode.d0.loss_mask: 0.6217  decode.d0.loss_dice: 1.0874  decode.d1.loss_cls: 1.0922  decode.d1.loss_mask: 0.6386  decode.d1.loss_dice: 0.9804  decode.d2.loss_cls: 1.1275  decode.d2.loss_mask: 0.6124  decode.d2.loss_dice: 0.9389  decode.d3.loss_cls: 1.0697  decode.d3.loss_mask: 0.5879  decode.d3.loss_dice: 0.9081  decode.d4.loss_cls: 1.0829  decode.d4.loss_mask: 0.5928  decode.d4.loss_dice: 0.8887  decode.d5.loss_cls: 1.0257  decode.d5.loss_mask: 0.5794  decode.d5.loss_dice: 0.8909  decode.d6.loss_cls: 1.0495  decode.d6.loss_mask: 0.5715  decode.d6.loss_dice: 0.8827  decode.d7.loss_cls: 1.0467  decode.d7.loss_mask: 0.5886  decode.d7.loss_dice: 0.9148  decode.d8.loss_cls: 0.9919  decode.d8.loss_mask: 0.5888  decode.d8.loss_dice: 0.8989
2023/05/24 06:53:54 - mmengine - INFO - Iter(train) [102200/160000]  lr: 3.9997e-06  eta: 6:55:25  time: 0.4228  data_time: 0.0106  memory: 4928  grad_norm: 97.6923  loss: 35.1711  decode.loss_cls: 1.1524  decode.loss_mask: 0.6511  decode.loss_dice: 1.4767  decode.d0.loss_cls: 2.8026  decode.d0.loss_mask: 0.6636  decode.d0.loss_dice: 1.6616  decode.d1.loss_cls: 1.3521  decode.d1.loss_mask: 0.6809  decode.d1.loss_dice: 1.5602  decode.d2.loss_cls: 1.3418  decode.d2.loss_mask: 0.6436  decode.d2.loss_dice: 1.4828  decode.d3.loss_cls: 1.2053  decode.d3.loss_mask: 0.6653  decode.d3.loss_dice: 1.4297  decode.d4.loss_cls: 1.1996  decode.d4.loss_mask: 0.6536  decode.d4.loss_dice: 1.4321  decode.d5.loss_cls: 1.1931  decode.d5.loss_mask: 0.6523  decode.d5.loss_dice: 1.4126  decode.d6.loss_cls: 1.2067  decode.d6.loss_mask: 0.6474  decode.d6.loss_dice: 1.4708  decode.d7.loss_cls: 1.1866  decode.d7.loss_mask: 0.6505  decode.d7.loss_dice: 1.4071  decode.d8.loss_cls: 1.2176  decode.d8.loss_mask: 0.6356  decode.d8.loss_dice: 1.4356
2023/05/24 06:54:15 - mmengine - INFO - Iter(train) [102250/160000]  lr: 3.9966e-06  eta: 6:55:03  time: 0.4310  data_time: 0.0105  memory: 4846  grad_norm: 93.5838  loss: 32.0106  decode.loss_cls: 1.0193  decode.loss_mask: 0.7957  decode.loss_dice: 1.0654  decode.d0.loss_cls: 3.2227  decode.d0.loss_mask: 0.8651  decode.d0.loss_dice: 1.2310  decode.d1.loss_cls: 1.1783  decode.d1.loss_mask: 0.8990  decode.d1.loss_dice: 1.1459  decode.d2.loss_cls: 1.0717  decode.d2.loss_mask: 0.8420  decode.d2.loss_dice: 1.1366  decode.d3.loss_cls: 1.0605  decode.d3.loss_mask: 0.8358  decode.d3.loss_dice: 1.0870  decode.d4.loss_cls: 1.0130  decode.d4.loss_mask: 0.8542  decode.d4.loss_dice: 1.0989  decode.d5.loss_cls: 1.0589  decode.d5.loss_mask: 0.8206  decode.d5.loss_dice: 1.0761  decode.d6.loss_cls: 1.0360  decode.d6.loss_mask: 0.7972  decode.d6.loss_dice: 1.0461  decode.d7.loss_cls: 1.0365  decode.d7.loss_mask: 0.8116  decode.d7.loss_dice: 1.0611  decode.d8.loss_cls: 0.9861  decode.d8.loss_mask: 0.8081  decode.d8.loss_dice: 1.0500
2023/05/24 06:54:36 - mmengine - INFO - Iter(train) [102300/160000]  lr: 3.9935e-06  eta: 6:54:41  time: 0.4265  data_time: 0.0114  memory: 4846  grad_norm: 106.7461  loss: 36.2732  decode.loss_cls: 1.1025  decode.loss_mask: 0.8329  decode.loss_dice: 1.3831  decode.d0.loss_cls: 3.0829  decode.d0.loss_mask: 0.9089  decode.d0.loss_dice: 1.6417  decode.d1.loss_cls: 1.2181  decode.d1.loss_mask: 0.8687  decode.d1.loss_dice: 1.4870  decode.d2.loss_cls: 1.1419  decode.d2.loss_mask: 0.8989  decode.d2.loss_dice: 1.4152  decode.d3.loss_cls: 1.1671  decode.d3.loss_mask: 0.8164  decode.d3.loss_dice: 1.4042  decode.d4.loss_cls: 1.1261  decode.d4.loss_mask: 0.8545  decode.d4.loss_dice: 1.4209  decode.d5.loss_cls: 1.1557  decode.d5.loss_mask: 0.8391  decode.d5.loss_dice: 1.3927  decode.d6.loss_cls: 1.1633  decode.d6.loss_mask: 0.8431  decode.d6.loss_dice: 1.3803  decode.d7.loss_cls: 1.1453  decode.d7.loss_mask: 0.8412  decode.d7.loss_dice: 1.3840  decode.d8.loss_cls: 1.0996  decode.d8.loss_mask: 0.8553  decode.d8.loss_dice: 1.4026
2023/05/24 06:54:57 - mmengine - INFO - Iter(train) [102350/160000]  lr: 3.9904e-06  eta: 6:54:20  time: 0.4179  data_time: 0.0104  memory: 4899  grad_norm: 92.3527  loss: 45.3479  decode.loss_cls: 1.5138  decode.loss_mask: 1.1115  decode.loss_dice: 1.6781  decode.d0.loss_cls: 3.3635  decode.d0.loss_mask: 1.0582  decode.d0.loss_dice: 1.9018  decode.d1.loss_cls: 1.6128  decode.d1.loss_mask: 1.1056  decode.d1.loss_dice: 1.8400  decode.d2.loss_cls: 1.5778  decode.d2.loss_mask: 1.0553  decode.d2.loss_dice: 1.7178  decode.d3.loss_cls: 1.5495  decode.d3.loss_mask: 1.0754  decode.d3.loss_dice: 1.6940  decode.d4.loss_cls: 1.5608  decode.d4.loss_mask: 1.0750  decode.d4.loss_dice: 1.6732  decode.d5.loss_cls: 1.5105  decode.d5.loss_mask: 1.0622  decode.d5.loss_dice: 1.6927  decode.d6.loss_cls: 1.5850  decode.d6.loss_mask: 1.0762  decode.d6.loss_dice: 1.6571  decode.d7.loss_cls: 1.5024  decode.d7.loss_mask: 1.1027  decode.d7.loss_dice: 1.6727  decode.d8.loss_cls: 1.4995  decode.d8.loss_mask: 1.1207  decode.d8.loss_dice: 1.7020
2023/05/24 06:55:21 - mmengine - INFO - Iter(train) [102400/160000]  lr: 3.9873e-06  eta: 6:53:59  time: 0.4718  data_time: 0.0109  memory: 4836  grad_norm: 118.7013  loss: 37.0332  decode.loss_cls: 1.1617  decode.loss_mask: 0.7736  decode.loss_dice: 1.3992  decode.d0.loss_cls: 3.3985  decode.d0.loss_mask: 0.8858  decode.d0.loss_dice: 1.6150  decode.d1.loss_cls: 1.3598  decode.d1.loss_mask: 0.8526  decode.d1.loss_dice: 1.5174  decode.d2.loss_cls: 1.3417  decode.d2.loss_mask: 0.8093  decode.d2.loss_dice: 1.4691  decode.d3.loss_cls: 1.2978  decode.d3.loss_mask: 0.7925  decode.d3.loss_dice: 1.4267  decode.d4.loss_cls: 1.2781  decode.d4.loss_mask: 0.7979  decode.d4.loss_dice: 1.4250  decode.d5.loss_cls: 1.2092  decode.d5.loss_mask: 0.7982  decode.d5.loss_dice: 1.3914  decode.d6.loss_cls: 1.1939  decode.d6.loss_mask: 0.7786  decode.d6.loss_dice: 1.3653  decode.d7.loss_cls: 1.1597  decode.d7.loss_mask: 0.7718  decode.d7.loss_dice: 1.3880  decode.d8.loss_cls: 1.2021  decode.d8.loss_mask: 0.7771  decode.d8.loss_dice: 1.3962
2023/05/24 06:55:43 - mmengine - INFO - Iter(train) [102450/160000]  lr: 3.9841e-06  eta: 6:53:38  time: 0.4203  data_time: 0.0103  memory: 4866  grad_norm: 100.4805  loss: 39.7695  decode.loss_cls: 1.4205  decode.loss_mask: 0.7910  decode.loss_dice: 1.4151  decode.d0.loss_cls: 3.3984  decode.d0.loss_mask: 0.8219  decode.d0.loss_dice: 1.7719  decode.d1.loss_cls: 1.5373  decode.d1.loss_mask: 0.8929  decode.d1.loss_dice: 1.5947  decode.d2.loss_cls: 1.4521  decode.d2.loss_mask: 0.8264  decode.d2.loss_dice: 1.5251  decode.d3.loss_cls: 1.5214  decode.d3.loss_mask: 0.8131  decode.d3.loss_dice: 1.4892  decode.d4.loss_cls: 1.4426  decode.d4.loss_mask: 0.8414  decode.d4.loss_dice: 1.4670  decode.d5.loss_cls: 1.4493  decode.d5.loss_mask: 0.7896  decode.d5.loss_dice: 1.4884  decode.d6.loss_cls: 1.4052  decode.d6.loss_mask: 0.7922  decode.d6.loss_dice: 1.4499  decode.d7.loss_cls: 1.4218  decode.d7.loss_mask: 0.7919  decode.d7.loss_dice: 1.4794  decode.d8.loss_cls: 1.4046  decode.d8.loss_mask: 0.8291  decode.d8.loss_dice: 1.4463
2023/05/24 06:56:04 - mmengine - INFO - Iter(train) [102500/160000]  lr: 3.9810e-06  eta: 6:53:16  time: 0.4205  data_time: 0.0105  memory: 4891  grad_norm: 104.2417  loss: 28.9659  decode.loss_cls: 0.7095  decode.loss_mask: 0.7633  decode.loss_dice: 1.0799  decode.d0.loss_cls: 2.9253  decode.d0.loss_mask: 0.8314  decode.d0.loss_dice: 1.3391  decode.d1.loss_cls: 0.8999  decode.d1.loss_mask: 0.7349  decode.d1.loss_dice: 1.1624  decode.d2.loss_cls: 0.8131  decode.d2.loss_mask: 0.7359  decode.d2.loss_dice: 1.1193  decode.d3.loss_cls: 0.7670  decode.d3.loss_mask: 0.7667  decode.d3.loss_dice: 1.1377  decode.d4.loss_cls: 0.7644  decode.d4.loss_mask: 0.7605  decode.d4.loss_dice: 1.1074  decode.d5.loss_cls: 0.7349  decode.d5.loss_mask: 0.7827  decode.d5.loss_dice: 1.0991  decode.d6.loss_cls: 0.7936  decode.d6.loss_mask: 0.7832  decode.d6.loss_dice: 1.1205  decode.d7.loss_cls: 0.7264  decode.d7.loss_mask: 0.7854  decode.d7.loss_dice: 1.1114  decode.d8.loss_cls: 0.7359  decode.d8.loss_mask: 0.7686  decode.d8.loss_dice: 1.1065
2023/05/24 06:56:26 - mmengine - INFO - Iter(train) [102550/160000]  lr: 3.9779e-06  eta: 6:52:54  time: 0.4253  data_time: 0.0107  memory: 4864  grad_norm: 90.5150  loss: 39.0485  decode.loss_cls: 1.3550  decode.loss_mask: 0.8884  decode.loss_dice: 1.3235  decode.d0.loss_cls: 3.4368  decode.d0.loss_mask: 0.9832  decode.d0.loss_dice: 1.5550  decode.d1.loss_cls: 1.5597  decode.d1.loss_mask: 0.9731  decode.d1.loss_dice: 1.4662  decode.d2.loss_cls: 1.4166  decode.d2.loss_mask: 0.9236  decode.d2.loss_dice: 1.4326  decode.d3.loss_cls: 1.4741  decode.d3.loss_mask: 0.9074  decode.d3.loss_dice: 1.3590  decode.d4.loss_cls: 1.3694  decode.d4.loss_mask: 0.8911  decode.d4.loss_dice: 1.3682  decode.d5.loss_cls: 1.3959  decode.d5.loss_mask: 0.9039  decode.d5.loss_dice: 1.3147  decode.d6.loss_cls: 1.3454  decode.d6.loss_mask: 0.9063  decode.d6.loss_dice: 1.3397  decode.d7.loss_cls: 1.3065  decode.d7.loss_mask: 0.9281  decode.d7.loss_dice: 1.3452  decode.d8.loss_cls: 1.3437  decode.d8.loss_mask: 0.9030  decode.d8.loss_dice: 1.3333
2023/05/24 06:56:47 - mmengine - INFO - Iter(train) [102600/160000]  lr: 3.9748e-06  eta: 6:52:33  time: 0.4214  data_time: 0.0103  memory: 4848  grad_norm: 88.8928  loss: 32.9276  decode.loss_cls: 1.3635  decode.loss_mask: 0.6410  decode.loss_dice: 1.0362  decode.d0.loss_cls: 3.0393  decode.d0.loss_mask: 0.6748  decode.d0.loss_dice: 1.2322  decode.d1.loss_cls: 1.4647  decode.d1.loss_mask: 0.6416  decode.d1.loss_dice: 1.1226  decode.d2.loss_cls: 1.4688  decode.d2.loss_mask: 0.6288  decode.d2.loss_dice: 1.0902  decode.d3.loss_cls: 1.4403  decode.d3.loss_mask: 0.6143  decode.d3.loss_dice: 1.0673  decode.d4.loss_cls: 1.3914  decode.d4.loss_mask: 0.6281  decode.d4.loss_dice: 1.1104  decode.d5.loss_cls: 1.4494  decode.d5.loss_mask: 0.6049  decode.d5.loss_dice: 1.0420  decode.d6.loss_cls: 1.4169  decode.d6.loss_mask: 0.6284  decode.d6.loss_dice: 1.0398  decode.d7.loss_cls: 1.4346  decode.d7.loss_mask: 0.6322  decode.d7.loss_dice: 0.9932  decode.d8.loss_cls: 1.4023  decode.d8.loss_mask: 0.6118  decode.d8.loss_dice: 1.0164
2023/05/24 06:57:09 - mmengine - INFO - Iter(train) [102650/160000]  lr: 3.9717e-06  eta: 6:52:11  time: 0.4298  data_time: 0.0106  memory: 4807  grad_norm: 117.5582  loss: 30.1107  decode.loss_cls: 1.0971  decode.loss_mask: 0.6903  decode.loss_dice: 0.8715  decode.d0.loss_cls: 3.2048  decode.d0.loss_mask: 0.8254  decode.d0.loss_dice: 1.1260  decode.d1.loss_cls: 1.2145  decode.d1.loss_mask: 0.7888  decode.d1.loss_dice: 1.0693  decode.d2.loss_cls: 1.1523  decode.d2.loss_mask: 0.7515  decode.d2.loss_dice: 0.9772  decode.d3.loss_cls: 1.1416  decode.d3.loss_mask: 0.7138  decode.d3.loss_dice: 0.9220  decode.d4.loss_cls: 1.1147  decode.d4.loss_mask: 0.7104  decode.d4.loss_dice: 0.9179  decode.d5.loss_cls: 1.1208  decode.d5.loss_mask: 0.7158  decode.d5.loss_dice: 0.9044  decode.d6.loss_cls: 1.1468  decode.d6.loss_mask: 0.6967  decode.d6.loss_dice: 0.8497  decode.d7.loss_cls: 1.1191  decode.d7.loss_mask: 0.7061  decode.d7.loss_dice: 0.8754  decode.d8.loss_cls: 1.1146  decode.d8.loss_mask: 0.7005  decode.d8.loss_dice: 0.8718
2023/05/24 06:57:31 - mmengine - INFO - Iter(train) [102700/160000]  lr: 3.9686e-06  eta: 6:51:50  time: 0.4666  data_time: 0.0113  memory: 4946  grad_norm: 85.7815  loss: 37.3605  decode.loss_cls: 1.2335  decode.loss_mask: 0.8364  decode.loss_dice: 1.3990  decode.d0.loss_cls: 3.2488  decode.d0.loss_mask: 0.8118  decode.d0.loss_dice: 1.6620  decode.d1.loss_cls: 1.2774  decode.d1.loss_mask: 0.8877  decode.d1.loss_dice: 1.5214  decode.d2.loss_cls: 1.2769  decode.d2.loss_mask: 0.8394  decode.d2.loss_dice: 1.3935  decode.d3.loss_cls: 1.2986  decode.d3.loss_mask: 0.8134  decode.d3.loss_dice: 1.4125  decode.d4.loss_cls: 1.2581  decode.d4.loss_mask: 0.8281  decode.d4.loss_dice: 1.3834  decode.d5.loss_cls: 1.2808  decode.d5.loss_mask: 0.8437  decode.d5.loss_dice: 1.4227  decode.d6.loss_cls: 1.2381  decode.d6.loss_mask: 0.8301  decode.d6.loss_dice: 1.4177  decode.d7.loss_cls: 1.2370  decode.d7.loss_mask: 0.8426  decode.d7.loss_dice: 1.4053  decode.d8.loss_cls: 1.2225  decode.d8.loss_mask: 0.8372  decode.d8.loss_dice: 1.4008
2023/05/24 06:57:54 - mmengine - INFO - Iter(train) [102750/160000]  lr: 3.9654e-06  eta: 6:51:29  time: 0.4750  data_time: 0.0108  memory: 4821  grad_norm: 92.2791  loss: 37.3654  decode.loss_cls: 1.3232  decode.loss_mask: 0.8904  decode.loss_dice: 1.2339  decode.d0.loss_cls: 3.2188  decode.d0.loss_mask: 0.9471  decode.d0.loss_dice: 1.5562  decode.d1.loss_cls: 1.3035  decode.d1.loss_mask: 0.9673  decode.d1.loss_dice: 1.4433  decode.d2.loss_cls: 1.2542  decode.d2.loss_mask: 0.9593  decode.d2.loss_dice: 1.3616  decode.d3.loss_cls: 1.2963  decode.d3.loss_mask: 0.9432  decode.d3.loss_dice: 1.3003  decode.d4.loss_cls: 1.2691  decode.d4.loss_mask: 0.9394  decode.d4.loss_dice: 1.2932  decode.d5.loss_cls: 1.2725  decode.d5.loss_mask: 0.9388  decode.d5.loss_dice: 1.2879  decode.d6.loss_cls: 1.2636  decode.d6.loss_mask: 0.9221  decode.d6.loss_dice: 1.2725  decode.d7.loss_cls: 1.2812  decode.d7.loss_mask: 0.9092  decode.d7.loss_dice: 1.2658  decode.d8.loss_cls: 1.2592  decode.d8.loss_mask: 0.9361  decode.d8.loss_dice: 1.2560
2023/05/24 06:58:17 - mmengine - INFO - Iter(train) [102800/160000]  lr: 3.9623e-06  eta: 6:51:08  time: 0.4177  data_time: 0.0107  memory: 4845  grad_norm: 86.1588  loss: 35.5853  decode.loss_cls: 1.3062  decode.loss_mask: 0.7349  decode.loss_dice: 1.3121  decode.d0.loss_cls: 3.1576  decode.d0.loss_mask: 0.7005  decode.d0.loss_dice: 1.5204  decode.d1.loss_cls: 1.4631  decode.d1.loss_mask: 0.7359  decode.d1.loss_dice: 1.3900  decode.d2.loss_cls: 1.2914  decode.d2.loss_mask: 0.7430  decode.d2.loss_dice: 1.3609  decode.d3.loss_cls: 1.3165  decode.d3.loss_mask: 0.7209  decode.d3.loss_dice: 1.2989  decode.d4.loss_cls: 1.3049  decode.d4.loss_mask: 0.6959  decode.d4.loss_dice: 1.2820  decode.d5.loss_cls: 1.3063  decode.d5.loss_mask: 0.6996  decode.d5.loss_dice: 1.3165  decode.d6.loss_cls: 1.2970  decode.d6.loss_mask: 0.7271  decode.d6.loss_dice: 1.2765  decode.d7.loss_cls: 1.3100  decode.d7.loss_mask: 0.7376  decode.d7.loss_dice: 1.2643  decode.d8.loss_cls: 1.2971  decode.d8.loss_mask: 0.7303  decode.d8.loss_dice: 1.2881
2023/05/24 06:58:40 - mmengine - INFO - Iter(train) [102850/160000]  lr: 3.9592e-06  eta: 6:50:48  time: 0.4706  data_time: 0.0104  memory: 4848  grad_norm: 82.2425  loss: 43.1598  decode.loss_cls: 1.4699  decode.loss_mask: 0.9055  decode.loss_dice: 1.6622  decode.d0.loss_cls: 3.3789  decode.d0.loss_mask: 0.9871  decode.d0.loss_dice: 1.9344  decode.d1.loss_cls: 1.5846  decode.d1.loss_mask: 0.9689  decode.d1.loss_dice: 1.8138  decode.d2.loss_cls: 1.4857  decode.d2.loss_mask: 0.9485  decode.d2.loss_dice: 1.7032  decode.d3.loss_cls: 1.4154  decode.d3.loss_mask: 0.9339  decode.d3.loss_dice: 1.6735  decode.d4.loss_cls: 1.4585  decode.d4.loss_mask: 0.9255  decode.d4.loss_dice: 1.6949  decode.d5.loss_cls: 1.4817  decode.d5.loss_mask: 0.9219  decode.d5.loss_dice: 1.6827  decode.d6.loss_cls: 1.4615  decode.d6.loss_mask: 0.9184  decode.d6.loss_dice: 1.6471  decode.d7.loss_cls: 1.4777  decode.d7.loss_mask: 0.9329  decode.d7.loss_dice: 1.6680  decode.d8.loss_cls: 1.4636  decode.d8.loss_mask: 0.9176  decode.d8.loss_dice: 1.6422
2023/05/24 06:59:04 - mmengine - INFO - Iter(train) [102900/160000]  lr: 3.9561e-06  eta: 6:50:28  time: 0.4757  data_time: 0.0105  memory: 4822  grad_norm: 84.3527  loss: 33.8857  decode.loss_cls: 1.3181  decode.loss_mask: 0.6949  decode.loss_dice: 1.0780  decode.d0.loss_cls: 2.9928  decode.d0.loss_mask: 0.7438  decode.d0.loss_dice: 1.2364  decode.d1.loss_cls: 1.5234  decode.d1.loss_mask: 0.7076  decode.d1.loss_dice: 1.1730  decode.d2.loss_cls: 1.5009  decode.d2.loss_mask: 0.7237  decode.d2.loss_dice: 1.1321  decode.d3.loss_cls: 1.4066  decode.d3.loss_mask: 0.7585  decode.d3.loss_dice: 1.1268  decode.d4.loss_cls: 1.3553  decode.d4.loss_mask: 0.7318  decode.d4.loss_dice: 1.1010  decode.d5.loss_cls: 1.3311  decode.d5.loss_mask: 0.7508  decode.d5.loss_dice: 1.0871  decode.d6.loss_cls: 1.3378  decode.d6.loss_mask: 0.7192  decode.d6.loss_dice: 1.0792  decode.d7.loss_cls: 1.3210  decode.d7.loss_mask: 0.7227  decode.d7.loss_dice: 1.0883  decode.d8.loss_cls: 1.3448  decode.d8.loss_mask: 0.7131  decode.d8.loss_dice: 1.0858
2023/05/24 06:59:26 - mmengine - INFO - Iter(train) [102950/160000]  lr: 3.9530e-06  eta: 6:50:06  time: 0.4673  data_time: 0.0106  memory: 4830  grad_norm: 115.3332  loss: 40.0627  decode.loss_cls: 1.2531  decode.loss_mask: 0.9078  decode.loss_dice: 1.6616  decode.d0.loss_cls: 2.9284  decode.d0.loss_mask: 0.9245  decode.d0.loss_dice: 1.8443  decode.d1.loss_cls: 1.3869  decode.d1.loss_mask: 0.9370  decode.d1.loss_dice: 1.7417  decode.d2.loss_cls: 1.2801  decode.d2.loss_mask: 0.9320  decode.d2.loss_dice: 1.6327  decode.d3.loss_cls: 1.3448  decode.d3.loss_mask: 0.8950  decode.d3.loss_dice: 1.6025  decode.d4.loss_cls: 1.2559  decode.d4.loss_mask: 0.9049  decode.d4.loss_dice: 1.6135  decode.d5.loss_cls: 1.2582  decode.d5.loss_mask: 0.8960  decode.d5.loss_dice: 1.5705  decode.d6.loss_cls: 1.2221  decode.d6.loss_mask: 0.9035  decode.d6.loss_dice: 1.6404  decode.d7.loss_cls: 1.2163  decode.d7.loss_mask: 0.8988  decode.d7.loss_dice: 1.6286  decode.d8.loss_cls: 1.2494  decode.d8.loss_mask: 0.8919  decode.d8.loss_dice: 1.6404
2023/05/24 06:59:49 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 06:59:49 - mmengine - INFO - Iter(train) [103000/160000]  lr: 3.9499e-06  eta: 6:49:46  time: 0.4551  data_time: 0.0108  memory: 4921  grad_norm: 130.6968  loss: 27.6785  decode.loss_cls: 0.9588  decode.loss_mask: 0.7070  decode.loss_dice: 0.8489  decode.d0.loss_cls: 2.8187  decode.d0.loss_mask: 0.7057  decode.d0.loss_dice: 1.0309  decode.d1.loss_cls: 0.9551  decode.d1.loss_mask: 0.7874  decode.d1.loss_dice: 0.9951  decode.d2.loss_cls: 1.0024  decode.d2.loss_mask: 0.7142  decode.d2.loss_dice: 0.9379  decode.d3.loss_cls: 0.9936  decode.d3.loss_mask: 0.7048  decode.d3.loss_dice: 0.8767  decode.d4.loss_cls: 0.9423  decode.d4.loss_mask: 0.6986  decode.d4.loss_dice: 0.8782  decode.d5.loss_cls: 0.9772  decode.d5.loss_mask: 0.6882  decode.d5.loss_dice: 0.8593  decode.d6.loss_cls: 0.9270  decode.d6.loss_mask: 0.7349  decode.d6.loss_dice: 0.8747  decode.d7.loss_cls: 0.9085  decode.d7.loss_mask: 0.7356  decode.d7.loss_dice: 0.8902  decode.d8.loss_cls: 0.9482  decode.d8.loss_mask: 0.7208  decode.d8.loss_dice: 0.8576
2023/05/24 06:59:49 - mmengine - INFO - Saving checkpoint at 103000 iterations
2023/05/24 07:00:15 - mmengine - INFO - Iter(train) [103050/160000]  lr: 3.9467e-06  eta: 6:49:26  time: 0.4210  data_time: 0.0104  memory: 4939  grad_norm: 103.7611  loss: 47.5164  decode.loss_cls: 1.6370  decode.loss_mask: 1.0919  decode.loss_dice: 1.6861  decode.d0.loss_cls: 3.6715  decode.d0.loss_mask: 1.1635  decode.d0.loss_dice: 1.9357  decode.d1.loss_cls: 1.8733  decode.d1.loss_mask: 1.0822  decode.d1.loss_dice: 1.8556  decode.d2.loss_cls: 1.7506  decode.d2.loss_mask: 1.0589  decode.d2.loss_dice: 1.7991  decode.d3.loss_cls: 1.7349  decode.d3.loss_mask: 1.0491  decode.d3.loss_dice: 1.7646  decode.d4.loss_cls: 1.6604  decode.d4.loss_mask: 1.0693  decode.d4.loss_dice: 1.8186  decode.d5.loss_cls: 1.7026  decode.d5.loss_mask: 1.0432  decode.d5.loss_dice: 1.7362  decode.d6.loss_cls: 1.6158  decode.d6.loss_mask: 1.0651  decode.d6.loss_dice: 1.7585  decode.d7.loss_cls: 1.6004  decode.d7.loss_mask: 1.0677  decode.d7.loss_dice: 1.7564  decode.d8.loss_cls: 1.6534  decode.d8.loss_mask: 1.0706  decode.d8.loss_dice: 1.7441
2023/05/24 07:00:38 - mmengine - INFO - Iter(train) [103100/160000]  lr: 3.9436e-06  eta: 6:49:05  time: 0.4786  data_time: 0.0107  memory: 4837  grad_norm: 206.3229  loss: 38.3147  decode.loss_cls: 1.1341  decode.loss_mask: 0.8202  decode.loss_dice: 1.5818  decode.d0.loss_cls: 3.2732  decode.d0.loss_mask: 0.8399  decode.d0.loss_dice: 1.8228  decode.d1.loss_cls: 1.1410  decode.d1.loss_mask: 0.8327  decode.d1.loss_dice: 1.7783  decode.d2.loss_cls: 1.1547  decode.d2.loss_mask: 0.8289  decode.d2.loss_dice: 1.6948  decode.d3.loss_cls: 1.1503  decode.d3.loss_mask: 0.8398  decode.d3.loss_dice: 1.5881  decode.d4.loss_cls: 1.1660  decode.d4.loss_mask: 0.8210  decode.d4.loss_dice: 1.6289  decode.d5.loss_cls: 1.1798  decode.d5.loss_mask: 0.7937  decode.d5.loss_dice: 1.5929  decode.d6.loss_cls: 1.1576  decode.d6.loss_mask: 0.8020  decode.d6.loss_dice: 1.5604  decode.d7.loss_cls: 1.1418  decode.d7.loss_mask: 0.8194  decode.d7.loss_dice: 1.6150  decode.d8.loss_cls: 1.1566  decode.d8.loss_mask: 0.8116  decode.d8.loss_dice: 1.5876
2023/05/24 07:00:59 - mmengine - INFO - Iter(train) [103150/160000]  lr: 3.9405e-06  eta: 6:48:44  time: 0.4179  data_time: 0.0107  memory: 4868  grad_norm: 100.8980  loss: 36.1890  decode.loss_cls: 1.1616  decode.loss_mask: 0.8866  decode.loss_dice: 1.2405  decode.d0.loss_cls: 3.2459  decode.d0.loss_mask: 0.9851  decode.d0.loss_dice: 1.5265  decode.d1.loss_cls: 1.2501  decode.d1.loss_mask: 0.9602  decode.d1.loss_dice: 1.4475  decode.d2.loss_cls: 1.1700  decode.d2.loss_mask: 0.9584  decode.d2.loss_dice: 1.3358  decode.d3.loss_cls: 1.1513  decode.d3.loss_mask: 0.9343  decode.d3.loss_dice: 1.2954  decode.d4.loss_cls: 1.1108  decode.d4.loss_mask: 0.9326  decode.d4.loss_dice: 1.2748  decode.d5.loss_cls: 1.1660  decode.d5.loss_mask: 0.9211  decode.d5.loss_dice: 1.2858  decode.d6.loss_cls: 1.2108  decode.d6.loss_mask: 0.8990  decode.d6.loss_dice: 1.2519  decode.d7.loss_cls: 1.1731  decode.d7.loss_mask: 0.8983  decode.d7.loss_dice: 1.2335  decode.d8.loss_cls: 1.1542  decode.d8.loss_mask: 0.8966  decode.d8.loss_dice: 1.2312
2023/05/24 07:01:20 - mmengine - INFO - Iter(train) [103200/160000]  lr: 3.9374e-06  eta: 6:48:22  time: 0.4171  data_time: 0.0108  memory: 4845  grad_norm: 103.8681  loss: 29.6449  decode.loss_cls: 0.9339  decode.loss_mask: 0.7936  decode.loss_dice: 1.0161  decode.d0.loss_cls: 2.6250  decode.d0.loss_mask: 0.8729  decode.d0.loss_dice: 1.1421  decode.d1.loss_cls: 1.1284  decode.d1.loss_mask: 0.7717  decode.d1.loss_dice: 1.0240  decode.d2.loss_cls: 1.0610  decode.d2.loss_mask: 0.7633  decode.d2.loss_dice: 0.9772  decode.d3.loss_cls: 1.0174  decode.d3.loss_mask: 0.7807  decode.d3.loss_dice: 0.9923  decode.d4.loss_cls: 0.9902  decode.d4.loss_mask: 0.7823  decode.d4.loss_dice: 1.0003  decode.d5.loss_cls: 0.9978  decode.d5.loss_mask: 0.7940  decode.d5.loss_dice: 1.0219  decode.d6.loss_cls: 0.9856  decode.d6.loss_mask: 0.7685  decode.d6.loss_dice: 0.9643  decode.d7.loss_cls: 0.9577  decode.d7.loss_mask: 0.7627  decode.d7.loss_dice: 0.9758  decode.d8.loss_cls: 0.9675  decode.d8.loss_mask: 0.7794  decode.d8.loss_dice: 0.9970
2023/05/24 07:01:41 - mmengine - INFO - Iter(train) [103250/160000]  lr: 3.9343e-06  eta: 6:48:00  time: 0.4172  data_time: 0.0107  memory: 4837  grad_norm: 109.5272  loss: 33.0348  decode.loss_cls: 1.1907  decode.loss_mask: 0.8111  decode.loss_dice: 1.0375  decode.d0.loss_cls: 3.0039  decode.d0.loss_mask: 0.8430  decode.d0.loss_dice: 1.2094  decode.d1.loss_cls: 1.3690  decode.d1.loss_mask: 0.7589  decode.d1.loss_dice: 1.1263  decode.d2.loss_cls: 1.3396  decode.d2.loss_mask: 0.7659  decode.d2.loss_dice: 1.0534  decode.d3.loss_cls: 1.2573  decode.d3.loss_mask: 0.7951  decode.d3.loss_dice: 1.0418  decode.d4.loss_cls: 1.2353  decode.d4.loss_mask: 0.7971  decode.d4.loss_dice: 1.0205  decode.d5.loss_cls: 1.2906  decode.d5.loss_mask: 0.7938  decode.d5.loss_dice: 1.0105  decode.d6.loss_cls: 1.3181  decode.d6.loss_mask: 0.8111  decode.d6.loss_dice: 1.0083  decode.d7.loss_cls: 1.2700  decode.d7.loss_mask: 0.8005  decode.d7.loss_dice: 1.0007  decode.d8.loss_cls: 1.2655  decode.d8.loss_mask: 0.8079  decode.d8.loss_dice: 1.0018
2023/05/24 07:02:02 - mmengine - INFO - Iter(train) [103300/160000]  lr: 3.9311e-06  eta: 6:47:38  time: 0.4287  data_time: 0.0112  memory: 4904  grad_norm: 91.8974  loss: 35.7954  decode.loss_cls: 1.4170  decode.loss_mask: 0.6810  decode.loss_dice: 1.2001  decode.d0.loss_cls: 3.2198  decode.d0.loss_mask: 0.7415  decode.d0.loss_dice: 1.4880  decode.d1.loss_cls: 1.4482  decode.d1.loss_mask: 0.7338  decode.d1.loss_dice: 1.3552  decode.d2.loss_cls: 1.4797  decode.d2.loss_mask: 0.7005  decode.d2.loss_dice: 1.3080  decode.d3.loss_cls: 1.4659  decode.d3.loss_mask: 0.7061  decode.d3.loss_dice: 1.2530  decode.d4.loss_cls: 1.4222  decode.d4.loss_mask: 0.6976  decode.d4.loss_dice: 1.2363  decode.d5.loss_cls: 1.4378  decode.d5.loss_mask: 0.7071  decode.d5.loss_dice: 1.2126  decode.d6.loss_cls: 1.4107  decode.d6.loss_mask: 0.7024  decode.d6.loss_dice: 1.1970  decode.d7.loss_cls: 1.4052  decode.d7.loss_mask: 0.6924  decode.d7.loss_dice: 1.1921  decode.d8.loss_cls: 1.4236  decode.d8.loss_mask: 0.6734  decode.d8.loss_dice: 1.1875
2023/05/24 07:02:23 - mmengine - INFO - Iter(train) [103350/160000]  lr: 3.9280e-06  eta: 6:47:16  time: 0.4162  data_time: 0.0104  memory: 4822  grad_norm: 93.7218  loss: 37.5081  decode.loss_cls: 1.1491  decode.loss_mask: 0.6364  decode.loss_dice: 1.6182  decode.d0.loss_cls: 3.3312  decode.d0.loss_mask: 0.7655  decode.d0.loss_dice: 1.9025  decode.d1.loss_cls: 1.2607  decode.d1.loss_mask: 0.8084  decode.d1.loss_dice: 1.7961  decode.d2.loss_cls: 1.1666  decode.d2.loss_mask: 0.7466  decode.d2.loss_dice: 1.7324  decode.d3.loss_cls: 1.2005  decode.d3.loss_mask: 0.6891  decode.d3.loss_dice: 1.5867  decode.d4.loss_cls: 1.1425  decode.d4.loss_mask: 0.6869  decode.d4.loss_dice: 1.6602  decode.d5.loss_cls: 1.1085  decode.d5.loss_mask: 0.6757  decode.d5.loss_dice: 1.6118  decode.d6.loss_cls: 1.1722  decode.d6.loss_mask: 0.6343  decode.d6.loss_dice: 1.5474  decode.d7.loss_cls: 1.2029  decode.d7.loss_mask: 0.6336  decode.d7.loss_dice: 1.6160  decode.d8.loss_cls: 1.1953  decode.d8.loss_mask: 0.6359  decode.d8.loss_dice: 1.5949
2023/05/24 07:02:46 - mmengine - INFO - Iter(train) [103400/160000]  lr: 3.9249e-06  eta: 6:46:55  time: 0.4239  data_time: 0.0109  memory: 4876  grad_norm: 100.2972  loss: 44.8348  decode.loss_cls: 1.6874  decode.loss_mask: 0.9225  decode.loss_dice: 1.6343  decode.d0.loss_cls: 3.5232  decode.d0.loss_mask: 0.9797  decode.d0.loss_dice: 1.9205  decode.d1.loss_cls: 1.8390  decode.d1.loss_mask: 0.9516  decode.d1.loss_dice: 1.7956  decode.d2.loss_cls: 1.7610  decode.d2.loss_mask: 0.9167  decode.d2.loss_dice: 1.6932  decode.d3.loss_cls: 1.7047  decode.d3.loss_mask: 0.9064  decode.d3.loss_dice: 1.6193  decode.d4.loss_cls: 1.6796  decode.d4.loss_mask: 0.8992  decode.d4.loss_dice: 1.6113  decode.d5.loss_cls: 1.7052  decode.d5.loss_mask: 0.8988  decode.d5.loss_dice: 1.6496  decode.d6.loss_cls: 1.6703  decode.d6.loss_mask: 0.8979  decode.d6.loss_dice: 1.6078  decode.d7.loss_cls: 1.6571  decode.d7.loss_mask: 0.9095  decode.d7.loss_dice: 1.6013  decode.d8.loss_cls: 1.6508  decode.d8.loss_mask: 0.9050  decode.d8.loss_dice: 1.6365
2023/05/24 07:03:07 - mmengine - INFO - Iter(train) [103450/160000]  lr: 3.9218e-06  eta: 6:46:33  time: 0.4154  data_time: 0.0112  memory: 4817  grad_norm: 108.7825  loss: 33.5082  decode.loss_cls: 1.0485  decode.loss_mask: 0.8185  decode.loss_dice: 1.1732  decode.d0.loss_cls: 3.0737  decode.d0.loss_mask: 0.9137  decode.d0.loss_dice: 1.4192  decode.d1.loss_cls: 1.2201  decode.d1.loss_mask: 0.8580  decode.d1.loss_dice: 1.3353  decode.d2.loss_cls: 1.1286  decode.d2.loss_mask: 0.8321  decode.d2.loss_dice: 1.2300  decode.d3.loss_cls: 1.0916  decode.d3.loss_mask: 0.7927  decode.d3.loss_dice: 1.2135  decode.d4.loss_cls: 1.1047  decode.d4.loss_mask: 0.8075  decode.d4.loss_dice: 1.2079  decode.d5.loss_cls: 1.0747  decode.d5.loss_mask: 0.8137  decode.d5.loss_dice: 1.1839  decode.d6.loss_cls: 1.0672  decode.d6.loss_mask: 0.8365  decode.d6.loss_dice: 1.1895  decode.d7.loss_cls: 1.0405  decode.d7.loss_mask: 0.8273  decode.d7.loss_dice: 1.1821  decode.d8.loss_cls: 1.0391  decode.d8.loss_mask: 0.8156  decode.d8.loss_dice: 1.1693
2023/05/24 07:03:29 - mmengine - INFO - Iter(train) [103500/160000]  lr: 3.9187e-06  eta: 6:46:12  time: 0.4755  data_time: 0.0112  memory: 4898  grad_norm: 117.8745  loss: 27.4544  decode.loss_cls: 1.0404  decode.loss_mask: 0.5385  decode.loss_dice: 0.8657  decode.d0.loss_cls: 3.0019  decode.d0.loss_mask: 0.6039  decode.d0.loss_dice: 1.0340  decode.d1.loss_cls: 1.1496  decode.d1.loss_mask: 0.6012  decode.d1.loss_dice: 0.9760  decode.d2.loss_cls: 1.1290  decode.d2.loss_mask: 0.5853  decode.d2.loss_dice: 0.9358  decode.d3.loss_cls: 1.0778  decode.d3.loss_mask: 0.5879  decode.d3.loss_dice: 0.9083  decode.d4.loss_cls: 1.0967  decode.d4.loss_mask: 0.5425  decode.d4.loss_dice: 0.8769  decode.d5.loss_cls: 1.0734  decode.d5.loss_mask: 0.5621  decode.d5.loss_dice: 0.9030  decode.d6.loss_cls: 1.0517  decode.d6.loss_mask: 0.5045  decode.d6.loss_dice: 0.8583  decode.d7.loss_cls: 1.1043  decode.d7.loss_mask: 0.5284  decode.d7.loss_dice: 0.8517  decode.d8.loss_cls: 0.9941  decode.d8.loss_mask: 0.5891  decode.d8.loss_dice: 0.8823
2023/05/24 07:03:51 - mmengine - INFO - Iter(train) [103550/160000]  lr: 3.9155e-06  eta: 6:45:50  time: 0.4307  data_time: 0.0105  memory: 4828  grad_norm: 98.6395  loss: 39.2480  decode.loss_cls: 1.4172  decode.loss_mask: 0.8143  decode.loss_dice: 1.4321  decode.d0.loss_cls: 3.1650  decode.d0.loss_mask: 0.9286  decode.d0.loss_dice: 1.6761  decode.d1.loss_cls: 1.4198  decode.d1.loss_mask: 0.8787  decode.d1.loss_dice: 1.5754  decode.d2.loss_cls: 1.4668  decode.d2.loss_mask: 0.8248  decode.d2.loss_dice: 1.5124  decode.d3.loss_cls: 1.4064  decode.d3.loss_mask: 0.8486  decode.d3.loss_dice: 1.5092  decode.d4.loss_cls: 1.3787  decode.d4.loss_mask: 0.8512  decode.d4.loss_dice: 1.5343  decode.d5.loss_cls: 1.3400  decode.d5.loss_mask: 0.8387  decode.d5.loss_dice: 1.5083  decode.d6.loss_cls: 1.3215  decode.d6.loss_mask: 0.8379  decode.d6.loss_dice: 1.4749  decode.d7.loss_cls: 1.3104  decode.d7.loss_mask: 0.8395  decode.d7.loss_dice: 1.4934  decode.d8.loss_cls: 1.3637  decode.d8.loss_mask: 0.8323  decode.d8.loss_dice: 1.4477
2023/05/24 07:04:12 - mmengine - INFO - Iter(train) [103600/160000]  lr: 3.9124e-06  eta: 6:45:29  time: 0.4237  data_time: 0.0103  memory: 4927  grad_norm: 91.7316  loss: 33.5593  decode.loss_cls: 1.1498  decode.loss_mask: 0.8028  decode.loss_dice: 1.1238  decode.d0.loss_cls: 3.2118  decode.d0.loss_mask: 0.8533  decode.d0.loss_dice: 1.3111  decode.d1.loss_cls: 1.2282  decode.d1.loss_mask: 0.8786  decode.d1.loss_dice: 1.2997  decode.d2.loss_cls: 1.2082  decode.d2.loss_mask: 0.8033  decode.d2.loss_dice: 1.1771  decode.d3.loss_cls: 1.2157  decode.d3.loss_mask: 0.7899  decode.d3.loss_dice: 1.1494  decode.d4.loss_cls: 1.1719  decode.d4.loss_mask: 0.7779  decode.d4.loss_dice: 1.1295  decode.d5.loss_cls: 1.1728  decode.d5.loss_mask: 0.7786  decode.d5.loss_dice: 1.1221  decode.d6.loss_cls: 1.1525  decode.d6.loss_mask: 0.7891  decode.d6.loss_dice: 1.1149  decode.d7.loss_cls: 1.1246  decode.d7.loss_mask: 0.8108  decode.d7.loss_dice: 1.1375  decode.d8.loss_cls: 1.1512  decode.d8.loss_mask: 0.7993  decode.d8.loss_dice: 1.1236
2023/05/24 07:04:33 - mmengine - INFO - Iter(train) [103650/160000]  lr: 3.9093e-06  eta: 6:45:07  time: 0.4203  data_time: 0.0113  memory: 4904  grad_norm: 92.8388  loss: 36.0777  decode.loss_cls: 1.1303  decode.loss_mask: 0.8770  decode.loss_dice: 1.2262  decode.d0.loss_cls: 3.4051  decode.d0.loss_mask: 0.9092  decode.d0.loss_dice: 1.5009  decode.d1.loss_cls: 1.2860  decode.d1.loss_mask: 0.9477  decode.d1.loss_dice: 1.3897  decode.d2.loss_cls: 1.2824  decode.d2.loss_mask: 0.8816  decode.d2.loss_dice: 1.3058  decode.d3.loss_cls: 1.2566  decode.d3.loss_mask: 0.8970  decode.d3.loss_dice: 1.2923  decode.d4.loss_cls: 1.1891  decode.d4.loss_mask: 0.9174  decode.d4.loss_dice: 1.2884  decode.d5.loss_cls: 1.1421  decode.d5.loss_mask: 0.9144  decode.d5.loss_dice: 1.2511  decode.d6.loss_cls: 1.1665  decode.d6.loss_mask: 0.8757  decode.d6.loss_dice: 1.2248  decode.d7.loss_cls: 1.1375  decode.d7.loss_mask: 0.8874  decode.d7.loss_dice: 1.2503  decode.d8.loss_cls: 1.1346  decode.d8.loss_mask: 0.8818  decode.d8.loss_dice: 1.2289
2023/05/24 07:04:55 - mmengine - INFO - Iter(train) [103700/160000]  lr: 3.9062e-06  eta: 6:44:45  time: 0.4250  data_time: 0.0107  memory: 4888  grad_norm: 86.8409  loss: 30.8929  decode.loss_cls: 0.9029  decode.loss_mask: 0.7608  decode.loss_dice: 1.1226  decode.d0.loss_cls: 3.1027  decode.d0.loss_mask: 0.7633  decode.d0.loss_dice: 1.2432  decode.d1.loss_cls: 1.0941  decode.d1.loss_mask: 0.8031  decode.d1.loss_dice: 1.2190  decode.d2.loss_cls: 0.9932  decode.d2.loss_mask: 0.7652  decode.d2.loss_dice: 1.1832  decode.d3.loss_cls: 0.9674  decode.d3.loss_mask: 0.7512  decode.d3.loss_dice: 1.1447  decode.d4.loss_cls: 0.9348  decode.d4.loss_mask: 0.7629  decode.d4.loss_dice: 1.1452  decode.d5.loss_cls: 0.9274  decode.d5.loss_mask: 0.7525  decode.d5.loss_dice: 1.1548  decode.d6.loss_cls: 0.9204  decode.d6.loss_mask: 0.7604  decode.d6.loss_dice: 1.1134  decode.d7.loss_cls: 0.9197  decode.d7.loss_mask: 0.7549  decode.d7.loss_dice: 1.1238  decode.d8.loss_cls: 0.9267  decode.d8.loss_mask: 0.7547  decode.d8.loss_dice: 1.1248
2023/05/24 07:05:16 - mmengine - INFO - Iter(train) [103750/160000]  lr: 3.9031e-06  eta: 6:44:24  time: 0.4176  data_time: 0.0104  memory: 4857  grad_norm: 98.2372  loss: 28.1736  decode.loss_cls: 0.9488  decode.loss_mask: 0.6766  decode.loss_dice: 0.8801  decode.d0.loss_cls: 2.8211  decode.d0.loss_mask: 0.7697  decode.d0.loss_dice: 1.0583  decode.d1.loss_cls: 1.1107  decode.d1.loss_mask: 0.7665  decode.d1.loss_dice: 0.9918  decode.d2.loss_cls: 1.0650  decode.d2.loss_mask: 0.7055  decode.d2.loss_dice: 0.9138  decode.d3.loss_cls: 1.0283  decode.d3.loss_mask: 0.6921  decode.d3.loss_dice: 0.8978  decode.d4.loss_cls: 1.0144  decode.d4.loss_mask: 0.6981  decode.d4.loss_dice: 0.9002  decode.d5.loss_cls: 1.0231  decode.d5.loss_mask: 0.6810  decode.d5.loss_dice: 0.8910  decode.d6.loss_cls: 0.9478  decode.d6.loss_mask: 0.7009  decode.d6.loss_dice: 0.9018  decode.d7.loss_cls: 0.9617  decode.d7.loss_mask: 0.6815  decode.d7.loss_dice: 0.8972  decode.d8.loss_cls: 0.9871  decode.d8.loss_mask: 0.6786  decode.d8.loss_dice: 0.8830
2023/05/24 07:05:38 - mmengine - INFO - Iter(train) [103800/160000]  lr: 3.8999e-06  eta: 6:44:02  time: 0.4184  data_time: 0.0106  memory: 4841  grad_norm: 108.6429  loss: 31.2111  decode.loss_cls: 1.0494  decode.loss_mask: 0.6533  decode.loss_dice: 1.2114  decode.d0.loss_cls: 3.0715  decode.d0.loss_mask: 0.6878  decode.d0.loss_dice: 1.3543  decode.d1.loss_cls: 1.0694  decode.d1.loss_mask: 0.6827  decode.d1.loss_dice: 1.2928  decode.d2.loss_cls: 1.0030  decode.d2.loss_mask: 0.6815  decode.d2.loss_dice: 1.2413  decode.d3.loss_cls: 0.9800  decode.d3.loss_mask: 0.6551  decode.d3.loss_dice: 1.2398  decode.d4.loss_cls: 0.9867  decode.d4.loss_mask: 0.6792  decode.d4.loss_dice: 1.2475  decode.d5.loss_cls: 0.9560  decode.d5.loss_mask: 0.6806  decode.d5.loss_dice: 1.2492  decode.d6.loss_cls: 0.9813  decode.d6.loss_mask: 0.6783  decode.d6.loss_dice: 1.2173  decode.d7.loss_cls: 0.9526  decode.d7.loss_mask: 0.6709  decode.d7.loss_dice: 1.2075  decode.d8.loss_cls: 0.9754  decode.d8.loss_mask: 0.6598  decode.d8.loss_dice: 1.1954
2023/05/24 07:06:00 - mmengine - INFO - Iter(train) [103850/160000]  lr: 3.8968e-06  eta: 6:43:41  time: 0.4586  data_time: 0.0105  memory: 4876  grad_norm: 98.3097  loss: 43.8310  decode.loss_cls: 1.3981  decode.loss_mask: 0.8968  decode.loss_dice: 1.7299  decode.d0.loss_cls: 3.5251  decode.d0.loss_mask: 1.0284  decode.d0.loss_dice: 2.0895  decode.d1.loss_cls: 1.5216  decode.d1.loss_mask: 1.0106  decode.d1.loss_dice: 1.9386  decode.d2.loss_cls: 1.5198  decode.d2.loss_mask: 0.9283  decode.d2.loss_dice: 1.7912  decode.d3.loss_cls: 1.4629  decode.d3.loss_mask: 0.9654  decode.d3.loss_dice: 1.7587  decode.d4.loss_cls: 1.4720  decode.d4.loss_mask: 0.9169  decode.d4.loss_dice: 1.7258  decode.d5.loss_cls: 1.4278  decode.d5.loss_mask: 0.9524  decode.d5.loss_dice: 1.7123  decode.d6.loss_cls: 1.4478  decode.d6.loss_mask: 0.8942  decode.d6.loss_dice: 1.7111  decode.d7.loss_cls: 1.4053  decode.d7.loss_mask: 0.8902  decode.d7.loss_dice: 1.6990  decode.d8.loss_cls: 1.4118  decode.d8.loss_mask: 0.8947  decode.d8.loss_dice: 1.7050
2023/05/24 07:06:22 - mmengine - INFO - Iter(train) [103900/160000]  lr: 3.8937e-06  eta: 6:43:20  time: 0.4241  data_time: 0.0106  memory: 4866  grad_norm: 125.5280  loss: 41.7471  decode.loss_cls: 1.3912  decode.loss_mask: 0.9696  decode.loss_dice: 1.4496  decode.d0.loss_cls: 3.4301  decode.d0.loss_mask: 1.0653  decode.d0.loss_dice: 1.7299  decode.d1.loss_cls: 1.6309  decode.d1.loss_mask: 0.9945  decode.d1.loss_dice: 1.6000  decode.d2.loss_cls: 1.4776  decode.d2.loss_mask: 1.0145  decode.d2.loss_dice: 1.5433  decode.d3.loss_cls: 1.4352  decode.d3.loss_mask: 1.0365  decode.d3.loss_dice: 1.5191  decode.d4.loss_cls: 1.4204  decode.d4.loss_mask: 1.0284  decode.d4.loss_dice: 1.5178  decode.d5.loss_cls: 1.3736  decode.d5.loss_mask: 0.9837  decode.d5.loss_dice: 1.5325  decode.d6.loss_cls: 1.4186  decode.d6.loss_mask: 0.9876  decode.d6.loss_dice: 1.4696  decode.d7.loss_cls: 1.4938  decode.d7.loss_mask: 0.9533  decode.d7.loss_dice: 1.4184  decode.d8.loss_cls: 1.4305  decode.d8.loss_mask: 0.9582  decode.d8.loss_dice: 1.4734
2023/05/24 07:06:44 - mmengine - INFO - Iter(train) [103950/160000]  lr: 3.8906e-06  eta: 6:42:58  time: 0.4264  data_time: 0.0104  memory: 4857  grad_norm: 91.6480  loss: 31.3730  decode.loss_cls: 1.0575  decode.loss_mask: 0.7628  decode.loss_dice: 1.1264  decode.d0.loss_cls: 2.9334  decode.d0.loss_mask: 0.7776  decode.d0.loss_dice: 1.1961  decode.d1.loss_cls: 1.0315  decode.d1.loss_mask: 0.7944  decode.d1.loss_dice: 1.2105  decode.d2.loss_cls: 1.0212  decode.d2.loss_mask: 0.7703  decode.d2.loss_dice: 1.1596  decode.d3.loss_cls: 1.0170  decode.d3.loss_mask: 0.7925  decode.d3.loss_dice: 1.1122  decode.d4.loss_cls: 1.0352  decode.d4.loss_mask: 0.7776  decode.d4.loss_dice: 1.1325  decode.d5.loss_cls: 0.9965  decode.d5.loss_mask: 0.7920  decode.d5.loss_dice: 1.1027  decode.d6.loss_cls: 1.0426  decode.d6.loss_mask: 0.7484  decode.d6.loss_dice: 1.1228  decode.d7.loss_cls: 1.0498  decode.d7.loss_mask: 0.7659  decode.d7.loss_dice: 1.1322  decode.d8.loss_cls: 1.0028  decode.d8.loss_mask: 0.7718  decode.d8.loss_dice: 1.1373
2023/05/24 07:07:05 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 07:07:05 - mmengine - INFO - Iter(train) [104000/160000]  lr: 3.8874e-06  eta: 6:42:36  time: 0.4348  data_time: 0.0105  memory: 4894  grad_norm: 77.6243  loss: 34.0909  decode.loss_cls: 1.0958  decode.loss_mask: 0.7233  decode.loss_dice: 1.3054  decode.d0.loss_cls: 3.1158  decode.d0.loss_mask: 0.6933  decode.d0.loss_dice: 1.4767  decode.d1.loss_cls: 1.2854  decode.d1.loss_mask: 0.6939  decode.d1.loss_dice: 1.4233  decode.d2.loss_cls: 1.2516  decode.d2.loss_mask: 0.7125  decode.d2.loss_dice: 1.3329  decode.d3.loss_cls: 1.2721  decode.d3.loss_mask: 0.6850  decode.d3.loss_dice: 1.2520  decode.d4.loss_cls: 1.2180  decode.d4.loss_mask: 0.7025  decode.d4.loss_dice: 1.2759  decode.d5.loss_cls: 1.2239  decode.d5.loss_mask: 0.6817  decode.d5.loss_dice: 1.2888  decode.d6.loss_cls: 1.1918  decode.d6.loss_mask: 0.7101  decode.d6.loss_dice: 1.2497  decode.d7.loss_cls: 1.1580  decode.d7.loss_mask: 0.7092  decode.d7.loss_dice: 1.2653  decode.d8.loss_cls: 1.1030  decode.d8.loss_mask: 0.7230  decode.d8.loss_dice: 1.2712
2023/05/24 07:07:05 - mmengine - INFO - Saving checkpoint at 104000 iterations
2023/05/24 07:07:32 - mmengine - INFO - Iter(train) [104050/160000]  lr: 3.8843e-06  eta: 6:42:18  time: 0.4266  data_time: 0.0105  memory: 4869  grad_norm: 92.5248  loss: 26.4515  decode.loss_cls: 0.9638  decode.loss_mask: 0.5703  decode.loss_dice: 0.8889  decode.d0.loss_cls: 2.6810  decode.d0.loss_mask: 0.6647  decode.d0.loss_dice: 1.0461  decode.d1.loss_cls: 1.0191  decode.d1.loss_mask: 0.6324  decode.d1.loss_dice: 0.9445  decode.d2.loss_cls: 0.9608  decode.d2.loss_mask: 0.6257  decode.d2.loss_dice: 0.9282  decode.d3.loss_cls: 0.9148  decode.d3.loss_mask: 0.5970  decode.d3.loss_dice: 0.8826  decode.d4.loss_cls: 0.9509  decode.d4.loss_mask: 0.6010  decode.d4.loss_dice: 0.9091  decode.d5.loss_cls: 0.9269  decode.d5.loss_mask: 0.6046  decode.d5.loss_dice: 0.9029  decode.d6.loss_cls: 0.9899  decode.d6.loss_mask: 0.5745  decode.d6.loss_dice: 0.8644  decode.d7.loss_cls: 0.9945  decode.d7.loss_mask: 0.5576  decode.d7.loss_dice: 0.8670  decode.d8.loss_cls: 0.9491  decode.d8.loss_mask: 0.5695  decode.d8.loss_dice: 0.8697
2023/05/24 07:07:54 - mmengine - INFO - Iter(train) [104100/160000]  lr: 3.8812e-06  eta: 6:41:56  time: 0.4729  data_time: 0.0105  memory: 4829  grad_norm: 88.1668  loss: 35.4819  decode.loss_cls: 1.2732  decode.loss_mask: 0.8345  decode.loss_dice: 1.1807  decode.d0.loss_cls: 2.9173  decode.d0.loss_mask: 0.9050  decode.d0.loss_dice: 1.4171  decode.d1.loss_cls: 1.3848  decode.d1.loss_mask: 0.8677  decode.d1.loss_dice: 1.3175  decode.d2.loss_cls: 1.3463  decode.d2.loss_mask: 0.8388  decode.d2.loss_dice: 1.2325  decode.d3.loss_cls: 1.3357  decode.d3.loss_mask: 0.8346  decode.d3.loss_dice: 1.2122  decode.d4.loss_cls: 1.2458  decode.d4.loss_mask: 0.8519  decode.d4.loss_dice: 1.2173  decode.d5.loss_cls: 1.3047  decode.d5.loss_mask: 0.8467  decode.d5.loss_dice: 1.2076  decode.d6.loss_cls: 1.3105  decode.d6.loss_mask: 0.8288  decode.d6.loss_dice: 1.1852  decode.d7.loss_cls: 1.2871  decode.d7.loss_mask: 0.8267  decode.d7.loss_dice: 1.1838  decode.d8.loss_cls: 1.2685  decode.d8.loss_mask: 0.8288  decode.d8.loss_dice: 1.1906
2023/05/24 07:08:17 - mmengine - INFO - Iter(train) [104150/160000]  lr: 3.8781e-06  eta: 6:41:35  time: 0.4303  data_time: 0.0104  memory: 4861  grad_norm: 90.9959  loss: 32.4596  decode.loss_cls: 1.0879  decode.loss_mask: 0.6508  decode.loss_dice: 1.2114  decode.d0.loss_cls: 3.2137  decode.d0.loss_mask: 0.6946  decode.d0.loss_dice: 1.4323  decode.d1.loss_cls: 1.1584  decode.d1.loss_mask: 0.6853  decode.d1.loss_dice: 1.3375  decode.d2.loss_cls: 1.1966  decode.d2.loss_mask: 0.6655  decode.d2.loss_dice: 1.2490  decode.d3.loss_cls: 1.1152  decode.d3.loss_mask: 0.6514  decode.d3.loss_dice: 1.2380  decode.d4.loss_cls: 1.0713  decode.d4.loss_mask: 0.6421  decode.d4.loss_dice: 1.2273  decode.d5.loss_cls: 1.0979  decode.d5.loss_mask: 0.6607  decode.d5.loss_dice: 1.2541  decode.d6.loss_cls: 1.1250  decode.d6.loss_mask: 0.6343  decode.d6.loss_dice: 1.2063  decode.d7.loss_cls: 1.1298  decode.d7.loss_mask: 0.6324  decode.d7.loss_dice: 1.2274  decode.d8.loss_cls: 1.1118  decode.d8.loss_mask: 0.6376  decode.d8.loss_dice: 1.2141
2023/05/24 07:08:38 - mmengine - INFO - Iter(train) [104200/160000]  lr: 3.8749e-06  eta: 6:41:14  time: 0.4183  data_time: 0.0104  memory: 4859  grad_norm: 110.5981  loss: 38.6555  decode.loss_cls: 1.2132  decode.loss_mask: 0.8782  decode.loss_dice: 1.4477  decode.d0.loss_cls: 3.2791  decode.d0.loss_mask: 0.9598  decode.d0.loss_dice: 1.6604  decode.d1.loss_cls: 1.3962  decode.d1.loss_mask: 0.9819  decode.d1.loss_dice: 1.5813  decode.d2.loss_cls: 1.2973  decode.d2.loss_mask: 0.9743  decode.d2.loss_dice: 1.5412  decode.d3.loss_cls: 1.2727  decode.d3.loss_mask: 0.9573  decode.d3.loss_dice: 1.4606  decode.d4.loss_cls: 1.2187  decode.d4.loss_mask: 0.9201  decode.d4.loss_dice: 1.4811  decode.d5.loss_cls: 1.2273  decode.d5.loss_mask: 0.9107  decode.d5.loss_dice: 1.4684  decode.d6.loss_cls: 1.2272  decode.d6.loss_mask: 0.9026  decode.d6.loss_dice: 1.3796  decode.d7.loss_cls: 1.2032  decode.d7.loss_mask: 0.8698  decode.d7.loss_dice: 1.4423  decode.d8.loss_cls: 1.1797  decode.d8.loss_mask: 0.8800  decode.d8.loss_dice: 1.4438
2023/05/24 07:09:00 - mmengine - INFO - Iter(train) [104250/160000]  lr: 3.8718e-06  eta: 6:40:52  time: 0.4792  data_time: 0.0106  memory: 4867  grad_norm: 112.7165  loss: 28.5931  decode.loss_cls: 0.9611  decode.loss_mask: 0.4926  decode.loss_dice: 1.0844  decode.d0.loss_cls: 2.9995  decode.d0.loss_mask: 0.5157  decode.d0.loss_dice: 1.2979  decode.d1.loss_cls: 1.0454  decode.d1.loss_mask: 0.5455  decode.d1.loss_dice: 1.2264  decode.d2.loss_cls: 1.0704  decode.d2.loss_mask: 0.5069  decode.d2.loss_dice: 1.1616  decode.d3.loss_cls: 1.0069  decode.d3.loss_mask: 0.5201  decode.d3.loss_dice: 1.0970  decode.d4.loss_cls: 0.9716  decode.d4.loss_mask: 0.5093  decode.d4.loss_dice: 1.1342  decode.d5.loss_cls: 0.9640  decode.d5.loss_mask: 0.5135  decode.d5.loss_dice: 1.1220  decode.d6.loss_cls: 0.9987  decode.d6.loss_mask: 0.5137  decode.d6.loss_dice: 1.1100  decode.d7.loss_cls: 0.9938  decode.d7.loss_mask: 0.5002  decode.d7.loss_dice: 1.1178  decode.d8.loss_cls: 0.9945  decode.d8.loss_mask: 0.4869  decode.d8.loss_dice: 1.1316
2023/05/24 07:09:22 - mmengine - INFO - Iter(train) [104300/160000]  lr: 3.8687e-06  eta: 6:40:31  time: 0.4228  data_time: 0.0106  memory: 4865  grad_norm: 98.7750  loss: 33.5748  decode.loss_cls: 1.1420  decode.loss_mask: 0.6849  decode.loss_dice: 1.2654  decode.d0.loss_cls: 2.9201  decode.d0.loss_mask: 0.7889  decode.d0.loss_dice: 1.4876  decode.d1.loss_cls: 1.1186  decode.d1.loss_mask: 0.7700  decode.d1.loss_dice: 1.3745  decode.d2.loss_cls: 1.1881  decode.d2.loss_mask: 0.7218  decode.d2.loss_dice: 1.3319  decode.d3.loss_cls: 1.2073  decode.d3.loss_mask: 0.7016  decode.d3.loss_dice: 1.3200  decode.d4.loss_cls: 1.1427  decode.d4.loss_mask: 0.6976  decode.d4.loss_dice: 1.3033  decode.d5.loss_cls: 1.1527  decode.d5.loss_mask: 0.6956  decode.d5.loss_dice: 1.2766  decode.d6.loss_cls: 1.1494  decode.d6.loss_mask: 0.6984  decode.d6.loss_dice: 1.2689  decode.d7.loss_cls: 1.1746  decode.d7.loss_mask: 0.6909  decode.d7.loss_dice: 1.2356  decode.d8.loss_cls: 1.1076  decode.d8.loss_mask: 0.7010  decode.d8.loss_dice: 1.2570
2023/05/24 07:09:43 - mmengine - INFO - Iter(train) [104350/160000]  lr: 3.8656e-06  eta: 6:40:09  time: 0.4201  data_time: 0.0107  memory: 4908  grad_norm: 104.6263  loss: 35.8137  decode.loss_cls: 1.2926  decode.loss_mask: 0.6886  decode.loss_dice: 1.2901  decode.d0.loss_cls: 3.2471  decode.d0.loss_mask: 0.7491  decode.d0.loss_dice: 1.6367  decode.d1.loss_cls: 1.4741  decode.d1.loss_mask: 0.6981  decode.d1.loss_dice: 1.4338  decode.d2.loss_cls: 1.4274  decode.d2.loss_mask: 0.6860  decode.d2.loss_dice: 1.3571  decode.d3.loss_cls: 1.3358  decode.d3.loss_mask: 0.6960  decode.d3.loss_dice: 1.3413  decode.d4.loss_cls: 1.3293  decode.d4.loss_mask: 0.7086  decode.d4.loss_dice: 1.3426  decode.d5.loss_cls: 1.2849  decode.d5.loss_mask: 0.7034  decode.d5.loss_dice: 1.3202  decode.d6.loss_cls: 1.2672  decode.d6.loss_mask: 0.6976  decode.d6.loss_dice: 1.2907  decode.d7.loss_cls: 1.2771  decode.d7.loss_mask: 0.6908  decode.d7.loss_dice: 1.2739  decode.d8.loss_cls: 1.2928  decode.d8.loss_mask: 0.6844  decode.d8.loss_dice: 1.2965
2023/05/24 07:10:05 - mmengine - INFO - Iter(train) [104400/160000]  lr: 3.8624e-06  eta: 6:39:47  time: 0.4250  data_time: 0.0110  memory: 4871  grad_norm: 89.0086  loss: 34.0695  decode.loss_cls: 1.2758  decode.loss_mask: 0.6939  decode.loss_dice: 1.2643  decode.d0.loss_cls: 2.8462  decode.d0.loss_mask: 0.6584  decode.d0.loss_dice: 1.4507  decode.d1.loss_cls: 1.2562  decode.d1.loss_mask: 0.7658  decode.d1.loss_dice: 1.3800  decode.d2.loss_cls: 1.3114  decode.d2.loss_mask: 0.6606  decode.d2.loss_dice: 1.3125  decode.d3.loss_cls: 1.1857  decode.d3.loss_mask: 0.6942  decode.d3.loss_dice: 1.3341  decode.d4.loss_cls: 1.2044  decode.d4.loss_mask: 0.6810  decode.d4.loss_dice: 1.2891  decode.d5.loss_cls: 1.2388  decode.d5.loss_mask: 0.6455  decode.d5.loss_dice: 1.2981  decode.d6.loss_cls: 1.3086  decode.d6.loss_mask: 0.6451  decode.d6.loss_dice: 1.2876  decode.d7.loss_cls: 1.2470  decode.d7.loss_mask: 0.6535  decode.d7.loss_dice: 1.2759  decode.d8.loss_cls: 1.2851  decode.d8.loss_mask: 0.6563  decode.d8.loss_dice: 1.2640
2023/05/24 07:10:26 - mmengine - INFO - Iter(train) [104450/160000]  lr: 3.8593e-06  eta: 6:39:26  time: 0.4356  data_time: 0.0110  memory: 4856  grad_norm: 117.2674  loss: 40.5339  decode.loss_cls: 1.3186  decode.loss_mask: 0.8978  decode.loss_dice: 1.5635  decode.d0.loss_cls: 3.1934  decode.d0.loss_mask: 0.9756  decode.d0.loss_dice: 1.7470  decode.d1.loss_cls: 1.5714  decode.d1.loss_mask: 0.9298  decode.d1.loss_dice: 1.6500  decode.d2.loss_cls: 1.4055  decode.d2.loss_mask: 0.9427  decode.d2.loss_dice: 1.6122  decode.d3.loss_cls: 1.2965  decode.d3.loss_mask: 0.9149  decode.d3.loss_dice: 1.6258  decode.d4.loss_cls: 1.3495  decode.d4.loss_mask: 0.9231  decode.d4.loss_dice: 1.5968  decode.d5.loss_cls: 1.3218  decode.d5.loss_mask: 0.8729  decode.d5.loss_dice: 1.5321  decode.d6.loss_cls: 1.2952  decode.d6.loss_mask: 0.8951  decode.d6.loss_dice: 1.5514  decode.d7.loss_cls: 1.2917  decode.d7.loss_mask: 0.9042  decode.d7.loss_dice: 1.5594  decode.d8.loss_cls: 1.3366  decode.d8.loss_mask: 0.9035  decode.d8.loss_dice: 1.5561
2023/05/24 07:10:47 - mmengine - INFO - Iter(train) [104500/160000]  lr: 3.8562e-06  eta: 6:39:04  time: 0.4204  data_time: 0.0105  memory: 4920  grad_norm: 91.9305  loss: 36.4143  decode.loss_cls: 1.2988  decode.loss_mask: 0.7379  decode.loss_dice: 1.3355  decode.d0.loss_cls: 3.2240  decode.d0.loss_mask: 0.7605  decode.d0.loss_dice: 1.4419  decode.d1.loss_cls: 1.3336  decode.d1.loss_mask: 0.7623  decode.d1.loss_dice: 1.4569  decode.d2.loss_cls: 1.3480  decode.d2.loss_mask: 0.7739  decode.d2.loss_dice: 1.4002  decode.d3.loss_cls: 1.2987  decode.d3.loss_mask: 0.7549  decode.d3.loss_dice: 1.3338  decode.d4.loss_cls: 1.2967  decode.d4.loss_mask: 0.7588  decode.d4.loss_dice: 1.3677  decode.d5.loss_cls: 1.3116  decode.d5.loss_mask: 0.7716  decode.d5.loss_dice: 1.3919  decode.d6.loss_cls: 1.3140  decode.d6.loss_mask: 0.7442  decode.d6.loss_dice: 1.3631  decode.d7.loss_cls: 1.2885  decode.d7.loss_mask: 0.7741  decode.d7.loss_dice: 1.3801  decode.d8.loss_cls: 1.2867  decode.d8.loss_mask: 0.7623  decode.d8.loss_dice: 1.3422
2023/05/24 07:11:09 - mmengine - INFO - Iter(train) [104550/160000]  lr: 3.8531e-06  eta: 6:38:42  time: 0.4250  data_time: 0.0111  memory: 4916  grad_norm: 92.3434  loss: 41.0830  decode.loss_cls: 1.3920  decode.loss_mask: 0.8134  decode.loss_dice: 1.6589  decode.d0.loss_cls: 3.3849  decode.d0.loss_mask: 0.8066  decode.d0.loss_dice: 1.8503  decode.d1.loss_cls: 1.4711  decode.d1.loss_mask: 0.8564  decode.d1.loss_dice: 1.7401  decode.d2.loss_cls: 1.4052  decode.d2.loss_mask: 0.8646  decode.d2.loss_dice: 1.6708  decode.d3.loss_cls: 1.4094  decode.d3.loss_mask: 0.8630  decode.d3.loss_dice: 1.6705  decode.d4.loss_cls: 1.3657  decode.d4.loss_mask: 0.8729  decode.d4.loss_dice: 1.6307  decode.d5.loss_cls: 1.3412  decode.d5.loss_mask: 0.8495  decode.d5.loss_dice: 1.6329  decode.d6.loss_cls: 1.3927  decode.d6.loss_mask: 0.8269  decode.d6.loss_dice: 1.6309  decode.d7.loss_cls: 1.3548  decode.d7.loss_mask: 0.8351  decode.d7.loss_dice: 1.6158  decode.d8.loss_cls: 1.3915  decode.d8.loss_mask: 0.8436  decode.d8.loss_dice: 1.6417
2023/05/24 07:11:32 - mmengine - INFO - Iter(train) [104600/160000]  lr: 3.8499e-06  eta: 6:38:22  time: 0.4747  data_time: 0.0107  memory: 4859  grad_norm: 100.5003  loss: 44.3641  decode.loss_cls: 1.4846  decode.loss_mask: 1.0271  decode.loss_dice: 1.6583  decode.d0.loss_cls: 3.5647  decode.d0.loss_mask: 1.0686  decode.d0.loss_dice: 1.9413  decode.d1.loss_cls: 1.5990  decode.d1.loss_mask: 1.0379  decode.d1.loss_dice: 1.7506  decode.d2.loss_cls: 1.6728  decode.d2.loss_mask: 1.0401  decode.d2.loss_dice: 1.6874  decode.d3.loss_cls: 1.5392  decode.d3.loss_mask: 1.0307  decode.d3.loss_dice: 1.6316  decode.d4.loss_cls: 1.4725  decode.d4.loss_mask: 1.0236  decode.d4.loss_dice: 1.6183  decode.d5.loss_cls: 1.4421  decode.d5.loss_mask: 1.0155  decode.d5.loss_dice: 1.6367  decode.d6.loss_cls: 1.5574  decode.d6.loss_mask: 0.9977  decode.d6.loss_dice: 1.6048  decode.d7.loss_cls: 1.4887  decode.d7.loss_mask: 1.0166  decode.d7.loss_dice: 1.6108  decode.d8.loss_cls: 1.4644  decode.d8.loss_mask: 1.0363  decode.d8.loss_dice: 1.6448
2023/05/24 07:11:55 - mmengine - INFO - Iter(train) [104650/160000]  lr: 3.8468e-06  eta: 6:38:01  time: 0.4754  data_time: 0.0106  memory: 4808  grad_norm: 105.0685  loss: 35.3599  decode.loss_cls: 1.1873  decode.loss_mask: 0.8473  decode.loss_dice: 1.2230  decode.d0.loss_cls: 3.0978  decode.d0.loss_mask: 0.9190  decode.d0.loss_dice: 1.3968  decode.d1.loss_cls: 1.4286  decode.d1.loss_mask: 0.8381  decode.d1.loss_dice: 1.2791  decode.d2.loss_cls: 1.4231  decode.d2.loss_mask: 0.8331  decode.d2.loss_dice: 1.2564  decode.d3.loss_cls: 1.2566  decode.d3.loss_mask: 0.8278  decode.d3.loss_dice: 1.2382  decode.d4.loss_cls: 1.2634  decode.d4.loss_mask: 0.8103  decode.d4.loss_dice: 1.2504  decode.d5.loss_cls: 1.2195  decode.d5.loss_mask: 0.8186  decode.d5.loss_dice: 1.2148  decode.d6.loss_cls: 1.2579  decode.d6.loss_mask: 0.8142  decode.d6.loss_dice: 1.1645  decode.d7.loss_cls: 1.2033  decode.d7.loss_mask: 0.8181  decode.d7.loss_dice: 1.2109  decode.d8.loss_cls: 1.2248  decode.d8.loss_mask: 0.8343  decode.d8.loss_dice: 1.2026
2023/05/24 07:12:19 - mmengine - INFO - Iter(train) [104700/160000]  lr: 3.8437e-06  eta: 6:37:41  time: 0.4748  data_time: 0.0102  memory: 4829  grad_norm: 102.8940  loss: 28.0179  decode.loss_cls: 1.1448  decode.loss_mask: 0.5787  decode.loss_dice: 0.8651  decode.d0.loss_cls: 2.7254  decode.d0.loss_mask: 0.6647  decode.d0.loss_dice: 1.0296  decode.d1.loss_cls: 1.2546  decode.d1.loss_mask: 0.6008  decode.d1.loss_dice: 0.9168  decode.d2.loss_cls: 1.0807  decode.d2.loss_mask: 0.5714  decode.d2.loss_dice: 0.8973  decode.d3.loss_cls: 1.1847  decode.d3.loss_mask: 0.5869  decode.d3.loss_dice: 0.8716  decode.d4.loss_cls: 1.1347  decode.d4.loss_mask: 0.5841  decode.d4.loss_dice: 0.8858  decode.d5.loss_cls: 1.1268  decode.d5.loss_mask: 0.5921  decode.d5.loss_dice: 0.8998  decode.d6.loss_cls: 1.1207  decode.d6.loss_mask: 0.5780  decode.d6.loss_dice: 0.8709  decode.d7.loss_cls: 1.1634  decode.d7.loss_mask: 0.5858  decode.d7.loss_dice: 0.8732  decode.d8.loss_cls: 1.1802  decode.d8.loss_mask: 0.5757  decode.d8.loss_dice: 0.8737
2023/05/24 07:12:43 - mmengine - INFO - Iter(train) [104750/160000]  lr: 3.8406e-06  eta: 6:37:20  time: 0.4735  data_time: 0.0105  memory: 4789  grad_norm: 102.1093  loss: 31.1804  decode.loss_cls: 0.9190  decode.loss_mask: 0.8703  decode.loss_dice: 1.0843  decode.d0.loss_cls: 2.8970  decode.d0.loss_mask: 0.7549  decode.d0.loss_dice: 1.2294  decode.d1.loss_cls: 1.0628  decode.d1.loss_mask: 0.8419  decode.d1.loss_dice: 1.1488  decode.d2.loss_cls: 1.0123  decode.d2.loss_mask: 0.8430  decode.d2.loss_dice: 1.1141  decode.d3.loss_cls: 0.9718  decode.d3.loss_mask: 0.8546  decode.d3.loss_dice: 1.1297  decode.d4.loss_cls: 0.9254  decode.d4.loss_mask: 0.8491  decode.d4.loss_dice: 1.0893  decode.d5.loss_cls: 0.9334  decode.d5.loss_mask: 0.8477  decode.d5.loss_dice: 1.1078  decode.d6.loss_cls: 0.9866  decode.d6.loss_mask: 0.8493  decode.d6.loss_dice: 1.0729  decode.d7.loss_cls: 0.9216  decode.d7.loss_mask: 0.8701  decode.d7.loss_dice: 1.1177  decode.d8.loss_cls: 0.9459  decode.d8.loss_mask: 0.8634  decode.d8.loss_dice: 1.0661
2023/05/24 07:13:06 - mmengine - INFO - Iter(train) [104800/160000]  lr: 3.8374e-06  eta: 6:37:00  time: 0.4113  data_time: 0.0105  memory: 4839  grad_norm: 84.0687  loss: 34.1629  decode.loss_cls: 1.3077  decode.loss_mask: 0.7290  decode.loss_dice: 1.1158  decode.d0.loss_cls: 3.1433  decode.d0.loss_mask: 0.7942  decode.d0.loss_dice: 1.3593  decode.d1.loss_cls: 1.4099  decode.d1.loss_mask: 0.8171  decode.d1.loss_dice: 1.1999  decode.d2.loss_cls: 1.4673  decode.d2.loss_mask: 0.7528  decode.d2.loss_dice: 1.1511  decode.d3.loss_cls: 1.3463  decode.d3.loss_mask: 0.7324  decode.d3.loss_dice: 1.0910  decode.d4.loss_cls: 1.3023  decode.d4.loss_mask: 0.7368  decode.d4.loss_dice: 1.1011  decode.d5.loss_cls: 1.3237  decode.d5.loss_mask: 0.7496  decode.d5.loss_dice: 1.1381  decode.d6.loss_cls: 1.3216  decode.d6.loss_mask: 0.7386  decode.d6.loss_dice: 1.1105  decode.d7.loss_cls: 1.2751  decode.d7.loss_mask: 0.7259  decode.d7.loss_dice: 1.1088  decode.d8.loss_cls: 1.2751  decode.d8.loss_mask: 0.7255  decode.d8.loss_dice: 1.1130
2023/05/24 07:13:28 - mmengine - INFO - Iter(train) [104850/160000]  lr: 3.8343e-06  eta: 6:36:38  time: 0.4246  data_time: 0.0106  memory: 4868  grad_norm: 89.8408  loss: 44.1605  decode.loss_cls: 1.4348  decode.loss_mask: 0.9219  decode.loss_dice: 1.7670  decode.d0.loss_cls: 3.4727  decode.d0.loss_mask: 0.9637  decode.d0.loss_dice: 2.0093  decode.d1.loss_cls: 1.5152  decode.d1.loss_mask: 0.9216  decode.d1.loss_dice: 1.9210  decode.d2.loss_cls: 1.4764  decode.d2.loss_mask: 0.9458  decode.d2.loss_dice: 1.8114  decode.d3.loss_cls: 1.4849  decode.d3.loss_mask: 0.9333  decode.d3.loss_dice: 1.7852  decode.d4.loss_cls: 1.3277  decode.d4.loss_mask: 0.9379  decode.d4.loss_dice: 1.8444  decode.d5.loss_cls: 1.4698  decode.d5.loss_mask: 0.9128  decode.d5.loss_dice: 1.7709  decode.d6.loss_cls: 1.5525  decode.d6.loss_mask: 0.9107  decode.d6.loss_dice: 1.7711  decode.d7.loss_cls: 1.4705  decode.d7.loss_mask: 0.9028  decode.d7.loss_dice: 1.7915  decode.d8.loss_cls: 1.4794  decode.d8.loss_mask: 0.9340  decode.d8.loss_dice: 1.7200
2023/05/24 07:13:49 - mmengine - INFO - Iter(train) [104900/160000]  lr: 3.8312e-06  eta: 6:36:16  time: 0.4211  data_time: 0.0105  memory: 4908  grad_norm: 84.7024  loss: 30.7408  decode.loss_cls: 0.8640  decode.loss_mask: 0.5816  decode.loss_dice: 1.2644  decode.d0.loss_cls: 2.9836  decode.d0.loss_mask: 0.6897  decode.d0.loss_dice: 1.5027  decode.d1.loss_cls: 1.0709  decode.d1.loss_mask: 0.6404  decode.d1.loss_dice: 1.4250  decode.d2.loss_cls: 0.9314  decode.d2.loss_mask: 0.5857  decode.d2.loss_dice: 1.3674  decode.d3.loss_cls: 0.9871  decode.d3.loss_mask: 0.5881  decode.d3.loss_dice: 1.2955  decode.d4.loss_cls: 0.9591  decode.d4.loss_mask: 0.5853  decode.d4.loss_dice: 1.2721  decode.d5.loss_cls: 0.9656  decode.d5.loss_mask: 0.5838  decode.d5.loss_dice: 1.2813  decode.d6.loss_cls: 0.9402  decode.d6.loss_mask: 0.5870  decode.d6.loss_dice: 1.2583  decode.d7.loss_cls: 0.9281  decode.d7.loss_mask: 0.5905  decode.d7.loss_dice: 1.2515  decode.d8.loss_cls: 0.9343  decode.d8.loss_mask: 0.5753  decode.d8.loss_dice: 1.2506
2023/05/24 07:14:10 - mmengine - INFO - Iter(train) [104950/160000]  lr: 3.8280e-06  eta: 6:35:55  time: 0.4172  data_time: 0.0113  memory: 4818  grad_norm: 122.8900  loss: 38.7845  decode.loss_cls: 1.4007  decode.loss_mask: 0.7771  decode.loss_dice: 1.4454  decode.d0.loss_cls: 3.3223  decode.d0.loss_mask: 0.8780  decode.d0.loss_dice: 1.6835  decode.d1.loss_cls: 1.5361  decode.d1.loss_mask: 0.7889  decode.d1.loss_dice: 1.5352  decode.d2.loss_cls: 1.5209  decode.d2.loss_mask: 0.7783  decode.d2.loss_dice: 1.4553  decode.d3.loss_cls: 1.4319  decode.d3.loss_mask: 0.7801  decode.d3.loss_dice: 1.4420  decode.d4.loss_cls: 1.4308  decode.d4.loss_mask: 0.7688  decode.d4.loss_dice: 1.4424  decode.d5.loss_cls: 1.4251  decode.d5.loss_mask: 0.7744  decode.d5.loss_dice: 1.4283  decode.d6.loss_cls: 1.3777  decode.d6.loss_mask: 0.7713  decode.d6.loss_dice: 1.4193  decode.d7.loss_cls: 1.3625  decode.d7.loss_mask: 0.7698  decode.d7.loss_dice: 1.4230  decode.d8.loss_cls: 1.3926  decode.d8.loss_mask: 0.7777  decode.d8.loss_dice: 1.4452
2023/05/24 07:14:31 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 07:14:31 - mmengine - INFO - Iter(train) [105000/160000]  lr: 3.8249e-06  eta: 6:35:33  time: 0.4172  data_time: 0.0105  memory: 4888  grad_norm: 87.6954  loss: 33.6153  decode.loss_cls: 1.1705  decode.loss_mask: 0.7292  decode.loss_dice: 1.1429  decode.d0.loss_cls: 3.1039  decode.d0.loss_mask: 0.8147  decode.d0.loss_dice: 1.3384  decode.d1.loss_cls: 1.3182  decode.d1.loss_mask: 0.8058  decode.d1.loss_dice: 1.2967  decode.d2.loss_cls: 1.3091  decode.d2.loss_mask: 0.7455  decode.d2.loss_dice: 1.2797  decode.d3.loss_cls: 1.2142  decode.d3.loss_mask: 0.7658  decode.d3.loss_dice: 1.1959  decode.d4.loss_cls: 1.1930  decode.d4.loss_mask: 0.7507  decode.d4.loss_dice: 1.1864  decode.d5.loss_cls: 1.1917  decode.d5.loss_mask: 0.7302  decode.d5.loss_dice: 1.1664  decode.d6.loss_cls: 1.2074  decode.d6.loss_mask: 0.7359  decode.d6.loss_dice: 1.1251  decode.d7.loss_cls: 1.1861  decode.d7.loss_mask: 0.7358  decode.d7.loss_dice: 1.1378  decode.d8.loss_cls: 1.1903  decode.d8.loss_mask: 0.7205  decode.d8.loss_dice: 1.1273
2023/05/24 07:14:31 - mmengine - INFO - Saving checkpoint at 105000 iterations
2023/05/24 07:14:44 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:01:17  time: 0.0818  data_time: 0.0018  memory: 2167  
2023/05/24 07:14:49 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:59  time: 0.0889  data_time: 0.0019  memory: 2216  
2023/05/24 07:14:53 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:48  time: 0.0797  data_time: 0.0018  memory: 2167  
2023/05/24 07:14:57 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:41  time: 0.0799  data_time: 0.0018  memory: 2104  
2023/05/24 07:15:01 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:35  time: 0.0790  data_time: 0.0018  memory: 2831  
2023/05/24 07:15:05 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0790  data_time: 0.0018  memory: 2167  
2023/05/24 07:15:09 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:25  time: 0.0901  data_time: 0.0017  memory: 2167  
2023/05/24 07:15:13 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:20  time: 0.0809  data_time: 0.0018  memory: 2167  
2023/05/24 07:15:17 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.1026  data_time: 0.0021  memory: 2944  
2023/05/24 07:15:22 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:11  time: 0.0958  data_time: 0.0020  memory: 2356  
2023/05/24 07:15:27 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0931  data_time: 0.0018  memory: 2217  
2023/05/24 07:15:32 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0927  data_time: 0.0018  memory: 2328  
2023/05/24 07:15:36 - mmengine - INFO - per class results:
2023/05/24 07:15:36 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.22 | 93.39 |
|     bicycle      | 69.44 | 82.61 |
|       car        | 59.24 | 85.25 |
|    motorcycle    | 81.68 | 89.54 |
|     airplane     | 86.14 | 92.03 |
|       bus        | 78.84 | 89.39 |
|      train       | 82.68 | 92.88 |
|      truck       | 56.14 | 70.25 |
|       boat       | 61.11 | 79.21 |
|  traffic light   | 66.66 | 84.94 |
|   fire hydrant   | 87.37 | 94.77 |
|    stop sign     | 89.84 | 97.84 |
|  parking meter   | 75.56 | 86.63 |
|      bench       | 50.26 | 67.44 |
|       bird       | 82.43 |  90.4 |
|       cat        | 85.55 | 91.69 |
|       dog        | 78.31 | 84.66 |
|      horse       | 78.99 | 90.02 |
|      sheep       | 86.39 | 93.02 |
|       cow        | 83.12 | 88.47 |
|     elephant     | 89.89 | 94.97 |
|       bear       | 92.29 | 94.95 |
|      zebra       | 90.24 | 93.16 |
|     giraffe      | 87.37 | 92.95 |
|     backpack     | 33.43 | 55.83 |
|     umbrella     |  81.8 | 88.15 |
|     handbag      |  31.7 | 59.17 |
|       tie        | 11.83 | 16.03 |
|     suitcase     | 79.09 | 88.23 |
|     frisbee      | 77.66 | 89.91 |
|       skis       | 42.22 | 53.68 |
|    snowboard     | 52.78 | 71.91 |
|   sports ball    |  55.8 | 71.98 |
|       kite       | 62.67 | 75.85 |
|   baseball bat   | 51.43 | 62.52 |
|  baseball glove  | 74.63 |  87.8 |
|    skateboard    | 78.28 | 88.35 |
|    surfboard     | 70.68 | 86.39 |
|  tennis racket   | 85.69 | 91.61 |
|      bottle      | 38.58 | 50.99 |
|    wine glass    | 54.57 | 74.13 |
|       cup        | 53.41 | 71.93 |
|       fork       | 16.53 | 17.87 |
|      knife       | 19.35 | 23.83 |
|      spoon       | 32.46 | 45.71 |
|       bowl       | 46.19 | 66.47 |
|      banana      | 69.08 | 86.95 |
|      apple       | 50.19 | 69.62 |
|     sandwich     | 43.13 | 55.95 |
|      orange      | 64.75 | 68.79 |
|     broccoli     | 56.34 | 65.22 |
|      carrot      | 46.55 | 49.52 |
|     hot dog      | 50.77 | 59.65 |
|      pizza       | 68.46 | 84.74 |
|      donut       | 70.02 | 88.82 |
|       cake       | 58.81 | 71.99 |
|      chair       | 44.64 | 64.38 |
|      couch       |  54.8 | 80.44 |
|   potted plant   | 29.95 | 39.19 |
|       bed        | 61.55 | 83.31 |
|   dining table   |  43.0 | 81.83 |
|      toilet      | 80.75 | 90.87 |
|        tv        | 75.01 | 87.07 |
|      laptop      | 72.54 | 86.61 |
|      mouse       | 75.81 |  88.4 |
|      remote      | 61.91 | 75.09 |
|     keyboard     | 61.58 | 68.41 |
|    cell phone    |  68.2 | 85.77 |
|    microwave     | 64.84 | 76.09 |
|       oven       |  54.2 | 86.11 |
|     toaster      | 32.27 | 53.88 |
|       sink       | 58.06 | 79.23 |
|   refrigerator   | 77.19 | 92.21 |
|       book       | 48.96 | 67.39 |
|      clock       | 72.65 | 81.89 |
|       vase       | 62.09 |  82.4 |
|     scissors     | 77.65 | 87.91 |
|    teddy bear    | 74.05 | 86.13 |
|    hair drier    | 34.95 | 48.52 |
|    toothbrush    | 38.27 | 73.51 |
|      banner      | 37.63 | 62.37 |
|     blanket      |  3.29 |  3.52 |
|      branch      | 17.68 | 25.38 |
|      bridge      | 33.68 | 53.84 |
|  building-other  |  53.3 | 70.97 |
|       bush       |  31.5 | 50.43 |
|     cabinet      | 53.95 | 74.33 |
|       cage       |  21.3 | 38.58 |
|    cardboard     | 43.26 | 54.23 |
|      carpet      | 52.31 | 71.99 |
|  ceiling-other   | 63.01 |  78.4 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 20.64 | 28.61 |
|      clouds      | 43.54 | 52.83 |
|     counter      | 26.72 | 46.48 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 63.11 | 75.23 |
|    desk-stuff    | 43.78 | 55.98 |
|       dirt       | 37.26 | 51.91 |
|    door-stuff    | 37.41 | 60.13 |
|      fence       | 28.34 | 46.96 |
|   floor-marble   |  4.06 |  4.21 |
|   floor-other    | 19.91 | 24.84 |
|   floor-stone    |  1.87 |  1.97 |
|    floor-tile    | 58.17 | 71.21 |
|    floor-wood    | 59.04 | 77.48 |
|      flower      | 42.93 | 74.29 |
|       fog        |  1.24 |  1.25 |
|    food-other    | 26.33 | 30.62 |
|      fruit       | 37.75 | 57.05 |
| furniture-other  | 17.58 | 25.06 |
|      grass       | 69.79 |  84.3 |
|      gravel      | 26.45 | 41.59 |
|   ground-other   |  0.22 |  0.24 |
|       hill       | 21.54 |  30.5 |
|      house       | 25.67 | 31.22 |
|      leaves      | 23.46 | 26.95 |
|      light       | 37.71 | 53.76 |
|       mat        |  0.0  |  0.0  |
|      metal       | 30.86 | 47.41 |
|   mirror-stuff   | 49.74 | 73.39 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 50.48 | 69.65 |
|       mud        |  3.74 |  7.69 |
|      napkin      |  1.8  |  1.81 |
|       net        | 43.31 | 60.39 |
|      paper       | 30.23 | 43.96 |
|     pavement     | 51.38 | 76.09 |
|      pillow      |  11.7 | 13.82 |
|   plant-other    | 20.08 | 34.14 |
|     plastic      | 17.56 | 22.68 |
|     platform     | 25.36 | 37.89 |
|   playingfield   | 68.87 | 89.72 |
|     railing      |  8.87 | 14.93 |
|     railroad     | 61.89 | 79.13 |
|      river       | 39.86 | 49.84 |
|       road       | 66.76 | 81.67 |
|       rock       | 36.16 | 52.39 |
|       roof       | 16.35 | 21.07 |
|       rug        | 34.05 | 53.11 |
|      salad       |  0.0  |  0.0  |
|       sand       |  62.5 | 71.87 |
|       sea        | 84.14 | 92.95 |
|      shelf       | 33.78 |  45.9 |
|    sky-other     | 70.54 | 90.34 |
|    skyscraper    | 34.26 | 43.64 |
|       snow       | 88.03 | 92.46 |
|   solid-other    |  0.14 |  0.14 |
|      stairs      | 22.31 | 37.12 |
|      stone       | 20.51 | 41.85 |
|      straw       | 28.27 | 36.74 |
| structural-other |  0.02 |  0.02 |
|      table       | 12.67 | 15.92 |
|       tent       |  8.25 | 11.33 |
|  textile-other   |  9.69 | 14.63 |
|      towel       | 33.32 | 42.11 |
|       tree       |  73.0 |  85.0 |
|    vegetable     | 33.58 | 46.05 |
|    wall-brick    | 47.17 | 67.05 |
|  wall-concrete   | 60.46 |  82.5 |
|    wall-other    | 17.65 | 24.89 |
|    wall-panel    |  4.71 |  5.64 |
|    wall-stone    | 32.58 | 36.67 |
|    wall-tile     | 66.59 | 82.68 |
|    wall-wood     | 40.07 |  56.3 |
|   water-other    | 25.91 | 44.29 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 51.02 | 60.08 |
|   window-other   | 47.49 | 73.07 |
|       wood       | 23.34 | 36.32 |
+------------------+-------+-------+
2023/05/24 07:15:36 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.9300  mIoU: 46.3500  mAcc: 58.5600  data_time: 0.0021  time: 0.0913
2023/05/24 07:16:00 - mmengine - INFO - Iter(train) [105050/160000]  lr: 3.8218e-06  eta: 6:35:13  time: 0.4847  data_time: 0.0112  memory: 4841  grad_norm: 102.5476  loss: 33.5043  decode.loss_cls: 1.1312  decode.loss_mask: 0.7047  decode.loss_dice: 1.3060  decode.d0.loss_cls: 2.9526  decode.d0.loss_mask: 0.7070  decode.d0.loss_dice: 1.4120  decode.d1.loss_cls: 1.3073  decode.d1.loss_mask: 0.7073  decode.d1.loss_dice: 1.3572  decode.d2.loss_cls: 1.1865  decode.d2.loss_mask: 0.7696  decode.d2.loss_dice: 1.3265  decode.d3.loss_cls: 1.1698  decode.d3.loss_mask: 0.7056  decode.d3.loss_dice: 1.2411  decode.d4.loss_cls: 1.1315  decode.d4.loss_mask: 0.7212  decode.d4.loss_dice: 1.2554  decode.d5.loss_cls: 1.1868  decode.d5.loss_mask: 0.7075  decode.d5.loss_dice: 1.2381  decode.d6.loss_cls: 1.1485  decode.d6.loss_mask: 0.6961  decode.d6.loss_dice: 1.2478  decode.d7.loss_cls: 1.1349  decode.d7.loss_mask: 0.7172  decode.d7.loss_dice: 1.2372  decode.d8.loss_cls: 1.1570  decode.d8.loss_mask: 0.7193  decode.d8.loss_dice: 1.2216
2023/05/24 07:16:22 - mmengine - INFO - Iter(train) [105100/160000]  lr: 3.8186e-06  eta: 6:34:52  time: 0.4312  data_time: 0.0107  memory: 4925  grad_norm: 89.0773  loss: 41.3292  decode.loss_cls: 1.2681  decode.loss_mask: 0.7750  decode.loss_dice: 1.7677  decode.d0.loss_cls: 3.3681  decode.d0.loss_mask: 0.8192  decode.d0.loss_dice: 2.1331  decode.d1.loss_cls: 1.3784  decode.d1.loss_mask: 0.7995  decode.d1.loss_dice: 1.9405  decode.d2.loss_cls: 1.3290  decode.d2.loss_mask: 0.7843  decode.d2.loss_dice: 1.8358  decode.d3.loss_cls: 1.3448  decode.d3.loss_mask: 0.7521  decode.d3.loss_dice: 1.8126  decode.d4.loss_cls: 1.3165  decode.d4.loss_mask: 0.7615  decode.d4.loss_dice: 1.8233  decode.d5.loss_cls: 1.3064  decode.d5.loss_mask: 0.7592  decode.d5.loss_dice: 1.7860  decode.d6.loss_cls: 1.3100  decode.d6.loss_mask: 0.7529  decode.d6.loss_dice: 1.7574  decode.d7.loss_cls: 1.2390  decode.d7.loss_mask: 0.7660  decode.d7.loss_dice: 1.7821  decode.d8.loss_cls: 1.2954  decode.d8.loss_mask: 0.7820  decode.d8.loss_dice: 1.7831
2023/05/24 07:16:43 - mmengine - INFO - Iter(train) [105150/160000]  lr: 3.8155e-06  eta: 6:34:30  time: 0.4222  data_time: 0.0103  memory: 4840  grad_norm: 110.4049  loss: 35.8967  decode.loss_cls: 1.2379  decode.loss_mask: 0.8075  decode.loss_dice: 1.2376  decode.d0.loss_cls: 3.1720  decode.d0.loss_mask: 0.8763  decode.d0.loss_dice: 1.4121  decode.d1.loss_cls: 1.4901  decode.d1.loss_mask: 0.8516  decode.d1.loss_dice: 1.3575  decode.d2.loss_cls: 1.4179  decode.d2.loss_mask: 0.8153  decode.d2.loss_dice: 1.2684  decode.d3.loss_cls: 1.3025  decode.d3.loss_mask: 0.8160  decode.d3.loss_dice: 1.2363  decode.d4.loss_cls: 1.2634  decode.d4.loss_mask: 0.8087  decode.d4.loss_dice: 1.2406  decode.d5.loss_cls: 1.2953  decode.d5.loss_mask: 0.7952  decode.d5.loss_dice: 1.2443  decode.d6.loss_cls: 1.2909  decode.d6.loss_mask: 0.8121  decode.d6.loss_dice: 1.2411  decode.d7.loss_cls: 1.2952  decode.d7.loss_mask: 0.8058  decode.d7.loss_dice: 1.2283  decode.d8.loss_cls: 1.2440  decode.d8.loss_mask: 0.8040  decode.d8.loss_dice: 1.2289
2023/05/24 07:17:04 - mmengine - INFO - Iter(train) [105200/160000]  lr: 3.8124e-06  eta: 6:34:08  time: 0.4213  data_time: 0.0104  memory: 4857  grad_norm: 101.9918  loss: 42.5507  decode.loss_cls: 1.5370  decode.loss_mask: 0.9208  decode.loss_dice: 1.5487  decode.d0.loss_cls: 3.3902  decode.d0.loss_mask: 0.9370  decode.d0.loss_dice: 1.7266  decode.d1.loss_cls: 1.6255  decode.d1.loss_mask: 0.9738  decode.d1.loss_dice: 1.6775  decode.d2.loss_cls: 1.5665  decode.d2.loss_mask: 0.9437  decode.d2.loss_dice: 1.6245  decode.d3.loss_cls: 1.6303  decode.d3.loss_mask: 0.9033  decode.d3.loss_dice: 1.4714  decode.d4.loss_cls: 1.5423  decode.d4.loss_mask: 0.9215  decode.d4.loss_dice: 1.5468  decode.d5.loss_cls: 1.5892  decode.d5.loss_mask: 0.9273  decode.d5.loss_dice: 1.5416  decode.d6.loss_cls: 1.6246  decode.d6.loss_mask: 0.9045  decode.d6.loss_dice: 1.4985  decode.d7.loss_cls: 1.5694  decode.d7.loss_mask: 0.9175  decode.d7.loss_dice: 1.5129  decode.d8.loss_cls: 1.5715  decode.d8.loss_mask: 0.9140  decode.d8.loss_dice: 1.4924
2023/05/24 07:17:25 - mmengine - INFO - Iter(train) [105250/160000]  lr: 3.8093e-06  eta: 6:33:46  time: 0.4312  data_time: 0.0105  memory: 4845  grad_norm: 90.9863  loss: 34.7290  decode.loss_cls: 1.1489  decode.loss_mask: 0.8804  decode.loss_dice: 1.1929  decode.d0.loss_cls: 3.2065  decode.d0.loss_mask: 0.9884  decode.d0.loss_dice: 1.4335  decode.d1.loss_cls: 1.2078  decode.d1.loss_mask: 0.8938  decode.d1.loss_dice: 1.2634  decode.d2.loss_cls: 1.1353  decode.d2.loss_mask: 0.8925  decode.d2.loss_dice: 1.2112  decode.d3.loss_cls: 1.1649  decode.d3.loss_mask: 0.8858  decode.d3.loss_dice: 1.1839  decode.d4.loss_cls: 1.0916  decode.d4.loss_mask: 0.9006  decode.d4.loss_dice: 1.1963  decode.d5.loss_cls: 1.0860  decode.d5.loss_mask: 0.8869  decode.d5.loss_dice: 1.2046  decode.d6.loss_cls: 1.0734  decode.d6.loss_mask: 0.9610  decode.d6.loss_dice: 1.2173  decode.d7.loss_cls: 1.0725  decode.d7.loss_mask: 0.9320  decode.d7.loss_dice: 1.2091  decode.d8.loss_cls: 1.0723  decode.d8.loss_mask: 0.9348  decode.d8.loss_dice: 1.2013
2023/05/24 07:17:46 - mmengine - INFO - Iter(train) [105300/160000]  lr: 3.8061e-06  eta: 6:33:25  time: 0.4162  data_time: 0.0105  memory: 4804  grad_norm: 98.0995  loss: 35.0288  decode.loss_cls: 1.2131  decode.loss_mask: 0.7221  decode.loss_dice: 1.2405  decode.d0.loss_cls: 3.1765  decode.d0.loss_mask: 0.8175  decode.d0.loss_dice: 1.4134  decode.d1.loss_cls: 1.4201  decode.d1.loss_mask: 0.7675  decode.d1.loss_dice: 1.3633  decode.d2.loss_cls: 1.3691  decode.d2.loss_mask: 0.7379  decode.d2.loss_dice: 1.3055  decode.d3.loss_cls: 1.3122  decode.d3.loss_mask: 0.7407  decode.d3.loss_dice: 1.2535  decode.d4.loss_cls: 1.2632  decode.d4.loss_mask: 0.7200  decode.d4.loss_dice: 1.2735  decode.d5.loss_cls: 1.2740  decode.d5.loss_mask: 0.7104  decode.d5.loss_dice: 1.2601  decode.d6.loss_cls: 1.2530  decode.d6.loss_mask: 0.7229  decode.d6.loss_dice: 1.2460  decode.d7.loss_cls: 1.2764  decode.d7.loss_mask: 0.7200  decode.d7.loss_dice: 1.2608  decode.d8.loss_cls: 1.2216  decode.d8.loss_mask: 0.7222  decode.d8.loss_dice: 1.2514
2023/05/24 07:18:08 - mmengine - INFO - Iter(train) [105350/160000]  lr: 3.8030e-06  eta: 6:33:03  time: 0.4205  data_time: 0.0103  memory: 4857  grad_norm: 98.5241  loss: 25.2789  decode.loss_cls: 0.8635  decode.loss_mask: 0.5635  decode.loss_dice: 0.8703  decode.d0.loss_cls: 2.7099  decode.d0.loss_mask: 0.5330  decode.d0.loss_dice: 1.0048  decode.d1.loss_cls: 0.9916  decode.d1.loss_mask: 0.5518  decode.d1.loss_dice: 0.9065  decode.d2.loss_cls: 0.9115  decode.d2.loss_mask: 0.5382  decode.d2.loss_dice: 0.8859  decode.d3.loss_cls: 0.8219  decode.d3.loss_mask: 0.5626  decode.d3.loss_dice: 0.8869  decode.d4.loss_cls: 0.9283  decode.d4.loss_mask: 0.5628  decode.d4.loss_dice: 0.8874  decode.d5.loss_cls: 0.9311  decode.d5.loss_mask: 0.5679  decode.d5.loss_dice: 0.8693  decode.d6.loss_cls: 0.8769  decode.d6.loss_mask: 0.5691  decode.d6.loss_dice: 0.8707  decode.d7.loss_cls: 0.8615  decode.d7.loss_mask: 0.5607  decode.d7.loss_dice: 0.8717  decode.d8.loss_cls: 0.9075  decode.d8.loss_mask: 0.5547  decode.d8.loss_dice: 0.8575
2023/05/24 07:18:29 - mmengine - INFO - Iter(train) [105400/160000]  lr: 3.7999e-06  eta: 6:32:41  time: 0.4216  data_time: 0.0105  memory: 4877  grad_norm: 95.0819  loss: 40.3502  decode.loss_cls: 1.2999  decode.loss_mask: 0.8819  decode.loss_dice: 1.6296  decode.d0.loss_cls: 3.1688  decode.d0.loss_mask: 0.9404  decode.d0.loss_dice: 1.7690  decode.d1.loss_cls: 1.4509  decode.d1.loss_mask: 0.9248  decode.d1.loss_dice: 1.7348  decode.d2.loss_cls: 1.3258  decode.d2.loss_mask: 0.9172  decode.d2.loss_dice: 1.6538  decode.d3.loss_cls: 1.3352  decode.d3.loss_mask: 0.8809  decode.d3.loss_dice: 1.5730  decode.d4.loss_cls: 1.3082  decode.d4.loss_mask: 0.8935  decode.d4.loss_dice: 1.5991  decode.d5.loss_cls: 1.2962  decode.d5.loss_mask: 0.8928  decode.d5.loss_dice: 1.5959  decode.d6.loss_cls: 1.2889  decode.d6.loss_mask: 0.8857  decode.d6.loss_dice: 1.5478  decode.d7.loss_cls: 1.2922  decode.d7.loss_mask: 0.8945  decode.d7.loss_dice: 1.5861  decode.d8.loss_cls: 1.3068  decode.d8.loss_mask: 0.8784  decode.d8.loss_dice: 1.5982
2023/05/24 07:18:50 - mmengine - INFO - Iter(train) [105450/160000]  lr: 3.7967e-06  eta: 6:32:19  time: 0.4279  data_time: 0.0105  memory: 4871  grad_norm: 111.6455  loss: 34.3864  decode.loss_cls: 1.1712  decode.loss_mask: 0.6606  decode.loss_dice: 1.3632  decode.d0.loss_cls: 3.1409  decode.d0.loss_mask: 0.7415  decode.d0.loss_dice: 1.5711  decode.d1.loss_cls: 1.2844  decode.d1.loss_mask: 0.6911  decode.d1.loss_dice: 1.5212  decode.d2.loss_cls: 1.1727  decode.d2.loss_mask: 0.6659  decode.d2.loss_dice: 1.4347  decode.d3.loss_cls: 1.1099  decode.d3.loss_mask: 0.6553  decode.d3.loss_dice: 1.3958  decode.d4.loss_cls: 1.1374  decode.d4.loss_mask: 0.6420  decode.d4.loss_dice: 1.3805  decode.d5.loss_cls: 1.1354  decode.d5.loss_mask: 0.6391  decode.d5.loss_dice: 1.3882  decode.d6.loss_cls: 1.1624  decode.d6.loss_mask: 0.6650  decode.d6.loss_dice: 1.3121  decode.d7.loss_cls: 1.1467  decode.d7.loss_mask: 0.6484  decode.d7.loss_dice: 1.3669  decode.d8.loss_cls: 1.1485  decode.d8.loss_mask: 0.6697  decode.d8.loss_dice: 1.3645
2023/05/24 07:19:11 - mmengine - INFO - Iter(train) [105500/160000]  lr: 3.7936e-06  eta: 6:31:57  time: 0.4191  data_time: 0.0104  memory: 4847  grad_norm: 90.5742  loss: 39.9025  decode.loss_cls: 1.5953  decode.loss_mask: 0.7527  decode.loss_dice: 1.3356  decode.d0.loss_cls: 3.4891  decode.d0.loss_mask: 0.8515  decode.d0.loss_dice: 1.5664  decode.d1.loss_cls: 1.7832  decode.d1.loss_mask: 0.8156  decode.d1.loss_dice: 1.4486  decode.d2.loss_cls: 1.6487  decode.d2.loss_mask: 0.7882  decode.d2.loss_dice: 1.3656  decode.d3.loss_cls: 1.5746  decode.d3.loss_mask: 0.8086  decode.d3.loss_dice: 1.3912  decode.d4.loss_cls: 1.6151  decode.d4.loss_mask: 0.7966  decode.d4.loss_dice: 1.3641  decode.d5.loss_cls: 1.5931  decode.d5.loss_mask: 0.7823  decode.d5.loss_dice: 1.3478  decode.d6.loss_cls: 1.6508  decode.d6.loss_mask: 0.7700  decode.d6.loss_dice: 1.3270  decode.d7.loss_cls: 1.6364  decode.d7.loss_mask: 0.7596  decode.d7.loss_dice: 1.3483  decode.d8.loss_cls: 1.5964  decode.d8.loss_mask: 0.7527  decode.d8.loss_dice: 1.3476
2023/05/24 07:19:33 - mmengine - INFO - Iter(train) [105550/160000]  lr: 3.7905e-06  eta: 6:31:36  time: 0.4256  data_time: 0.0105  memory: 4891  grad_norm: 105.7699  loss: 35.3237  decode.loss_cls: 1.1069  decode.loss_mask: 0.9649  decode.loss_dice: 1.1899  decode.d0.loss_cls: 3.0040  decode.d0.loss_mask: 0.9571  decode.d0.loss_dice: 1.3210  decode.d1.loss_cls: 1.1888  decode.d1.loss_mask: 0.9702  decode.d1.loss_dice: 1.3193  decode.d2.loss_cls: 1.1407  decode.d2.loss_mask: 0.9796  decode.d2.loss_dice: 1.2396  decode.d3.loss_cls: 1.1277  decode.d3.loss_mask: 0.9794  decode.d3.loss_dice: 1.2397  decode.d4.loss_cls: 1.0879  decode.d4.loss_mask: 0.9982  decode.d4.loss_dice: 1.2332  decode.d5.loss_cls: 1.1488  decode.d5.loss_mask: 0.9508  decode.d5.loss_dice: 1.2198  decode.d6.loss_cls: 1.1511  decode.d6.loss_mask: 0.9753  decode.d6.loss_dice: 1.2216  decode.d7.loss_cls: 1.0866  decode.d7.loss_mask: 0.9937  decode.d7.loss_dice: 1.2111  decode.d8.loss_cls: 1.1306  decode.d8.loss_mask: 0.9721  decode.d8.loss_dice: 1.2142
2023/05/24 07:19:54 - mmengine - INFO - Iter(train) [105600/160000]  lr: 3.7873e-06  eta: 6:31:14  time: 0.4264  data_time: 0.0112  memory: 4879  grad_norm: 110.9527  loss: 44.8480  decode.loss_cls: 1.6093  decode.loss_mask: 1.0301  decode.loss_dice: 1.4484  decode.d0.loss_cls: 3.8097  decode.d0.loss_mask: 1.1517  decode.d0.loss_dice: 1.8064  decode.d1.loss_cls: 1.8066  decode.d1.loss_mask: 1.0677  decode.d1.loss_dice: 1.6909  decode.d2.loss_cls: 1.6939  decode.d2.loss_mask: 1.0964  decode.d2.loss_dice: 1.6182  decode.d3.loss_cls: 1.6445  decode.d3.loss_mask: 1.0823  decode.d3.loss_dice: 1.5244  decode.d4.loss_cls: 1.6391  decode.d4.loss_mask: 1.0913  decode.d4.loss_dice: 1.5273  decode.d5.loss_cls: 1.6230  decode.d5.loss_mask: 1.0356  decode.d5.loss_dice: 1.5074  decode.d6.loss_cls: 1.6387  decode.d6.loss_mask: 1.0161  decode.d6.loss_dice: 1.4700  decode.d7.loss_cls: 1.6022  decode.d7.loss_mask: 1.0367  decode.d7.loss_dice: 1.4486  decode.d8.loss_cls: 1.6207  decode.d8.loss_mask: 1.0303  decode.d8.loss_dice: 1.4805
2023/05/24 07:20:16 - mmengine - INFO - Iter(train) [105650/160000]  lr: 3.7842e-06  eta: 6:30:52  time: 0.4325  data_time: 0.0103  memory: 4845  grad_norm: 98.6546  loss: 40.6473  decode.loss_cls: 1.2988  decode.loss_mask: 0.9096  decode.loss_dice: 1.5146  decode.d0.loss_cls: 3.4579  decode.d0.loss_mask: 0.9950  decode.d0.loss_dice: 1.8439  decode.d1.loss_cls: 1.4029  decode.d1.loss_mask: 0.9307  decode.d1.loss_dice: 1.7282  decode.d2.loss_cls: 1.3925  decode.d2.loss_mask: 0.9070  decode.d2.loss_dice: 1.5918  decode.d3.loss_cls: 1.3401  decode.d3.loss_mask: 0.8931  decode.d3.loss_dice: 1.5723  decode.d4.loss_cls: 1.3082  decode.d4.loss_mask: 0.9005  decode.d4.loss_dice: 1.6113  decode.d5.loss_cls: 1.3350  decode.d5.loss_mask: 0.9320  decode.d5.loss_dice: 1.6051  decode.d6.loss_cls: 1.3096  decode.d6.loss_mask: 0.8736  decode.d6.loss_dice: 1.5180  decode.d7.loss_cls: 1.2833  decode.d7.loss_mask: 0.8862  decode.d7.loss_dice: 1.5731  decode.d8.loss_cls: 1.3269  decode.d8.loss_mask: 0.8926  decode.d8.loss_dice: 1.5136
2023/05/24 07:20:37 - mmengine - INFO - Iter(train) [105700/160000]  lr: 3.7811e-06  eta: 6:30:31  time: 0.4271  data_time: 0.0104  memory: 4846  grad_norm: 89.4477  loss: 35.0121  decode.loss_cls: 1.3533  decode.loss_mask: 0.7165  decode.loss_dice: 1.1766  decode.d0.loss_cls: 3.2641  decode.d0.loss_mask: 0.8038  decode.d0.loss_dice: 1.4223  decode.d1.loss_cls: 1.3550  decode.d1.loss_mask: 0.8179  decode.d1.loss_dice: 1.3079  decode.d2.loss_cls: 1.3481  decode.d2.loss_mask: 0.7390  decode.d2.loss_dice: 1.2557  decode.d3.loss_cls: 1.2721  decode.d3.loss_mask: 0.7403  decode.d3.loss_dice: 1.2006  decode.d4.loss_cls: 1.2321  decode.d4.loss_mask: 0.7622  decode.d4.loss_dice: 1.2413  decode.d5.loss_cls: 1.2734  decode.d5.loss_mask: 0.7539  decode.d5.loss_dice: 1.2187  decode.d6.loss_cls: 1.2955  decode.d6.loss_mask: 0.7404  decode.d6.loss_dice: 1.1864  decode.d7.loss_cls: 1.3362  decode.d7.loss_mask: 0.7583  decode.d7.loss_dice: 1.1978  decode.d8.loss_cls: 1.2924  decode.d8.loss_mask: 0.7632  decode.d8.loss_dice: 1.1871
2023/05/24 07:20:59 - mmengine - INFO - Iter(train) [105750/160000]  lr: 3.7779e-06  eta: 6:30:09  time: 0.4282  data_time: 0.0110  memory: 4855  grad_norm: 120.9767  loss: 40.3937  decode.loss_cls: 1.3351  decode.loss_mask: 0.9083  decode.loss_dice: 1.4611  decode.d0.loss_cls: 3.2675  decode.d0.loss_mask: 0.9884  decode.d0.loss_dice: 1.8087  decode.d1.loss_cls: 1.4914  decode.d1.loss_mask: 1.0013  decode.d1.loss_dice: 1.6948  decode.d2.loss_cls: 1.4502  decode.d2.loss_mask: 0.9400  decode.d2.loss_dice: 1.5985  decode.d3.loss_cls: 1.3733  decode.d3.loss_mask: 0.9247  decode.d3.loss_dice: 1.5476  decode.d4.loss_cls: 1.4012  decode.d4.loss_mask: 0.8870  decode.d4.loss_dice: 1.4954  decode.d5.loss_cls: 1.4042  decode.d5.loss_mask: 0.9300  decode.d5.loss_dice: 1.4680  decode.d6.loss_cls: 1.3293  decode.d6.loss_mask: 0.9114  decode.d6.loss_dice: 1.4726  decode.d7.loss_cls: 1.3282  decode.d7.loss_mask: 0.8815  decode.d7.loss_dice: 1.4508  decode.d8.loss_cls: 1.3324  decode.d8.loss_mask: 0.8826  decode.d8.loss_dice: 1.4283
2023/05/24 07:21:20 - mmengine - INFO - Iter(train) [105800/160000]  lr: 3.7748e-06  eta: 6:29:48  time: 0.4481  data_time: 0.0106  memory: 4837  grad_norm: 116.8465  loss: 37.7052  decode.loss_cls: 1.2852  decode.loss_mask: 0.8768  decode.loss_dice: 1.2849  decode.d0.loss_cls: 3.3687  decode.d0.loss_mask: 0.8948  decode.d0.loss_dice: 1.5926  decode.d1.loss_cls: 1.4122  decode.d1.loss_mask: 0.9481  decode.d1.loss_dice: 1.4381  decode.d2.loss_cls: 1.3382  decode.d2.loss_mask: 0.8884  decode.d2.loss_dice: 1.3439  decode.d3.loss_cls: 1.4077  decode.d3.loss_mask: 0.8599  decode.d3.loss_dice: 1.3129  decode.d4.loss_cls: 1.3509  decode.d4.loss_mask: 0.8509  decode.d4.loss_dice: 1.3048  decode.d5.loss_cls: 1.3136  decode.d5.loss_mask: 0.8511  decode.d5.loss_dice: 1.3243  decode.d6.loss_cls: 1.3291  decode.d6.loss_mask: 0.8726  decode.d6.loss_dice: 1.2909  decode.d7.loss_cls: 1.3207  decode.d7.loss_mask: 0.8866  decode.d7.loss_dice: 1.2787  decode.d8.loss_cls: 1.3179  decode.d8.loss_mask: 0.8764  decode.d8.loss_dice: 1.2844
2023/05/24 07:21:41 - mmengine - INFO - Iter(train) [105850/160000]  lr: 3.7717e-06  eta: 6:29:26  time: 0.4208  data_time: 0.0104  memory: 4847  grad_norm: 91.1005  loss: 40.3351  decode.loss_cls: 1.4973  decode.loss_mask: 0.8567  decode.loss_dice: 1.3886  decode.d0.loss_cls: 3.1601  decode.d0.loss_mask: 0.9792  decode.d0.loss_dice: 1.6178  decode.d1.loss_cls: 1.6637  decode.d1.loss_mask: 0.9171  decode.d1.loss_dice: 1.4643  decode.d2.loss_cls: 1.5870  decode.d2.loss_mask: 0.8835  decode.d2.loss_dice: 1.4380  decode.d3.loss_cls: 1.6197  decode.d3.loss_mask: 0.8450  decode.d3.loss_dice: 1.4104  decode.d4.loss_cls: 1.5190  decode.d4.loss_mask: 0.8835  decode.d4.loss_dice: 1.4141  decode.d5.loss_cls: 1.5983  decode.d5.loss_mask: 0.8771  decode.d5.loss_dice: 1.4028  decode.d6.loss_cls: 1.5280  decode.d6.loss_mask: 0.8592  decode.d6.loss_dice: 1.4155  decode.d7.loss_cls: 1.5231  decode.d7.loss_mask: 0.8492  decode.d7.loss_dice: 1.3841  decode.d8.loss_cls: 1.5039  decode.d8.loss_mask: 0.8602  decode.d8.loss_dice: 1.3887
2023/05/24 07:22:02 - mmengine - INFO - Iter(train) [105900/160000]  lr: 3.7685e-06  eta: 6:29:04  time: 0.4187  data_time: 0.0107  memory: 4856  grad_norm: 96.3560  loss: 34.7525  decode.loss_cls: 1.1904  decode.loss_mask: 0.7808  decode.loss_dice: 1.2299  decode.d0.loss_cls: 3.0268  decode.d0.loss_mask: 0.8027  decode.d0.loss_dice: 1.3755  decode.d1.loss_cls: 1.3617  decode.d1.loss_mask: 0.8234  decode.d1.loss_dice: 1.3666  decode.d2.loss_cls: 1.2960  decode.d2.loss_mask: 0.7904  decode.d2.loss_dice: 1.3057  decode.d3.loss_cls: 1.2452  decode.d3.loss_mask: 0.7753  decode.d3.loss_dice: 1.2517  decode.d4.loss_cls: 1.2068  decode.d4.loss_mask: 0.7733  decode.d4.loss_dice: 1.2193  decode.d5.loss_cls: 1.2190  decode.d5.loss_mask: 0.8046  decode.d5.loss_dice: 1.2605  decode.d6.loss_cls: 1.2267  decode.d6.loss_mask: 0.7811  decode.d6.loss_dice: 1.2396  decode.d7.loss_cls: 1.1519  decode.d7.loss_mask: 0.7823  decode.d7.loss_dice: 1.2372  decode.d8.loss_cls: 1.1903  decode.d8.loss_mask: 0.7858  decode.d8.loss_dice: 1.2519
2023/05/24 07:22:24 - mmengine - INFO - Iter(train) [105950/160000]  lr: 3.7654e-06  eta: 6:28:42  time: 0.4277  data_time: 0.0103  memory: 4857  grad_norm: 111.7750  loss: 29.2387  decode.loss_cls: 0.9214  decode.loss_mask: 0.6289  decode.loss_dice: 1.1096  decode.d0.loss_cls: 3.0715  decode.d0.loss_mask: 0.6870  decode.d0.loss_dice: 1.2977  decode.d1.loss_cls: 1.0623  decode.d1.loss_mask: 0.6180  decode.d1.loss_dice: 1.2068  decode.d2.loss_cls: 0.9186  decode.d2.loss_mask: 0.6542  decode.d2.loss_dice: 1.1614  decode.d3.loss_cls: 0.9369  decode.d3.loss_mask: 0.6417  decode.d3.loss_dice: 1.1466  decode.d4.loss_cls: 0.9000  decode.d4.loss_mask: 0.6516  decode.d4.loss_dice: 1.1247  decode.d5.loss_cls: 0.8864  decode.d5.loss_mask: 0.6317  decode.d5.loss_dice: 1.1195  decode.d6.loss_cls: 0.8481  decode.d6.loss_mask: 0.6382  decode.d6.loss_dice: 1.1494  decode.d7.loss_cls: 0.8990  decode.d7.loss_mask: 0.6309  decode.d7.loss_dice: 1.1066  decode.d8.loss_cls: 0.8648  decode.d8.loss_mask: 0.6256  decode.d8.loss_dice: 1.0995
2023/05/24 07:22:45 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 07:22:45 - mmengine - INFO - Iter(train) [106000/160000]  lr: 3.7623e-06  eta: 6:28:21  time: 0.4186  data_time: 0.0102  memory: 4889  grad_norm: 91.2386  loss: 40.7536  decode.loss_cls: 1.4239  decode.loss_mask: 0.7784  decode.loss_dice: 1.5245  decode.d0.loss_cls: 3.3628  decode.d0.loss_mask: 0.8940  decode.d0.loss_dice: 1.7769  decode.d1.loss_cls: 1.5930  decode.d1.loss_mask: 0.8141  decode.d1.loss_dice: 1.6537  decode.d2.loss_cls: 1.5389  decode.d2.loss_mask: 0.8129  decode.d2.loss_dice: 1.5827  decode.d3.loss_cls: 1.5513  decode.d3.loss_mask: 0.7748  decode.d3.loss_dice: 1.5867  decode.d4.loss_cls: 1.4366  decode.d4.loss_mask: 0.8180  decode.d4.loss_dice: 1.5976  decode.d5.loss_cls: 1.4794  decode.d5.loss_mask: 0.7962  decode.d5.loss_dice: 1.5934  decode.d6.loss_cls: 1.4783  decode.d6.loss_mask: 0.7702  decode.d6.loss_dice: 1.5624  decode.d7.loss_cls: 1.4487  decode.d7.loss_mask: 0.7652  decode.d7.loss_dice: 1.5590  decode.d8.loss_cls: 1.4576  decode.d8.loss_mask: 0.7668  decode.d8.loss_dice: 1.5556
2023/05/24 07:22:45 - mmengine - INFO - Saving checkpoint at 106000 iterations
2023/05/24 07:23:13 - mmengine - INFO - Iter(train) [106050/160000]  lr: 3.7591e-06  eta: 6:28:02  time: 0.4783  data_time: 0.0101  memory: 4821  grad_norm: 85.2915  loss: 34.8861  decode.loss_cls: 1.1053  decode.loss_mask: 0.7802  decode.loss_dice: 1.2527  decode.d0.loss_cls: 3.3201  decode.d0.loss_mask: 0.8474  decode.d0.loss_dice: 1.4619  decode.d1.loss_cls: 1.3358  decode.d1.loss_mask: 0.8048  decode.d1.loss_dice: 1.3439  decode.d2.loss_cls: 1.2323  decode.d2.loss_mask: 0.8197  decode.d2.loss_dice: 1.2750  decode.d3.loss_cls: 1.1386  decode.d3.loss_mask: 0.8329  decode.d3.loss_dice: 1.2849  decode.d4.loss_cls: 1.1581  decode.d4.loss_mask: 0.8033  decode.d4.loss_dice: 1.3200  decode.d5.loss_cls: 1.1858  decode.d5.loss_mask: 0.7959  decode.d5.loss_dice: 1.2952  decode.d6.loss_cls: 1.1080  decode.d6.loss_mask: 0.8006  decode.d6.loss_dice: 1.2759  decode.d7.loss_cls: 1.1321  decode.d7.loss_mask: 0.7925  decode.d7.loss_dice: 1.2413  decode.d8.loss_cls: 1.0897  decode.d8.loss_mask: 0.7910  decode.d8.loss_dice: 1.2612
2023/05/24 07:23:37 - mmengine - INFO - Iter(train) [106100/160000]  lr: 3.7560e-06  eta: 6:27:42  time: 0.4309  data_time: 0.0102  memory: 4906  grad_norm: 103.0968  loss: 42.2073  decode.loss_cls: 1.3514  decode.loss_mask: 0.8933  decode.loss_dice: 1.7009  decode.d0.loss_cls: 3.3522  decode.d0.loss_mask: 0.9265  decode.d0.loss_dice: 1.9085  decode.d1.loss_cls: 1.5024  decode.d1.loss_mask: 0.8491  decode.d1.loss_dice: 1.8188  decode.d2.loss_cls: 1.5069  decode.d2.loss_mask: 0.8725  decode.d2.loss_dice: 1.7837  decode.d3.loss_cls: 1.4126  decode.d3.loss_mask: 0.8845  decode.d3.loss_dice: 1.6825  decode.d4.loss_cls: 1.3879  decode.d4.loss_mask: 0.8879  decode.d4.loss_dice: 1.6819  decode.d5.loss_cls: 1.3627  decode.d5.loss_mask: 0.8915  decode.d5.loss_dice: 1.7270  decode.d6.loss_cls: 1.3845  decode.d6.loss_mask: 0.8776  decode.d6.loss_dice: 1.7035  decode.d7.loss_cls: 1.3862  decode.d7.loss_mask: 0.8510  decode.d7.loss_dice: 1.6803  decode.d8.loss_cls: 1.3506  decode.d8.loss_mask: 0.8845  decode.d8.loss_dice: 1.7043
2023/05/24 07:23:59 - mmengine - INFO - Iter(train) [106150/160000]  lr: 3.7529e-06  eta: 6:27:21  time: 0.4349  data_time: 0.0107  memory: 4846  grad_norm: 87.7857  loss: 37.0081  decode.loss_cls: 0.9894  decode.loss_mask: 0.9911  decode.loss_dice: 1.4781  decode.d0.loss_cls: 3.1228  decode.d0.loss_mask: 1.0639  decode.d0.loss_dice: 1.5857  decode.d1.loss_cls: 1.0772  decode.d1.loss_mask: 1.0066  decode.d1.loss_dice: 1.5451  decode.d2.loss_cls: 1.0682  decode.d2.loss_mask: 0.9908  decode.d2.loss_dice: 1.4956  decode.d3.loss_cls: 1.0086  decode.d3.loss_mask: 0.9823  decode.d3.loss_dice: 1.4557  decode.d4.loss_cls: 1.0057  decode.d4.loss_mask: 0.9847  decode.d4.loss_dice: 1.4709  decode.d5.loss_cls: 0.9994  decode.d5.loss_mask: 0.9551  decode.d5.loss_dice: 1.4606  decode.d6.loss_cls: 1.0036  decode.d6.loss_mask: 0.9814  decode.d6.loss_dice: 1.4561  decode.d7.loss_cls: 0.9872  decode.d7.loss_mask: 0.9693  decode.d7.loss_dice: 1.4556  decode.d8.loss_cls: 1.0258  decode.d8.loss_mask: 0.9696  decode.d8.loss_dice: 1.4218
2023/05/24 07:24:21 - mmengine - INFO - Iter(train) [106200/160000]  lr: 3.7497e-06  eta: 6:26:59  time: 0.4463  data_time: 0.0112  memory: 4832  grad_norm: 108.0595  loss: 41.1320  decode.loss_cls: 1.4153  decode.loss_mask: 0.9446  decode.loss_dice: 1.3945  decode.d0.loss_cls: 3.3927  decode.d0.loss_mask: 1.1041  decode.d0.loss_dice: 1.7221  decode.d1.loss_cls: 1.4791  decode.d1.loss_mask: 1.0188  decode.d1.loss_dice: 1.6382  decode.d2.loss_cls: 1.5214  decode.d2.loss_mask: 0.9990  decode.d2.loss_dice: 1.5254  decode.d3.loss_cls: 1.4565  decode.d3.loss_mask: 0.9631  decode.d3.loss_dice: 1.4777  decode.d4.loss_cls: 1.4873  decode.d4.loss_mask: 0.9632  decode.d4.loss_dice: 1.4371  decode.d5.loss_cls: 1.4688  decode.d5.loss_mask: 0.9625  decode.d5.loss_dice: 1.4350  decode.d6.loss_cls: 1.4423  decode.d6.loss_mask: 0.9358  decode.d6.loss_dice: 1.4236  decode.d7.loss_cls: 1.4418  decode.d7.loss_mask: 0.9362  decode.d7.loss_dice: 1.3950  decode.d8.loss_cls: 1.3928  decode.d8.loss_mask: 0.9494  decode.d8.loss_dice: 1.4088
2023/05/24 07:24:42 - mmengine - INFO - Iter(train) [106250/160000]  lr: 3.7466e-06  eta: 6:26:37  time: 0.4216  data_time: 0.0108  memory: 4863  grad_norm: 90.7592  loss: 32.5284  decode.loss_cls: 1.1946  decode.loss_mask: 0.7158  decode.loss_dice: 1.0812  decode.d0.loss_cls: 2.9560  decode.d0.loss_mask: 0.7733  decode.d0.loss_dice: 1.3230  decode.d1.loss_cls: 1.2500  decode.d1.loss_mask: 0.7438  decode.d1.loss_dice: 1.2107  decode.d2.loss_cls: 1.2733  decode.d2.loss_mask: 0.7147  decode.d2.loss_dice: 1.1451  decode.d3.loss_cls: 1.2032  decode.d3.loss_mask: 0.7226  decode.d3.loss_dice: 1.1286  decode.d4.loss_cls: 1.2145  decode.d4.loss_mask: 0.7259  decode.d4.loss_dice: 1.1042  decode.d5.loss_cls: 1.1553  decode.d5.loss_mask: 0.7336  decode.d5.loss_dice: 1.1231  decode.d6.loss_cls: 1.1953  decode.d6.loss_mask: 0.7416  decode.d6.loss_dice: 1.1050  decode.d7.loss_cls: 1.1404  decode.d7.loss_mask: 0.7434  decode.d7.loss_dice: 1.1213  decode.d8.loss_cls: 1.1588  decode.d8.loss_mask: 0.7197  decode.d8.loss_dice: 1.1105
2023/05/24 07:25:05 - mmengine - INFO - Iter(train) [106300/160000]  lr: 3.7434e-06  eta: 6:26:16  time: 0.4786  data_time: 0.0103  memory: 4834  grad_norm: 85.9691  loss: 30.8681  decode.loss_cls: 1.2175  decode.loss_mask: 0.5466  decode.loss_dice: 1.0949  decode.d0.loss_cls: 2.7855  decode.d0.loss_mask: 0.5916  decode.d0.loss_dice: 1.2952  decode.d1.loss_cls: 1.3878  decode.d1.loss_mask: 0.5567  decode.d1.loss_dice: 1.1886  decode.d2.loss_cls: 1.3006  decode.d2.loss_mask: 0.5706  decode.d2.loss_dice: 1.1292  decode.d3.loss_cls: 1.2362  decode.d3.loss_mask: 0.5544  decode.d3.loss_dice: 1.0761  decode.d4.loss_cls: 1.2334  decode.d4.loss_mask: 0.5578  decode.d4.loss_dice: 1.0744  decode.d5.loss_cls: 1.2081  decode.d5.loss_mask: 0.5596  decode.d5.loss_dice: 1.1129  decode.d6.loss_cls: 1.2076  decode.d6.loss_mask: 0.5626  decode.d6.loss_dice: 1.0765  decode.d7.loss_cls: 1.2176  decode.d7.loss_mask: 0.5662  decode.d7.loss_dice: 1.1006  decode.d8.loss_cls: 1.2181  decode.d8.loss_mask: 0.5457  decode.d8.loss_dice: 1.0954
2023/05/24 07:25:28 - mmengine - INFO - Iter(train) [106350/160000]  lr: 3.7403e-06  eta: 6:25:55  time: 0.4279  data_time: 0.0106  memory: 4857  grad_norm: 96.6313  loss: 37.0192  decode.loss_cls: 1.2643  decode.loss_mask: 0.8313  decode.loss_dice: 1.3035  decode.d0.loss_cls: 3.1163  decode.d0.loss_mask: 0.9114  decode.d0.loss_dice: 1.5566  decode.d1.loss_cls: 1.4448  decode.d1.loss_mask: 0.8462  decode.d1.loss_dice: 1.4246  decode.d2.loss_cls: 1.3904  decode.d2.loss_mask: 0.8670  decode.d2.loss_dice: 1.3671  decode.d3.loss_cls: 1.2217  decode.d3.loss_mask: 0.9328  decode.d3.loss_dice: 1.3614  decode.d4.loss_cls: 1.2543  decode.d4.loss_mask: 0.8963  decode.d4.loss_dice: 1.3399  decode.d5.loss_cls: 1.2631  decode.d5.loss_mask: 0.8628  decode.d5.loss_dice: 1.3202  decode.d6.loss_cls: 1.2478  decode.d6.loss_mask: 0.8520  decode.d6.loss_dice: 1.3269  decode.d7.loss_cls: 1.2356  decode.d7.loss_mask: 0.8490  decode.d7.loss_dice: 1.3378  decode.d8.loss_cls: 1.2664  decode.d8.loss_mask: 0.8238  decode.d8.loss_dice: 1.3040
2023/05/24 07:25:49 - mmengine - INFO - Iter(train) [106400/160000]  lr: 3.7372e-06  eta: 6:25:34  time: 0.4574  data_time: 0.0104  memory: 4876  grad_norm: 83.4637  loss: 35.2062  decode.loss_cls: 1.2125  decode.loss_mask: 0.7775  decode.loss_dice: 1.1840  decode.d0.loss_cls: 3.1751  decode.d0.loss_mask: 0.8922  decode.d0.loss_dice: 1.4252  decode.d1.loss_cls: 1.3832  decode.d1.loss_mask: 0.9343  decode.d1.loss_dice: 1.2989  decode.d2.loss_cls: 1.2990  decode.d2.loss_mask: 0.8605  decode.d2.loss_dice: 1.2423  decode.d3.loss_cls: 1.2892  decode.d3.loss_mask: 0.8207  decode.d3.loss_dice: 1.2146  decode.d4.loss_cls: 1.2556  decode.d4.loss_mask: 0.8206  decode.d4.loss_dice: 1.2263  decode.d5.loss_cls: 1.2441  decode.d5.loss_mask: 0.8233  decode.d5.loss_dice: 1.1844  decode.d6.loss_cls: 1.2498  decode.d6.loss_mask: 0.8063  decode.d6.loss_dice: 1.2097  decode.d7.loss_cls: 1.2027  decode.d7.loss_mask: 0.8236  decode.d7.loss_dice: 1.2068  decode.d8.loss_cls: 1.1791  decode.d8.loss_mask: 0.7953  decode.d8.loss_dice: 1.1691
2023/05/24 07:26:11 - mmengine - INFO - Iter(train) [106450/160000]  lr: 3.7340e-06  eta: 6:25:12  time: 0.4232  data_time: 0.0107  memory: 4803  grad_norm: 86.6050  loss: 34.4718  decode.loss_cls: 1.1882  decode.loss_mask: 0.7175  decode.loss_dice: 1.3217  decode.d0.loss_cls: 3.1249  decode.d0.loss_mask: 0.7940  decode.d0.loss_dice: 1.4792  decode.d1.loss_cls: 1.1743  decode.d1.loss_mask: 0.7977  decode.d1.loss_dice: 1.4284  decode.d2.loss_cls: 1.1494  decode.d2.loss_mask: 0.7432  decode.d2.loss_dice: 1.3620  decode.d3.loss_cls: 1.1692  decode.d3.loss_mask: 0.7546  decode.d3.loss_dice: 1.3287  decode.d4.loss_cls: 1.0939  decode.d4.loss_mask: 0.7606  decode.d4.loss_dice: 1.3330  decode.d5.loss_cls: 1.1544  decode.d5.loss_mask: 0.7232  decode.d5.loss_dice: 1.3198  decode.d6.loss_cls: 1.1595  decode.d6.loss_mask: 0.7168  decode.d6.loss_dice: 1.3118  decode.d7.loss_cls: 1.0919  decode.d7.loss_mask: 0.7530  decode.d7.loss_dice: 1.3223  decode.d8.loss_cls: 1.1683  decode.d8.loss_mask: 0.7171  decode.d8.loss_dice: 1.3133
2023/05/24 07:26:32 - mmengine - INFO - Iter(train) [106500/160000]  lr: 3.7309e-06  eta: 6:24:50  time: 0.4222  data_time: 0.0103  memory: 4991  grad_norm: 82.9029  loss: 40.2610  decode.loss_cls: 1.5461  decode.loss_mask: 0.7990  decode.loss_dice: 1.4008  decode.d0.loss_cls: 3.5748  decode.d0.loss_mask: 0.7498  decode.d0.loss_dice: 1.6776  decode.d1.loss_cls: 1.6222  decode.d1.loss_mask: 0.8298  decode.d1.loss_dice: 1.5248  decode.d2.loss_cls: 1.5202  decode.d2.loss_mask: 0.8517  decode.d2.loss_dice: 1.5119  decode.d3.loss_cls: 1.5521  decode.d3.loss_mask: 0.8631  decode.d3.loss_dice: 1.4379  decode.d4.loss_cls: 1.5023  decode.d4.loss_mask: 0.7910  decode.d4.loss_dice: 1.4820  decode.d5.loss_cls: 1.5141  decode.d5.loss_mask: 0.8221  decode.d5.loss_dice: 1.4526  decode.d6.loss_cls: 1.5381  decode.d6.loss_mask: 0.7972  decode.d6.loss_dice: 1.4155  decode.d7.loss_cls: 1.5489  decode.d7.loss_mask: 0.7788  decode.d7.loss_dice: 1.4159  decode.d8.loss_cls: 1.5157  decode.d8.loss_mask: 0.8104  decode.d8.loss_dice: 1.4148
2023/05/24 07:26:53 - mmengine - INFO - Iter(train) [106550/160000]  lr: 3.7278e-06  eta: 6:24:29  time: 0.4222  data_time: 0.0106  memory: 4836  grad_norm: 119.6328  loss: 35.5164  decode.loss_cls: 1.2555  decode.loss_mask: 0.7813  decode.loss_dice: 1.1749  decode.d0.loss_cls: 3.3236  decode.d0.loss_mask: 0.8702  decode.d0.loss_dice: 1.5011  decode.d1.loss_cls: 1.4145  decode.d1.loss_mask: 0.8060  decode.d1.loss_dice: 1.3629  decode.d2.loss_cls: 1.2792  decode.d2.loss_mask: 0.7931  decode.d2.loss_dice: 1.2181  decode.d3.loss_cls: 1.4052  decode.d3.loss_mask: 0.7711  decode.d3.loss_dice: 1.1796  decode.d4.loss_cls: 1.3816  decode.d4.loss_mask: 0.7776  decode.d4.loss_dice: 1.2125  decode.d5.loss_cls: 1.3292  decode.d5.loss_mask: 0.8288  decode.d5.loss_dice: 1.1980  decode.d6.loss_cls: 1.2911  decode.d6.loss_mask: 0.7880  decode.d6.loss_dice: 1.1694  decode.d7.loss_cls: 1.2358  decode.d7.loss_mask: 0.7926  decode.d7.loss_dice: 1.1790  decode.d8.loss_cls: 1.2584  decode.d8.loss_mask: 0.7900  decode.d8.loss_dice: 1.1481
2023/05/24 07:27:15 - mmengine - INFO - Iter(train) [106600/160000]  lr: 3.7246e-06  eta: 6:24:07  time: 0.4186  data_time: 0.0108  memory: 4898  grad_norm: 98.9985  loss: 35.4073  decode.loss_cls: 1.2898  decode.loss_mask: 0.7834  decode.loss_dice: 1.2207  decode.d0.loss_cls: 3.0278  decode.d0.loss_mask: 0.8151  decode.d0.loss_dice: 1.4259  decode.d1.loss_cls: 1.4304  decode.d1.loss_mask: 0.8225  decode.d1.loss_dice: 1.3061  decode.d2.loss_cls: 1.3063  decode.d2.loss_mask: 0.8254  decode.d2.loss_dice: 1.2375  decode.d3.loss_cls: 1.2586  decode.d3.loss_mask: 0.8037  decode.d3.loss_dice: 1.2534  decode.d4.loss_cls: 1.2941  decode.d4.loss_mask: 0.7755  decode.d4.loss_dice: 1.2587  decode.d5.loss_cls: 1.3328  decode.d5.loss_mask: 0.7979  decode.d5.loss_dice: 1.2275  decode.d6.loss_cls: 1.2759  decode.d6.loss_mask: 0.7738  decode.d6.loss_dice: 1.2426  decode.d7.loss_cls: 1.3490  decode.d7.loss_mask: 0.7741  decode.d7.loss_dice: 1.2299  decode.d8.loss_cls: 1.2683  decode.d8.loss_mask: 0.7843  decode.d8.loss_dice: 1.2164
2023/05/24 07:27:36 - mmengine - INFO - Iter(train) [106650/160000]  lr: 3.7215e-06  eta: 6:23:45  time: 0.4208  data_time: 0.0105  memory: 4830  grad_norm: 118.5815  loss: 28.5000  decode.loss_cls: 1.0281  decode.loss_mask: 0.6297  decode.loss_dice: 0.9341  decode.d0.loss_cls: 2.9000  decode.d0.loss_mask: 0.6809  decode.d0.loss_dice: 1.1444  decode.d1.loss_cls: 1.1849  decode.d1.loss_mask: 0.7141  decode.d1.loss_dice: 1.0403  decode.d2.loss_cls: 1.0208  decode.d2.loss_mask: 0.7181  decode.d2.loss_dice: 1.0049  decode.d3.loss_cls: 1.0200  decode.d3.loss_mask: 0.6499  decode.d3.loss_dice: 0.9415  decode.d4.loss_cls: 1.0228  decode.d4.loss_mask: 0.6475  decode.d4.loss_dice: 0.9202  decode.d5.loss_cls: 1.0216  decode.d5.loss_mask: 0.6514  decode.d5.loss_dice: 0.9309  decode.d6.loss_cls: 1.0689  decode.d6.loss_mask: 0.6231  decode.d6.loss_dice: 0.9132  decode.d7.loss_cls: 1.0250  decode.d7.loss_mask: 0.6147  decode.d7.loss_dice: 0.9067  decode.d8.loss_cls: 0.9968  decode.d8.loss_mask: 0.6242  decode.d8.loss_dice: 0.9218
2023/05/24 07:27:57 - mmengine - INFO - Iter(train) [106700/160000]  lr: 3.7183e-06  eta: 6:23:23  time: 0.4242  data_time: 0.0106  memory: 4805  grad_norm: 100.8066  loss: 34.1116  decode.loss_cls: 1.2822  decode.loss_mask: 0.8253  decode.loss_dice: 0.9913  decode.d0.loss_cls: 3.2272  decode.d0.loss_mask: 0.8685  decode.d0.loss_dice: 1.2304  decode.d1.loss_cls: 1.4665  decode.d1.loss_mask: 0.8417  decode.d1.loss_dice: 1.0590  decode.d2.loss_cls: 1.3873  decode.d2.loss_mask: 0.8432  decode.d2.loss_dice: 1.0603  decode.d3.loss_cls: 1.3977  decode.d3.loss_mask: 0.8346  decode.d3.loss_dice: 1.0381  decode.d4.loss_cls: 1.3653  decode.d4.loss_mask: 0.8165  decode.d4.loss_dice: 1.0397  decode.d5.loss_cls: 1.2841  decode.d5.loss_mask: 0.8401  decode.d5.loss_dice: 1.0526  decode.d6.loss_cls: 1.3424  decode.d6.loss_mask: 0.8147  decode.d6.loss_dice: 0.9896  decode.d7.loss_cls: 1.3228  decode.d7.loss_mask: 0.8122  decode.d7.loss_dice: 0.9754  decode.d8.loss_cls: 1.2947  decode.d8.loss_mask: 0.8118  decode.d8.loss_dice: 0.9964
2023/05/24 07:28:19 - mmengine - INFO - Iter(train) [106750/160000]  lr: 3.7152e-06  eta: 6:23:02  time: 0.4358  data_time: 0.0104  memory: 4875  grad_norm: 97.3069  loss: 29.1035  decode.loss_cls: 0.9804  decode.loss_mask: 0.5948  decode.loss_dice: 1.0301  decode.d0.loss_cls: 2.9413  decode.d0.loss_mask: 0.6862  decode.d0.loss_dice: 1.2087  decode.d1.loss_cls: 1.1634  decode.d1.loss_mask: 0.6248  decode.d1.loss_dice: 1.1507  decode.d2.loss_cls: 1.0319  decode.d2.loss_mask: 0.6152  decode.d2.loss_dice: 1.1069  decode.d3.loss_cls: 1.0632  decode.d3.loss_mask: 0.5863  decode.d3.loss_dice: 1.0216  decode.d4.loss_cls: 1.0486  decode.d4.loss_mask: 0.5995  decode.d4.loss_dice: 1.0362  decode.d5.loss_cls: 1.0870  decode.d5.loss_mask: 0.6007  decode.d5.loss_dice: 1.0066  decode.d6.loss_cls: 1.0241  decode.d6.loss_mask: 0.5968  decode.d6.loss_dice: 1.0213  decode.d7.loss_cls: 1.0327  decode.d7.loss_mask: 0.5903  decode.d7.loss_dice: 1.0286  decode.d8.loss_cls: 1.0281  decode.d8.loss_mask: 0.5919  decode.d8.loss_dice: 1.0057
2023/05/24 07:28:42 - mmengine - INFO - Iter(train) [106800/160000]  lr: 3.7121e-06  eta: 6:22:41  time: 0.4492  data_time: 0.0105  memory: 4866  grad_norm: 95.6171  loss: 38.3347  decode.loss_cls: 1.2910  decode.loss_mask: 0.7721  decode.loss_dice: 1.4688  decode.d0.loss_cls: 3.2655  decode.d0.loss_mask: 0.8059  decode.d0.loss_dice: 1.6804  decode.d1.loss_cls: 1.4664  decode.d1.loss_mask: 0.7868  decode.d1.loss_dice: 1.5701  decode.d2.loss_cls: 1.4109  decode.d2.loss_mask: 0.7965  decode.d2.loss_dice: 1.5410  decode.d3.loss_cls: 1.3810  decode.d3.loss_mask: 0.7798  decode.d3.loss_dice: 1.5137  decode.d4.loss_cls: 1.3543  decode.d4.loss_mask: 0.7887  decode.d4.loss_dice: 1.4983  decode.d5.loss_cls: 1.3004  decode.d5.loss_mask: 0.7724  decode.d5.loss_dice: 1.5036  decode.d6.loss_cls: 1.3211  decode.d6.loss_mask: 0.7717  decode.d6.loss_dice: 1.4534  decode.d7.loss_cls: 1.3076  decode.d7.loss_mask: 0.7632  decode.d7.loss_dice: 1.4586  decode.d8.loss_cls: 1.2927  decode.d8.loss_mask: 0.7643  decode.d8.loss_dice: 1.4547
2023/05/24 07:29:04 - mmengine - INFO - Iter(train) [106850/160000]  lr: 3.7089e-06  eta: 6:22:19  time: 0.4295  data_time: 0.0107  memory: 4850  grad_norm: 94.6898  loss: 39.4974  decode.loss_cls: 1.2746  decode.loss_mask: 0.7613  decode.loss_dice: 1.6390  decode.d0.loss_cls: 3.2026  decode.d0.loss_mask: 0.8303  decode.d0.loss_dice: 1.9456  decode.d1.loss_cls: 1.4085  decode.d1.loss_mask: 0.7880  decode.d1.loss_dice: 1.7531  decode.d2.loss_cls: 1.3439  decode.d2.loss_mask: 0.7711  decode.d2.loss_dice: 1.6730  decode.d3.loss_cls: 1.2738  decode.d3.loss_mask: 0.7655  decode.d3.loss_dice: 1.6710  decode.d4.loss_cls: 1.3041  decode.d4.loss_mask: 0.7621  decode.d4.loss_dice: 1.6153  decode.d5.loss_cls: 1.2329  decode.d5.loss_mask: 0.7691  decode.d5.loss_dice: 1.6415  decode.d6.loss_cls: 1.3444  decode.d6.loss_mask: 0.7488  decode.d6.loss_dice: 1.5963  decode.d7.loss_cls: 1.3534  decode.d7.loss_mask: 0.7540  decode.d7.loss_dice: 1.5974  decode.d8.loss_cls: 1.3084  decode.d8.loss_mask: 0.7496  decode.d8.loss_dice: 1.6189
2023/05/24 07:29:25 - mmengine - INFO - Iter(train) [106900/160000]  lr: 3.7058e-06  eta: 6:21:58  time: 0.4300  data_time: 0.0110  memory: 4863  grad_norm: 98.3860  loss: 32.6419  decode.loss_cls: 1.1932  decode.loss_mask: 0.6712  decode.loss_dice: 1.0675  decode.d0.loss_cls: 3.4306  decode.d0.loss_mask: 0.7290  decode.d0.loss_dice: 1.2880  decode.d1.loss_cls: 1.3394  decode.d1.loss_mask: 0.7161  decode.d1.loss_dice: 1.1540  decode.d2.loss_cls: 1.2795  decode.d2.loss_mask: 0.7028  decode.d2.loss_dice: 1.0799  decode.d3.loss_cls: 1.2569  decode.d3.loss_mask: 0.6908  decode.d3.loss_dice: 1.1234  decode.d4.loss_cls: 1.2125  decode.d4.loss_mask: 0.6925  decode.d4.loss_dice: 1.0894  decode.d5.loss_cls: 1.2772  decode.d5.loss_mask: 0.6876  decode.d5.loss_dice: 1.0927  decode.d6.loss_cls: 1.2041  decode.d6.loss_mask: 0.6826  decode.d6.loss_dice: 1.0689  decode.d7.loss_cls: 1.2339  decode.d7.loss_mask: 0.6709  decode.d7.loss_dice: 1.0775  decode.d8.loss_cls: 1.1451  decode.d8.loss_mask: 0.6719  decode.d8.loss_dice: 1.1129
2023/05/24 07:29:46 - mmengine - INFO - Iter(train) [106950/160000]  lr: 3.7026e-06  eta: 6:21:36  time: 0.4279  data_time: 0.0105  memory: 4882  grad_norm: 102.0443  loss: 30.1803  decode.loss_cls: 0.9880  decode.loss_mask: 0.7059  decode.loss_dice: 0.9856  decode.d0.loss_cls: 3.1697  decode.d0.loss_mask: 0.8104  decode.d0.loss_dice: 1.2199  decode.d1.loss_cls: 1.1829  decode.d1.loss_mask: 0.8016  decode.d1.loss_dice: 1.1442  decode.d2.loss_cls: 1.0793  decode.d2.loss_mask: 0.7075  decode.d2.loss_dice: 1.0493  decode.d3.loss_cls: 1.1030  decode.d3.loss_mask: 0.6983  decode.d3.loss_dice: 0.9888  decode.d4.loss_cls: 1.0672  decode.d4.loss_mask: 0.6979  decode.d4.loss_dice: 0.9962  decode.d5.loss_cls: 1.0268  decode.d5.loss_mask: 0.6990  decode.d5.loss_dice: 1.0129  decode.d6.loss_cls: 0.9813  decode.d6.loss_mask: 0.7032  decode.d6.loss_dice: 0.9921  decode.d7.loss_cls: 0.9872  decode.d7.loss_mask: 0.7066  decode.d7.loss_dice: 0.9767  decode.d8.loss_cls: 0.9923  decode.d8.loss_mask: 0.7107  decode.d8.loss_dice: 0.9959
2023/05/24 07:30:08 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 07:30:08 - mmengine - INFO - Iter(train) [107000/160000]  lr: 3.6995e-06  eta: 6:21:14  time: 0.4275  data_time: 0.0105  memory: 4955  grad_norm: 102.5457  loss: 28.0189  decode.loss_cls: 0.8588  decode.loss_mask: 0.7415  decode.loss_dice: 0.9905  decode.d0.loss_cls: 2.7887  decode.d0.loss_mask: 0.7085  decode.d0.loss_dice: 1.0018  decode.d1.loss_cls: 0.9641  decode.d1.loss_mask: 0.7443  decode.d1.loss_dice: 1.0654  decode.d2.loss_cls: 0.8943  decode.d2.loss_mask: 0.7255  decode.d2.loss_dice: 0.9693  decode.d3.loss_cls: 0.8918  decode.d3.loss_mask: 0.7271  decode.d3.loss_dice: 0.9809  decode.d4.loss_cls: 0.8755  decode.d4.loss_mask: 0.7193  decode.d4.loss_dice: 0.9666  decode.d5.loss_cls: 0.9283  decode.d5.loss_mask: 0.7243  decode.d5.loss_dice: 0.9994  decode.d6.loss_cls: 0.8331  decode.d6.loss_mask: 0.7330  decode.d6.loss_dice: 0.9950  decode.d7.loss_cls: 0.8972  decode.d7.loss_mask: 0.7289  decode.d7.loss_dice: 0.9628  decode.d8.loss_cls: 0.8756  decode.d8.loss_mask: 0.7475  decode.d8.loss_dice: 0.9795
2023/05/24 07:30:08 - mmengine - INFO - Saving checkpoint at 107000 iterations
2023/05/24 07:30:35 - mmengine - INFO - Iter(train) [107050/160000]  lr: 3.6964e-06  eta: 6:20:56  time: 0.4290  data_time: 0.0108  memory: 4815  grad_norm: 101.9787  loss: 42.3185  decode.loss_cls: 1.4010  decode.loss_mask: 0.9682  decode.loss_dice: 1.5608  decode.d0.loss_cls: 3.5811  decode.d0.loss_mask: 1.0063  decode.d0.loss_dice: 1.7968  decode.d1.loss_cls: 1.5933  decode.d1.loss_mask: 0.9433  decode.d1.loss_dice: 1.6758  decode.d2.loss_cls: 1.4600  decode.d2.loss_mask: 0.9861  decode.d2.loss_dice: 1.6060  decode.d3.loss_cls: 1.4631  decode.d3.loss_mask: 0.9490  decode.d3.loss_dice: 1.5867  decode.d4.loss_cls: 1.3928  decode.d4.loss_mask: 0.9673  decode.d4.loss_dice: 1.6077  decode.d5.loss_cls: 1.3250  decode.d5.loss_mask: 1.0015  decode.d5.loss_dice: 1.5988  decode.d6.loss_cls: 1.4198  decode.d6.loss_mask: 0.9754  decode.d6.loss_dice: 1.5825  decode.d7.loss_cls: 1.3729  decode.d7.loss_mask: 0.9707  decode.d7.loss_dice: 1.5888  decode.d8.loss_cls: 1.3961  decode.d8.loss_mask: 0.9772  decode.d8.loss_dice: 1.5646
2023/05/24 07:30:58 - mmengine - INFO - Iter(train) [107100/160000]  lr: 3.6932e-06  eta: 6:20:35  time: 0.4413  data_time: 0.0104  memory: 4890  grad_norm: 89.7201  loss: 33.6529  decode.loss_cls: 1.1278  decode.loss_mask: 0.7939  decode.loss_dice: 1.2170  decode.d0.loss_cls: 3.0111  decode.d0.loss_mask: 0.8583  decode.d0.loss_dice: 1.4086  decode.d1.loss_cls: 1.2756  decode.d1.loss_mask: 0.8119  decode.d1.loss_dice: 1.2400  decode.d2.loss_cls: 1.1860  decode.d2.loss_mask: 0.8255  decode.d2.loss_dice: 1.2729  decode.d3.loss_cls: 1.1718  decode.d3.loss_mask: 0.7329  decode.d3.loss_dice: 1.2143  decode.d4.loss_cls: 1.1692  decode.d4.loss_mask: 0.7361  decode.d4.loss_dice: 1.2162  decode.d5.loss_cls: 1.1122  decode.d5.loss_mask: 0.7547  decode.d5.loss_dice: 1.2359  decode.d6.loss_cls: 1.1485  decode.d6.loss_mask: 0.7460  decode.d6.loss_dice: 1.2192  decode.d7.loss_cls: 1.1147  decode.d7.loss_mask: 0.7527  decode.d7.loss_dice: 1.2039  decode.d8.loss_cls: 1.1093  decode.d8.loss_mask: 0.7648  decode.d8.loss_dice: 1.2218
2023/05/24 07:31:19 - mmengine - INFO - Iter(train) [107150/160000]  lr: 3.6901e-06  eta: 6:20:13  time: 0.4123  data_time: 0.0105  memory: 4838  grad_norm: 97.8990  loss: 31.2346  decode.loss_cls: 1.0575  decode.loss_mask: 0.7496  decode.loss_dice: 1.0702  decode.d0.loss_cls: 3.0047  decode.d0.loss_mask: 0.8116  decode.d0.loss_dice: 1.2737  decode.d1.loss_cls: 1.1667  decode.d1.loss_mask: 0.7531  decode.d1.loss_dice: 1.1559  decode.d2.loss_cls: 1.1127  decode.d2.loss_mask: 0.7607  decode.d2.loss_dice: 1.1125  decode.d3.loss_cls: 1.0783  decode.d3.loss_mask: 0.7328  decode.d3.loss_dice: 1.0735  decode.d4.loss_cls: 1.0485  decode.d4.loss_mask: 0.7464  decode.d4.loss_dice: 1.0989  decode.d5.loss_cls: 1.0381  decode.d5.loss_mask: 0.7466  decode.d5.loss_dice: 1.0783  decode.d6.loss_cls: 1.0495  decode.d6.loss_mask: 0.7376  decode.d6.loss_dice: 1.0545  decode.d7.loss_cls: 1.0078  decode.d7.loss_mask: 0.7742  decode.d7.loss_dice: 1.0752  decode.d8.loss_cls: 1.0035  decode.d8.loss_mask: 0.7866  decode.d8.loss_dice: 1.0755
2023/05/24 07:31:40 - mmengine - INFO - Iter(train) [107200/160000]  lr: 3.6869e-06  eta: 6:19:51  time: 0.4269  data_time: 0.0107  memory: 4823  grad_norm: 90.4417  loss: 31.0404  decode.loss_cls: 1.1432  decode.loss_mask: 0.6805  decode.loss_dice: 1.0820  decode.d0.loss_cls: 2.7829  decode.d0.loss_mask: 0.6351  decode.d0.loss_dice: 1.1875  decode.d1.loss_cls: 1.2751  decode.d1.loss_mask: 0.7373  decode.d1.loss_dice: 1.1370  decode.d2.loss_cls: 1.2737  decode.d2.loss_mask: 0.6770  decode.d2.loss_dice: 1.0790  decode.d3.loss_cls: 1.1571  decode.d3.loss_mask: 0.7111  decode.d3.loss_dice: 1.0739  decode.d4.loss_cls: 1.1562  decode.d4.loss_mask: 0.7143  decode.d4.loss_dice: 1.0651  decode.d5.loss_cls: 1.1757  decode.d5.loss_mask: 0.6383  decode.d5.loss_dice: 1.0537  decode.d6.loss_cls: 1.1848  decode.d6.loss_mask: 0.6378  decode.d6.loss_dice: 1.0599  decode.d7.loss_cls: 1.1412  decode.d7.loss_mask: 0.6671  decode.d7.loss_dice: 1.0653  decode.d8.loss_cls: 1.1314  decode.d8.loss_mask: 0.6708  decode.d8.loss_dice: 1.0466
2023/05/24 07:32:02 - mmengine - INFO - Iter(train) [107250/160000]  lr: 3.6838e-06  eta: 6:19:30  time: 0.4485  data_time: 0.0114  memory: 4866  grad_norm: 93.5244  loss: 36.7940  decode.loss_cls: 1.2241  decode.loss_mask: 0.7984  decode.loss_dice: 1.3785  decode.d0.loss_cls: 3.1539  decode.d0.loss_mask: 0.9634  decode.d0.loss_dice: 1.6261  decode.d1.loss_cls: 1.2425  decode.d1.loss_mask: 0.9054  decode.d1.loss_dice: 1.5468  decode.d2.loss_cls: 1.1979  decode.d2.loss_mask: 0.8539  decode.d2.loss_dice: 1.4745  decode.d3.loss_cls: 1.2327  decode.d3.loss_mask: 0.8186  decode.d3.loss_dice: 1.4202  decode.d4.loss_cls: 1.2099  decode.d4.loss_mask: 0.8545  decode.d4.loss_dice: 1.4023  decode.d5.loss_cls: 1.2018  decode.d5.loss_mask: 0.8054  decode.d5.loss_dice: 1.3876  decode.d6.loss_cls: 1.1711  decode.d6.loss_mask: 0.7982  decode.d6.loss_dice: 1.3794  decode.d7.loss_cls: 1.1507  decode.d7.loss_mask: 0.8134  decode.d7.loss_dice: 1.4010  decode.d8.loss_cls: 1.2236  decode.d8.loss_mask: 0.7934  decode.d8.loss_dice: 1.3646
2023/05/24 07:32:24 - mmengine - INFO - Iter(train) [107300/160000]  lr: 3.6806e-06  eta: 6:19:08  time: 0.4417  data_time: 0.0104  memory: 4846  grad_norm: 84.7882  loss: 33.0047  decode.loss_cls: 0.9847  decode.loss_mask: 0.7117  decode.loss_dice: 1.2934  decode.d0.loss_cls: 2.7763  decode.d0.loss_mask: 0.8093  decode.d0.loss_dice: 1.4644  decode.d1.loss_cls: 1.1505  decode.d1.loss_mask: 0.7355  decode.d1.loss_dice: 1.4210  decode.d2.loss_cls: 1.1150  decode.d2.loss_mask: 0.7207  decode.d2.loss_dice: 1.3641  decode.d3.loss_cls: 1.0658  decode.d3.loss_mask: 0.7293  decode.d3.loss_dice: 1.3334  decode.d4.loss_cls: 1.0673  decode.d4.loss_mask: 0.7330  decode.d4.loss_dice: 1.3232  decode.d5.loss_cls: 1.0136  decode.d5.loss_mask: 0.7267  decode.d5.loss_dice: 1.3214  decode.d6.loss_cls: 0.9782  decode.d6.loss_mask: 0.7181  decode.d6.loss_dice: 1.3438  decode.d7.loss_cls: 1.0120  decode.d7.loss_mask: 0.7147  decode.d7.loss_dice: 1.3171  decode.d8.loss_cls: 1.0247  decode.d8.loss_mask: 0.7112  decode.d8.loss_dice: 1.3245
2023/05/24 07:32:46 - mmengine - INFO - Iter(train) [107350/160000]  lr: 3.6775e-06  eta: 6:18:47  time: 0.4278  data_time: 0.0104  memory: 4879  grad_norm: 115.5191  loss: 33.1930  decode.loss_cls: 1.0207  decode.loss_mask: 0.7913  decode.loss_dice: 1.2397  decode.d0.loss_cls: 2.9564  decode.d0.loss_mask: 0.8569  decode.d0.loss_dice: 1.4324  decode.d1.loss_cls: 1.2380  decode.d1.loss_mask: 0.7721  decode.d1.loss_dice: 1.3188  decode.d2.loss_cls: 1.1384  decode.d2.loss_mask: 0.7636  decode.d2.loss_dice: 1.2759  decode.d3.loss_cls: 1.1783  decode.d3.loss_mask: 0.7441  decode.d3.loss_dice: 1.2413  decode.d4.loss_cls: 1.0867  decode.d4.loss_mask: 0.7622  decode.d4.loss_dice: 1.2146  decode.d5.loss_cls: 1.0479  decode.d5.loss_mask: 0.7577  decode.d5.loss_dice: 1.2359  decode.d6.loss_cls: 1.0628  decode.d6.loss_mask: 0.7737  decode.d6.loss_dice: 1.2140  decode.d7.loss_cls: 1.0107  decode.d7.loss_mask: 0.7718  decode.d7.loss_dice: 1.2441  decode.d8.loss_cls: 1.0300  decode.d8.loss_mask: 0.7768  decode.d8.loss_dice: 1.2362
2023/05/24 07:33:10 - mmengine - INFO - Iter(train) [107400/160000]  lr: 3.6744e-06  eta: 6:18:26  time: 0.4749  data_time: 0.0103  memory: 4910  grad_norm: 105.3257  loss: 30.8349  decode.loss_cls: 1.0443  decode.loss_mask: 0.6762  decode.loss_dice: 0.9941  decode.d0.loss_cls: 2.9859  decode.d0.loss_mask: 0.7190  decode.d0.loss_dice: 1.2264  decode.d1.loss_cls: 1.3671  decode.d1.loss_mask: 0.6940  decode.d1.loss_dice: 1.0996  decode.d2.loss_cls: 1.2487  decode.d2.loss_mask: 0.6849  decode.d2.loss_dice: 1.0526  decode.d3.loss_cls: 1.1900  decode.d3.loss_mask: 0.6870  decode.d3.loss_dice: 1.0308  decode.d4.loss_cls: 1.1887  decode.d4.loss_mask: 0.7048  decode.d4.loss_dice: 1.0218  decode.d5.loss_cls: 1.1351  decode.d5.loss_mask: 0.6798  decode.d5.loss_dice: 1.0284  decode.d6.loss_cls: 1.1170  decode.d6.loss_mask: 0.6787  decode.d6.loss_dice: 1.0208  decode.d7.loss_cls: 1.0827  decode.d7.loss_mask: 0.6788  decode.d7.loss_dice: 1.0447  decode.d8.loss_cls: 1.0999  decode.d8.loss_mask: 0.6564  decode.d8.loss_dice: 0.9967
2023/05/24 07:33:31 - mmengine - INFO - Iter(train) [107450/160000]  lr: 3.6712e-06  eta: 6:18:05  time: 0.4268  data_time: 0.0106  memory: 4824  grad_norm: 93.7458  loss: 40.5864  decode.loss_cls: 1.4664  decode.loss_mask: 0.9029  decode.loss_dice: 1.4112  decode.d0.loss_cls: 3.4858  decode.d0.loss_mask: 0.9554  decode.d0.loss_dice: 1.7086  decode.d1.loss_cls: 1.5698  decode.d1.loss_mask: 0.9784  decode.d1.loss_dice: 1.5776  decode.d2.loss_cls: 1.4426  decode.d2.loss_mask: 0.9539  decode.d2.loss_dice: 1.4818  decode.d3.loss_cls: 1.4822  decode.d3.loss_mask: 0.8956  decode.d3.loss_dice: 1.3983  decode.d4.loss_cls: 1.4671  decode.d4.loss_mask: 0.8944  decode.d4.loss_dice: 1.4090  decode.d5.loss_cls: 1.4900  decode.d5.loss_mask: 0.8801  decode.d5.loss_dice: 1.4287  decode.d6.loss_cls: 1.4392  decode.d6.loss_mask: 0.9042  decode.d6.loss_dice: 1.4054  decode.d7.loss_cls: 1.4477  decode.d7.loss_mask: 0.9215  decode.d7.loss_dice: 1.4031  decode.d8.loss_cls: 1.4496  decode.d8.loss_mask: 0.8908  decode.d8.loss_dice: 1.4453
2023/05/24 07:33:53 - mmengine - INFO - Iter(train) [107500/160000]  lr: 3.6681e-06  eta: 6:17:43  time: 0.4149  data_time: 0.0110  memory: 4917  grad_norm: 93.8834  loss: 36.4379  decode.loss_cls: 1.1456  decode.loss_mask: 0.8311  decode.loss_dice: 1.3880  decode.d0.loss_cls: 3.1118  decode.d0.loss_mask: 0.8441  decode.d0.loss_dice: 1.6249  decode.d1.loss_cls: 1.3278  decode.d1.loss_mask: 0.8561  decode.d1.loss_dice: 1.5121  decode.d2.loss_cls: 1.2654  decode.d2.loss_mask: 0.8447  decode.d2.loss_dice: 1.4196  decode.d3.loss_cls: 1.2339  decode.d3.loss_mask: 0.8248  decode.d3.loss_dice: 1.3599  decode.d4.loss_cls: 1.1496  decode.d4.loss_mask: 0.8277  decode.d4.loss_dice: 1.3960  decode.d5.loss_cls: 1.1758  decode.d5.loss_mask: 0.8496  decode.d5.loss_dice: 1.3852  decode.d6.loss_cls: 1.2112  decode.d6.loss_mask: 0.8003  decode.d6.loss_dice: 1.3555  decode.d7.loss_cls: 1.1821  decode.d7.loss_mask: 0.8050  decode.d7.loss_dice: 1.3645  decode.d8.loss_cls: 1.1577  decode.d8.loss_mask: 0.8159  decode.d8.loss_dice: 1.3721
2023/05/24 07:34:14 - mmengine - INFO - Iter(train) [107550/160000]  lr: 3.6649e-06  eta: 6:17:21  time: 0.4201  data_time: 0.0105  memory: 4899  grad_norm: 88.2056  loss: 37.3065  decode.loss_cls: 1.2365  decode.loss_mask: 0.8486  decode.loss_dice: 1.3252  decode.d0.loss_cls: 3.0988  decode.d0.loss_mask: 1.0248  decode.d0.loss_dice: 1.6052  decode.d1.loss_cls: 1.3813  decode.d1.loss_mask: 0.9369  decode.d1.loss_dice: 1.4648  decode.d2.loss_cls: 1.4219  decode.d2.loss_mask: 0.8828  decode.d2.loss_dice: 1.4242  decode.d3.loss_cls: 1.3539  decode.d3.loss_mask: 0.8403  decode.d3.loss_dice: 1.3726  decode.d4.loss_cls: 1.2450  decode.d4.loss_mask: 0.8630  decode.d4.loss_dice: 1.3570  decode.d5.loss_cls: 1.2420  decode.d5.loss_mask: 0.8299  decode.d5.loss_dice: 1.3404  decode.d6.loss_cls: 1.2867  decode.d6.loss_mask: 0.8221  decode.d6.loss_dice: 1.2984  decode.d7.loss_cls: 1.2376  decode.d7.loss_mask: 0.8514  decode.d7.loss_dice: 1.3021  decode.d8.loss_cls: 1.2138  decode.d8.loss_mask: 0.8517  decode.d8.loss_dice: 1.3478
2023/05/24 07:34:36 - mmengine - INFO - Iter(train) [107600/160000]  lr: 3.6618e-06  eta: 6:17:00  time: 0.4723  data_time: 0.0104  memory: 4869  grad_norm: 80.1378  loss: 38.3058  decode.loss_cls: 1.2328  decode.loss_mask: 1.0479  decode.loss_dice: 1.3486  decode.d0.loss_cls: 3.1241  decode.d0.loss_mask: 1.0824  decode.d0.loss_dice: 1.5097  decode.d1.loss_cls: 1.2524  decode.d1.loss_mask: 1.0606  decode.d1.loss_dice: 1.4992  decode.d2.loss_cls: 1.1531  decode.d2.loss_mask: 1.0405  decode.d2.loss_dice: 1.4176  decode.d3.loss_cls: 1.2675  decode.d3.loss_mask: 1.0101  decode.d3.loss_dice: 1.3581  decode.d4.loss_cls: 1.1358  decode.d4.loss_mask: 1.0517  decode.d4.loss_dice: 1.3369  decode.d5.loss_cls: 1.1336  decode.d5.loss_mask: 1.0530  decode.d5.loss_dice: 1.3846  decode.d6.loss_cls: 1.2111  decode.d6.loss_mask: 1.0359  decode.d6.loss_dice: 1.3529  decode.d7.loss_cls: 1.2269  decode.d7.loss_mask: 1.0491  decode.d7.loss_dice: 1.3306  decode.d8.loss_cls: 1.2185  decode.d8.loss_mask: 1.0383  decode.d8.loss_dice: 1.3423
2023/05/24 07:34:58 - mmengine - INFO - Iter(train) [107650/160000]  lr: 3.6586e-06  eta: 6:16:38  time: 0.4262  data_time: 0.0113  memory: 4918  grad_norm: 86.9058  loss: 34.8601  decode.loss_cls: 1.1974  decode.loss_mask: 0.6459  decode.loss_dice: 1.3298  decode.d0.loss_cls: 3.2884  decode.d0.loss_mask: 0.7288  decode.d0.loss_dice: 1.5561  decode.d1.loss_cls: 1.3264  decode.d1.loss_mask: 0.6984  decode.d1.loss_dice: 1.4419  decode.d2.loss_cls: 1.1904  decode.d2.loss_mask: 0.6997  decode.d2.loss_dice: 1.4200  decode.d3.loss_cls: 1.1842  decode.d3.loss_mask: 0.6473  decode.d3.loss_dice: 1.3519  decode.d4.loss_cls: 1.1529  decode.d4.loss_mask: 0.6589  decode.d4.loss_dice: 1.3583  decode.d5.loss_cls: 1.2349  decode.d5.loss_mask: 0.6600  decode.d5.loss_dice: 1.3805  decode.d6.loss_cls: 1.2598  decode.d6.loss_mask: 0.6468  decode.d6.loss_dice: 1.3453  decode.d7.loss_cls: 1.2088  decode.d7.loss_mask: 0.6571  decode.d7.loss_dice: 1.3715  decode.d8.loss_cls: 1.2056  decode.d8.loss_mask: 0.6429  decode.d8.loss_dice: 1.3703
2023/05/24 07:35:19 - mmengine - INFO - Iter(train) [107700/160000]  lr: 3.6555e-06  eta: 6:16:16  time: 0.4182  data_time: 0.0107  memory: 4846  grad_norm: 121.6681  loss: 36.8632  decode.loss_cls: 1.2852  decode.loss_mask: 0.8814  decode.loss_dice: 1.3079  decode.d0.loss_cls: 3.0296  decode.d0.loss_mask: 0.8890  decode.d0.loss_dice: 1.4404  decode.d1.loss_cls: 1.4288  decode.d1.loss_mask: 0.9006  decode.d1.loss_dice: 1.3380  decode.d2.loss_cls: 1.3293  decode.d2.loss_mask: 0.8949  decode.d2.loss_dice: 1.2906  decode.d3.loss_cls: 1.3672  decode.d3.loss_mask: 0.8627  decode.d3.loss_dice: 1.2825  decode.d4.loss_cls: 1.3016  decode.d4.loss_mask: 0.8847  decode.d4.loss_dice: 1.2879  decode.d5.loss_cls: 1.3495  decode.d5.loss_mask: 0.8357  decode.d5.loss_dice: 1.2704  decode.d6.loss_cls: 1.3177  decode.d6.loss_mask: 0.8704  decode.d6.loss_dice: 1.2763  decode.d7.loss_cls: 1.3033  decode.d7.loss_mask: 0.8569  decode.d7.loss_dice: 1.2970  decode.d8.loss_cls: 1.3211  decode.d8.loss_mask: 0.8590  decode.d8.loss_dice: 1.3035
2023/05/24 07:35:41 - mmengine - INFO - Iter(train) [107750/160000]  lr: 3.6523e-06  eta: 6:15:55  time: 0.4465  data_time: 0.0105  memory: 4845  grad_norm: 95.6896  loss: 27.6362  decode.loss_cls: 0.9333  decode.loss_mask: 0.6400  decode.loss_dice: 0.9205  decode.d0.loss_cls: 2.8246  decode.d0.loss_mask: 0.7472  decode.d0.loss_dice: 1.0381  decode.d1.loss_cls: 1.0274  decode.d1.loss_mask: 0.7396  decode.d1.loss_dice: 1.0486  decode.d2.loss_cls: 0.9922  decode.d2.loss_mask: 0.6856  decode.d2.loss_dice: 0.9540  decode.d3.loss_cls: 0.9619  decode.d3.loss_mask: 0.6580  decode.d3.loss_dice: 0.9598  decode.d4.loss_cls: 0.9337  decode.d4.loss_mask: 0.6623  decode.d4.loss_dice: 0.9231  decode.d5.loss_cls: 0.9173  decode.d5.loss_mask: 0.6646  decode.d5.loss_dice: 0.9388  decode.d6.loss_cls: 0.9026  decode.d6.loss_mask: 0.6620  decode.d6.loss_dice: 0.9412  decode.d7.loss_cls: 0.8795  decode.d7.loss_mask: 0.6517  decode.d7.loss_dice: 0.9385  decode.d8.loss_cls: 0.8847  decode.d8.loss_mask: 0.6533  decode.d8.loss_dice: 0.9521
2023/05/24 07:36:02 - mmengine - INFO - Iter(train) [107800/160000]  lr: 3.6492e-06  eta: 6:15:33  time: 0.4173  data_time: 0.0107  memory: 4857  grad_norm: 98.9685  loss: 37.2763  decode.loss_cls: 1.3031  decode.loss_mask: 0.9168  decode.loss_dice: 1.1706  decode.d0.loss_cls: 3.2666  decode.d0.loss_mask: 0.9161  decode.d0.loss_dice: 1.3282  decode.d1.loss_cls: 1.4906  decode.d1.loss_mask: 0.9999  decode.d1.loss_dice: 1.3197  decode.d2.loss_cls: 1.4776  decode.d2.loss_mask: 0.9802  decode.d2.loss_dice: 1.2409  decode.d3.loss_cls: 1.4449  decode.d3.loss_mask: 0.9394  decode.d3.loss_dice: 1.1819  decode.d4.loss_cls: 1.3267  decode.d4.loss_mask: 0.9236  decode.d4.loss_dice: 1.1907  decode.d5.loss_cls: 1.3762  decode.d5.loss_mask: 0.9098  decode.d5.loss_dice: 1.1827  decode.d6.loss_cls: 1.3251  decode.d6.loss_mask: 0.9293  decode.d6.loss_dice: 1.1886  decode.d7.loss_cls: 1.3472  decode.d7.loss_mask: 0.9466  decode.d7.loss_dice: 1.2178  decode.d8.loss_cls: 1.2985  decode.d8.loss_mask: 0.9499  decode.d8.loss_dice: 1.1872
2023/05/24 07:36:23 - mmengine - INFO - Iter(train) [107850/160000]  lr: 3.6461e-06  eta: 6:15:11  time: 0.4183  data_time: 0.0107  memory: 4857  grad_norm: 97.4938  loss: 32.2285  decode.loss_cls: 0.9885  decode.loss_mask: 0.8042  decode.loss_dice: 1.1258  decode.d0.loss_cls: 2.8990  decode.d0.loss_mask: 0.9155  decode.d0.loss_dice: 1.3344  decode.d1.loss_cls: 1.1225  decode.d1.loss_mask: 0.8542  decode.d1.loss_dice: 1.1770  decode.d2.loss_cls: 1.0735  decode.d2.loss_mask: 0.8645  decode.d2.loss_dice: 1.2146  decode.d3.loss_cls: 1.0251  decode.d3.loss_mask: 0.8434  decode.d3.loss_dice: 1.1815  decode.d4.loss_cls: 0.9693  decode.d4.loss_mask: 0.8582  decode.d4.loss_dice: 1.1552  decode.d5.loss_cls: 0.9824  decode.d5.loss_mask: 0.8362  decode.d5.loss_dice: 1.1582  decode.d6.loss_cls: 0.9973  decode.d6.loss_mask: 0.8358  decode.d6.loss_dice: 1.1364  decode.d7.loss_cls: 0.9647  decode.d7.loss_mask: 0.8152  decode.d7.loss_dice: 1.1420  decode.d8.loss_cls: 0.9722  decode.d8.loss_mask: 0.8362  decode.d8.loss_dice: 1.1455
2023/05/24 07:36:44 - mmengine - INFO - Iter(train) [107900/160000]  lr: 3.6429e-06  eta: 6:14:50  time: 0.4195  data_time: 0.0104  memory: 4926  grad_norm: 85.2020  loss: 38.7920  decode.loss_cls: 1.1973  decode.loss_mask: 0.7508  decode.loss_dice: 1.6116  decode.d0.loss_cls: 3.3638  decode.d0.loss_mask: 0.8591  decode.d0.loss_dice: 1.9360  decode.d1.loss_cls: 1.2195  decode.d1.loss_mask: 0.8004  decode.d1.loss_dice: 1.8041  decode.d2.loss_cls: 1.2171  decode.d2.loss_mask: 0.8103  decode.d2.loss_dice: 1.6750  decode.d3.loss_cls: 1.1207  decode.d3.loss_mask: 0.8047  decode.d3.loss_dice: 1.6593  decode.d4.loss_cls: 1.1068  decode.d4.loss_mask: 0.8065  decode.d4.loss_dice: 1.6829  decode.d5.loss_cls: 1.2238  decode.d5.loss_mask: 0.7532  decode.d5.loss_dice: 1.6416  decode.d6.loss_cls: 1.1622  decode.d6.loss_mask: 0.7983  decode.d6.loss_dice: 1.6336  decode.d7.loss_cls: 1.2284  decode.d7.loss_mask: 0.7501  decode.d7.loss_dice: 1.6282  decode.d8.loss_cls: 1.1943  decode.d8.loss_mask: 0.7399  decode.d8.loss_dice: 1.6126
2023/05/24 07:37:05 - mmengine - INFO - Iter(train) [107950/160000]  lr: 3.6398e-06  eta: 6:14:28  time: 0.4220  data_time: 0.0111  memory: 4848  grad_norm: 96.6074  loss: 36.1106  decode.loss_cls: 1.1171  decode.loss_mask: 0.7650  decode.loss_dice: 1.4102  decode.d0.loss_cls: 3.0907  decode.d0.loss_mask: 0.8225  decode.d0.loss_dice: 1.5769  decode.d1.loss_cls: 1.4311  decode.d1.loss_mask: 0.8438  decode.d1.loss_dice: 1.4908  decode.d2.loss_cls: 1.2939  decode.d2.loss_mask: 0.7718  decode.d2.loss_dice: 1.4304  decode.d3.loss_cls: 1.1686  decode.d3.loss_mask: 0.7574  decode.d3.loss_dice: 1.4359  decode.d4.loss_cls: 1.1736  decode.d4.loss_mask: 0.7675  decode.d4.loss_dice: 1.4088  decode.d5.loss_cls: 1.1779  decode.d5.loss_mask: 0.7858  decode.d5.loss_dice: 1.4350  decode.d6.loss_cls: 1.1583  decode.d6.loss_mask: 0.7752  decode.d6.loss_dice: 1.4118  decode.d7.loss_cls: 1.1505  decode.d7.loss_mask: 0.7611  decode.d7.loss_dice: 1.4053  decode.d8.loss_cls: 1.1335  decode.d8.loss_mask: 0.7706  decode.d8.loss_dice: 1.3897
2023/05/24 07:37:26 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 07:37:26 - mmengine - INFO - Iter(train) [108000/160000]  lr: 3.6366e-06  eta: 6:14:06  time: 0.4250  data_time: 0.0104  memory: 4890  grad_norm: 94.8927  loss: 34.6143  decode.loss_cls: 1.2061  decode.loss_mask: 0.7676  decode.loss_dice: 1.2234  decode.d0.loss_cls: 3.1161  decode.d0.loss_mask: 0.8569  decode.d0.loss_dice: 1.4639  decode.d1.loss_cls: 1.2731  decode.d1.loss_mask: 0.7981  decode.d1.loss_dice: 1.3492  decode.d2.loss_cls: 1.2498  decode.d2.loss_mask: 0.8063  decode.d2.loss_dice: 1.2789  decode.d3.loss_cls: 1.1896  decode.d3.loss_mask: 0.7744  decode.d3.loss_dice: 1.2434  decode.d4.loss_cls: 1.1775  decode.d4.loss_mask: 0.7940  decode.d4.loss_dice: 1.2692  decode.d5.loss_cls: 1.1775  decode.d5.loss_mask: 0.7922  decode.d5.loss_dice: 1.2357  decode.d6.loss_cls: 1.1709  decode.d6.loss_mask: 0.7832  decode.d6.loss_dice: 1.2174  decode.d7.loss_cls: 1.1796  decode.d7.loss_mask: 0.7828  decode.d7.loss_dice: 1.2415  decode.d8.loss_cls: 1.1764  decode.d8.loss_mask: 0.7726  decode.d8.loss_dice: 1.2470
2023/05/24 07:37:26 - mmengine - INFO - Saving checkpoint at 108000 iterations
2023/05/24 07:37:53 - mmengine - INFO - Iter(train) [108050/160000]  lr: 3.6335e-06  eta: 6:13:47  time: 0.4328  data_time: 0.0109  memory: 4859  grad_norm: 84.6421  loss: 32.8472  decode.loss_cls: 1.0873  decode.loss_mask: 0.7494  decode.loss_dice: 1.1623  decode.d0.loss_cls: 3.0377  decode.d0.loss_mask: 0.7975  decode.d0.loss_dice: 1.3252  decode.d1.loss_cls: 1.2120  decode.d1.loss_mask: 0.7983  decode.d1.loss_dice: 1.2736  decode.d2.loss_cls: 1.1420  decode.d2.loss_mask: 0.8286  decode.d2.loss_dice: 1.2417  decode.d3.loss_cls: 1.1105  decode.d3.loss_mask: 0.7769  decode.d3.loss_dice: 1.2032  decode.d4.loss_cls: 1.1237  decode.d4.loss_mask: 0.7775  decode.d4.loss_dice: 1.1863  decode.d5.loss_cls: 1.0473  decode.d5.loss_mask: 0.8045  decode.d5.loss_dice: 1.1911  decode.d6.loss_cls: 1.0484  decode.d6.loss_mask: 0.7704  decode.d6.loss_dice: 1.1581  decode.d7.loss_cls: 1.0646  decode.d7.loss_mask: 0.7675  decode.d7.loss_dice: 1.1740  decode.d8.loss_cls: 1.0498  decode.d8.loss_mask: 0.7631  decode.d8.loss_dice: 1.1747
2023/05/24 07:38:15 - mmengine - INFO - Iter(train) [108100/160000]  lr: 3.6303e-06  eta: 6:13:25  time: 0.4316  data_time: 0.0107  memory: 4836  grad_norm: 96.3318  loss: 40.1267  decode.loss_cls: 1.2685  decode.loss_mask: 0.9703  decode.loss_dice: 1.4665  decode.d0.loss_cls: 3.3112  decode.d0.loss_mask: 0.9454  decode.d0.loss_dice: 1.6940  decode.d1.loss_cls: 1.4539  decode.d1.loss_mask: 0.9985  decode.d1.loss_dice: 1.6319  decode.d2.loss_cls: 1.3738  decode.d2.loss_mask: 0.9758  decode.d2.loss_dice: 1.5398  decode.d3.loss_cls: 1.3436  decode.d3.loss_mask: 0.9431  decode.d3.loss_dice: 1.4695  decode.d4.loss_cls: 1.3630  decode.d4.loss_mask: 0.9222  decode.d4.loss_dice: 1.4717  decode.d5.loss_cls: 1.3293  decode.d5.loss_mask: 0.9529  decode.d5.loss_dice: 1.4737  decode.d6.loss_cls: 1.3362  decode.d6.loss_mask: 0.9631  decode.d6.loss_dice: 1.4681  decode.d7.loss_cls: 1.3682  decode.d7.loss_mask: 0.9386  decode.d7.loss_dice: 1.4927  decode.d8.loss_cls: 1.2785  decode.d8.loss_mask: 0.9337  decode.d8.loss_dice: 1.4494
2023/05/24 07:38:36 - mmengine - INFO - Iter(train) [108150/160000]  lr: 3.6272e-06  eta: 6:13:03  time: 0.4178  data_time: 0.0103  memory: 4865  grad_norm: 92.6048  loss: 36.8264  decode.loss_cls: 1.3431  decode.loss_mask: 0.7032  decode.loss_dice: 1.3067  decode.d0.loss_cls: 3.2979  decode.d0.loss_mask: 0.7193  decode.d0.loss_dice: 1.5171  decode.d1.loss_cls: 1.5264  decode.d1.loss_mask: 0.7425  decode.d1.loss_dice: 1.4308  decode.d2.loss_cls: 1.4217  decode.d2.loss_mask: 0.7403  decode.d2.loss_dice: 1.3406  decode.d3.loss_cls: 1.4794  decode.d3.loss_mask: 0.7098  decode.d3.loss_dice: 1.3456  decode.d4.loss_cls: 1.4192  decode.d4.loss_mask: 0.6976  decode.d4.loss_dice: 1.3070  decode.d5.loss_cls: 1.4322  decode.d5.loss_mask: 0.7083  decode.d5.loss_dice: 1.3309  decode.d6.loss_cls: 1.4421  decode.d6.loss_mask: 0.7009  decode.d6.loss_dice: 1.3516  decode.d7.loss_cls: 1.3608  decode.d7.loss_mask: 0.7205  decode.d7.loss_dice: 1.3434  decode.d8.loss_cls: 1.3648  decode.d8.loss_mask: 0.7008  decode.d8.loss_dice: 1.3218
2023/05/24 07:38:57 - mmengine - INFO - Iter(train) [108200/160000]  lr: 3.6240e-06  eta: 6:12:42  time: 0.4221  data_time: 0.0106  memory: 4823  grad_norm: 95.5663  loss: 34.4592  decode.loss_cls: 1.2690  decode.loss_mask: 0.6939  decode.loss_dice: 1.1767  decode.d0.loss_cls: 3.1597  decode.d0.loss_mask: 0.8153  decode.d0.loss_dice: 1.3894  decode.d1.loss_cls: 1.4407  decode.d1.loss_mask: 0.7401  decode.d1.loss_dice: 1.3510  decode.d2.loss_cls: 1.4225  decode.d2.loss_mask: 0.6981  decode.d2.loss_dice: 1.2370  decode.d3.loss_cls: 1.3401  decode.d3.loss_mask: 0.6986  decode.d3.loss_dice: 1.1907  decode.d4.loss_cls: 1.2825  decode.d4.loss_mask: 0.6957  decode.d4.loss_dice: 1.2004  decode.d5.loss_cls: 1.2578  decode.d5.loss_mask: 0.6969  decode.d5.loss_dice: 1.2049  decode.d6.loss_cls: 1.2713  decode.d6.loss_mask: 0.6973  decode.d6.loss_dice: 1.2005  decode.d7.loss_cls: 1.2819  decode.d7.loss_mask: 0.6965  decode.d7.loss_dice: 1.1904  decode.d8.loss_cls: 1.2952  decode.d8.loss_mask: 0.6872  decode.d8.loss_dice: 1.1779
2023/05/24 07:39:19 - mmengine - INFO - Iter(train) [108250/160000]  lr: 3.6209e-06  eta: 6:12:20  time: 0.4870  data_time: 0.0108  memory: 4857  grad_norm: 90.2148  loss: 31.1086  decode.loss_cls: 1.0569  decode.loss_mask: 0.7409  decode.loss_dice: 1.0351  decode.d0.loss_cls: 2.9444  decode.d0.loss_mask: 0.7749  decode.d0.loss_dice: 1.2390  decode.d1.loss_cls: 1.2854  decode.d1.loss_mask: 0.7718  decode.d1.loss_dice: 1.2133  decode.d2.loss_cls: 1.1618  decode.d2.loss_mask: 0.7197  decode.d2.loss_dice: 1.1362  decode.d3.loss_cls: 1.0712  decode.d3.loss_mask: 0.6992  decode.d3.loss_dice: 1.0661  decode.d4.loss_cls: 1.0384  decode.d4.loss_mask: 0.7169  decode.d4.loss_dice: 1.0978  decode.d5.loss_cls: 1.0058  decode.d5.loss_mask: 0.7197  decode.d5.loss_dice: 1.0816  decode.d6.loss_cls: 1.0558  decode.d6.loss_mask: 0.7289  decode.d6.loss_dice: 1.1059  decode.d7.loss_cls: 1.0472  decode.d7.loss_mask: 0.7000  decode.d7.loss_dice: 1.0767  decode.d8.loss_cls: 1.0500  decode.d8.loss_mask: 0.7416  decode.d8.loss_dice: 1.0266
2023/05/24 07:39:41 - mmengine - INFO - Iter(train) [108300/160000]  lr: 3.6177e-06  eta: 6:11:59  time: 0.4204  data_time: 0.0105  memory: 4821  grad_norm: 86.7668  loss: 39.9940  decode.loss_cls: 1.2132  decode.loss_mask: 0.9827  decode.loss_dice: 1.5154  decode.d0.loss_cls: 3.2221  decode.d0.loss_mask: 0.9695  decode.d0.loss_dice: 1.7470  decode.d1.loss_cls: 1.4404  decode.d1.loss_mask: 1.0133  decode.d1.loss_dice: 1.7020  decode.d2.loss_cls: 1.3218  decode.d2.loss_mask: 0.9810  decode.d2.loss_dice: 1.5168  decode.d3.loss_cls: 1.3007  decode.d3.loss_mask: 0.9674  decode.d3.loss_dice: 1.5310  decode.d4.loss_cls: 1.2702  decode.d4.loss_mask: 0.9808  decode.d4.loss_dice: 1.4787  decode.d5.loss_cls: 1.2363  decode.d5.loss_mask: 0.9353  decode.d5.loss_dice: 1.4801  decode.d6.loss_cls: 1.2513  decode.d6.loss_mask: 0.9496  decode.d6.loss_dice: 1.5241  decode.d7.loss_cls: 1.2564  decode.d7.loss_mask: 0.9446  decode.d7.loss_dice: 1.5345  decode.d8.loss_cls: 1.2444  decode.d8.loss_mask: 0.9826  decode.d8.loss_dice: 1.5008
2023/05/24 07:40:04 - mmengine - INFO - Iter(train) [108350/160000]  lr: 3.6146e-06  eta: 6:11:38  time: 0.4816  data_time: 0.0105  memory: 4848  grad_norm: 97.5117  loss: 37.7083  decode.loss_cls: 1.3586  decode.loss_mask: 0.6880  decode.loss_dice: 1.3237  decode.d0.loss_cls: 3.2853  decode.d0.loss_mask: 0.8265  decode.d0.loss_dice: 1.6489  decode.d1.loss_cls: 1.5064  decode.d1.loss_mask: 0.8234  decode.d1.loss_dice: 1.5051  decode.d2.loss_cls: 1.5100  decode.d2.loss_mask: 0.7454  decode.d2.loss_dice: 1.3962  decode.d3.loss_cls: 1.5097  decode.d3.loss_mask: 0.7358  decode.d3.loss_dice: 1.3757  decode.d4.loss_cls: 1.4471  decode.d4.loss_mask: 0.7192  decode.d4.loss_dice: 1.3503  decode.d5.loss_cls: 1.4679  decode.d5.loss_mask: 0.7222  decode.d5.loss_dice: 1.3988  decode.d6.loss_cls: 1.4313  decode.d6.loss_mask: 0.7130  decode.d6.loss_dice: 1.3183  decode.d7.loss_cls: 1.4286  decode.d7.loss_mask: 0.7147  decode.d7.loss_dice: 1.3597  decode.d8.loss_cls: 1.3775  decode.d8.loss_mask: 0.7073  decode.d8.loss_dice: 1.3139
2023/05/24 07:40:28 - mmengine - INFO - Iter(train) [108400/160000]  lr: 3.6114e-06  eta: 6:11:17  time: 0.4753  data_time: 0.0109  memory: 4847  grad_norm: 80.8972  loss: 35.7785  decode.loss_cls: 0.9368  decode.loss_mask: 0.9629  decode.loss_dice: 1.3549  decode.d0.loss_cls: 2.9021  decode.d0.loss_mask: 0.9389  decode.d0.loss_dice: 1.5140  decode.d1.loss_cls: 1.2346  decode.d1.loss_mask: 0.9720  decode.d1.loss_dice: 1.4515  decode.d2.loss_cls: 1.2011  decode.d2.loss_mask: 0.9196  decode.d2.loss_dice: 1.3711  decode.d3.loss_cls: 1.1882  decode.d3.loss_mask: 0.8553  decode.d3.loss_dice: 1.3333  decode.d4.loss_cls: 1.2106  decode.d4.loss_mask: 0.8694  decode.d4.loss_dice: 1.3413  decode.d5.loss_cls: 1.0834  decode.d5.loss_mask: 0.8967  decode.d5.loss_dice: 1.3301  decode.d6.loss_cls: 1.0358  decode.d6.loss_mask: 0.9051  decode.d6.loss_dice: 1.3568  decode.d7.loss_cls: 1.0848  decode.d7.loss_mask: 0.9169  decode.d7.loss_dice: 1.3625  decode.d8.loss_cls: 0.9503  decode.d8.loss_mask: 0.9198  decode.d8.loss_dice: 1.3787
2023/05/24 07:40:50 - mmengine - INFO - Iter(train) [108450/160000]  lr: 3.6083e-06  eta: 6:10:56  time: 0.4329  data_time: 0.0105  memory: 4821  grad_norm: 90.3454  loss: 35.1502  decode.loss_cls: 1.1902  decode.loss_mask: 0.7586  decode.loss_dice: 1.2592  decode.d0.loss_cls: 3.2841  decode.d0.loss_mask: 0.7178  decode.d0.loss_dice: 1.4302  decode.d1.loss_cls: 1.2945  decode.d1.loss_mask: 0.8322  decode.d1.loss_dice: 1.3828  decode.d2.loss_cls: 1.2480  decode.d2.loss_mask: 0.8371  decode.d2.loss_dice: 1.3207  decode.d3.loss_cls: 1.2490  decode.d3.loss_mask: 0.7901  decode.d3.loss_dice: 1.2916  decode.d4.loss_cls: 1.2504  decode.d4.loss_mask: 0.8008  decode.d4.loss_dice: 1.2641  decode.d5.loss_cls: 1.1650  decode.d5.loss_mask: 0.7758  decode.d5.loss_dice: 1.2796  decode.d6.loss_cls: 1.1795  decode.d6.loss_mask: 0.7896  decode.d6.loss_dice: 1.2550  decode.d7.loss_cls: 1.1761  decode.d7.loss_mask: 0.8076  decode.d7.loss_dice: 1.2885  decode.d8.loss_cls: 1.2140  decode.d8.loss_mask: 0.7702  decode.d8.loss_dice: 1.2481
2023/05/24 07:41:11 - mmengine - INFO - Iter(train) [108500/160000]  lr: 3.6051e-06  eta: 6:10:34  time: 0.4117  data_time: 0.0102  memory: 4829  grad_norm: 102.6476  loss: 27.2870  decode.loss_cls: 0.7817  decode.loss_mask: 0.7379  decode.loss_dice: 0.9324  decode.d0.loss_cls: 2.7467  decode.d0.loss_mask: 0.7726  decode.d0.loss_dice: 1.0306  decode.d1.loss_cls: 0.8812  decode.d1.loss_mask: 0.7770  decode.d1.loss_dice: 0.9989  decode.d2.loss_cls: 0.8514  decode.d2.loss_mask: 0.7626  decode.d2.loss_dice: 0.9723  decode.d3.loss_cls: 0.8156  decode.d3.loss_mask: 0.7771  decode.d3.loss_dice: 0.9786  decode.d4.loss_cls: 0.8119  decode.d4.loss_mask: 0.7545  decode.d4.loss_dice: 0.9481  decode.d5.loss_cls: 0.7711  decode.d5.loss_mask: 0.7492  decode.d5.loss_dice: 0.9407  decode.d6.loss_cls: 0.8677  decode.d6.loss_mask: 0.7437  decode.d6.loss_dice: 0.9369  decode.d7.loss_cls: 0.7660  decode.d7.loss_mask: 0.7598  decode.d7.loss_dice: 0.9475  decode.d8.loss_cls: 0.8320  decode.d8.loss_mask: 0.7265  decode.d8.loss_dice: 0.9149
2023/05/24 07:41:32 - mmengine - INFO - Iter(train) [108550/160000]  lr: 3.6020e-06  eta: 6:10:13  time: 0.4313  data_time: 0.0112  memory: 4895  grad_norm: 96.3553  loss: 40.1884  decode.loss_cls: 1.2934  decode.loss_mask: 0.9216  decode.loss_dice: 1.5259  decode.d0.loss_cls: 3.1231  decode.d0.loss_mask: 0.9037  decode.d0.loss_dice: 1.7676  decode.d1.loss_cls: 1.4718  decode.d1.loss_mask: 0.9453  decode.d1.loss_dice: 1.6853  decode.d2.loss_cls: 1.3618  decode.d2.loss_mask: 0.8845  decode.d2.loss_dice: 1.5698  decode.d3.loss_cls: 1.4304  decode.d3.loss_mask: 0.8689  decode.d3.loss_dice: 1.4986  decode.d4.loss_cls: 1.3510  decode.d4.loss_mask: 0.8991  decode.d4.loss_dice: 1.5255  decode.d5.loss_cls: 1.3830  decode.d5.loss_mask: 0.8985  decode.d5.loss_dice: 1.5675  decode.d6.loss_cls: 1.3169  decode.d6.loss_mask: 0.9125  decode.d6.loss_dice: 1.5244  decode.d7.loss_cls: 1.3084  decode.d7.loss_mask: 0.9246  decode.d7.loss_dice: 1.5387  decode.d8.loss_cls: 1.3228  decode.d8.loss_mask: 0.9256  decode.d8.loss_dice: 1.5382
2023/05/24 07:41:53 - mmengine - INFO - Iter(train) [108600/160000]  lr: 3.5988e-06  eta: 6:09:51  time: 0.4179  data_time: 0.0107  memory: 4836  grad_norm: 104.2837  loss: 30.8001  decode.loss_cls: 1.0340  decode.loss_mask: 0.6842  decode.loss_dice: 1.0731  decode.d0.loss_cls: 2.9988  decode.d0.loss_mask: 0.7819  decode.d0.loss_dice: 1.2078  decode.d1.loss_cls: 1.1676  decode.d1.loss_mask: 0.7512  decode.d1.loss_dice: 1.1958  decode.d2.loss_cls: 1.0415  decode.d2.loss_mask: 0.6932  decode.d2.loss_dice: 1.1163  decode.d3.loss_cls: 1.0966  decode.d3.loss_mask: 0.6948  decode.d3.loss_dice: 1.0978  decode.d4.loss_cls: 1.0992  decode.d4.loss_mask: 0.6991  decode.d4.loss_dice: 1.0801  decode.d5.loss_cls: 1.0554  decode.d5.loss_mask: 0.7009  decode.d5.loss_dice: 1.0830  decode.d6.loss_cls: 1.0538  decode.d6.loss_mask: 0.6879  decode.d6.loss_dice: 1.0775  decode.d7.loss_cls: 1.0499  decode.d7.loss_mask: 0.6904  decode.d7.loss_dice: 1.0917  decode.d8.loss_cls: 1.0422  decode.d8.loss_mask: 0.6891  decode.d8.loss_dice: 1.0654
2023/05/24 07:42:16 - mmengine - INFO - Iter(train) [108650/160000]  lr: 3.5957e-06  eta: 6:09:30  time: 0.4772  data_time: 0.0103  memory: 4836  grad_norm: 106.4740  loss: 31.9207  decode.loss_cls: 0.9603  decode.loss_mask: 0.7283  decode.loss_dice: 1.1640  decode.d0.loss_cls: 3.1858  decode.d0.loss_mask: 0.7614  decode.d0.loss_dice: 1.3452  decode.d1.loss_cls: 1.1159  decode.d1.loss_mask: 0.7861  decode.d1.loss_dice: 1.3074  decode.d2.loss_cls: 1.0540  decode.d2.loss_mask: 0.7339  decode.d2.loss_dice: 1.2450  decode.d3.loss_cls: 1.0512  decode.d3.loss_mask: 0.7320  decode.d3.loss_dice: 1.2529  decode.d4.loss_cls: 0.9872  decode.d4.loss_mask: 0.7355  decode.d4.loss_dice: 1.1923  decode.d5.loss_cls: 0.9839  decode.d5.loss_mask: 0.7248  decode.d5.loss_dice: 1.2315  decode.d6.loss_cls: 0.9680  decode.d6.loss_mask: 0.7363  decode.d6.loss_dice: 1.1946  decode.d7.loss_cls: 0.9425  decode.d7.loss_mask: 0.7463  decode.d7.loss_dice: 1.1823  decode.d8.loss_cls: 0.9424  decode.d8.loss_mask: 0.7499  decode.d8.loss_dice: 1.1796
2023/05/24 07:42:38 - mmengine - INFO - Iter(train) [108700/160000]  lr: 3.5925e-06  eta: 6:09:08  time: 0.4227  data_time: 0.0113  memory: 4859  grad_norm: 92.0743  loss: 38.9167  decode.loss_cls: 1.5045  decode.loss_mask: 0.7190  decode.loss_dice: 1.4116  decode.d0.loss_cls: 3.2562  decode.d0.loss_mask: 0.7322  decode.d0.loss_dice: 1.6368  decode.d1.loss_cls: 1.7423  decode.d1.loss_mask: 0.7317  decode.d1.loss_dice: 1.5079  decode.d2.loss_cls: 1.6077  decode.d2.loss_mask: 0.7259  decode.d2.loss_dice: 1.4426  decode.d3.loss_cls: 1.5956  decode.d3.loss_mask: 0.7279  decode.d3.loss_dice: 1.4233  decode.d4.loss_cls: 1.5550  decode.d4.loss_mask: 0.7266  decode.d4.loss_dice: 1.4137  decode.d5.loss_cls: 1.5648  decode.d5.loss_mask: 0.6816  decode.d5.loss_dice: 1.3478  decode.d6.loss_cls: 1.5363  decode.d6.loss_mask: 0.6928  decode.d6.loss_dice: 1.3894  decode.d7.loss_cls: 1.5102  decode.d7.loss_mask: 0.6959  decode.d7.loss_dice: 1.3919  decode.d8.loss_cls: 1.5555  decode.d8.loss_mask: 0.7053  decode.d8.loss_dice: 1.3848
2023/05/24 07:42:59 - mmengine - INFO - Iter(train) [108750/160000]  lr: 3.5894e-06  eta: 6:08:46  time: 0.4219  data_time: 0.0107  memory: 4889  grad_norm: 117.9676  loss: 42.6719  decode.loss_cls: 1.4531  decode.loss_mask: 0.9974  decode.loss_dice: 1.5165  decode.d0.loss_cls: 3.3500  decode.d0.loss_mask: 1.0572  decode.d0.loss_dice: 1.7289  decode.d1.loss_cls: 1.5655  decode.d1.loss_mask: 1.0660  decode.d1.loss_dice: 1.6757  decode.d2.loss_cls: 1.5028  decode.d2.loss_mask: 0.9726  decode.d2.loss_dice: 1.6185  decode.d3.loss_cls: 1.5250  decode.d3.loss_mask: 0.9674  decode.d3.loss_dice: 1.5579  decode.d4.loss_cls: 1.4806  decode.d4.loss_mask: 0.9952  decode.d4.loss_dice: 1.6162  decode.d5.loss_cls: 1.4430  decode.d5.loss_mask: 1.0012  decode.d5.loss_dice: 1.5915  decode.d6.loss_cls: 1.4498  decode.d6.loss_mask: 0.9718  decode.d6.loss_dice: 1.5771  decode.d7.loss_cls: 1.4509  decode.d7.loss_mask: 0.9895  decode.d7.loss_dice: 1.5703  decode.d8.loss_cls: 1.4420  decode.d8.loss_mask: 0.9684  decode.d8.loss_dice: 1.5698
2023/05/24 07:43:20 - mmengine - INFO - Iter(train) [108800/160000]  lr: 3.5862e-06  eta: 6:08:25  time: 0.4273  data_time: 0.0106  memory: 4898  grad_norm: 91.5936  loss: 37.3501  decode.loss_cls: 1.3039  decode.loss_mask: 0.7413  decode.loss_dice: 1.3923  decode.d0.loss_cls: 3.2363  decode.d0.loss_mask: 0.7791  decode.d0.loss_dice: 1.6252  decode.d1.loss_cls: 1.4316  decode.d1.loss_mask: 0.7762  decode.d1.loss_dice: 1.5114  decode.d2.loss_cls: 1.3983  decode.d2.loss_mask: 0.7942  decode.d2.loss_dice: 1.4953  decode.d3.loss_cls: 1.3639  decode.d3.loss_mask: 0.7481  decode.d3.loss_dice: 1.4283  decode.d4.loss_cls: 1.2975  decode.d4.loss_mask: 0.7611  decode.d4.loss_dice: 1.4378  decode.d5.loss_cls: 1.3598  decode.d5.loss_mask: 0.7553  decode.d5.loss_dice: 1.4192  decode.d6.loss_cls: 1.3097  decode.d6.loss_mask: 0.7455  decode.d6.loss_dice: 1.4001  decode.d7.loss_cls: 1.3109  decode.d7.loss_mask: 0.7427  decode.d7.loss_dice: 1.3649  decode.d8.loss_cls: 1.2768  decode.d8.loss_mask: 0.7528  decode.d8.loss_dice: 1.3907
2023/05/24 07:43:41 - mmengine - INFO - Iter(train) [108850/160000]  lr: 3.5831e-06  eta: 6:08:03  time: 0.4185  data_time: 0.0105  memory: 4899  grad_norm: 103.0561  loss: 35.2133  decode.loss_cls: 1.1041  decode.loss_mask: 0.7839  decode.loss_dice: 1.3299  decode.d0.loss_cls: 3.0751  decode.d0.loss_mask: 0.7698  decode.d0.loss_dice: 1.5766  decode.d1.loss_cls: 1.2956  decode.d1.loss_mask: 0.8388  decode.d1.loss_dice: 1.4791  decode.d2.loss_cls: 1.1424  decode.d2.loss_mask: 0.8355  decode.d2.loss_dice: 1.4640  decode.d3.loss_cls: 1.1150  decode.d3.loss_mask: 0.8300  decode.d3.loss_dice: 1.4174  decode.d4.loss_cls: 1.1614  decode.d4.loss_mask: 0.7742  decode.d4.loss_dice: 1.3391  decode.d5.loss_cls: 1.1180  decode.d5.loss_mask: 0.7786  decode.d5.loss_dice: 1.3411  decode.d6.loss_cls: 1.1472  decode.d6.loss_mask: 0.7692  decode.d6.loss_dice: 1.3284  decode.d7.loss_cls: 1.1328  decode.d7.loss_mask: 0.7780  decode.d7.loss_dice: 1.3034  decode.d8.loss_cls: 1.1273  decode.d8.loss_mask: 0.7606  decode.d8.loss_dice: 1.2968
2023/05/24 07:44:02 - mmengine - INFO - Iter(train) [108900/160000]  lr: 3.5799e-06  eta: 6:07:41  time: 0.4219  data_time: 0.0107  memory: 4846  grad_norm: 88.0012  loss: 51.7439  decode.loss_cls: 1.7058  decode.loss_mask: 0.9177  decode.loss_dice: 2.1987  decode.d0.loss_cls: 3.7458  decode.d0.loss_mask: 0.9547  decode.d0.loss_dice: 2.5317  decode.d1.loss_cls: 1.8242  decode.d1.loss_mask: 0.9549  decode.d1.loss_dice: 2.3883  decode.d2.loss_cls: 1.8686  decode.d2.loss_mask: 0.9694  decode.d2.loss_dice: 2.2932  decode.d3.loss_cls: 1.7579  decode.d3.loss_mask: 0.9231  decode.d3.loss_dice: 2.2859  decode.d4.loss_cls: 1.7821  decode.d4.loss_mask: 0.9319  decode.d4.loss_dice: 2.2434  decode.d5.loss_cls: 1.7566  decode.d5.loss_mask: 0.9115  decode.d5.loss_dice: 2.2694  decode.d6.loss_cls: 1.7521  decode.d6.loss_mask: 0.9098  decode.d6.loss_dice: 2.2126  decode.d7.loss_cls: 1.7368  decode.d7.loss_mask: 0.9071  decode.d7.loss_dice: 2.1778  decode.d8.loss_cls: 1.6959  decode.d8.loss_mask: 0.9060  decode.d8.loss_dice: 2.2310
2023/05/24 07:44:24 - mmengine - INFO - Iter(train) [108950/160000]  lr: 3.5768e-06  eta: 6:07:19  time: 0.4237  data_time: 0.0104  memory: 4845  grad_norm: 105.9807  loss: 37.6740  decode.loss_cls: 1.2386  decode.loss_mask: 0.8870  decode.loss_dice: 1.3623  decode.d0.loss_cls: 2.9351  decode.d0.loss_mask: 0.9747  decode.d0.loss_dice: 1.6489  decode.d1.loss_cls: 1.3233  decode.d1.loss_mask: 0.9154  decode.d1.loss_dice: 1.5237  decode.d2.loss_cls: 1.3121  decode.d2.loss_mask: 0.8675  decode.d2.loss_dice: 1.4491  decode.d3.loss_cls: 1.3308  decode.d3.loss_mask: 0.8630  decode.d3.loss_dice: 1.4102  decode.d4.loss_cls: 1.3202  decode.d4.loss_mask: 0.8573  decode.d4.loss_dice: 1.4051  decode.d5.loss_cls: 1.2493  decode.d5.loss_mask: 0.8623  decode.d5.loss_dice: 1.3990  decode.d6.loss_cls: 1.2624  decode.d6.loss_mask: 0.8848  decode.d6.loss_dice: 1.3663  decode.d7.loss_cls: 1.3028  decode.d7.loss_mask: 0.8746  decode.d7.loss_dice: 1.3659  decode.d8.loss_cls: 1.2262  decode.d8.loss_mask: 0.8778  decode.d8.loss_dice: 1.3782
2023/05/24 07:44:45 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 07:44:45 - mmengine - INFO - Iter(train) [109000/160000]  lr: 3.5736e-06  eta: 6:06:58  time: 0.4171  data_time: 0.0103  memory: 4898  grad_norm: 190.7081  loss: 45.4113  decode.loss_cls: 1.4054  decode.loss_mask: 1.0169  decode.loss_dice: 1.7696  decode.d0.loss_cls: 3.8137  decode.d0.loss_mask: 1.1798  decode.d0.loss_dice: 2.0853  decode.d1.loss_cls: 1.5557  decode.d1.loss_mask: 1.1195  decode.d1.loss_dice: 1.9448  decode.d2.loss_cls: 1.4958  decode.d2.loss_mask: 1.0514  decode.d2.loss_dice: 1.8111  decode.d3.loss_cls: 1.4531  decode.d3.loss_mask: 0.9977  decode.d3.loss_dice: 1.7758  decode.d4.loss_cls: 1.4376  decode.d4.loss_mask: 1.0020  decode.d4.loss_dice: 1.7330  decode.d5.loss_cls: 1.4272  decode.d5.loss_mask: 0.9987  decode.d5.loss_dice: 1.7976  decode.d6.loss_cls: 1.4611  decode.d6.loss_mask: 0.9979  decode.d6.loss_dice: 1.7367  decode.d7.loss_cls: 1.4198  decode.d7.loss_mask: 1.0030  decode.d7.loss_dice: 1.7716  decode.d8.loss_cls: 1.4264  decode.d8.loss_mask: 0.9794  decode.d8.loss_dice: 1.7438
2023/05/24 07:44:45 - mmengine - INFO - Saving checkpoint at 109000 iterations
2023/05/24 07:45:13 - mmengine - INFO - Iter(train) [109050/160000]  lr: 3.5705e-06  eta: 6:06:39  time: 0.4332  data_time: 0.0104  memory: 4829  grad_norm: 109.2482  loss: 31.0419  decode.loss_cls: 0.9992  decode.loss_mask: 0.6840  decode.loss_dice: 1.0858  decode.d0.loss_cls: 3.3245  decode.d0.loss_mask: 0.7232  decode.d0.loss_dice: 1.2561  decode.d1.loss_cls: 1.2231  decode.d1.loss_mask: 0.7035  decode.d1.loss_dice: 1.1919  decode.d2.loss_cls: 1.1324  decode.d2.loss_mask: 0.6776  decode.d2.loss_dice: 1.1592  decode.d3.loss_cls: 1.0473  decode.d3.loss_mask: 0.6859  decode.d3.loss_dice: 1.1400  decode.d4.loss_cls: 1.0663  decode.d4.loss_mask: 0.6547  decode.d4.loss_dice: 1.1068  decode.d5.loss_cls: 1.0008  decode.d5.loss_mask: 0.7124  decode.d5.loss_dice: 1.1472  decode.d6.loss_cls: 1.0508  decode.d6.loss_mask: 0.6668  decode.d6.loss_dice: 1.0712  decode.d7.loss_cls: 0.9802  decode.d7.loss_mask: 0.6845  decode.d7.loss_dice: 1.1003  decode.d8.loss_cls: 0.9626  decode.d8.loss_mask: 0.6845  decode.d8.loss_dice: 1.1191
2023/05/24 07:45:34 - mmengine - INFO - Iter(train) [109100/160000]  lr: 3.5673e-06  eta: 6:06:17  time: 0.4140  data_time: 0.0105  memory: 4926  grad_norm: 112.7825  loss: 39.9693  decode.loss_cls: 1.3680  decode.loss_mask: 0.8626  decode.loss_dice: 1.4700  decode.d0.loss_cls: 3.3509  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 1.7483  decode.d1.loss_cls: 1.4332  decode.d1.loss_mask: 0.9163  decode.d1.loss_dice: 1.5922  decode.d2.loss_cls: 1.5008  decode.d2.loss_mask: 0.8638  decode.d2.loss_dice: 1.4826  decode.d3.loss_cls: 1.3993  decode.d3.loss_mask: 0.8807  decode.d3.loss_dice: 1.4519  decode.d4.loss_cls: 1.3424  decode.d4.loss_mask: 0.9272  decode.d4.loss_dice: 1.4771  decode.d5.loss_cls: 1.4282  decode.d5.loss_mask: 0.8871  decode.d5.loss_dice: 1.4508  decode.d6.loss_cls: 1.4082  decode.d6.loss_mask: 0.8808  decode.d6.loss_dice: 1.4720  decode.d7.loss_cls: 1.3946  decode.d7.loss_mask: 0.8619  decode.d7.loss_dice: 1.4928  decode.d8.loss_cls: 1.3606  decode.d8.loss_mask: 0.8724  decode.d8.loss_dice: 1.4439
2023/05/24 07:45:56 - mmengine - INFO - Iter(train) [109150/160000]  lr: 3.5642e-06  eta: 6:05:56  time: 0.4753  data_time: 0.0106  memory: 4952  grad_norm: 87.2579  loss: 42.4654  decode.loss_cls: 1.4686  decode.loss_mask: 0.7851  decode.loss_dice: 1.6349  decode.d0.loss_cls: 3.5247  decode.d0.loss_mask: 0.8431  decode.d0.loss_dice: 2.0212  decode.d1.loss_cls: 1.6924  decode.d1.loss_mask: 0.9050  decode.d1.loss_dice: 1.7780  decode.d2.loss_cls: 1.5726  decode.d2.loss_mask: 0.8505  decode.d2.loss_dice: 1.6639  decode.d3.loss_cls: 1.5280  decode.d3.loss_mask: 0.8323  decode.d3.loss_dice: 1.6461  decode.d4.loss_cls: 1.4995  decode.d4.loss_mask: 0.8164  decode.d4.loss_dice: 1.6694  decode.d5.loss_cls: 1.4799  decode.d5.loss_mask: 0.8206  decode.d5.loss_dice: 1.6601  decode.d6.loss_cls: 1.5241  decode.d6.loss_mask: 0.7983  decode.d6.loss_dice: 1.6343  decode.d7.loss_cls: 1.5143  decode.d7.loss_mask: 0.7855  decode.d7.loss_dice: 1.6150  decode.d8.loss_cls: 1.5111  decode.d8.loss_mask: 0.7881  decode.d8.loss_dice: 1.6024
2023/05/24 07:46:18 - mmengine - INFO - Iter(train) [109200/160000]  lr: 3.5610e-06  eta: 6:05:34  time: 0.4145  data_time: 0.0103  memory: 4836  grad_norm: 108.0106  loss: 34.7695  decode.loss_cls: 1.3290  decode.loss_mask: 0.6951  decode.loss_dice: 1.1209  decode.d0.loss_cls: 3.2318  decode.d0.loss_mask: 0.8156  decode.d0.loss_dice: 1.3773  decode.d1.loss_cls: 1.4801  decode.d1.loss_mask: 0.8132  decode.d1.loss_dice: 1.3131  decode.d2.loss_cls: 1.3539  decode.d2.loss_mask: 0.7759  decode.d2.loss_dice: 1.2134  decode.d3.loss_cls: 1.3257  decode.d3.loss_mask: 0.7289  decode.d3.loss_dice: 1.1763  decode.d4.loss_cls: 1.2563  decode.d4.loss_mask: 0.7652  decode.d4.loss_dice: 1.1877  decode.d5.loss_cls: 1.2694  decode.d5.loss_mask: 0.7108  decode.d5.loss_dice: 1.1856  decode.d6.loss_cls: 1.3393  decode.d6.loss_mask: 0.7002  decode.d6.loss_dice: 1.1505  decode.d7.loss_cls: 1.3927  decode.d7.loss_mask: 0.6965  decode.d7.loss_dice: 1.1609  decode.d8.loss_cls: 1.3801  decode.d8.loss_mask: 0.6943  decode.d8.loss_dice: 1.1300
2023/05/24 07:46:41 - mmengine - INFO - Iter(train) [109250/160000]  lr: 3.5578e-06  eta: 6:05:13  time: 0.4741  data_time: 0.0102  memory: 4808  grad_norm: 101.1915  loss: 39.8878  decode.loss_cls: 1.4350  decode.loss_mask: 0.7957  decode.loss_dice: 1.4463  decode.d0.loss_cls: 3.2075  decode.d0.loss_mask: 0.8955  decode.d0.loss_dice: 1.8200  decode.d1.loss_cls: 1.5120  decode.d1.loss_mask: 0.9169  decode.d1.loss_dice: 1.6191  decode.d2.loss_cls: 1.5675  decode.d2.loss_mask: 0.8295  decode.d2.loss_dice: 1.5165  decode.d3.loss_cls: 1.5047  decode.d3.loss_mask: 0.8121  decode.d3.loss_dice: 1.4808  decode.d4.loss_cls: 1.4686  decode.d4.loss_mask: 0.8186  decode.d4.loss_dice: 1.4630  decode.d5.loss_cls: 1.4341  decode.d5.loss_mask: 0.8145  decode.d5.loss_dice: 1.4384  decode.d6.loss_cls: 1.4728  decode.d6.loss_mask: 0.7919  decode.d6.loss_dice: 1.4231  decode.d7.loss_cls: 1.4267  decode.d7.loss_mask: 0.8031  decode.d7.loss_dice: 1.4614  decode.d8.loss_cls: 1.4683  decode.d8.loss_mask: 0.8010  decode.d8.loss_dice: 1.4430
2023/05/24 07:47:02 - mmengine - INFO - Iter(train) [109300/160000]  lr: 3.5547e-06  eta: 6:04:52  time: 0.4273  data_time: 0.0107  memory: 4866  grad_norm: 96.9774  loss: 35.2010  decode.loss_cls: 1.1831  decode.loss_mask: 0.7472  decode.loss_dice: 1.3172  decode.d0.loss_cls: 3.0285  decode.d0.loss_mask: 0.7430  decode.d0.loss_dice: 1.5355  decode.d1.loss_cls: 1.3572  decode.d1.loss_mask: 0.7615  decode.d1.loss_dice: 1.4419  decode.d2.loss_cls: 1.2841  decode.d2.loss_mask: 0.7473  decode.d2.loss_dice: 1.3801  decode.d3.loss_cls: 1.2618  decode.d3.loss_mask: 0.7343  decode.d3.loss_dice: 1.3468  decode.d4.loss_cls: 1.2307  decode.d4.loss_mask: 0.7511  decode.d4.loss_dice: 1.3495  decode.d5.loss_cls: 1.2072  decode.d5.loss_mask: 0.7308  decode.d5.loss_dice: 1.3121  decode.d6.loss_cls: 1.1866  decode.d6.loss_mask: 0.7467  decode.d6.loss_dice: 1.2978  decode.d7.loss_cls: 1.1674  decode.d7.loss_mask: 0.7489  decode.d7.loss_dice: 1.3058  decode.d8.loss_cls: 1.1775  decode.d8.loss_mask: 0.7620  decode.d8.loss_dice: 1.3576
2023/05/24 07:47:24 - mmengine - INFO - Iter(train) [109350/160000]  lr: 3.5515e-06  eta: 6:04:30  time: 0.4578  data_time: 0.0110  memory: 4837  grad_norm: 89.0484  loss: 35.2224  decode.loss_cls: 1.1907  decode.loss_mask: 0.8318  decode.loss_dice: 1.2188  decode.d0.loss_cls: 3.2668  decode.d0.loss_mask: 0.8564  decode.d0.loss_dice: 1.4039  decode.d1.loss_cls: 1.2222  decode.d1.loss_mask: 0.9363  decode.d1.loss_dice: 1.3451  decode.d2.loss_cls: 1.2396  decode.d2.loss_mask: 0.8910  decode.d2.loss_dice: 1.2619  decode.d3.loss_cls: 1.2158  decode.d3.loss_mask: 0.8393  decode.d3.loss_dice: 1.2385  decode.d4.loss_cls: 1.1754  decode.d4.loss_mask: 0.8654  decode.d4.loss_dice: 1.2278  decode.d5.loss_cls: 1.2336  decode.d5.loss_mask: 0.8264  decode.d5.loss_dice: 1.1888  decode.d6.loss_cls: 1.2010  decode.d6.loss_mask: 0.8300  decode.d6.loss_dice: 1.2408  decode.d7.loss_cls: 1.2196  decode.d7.loss_mask: 0.8263  decode.d7.loss_dice: 1.2078  decode.d8.loss_cls: 1.2278  decode.d8.loss_mask: 0.8260  decode.d8.loss_dice: 1.1676
2023/05/24 07:47:48 - mmengine - INFO - Iter(train) [109400/160000]  lr: 3.5484e-06  eta: 6:04:09  time: 0.4739  data_time: 0.0106  memory: 4803  grad_norm: 94.6931  loss: 31.5978  decode.loss_cls: 1.0832  decode.loss_mask: 0.7075  decode.loss_dice: 1.1392  decode.d0.loss_cls: 2.9899  decode.d0.loss_mask: 0.7699  decode.d0.loss_dice: 1.2905  decode.d1.loss_cls: 1.2060  decode.d1.loss_mask: 0.7421  decode.d1.loss_dice: 1.1990  decode.d2.loss_cls: 1.1731  decode.d2.loss_mask: 0.6953  decode.d2.loss_dice: 1.1649  decode.d3.loss_cls: 1.0879  decode.d3.loss_mask: 0.6788  decode.d3.loss_dice: 1.1345  decode.d4.loss_cls: 1.0876  decode.d4.loss_mask: 0.6914  decode.d4.loss_dice: 1.1339  decode.d5.loss_cls: 1.0651  decode.d5.loss_mask: 0.6874  decode.d5.loss_dice: 1.1415  decode.d6.loss_cls: 1.1081  decode.d6.loss_mask: 0.6837  decode.d6.loss_dice: 1.1195  decode.d7.loss_cls: 1.1278  decode.d7.loss_mask: 0.6765  decode.d7.loss_dice: 1.1188  decode.d8.loss_cls: 1.0903  decode.d8.loss_mask: 0.6773  decode.d8.loss_dice: 1.1271
2023/05/24 07:48:11 - mmengine - INFO - Iter(train) [109450/160000]  lr: 3.5452e-06  eta: 6:03:48  time: 0.4302  data_time: 0.0104  memory: 4823  grad_norm: 115.8787  loss: 40.5739  decode.loss_cls: 1.1123  decode.loss_mask: 1.0632  decode.loss_dice: 1.5791  decode.d0.loss_cls: 3.0640  decode.d0.loss_mask: 1.1780  decode.d0.loss_dice: 1.8819  decode.d1.loss_cls: 1.1721  decode.d1.loss_mask: 1.1369  decode.d1.loss_dice: 1.7463  decode.d2.loss_cls: 1.1725  decode.d2.loss_mask: 1.0978  decode.d2.loss_dice: 1.6871  decode.d3.loss_cls: 1.1391  decode.d3.loss_mask: 1.0792  decode.d3.loss_dice: 1.6050  decode.d4.loss_cls: 1.0963  decode.d4.loss_mask: 1.0880  decode.d4.loss_dice: 1.6027  decode.d5.loss_cls: 1.0994  decode.d5.loss_mask: 1.0711  decode.d5.loss_dice: 1.5843  decode.d6.loss_cls: 1.1507  decode.d6.loss_mask: 1.0833  decode.d6.loss_dice: 1.5503  decode.d7.loss_cls: 1.1414  decode.d7.loss_mask: 1.0714  decode.d7.loss_dice: 1.5673  decode.d8.loss_cls: 1.1478  decode.d8.loss_mask: 1.0587  decode.d8.loss_dice: 1.5466
2023/05/24 07:48:32 - mmengine - INFO - Iter(train) [109500/160000]  lr: 3.5421e-06  eta: 6:03:27  time: 0.4318  data_time: 0.0111  memory: 4867  grad_norm: 104.4704  loss: 31.9334  decode.loss_cls: 0.9492  decode.loss_mask: 0.7596  decode.loss_dice: 1.2182  decode.d0.loss_cls: 2.9204  decode.d0.loss_mask: 0.8112  decode.d0.loss_dice: 1.3812  decode.d1.loss_cls: 1.0094  decode.d1.loss_mask: 0.8303  decode.d1.loss_dice: 1.3510  decode.d2.loss_cls: 0.9452  decode.d2.loss_mask: 0.8397  decode.d2.loss_dice: 1.2563  decode.d3.loss_cls: 0.9311  decode.d3.loss_mask: 0.8075  decode.d3.loss_dice: 1.2513  decode.d4.loss_cls: 0.8623  decode.d4.loss_mask: 0.8192  decode.d4.loss_dice: 1.2601  decode.d5.loss_cls: 0.8781  decode.d5.loss_mask: 0.8047  decode.d5.loss_dice: 1.2444  decode.d6.loss_cls: 0.8819  decode.d6.loss_mask: 0.8023  decode.d6.loss_dice: 1.2273  decode.d7.loss_cls: 0.9269  decode.d7.loss_mask: 0.8064  decode.d7.loss_dice: 1.2413  decode.d8.loss_cls: 0.9017  decode.d8.loss_mask: 0.7910  decode.d8.loss_dice: 1.2241
2023/05/24 07:48:53 - mmengine - INFO - Iter(train) [109550/160000]  lr: 3.5389e-06  eta: 6:03:05  time: 0.4174  data_time: 0.0106  memory: 4889  grad_norm: 100.1779  loss: 29.1956  decode.loss_cls: 0.9845  decode.loss_mask: 0.5618  decode.loss_dice: 1.1053  decode.d0.loss_cls: 2.8583  decode.d0.loss_mask: 0.6771  decode.d0.loss_dice: 1.2523  decode.d1.loss_cls: 1.0267  decode.d1.loss_mask: 0.6540  decode.d1.loss_dice: 1.2071  decode.d2.loss_cls: 0.9821  decode.d2.loss_mask: 0.6354  decode.d2.loss_dice: 1.1985  decode.d3.loss_cls: 0.9782  decode.d3.loss_mask: 0.6119  decode.d3.loss_dice: 1.1302  decode.d4.loss_cls: 0.9706  decode.d4.loss_mask: 0.6027  decode.d4.loss_dice: 1.1233  decode.d5.loss_cls: 0.9532  decode.d5.loss_mask: 0.6404  decode.d5.loss_dice: 1.1429  decode.d6.loss_cls: 0.9274  decode.d6.loss_mask: 0.6123  decode.d6.loss_dice: 1.1319  decode.d7.loss_cls: 0.9118  decode.d7.loss_mask: 0.5822  decode.d7.loss_dice: 1.0903  decode.d8.loss_cls: 0.9844  decode.d8.loss_mask: 0.5683  decode.d8.loss_dice: 1.0905
2023/05/24 07:49:16 - mmengine - INFO - Iter(train) [109600/160000]  lr: 3.5358e-06  eta: 6:02:44  time: 0.4258  data_time: 0.0105  memory: 4837  grad_norm: 91.7800  loss: 33.7520  decode.loss_cls: 1.0903  decode.loss_mask: 0.7078  decode.loss_dice: 1.3076  decode.d0.loss_cls: 3.1423  decode.d0.loss_mask: 0.6991  decode.d0.loss_dice: 1.4165  decode.d1.loss_cls: 1.4010  decode.d1.loss_mask: 0.7153  decode.d1.loss_dice: 1.3935  decode.d2.loss_cls: 1.2722  decode.d2.loss_mask: 0.6916  decode.d2.loss_dice: 1.3000  decode.d3.loss_cls: 1.1935  decode.d3.loss_mask: 0.6973  decode.d3.loss_dice: 1.2875  decode.d4.loss_cls: 1.1393  decode.d4.loss_mask: 0.7014  decode.d4.loss_dice: 1.2667  decode.d5.loss_cls: 1.1057  decode.d5.loss_mask: 0.7360  decode.d5.loss_dice: 1.2473  decode.d6.loss_cls: 1.1103  decode.d6.loss_mask: 0.7266  decode.d6.loss_dice: 1.2331  decode.d7.loss_cls: 1.0768  decode.d7.loss_mask: 0.7270  decode.d7.loss_dice: 1.2915  decode.d8.loss_cls: 1.1081  decode.d8.loss_mask: 0.6951  decode.d8.loss_dice: 1.2716
2023/05/24 07:49:37 - mmengine - INFO - Iter(train) [109650/160000]  lr: 3.5326e-06  eta: 6:02:22  time: 0.4281  data_time: 0.0105  memory: 4908  grad_norm: 102.9248  loss: 29.5255  decode.loss_cls: 0.9338  decode.loss_mask: 0.7570  decode.loss_dice: 1.0277  decode.d0.loss_cls: 2.7573  decode.d0.loss_mask: 0.8665  decode.d0.loss_dice: 1.2128  decode.d1.loss_cls: 1.0633  decode.d1.loss_mask: 0.8409  decode.d1.loss_dice: 1.1090  decode.d2.loss_cls: 0.9931  decode.d2.loss_mask: 0.7837  decode.d2.loss_dice: 1.0609  decode.d3.loss_cls: 0.9339  decode.d3.loss_mask: 0.7616  decode.d3.loss_dice: 1.0441  decode.d4.loss_cls: 0.9220  decode.d4.loss_mask: 0.7450  decode.d4.loss_dice: 1.0172  decode.d5.loss_cls: 0.9240  decode.d5.loss_mask: 0.7379  decode.d5.loss_dice: 1.0061  decode.d6.loss_cls: 0.9080  decode.d6.loss_mask: 0.7592  decode.d6.loss_dice: 0.9904  decode.d7.loss_cls: 0.9220  decode.d7.loss_mask: 0.7576  decode.d7.loss_dice: 1.0096  decode.d8.loss_cls: 0.9191  decode.d8.loss_mask: 0.7535  decode.d8.loss_dice: 1.0086
2023/05/24 07:49:58 - mmengine - INFO - Iter(train) [109700/160000]  lr: 3.5294e-06  eta: 6:02:00  time: 0.4229  data_time: 0.0109  memory: 4847  grad_norm: 104.7854  loss: 29.6437  decode.loss_cls: 1.0274  decode.loss_mask: 0.6339  decode.loss_dice: 1.0428  decode.d0.loss_cls: 2.8552  decode.d0.loss_mask: 0.6645  decode.d0.loss_dice: 1.2133  decode.d1.loss_cls: 1.1981  decode.d1.loss_mask: 0.6332  decode.d1.loss_dice: 1.0999  decode.d2.loss_cls: 1.1077  decode.d2.loss_mask: 0.6622  decode.d2.loss_dice: 1.0972  decode.d3.loss_cls: 1.0835  decode.d3.loss_mask: 0.6344  decode.d3.loss_dice: 1.0704  decode.d4.loss_cls: 1.0426  decode.d4.loss_mask: 0.6549  decode.d4.loss_dice: 1.0510  decode.d5.loss_cls: 1.0842  decode.d5.loss_mask: 0.6176  decode.d5.loss_dice: 1.0361  decode.d6.loss_cls: 1.0422  decode.d6.loss_mask: 0.6379  decode.d6.loss_dice: 1.0513  decode.d7.loss_cls: 1.0432  decode.d7.loss_mask: 0.6207  decode.d7.loss_dice: 1.0398  decode.d8.loss_cls: 1.0235  decode.d8.loss_mask: 0.6376  decode.d8.loss_dice: 1.0376
2023/05/24 07:50:20 - mmengine - INFO - Iter(train) [109750/160000]  lr: 3.5263e-06  eta: 6:01:39  time: 0.4673  data_time: 0.0111  memory: 4896  grad_norm: 111.6586  loss: 45.1731  decode.loss_cls: 1.3499  decode.loss_mask: 0.9421  decode.loss_dice: 1.8883  decode.d0.loss_cls: 3.4663  decode.d0.loss_mask: 0.9691  decode.d0.loss_dice: 2.2176  decode.d1.loss_cls: 1.5986  decode.d1.loss_mask: 0.9593  decode.d1.loss_dice: 1.9858  decode.d2.loss_cls: 1.5458  decode.d2.loss_mask: 0.9370  decode.d2.loss_dice: 1.9413  decode.d3.loss_cls: 1.4281  decode.d3.loss_mask: 0.9456  decode.d3.loss_dice: 1.9295  decode.d4.loss_cls: 1.4243  decode.d4.loss_mask: 0.9481  decode.d4.loss_dice: 1.9043  decode.d5.loss_cls: 1.3870  decode.d5.loss_mask: 0.9402  decode.d5.loss_dice: 1.9106  decode.d6.loss_cls: 1.3565  decode.d6.loss_mask: 0.9433  decode.d6.loss_dice: 1.8579  decode.d7.loss_cls: 1.3709  decode.d7.loss_mask: 0.9242  decode.d7.loss_dice: 1.8903  decode.d8.loss_cls: 1.3761  decode.d8.loss_mask: 0.9330  decode.d8.loss_dice: 1.9021
2023/05/24 07:50:42 - mmengine - INFO - Iter(train) [109800/160000]  lr: 3.5231e-06  eta: 6:01:17  time: 0.4080  data_time: 0.0103  memory: 4829  grad_norm: 89.8076  loss: 42.9239  decode.loss_cls: 1.2691  decode.loss_mask: 0.9815  decode.loss_dice: 1.7050  decode.d0.loss_cls: 3.2690  decode.d0.loss_mask: 1.1525  decode.d0.loss_dice: 2.0302  decode.d1.loss_cls: 1.3637  decode.d1.loss_mask: 1.0253  decode.d1.loss_dice: 1.9273  decode.d2.loss_cls: 1.3150  decode.d2.loss_mask: 1.0072  decode.d2.loss_dice: 1.8164  decode.d3.loss_cls: 1.2760  decode.d3.loss_mask: 1.0000  decode.d3.loss_dice: 1.7865  decode.d4.loss_cls: 1.2626  decode.d4.loss_mask: 1.0015  decode.d4.loss_dice: 1.8131  decode.d5.loss_cls: 1.2701  decode.d5.loss_mask: 0.9939  decode.d5.loss_dice: 1.7768  decode.d6.loss_cls: 1.2919  decode.d6.loss_mask: 0.9663  decode.d6.loss_dice: 1.7033  decode.d7.loss_cls: 1.2664  decode.d7.loss_mask: 0.9677  decode.d7.loss_dice: 1.7193  decode.d8.loss_cls: 1.2465  decode.d8.loss_mask: 0.9752  decode.d8.loss_dice: 1.7446
2023/05/24 07:51:05 - mmengine - INFO - Iter(train) [109850/160000]  lr: 3.5200e-06  eta: 6:00:56  time: 0.4790  data_time: 0.0102  memory: 4898  grad_norm: 108.8355  loss: 37.9684  decode.loss_cls: 0.9625  decode.loss_mask: 0.9301  decode.loss_dice: 1.5547  decode.d0.loss_cls: 3.2201  decode.d0.loss_mask: 0.9523  decode.d0.loss_dice: 1.8184  decode.d1.loss_cls: 1.2504  decode.d1.loss_mask: 0.9429  decode.d1.loss_dice: 1.7244  decode.d2.loss_cls: 1.0742  decode.d2.loss_mask: 0.9324  decode.d2.loss_dice: 1.5845  decode.d3.loss_cls: 1.0653  decode.d3.loss_mask: 0.9003  decode.d3.loss_dice: 1.5313  decode.d4.loss_cls: 1.1081  decode.d4.loss_mask: 0.9004  decode.d4.loss_dice: 1.5219  decode.d5.loss_cls: 1.0144  decode.d5.loss_mask: 0.9222  decode.d5.loss_dice: 1.5625  decode.d6.loss_cls: 1.0390  decode.d6.loss_mask: 0.9321  decode.d6.loss_dice: 1.5574  decode.d7.loss_cls: 1.0360  decode.d7.loss_mask: 0.9244  decode.d7.loss_dice: 1.5395  decode.d8.loss_cls: 0.9916  decode.d8.loss_mask: 0.9192  decode.d8.loss_dice: 1.5560
2023/05/24 07:51:28 - mmengine - INFO - Iter(train) [109900/160000]  lr: 3.5168e-06  eta: 6:00:35  time: 0.4800  data_time: 0.0105  memory: 4857  grad_norm: 143.7750  loss: 28.5579  decode.loss_cls: 1.0022  decode.loss_mask: 0.6784  decode.loss_dice: 0.9198  decode.d0.loss_cls: 3.0079  decode.d0.loss_mask: 0.7156  decode.d0.loss_dice: 1.1147  decode.d1.loss_cls: 1.0866  decode.d1.loss_mask: 0.7160  decode.d1.loss_dice: 0.9680  decode.d2.loss_cls: 1.0350  decode.d2.loss_mask: 0.6849  decode.d2.loss_dice: 0.9596  decode.d3.loss_cls: 0.9913  decode.d3.loss_mask: 0.7039  decode.d3.loss_dice: 0.9373  decode.d4.loss_cls: 0.9974  decode.d4.loss_mask: 0.6970  decode.d4.loss_dice: 0.9260  decode.d5.loss_cls: 0.9982  decode.d5.loss_mask: 0.6860  decode.d5.loss_dice: 0.9181  decode.d6.loss_cls: 1.0224  decode.d6.loss_mask: 0.6733  decode.d6.loss_dice: 0.9266  decode.d7.loss_cls: 1.0163  decode.d7.loss_mask: 0.6686  decode.d7.loss_dice: 0.9162  decode.d8.loss_cls: 1.0062  decode.d8.loss_mask: 0.6686  decode.d8.loss_dice: 0.9157
2023/05/24 07:51:49 - mmengine - INFO - Iter(train) [109950/160000]  lr: 3.5136e-06  eta: 6:00:13  time: 0.4345  data_time: 0.0106  memory: 4877  grad_norm: 97.2227  loss: 31.8834  decode.loss_cls: 1.1553  decode.loss_mask: 0.6822  decode.loss_dice: 1.0642  decode.d0.loss_cls: 3.0938  decode.d0.loss_mask: 0.7332  decode.d0.loss_dice: 1.2789  decode.d1.loss_cls: 1.2756  decode.d1.loss_mask: 0.7455  decode.d1.loss_dice: 1.1866  decode.d2.loss_cls: 1.2407  decode.d2.loss_mask: 0.7081  decode.d2.loss_dice: 1.1114  decode.d3.loss_cls: 1.1652  decode.d3.loss_mask: 0.6851  decode.d3.loss_dice: 1.1077  decode.d4.loss_cls: 1.1510  decode.d4.loss_mask: 0.6918  decode.d4.loss_dice: 1.1086  decode.d5.loss_cls: 1.1247  decode.d5.loss_mask: 0.6861  decode.d5.loss_dice: 1.1123  decode.d6.loss_cls: 1.1604  decode.d6.loss_mask: 0.6827  decode.d6.loss_dice: 1.0850  decode.d7.loss_cls: 1.1605  decode.d7.loss_mask: 0.6855  decode.d7.loss_dice: 1.0786  decode.d8.loss_cls: 1.1673  decode.d8.loss_mask: 0.6806  decode.d8.loss_dice: 1.0751
2023/05/24 07:52:11 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 07:52:11 - mmengine - INFO - Iter(train) [110000/160000]  lr: 3.5105e-06  eta: 5:59:52  time: 0.4270  data_time: 0.0106  memory: 4874  grad_norm: 124.3978  loss: 44.8068  decode.loss_cls: 1.6323  decode.loss_mask: 0.8907  decode.loss_dice: 1.6876  decode.d0.loss_cls: 3.7136  decode.d0.loss_mask: 0.9003  decode.d0.loss_dice: 2.0325  decode.d1.loss_cls: 1.7070  decode.d1.loss_mask: 0.9403  decode.d1.loss_dice: 1.8864  decode.d2.loss_cls: 1.6890  decode.d2.loss_mask: 0.8608  decode.d2.loss_dice: 1.7222  decode.d3.loss_cls: 1.6549  decode.d3.loss_mask: 0.8690  decode.d3.loss_dice: 1.6813  decode.d4.loss_cls: 1.6048  decode.d4.loss_mask: 0.8537  decode.d4.loss_dice: 1.6922  decode.d5.loss_cls: 1.6246  decode.d5.loss_mask: 0.8512  decode.d5.loss_dice: 1.6880  decode.d6.loss_cls: 1.7002  decode.d6.loss_mask: 0.8967  decode.d6.loss_dice: 1.6637  decode.d7.loss_cls: 1.6323  decode.d7.loss_mask: 0.8934  decode.d7.loss_dice: 1.6698  decode.d8.loss_cls: 1.6122  decode.d8.loss_mask: 0.8708  decode.d8.loss_dice: 1.6851
2023/05/24 07:52:11 - mmengine - INFO - Saving checkpoint at 110000 iterations
2023/05/24 07:52:21 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:49  time: 0.0862  data_time: 0.0019  memory: 2167  
2023/05/24 07:52:25 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:45  time: 0.0795  data_time: 0.0018  memory: 2216  
2023/05/24 07:52:29 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:40  time: 0.0799  data_time: 0.0018  memory: 2167  
2023/05/24 07:52:33 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0797  data_time: 0.0019  memory: 2104  
2023/05/24 07:52:37 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0900  data_time: 0.0020  memory: 2831  
2023/05/24 07:52:44 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0838  data_time: 0.0018  memory: 2167  
2023/05/24 07:52:48 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0814  data_time: 0.0019  memory: 2167  
2023/05/24 07:52:52 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0810  data_time: 0.0018  memory: 2167  
2023/05/24 07:52:56 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0818  data_time: 0.0019  memory: 2944  
2023/05/24 07:53:01 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0793  data_time: 0.0019  memory: 2356  
2023/05/24 07:53:05 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0775  data_time: 0.0017  memory: 2217  
2023/05/24 07:53:09 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0795  data_time: 0.0017  memory: 2328  
2023/05/24 07:53:12 - mmengine - INFO - per class results:
2023/05/24 07:53:12 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.25 | 92.94 |
|     bicycle      |  70.7 | 82.41 |
|       car        | 62.72 | 85.42 |
|    motorcycle    | 81.49 |  89.2 |
|     airplane     |  81.7 | 89.04 |
|       bus        | 81.15 | 88.01 |
|      train       | 85.81 | 92.82 |
|      truck       | 54.04 | 68.66 |
|       boat       | 60.14 | 81.31 |
|  traffic light   | 68.32 | 79.37 |
|   fire hydrant   | 88.51 | 94.48 |
|    stop sign     | 92.38 | 96.03 |
|  parking meter   | 71.35 |  79.6 |
|      bench       | 49.74 |  70.0 |
|       bird       |  81.1 | 90.31 |
|       cat        | 85.71 |  92.5 |
|       dog        | 80.66 | 88.32 |
|      horse       | 78.33 | 90.11 |
|      sheep       | 85.17 | 91.26 |
|       cow        | 80.88 | 88.76 |
|     elephant     | 89.27 | 94.63 |
|       bear       | 92.34 | 94.86 |
|      zebra       | 89.98 | 93.41 |
|     giraffe      | 87.29 | 92.91 |
|     backpack     | 34.47 | 57.01 |
|     umbrella     | 76.85 | 89.18 |
|     handbag      | 30.22 | 58.24 |
|       tie        | 14.16 |  19.8 |
|     suitcase     | 74.18 | 90.73 |
|     frisbee      | 62.94 | 91.82 |
|       skis       | 42.27 | 55.61 |
|    snowboard     |  50.0 | 66.63 |
|   sports ball    | 57.72 | 71.28 |
|       kite       | 52.84 | 62.23 |
|   baseball bat   | 54.45 |  67.0 |
|  baseball glove  | 68.53 | 86.65 |
|    skateboard    |  58.1 | 64.46 |
|    surfboard     |  69.2 | 87.27 |
|  tennis racket   | 85.86 | 92.64 |
|      bottle      | 41.25 |  52.1 |
|    wine glass    | 58.12 | 78.07 |
|       cup        | 50.69 | 74.33 |
|       fork       | 26.46 | 32.59 |
|      knife       |  25.7 | 34.77 |
|      spoon       | 36.23 | 56.86 |
|       bowl       | 49.33 | 67.93 |
|      banana      | 67.76 | 86.71 |
|      apple       | 52.64 | 68.86 |
|     sandwich     | 42.26 | 53.13 |
|      orange      |  65.1 |  71.3 |
|     broccoli     | 47.93 | 54.55 |
|      carrot      | 43.98 | 46.98 |
|     hot dog      | 46.35 | 52.23 |
|      pizza       | 67.11 | 80.54 |
|      donut       | 61.53 | 71.39 |
|       cake       | 57.85 | 68.97 |
|      chair       | 45.95 |  65.8 |
|      couch       |  56.5 | 76.25 |
|   potted plant   | 30.97 | 42.13 |
|       bed        | 62.86 | 77.43 |
|   dining table   | 42.04 | 83.66 |
|      toilet      | 82.04 | 91.22 |
|        tv        | 73.45 | 85.13 |
|      laptop      | 73.43 | 90.74 |
|      mouse       | 75.49 | 88.21 |
|      remote      | 62.88 | 72.36 |
|     keyboard     | 60.86 |  70.5 |
|    cell phone    | 63.93 | 79.18 |
|    microwave     | 65.48 | 75.81 |
|       oven       | 58.63 |  74.6 |
|     toaster      | 23.25 |  28.8 |
|       sink       |  61.2 | 78.98 |
|   refrigerator   | 76.62 |  92.3 |
|       book       | 47.23 |  70.2 |
|      clock       | 71.57 | 76.74 |
|       vase       | 58.94 | 82.39 |
|     scissors     | 70.01 | 77.88 |
|    teddy bear    | 74.01 | 84.53 |
|    hair drier    |  41.7 | 46.72 |
|    toothbrush    | 36.65 | 70.19 |
|      banner      | 32.48 |  63.9 |
|     blanket      |  7.26 |  9.85 |
|      branch      | 15.38 | 19.23 |
|      bridge      | 31.66 |  48.1 |
|  building-other  | 53.88 | 76.22 |
|       bush       | 26.09 | 31.81 |
|     cabinet      |  53.9 | 72.25 |
|       cage       | 19.49 | 32.79 |
|    cardboard     | 44.08 | 53.48 |
|      carpet      | 52.66 | 62.62 |
|  ceiling-other   | 62.41 | 83.64 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 20.52 | 28.46 |
|      clouds      | 44.17 | 54.91 |
|     counter      | 26.11 | 49.56 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 64.33 | 79.49 |
|    desk-stuff    | 46.57 | 61.29 |
|       dirt       | 38.59 | 56.85 |
|    door-stuff    | 40.31 | 62.18 |
|      fence       | 28.74 | 48.17 |
|   floor-marble   |  3.69 |  4.32 |
|   floor-other    | 21.51 | 30.65 |
|   floor-stone    |  4.68 |  5.67 |
|    floor-tile    | 59.84 | 72.17 |
|    floor-wood    | 59.42 | 73.73 |
|      flower      | 43.75 | 68.24 |
|       fog        |  5.75 |  6.45 |
|    food-other    | 25.09 | 29.83 |
|      fruit       | 37.42 | 56.42 |
| furniture-other  | 17.11 | 25.32 |
|      grass       |  69.0 | 85.89 |
|      gravel      | 27.56 | 42.47 |
|   ground-other   |  0.41 |  0.47 |
|       hill       | 21.07 | 30.46 |
|      house       | 20.13 | 22.11 |
|      leaves      | 24.69 | 32.92 |
|      light       | 38.12 | 53.49 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.79 |  50.5 |
|   mirror-stuff   | 46.53 | 67.93 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 52.61 | 71.15 |
|       mud        |  3.85 |  8.0  |
|      napkin      |  7.33 |  7.4  |
|       net        | 39.31 | 62.46 |
|      paper       | 23.84 | 29.08 |
|     pavement     | 52.14 | 72.89 |
|      pillow      |  14.7 | 18.87 |
|   plant-other    | 19.26 | 32.36 |
|     plastic      | 23.43 | 33.04 |
|     platform     | 30.88 | 48.43 |
|   playingfield   | 67.26 | 84.48 |
|     railing      |  5.02 |  9.28 |
|     railroad     | 60.44 | 75.67 |
|      river       | 47.51 | 60.45 |
|       road       | 65.55 | 79.17 |
|       rock       |  46.0 | 72.79 |
|       roof       | 11.86 | 14.61 |
|       rug        | 37.39 | 63.89 |
|      salad       |  0.01 |  0.01 |
|       sand       |  61.2 | 71.48 |
|       sea        |  85.6 | 90.66 |
|      shelf       | 34.38 | 52.46 |
|    sky-other     | 70.42 | 88.62 |
|    skyscraper    | 33.23 | 39.85 |
|       snow       | 88.56 | 92.87 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      |  23.8 | 37.58 |
|      stone       | 10.02 | 13.53 |
|      straw       |  24.6 |  29.3 |
| structural-other |  0.0  |  0.0  |
|      table       | 11.07 | 13.15 |
|       tent       |  9.01 | 14.32 |
|  textile-other   |  9.47 | 14.47 |
|      towel       | 32.09 | 45.37 |
|       tree       | 72.62 | 88.24 |
|    vegetable     | 35.71 | 47.71 |
|    wall-brick    | 50.01 | 62.97 |
|  wall-concrete   | 60.67 | 79.95 |
|    wall-other    | 18.15 | 27.94 |
|    wall-panel    |  2.5  |  2.76 |
|    wall-stone    | 34.08 | 41.58 |
|    wall-tile     | 66.64 | 80.89 |
|    wall-wood     | 41.01 |  56.9 |
|   water-other    | 25.95 | 46.56 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 52.02 | 60.34 |
|   window-other   | 45.98 | 73.56 |
|       wood       | 25.33 |  40.0 |
+------------------+-------+-------+
2023/05/24 07:53:12 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.8200  mIoU: 46.0300  mAcc: 57.9600  data_time: 0.0020  time: 0.0864
2023/05/24 07:53:34 - mmengine - INFO - Iter(train) [110050/160000]  lr: 3.5073e-06  eta: 5:59:31  time: 0.4241  data_time: 0.0106  memory: 4855  grad_norm: 99.7814  loss: 32.8496  decode.loss_cls: 0.9052  decode.loss_mask: 0.7695  decode.loss_dice: 1.3228  decode.d0.loss_cls: 2.9592  decode.d0.loss_mask: 0.7775  decode.d0.loss_dice: 1.4946  decode.d1.loss_cls: 1.1377  decode.d1.loss_mask: 0.7845  decode.d1.loss_dice: 1.2994  decode.d2.loss_cls: 1.0523  decode.d2.loss_mask: 0.7767  decode.d2.loss_dice: 1.3636  decode.d3.loss_cls: 0.9947  decode.d3.loss_mask: 0.7673  decode.d3.loss_dice: 1.3477  decode.d4.loss_cls: 1.0029  decode.d4.loss_mask: 0.7612  decode.d4.loss_dice: 1.3311  decode.d5.loss_cls: 0.9680  decode.d5.loss_mask: 0.7467  decode.d5.loss_dice: 1.2777  decode.d6.loss_cls: 0.9566  decode.d6.loss_mask: 0.7701  decode.d6.loss_dice: 1.3303  decode.d7.loss_cls: 0.8869  decode.d7.loss_mask: 0.7540  decode.d7.loss_dice: 1.3268  decode.d8.loss_cls: 0.9635  decode.d8.loss_mask: 0.7306  decode.d8.loss_dice: 1.2904
2023/05/24 07:53:55 - mmengine - INFO - Iter(train) [110100/160000]  lr: 3.5042e-06  eta: 5:59:09  time: 0.4262  data_time: 0.0104  memory: 4890  grad_norm: 107.2815  loss: 32.5544  decode.loss_cls: 0.9603  decode.loss_mask: 0.6143  decode.loss_dice: 1.3749  decode.d0.loss_cls: 2.9656  decode.d0.loss_mask: 0.6779  decode.d0.loss_dice: 1.5698  decode.d1.loss_cls: 0.9536  decode.d1.loss_mask: 0.6963  decode.d1.loss_dice: 1.5639  decode.d2.loss_cls: 0.9299  decode.d2.loss_mask: 0.6778  decode.d2.loss_dice: 1.4935  decode.d3.loss_cls: 0.9373  decode.d3.loss_mask: 0.6545  decode.d3.loss_dice: 1.4348  decode.d4.loss_cls: 0.9037  decode.d4.loss_mask: 0.6502  decode.d4.loss_dice: 1.4783  decode.d5.loss_cls: 0.9759  decode.d5.loss_mask: 0.6222  decode.d5.loss_dice: 1.3902  decode.d6.loss_cls: 0.8992  decode.d6.loss_mask: 0.6489  decode.d6.loss_dice: 1.4373  decode.d7.loss_cls: 0.9504  decode.d7.loss_mask: 0.6399  decode.d7.loss_dice: 1.3989  decode.d8.loss_cls: 1.0217  decode.d8.loss_mask: 0.6188  decode.d8.loss_dice: 1.4142
2023/05/24 07:54:17 - mmengine - INFO - Iter(train) [110150/160000]  lr: 3.5010e-06  eta: 5:58:48  time: 0.4249  data_time: 0.0104  memory: 4857  grad_norm: 113.5245  loss: 34.7810  decode.loss_cls: 1.2293  decode.loss_mask: 0.7429  decode.loss_dice: 1.2637  decode.d0.loss_cls: 3.1594  decode.d0.loss_mask: 0.7681  decode.d0.loss_dice: 1.4500  decode.d1.loss_cls: 1.3536  decode.d1.loss_mask: 0.7647  decode.d1.loss_dice: 1.3057  decode.d2.loss_cls: 1.2315  decode.d2.loss_mask: 0.7882  decode.d2.loss_dice: 1.2717  decode.d3.loss_cls: 1.2661  decode.d3.loss_mask: 0.7500  decode.d3.loss_dice: 1.2959  decode.d4.loss_cls: 1.2195  decode.d4.loss_mask: 0.7810  decode.d4.loss_dice: 1.2904  decode.d5.loss_cls: 1.1947  decode.d5.loss_mask: 0.7826  decode.d5.loss_dice: 1.2443  decode.d6.loss_cls: 1.2061  decode.d6.loss_mask: 0.7569  decode.d6.loss_dice: 1.2303  decode.d7.loss_cls: 1.1815  decode.d7.loss_mask: 0.7566  decode.d7.loss_dice: 1.2554  decode.d8.loss_cls: 1.2026  decode.d8.loss_mask: 0.7896  decode.d8.loss_dice: 1.2487
2023/05/24 07:54:38 - mmengine - INFO - Iter(train) [110200/160000]  lr: 3.4978e-06  eta: 5:58:26  time: 0.4270  data_time: 0.0106  memory: 4897  grad_norm: 94.6926  loss: 24.6141  decode.loss_cls: 0.8957  decode.loss_mask: 0.4500  decode.loss_dice: 0.8112  decode.d0.loss_cls: 2.8288  decode.d0.loss_mask: 0.5657  decode.d0.loss_dice: 1.1108  decode.d1.loss_cls: 1.0474  decode.d1.loss_mask: 0.5008  decode.d1.loss_dice: 0.9375  decode.d2.loss_cls: 0.9734  decode.d2.loss_mask: 0.4721  decode.d2.loss_dice: 0.8772  decode.d3.loss_cls: 0.9361  decode.d3.loss_mask: 0.4580  decode.d3.loss_dice: 0.8439  decode.d4.loss_cls: 0.8854  decode.d4.loss_mask: 0.4611  decode.d4.loss_dice: 0.8207  decode.d5.loss_cls: 0.9032  decode.d5.loss_mask: 0.4601  decode.d5.loss_dice: 0.8309  decode.d6.loss_cls: 0.9382  decode.d6.loss_mask: 0.4357  decode.d6.loss_dice: 0.8142  decode.d7.loss_cls: 0.9180  decode.d7.loss_mask: 0.4488  decode.d7.loss_dice: 0.8172  decode.d8.loss_cls: 0.9167  decode.d8.loss_mask: 0.4459  decode.d8.loss_dice: 0.8094
2023/05/24 07:55:01 - mmengine - INFO - Iter(train) [110250/160000]  lr: 3.4947e-06  eta: 5:58:05  time: 0.4767  data_time: 0.0105  memory: 4845  grad_norm: 85.2519  loss: 39.2084  decode.loss_cls: 1.0180  decode.loss_mask: 1.0520  decode.loss_dice: 1.5108  decode.d0.loss_cls: 3.2158  decode.d0.loss_mask: 1.1179  decode.d0.loss_dice: 1.6894  decode.d1.loss_cls: 1.1658  decode.d1.loss_mask: 1.0759  decode.d1.loss_dice: 1.6120  decode.d2.loss_cls: 1.1350  decode.d2.loss_mask: 1.0446  decode.d2.loss_dice: 1.5745  decode.d3.loss_cls: 1.1524  decode.d3.loss_mask: 1.0411  decode.d3.loss_dice: 1.5488  decode.d4.loss_cls: 1.1402  decode.d4.loss_mask: 1.0493  decode.d4.loss_dice: 1.5390  decode.d5.loss_cls: 1.0690  decode.d5.loss_mask: 1.0534  decode.d5.loss_dice: 1.5444  decode.d6.loss_cls: 1.0324  decode.d6.loss_mask: 1.0784  decode.d6.loss_dice: 1.5176  decode.d7.loss_cls: 1.0976  decode.d7.loss_mask: 1.0437  decode.d7.loss_dice: 1.5045  decode.d8.loss_cls: 1.0274  decode.d8.loss_mask: 1.0537  decode.d8.loss_dice: 1.5036
2023/05/24 07:55:24 - mmengine - INFO - Iter(train) [110300/160000]  lr: 3.4915e-06  eta: 5:57:44  time: 0.4221  data_time: 0.0107  memory: 4847  grad_norm: 100.3812  loss: 28.7594  decode.loss_cls: 0.9357  decode.loss_mask: 0.5840  decode.loss_dice: 1.0195  decode.d0.loss_cls: 3.0366  decode.d0.loss_mask: 0.6821  decode.d0.loss_dice: 1.2056  decode.d1.loss_cls: 1.1113  decode.d1.loss_mask: 0.6598  decode.d1.loss_dice: 1.1417  decode.d2.loss_cls: 1.0057  decode.d2.loss_mask: 0.6562  decode.d2.loss_dice: 1.1154  decode.d3.loss_cls: 1.0049  decode.d3.loss_mask: 0.5966  decode.d3.loss_dice: 1.0584  decode.d4.loss_cls: 0.9400  decode.d4.loss_mask: 0.6088  decode.d4.loss_dice: 1.0706  decode.d5.loss_cls: 0.9186  decode.d5.loss_mask: 0.6103  decode.d5.loss_dice: 1.0635  decode.d6.loss_cls: 0.9851  decode.d6.loss_mask: 0.6002  decode.d6.loss_dice: 1.0269  decode.d7.loss_cls: 0.9344  decode.d7.loss_mask: 0.6059  decode.d7.loss_dice: 1.0194  decode.d8.loss_cls: 0.9397  decode.d8.loss_mask: 0.6001  decode.d8.loss_dice: 1.0223
2023/05/24 07:55:45 - mmengine - INFO - Iter(train) [110350/160000]  lr: 3.4884e-06  eta: 5:57:22  time: 0.4232  data_time: 0.0105  memory: 4866  grad_norm: 95.2332  loss: 36.2389  decode.loss_cls: 1.2409  decode.loss_mask: 0.8448  decode.loss_dice: 1.2771  decode.d0.loss_cls: 3.1164  decode.d0.loss_mask: 0.8810  decode.d0.loss_dice: 1.4303  decode.d1.loss_cls: 1.3864  decode.d1.loss_mask: 0.8779  decode.d1.loss_dice: 1.3429  decode.d2.loss_cls: 1.3212  decode.d2.loss_mask: 0.8347  decode.d2.loss_dice: 1.3309  decode.d3.loss_cls: 1.2880  decode.d3.loss_mask: 0.8189  decode.d3.loss_dice: 1.3130  decode.d4.loss_cls: 1.2973  decode.d4.loss_mask: 0.8163  decode.d4.loss_dice: 1.2961  decode.d5.loss_cls: 1.2877  decode.d5.loss_mask: 0.8279  decode.d5.loss_dice: 1.2773  decode.d6.loss_cls: 1.3071  decode.d6.loss_mask: 0.8116  decode.d6.loss_dice: 1.2385  decode.d7.loss_cls: 1.3247  decode.d7.loss_mask: 0.8331  decode.d7.loss_dice: 1.2636  decode.d8.loss_cls: 1.2627  decode.d8.loss_mask: 0.8227  decode.d8.loss_dice: 1.2676
2023/05/24 07:56:07 - mmengine - INFO - Iter(train) [110400/160000]  lr: 3.4852e-06  eta: 5:57:01  time: 0.4259  data_time: 0.0105  memory: 4858  grad_norm: 88.8571  loss: 35.8694  decode.loss_cls: 1.4243  decode.loss_mask: 0.6950  decode.loss_dice: 1.2028  decode.d0.loss_cls: 3.3445  decode.d0.loss_mask: 0.7830  decode.d0.loss_dice: 1.5161  decode.d1.loss_cls: 1.4428  decode.d1.loss_mask: 0.7696  decode.d1.loss_dice: 1.3444  decode.d2.loss_cls: 1.4492  decode.d2.loss_mask: 0.7203  decode.d2.loss_dice: 1.2635  decode.d3.loss_cls: 1.4202  decode.d3.loss_mask: 0.6969  decode.d3.loss_dice: 1.2264  decode.d4.loss_cls: 1.4086  decode.d4.loss_mask: 0.6964  decode.d4.loss_dice: 1.2357  decode.d5.loss_cls: 1.3874  decode.d5.loss_mask: 0.7267  decode.d5.loss_dice: 1.2473  decode.d6.loss_cls: 1.3827  decode.d6.loss_mask: 0.6977  decode.d6.loss_dice: 1.1908  decode.d7.loss_cls: 1.3616  decode.d7.loss_mask: 0.7352  decode.d7.loss_dice: 1.1910  decode.d8.loss_cls: 1.3673  decode.d8.loss_mask: 0.7382  decode.d8.loss_dice: 1.2037
2023/05/24 07:56:28 - mmengine - INFO - Iter(train) [110450/160000]  lr: 3.4820e-06  eta: 5:56:39  time: 0.4333  data_time: 0.0106  memory: 4889  grad_norm: 90.7730  loss: 42.1201  decode.loss_cls: 1.3853  decode.loss_mask: 0.9273  decode.loss_dice: 1.5833  decode.d0.loss_cls: 3.3182  decode.d0.loss_mask: 1.0313  decode.d0.loss_dice: 1.8410  decode.d1.loss_cls: 1.5172  decode.d1.loss_mask: 1.0075  decode.d1.loss_dice: 1.7280  decode.d2.loss_cls: 1.4897  decode.d2.loss_mask: 0.8826  decode.d2.loss_dice: 1.6112  decode.d3.loss_cls: 1.4776  decode.d3.loss_mask: 0.9408  decode.d3.loss_dice: 1.6185  decode.d4.loss_cls: 1.3992  decode.d4.loss_mask: 0.9243  decode.d4.loss_dice: 1.6169  decode.d5.loss_cls: 1.3951  decode.d5.loss_mask: 0.9708  decode.d5.loss_dice: 1.5704  decode.d6.loss_cls: 1.4325  decode.d6.loss_mask: 0.9835  decode.d6.loss_dice: 1.5727  decode.d7.loss_cls: 1.4078  decode.d7.loss_mask: 0.9775  decode.d7.loss_dice: 1.5738  decode.d8.loss_cls: 1.3724  decode.d8.loss_mask: 0.9711  decode.d8.loss_dice: 1.5925
2023/05/24 07:56:49 - mmengine - INFO - Iter(train) [110500/160000]  lr: 3.4789e-06  eta: 5:56:17  time: 0.4155  data_time: 0.0102  memory: 4859  grad_norm: 96.0405  loss: 31.2925  decode.loss_cls: 1.1194  decode.loss_mask: 0.5460  decode.loss_dice: 1.1286  decode.d0.loss_cls: 3.1107  decode.d0.loss_mask: 0.5888  decode.d0.loss_dice: 1.3803  decode.d1.loss_cls: 1.2690  decode.d1.loss_mask: 0.5946  decode.d1.loss_dice: 1.3059  decode.d2.loss_cls: 1.1899  decode.d2.loss_mask: 0.5653  decode.d2.loss_dice: 1.2421  decode.d3.loss_cls: 1.1389  decode.d3.loss_mask: 0.5586  decode.d3.loss_dice: 1.1946  decode.d4.loss_cls: 1.1329  decode.d4.loss_mask: 0.5435  decode.d4.loss_dice: 1.1837  decode.d5.loss_cls: 1.1023  decode.d5.loss_mask: 0.5415  decode.d5.loss_dice: 1.2016  decode.d6.loss_cls: 1.1353  decode.d6.loss_mask: 0.5674  decode.d6.loss_dice: 1.1814  decode.d7.loss_cls: 1.1289  decode.d7.loss_mask: 0.5733  decode.d7.loss_dice: 1.1594  decode.d8.loss_cls: 1.1627  decode.d8.loss_mask: 0.5574  decode.d8.loss_dice: 1.1886
2023/05/24 07:57:11 - mmengine - INFO - Iter(train) [110550/160000]  lr: 3.4757e-06  eta: 5:55:56  time: 0.4814  data_time: 0.0104  memory: 4845  grad_norm: 99.8573  loss: 36.7356  decode.loss_cls: 1.1443  decode.loss_mask: 0.8225  decode.loss_dice: 1.3735  decode.d0.loss_cls: 3.5670  decode.d0.loss_mask: 0.8567  decode.d0.loss_dice: 1.5924  decode.d1.loss_cls: 1.2415  decode.d1.loss_mask: 0.8478  decode.d1.loss_dice: 1.5356  decode.d2.loss_cls: 1.1691  decode.d2.loss_mask: 0.7994  decode.d2.loss_dice: 1.4330  decode.d3.loss_cls: 1.1974  decode.d3.loss_mask: 0.8221  decode.d3.loss_dice: 1.3802  decode.d4.loss_cls: 1.2022  decode.d4.loss_mask: 0.8202  decode.d4.loss_dice: 1.4027  decode.d5.loss_cls: 1.1832  decode.d5.loss_mask: 0.8245  decode.d5.loss_dice: 1.3918  decode.d6.loss_cls: 1.1864  decode.d6.loss_mask: 0.8145  decode.d6.loss_dice: 1.3949  decode.d7.loss_cls: 1.1839  decode.d7.loss_mask: 0.8057  decode.d7.loss_dice: 1.3706  decode.d8.loss_cls: 1.1593  decode.d8.loss_mask: 0.8207  decode.d8.loss_dice: 1.3923
2023/05/24 07:57:34 - mmengine - INFO - Iter(train) [110600/160000]  lr: 3.4726e-06  eta: 5:55:35  time: 0.4790  data_time: 0.0105  memory: 4866  grad_norm: 117.7111  loss: 29.8634  decode.loss_cls: 0.9296  decode.loss_mask: 0.6993  decode.loss_dice: 1.0506  decode.d0.loss_cls: 2.7436  decode.d0.loss_mask: 0.7645  decode.d0.loss_dice: 1.3225  decode.d1.loss_cls: 1.1443  decode.d1.loss_mask: 0.7300  decode.d1.loss_dice: 1.2148  decode.d2.loss_cls: 1.0659  decode.d2.loss_mask: 0.7105  decode.d2.loss_dice: 1.1543  decode.d3.loss_cls: 0.9831  decode.d3.loss_mask: 0.7044  decode.d3.loss_dice: 1.1234  decode.d4.loss_cls: 0.8746  decode.d4.loss_mask: 0.7240  decode.d4.loss_dice: 1.1286  decode.d5.loss_cls: 0.8948  decode.d5.loss_mask: 0.7131  decode.d5.loss_dice: 1.0863  decode.d6.loss_cls: 0.9393  decode.d6.loss_mask: 0.7005  decode.d6.loss_dice: 1.0550  decode.d7.loss_cls: 0.8882  decode.d7.loss_mask: 0.7028  decode.d7.loss_dice: 1.0939  decode.d8.loss_cls: 0.9265  decode.d8.loss_mask: 0.7119  decode.d8.loss_dice: 1.0830
2023/05/24 07:57:56 - mmengine - INFO - Iter(train) [110650/160000]  lr: 3.4694e-06  eta: 5:55:13  time: 0.4332  data_time: 0.0108  memory: 4951  grad_norm: 123.9816  loss: 49.3040  decode.loss_cls: 1.8054  decode.loss_mask: 0.7932  decode.loss_dice: 1.9697  decode.d0.loss_cls: 3.9694  decode.d0.loss_mask: 0.9058  decode.d0.loss_dice: 2.3343  decode.d1.loss_cls: 1.9798  decode.d1.loss_mask: 0.8437  decode.d1.loss_dice: 2.1210  decode.d2.loss_cls: 1.8994  decode.d2.loss_mask: 0.8282  decode.d2.loss_dice: 2.0180  decode.d3.loss_cls: 1.9078  decode.d3.loss_mask: 0.8056  decode.d3.loss_dice: 1.9818  decode.d4.loss_cls: 1.9338  decode.d4.loss_mask: 0.8086  decode.d4.loss_dice: 1.9882  decode.d5.loss_cls: 1.8757  decode.d5.loss_mask: 0.7997  decode.d5.loss_dice: 1.9436  decode.d6.loss_cls: 1.8424  decode.d6.loss_mask: 0.8305  decode.d6.loss_dice: 1.9623  decode.d7.loss_cls: 1.7904  decode.d7.loss_mask: 0.8118  decode.d7.loss_dice: 1.9755  decode.d8.loss_cls: 1.7934  decode.d8.loss_mask: 0.8006  decode.d8.loss_dice: 1.9844
2023/05/24 07:58:17 - mmengine - INFO - Iter(train) [110700/160000]  lr: 3.4662e-06  eta: 5:54:51  time: 0.4200  data_time: 0.0107  memory: 4814  grad_norm: 94.7976  loss: 22.6531  decode.loss_cls: 0.7556  decode.loss_mask: 0.5869  decode.loss_dice: 0.6691  decode.d0.loss_cls: 2.7106  decode.d0.loss_mask: 0.6060  decode.d0.loss_dice: 0.6633  decode.d1.loss_cls: 0.9328  decode.d1.loss_mask: 0.6392  decode.d1.loss_dice: 0.7186  decode.d2.loss_cls: 0.8969  decode.d2.loss_mask: 0.6075  decode.d2.loss_dice: 0.6666  decode.d3.loss_cls: 0.7859  decode.d3.loss_mask: 0.6029  decode.d3.loss_dice: 0.6612  decode.d4.loss_cls: 0.8197  decode.d4.loss_mask: 0.6156  decode.d4.loss_dice: 0.6833  decode.d5.loss_cls: 0.7580  decode.d5.loss_mask: 0.5969  decode.d5.loss_dice: 0.6336  decode.d6.loss_cls: 0.8436  decode.d6.loss_mask: 0.5832  decode.d6.loss_dice: 0.6299  decode.d7.loss_cls: 0.7515  decode.d7.loss_mask: 0.5912  decode.d7.loss_dice: 0.6596  decode.d8.loss_cls: 0.7477  decode.d8.loss_mask: 0.5947  decode.d8.loss_dice: 0.6416
2023/05/24 07:58:38 - mmengine - INFO - Iter(train) [110750/160000]  lr: 3.4631e-06  eta: 5:54:30  time: 0.4217  data_time: 0.0103  memory: 4968  grad_norm: 95.6812  loss: 32.1957  decode.loss_cls: 1.0010  decode.loss_mask: 0.7934  decode.loss_dice: 1.0937  decode.d0.loss_cls: 3.1547  decode.d0.loss_mask: 0.9434  decode.d0.loss_dice: 1.3098  decode.d1.loss_cls: 1.1704  decode.d1.loss_mask: 0.8097  decode.d1.loss_dice: 1.1684  decode.d2.loss_cls: 1.0329  decode.d2.loss_mask: 0.8615  decode.d2.loss_dice: 1.2194  decode.d3.loss_cls: 1.0841  decode.d3.loss_mask: 0.7898  decode.d3.loss_dice: 1.1411  decode.d4.loss_cls: 1.0238  decode.d4.loss_mask: 0.7772  decode.d4.loss_dice: 1.1266  decode.d5.loss_cls: 0.9997  decode.d5.loss_mask: 0.7895  decode.d5.loss_dice: 1.1439  decode.d6.loss_cls: 1.0263  decode.d6.loss_mask: 0.8030  decode.d6.loss_dice: 1.1317  decode.d7.loss_cls: 1.0108  decode.d7.loss_mask: 0.8070  decode.d7.loss_dice: 1.1084  decode.d8.loss_cls: 0.9989  decode.d8.loss_mask: 0.7942  decode.d8.loss_dice: 1.0815
2023/05/24 07:59:00 - mmengine - INFO - Iter(train) [110800/160000]  lr: 3.4599e-06  eta: 5:54:08  time: 0.4215  data_time: 0.0106  memory: 4865  grad_norm: 109.4602  loss: 35.7319  decode.loss_cls: 1.3519  decode.loss_mask: 0.7792  decode.loss_dice: 1.1780  decode.d0.loss_cls: 3.2096  decode.d0.loss_mask: 0.8794  decode.d0.loss_dice: 1.3984  decode.d1.loss_cls: 1.4731  decode.d1.loss_mask: 0.9134  decode.d1.loss_dice: 1.3573  decode.d2.loss_cls: 1.3597  decode.d2.loss_mask: 0.8461  decode.d2.loss_dice: 1.2553  decode.d3.loss_cls: 1.3471  decode.d3.loss_mask: 0.8077  decode.d3.loss_dice: 1.1781  decode.d4.loss_cls: 1.3715  decode.d4.loss_mask: 0.7788  decode.d4.loss_dice: 1.1635  decode.d5.loss_cls: 1.2277  decode.d5.loss_mask: 0.8052  decode.d5.loss_dice: 1.2003  decode.d6.loss_cls: 1.2544  decode.d6.loss_mask: 0.7980  decode.d6.loss_dice: 1.1982  decode.d7.loss_cls: 1.2934  decode.d7.loss_mask: 0.8003  decode.d7.loss_dice: 1.1947  decode.d8.loss_cls: 1.3221  decode.d8.loss_mask: 0.7977  decode.d8.loss_dice: 1.1918
2023/05/24 07:59:24 - mmengine - INFO - Iter(train) [110850/160000]  lr: 3.4567e-06  eta: 5:53:48  time: 0.4551  data_time: 0.0110  memory: 4839  grad_norm: 80.3649  loss: 24.6458  decode.loss_cls: 0.7711  decode.loss_mask: 0.6601  decode.loss_dice: 0.8246  decode.d0.loss_cls: 2.6982  decode.d0.loss_mask: 0.5888  decode.d0.loss_dice: 0.9165  decode.d1.loss_cls: 0.9431  decode.d1.loss_mask: 0.6759  decode.d1.loss_dice: 0.8999  decode.d2.loss_cls: 0.7910  decode.d2.loss_mask: 0.6661  decode.d2.loss_dice: 0.8499  decode.d3.loss_cls: 0.7777  decode.d3.loss_mask: 0.6426  decode.d3.loss_dice: 0.8109  decode.d4.loss_cls: 0.7605  decode.d4.loss_mask: 0.6638  decode.d4.loss_dice: 0.8125  decode.d5.loss_cls: 0.7414  decode.d5.loss_mask: 0.6700  decode.d5.loss_dice: 0.8067  decode.d6.loss_cls: 0.7343  decode.d6.loss_mask: 0.6877  decode.d6.loss_dice: 0.8217  decode.d7.loss_cls: 0.7202  decode.d7.loss_mask: 0.6713  decode.d7.loss_dice: 0.8075  decode.d8.loss_cls: 0.7353  decode.d8.loss_mask: 0.6683  decode.d8.loss_dice: 0.8281
2023/05/24 07:59:45 - mmengine - INFO - Iter(train) [110900/160000]  lr: 3.4536e-06  eta: 5:53:26  time: 0.4268  data_time: 0.0105  memory: 4899  grad_norm: 128.0061  loss: 35.7602  decode.loss_cls: 1.1770  decode.loss_mask: 0.8222  decode.loss_dice: 1.2670  decode.d0.loss_cls: 3.2494  decode.d0.loss_mask: 0.8254  decode.d0.loss_dice: 1.4585  decode.d1.loss_cls: 1.2484  decode.d1.loss_mask: 0.8936  decode.d1.loss_dice: 1.3986  decode.d2.loss_cls: 1.2915  decode.d2.loss_mask: 0.8633  decode.d2.loss_dice: 1.3147  decode.d3.loss_cls: 1.2056  decode.d3.loss_mask: 0.8531  decode.d3.loss_dice: 1.3021  decode.d4.loss_cls: 1.1802  decode.d4.loss_mask: 0.8329  decode.d4.loss_dice: 1.3157  decode.d5.loss_cls: 1.2077  decode.d5.loss_mask: 0.8208  decode.d5.loss_dice: 1.3006  decode.d6.loss_cls: 1.2175  decode.d6.loss_mask: 0.8413  decode.d6.loss_dice: 1.2687  decode.d7.loss_cls: 1.1954  decode.d7.loss_mask: 0.8320  decode.d7.loss_dice: 1.2958  decode.d8.loss_cls: 1.1781  decode.d8.loss_mask: 0.8302  decode.d8.loss_dice: 1.2724
2023/05/24 08:00:07 - mmengine - INFO - Iter(train) [110950/160000]  lr: 3.4504e-06  eta: 5:53:04  time: 0.4201  data_time: 0.0105  memory: 4858  grad_norm: 96.7065  loss: 39.0076  decode.loss_cls: 1.3381  decode.loss_mask: 0.7767  decode.loss_dice: 1.5310  decode.d0.loss_cls: 3.3503  decode.d0.loss_mask: 0.8781  decode.d0.loss_dice: 1.8056  decode.d1.loss_cls: 1.3737  decode.d1.loss_mask: 0.8889  decode.d1.loss_dice: 1.6642  decode.d2.loss_cls: 1.3221  decode.d2.loss_mask: 0.8081  decode.d2.loss_dice: 1.5365  decode.d3.loss_cls: 1.3142  decode.d3.loss_mask: 0.8014  decode.d3.loss_dice: 1.5452  decode.d4.loss_cls: 1.2533  decode.d4.loss_mask: 0.7871  decode.d4.loss_dice: 1.5308  decode.d5.loss_cls: 1.2970  decode.d5.loss_mask: 0.7876  decode.d5.loss_dice: 1.5408  decode.d6.loss_cls: 1.3353  decode.d6.loss_mask: 0.7559  decode.d6.loss_dice: 1.5253  decode.d7.loss_cls: 1.2963  decode.d7.loss_mask: 0.8085  decode.d7.loss_dice: 1.5349  decode.d8.loss_cls: 1.3278  decode.d8.loss_mask: 0.7856  decode.d8.loss_dice: 1.5073
2023/05/24 08:00:28 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 08:00:28 - mmengine - INFO - Iter(train) [111000/160000]  lr: 3.4472e-06  eta: 5:52:42  time: 0.4252  data_time: 0.0104  memory: 4862  grad_norm: 96.0672  loss: 35.9776  decode.loss_cls: 1.2385  decode.loss_mask: 0.8377  decode.loss_dice: 1.2343  decode.d0.loss_cls: 3.1986  decode.d0.loss_mask: 0.9322  decode.d0.loss_dice: 1.5500  decode.d1.loss_cls: 1.4369  decode.d1.loss_mask: 0.8684  decode.d1.loss_dice: 1.3852  decode.d2.loss_cls: 1.2896  decode.d2.loss_mask: 0.8810  decode.d2.loss_dice: 1.3093  decode.d3.loss_cls: 1.2451  decode.d3.loss_mask: 0.8503  decode.d3.loss_dice: 1.2427  decode.d4.loss_cls: 1.1519  decode.d4.loss_mask: 0.8484  decode.d4.loss_dice: 1.2655  decode.d5.loss_cls: 1.1630  decode.d5.loss_mask: 0.8688  decode.d5.loss_dice: 1.2785  decode.d6.loss_cls: 1.2918  decode.d6.loss_mask: 0.8316  decode.d6.loss_dice: 1.2055  decode.d7.loss_cls: 1.2232  decode.d7.loss_mask: 0.8366  decode.d7.loss_dice: 1.2266  decode.d8.loss_cls: 1.1985  decode.d8.loss_mask: 0.8384  decode.d8.loss_dice: 1.2493
2023/05/24 08:00:28 - mmengine - INFO - Saving checkpoint at 111000 iterations
2023/05/24 08:00:54 - mmengine - INFO - Iter(train) [111050/160000]  lr: 3.4441e-06  eta: 5:52:23  time: 0.4271  data_time: 0.0106  memory: 4917  grad_norm: 102.5836  loss: 34.0362  decode.loss_cls: 1.2904  decode.loss_mask: 0.7199  decode.loss_dice: 1.1954  decode.d0.loss_cls: 2.8953  decode.d0.loss_mask: 0.8237  decode.d0.loss_dice: 1.2983  decode.d1.loss_cls: 1.3738  decode.d1.loss_mask: 0.7685  decode.d1.loss_dice: 1.1978  decode.d2.loss_cls: 1.2951  decode.d2.loss_mask: 0.7922  decode.d2.loss_dice: 1.2403  decode.d3.loss_cls: 1.2328  decode.d3.loss_mask: 0.7787  decode.d3.loss_dice: 1.2168  decode.d4.loss_cls: 1.2123  decode.d4.loss_mask: 0.7702  decode.d4.loss_dice: 1.2177  decode.d5.loss_cls: 1.1655  decode.d5.loss_mask: 0.7821  decode.d5.loss_dice: 1.2222  decode.d6.loss_cls: 1.3044  decode.d6.loss_mask: 0.7251  decode.d6.loss_dice: 1.2155  decode.d7.loss_cls: 1.1771  decode.d7.loss_mask: 0.7386  decode.d7.loss_dice: 1.2145  decode.d8.loss_cls: 1.2423  decode.d8.loss_mask: 0.7332  decode.d8.loss_dice: 1.1964
2023/05/24 08:01:16 - mmengine - INFO - Iter(train) [111100/160000]  lr: 3.4409e-06  eta: 5:52:01  time: 0.4258  data_time: 0.0105  memory: 4828  grad_norm: 104.1969  loss: 26.7706  decode.loss_cls: 1.0370  decode.loss_mask: 0.6223  decode.loss_dice: 0.7619  decode.d0.loss_cls: 2.9596  decode.d0.loss_mask: 0.6875  decode.d0.loss_dice: 0.9519  decode.d1.loss_cls: 1.1333  decode.d1.loss_mask: 0.6269  decode.d1.loss_dice: 0.8311  decode.d2.loss_cls: 1.0820  decode.d2.loss_mask: 0.6506  decode.d2.loss_dice: 0.8009  decode.d3.loss_cls: 1.0267  decode.d3.loss_mask: 0.6451  decode.d3.loss_dice: 0.7781  decode.d4.loss_cls: 1.0297  decode.d4.loss_mask: 0.6484  decode.d4.loss_dice: 0.8235  decode.d5.loss_cls: 1.0335  decode.d5.loss_mask: 0.6327  decode.d5.loss_dice: 0.7670  decode.d6.loss_cls: 1.0192  decode.d6.loss_mask: 0.6267  decode.d6.loss_dice: 0.7837  decode.d7.loss_cls: 1.0067  decode.d7.loss_mask: 0.6363  decode.d7.loss_dice: 0.7730  decode.d8.loss_cls: 0.9905  decode.d8.loss_mask: 0.6300  decode.d8.loss_dice: 0.7748
2023/05/24 08:01:37 - mmengine - INFO - Iter(train) [111150/160000]  lr: 3.4377e-06  eta: 5:51:39  time: 0.4246  data_time: 0.0109  memory: 4821  grad_norm: 103.4491  loss: 29.0079  decode.loss_cls: 1.0450  decode.loss_mask: 0.6116  decode.loss_dice: 0.9740  decode.d0.loss_cls: 2.8776  decode.d0.loss_mask: 0.6848  decode.d0.loss_dice: 1.0988  decode.d1.loss_cls: 1.0879  decode.d1.loss_mask: 0.6878  decode.d1.loss_dice: 1.0679  decode.d2.loss_cls: 1.0485  decode.d2.loss_mask: 0.6508  decode.d2.loss_dice: 1.0225  decode.d3.loss_cls: 1.1172  decode.d3.loss_mask: 0.6205  decode.d3.loss_dice: 0.9809  decode.d4.loss_cls: 1.1040  decode.d4.loss_mask: 0.6320  decode.d4.loss_dice: 1.0086  decode.d5.loss_cls: 1.0773  decode.d5.loss_mask: 0.6378  decode.d5.loss_dice: 1.0085  decode.d6.loss_cls: 1.0527  decode.d6.loss_mask: 0.6345  decode.d6.loss_dice: 1.0094  decode.d7.loss_cls: 1.0195  decode.d7.loss_mask: 0.6318  decode.d7.loss_dice: 0.9933  decode.d8.loss_cls: 0.9925  decode.d8.loss_mask: 0.6276  decode.d8.loss_dice: 1.0026
2023/05/24 08:01:58 - mmengine - INFO - Iter(train) [111200/160000]  lr: 3.4346e-06  eta: 5:51:18  time: 0.4204  data_time: 0.0104  memory: 4898  grad_norm: 83.4195  loss: 35.0051  decode.loss_cls: 1.1766  decode.loss_mask: 0.6872  decode.loss_dice: 1.3985  decode.d0.loss_cls: 3.1179  decode.d0.loss_mask: 0.7812  decode.d0.loss_dice: 1.6302  decode.d1.loss_cls: 1.1918  decode.d1.loss_mask: 0.7468  decode.d1.loss_dice: 1.4930  decode.d2.loss_cls: 1.1673  decode.d2.loss_mask: 0.7179  decode.d2.loss_dice: 1.4247  decode.d3.loss_cls: 1.1948  decode.d3.loss_mask: 0.7090  decode.d3.loss_dice: 1.3878  decode.d4.loss_cls: 1.1918  decode.d4.loss_mask: 0.6900  decode.d4.loss_dice: 1.3946  decode.d5.loss_cls: 1.1321  decode.d5.loss_mask: 0.6952  decode.d5.loss_dice: 1.3760  decode.d6.loss_cls: 1.1452  decode.d6.loss_mask: 0.7012  decode.d6.loss_dice: 1.3841  decode.d7.loss_cls: 1.1445  decode.d7.loss_mask: 0.7107  decode.d7.loss_dice: 1.4008  decode.d8.loss_cls: 1.1306  decode.d8.loss_mask: 0.7028  decode.d8.loss_dice: 1.3809
2023/05/24 08:02:20 - mmengine - INFO - Iter(train) [111250/160000]  lr: 3.4314e-06  eta: 5:50:56  time: 0.4413  data_time: 0.0106  memory: 4836  grad_norm: 141.9828  loss: 29.2654  decode.loss_cls: 1.0647  decode.loss_mask: 0.6967  decode.loss_dice: 0.9406  decode.d0.loss_cls: 2.8978  decode.d0.loss_mask: 0.7635  decode.d0.loss_dice: 1.0958  decode.d1.loss_cls: 1.1689  decode.d1.loss_mask: 0.7588  decode.d1.loss_dice: 1.0164  decode.d2.loss_cls: 1.0699  decode.d2.loss_mask: 0.7263  decode.d2.loss_dice: 1.0149  decode.d3.loss_cls: 1.0778  decode.d3.loss_mask: 0.6707  decode.d3.loss_dice: 0.9304  decode.d4.loss_cls: 1.0737  decode.d4.loss_mask: 0.6886  decode.d4.loss_dice: 0.9465  decode.d5.loss_cls: 1.0957  decode.d5.loss_mask: 0.6603  decode.d5.loss_dice: 0.9377  decode.d6.loss_cls: 1.0873  decode.d6.loss_mask: 0.6719  decode.d6.loss_dice: 0.8913  decode.d7.loss_cls: 1.0564  decode.d7.loss_mask: 0.6795  decode.d7.loss_dice: 0.9385  decode.d8.loss_cls: 1.0466  decode.d8.loss_mask: 0.6715  decode.d8.loss_dice: 0.9267
2023/05/24 08:02:42 - mmengine - INFO - Iter(train) [111300/160000]  lr: 3.4282e-06  eta: 5:50:34  time: 0.4244  data_time: 0.0109  memory: 4890  grad_norm: 170.5587  loss: 31.7082  decode.loss_cls: 1.1258  decode.loss_mask: 0.6946  decode.loss_dice: 1.0131  decode.d0.loss_cls: 3.2122  decode.d0.loss_mask: 0.7605  decode.d0.loss_dice: 1.2308  decode.d1.loss_cls: 1.3188  decode.d1.loss_mask: 0.7068  decode.d1.loss_dice: 1.1207  decode.d2.loss_cls: 1.2422  decode.d2.loss_mask: 0.6874  decode.d2.loss_dice: 1.1086  decode.d3.loss_cls: 1.1756  decode.d3.loss_mask: 0.6993  decode.d3.loss_dice: 1.0480  decode.d4.loss_cls: 1.1685  decode.d4.loss_mask: 0.7001  decode.d4.loss_dice: 1.0513  decode.d5.loss_cls: 1.1912  decode.d5.loss_mask: 0.6874  decode.d5.loss_dice: 1.0472  decode.d6.loss_cls: 1.2125  decode.d6.loss_mask: 0.6924  decode.d6.loss_dice: 1.0276  decode.d7.loss_cls: 1.1861  decode.d7.loss_mask: 0.6920  decode.d7.loss_dice: 1.0059  decode.d8.loss_cls: 1.1932  decode.d8.loss_mask: 0.6893  decode.d8.loss_dice: 1.0191
2023/05/24 08:03:03 - mmengine - INFO - Iter(train) [111350/160000]  lr: 3.4251e-06  eta: 5:50:13  time: 0.4286  data_time: 0.0106  memory: 4778  grad_norm: 112.1376  loss: 35.5725  decode.loss_cls: 0.9758  decode.loss_mask: 0.7644  decode.loss_dice: 1.4780  decode.d0.loss_cls: 3.0110  decode.d0.loss_mask: 0.7804  decode.d0.loss_dice: 1.7118  decode.d1.loss_cls: 1.1907  decode.d1.loss_mask: 0.8075  decode.d1.loss_dice: 1.5755  decode.d2.loss_cls: 1.0715  decode.d2.loss_mask: 0.7736  decode.d2.loss_dice: 1.5367  decode.d3.loss_cls: 1.0558  decode.d3.loss_mask: 0.7999  decode.d3.loss_dice: 1.5036  decode.d4.loss_cls: 1.0880  decode.d4.loss_mask: 0.7737  decode.d4.loss_dice: 1.4877  decode.d5.loss_cls: 1.0310  decode.d5.loss_mask: 0.7776  decode.d5.loss_dice: 1.5229  decode.d6.loss_cls: 1.0407  decode.d6.loss_mask: 0.7864  decode.d6.loss_dice: 1.5094  decode.d7.loss_cls: 0.9870  decode.d7.loss_mask: 0.7768  decode.d7.loss_dice: 1.5332  decode.d8.loss_cls: 0.9635  decode.d8.loss_mask: 0.7589  decode.d8.loss_dice: 1.4995
2023/05/24 08:03:24 - mmengine - INFO - Iter(train) [111400/160000]  lr: 3.4219e-06  eta: 5:49:51  time: 0.4165  data_time: 0.0106  memory: 4804  grad_norm: 103.3488  loss: 29.3723  decode.loss_cls: 1.1796  decode.loss_mask: 0.5326  decode.loss_dice: 0.9972  decode.d0.loss_cls: 2.8941  decode.d0.loss_mask: 0.6399  decode.d0.loss_dice: 1.1760  decode.d1.loss_cls: 1.3002  decode.d1.loss_mask: 0.5476  decode.d1.loss_dice: 1.0765  decode.d2.loss_cls: 1.2380  decode.d2.loss_mask: 0.5133  decode.d2.loss_dice: 1.0454  decode.d3.loss_cls: 1.2259  decode.d3.loss_mask: 0.5175  decode.d3.loss_dice: 0.9975  decode.d4.loss_cls: 1.2127  decode.d4.loss_mask: 0.5151  decode.d4.loss_dice: 0.9867  decode.d5.loss_cls: 1.1627  decode.d5.loss_mask: 0.5324  decode.d5.loss_dice: 1.0114  decode.d6.loss_cls: 1.1930  decode.d6.loss_mask: 0.5214  decode.d6.loss_dice: 0.9596  decode.d7.loss_cls: 1.1536  decode.d7.loss_mask: 0.5278  decode.d7.loss_dice: 1.0065  decode.d8.loss_cls: 1.2138  decode.d8.loss_mask: 0.5236  decode.d8.loss_dice: 0.9709
2023/05/24 08:03:45 - mmengine - INFO - Iter(train) [111450/160000]  lr: 3.4187e-06  eta: 5:49:29  time: 0.4147  data_time: 0.0107  memory: 4847  grad_norm: 111.0819  loss: 33.2989  decode.loss_cls: 1.1561  decode.loss_mask: 0.7377  decode.loss_dice: 1.1715  decode.d0.loss_cls: 3.0382  decode.d0.loss_mask: 0.7953  decode.d0.loss_dice: 1.4236  decode.d1.loss_cls: 1.3433  decode.d1.loss_mask: 0.7795  decode.d1.loss_dice: 1.2891  decode.d2.loss_cls: 1.1813  decode.d2.loss_mask: 0.7781  decode.d2.loss_dice: 1.2243  decode.d3.loss_cls: 1.2479  decode.d3.loss_mask: 0.7398  decode.d3.loss_dice: 1.1576  decode.d4.loss_cls: 1.2209  decode.d4.loss_mask: 0.7374  decode.d4.loss_dice: 1.1666  decode.d5.loss_cls: 1.1422  decode.d5.loss_mask: 0.7369  decode.d5.loss_dice: 1.1697  decode.d6.loss_cls: 1.1244  decode.d6.loss_mask: 0.7406  decode.d6.loss_dice: 1.1264  decode.d7.loss_cls: 1.1350  decode.d7.loss_mask: 0.7521  decode.d7.loss_dice: 1.1174  decode.d8.loss_cls: 1.1361  decode.d8.loss_mask: 0.7645  decode.d8.loss_dice: 1.1654
2023/05/24 08:04:08 - mmengine - INFO - Iter(train) [111500/160000]  lr: 3.4156e-06  eta: 5:49:08  time: 0.4776  data_time: 0.0102  memory: 4792  grad_norm: 97.7041  loss: 43.2949  decode.loss_cls: 1.6028  decode.loss_mask: 0.8986  decode.loss_dice: 1.4406  decode.d0.loss_cls: 3.6710  decode.d0.loss_mask: 1.0501  decode.d0.loss_dice: 1.7734  decode.d1.loss_cls: 1.7767  decode.d1.loss_mask: 1.0148  decode.d1.loss_dice: 1.7062  decode.d2.loss_cls: 1.6814  decode.d2.loss_mask: 0.9523  decode.d2.loss_dice: 1.6037  decode.d3.loss_cls: 1.5939  decode.d3.loss_mask: 0.9464  decode.d3.loss_dice: 1.5559  decode.d4.loss_cls: 1.6749  decode.d4.loss_mask: 0.9127  decode.d4.loss_dice: 1.5381  decode.d5.loss_cls: 1.6418  decode.d5.loss_mask: 0.9418  decode.d5.loss_dice: 1.4891  decode.d6.loss_cls: 1.5918  decode.d6.loss_mask: 0.8983  decode.d6.loss_dice: 1.4450  decode.d7.loss_cls: 1.6170  decode.d7.loss_mask: 0.8755  decode.d7.loss_dice: 1.4603  decode.d8.loss_cls: 1.5867  decode.d8.loss_mask: 0.8929  decode.d8.loss_dice: 1.4610
2023/05/24 08:04:30 - mmengine - INFO - Iter(train) [111550/160000]  lr: 3.4124e-06  eta: 5:48:47  time: 0.4184  data_time: 0.0105  memory: 4803  grad_norm: 91.0621  loss: 39.4024  decode.loss_cls: 1.3979  decode.loss_mask: 0.7628  decode.loss_dice: 1.4987  decode.d0.loss_cls: 3.2581  decode.d0.loss_mask: 0.7752  decode.d0.loss_dice: 1.7239  decode.d1.loss_cls: 1.5432  decode.d1.loss_mask: 0.7755  decode.d1.loss_dice: 1.6248  decode.d2.loss_cls: 1.4297  decode.d2.loss_mask: 0.7796  decode.d2.loss_dice: 1.5543  decode.d3.loss_cls: 1.4503  decode.d3.loss_mask: 0.7798  decode.d3.loss_dice: 1.5646  decode.d4.loss_cls: 1.4243  decode.d4.loss_mask: 0.7705  decode.d4.loss_dice: 1.5654  decode.d5.loss_cls: 1.4394  decode.d5.loss_mask: 0.7786  decode.d5.loss_dice: 1.5292  decode.d6.loss_cls: 1.3612  decode.d6.loss_mask: 0.7703  decode.d6.loss_dice: 1.5435  decode.d7.loss_cls: 1.3932  decode.d7.loss_mask: 0.7675  decode.d7.loss_dice: 1.5164  decode.d8.loss_cls: 1.3585  decode.d8.loss_mask: 0.7619  decode.d8.loss_dice: 1.5041
2023/05/24 08:04:52 - mmengine - INFO - Iter(train) [111600/160000]  lr: 3.4092e-06  eta: 5:48:25  time: 0.4355  data_time: 0.0110  memory: 4793  grad_norm: 108.4126  loss: 33.2973  decode.loss_cls: 1.1084  decode.loss_mask: 0.7654  decode.loss_dice: 1.1872  decode.d0.loss_cls: 3.0026  decode.d0.loss_mask: 0.7519  decode.d0.loss_dice: 1.2766  decode.d1.loss_cls: 1.1623  decode.d1.loss_mask: 0.7903  decode.d1.loss_dice: 1.3097  decode.d2.loss_cls: 1.1439  decode.d2.loss_mask: 0.7856  decode.d2.loss_dice: 1.2928  decode.d3.loss_cls: 1.1240  decode.d3.loss_mask: 0.7954  decode.d3.loss_dice: 1.2507  decode.d4.loss_cls: 1.1180  decode.d4.loss_mask: 0.8048  decode.d4.loss_dice: 1.2242  decode.d5.loss_cls: 1.1321  decode.d5.loss_mask: 0.7725  decode.d5.loss_dice: 1.2405  decode.d6.loss_cls: 1.0951  decode.d6.loss_mask: 0.7911  decode.d6.loss_dice: 1.2091  decode.d7.loss_cls: 1.1053  decode.d7.loss_mask: 0.7791  decode.d7.loss_dice: 1.1817  decode.d8.loss_cls: 1.1254  decode.d8.loss_mask: 0.7725  decode.d8.loss_dice: 1.1992
2023/05/24 08:05:13 - mmengine - INFO - Iter(train) [111650/160000]  lr: 3.4061e-06  eta: 5:48:03  time: 0.4158  data_time: 0.0103  memory: 4868  grad_norm: 150.2671  loss: 32.6813  decode.loss_cls: 1.2245  decode.loss_mask: 0.6769  decode.loss_dice: 1.1390  decode.d0.loss_cls: 2.8397  decode.d0.loss_mask: 0.7189  decode.d0.loss_dice: 1.4266  decode.d1.loss_cls: 1.2165  decode.d1.loss_mask: 0.6662  decode.d1.loss_dice: 1.2750  decode.d2.loss_cls: 1.2592  decode.d2.loss_mask: 0.6862  decode.d2.loss_dice: 1.2233  decode.d3.loss_cls: 1.2954  decode.d3.loss_mask: 0.6600  decode.d3.loss_dice: 1.1666  decode.d4.loss_cls: 1.1813  decode.d4.loss_mask: 0.6707  decode.d4.loss_dice: 1.1970  decode.d5.loss_cls: 1.2699  decode.d5.loss_mask: 0.6835  decode.d5.loss_dice: 1.1859  decode.d6.loss_cls: 1.1805  decode.d6.loss_mask: 0.6783  decode.d6.loss_dice: 1.1483  decode.d7.loss_cls: 1.2636  decode.d7.loss_mask: 0.6478  decode.d7.loss_dice: 1.1171  decode.d8.loss_cls: 1.1997  decode.d8.loss_mask: 0.6424  decode.d8.loss_dice: 1.1413
2023/05/24 08:05:35 - mmengine - INFO - Iter(train) [111700/160000]  lr: 3.4029e-06  eta: 5:47:42  time: 0.4814  data_time: 0.0105  memory: 4846  grad_norm: 87.9788  loss: 27.0696  decode.loss_cls: 0.9624  decode.loss_mask: 0.6110  decode.loss_dice: 0.9016  decode.d0.loss_cls: 2.5715  decode.d0.loss_mask: 0.6756  decode.d0.loss_dice: 1.0121  decode.d1.loss_cls: 1.1095  decode.d1.loss_mask: 0.6221  decode.d1.loss_dice: 0.9667  decode.d2.loss_cls: 1.1111  decode.d2.loss_mask: 0.6108  decode.d2.loss_dice: 0.9163  decode.d3.loss_cls: 0.9669  decode.d3.loss_mask: 0.6269  decode.d3.loss_dice: 0.9237  decode.d4.loss_cls: 0.9603  decode.d4.loss_mask: 0.6141  decode.d4.loss_dice: 0.8908  decode.d5.loss_cls: 1.0211  decode.d5.loss_mask: 0.6171  decode.d5.loss_dice: 0.8887  decode.d6.loss_cls: 0.9844  decode.d6.loss_mask: 0.6136  decode.d6.loss_dice: 0.9146  decode.d7.loss_cls: 0.9693  decode.d7.loss_mask: 0.6056  decode.d7.loss_dice: 0.8940  decode.d8.loss_cls: 0.9835  decode.d8.loss_mask: 0.6231  decode.d8.loss_dice: 0.9011
2023/05/24 08:05:59 - mmengine - INFO - Iter(train) [111750/160000]  lr: 3.3997e-06  eta: 5:47:21  time: 0.4776  data_time: 0.0107  memory: 4827  grad_norm: 95.2935  loss: 32.1836  decode.loss_cls: 1.2061  decode.loss_mask: 0.6960  decode.loss_dice: 1.0456  decode.d0.loss_cls: 3.1015  decode.d0.loss_mask: 0.7221  decode.d0.loss_dice: 1.2953  decode.d1.loss_cls: 1.2734  decode.d1.loss_mask: 0.7532  decode.d1.loss_dice: 1.1285  decode.d2.loss_cls: 1.2849  decode.d2.loss_mask: 0.7159  decode.d2.loss_dice: 1.0963  decode.d3.loss_cls: 1.2322  decode.d3.loss_mask: 0.7219  decode.d3.loss_dice: 1.1041  decode.d4.loss_cls: 1.2070  decode.d4.loss_mask: 0.7105  decode.d4.loss_dice: 1.0618  decode.d5.loss_cls: 1.2199  decode.d5.loss_mask: 0.6934  decode.d5.loss_dice: 1.0673  decode.d6.loss_cls: 1.2166  decode.d6.loss_mask: 0.6986  decode.d6.loss_dice: 1.0490  decode.d7.loss_cls: 1.2213  decode.d7.loss_mask: 0.6816  decode.d7.loss_dice: 1.0197  decode.d8.loss_cls: 1.2049  decode.d8.loss_mask: 0.6973  decode.d8.loss_dice: 1.0576
2023/05/24 08:06:21 - mmengine - INFO - Iter(train) [111800/160000]  lr: 3.3965e-06  eta: 5:47:00  time: 0.4212  data_time: 0.0109  memory: 4811  grad_norm: 96.7862  loss: 32.2104  decode.loss_cls: 1.1495  decode.loss_mask: 0.5735  decode.loss_dice: 1.1419  decode.d0.loss_cls: 3.0152  decode.d0.loss_mask: 0.6340  decode.d0.loss_dice: 1.2767  decode.d1.loss_cls: 1.3450  decode.d1.loss_mask: 0.7076  decode.d1.loss_dice: 1.2853  decode.d2.loss_cls: 1.2914  decode.d2.loss_mask: 0.6605  decode.d2.loss_dice: 1.2274  decode.d3.loss_cls: 1.2219  decode.d3.loss_mask: 0.6219  decode.d3.loss_dice: 1.1844  decode.d4.loss_cls: 1.1977  decode.d4.loss_mask: 0.6083  decode.d4.loss_dice: 1.1963  decode.d5.loss_cls: 1.1981  decode.d5.loss_mask: 0.6139  decode.d5.loss_dice: 1.2100  decode.d6.loss_cls: 1.2062  decode.d6.loss_mask: 0.5957  decode.d6.loss_dice: 1.1996  decode.d7.loss_cls: 1.1508  decode.d7.loss_mask: 0.5873  decode.d7.loss_dice: 1.1888  decode.d8.loss_cls: 1.1888  decode.d8.loss_mask: 0.5721  decode.d8.loss_dice: 1.1605
2023/05/24 08:06:44 - mmengine - INFO - Iter(train) [111850/160000]  lr: 3.3934e-06  eta: 5:46:39  time: 0.4760  data_time: 0.0104  memory: 4845  grad_norm: 99.0288  loss: 39.6361  decode.loss_cls: 1.4989  decode.loss_mask: 0.8451  decode.loss_dice: 1.2751  decode.d0.loss_cls: 3.1155  decode.d0.loss_mask: 1.0117  decode.d0.loss_dice: 1.6416  decode.d1.loss_cls: 1.5819  decode.d1.loss_mask: 0.9022  decode.d1.loss_dice: 1.4398  decode.d2.loss_cls: 1.6751  decode.d2.loss_mask: 0.8928  decode.d2.loss_dice: 1.3758  decode.d3.loss_cls: 1.6368  decode.d3.loss_mask: 0.8719  decode.d3.loss_dice: 1.3363  decode.d4.loss_cls: 1.5920  decode.d4.loss_mask: 0.8750  decode.d4.loss_dice: 1.3464  decode.d5.loss_cls: 1.5337  decode.d5.loss_mask: 0.8688  decode.d5.loss_dice: 1.3148  decode.d6.loss_cls: 1.5200  decode.d6.loss_mask: 0.8554  decode.d6.loss_dice: 1.3146  decode.d7.loss_cls: 1.5161  decode.d7.loss_mask: 0.8474  decode.d7.loss_dice: 1.3153  decode.d8.loss_cls: 1.5115  decode.d8.loss_mask: 0.8445  decode.d8.loss_dice: 1.2801
2023/05/24 08:07:07 - mmengine - INFO - Iter(train) [111900/160000]  lr: 3.3902e-06  eta: 5:46:18  time: 0.4181  data_time: 0.0108  memory: 4888  grad_norm: 94.1067  loss: 41.6283  decode.loss_cls: 1.4762  decode.loss_mask: 0.8435  decode.loss_dice: 1.5602  decode.d0.loss_cls: 3.5003  decode.d0.loss_mask: 0.8296  decode.d0.loss_dice: 1.7659  decode.d1.loss_cls: 1.6362  decode.d1.loss_mask: 0.8332  decode.d1.loss_dice: 1.6548  decode.d2.loss_cls: 1.5895  decode.d2.loss_mask: 0.8198  decode.d2.loss_dice: 1.5777  decode.d3.loss_cls: 1.5596  decode.d3.loss_mask: 0.8142  decode.d3.loss_dice: 1.5603  decode.d4.loss_cls: 1.5734  decode.d4.loss_mask: 0.8284  decode.d4.loss_dice: 1.5402  decode.d5.loss_cls: 1.5897  decode.d5.loss_mask: 0.8382  decode.d5.loss_dice: 1.5467  decode.d6.loss_cls: 1.5219  decode.d6.loss_mask: 0.8484  decode.d6.loss_dice: 1.5321  decode.d7.loss_cls: 1.4792  decode.d7.loss_mask: 0.8416  decode.d7.loss_dice: 1.5632  decode.d8.loss_cls: 1.5459  decode.d8.loss_mask: 0.8396  decode.d8.loss_dice: 1.5187
2023/05/24 08:07:29 - mmengine - INFO - Iter(train) [111950/160000]  lr: 3.3870e-06  eta: 5:45:56  time: 0.4240  data_time: 0.0105  memory: 4873  grad_norm: 132.8558  loss: 42.9899  decode.loss_cls: 1.6419  decode.loss_mask: 0.8271  decode.loss_dice: 1.5582  decode.d0.loss_cls: 3.8035  decode.d0.loss_mask: 0.8727  decode.d0.loss_dice: 1.7903  decode.d1.loss_cls: 1.7790  decode.d1.loss_mask: 0.8176  decode.d1.loss_dice: 1.6659  decode.d2.loss_cls: 1.6712  decode.d2.loss_mask: 0.8198  decode.d2.loss_dice: 1.6324  decode.d3.loss_cls: 1.6898  decode.d3.loss_mask: 0.7965  decode.d3.loss_dice: 1.5587  decode.d4.loss_cls: 1.6800  decode.d4.loss_mask: 0.7930  decode.d4.loss_dice: 1.5782  decode.d5.loss_cls: 1.6280  decode.d5.loss_mask: 0.8001  decode.d5.loss_dice: 1.5694  decode.d6.loss_cls: 1.6664  decode.d6.loss_mask: 0.8069  decode.d6.loss_dice: 1.5593  decode.d7.loss_cls: 1.6587  decode.d7.loss_mask: 0.8053  decode.d7.loss_dice: 1.5305  decode.d8.loss_cls: 1.6435  decode.d8.loss_mask: 0.8137  decode.d8.loss_dice: 1.5322
2023/05/24 08:07:50 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 08:07:50 - mmengine - INFO - Iter(train) [112000/160000]  lr: 3.3839e-06  eta: 5:45:35  time: 0.4231  data_time: 0.0104  memory: 4907  grad_norm: 85.5946  loss: 32.7343  decode.loss_cls: 1.1512  decode.loss_mask: 0.6151  decode.loss_dice: 1.1680  decode.d0.loss_cls: 3.1650  decode.d0.loss_mask: 0.6787  decode.d0.loss_dice: 1.3387  decode.d1.loss_cls: 1.3495  decode.d1.loss_mask: 0.6837  decode.d1.loss_dice: 1.2799  decode.d2.loss_cls: 1.2990  decode.d2.loss_mask: 0.6498  decode.d2.loss_dice: 1.2674  decode.d3.loss_cls: 1.1542  decode.d3.loss_mask: 0.6414  decode.d3.loss_dice: 1.2380  decode.d4.loss_cls: 1.1766  decode.d4.loss_mask: 0.6258  decode.d4.loss_dice: 1.2431  decode.d5.loss_cls: 1.1873  decode.d5.loss_mask: 0.6403  decode.d5.loss_dice: 1.2432  decode.d6.loss_cls: 1.1534  decode.d6.loss_mask: 0.6243  decode.d6.loss_dice: 1.1983  decode.d7.loss_cls: 1.1422  decode.d7.loss_mask: 0.6278  decode.d7.loss_dice: 1.2195  decode.d8.loss_cls: 1.1481  decode.d8.loss_mask: 0.6354  decode.d8.loss_dice: 1.1894
2023/05/24 08:07:50 - mmengine - INFO - Saving checkpoint at 112000 iterations
2023/05/24 08:08:17 - mmengine - INFO - Iter(train) [112050/160000]  lr: 3.3807e-06  eta: 5:45:16  time: 0.4385  data_time: 0.0112  memory: 4845  grad_norm: 107.7112  loss: 37.3963  decode.loss_cls: 1.1456  decode.loss_mask: 0.8299  decode.loss_dice: 1.4901  decode.d0.loss_cls: 3.2304  decode.d0.loss_mask: 0.9201  decode.d0.loss_dice: 1.7267  decode.d1.loss_cls: 1.2307  decode.d1.loss_mask: 0.8908  decode.d1.loss_dice: 1.5796  decode.d2.loss_cls: 1.2212  decode.d2.loss_mask: 0.8514  decode.d2.loss_dice: 1.4977  decode.d3.loss_cls: 1.1712  decode.d3.loss_mask: 0.8516  decode.d3.loss_dice: 1.5008  decode.d4.loss_cls: 1.1736  decode.d4.loss_mask: 0.8450  decode.d4.loss_dice: 1.5010  decode.d5.loss_cls: 1.1019  decode.d5.loss_mask: 0.8615  decode.d5.loss_dice: 1.4900  decode.d6.loss_cls: 1.1046  decode.d6.loss_mask: 0.8433  decode.d6.loss_dice: 1.4759  decode.d7.loss_cls: 1.1622  decode.d7.loss_mask: 0.8432  decode.d7.loss_dice: 1.4454  decode.d8.loss_cls: 1.0876  decode.d8.loss_mask: 0.8432  decode.d8.loss_dice: 1.4802
2023/05/24 08:08:39 - mmengine - INFO - Iter(train) [112100/160000]  lr: 3.3775e-06  eta: 5:44:54  time: 0.4170  data_time: 0.0106  memory: 4824  grad_norm: 97.0965  loss: 37.7613  decode.loss_cls: 1.4136  decode.loss_mask: 0.7428  decode.loss_dice: 1.3270  decode.d0.loss_cls: 3.1123  decode.d0.loss_mask: 0.9177  decode.d0.loss_dice: 1.6350  decode.d1.loss_cls: 1.5151  decode.d1.loss_mask: 0.8591  decode.d1.loss_dice: 1.4780  decode.d2.loss_cls: 1.4287  decode.d2.loss_mask: 0.8289  decode.d2.loss_dice: 1.4457  decode.d3.loss_cls: 1.4178  decode.d3.loss_mask: 0.7633  decode.d3.loss_dice: 1.3707  decode.d4.loss_cls: 1.4031  decode.d4.loss_mask: 0.7499  decode.d4.loss_dice: 1.3704  decode.d5.loss_cls: 1.3743  decode.d5.loss_mask: 0.7371  decode.d5.loss_dice: 1.3803  decode.d6.loss_cls: 1.4266  decode.d6.loss_mask: 0.7384  decode.d6.loss_dice: 1.3394  decode.d7.loss_cls: 1.3934  decode.d7.loss_mask: 0.7514  decode.d7.loss_dice: 1.3399  decode.d8.loss_cls: 1.3951  decode.d8.loss_mask: 0.7631  decode.d8.loss_dice: 1.3432
2023/05/24 08:09:01 - mmengine - INFO - Iter(train) [112150/160000]  lr: 3.3743e-06  eta: 5:44:32  time: 0.4183  data_time: 0.0103  memory: 4878  grad_norm: 84.3279  loss: 32.2120  decode.loss_cls: 0.9907  decode.loss_mask: 0.7797  decode.loss_dice: 1.2015  decode.d0.loss_cls: 2.9424  decode.d0.loss_mask: 0.7992  decode.d0.loss_dice: 1.3490  decode.d1.loss_cls: 1.0808  decode.d1.loss_mask: 0.8135  decode.d1.loss_dice: 1.2640  decode.d2.loss_cls: 1.0876  decode.d2.loss_mask: 0.7969  decode.d2.loss_dice: 1.2240  decode.d3.loss_cls: 1.1161  decode.d3.loss_mask: 0.7672  decode.d3.loss_dice: 1.2103  decode.d4.loss_cls: 0.9995  decode.d4.loss_mask: 0.7710  decode.d4.loss_dice: 1.1862  decode.d5.loss_cls: 0.9839  decode.d5.loss_mask: 0.7675  decode.d5.loss_dice: 1.1800  decode.d6.loss_cls: 1.0181  decode.d6.loss_mask: 0.7684  decode.d6.loss_dice: 1.1594  decode.d7.loss_cls: 1.0189  decode.d7.loss_mask: 0.7747  decode.d7.loss_dice: 1.1730  decode.d8.loss_cls: 1.0472  decode.d8.loss_mask: 0.7744  decode.d8.loss_dice: 1.1668
2023/05/24 08:09:23 - mmengine - INFO - Iter(train) [112200/160000]  lr: 3.3712e-06  eta: 5:44:11  time: 0.4385  data_time: 0.0111  memory: 4950  grad_norm: 112.7304  loss: 37.3959  decode.loss_cls: 1.4138  decode.loss_mask: 0.7593  decode.loss_dice: 1.2897  decode.d0.loss_cls: 3.1306  decode.d0.loss_mask: 0.8361  decode.d0.loss_dice: 1.4810  decode.d1.loss_cls: 1.4392  decode.d1.loss_mask: 0.8809  decode.d1.loss_dice: 1.3858  decode.d2.loss_cls: 1.3632  decode.d2.loss_mask: 0.8296  decode.d2.loss_dice: 1.3691  decode.d3.loss_cls: 1.3756  decode.d3.loss_mask: 0.8016  decode.d3.loss_dice: 1.3806  decode.d4.loss_cls: 1.4257  decode.d4.loss_mask: 0.7906  decode.d4.loss_dice: 1.3717  decode.d5.loss_cls: 1.3780  decode.d5.loss_mask: 0.7986  decode.d5.loss_dice: 1.3707  decode.d6.loss_cls: 1.4010  decode.d6.loss_mask: 0.7382  decode.d6.loss_dice: 1.3216  decode.d7.loss_cls: 1.4388  decode.d7.loss_mask: 0.7871  decode.d7.loss_dice: 1.3470  decode.d8.loss_cls: 1.4052  decode.d8.loss_mask: 0.7616  decode.d8.loss_dice: 1.3241
2023/05/24 08:09:44 - mmengine - INFO - Iter(train) [112250/160000]  lr: 3.3680e-06  eta: 5:43:49  time: 0.4297  data_time: 0.0104  memory: 4903  grad_norm: 110.1518  loss: 43.3499  decode.loss_cls: 1.4096  decode.loss_mask: 0.8807  decode.loss_dice: 1.7718  decode.d0.loss_cls: 3.3337  decode.d0.loss_mask: 0.9444  decode.d0.loss_dice: 1.9943  decode.d1.loss_cls: 1.4277  decode.d1.loss_mask: 0.9632  decode.d1.loss_dice: 1.9800  decode.d2.loss_cls: 1.4504  decode.d2.loss_mask: 0.9056  decode.d2.loss_dice: 1.8593  decode.d3.loss_cls: 1.3973  decode.d3.loss_mask: 0.9063  decode.d3.loss_dice: 1.8159  decode.d4.loss_cls: 1.3725  decode.d4.loss_mask: 0.9107  decode.d4.loss_dice: 1.8226  decode.d5.loss_cls: 1.3890  decode.d5.loss_mask: 0.8893  decode.d5.loss_dice: 1.7879  decode.d6.loss_cls: 1.3766  decode.d6.loss_mask: 0.8737  decode.d6.loss_dice: 1.7540  decode.d7.loss_cls: 1.4261  decode.d7.loss_mask: 0.8602  decode.d7.loss_dice: 1.7588  decode.d8.loss_cls: 1.4143  decode.d8.loss_mask: 0.9012  decode.d8.loss_dice: 1.7733
2023/05/24 08:10:08 - mmengine - INFO - Iter(train) [112300/160000]  lr: 3.3648e-06  eta: 5:43:29  time: 0.4693  data_time: 0.0103  memory: 4874  grad_norm: 83.8328  loss: 29.8677  decode.loss_cls: 1.0945  decode.loss_mask: 0.6148  decode.loss_dice: 1.0043  decode.d0.loss_cls: 2.9364  decode.d0.loss_mask: 0.6769  decode.d0.loss_dice: 1.2046  decode.d1.loss_cls: 1.2124  decode.d1.loss_mask: 0.6535  decode.d1.loss_dice: 1.1100  decode.d2.loss_cls: 1.1462  decode.d2.loss_mask: 0.6463  decode.d2.loss_dice: 1.0482  decode.d3.loss_cls: 1.1367  decode.d3.loss_mask: 0.6370  decode.d3.loss_dice: 1.0410  decode.d4.loss_cls: 1.0459  decode.d4.loss_mask: 0.6350  decode.d4.loss_dice: 1.0597  decode.d5.loss_cls: 1.0875  decode.d5.loss_mask: 0.6347  decode.d5.loss_dice: 1.0347  decode.d6.loss_cls: 1.1147  decode.d6.loss_mask: 0.6194  decode.d6.loss_dice: 1.0009  decode.d7.loss_cls: 1.1143  decode.d7.loss_mask: 0.6177  decode.d7.loss_dice: 1.0172  decode.d8.loss_cls: 1.0930  decode.d8.loss_mask: 0.6239  decode.d8.loss_dice: 1.0063
2023/05/24 08:10:29 - mmengine - INFO - Iter(train) [112350/160000]  lr: 3.3616e-06  eta: 5:43:07  time: 0.4357  data_time: 0.0107  memory: 4884  grad_norm: 96.3905  loss: 40.4034  decode.loss_cls: 1.4604  decode.loss_mask: 0.7954  decode.loss_dice: 1.5179  decode.d0.loss_cls: 3.1333  decode.d0.loss_mask: 0.9821  decode.d0.loss_dice: 1.6924  decode.d1.loss_cls: 1.5109  decode.d1.loss_mask: 0.8544  decode.d1.loss_dice: 1.5853  decode.d2.loss_cls: 1.5024  decode.d2.loss_mask: 0.8445  decode.d2.loss_dice: 1.5420  decode.d3.loss_cls: 1.5196  decode.d3.loss_mask: 0.8201  decode.d3.loss_dice: 1.5116  decode.d4.loss_cls: 1.5098  decode.d4.loss_mask: 0.7898  decode.d4.loss_dice: 1.5219  decode.d5.loss_cls: 1.5261  decode.d5.loss_mask: 0.8334  decode.d5.loss_dice: 1.4960  decode.d6.loss_cls: 1.5732  decode.d6.loss_mask: 0.7769  decode.d6.loss_dice: 1.4488  decode.d7.loss_cls: 1.5306  decode.d7.loss_mask: 0.8210  decode.d7.loss_dice: 1.4833  decode.d8.loss_cls: 1.4955  decode.d8.loss_mask: 0.8013  decode.d8.loss_dice: 1.5236
2023/05/24 08:10:53 - mmengine - INFO - Iter(train) [112400/160000]  lr: 3.3585e-06  eta: 5:42:46  time: 0.4928  data_time: 0.0106  memory: 4908  grad_norm: 91.3290  loss: 28.4550  decode.loss_cls: 0.7339  decode.loss_mask: 0.7807  decode.loss_dice: 1.0357  decode.d0.loss_cls: 2.7353  decode.d0.loss_mask: 0.8582  decode.d0.loss_dice: 1.1971  decode.d1.loss_cls: 0.8728  decode.d1.loss_mask: 0.8134  decode.d1.loss_dice: 1.1345  decode.d2.loss_cls: 0.8161  decode.d2.loss_mask: 0.8148  decode.d2.loss_dice: 1.0644  decode.d3.loss_cls: 0.7955  decode.d3.loss_mask: 0.8087  decode.d3.loss_dice: 1.0594  decode.d4.loss_cls: 0.7560  decode.d4.loss_mask: 0.7849  decode.d4.loss_dice: 1.0631  decode.d5.loss_cls: 0.7487  decode.d5.loss_mask: 0.7907  decode.d5.loss_dice: 1.0674  decode.d6.loss_cls: 0.7913  decode.d6.loss_mask: 0.7770  decode.d6.loss_dice: 1.0330  decode.d7.loss_cls: 0.7472  decode.d7.loss_mask: 0.7738  decode.d7.loss_dice: 1.0487  decode.d8.loss_cls: 0.7205  decode.d8.loss_mask: 0.7716  decode.d8.loss_dice: 1.0607
2023/05/24 08:11:14 - mmengine - INFO - Iter(train) [112450/160000]  lr: 3.3553e-06  eta: 5:42:24  time: 0.4151  data_time: 0.0105  memory: 4856  grad_norm: 84.9019  loss: 33.4107  decode.loss_cls: 1.2166  decode.loss_mask: 0.7382  decode.loss_dice: 1.1526  decode.d0.loss_cls: 3.0526  decode.d0.loss_mask: 0.7917  decode.d0.loss_dice: 1.3598  decode.d1.loss_cls: 1.2582  decode.d1.loss_mask: 0.7503  decode.d1.loss_dice: 1.2307  decode.d2.loss_cls: 1.2356  decode.d2.loss_mask: 0.7747  decode.d2.loss_dice: 1.1849  decode.d3.loss_cls: 1.1821  decode.d3.loss_mask: 0.7654  decode.d3.loss_dice: 1.1544  decode.d4.loss_cls: 1.2133  decode.d4.loss_mask: 0.7641  decode.d4.loss_dice: 1.1597  decode.d5.loss_cls: 1.1725  decode.d5.loss_mask: 0.7563  decode.d5.loss_dice: 1.1511  decode.d6.loss_cls: 1.2033  decode.d6.loss_mask: 0.7665  decode.d6.loss_dice: 1.1612  decode.d7.loss_cls: 1.1862  decode.d7.loss_mask: 0.7625  decode.d7.loss_dice: 1.1644  decode.d8.loss_cls: 1.2046  decode.d8.loss_mask: 0.7489  decode.d8.loss_dice: 1.1480
2023/05/24 08:11:36 - mmengine - INFO - Iter(train) [112500/160000]  lr: 3.3521e-06  eta: 5:42:03  time: 0.4273  data_time: 0.0102  memory: 4823  grad_norm: 111.6982  loss: 33.2623  decode.loss_cls: 1.2340  decode.loss_mask: 0.6217  decode.loss_dice: 1.1299  decode.d0.loss_cls: 3.1559  decode.d0.loss_mask: 0.7651  decode.d0.loss_dice: 1.4432  decode.d1.loss_cls: 1.3731  decode.d1.loss_mask: 0.6637  decode.d1.loss_dice: 1.3373  decode.d2.loss_cls: 1.3126  decode.d2.loss_mask: 0.6267  decode.d2.loss_dice: 1.2344  decode.d3.loss_cls: 1.2422  decode.d3.loss_mask: 0.6636  decode.d3.loss_dice: 1.2373  decode.d4.loss_cls: 1.2000  decode.d4.loss_mask: 0.6532  decode.d4.loss_dice: 1.2027  decode.d5.loss_cls: 1.2538  decode.d5.loss_mask: 0.6402  decode.d5.loss_dice: 1.1668  decode.d6.loss_cls: 1.2255  decode.d6.loss_mask: 0.6227  decode.d6.loss_dice: 1.2052  decode.d7.loss_cls: 1.1987  decode.d7.loss_mask: 0.6474  decode.d7.loss_dice: 1.1879  decode.d8.loss_cls: 1.2360  decode.d8.loss_mask: 0.6301  decode.d8.loss_dice: 1.1516
2023/05/24 08:11:57 - mmengine - INFO - Iter(train) [112550/160000]  lr: 3.3489e-06  eta: 5:41:41  time: 0.4324  data_time: 0.0108  memory: 4844  grad_norm: 128.2774  loss: 27.7095  decode.loss_cls: 0.8655  decode.loss_mask: 0.6883  decode.loss_dice: 0.9174  decode.d0.loss_cls: 2.9451  decode.d0.loss_mask: 0.7761  decode.d0.loss_dice: 1.1218  decode.d1.loss_cls: 1.0353  decode.d1.loss_mask: 0.7620  decode.d1.loss_dice: 1.0228  decode.d2.loss_cls: 0.9654  decode.d2.loss_mask: 0.7055  decode.d2.loss_dice: 0.9544  decode.d3.loss_cls: 0.8701  decode.d3.loss_mask: 0.7061  decode.d3.loss_dice: 0.9289  decode.d4.loss_cls: 0.8827  decode.d4.loss_mask: 0.7000  decode.d4.loss_dice: 0.9153  decode.d5.loss_cls: 0.9073  decode.d5.loss_mask: 0.7025  decode.d5.loss_dice: 0.9077  decode.d6.loss_cls: 0.8662  decode.d6.loss_mask: 0.6836  decode.d6.loss_dice: 0.9151  decode.d7.loss_cls: 0.8668  decode.d7.loss_mask: 0.6924  decode.d7.loss_dice: 0.9046  decode.d8.loss_cls: 0.9029  decode.d8.loss_mask: 0.6912  decode.d8.loss_dice: 0.9063
2023/05/24 08:12:18 - mmengine - INFO - Iter(train) [112600/160000]  lr: 3.3458e-06  eta: 5:41:19  time: 0.4226  data_time: 0.0109  memory: 4947  grad_norm: 79.8496  loss: 33.5354  decode.loss_cls: 1.0657  decode.loss_mask: 0.7489  decode.loss_dice: 1.2215  decode.d0.loss_cls: 3.1926  decode.d0.loss_mask: 0.8322  decode.d0.loss_dice: 1.4482  decode.d1.loss_cls: 1.2482  decode.d1.loss_mask: 0.7733  decode.d1.loss_dice: 1.3045  decode.d2.loss_cls: 1.1746  decode.d2.loss_mask: 0.7420  decode.d2.loss_dice: 1.2624  decode.d3.loss_cls: 1.1543  decode.d3.loss_mask: 0.7442  decode.d3.loss_dice: 1.2478  decode.d4.loss_cls: 1.0767  decode.d4.loss_mask: 0.7754  decode.d4.loss_dice: 1.2611  decode.d5.loss_cls: 1.0858  decode.d5.loss_mask: 0.7166  decode.d5.loss_dice: 1.2548  decode.d6.loss_cls: 1.1015  decode.d6.loss_mask: 0.7454  decode.d6.loss_dice: 1.2461  decode.d7.loss_cls: 1.0700  decode.d7.loss_mask: 0.7243  decode.d7.loss_dice: 1.2473  decode.d8.loss_cls: 1.0671  decode.d8.loss_mask: 0.7533  decode.d8.loss_dice: 1.2495
2023/05/24 08:12:39 - mmengine - INFO - Iter(train) [112650/160000]  lr: 3.3426e-06  eta: 5:40:57  time: 0.4266  data_time: 0.0103  memory: 4900  grad_norm: 112.9702  loss: 38.8418  decode.loss_cls: 1.3601  decode.loss_mask: 0.7717  decode.loss_dice: 1.4705  decode.d0.loss_cls: 3.2573  decode.d0.loss_mask: 0.8034  decode.d0.loss_dice: 1.7118  decode.d1.loss_cls: 1.6301  decode.d1.loss_mask: 0.7475  decode.d1.loss_dice: 1.5900  decode.d2.loss_cls: 1.5042  decode.d2.loss_mask: 0.7596  decode.d2.loss_dice: 1.5390  decode.d3.loss_cls: 1.3877  decode.d3.loss_mask: 0.7328  decode.d3.loss_dice: 1.5247  decode.d4.loss_cls: 1.3334  decode.d4.loss_mask: 0.7438  decode.d4.loss_dice: 1.4716  decode.d5.loss_cls: 1.4212  decode.d5.loss_mask: 0.7591  decode.d5.loss_dice: 1.4601  decode.d6.loss_cls: 1.3911  decode.d6.loss_mask: 0.7604  decode.d6.loss_dice: 1.4506  decode.d7.loss_cls: 1.3711  decode.d7.loss_mask: 0.7600  decode.d7.loss_dice: 1.4729  decode.d8.loss_cls: 1.4225  decode.d8.loss_mask: 0.7672  decode.d8.loss_dice: 1.4664
2023/05/24 08:13:01 - mmengine - INFO - Iter(train) [112700/160000]  lr: 3.3394e-06  eta: 5:40:36  time: 0.4734  data_time: 0.0104  memory: 4840  grad_norm: 107.1918  loss: 32.1551  decode.loss_cls: 1.0810  decode.loss_mask: 0.6405  decode.loss_dice: 1.2568  decode.d0.loss_cls: 2.8388  decode.d0.loss_mask: 0.6431  decode.d0.loss_dice: 1.3616  decode.d1.loss_cls: 1.1136  decode.d1.loss_mask: 0.6672  decode.d1.loss_dice: 1.2960  decode.d2.loss_cls: 1.1377  decode.d2.loss_mask: 0.6707  decode.d2.loss_dice: 1.3204  decode.d3.loss_cls: 1.1308  decode.d3.loss_mask: 0.6582  decode.d3.loss_dice: 1.2469  decode.d4.loss_cls: 1.1852  decode.d4.loss_mask: 0.6304  decode.d4.loss_dice: 1.2667  decode.d5.loss_cls: 1.1518  decode.d5.loss_mask: 0.6562  decode.d5.loss_dice: 1.2656  decode.d6.loss_cls: 1.1080  decode.d6.loss_mask: 0.6073  decode.d6.loss_dice: 1.2678  decode.d7.loss_cls: 1.1082  decode.d7.loss_mask: 0.5959  decode.d7.loss_dice: 1.2552  decode.d8.loss_cls: 1.1380  decode.d8.loss_mask: 0.6335  decode.d8.loss_dice: 1.2224
2023/05/24 08:13:25 - mmengine - INFO - Iter(train) [112750/160000]  lr: 3.3362e-06  eta: 5:40:15  time: 0.4260  data_time: 0.0114  memory: 5173  grad_norm: 90.0896  loss: 35.9326  decode.loss_cls: 1.2298  decode.loss_mask: 0.8884  decode.loss_dice: 1.1987  decode.d0.loss_cls: 3.0725  decode.d0.loss_mask: 0.9066  decode.d0.loss_dice: 1.4041  decode.d1.loss_cls: 1.3557  decode.d1.loss_mask: 0.9604  decode.d1.loss_dice: 1.3373  decode.d2.loss_cls: 1.2899  decode.d2.loss_mask: 0.9345  decode.d2.loss_dice: 1.2785  decode.d3.loss_cls: 1.2274  decode.d3.loss_mask: 0.9139  decode.d3.loss_dice: 1.2103  decode.d4.loss_cls: 1.2723  decode.d4.loss_mask: 0.8975  decode.d4.loss_dice: 1.1792  decode.d5.loss_cls: 1.2651  decode.d5.loss_mask: 0.9264  decode.d5.loss_dice: 1.1889  decode.d6.loss_cls: 1.2603  decode.d6.loss_mask: 0.8963  decode.d6.loss_dice: 1.1780  decode.d7.loss_cls: 1.2707  decode.d7.loss_mask: 0.8831  decode.d7.loss_dice: 1.1786  decode.d8.loss_cls: 1.2207  decode.d8.loss_mask: 0.8946  decode.d8.loss_dice: 1.2129
2023/05/24 08:13:46 - mmengine - INFO - Iter(train) [112800/160000]  lr: 3.3331e-06  eta: 5:39:53  time: 0.4368  data_time: 0.0105  memory: 4841  grad_norm: 96.7542  loss: 41.7489  decode.loss_cls: 1.4785  decode.loss_mask: 0.6930  decode.loss_dice: 1.7373  decode.d0.loss_cls: 3.4176  decode.d0.loss_mask: 0.7530  decode.d0.loss_dice: 1.9946  decode.d1.loss_cls: 1.6385  decode.d1.loss_mask: 0.6978  decode.d1.loss_dice: 1.8820  decode.d2.loss_cls: 1.4782  decode.d2.loss_mask: 0.6911  decode.d2.loss_dice: 1.7879  decode.d3.loss_cls: 1.5161  decode.d3.loss_mask: 0.6835  decode.d3.loss_dice: 1.7498  decode.d4.loss_cls: 1.5047  decode.d4.loss_mask: 0.6868  decode.d4.loss_dice: 1.7127  decode.d5.loss_cls: 1.5174  decode.d5.loss_mask: 0.6825  decode.d5.loss_dice: 1.7324  decode.d6.loss_cls: 1.4463  decode.d6.loss_mask: 0.6930  decode.d6.loss_dice: 1.7266  decode.d7.loss_cls: 1.4989  decode.d7.loss_mask: 0.6860  decode.d7.loss_dice: 1.7508  decode.d8.loss_cls: 1.4961  decode.d8.loss_mask: 0.6907  decode.d8.loss_dice: 1.7250
2023/05/24 08:14:09 - mmengine - INFO - Iter(train) [112850/160000]  lr: 3.3299e-06  eta: 5:39:32  time: 0.4187  data_time: 0.0104  memory: 4836  grad_norm: 85.7751  loss: 35.4629  decode.loss_cls: 1.2775  decode.loss_mask: 0.7834  decode.loss_dice: 1.1818  decode.d0.loss_cls: 3.5011  decode.d0.loss_mask: 0.7951  decode.d0.loss_dice: 1.4565  decode.d1.loss_cls: 1.3232  decode.d1.loss_mask: 0.8607  decode.d1.loss_dice: 1.2809  decode.d2.loss_cls: 1.2364  decode.d2.loss_mask: 0.8795  decode.d2.loss_dice: 1.2228  decode.d3.loss_cls: 1.3227  decode.d3.loss_mask: 0.8390  decode.d3.loss_dice: 1.2014  decode.d4.loss_cls: 1.2876  decode.d4.loss_mask: 0.8353  decode.d4.loss_dice: 1.2053  decode.d5.loss_cls: 1.1976  decode.d5.loss_mask: 0.8379  decode.d5.loss_dice: 1.1846  decode.d6.loss_cls: 1.2086  decode.d6.loss_mask: 0.8237  decode.d6.loss_dice: 1.2017  decode.d7.loss_cls: 1.2786  decode.d7.loss_mask: 0.7898  decode.d7.loss_dice: 1.2203  decode.d8.loss_cls: 1.2501  decode.d8.loss_mask: 0.7814  decode.d8.loss_dice: 1.1983
2023/05/24 08:14:30 - mmengine - INFO - Iter(train) [112900/160000]  lr: 3.3267e-06  eta: 5:39:10  time: 0.4208  data_time: 0.0107  memory: 4818  grad_norm: 90.9661  loss: 36.0389  decode.loss_cls: 1.5363  decode.loss_mask: 0.7332  decode.loss_dice: 1.1049  decode.d0.loss_cls: 3.3429  decode.d0.loss_mask: 0.8089  decode.d0.loss_dice: 1.4264  decode.d1.loss_cls: 1.5435  decode.d1.loss_mask: 0.7418  decode.d1.loss_dice: 1.2395  decode.d2.loss_cls: 1.4752  decode.d2.loss_mask: 0.7620  decode.d2.loss_dice: 1.1859  decode.d3.loss_cls: 1.4315  decode.d3.loss_mask: 0.7335  decode.d3.loss_dice: 1.1835  decode.d4.loss_cls: 1.4189  decode.d4.loss_mask: 0.7489  decode.d4.loss_dice: 1.1368  decode.d5.loss_cls: 1.4567  decode.d5.loss_mask: 0.7370  decode.d5.loss_dice: 1.1670  decode.d6.loss_cls: 1.5191  decode.d6.loss_mask: 0.7378  decode.d6.loss_dice: 1.1176  decode.d7.loss_cls: 1.4826  decode.d7.loss_mask: 0.7419  decode.d7.loss_dice: 1.1540  decode.d8.loss_cls: 1.4807  decode.d8.loss_mask: 0.7468  decode.d8.loss_dice: 1.1441
2023/05/24 08:14:52 - mmengine - INFO - Iter(train) [112950/160000]  lr: 3.3235e-06  eta: 5:38:49  time: 0.4164  data_time: 0.0105  memory: 4845  grad_norm: 104.3199  loss: 45.1747  decode.loss_cls: 1.3745  decode.loss_mask: 1.0872  decode.loss_dice: 1.7247  decode.d0.loss_cls: 3.5274  decode.d0.loss_mask: 1.2462  decode.d0.loss_dice: 2.0248  decode.d1.loss_cls: 1.4577  decode.d1.loss_mask: 1.1610  decode.d1.loss_dice: 1.9120  decode.d2.loss_cls: 1.4687  decode.d2.loss_mask: 1.1249  decode.d2.loss_dice: 1.8013  decode.d3.loss_cls: 1.3842  decode.d3.loss_mask: 1.1130  decode.d3.loss_dice: 1.7409  decode.d4.loss_cls: 1.3598  decode.d4.loss_mask: 1.1112  decode.d4.loss_dice: 1.7330  decode.d5.loss_cls: 1.3439  decode.d5.loss_mask: 1.1323  decode.d5.loss_dice: 1.7639  decode.d6.loss_cls: 1.3568  decode.d6.loss_mask: 1.1049  decode.d6.loss_dice: 1.7368  decode.d7.loss_cls: 1.3565  decode.d7.loss_mask: 1.0991  decode.d7.loss_dice: 1.7320  decode.d8.loss_cls: 1.3703  decode.d8.loss_mask: 1.0960  decode.d8.loss_dice: 1.7296
2023/05/24 08:15:14 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 08:15:14 - mmengine - INFO - Iter(train) [113000/160000]  lr: 3.3203e-06  eta: 5:38:27  time: 0.4176  data_time: 0.0107  memory: 4838  grad_norm: 106.5186  loss: 37.2425  decode.loss_cls: 1.3350  decode.loss_mask: 0.8248  decode.loss_dice: 1.3549  decode.d0.loss_cls: 3.1222  decode.d0.loss_mask: 0.8482  decode.d0.loss_dice: 1.5890  decode.d1.loss_cls: 1.3474  decode.d1.loss_mask: 0.8563  decode.d1.loss_dice: 1.5441  decode.d2.loss_cls: 1.3126  decode.d2.loss_mask: 0.8387  decode.d2.loss_dice: 1.3884  decode.d3.loss_cls: 1.3839  decode.d3.loss_mask: 0.7738  decode.d3.loss_dice: 1.3569  decode.d4.loss_cls: 1.3392  decode.d4.loss_mask: 0.7605  decode.d4.loss_dice: 1.3736  decode.d5.loss_cls: 1.3088  decode.d5.loss_mask: 0.8170  decode.d5.loss_dice: 1.3457  decode.d6.loss_cls: 1.3094  decode.d6.loss_mask: 0.7979  decode.d6.loss_dice: 1.3447  decode.d7.loss_cls: 1.3157  decode.d7.loss_mask: 0.8062  decode.d7.loss_dice: 1.3582  decode.d8.loss_cls: 1.3432  decode.d8.loss_mask: 0.8007  decode.d8.loss_dice: 1.3454
2023/05/24 08:15:14 - mmengine - INFO - Saving checkpoint at 113000 iterations
2023/05/24 08:15:40 - mmengine - INFO - Iter(train) [113050/160000]  lr: 3.3172e-06  eta: 5:38:08  time: 0.4214  data_time: 0.0108  memory: 4857  grad_norm: 99.8621  loss: 35.7223  decode.loss_cls: 1.1443  decode.loss_mask: 0.7287  decode.loss_dice: 1.4171  decode.d0.loss_cls: 3.1132  decode.d0.loss_mask: 0.7580  decode.d0.loss_dice: 1.5510  decode.d1.loss_cls: 1.2756  decode.d1.loss_mask: 0.8204  decode.d1.loss_dice: 1.5734  decode.d2.loss_cls: 1.2138  decode.d2.loss_mask: 0.7407  decode.d2.loss_dice: 1.4929  decode.d3.loss_cls: 1.2431  decode.d3.loss_mask: 0.6954  decode.d3.loss_dice: 1.4213  decode.d4.loss_cls: 1.2039  decode.d4.loss_mask: 0.6971  decode.d4.loss_dice: 1.4181  decode.d5.loss_cls: 1.2066  decode.d5.loss_mask: 0.7197  decode.d5.loss_dice: 1.4035  decode.d6.loss_cls: 1.1929  decode.d6.loss_mask: 0.7026  decode.d6.loss_dice: 1.3985  decode.d7.loss_cls: 1.1715  decode.d7.loss_mask: 0.7076  decode.d7.loss_dice: 1.3992  decode.d8.loss_cls: 1.1546  decode.d8.loss_mask: 0.7157  decode.d8.loss_dice: 1.4420
2023/05/24 08:16:02 - mmengine - INFO - Iter(train) [113100/160000]  lr: 3.3140e-06  eta: 5:37:46  time: 0.4260  data_time: 0.0108  memory: 4904  grad_norm: 95.9215  loss: 35.4990  decode.loss_cls: 1.2517  decode.loss_mask: 0.7117  decode.loss_dice: 1.3371  decode.d0.loss_cls: 3.0127  decode.d0.loss_mask: 0.7251  decode.d0.loss_dice: 1.5632  decode.d1.loss_cls: 1.4124  decode.d1.loss_mask: 0.7176  decode.d1.loss_dice: 1.4691  decode.d2.loss_cls: 1.3991  decode.d2.loss_mask: 0.6846  decode.d2.loss_dice: 1.3796  decode.d3.loss_cls: 1.2649  decode.d3.loss_mask: 0.7144  decode.d3.loss_dice: 1.3300  decode.d4.loss_cls: 1.3202  decode.d4.loss_mask: 0.6990  decode.d4.loss_dice: 1.3642  decode.d5.loss_cls: 1.2566  decode.d5.loss_mask: 0.7190  decode.d5.loss_dice: 1.3588  decode.d6.loss_cls: 1.2449  decode.d6.loss_mask: 0.7025  decode.d6.loss_dice: 1.3344  decode.d7.loss_cls: 1.2538  decode.d7.loss_mask: 0.7032  decode.d7.loss_dice: 1.2994  decode.d8.loss_cls: 1.2252  decode.d8.loss_mask: 0.7078  decode.d8.loss_dice: 1.3368
2023/05/24 08:16:23 - mmengine - INFO - Iter(train) [113150/160000]  lr: 3.3108e-06  eta: 5:37:24  time: 0.4264  data_time: 0.0106  memory: 4859  grad_norm: 90.9587  loss: 32.0003  decode.loss_cls: 0.9247  decode.loss_mask: 0.8307  decode.loss_dice: 1.2043  decode.d0.loss_cls: 2.6658  decode.d0.loss_mask: 0.8949  decode.d0.loss_dice: 1.4117  decode.d1.loss_cls: 0.9846  decode.d1.loss_mask: 0.8541  decode.d1.loss_dice: 1.2949  decode.d2.loss_cls: 1.0478  decode.d2.loss_mask: 0.8039  decode.d2.loss_dice: 1.2289  decode.d3.loss_cls: 0.9924  decode.d3.loss_mask: 0.8237  decode.d3.loss_dice: 1.2189  decode.d4.loss_cls: 0.9411  decode.d4.loss_mask: 0.8140  decode.d4.loss_dice: 1.2130  decode.d5.loss_cls: 0.9499  decode.d5.loss_mask: 0.8317  decode.d5.loss_dice: 1.2047  decode.d6.loss_cls: 0.9442  decode.d6.loss_mask: 0.8408  decode.d6.loss_dice: 1.1968  decode.d7.loss_cls: 0.9317  decode.d7.loss_mask: 0.8233  decode.d7.loss_dice: 1.1913  decode.d8.loss_cls: 0.9026  decode.d8.loss_mask: 0.8368  decode.d8.loss_dice: 1.1971
2023/05/24 08:16:44 - mmengine - INFO - Iter(train) [113200/160000]  lr: 3.3076e-06  eta: 5:37:03  time: 0.4317  data_time: 0.0104  memory: 4898  grad_norm: 90.3421  loss: 35.4258  decode.loss_cls: 1.1959  decode.loss_mask: 0.8196  decode.loss_dice: 1.2764  decode.d0.loss_cls: 3.3074  decode.d0.loss_mask: 0.8454  decode.d0.loss_dice: 1.5256  decode.d1.loss_cls: 1.2452  decode.d1.loss_mask: 0.8436  decode.d1.loss_dice: 1.3851  decode.d2.loss_cls: 1.1918  decode.d2.loss_mask: 0.8174  decode.d2.loss_dice: 1.3311  decode.d3.loss_cls: 1.2092  decode.d3.loss_mask: 0.8223  decode.d3.loss_dice: 1.2969  decode.d4.loss_cls: 1.1507  decode.d4.loss_mask: 0.8128  decode.d4.loss_dice: 1.3088  decode.d5.loss_cls: 1.1784  decode.d5.loss_mask: 0.8617  decode.d5.loss_dice: 1.3016  decode.d6.loss_cls: 1.1518  decode.d6.loss_mask: 0.8225  decode.d6.loss_dice: 1.2840  decode.d7.loss_cls: 1.1062  decode.d7.loss_mask: 0.8139  decode.d7.loss_dice: 1.2828  decode.d8.loss_cls: 1.1512  decode.d8.loss_mask: 0.8233  decode.d8.loss_dice: 1.2632
2023/05/24 08:17:06 - mmengine - INFO - Iter(train) [113250/160000]  lr: 3.3044e-06  eta: 5:36:41  time: 0.4553  data_time: 0.0108  memory: 4836  grad_norm: 88.0005  loss: 28.1095  decode.loss_cls: 1.2160  decode.loss_mask: 0.5011  decode.loss_dice: 0.8511  decode.d0.loss_cls: 2.7950  decode.d0.loss_mask: 0.5629  decode.d0.loss_dice: 1.0444  decode.d1.loss_cls: 1.2936  decode.d1.loss_mask: 0.5445  decode.d1.loss_dice: 0.9409  decode.d2.loss_cls: 1.2625  decode.d2.loss_mask: 0.5325  decode.d2.loss_dice: 0.8709  decode.d3.loss_cls: 1.2408  decode.d3.loss_mask: 0.5200  decode.d3.loss_dice: 0.8639  decode.d4.loss_cls: 1.2465  decode.d4.loss_mask: 0.5145  decode.d4.loss_dice: 0.8885  decode.d5.loss_cls: 1.2228  decode.d5.loss_mask: 0.5174  decode.d5.loss_dice: 0.8732  decode.d6.loss_cls: 1.2537  decode.d6.loss_mask: 0.5078  decode.d6.loss_dice: 0.8606  decode.d7.loss_cls: 1.2141  decode.d7.loss_mask: 0.5226  decode.d7.loss_dice: 0.8704  decode.d8.loss_cls: 1.1852  decode.d8.loss_mask: 0.5104  decode.d8.loss_dice: 0.8811
2023/05/24 08:17:29 - mmengine - INFO - Iter(train) [113300/160000]  lr: 3.3013e-06  eta: 5:36:20  time: 0.4737  data_time: 0.0103  memory: 4919  grad_norm: 103.1055  loss: 36.5310  decode.loss_cls: 1.1650  decode.loss_mask: 0.8012  decode.loss_dice: 1.3750  decode.d0.loss_cls: 3.1107  decode.d0.loss_mask: 0.9253  decode.d0.loss_dice: 1.5310  decode.d1.loss_cls: 1.3006  decode.d1.loss_mask: 0.9149  decode.d1.loss_dice: 1.4956  decode.d2.loss_cls: 1.2984  decode.d2.loss_mask: 0.8179  decode.d2.loss_dice: 1.4368  decode.d3.loss_cls: 1.2268  decode.d3.loss_mask: 0.8310  decode.d3.loss_dice: 1.3741  decode.d4.loss_cls: 1.2141  decode.d4.loss_mask: 0.8086  decode.d4.loss_dice: 1.3533  decode.d5.loss_cls: 1.2477  decode.d5.loss_mask: 0.7946  decode.d5.loss_dice: 1.3791  decode.d6.loss_cls: 1.1682  decode.d6.loss_mask: 0.8107  decode.d6.loss_dice: 1.4067  decode.d7.loss_cls: 1.1779  decode.d7.loss_mask: 0.8025  decode.d7.loss_dice: 1.3998  decode.d8.loss_cls: 1.1682  decode.d8.loss_mask: 0.7994  decode.d8.loss_dice: 1.3958
2023/05/24 08:17:51 - mmengine - INFO - Iter(train) [113350/160000]  lr: 3.2981e-06  eta: 5:35:59  time: 0.4193  data_time: 0.0106  memory: 4901  grad_norm: 90.9006  loss: 38.2877  decode.loss_cls: 1.2119  decode.loss_mask: 0.7724  decode.loss_dice: 1.5330  decode.d0.loss_cls: 3.3640  decode.d0.loss_mask: 0.8013  decode.d0.loss_dice: 1.7714  decode.d1.loss_cls: 1.4645  decode.d1.loss_mask: 0.8319  decode.d1.loss_dice: 1.6364  decode.d2.loss_cls: 1.3639  decode.d2.loss_mask: 0.7942  decode.d2.loss_dice: 1.6082  decode.d3.loss_cls: 1.3034  decode.d3.loss_mask: 0.7705  decode.d3.loss_dice: 1.5023  decode.d4.loss_cls: 1.2918  decode.d4.loss_mask: 0.7666  decode.d4.loss_dice: 1.5322  decode.d5.loss_cls: 1.2319  decode.d5.loss_mask: 0.7934  decode.d5.loss_dice: 1.5245  decode.d6.loss_cls: 1.2950  decode.d6.loss_mask: 0.7584  decode.d6.loss_dice: 1.4769  decode.d7.loss_cls: 1.1881  decode.d7.loss_mask: 0.7678  decode.d7.loss_dice: 1.4984  decode.d8.loss_cls: 1.1824  decode.d8.loss_mask: 0.7771  decode.d8.loss_dice: 1.4740
2023/05/24 08:18:14 - mmengine - INFO - Iter(train) [113400/160000]  lr: 3.2949e-06  eta: 5:35:37  time: 0.4729  data_time: 0.0103  memory: 4901  grad_norm: 93.0016  loss: 37.5231  decode.loss_cls: 1.3352  decode.loss_mask: 0.5773  decode.loss_dice: 1.5444  decode.d0.loss_cls: 3.1332  decode.d0.loss_mask: 0.6808  decode.d0.loss_dice: 1.7943  decode.d1.loss_cls: 1.5031  decode.d1.loss_mask: 0.6280  decode.d1.loss_dice: 1.6647  decode.d2.loss_cls: 1.4295  decode.d2.loss_mask: 0.6150  decode.d2.loss_dice: 1.6184  decode.d3.loss_cls: 1.4359  decode.d3.loss_mask: 0.5826  decode.d3.loss_dice: 1.5958  decode.d4.loss_cls: 1.3877  decode.d4.loss_mask: 0.5989  decode.d4.loss_dice: 1.5479  decode.d5.loss_cls: 1.3672  decode.d5.loss_mask: 0.5778  decode.d5.loss_dice: 1.5366  decode.d6.loss_cls: 1.3989  decode.d6.loss_mask: 0.5797  decode.d6.loss_dice: 1.5422  decode.d7.loss_cls: 1.3350  decode.d7.loss_mask: 0.5892  decode.d7.loss_dice: 1.5207  decode.d8.loss_cls: 1.3215  decode.d8.loss_mask: 0.5806  decode.d8.loss_dice: 1.5011
2023/05/24 08:18:38 - mmengine - INFO - Iter(train) [113450/160000]  lr: 3.2917e-06  eta: 5:35:17  time: 0.4723  data_time: 0.0103  memory: 4865  grad_norm: 87.6776  loss: 33.0588  decode.loss_cls: 1.1492  decode.loss_mask: 0.7653  decode.loss_dice: 1.0934  decode.d0.loss_cls: 3.1838  decode.d0.loss_mask: 0.7849  decode.d0.loss_dice: 1.3975  decode.d1.loss_cls: 1.2968  decode.d1.loss_mask: 0.8171  decode.d1.loss_dice: 1.2166  decode.d2.loss_cls: 1.2405  decode.d2.loss_mask: 0.7745  decode.d2.loss_dice: 1.1578  decode.d3.loss_cls: 1.2169  decode.d3.loss_mask: 0.7582  decode.d3.loss_dice: 1.1233  decode.d4.loss_cls: 1.2375  decode.d4.loss_mask: 0.7572  decode.d4.loss_dice: 1.1023  decode.d5.loss_cls: 1.1449  decode.d5.loss_mask: 0.7561  decode.d5.loss_dice: 1.1048  decode.d6.loss_cls: 1.1377  decode.d6.loss_mask: 0.7611  decode.d6.loss_dice: 1.1000  decode.d7.loss_cls: 1.1237  decode.d7.loss_mask: 0.7666  decode.d7.loss_dice: 1.1202  decode.d8.loss_cls: 1.1379  decode.d8.loss_mask: 0.7597  decode.d8.loss_dice: 1.0732
2023/05/24 08:18:59 - mmengine - INFO - Iter(train) [113500/160000]  lr: 3.2885e-06  eta: 5:34:55  time: 0.4278  data_time: 0.0104  memory: 4856  grad_norm: 92.8016  loss: 34.8685  decode.loss_cls: 1.0144  decode.loss_mask: 0.7980  decode.loss_dice: 1.3532  decode.d0.loss_cls: 3.2926  decode.d0.loss_mask: 0.8306  decode.d0.loss_dice: 1.5210  decode.d1.loss_cls: 1.2737  decode.d1.loss_mask: 0.8113  decode.d1.loss_dice: 1.3871  decode.d2.loss_cls: 1.1199  decode.d2.loss_mask: 0.7857  decode.d2.loss_dice: 1.3825  decode.d3.loss_cls: 1.0979  decode.d3.loss_mask: 0.7831  decode.d3.loss_dice: 1.3568  decode.d4.loss_cls: 1.0859  decode.d4.loss_mask: 0.8106  decode.d4.loss_dice: 1.3673  decode.d5.loss_cls: 1.0735  decode.d5.loss_mask: 0.8220  decode.d5.loss_dice: 1.3509  decode.d6.loss_cls: 1.0718  decode.d6.loss_mask: 0.7839  decode.d6.loss_dice: 1.3315  decode.d7.loss_cls: 1.0227  decode.d7.loss_mask: 0.8149  decode.d7.loss_dice: 1.3470  decode.d8.loss_cls: 1.0649  decode.d8.loss_mask: 0.7971  decode.d8.loss_dice: 1.3168
2023/05/24 08:19:22 - mmengine - INFO - Iter(train) [113550/160000]  lr: 3.2853e-06  eta: 5:34:34  time: 0.4183  data_time: 0.0107  memory: 4829  grad_norm: 132.3084  loss: 32.2284  decode.loss_cls: 1.0121  decode.loss_mask: 0.7639  decode.loss_dice: 1.1058  decode.d0.loss_cls: 3.1568  decode.d0.loss_mask: 0.8436  decode.d0.loss_dice: 1.3370  decode.d1.loss_cls: 1.1055  decode.d1.loss_mask: 0.8208  decode.d1.loss_dice: 1.2568  decode.d2.loss_cls: 1.1023  decode.d2.loss_mask: 0.8068  decode.d2.loss_dice: 1.2074  decode.d3.loss_cls: 1.0646  decode.d3.loss_mask: 0.8142  decode.d3.loss_dice: 1.1810  decode.d4.loss_cls: 0.9887  decode.d4.loss_mask: 0.8160  decode.d4.loss_dice: 1.1556  decode.d5.loss_cls: 0.9988  decode.d5.loss_mask: 0.7984  decode.d5.loss_dice: 1.1444  decode.d6.loss_cls: 0.9966  decode.d6.loss_mask: 0.7930  decode.d6.loss_dice: 1.1466  decode.d7.loss_cls: 1.0088  decode.d7.loss_mask: 0.7735  decode.d7.loss_dice: 1.1253  decode.d8.loss_cls: 0.9947  decode.d8.loss_mask: 0.7727  decode.d8.loss_dice: 1.1369
2023/05/24 08:19:43 - mmengine - INFO - Iter(train) [113600/160000]  lr: 3.2822e-06  eta: 5:34:12  time: 0.4220  data_time: 0.0107  memory: 4885  grad_norm: 104.6456  loss: 33.1206  decode.loss_cls: 1.1722  decode.loss_mask: 0.6186  decode.loss_dice: 1.1982  decode.d0.loss_cls: 3.0112  decode.d0.loss_mask: 0.7218  decode.d0.loss_dice: 1.4337  decode.d1.loss_cls: 1.2713  decode.d1.loss_mask: 0.7028  decode.d1.loss_dice: 1.2929  decode.d2.loss_cls: 1.2103  decode.d2.loss_mask: 0.6792  decode.d2.loss_dice: 1.2757  decode.d3.loss_cls: 1.2176  decode.d3.loss_mask: 0.7208  decode.d3.loss_dice: 1.2313  decode.d4.loss_cls: 1.1941  decode.d4.loss_mask: 0.6974  decode.d4.loss_dice: 1.2051  decode.d5.loss_cls: 1.1763  decode.d5.loss_mask: 0.6944  decode.d5.loss_dice: 1.2223  decode.d6.loss_cls: 1.2333  decode.d6.loss_mask: 0.6574  decode.d6.loss_dice: 1.1915  decode.d7.loss_cls: 1.2137  decode.d7.loss_mask: 0.6562  decode.d7.loss_dice: 1.2025  decode.d8.loss_cls: 1.1737  decode.d8.loss_mask: 0.6637  decode.d8.loss_dice: 1.1814
2023/05/24 08:20:05 - mmengine - INFO - Iter(train) [113650/160000]  lr: 3.2790e-06  eta: 5:33:51  time: 0.4202  data_time: 0.0104  memory: 4847  grad_norm: 78.0201  loss: 40.5124  decode.loss_cls: 1.5074  decode.loss_mask: 0.8506  decode.loss_dice: 1.3445  decode.d0.loss_cls: 3.7544  decode.d0.loss_mask: 0.9480  decode.d0.loss_dice: 1.6730  decode.d1.loss_cls: 1.7795  decode.d1.loss_mask: 0.8629  decode.d1.loss_dice: 1.3860  decode.d2.loss_cls: 1.8068  decode.d2.loss_mask: 0.8336  decode.d2.loss_dice: 1.3836  decode.d3.loss_cls: 1.6654  decode.d3.loss_mask: 0.8247  decode.d3.loss_dice: 1.3348  decode.d4.loss_cls: 1.6079  decode.d4.loss_mask: 0.8290  decode.d4.loss_dice: 1.3419  decode.d5.loss_cls: 1.5354  decode.d5.loss_mask: 0.8494  decode.d5.loss_dice: 1.3361  decode.d6.loss_cls: 1.5143  decode.d6.loss_mask: 0.8487  decode.d6.loss_dice: 1.3191  decode.d7.loss_cls: 1.5018  decode.d7.loss_mask: 0.8392  decode.d7.loss_dice: 1.3580  decode.d8.loss_cls: 1.4970  decode.d8.loss_mask: 0.8492  decode.d8.loss_dice: 1.3301
2023/05/24 08:20:26 - mmengine - INFO - Iter(train) [113700/160000]  lr: 3.2758e-06  eta: 5:33:29  time: 0.4377  data_time: 0.0107  memory: 4838  grad_norm: 99.5635  loss: 31.4694  decode.loss_cls: 0.9807  decode.loss_mask: 0.6525  decode.loss_dice: 1.2299  decode.d0.loss_cls: 2.9717  decode.d0.loss_mask: 0.6464  decode.d0.loss_dice: 1.4196  decode.d1.loss_cls: 1.1441  decode.d1.loss_mask: 0.6445  decode.d1.loss_dice: 1.3907  decode.d2.loss_cls: 1.0738  decode.d2.loss_mask: 0.6411  decode.d2.loss_dice: 1.3800  decode.d3.loss_cls: 1.0535  decode.d3.loss_mask: 0.6267  decode.d3.loss_dice: 1.2939  decode.d4.loss_cls: 1.0407  decode.d4.loss_mask: 0.6379  decode.d4.loss_dice: 1.2522  decode.d5.loss_cls: 1.0299  decode.d5.loss_mask: 0.6413  decode.d5.loss_dice: 1.2257  decode.d6.loss_cls: 1.0142  decode.d6.loss_mask: 0.6201  decode.d6.loss_dice: 1.2031  decode.d7.loss_cls: 0.9846  decode.d7.loss_mask: 0.6257  decode.d7.loss_dice: 1.2176  decode.d8.loss_cls: 0.9608  decode.d8.loss_mask: 0.6486  decode.d8.loss_dice: 1.2180
2023/05/24 08:20:48 - mmengine - INFO - Iter(train) [113750/160000]  lr: 3.2726e-06  eta: 5:33:07  time: 0.4228  data_time: 0.0104  memory: 4856  grad_norm: 95.8752  loss: 31.3227  decode.loss_cls: 0.9937  decode.loss_mask: 0.7839  decode.loss_dice: 1.0642  decode.d0.loss_cls: 2.8071  decode.d0.loss_mask: 0.8090  decode.d0.loss_dice: 1.3304  decode.d1.loss_cls: 1.0683  decode.d1.loss_mask: 0.8169  decode.d1.loss_dice: 1.2214  decode.d2.loss_cls: 0.9938  decode.d2.loss_mask: 0.8126  decode.d2.loss_dice: 1.1656  decode.d3.loss_cls: 0.9822  decode.d3.loss_mask: 0.7960  decode.d3.loss_dice: 1.1006  decode.d4.loss_cls: 1.0140  decode.d4.loss_mask: 0.7933  decode.d4.loss_dice: 1.0850  decode.d5.loss_cls: 1.0100  decode.d5.loss_mask: 0.7962  decode.d5.loss_dice: 1.1127  decode.d6.loss_cls: 1.1247  decode.d6.loss_mask: 0.7842  decode.d6.loss_dice: 1.0895  decode.d7.loss_cls: 0.9723  decode.d7.loss_mask: 0.7885  decode.d7.loss_dice: 1.1116  decode.d8.loss_cls: 1.0213  decode.d8.loss_mask: 0.7875  decode.d8.loss_dice: 1.0861
2023/05/24 08:21:09 - mmengine - INFO - Iter(train) [113800/160000]  lr: 3.2694e-06  eta: 5:32:46  time: 0.4206  data_time: 0.0104  memory: 5008  grad_norm: 114.1938  loss: 36.2980  decode.loss_cls: 1.3050  decode.loss_mask: 0.7440  decode.loss_dice: 1.2920  decode.d0.loss_cls: 3.0959  decode.d0.loss_mask: 0.8789  decode.d0.loss_dice: 1.6087  decode.d1.loss_cls: 1.3480  decode.d1.loss_mask: 0.8875  decode.d1.loss_dice: 1.4195  decode.d2.loss_cls: 1.3708  decode.d2.loss_mask: 0.8324  decode.d2.loss_dice: 1.3718  decode.d3.loss_cls: 1.3091  decode.d3.loss_mask: 0.7651  decode.d3.loss_dice: 1.3196  decode.d4.loss_cls: 1.2775  decode.d4.loss_mask: 0.7809  decode.d4.loss_dice: 1.3507  decode.d5.loss_cls: 1.2238  decode.d5.loss_mask: 0.7858  decode.d5.loss_dice: 1.3699  decode.d6.loss_cls: 1.2381  decode.d6.loss_mask: 0.7672  decode.d6.loss_dice: 1.2997  decode.d7.loss_cls: 1.3080  decode.d7.loss_mask: 0.7278  decode.d7.loss_dice: 1.3184  decode.d8.loss_cls: 1.2240  decode.d8.loss_mask: 0.7913  decode.d8.loss_dice: 1.2866
2023/05/24 08:21:33 - mmengine - INFO - Iter(train) [113850/160000]  lr: 3.2662e-06  eta: 5:32:25  time: 0.4739  data_time: 0.0105  memory: 4845  grad_norm: 108.8125  loss: 39.6368  decode.loss_cls: 1.2548  decode.loss_mask: 0.9101  decode.loss_dice: 1.4947  decode.d0.loss_cls: 3.3864  decode.d0.loss_mask: 0.9491  decode.d0.loss_dice: 1.6224  decode.d1.loss_cls: 1.4987  decode.d1.loss_mask: 0.9197  decode.d1.loss_dice: 1.5623  decode.d2.loss_cls: 1.4837  decode.d2.loss_mask: 0.8562  decode.d2.loss_dice: 1.5013  decode.d3.loss_cls: 1.3445  decode.d3.loss_mask: 0.9142  decode.d3.loss_dice: 1.4804  decode.d4.loss_cls: 1.3563  decode.d4.loss_mask: 0.8651  decode.d4.loss_dice: 1.4929  decode.d5.loss_cls: 1.3930  decode.d5.loss_mask: 0.8588  decode.d5.loss_dice: 1.4855  decode.d6.loss_cls: 1.3123  decode.d6.loss_mask: 0.8891  decode.d6.loss_dice: 1.4661  decode.d7.loss_cls: 1.3310  decode.d7.loss_mask: 0.8879  decode.d7.loss_dice: 1.4865  decode.d8.loss_cls: 1.2904  decode.d8.loss_mask: 0.8829  decode.d8.loss_dice: 1.4605
2023/05/24 08:21:56 - mmengine - INFO - Iter(train) [113900/160000]  lr: 3.2631e-06  eta: 5:32:04  time: 0.4538  data_time: 0.0108  memory: 4906  grad_norm: 89.1176  loss: 32.4879  decode.loss_cls: 1.0411  decode.loss_mask: 0.7286  decode.loss_dice: 1.1766  decode.d0.loss_cls: 3.2799  decode.d0.loss_mask: 0.7628  decode.d0.loss_dice: 1.3924  decode.d1.loss_cls: 1.2191  decode.d1.loss_mask: 0.7413  decode.d1.loss_dice: 1.2554  decode.d2.loss_cls: 1.1824  decode.d2.loss_mask: 0.7255  decode.d2.loss_dice: 1.2323  decode.d3.loss_cls: 1.1328  decode.d3.loss_mask: 0.7145  decode.d3.loss_dice: 1.1599  decode.d4.loss_cls: 1.0962  decode.d4.loss_mask: 0.7051  decode.d4.loss_dice: 1.1592  decode.d5.loss_cls: 1.1395  decode.d5.loss_mask: 0.7219  decode.d5.loss_dice: 1.1376  decode.d6.loss_cls: 1.0542  decode.d6.loss_mask: 0.7202  decode.d6.loss_dice: 1.1674  decode.d7.loss_cls: 1.0307  decode.d7.loss_mask: 0.7113  decode.d7.loss_dice: 1.1411  decode.d8.loss_cls: 1.0935  decode.d8.loss_mask: 0.7220  decode.d8.loss_dice: 1.1435
2023/05/24 08:22:17 - mmengine - INFO - Iter(train) [113950/160000]  lr: 3.2599e-06  eta: 5:31:42  time: 0.4163  data_time: 0.0105  memory: 4845  grad_norm: 98.2115  loss: 37.8816  decode.loss_cls: 1.2226  decode.loss_mask: 0.7430  decode.loss_dice: 1.4491  decode.d0.loss_cls: 3.3182  decode.d0.loss_mask: 0.8677  decode.d0.loss_dice: 1.7942  decode.d1.loss_cls: 1.3606  decode.d1.loss_mask: 0.7734  decode.d1.loss_dice: 1.6464  decode.d2.loss_cls: 1.3542  decode.d2.loss_mask: 0.7537  decode.d2.loss_dice: 1.5835  decode.d3.loss_cls: 1.2546  decode.d3.loss_mask: 0.7784  decode.d3.loss_dice: 1.5246  decode.d4.loss_cls: 1.2710  decode.d4.loss_mask: 0.7607  decode.d4.loss_dice: 1.5115  decode.d5.loss_cls: 1.2836  decode.d5.loss_mask: 0.7358  decode.d5.loss_dice: 1.4690  decode.d6.loss_cls: 1.2466  decode.d6.loss_mask: 0.7322  decode.d6.loss_dice: 1.5032  decode.d7.loss_cls: 1.2390  decode.d7.loss_mask: 0.7395  decode.d7.loss_dice: 1.4971  decode.d8.loss_cls: 1.2317  decode.d8.loss_mask: 0.7343  decode.d8.loss_dice: 1.5024
2023/05/24 08:22:39 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 08:22:39 - mmengine - INFO - Iter(train) [114000/160000]  lr: 3.2567e-06  eta: 5:31:20  time: 0.4327  data_time: 0.0106  memory: 4847  grad_norm: 100.9358  loss: 30.8071  decode.loss_cls: 1.0153  decode.loss_mask: 0.6698  decode.loss_dice: 1.1389  decode.d0.loss_cls: 2.8611  decode.d0.loss_mask: 0.7198  decode.d0.loss_dice: 1.3581  decode.d1.loss_cls: 1.1126  decode.d1.loss_mask: 0.7226  decode.d1.loss_dice: 1.2455  decode.d2.loss_cls: 1.0729  decode.d2.loss_mask: 0.6803  decode.d2.loss_dice: 1.2223  decode.d3.loss_cls: 1.0705  decode.d3.loss_mask: 0.6653  decode.d3.loss_dice: 1.1343  decode.d4.loss_cls: 1.0515  decode.d4.loss_mask: 0.6654  decode.d4.loss_dice: 1.1244  decode.d5.loss_cls: 1.0606  decode.d5.loss_mask: 0.6653  decode.d5.loss_dice: 1.1456  decode.d6.loss_cls: 1.0086  decode.d6.loss_mask: 0.6758  decode.d6.loss_dice: 1.1184  decode.d7.loss_cls: 0.9864  decode.d7.loss_mask: 0.6630  decode.d7.loss_dice: 1.1468  decode.d8.loss_cls: 1.0102  decode.d8.loss_mask: 0.6678  decode.d8.loss_dice: 1.1279
2023/05/24 08:22:39 - mmengine - INFO - Saving checkpoint at 114000 iterations
2023/05/24 08:23:05 - mmengine - INFO - Iter(train) [114050/160000]  lr: 3.2535e-06  eta: 5:31:01  time: 0.4265  data_time: 0.0108  memory: 4847  grad_norm: 90.3996  loss: 26.2881  decode.loss_cls: 0.8615  decode.loss_mask: 0.6521  decode.loss_dice: 0.8084  decode.d0.loss_cls: 2.8445  decode.d0.loss_mask: 0.7431  decode.d0.loss_dice: 0.9932  decode.d1.loss_cls: 0.9977  decode.d1.loss_mask: 0.6657  decode.d1.loss_dice: 0.8724  decode.d2.loss_cls: 0.9548  decode.d2.loss_mask: 0.6735  decode.d2.loss_dice: 0.8651  decode.d3.loss_cls: 0.9438  decode.d3.loss_mask: 0.6749  decode.d3.loss_dice: 0.8502  decode.d4.loss_cls: 0.9539  decode.d4.loss_mask: 0.6572  decode.d4.loss_dice: 0.7959  decode.d5.loss_cls: 0.9168  decode.d5.loss_mask: 0.6665  decode.d5.loss_dice: 0.8252  decode.d6.loss_cls: 0.8750  decode.d6.loss_mask: 0.6519  decode.d6.loss_dice: 0.8328  decode.d7.loss_cls: 0.9110  decode.d7.loss_mask: 0.6405  decode.d7.loss_dice: 0.8048  decode.d8.loss_cls: 0.8834  decode.d8.loss_mask: 0.6758  decode.d8.loss_dice: 0.7965
2023/05/24 08:23:26 - mmengine - INFO - Iter(train) [114100/160000]  lr: 3.2503e-06  eta: 5:30:39  time: 0.4309  data_time: 0.0109  memory: 4845  grad_norm: 99.6093  loss: 36.1929  decode.loss_cls: 1.2012  decode.loss_mask: 0.8304  decode.loss_dice: 1.3173  decode.d0.loss_cls: 3.1320  decode.d0.loss_mask: 0.8849  decode.d0.loss_dice: 1.5280  decode.d1.loss_cls: 1.4103  decode.d1.loss_mask: 0.8412  decode.d1.loss_dice: 1.3795  decode.d2.loss_cls: 1.3481  decode.d2.loss_mask: 0.8478  decode.d2.loss_dice: 1.3500  decode.d3.loss_cls: 1.2752  decode.d3.loss_mask: 0.8420  decode.d3.loss_dice: 1.2898  decode.d4.loss_cls: 1.2195  decode.d4.loss_mask: 0.8704  decode.d4.loss_dice: 1.3128  decode.d5.loss_cls: 1.1756  decode.d5.loss_mask: 0.8539  decode.d5.loss_dice: 1.3005  decode.d6.loss_cls: 1.1741  decode.d6.loss_mask: 0.8533  decode.d6.loss_dice: 1.3064  decode.d7.loss_cls: 1.1923  decode.d7.loss_mask: 0.8458  decode.d7.loss_dice: 1.2992  decode.d8.loss_cls: 1.1832  decode.d8.loss_mask: 0.8348  decode.d8.loss_dice: 1.2934
2023/05/24 08:23:47 - mmengine - INFO - Iter(train) [114150/160000]  lr: 3.2471e-06  eta: 5:30:17  time: 0.4250  data_time: 0.0109  memory: 4897  grad_norm: 127.9960  loss: 32.3581  decode.loss_cls: 1.1301  decode.loss_mask: 0.6730  decode.loss_dice: 1.1292  decode.d0.loss_cls: 2.8394  decode.d0.loss_mask: 0.7034  decode.d0.loss_dice: 1.3284  decode.d1.loss_cls: 1.1603  decode.d1.loss_mask: 0.7527  decode.d1.loss_dice: 1.2954  decode.d2.loss_cls: 1.2456  decode.d2.loss_mask: 0.6705  decode.d2.loss_dice: 1.2202  decode.d3.loss_cls: 1.2421  decode.d3.loss_mask: 0.6678  decode.d3.loss_dice: 1.1649  decode.d4.loss_cls: 1.2199  decode.d4.loss_mask: 0.6793  decode.d4.loss_dice: 1.1849  decode.d5.loss_cls: 1.1928  decode.d5.loss_mask: 0.6722  decode.d5.loss_dice: 1.2106  decode.d6.loss_cls: 1.1529  decode.d6.loss_mask: 0.6763  decode.d6.loss_dice: 1.1605  decode.d7.loss_cls: 1.1223  decode.d7.loss_mask: 0.6875  decode.d7.loss_dice: 1.2163  decode.d8.loss_cls: 1.1595  decode.d8.loss_mask: 0.6563  decode.d8.loss_dice: 1.1439
2023/05/24 08:24:09 - mmengine - INFO - Iter(train) [114200/160000]  lr: 3.2439e-06  eta: 5:29:55  time: 0.4319  data_time: 0.0106  memory: 4889  grad_norm: 89.8217  loss: 35.0885  decode.loss_cls: 1.2999  decode.loss_mask: 0.8316  decode.loss_dice: 1.1684  decode.d0.loss_cls: 2.8930  decode.d0.loss_mask: 0.9314  decode.d0.loss_dice: 1.3565  decode.d1.loss_cls: 1.3862  decode.d1.loss_mask: 0.8953  decode.d1.loss_dice: 1.3063  decode.d2.loss_cls: 1.2949  decode.d2.loss_mask: 0.8897  decode.d2.loss_dice: 1.2195  decode.d3.loss_cls: 1.3078  decode.d3.loss_mask: 0.8524  decode.d3.loss_dice: 1.1656  decode.d4.loss_cls: 1.2199  decode.d4.loss_mask: 0.8821  decode.d4.loss_dice: 1.1894  decode.d5.loss_cls: 1.2020  decode.d5.loss_mask: 0.8555  decode.d5.loss_dice: 1.1786  decode.d6.loss_cls: 1.2620  decode.d6.loss_mask: 0.8296  decode.d6.loss_dice: 1.1760  decode.d7.loss_cls: 1.2464  decode.d7.loss_mask: 0.8332  decode.d7.loss_dice: 1.1818  decode.d8.loss_cls: 1.2284  decode.d8.loss_mask: 0.8379  decode.d8.loss_dice: 1.1671
2023/05/24 08:24:30 - mmengine - INFO - Iter(train) [114250/160000]  lr: 3.2408e-06  eta: 5:29:33  time: 0.4203  data_time: 0.0106  memory: 4819  grad_norm: 97.9306  loss: 32.1204  decode.loss_cls: 1.0252  decode.loss_mask: 0.6960  decode.loss_dice: 1.1486  decode.d0.loss_cls: 2.8720  decode.d0.loss_mask: 0.7498  decode.d0.loss_dice: 1.3393  decode.d1.loss_cls: 1.3099  decode.d1.loss_mask: 0.7807  decode.d1.loss_dice: 1.2326  decode.d2.loss_cls: 1.1616  decode.d2.loss_mask: 0.7805  decode.d2.loss_dice: 1.2211  decode.d3.loss_cls: 1.0525  decode.d3.loss_mask: 0.7779  decode.d3.loss_dice: 1.2055  decode.d4.loss_cls: 1.0509  decode.d4.loss_mask: 0.7476  decode.d4.loss_dice: 1.1955  decode.d5.loss_cls: 1.0519  decode.d5.loss_mask: 0.7223  decode.d5.loss_dice: 1.1594  decode.d6.loss_cls: 1.0492  decode.d6.loss_mask: 0.7248  decode.d6.loss_dice: 1.1770  decode.d7.loss_cls: 1.0205  decode.d7.loss_mask: 0.7217  decode.d7.loss_dice: 1.1692  decode.d8.loss_cls: 1.0829  decode.d8.loss_mask: 0.7259  decode.d8.loss_dice: 1.1685
2023/05/24 08:24:51 - mmengine - INFO - Iter(train) [114300/160000]  lr: 3.2376e-06  eta: 5:29:12  time: 0.4258  data_time: 0.0106  memory: 4837  grad_norm: 92.6978  loss: 35.0057  decode.loss_cls: 1.0745  decode.loss_mask: 0.8034  decode.loss_dice: 1.2759  decode.d0.loss_cls: 3.1162  decode.d0.loss_mask: 0.9310  decode.d0.loss_dice: 1.5563  decode.d1.loss_cls: 1.2052  decode.d1.loss_mask: 0.8487  decode.d1.loss_dice: 1.5241  decode.d2.loss_cls: 1.1508  decode.d2.loss_mask: 0.8884  decode.d2.loss_dice: 1.4336  decode.d3.loss_cls: 1.0508  decode.d3.loss_mask: 0.8339  decode.d3.loss_dice: 1.3534  decode.d4.loss_cls: 1.0557  decode.d4.loss_mask: 0.8287  decode.d4.loss_dice: 1.3489  decode.d5.loss_cls: 1.0468  decode.d5.loss_mask: 0.8322  decode.d5.loss_dice: 1.3386  decode.d6.loss_cls: 1.0401  decode.d6.loss_mask: 0.8205  decode.d6.loss_dice: 1.2995  decode.d7.loss_cls: 1.0286  decode.d7.loss_mask: 0.8207  decode.d7.loss_dice: 1.3154  decode.d8.loss_cls: 1.0472  decode.d8.loss_mask: 0.8224  decode.d8.loss_dice: 1.3141
2023/05/24 08:25:13 - mmengine - INFO - Iter(train) [114350/160000]  lr: 3.2344e-06  eta: 5:28:50  time: 0.4287  data_time: 0.0105  memory: 4898  grad_norm: 97.2908  loss: 35.1339  decode.loss_cls: 1.3041  decode.loss_mask: 0.7384  decode.loss_dice: 1.2434  decode.d0.loss_cls: 2.9927  decode.d0.loss_mask: 0.8040  decode.d0.loss_dice: 1.5720  decode.d1.loss_cls: 1.3311  decode.d1.loss_mask: 0.7867  decode.d1.loss_dice: 1.3985  decode.d2.loss_cls: 1.2245  decode.d2.loss_mask: 0.7551  decode.d2.loss_dice: 1.3177  decode.d3.loss_cls: 1.2964  decode.d3.loss_mask: 0.7515  decode.d3.loss_dice: 1.2390  decode.d4.loss_cls: 1.2641  decode.d4.loss_mask: 0.7640  decode.d4.loss_dice: 1.2568  decode.d5.loss_cls: 1.2927  decode.d5.loss_mask: 0.7287  decode.d5.loss_dice: 1.2399  decode.d6.loss_cls: 1.2871  decode.d6.loss_mask: 0.7301  decode.d6.loss_dice: 1.2730  decode.d7.loss_cls: 1.2537  decode.d7.loss_mask: 0.7401  decode.d7.loss_dice: 1.2572  decode.d8.loss_cls: 1.3091  decode.d8.loss_mask: 0.7281  decode.d8.loss_dice: 1.2543
2023/05/24 08:25:34 - mmengine - INFO - Iter(train) [114400/160000]  lr: 3.2312e-06  eta: 5:28:28  time: 0.4345  data_time: 0.0113  memory: 4876  grad_norm: 113.8432  loss: 28.9911  decode.loss_cls: 0.9304  decode.loss_mask: 0.6656  decode.loss_dice: 0.9827  decode.d0.loss_cls: 2.9403  decode.d0.loss_mask: 0.7196  decode.d0.loss_dice: 1.1850  decode.d1.loss_cls: 1.2164  decode.d1.loss_mask: 0.7362  decode.d1.loss_dice: 1.0778  decode.d2.loss_cls: 1.1032  decode.d2.loss_mask: 0.6502  decode.d2.loss_dice: 0.9994  decode.d3.loss_cls: 1.0647  decode.d3.loss_mask: 0.6490  decode.d3.loss_dice: 0.9718  decode.d4.loss_cls: 0.9521  decode.d4.loss_mask: 0.6598  decode.d4.loss_dice: 1.0028  decode.d5.loss_cls: 0.9685  decode.d5.loss_mask: 0.6586  decode.d5.loss_dice: 0.9924  decode.d6.loss_cls: 0.9736  decode.d6.loss_mask: 0.6500  decode.d6.loss_dice: 0.9823  decode.d7.loss_cls: 0.9792  decode.d7.loss_mask: 0.6749  decode.d7.loss_dice: 1.0022  decode.d8.loss_cls: 0.9227  decode.d8.loss_mask: 0.6764  decode.d8.loss_dice: 1.0035
2023/05/24 08:25:56 - mmengine - INFO - Iter(train) [114450/160000]  lr: 3.2280e-06  eta: 5:28:07  time: 0.4258  data_time: 0.0106  memory: 4821  grad_norm: 115.9486  loss: 40.2882  decode.loss_cls: 1.3695  decode.loss_mask: 0.9566  decode.loss_dice: 1.4597  decode.d0.loss_cls: 3.2061  decode.d0.loss_mask: 0.9915  decode.d0.loss_dice: 1.7422  decode.d1.loss_cls: 1.4429  decode.d1.loss_mask: 0.9678  decode.d1.loss_dice: 1.5997  decode.d2.loss_cls: 1.3829  decode.d2.loss_mask: 0.9609  decode.d2.loss_dice: 1.5328  decode.d3.loss_cls: 1.3819  decode.d3.loss_mask: 0.9541  decode.d3.loss_dice: 1.5348  decode.d4.loss_cls: 1.3449  decode.d4.loss_mask: 0.9485  decode.d4.loss_dice: 1.4837  decode.d5.loss_cls: 1.3189  decode.d5.loss_mask: 0.9248  decode.d5.loss_dice: 1.4853  decode.d6.loss_cls: 1.3958  decode.d6.loss_mask: 0.9389  decode.d6.loss_dice: 1.4810  decode.d7.loss_cls: 1.2897  decode.d7.loss_mask: 0.9370  decode.d7.loss_dice: 1.5307  decode.d8.loss_cls: 1.3104  decode.d8.loss_mask: 0.9457  decode.d8.loss_dice: 1.4696
2023/05/24 08:26:17 - mmengine - INFO - Iter(train) [114500/160000]  lr: 3.2248e-06  eta: 5:27:45  time: 0.4244  data_time: 0.0103  memory: 5011  grad_norm: 80.0281  loss: 30.9694  decode.loss_cls: 1.0400  decode.loss_mask: 0.6236  decode.loss_dice: 1.1307  decode.d0.loss_cls: 3.2365  decode.d0.loss_mask: 0.7687  decode.d0.loss_dice: 1.3219  decode.d1.loss_cls: 1.2047  decode.d1.loss_mask: 0.6716  decode.d1.loss_dice: 1.2042  decode.d2.loss_cls: 1.1167  decode.d2.loss_mask: 0.6273  decode.d2.loss_dice: 1.1703  decode.d3.loss_cls: 1.0168  decode.d3.loss_mask: 0.6675  decode.d3.loss_dice: 1.1763  decode.d4.loss_cls: 1.0238  decode.d4.loss_mask: 0.6392  decode.d4.loss_dice: 1.1558  decode.d5.loss_cls: 1.0551  decode.d5.loss_mask: 0.6369  decode.d5.loss_dice: 1.1316  decode.d6.loss_cls: 1.0467  decode.d6.loss_mask: 0.6204  decode.d6.loss_dice: 1.1089  decode.d7.loss_cls: 1.0300  decode.d7.loss_mask: 0.6321  decode.d7.loss_dice: 1.1412  decode.d8.loss_cls: 1.0163  decode.d8.loss_mask: 0.6267  decode.d8.loss_dice: 1.1279
2023/05/24 08:26:38 - mmengine - INFO - Iter(train) [114550/160000]  lr: 3.2216e-06  eta: 5:27:23  time: 0.4272  data_time: 0.0105  memory: 4857  grad_norm: 97.4010  loss: 35.8002  decode.loss_cls: 1.1376  decode.loss_mask: 0.8766  decode.loss_dice: 1.2450  decode.d0.loss_cls: 3.1519  decode.d0.loss_mask: 0.9722  decode.d0.loss_dice: 1.6112  decode.d1.loss_cls: 1.1554  decode.d1.loss_mask: 0.9627  decode.d1.loss_dice: 1.3889  decode.d2.loss_cls: 1.1435  decode.d2.loss_mask: 0.9824  decode.d2.loss_dice: 1.3731  decode.d3.loss_cls: 1.1177  decode.d3.loss_mask: 0.9234  decode.d3.loss_dice: 1.2967  decode.d4.loss_cls: 1.1941  decode.d4.loss_mask: 0.8858  decode.d4.loss_dice: 1.3038  decode.d5.loss_cls: 1.1054  decode.d5.loss_mask: 0.8642  decode.d5.loss_dice: 1.3159  decode.d6.loss_cls: 1.1357  decode.d6.loss_mask: 0.8694  decode.d6.loss_dice: 1.2544  decode.d7.loss_cls: 1.0826  decode.d7.loss_mask: 0.8897  decode.d7.loss_dice: 1.2954  decode.d8.loss_cls: 1.0875  decode.d8.loss_mask: 0.8944  decode.d8.loss_dice: 1.2834
2023/05/24 08:27:02 - mmengine - INFO - Iter(train) [114600/160000]  lr: 3.2184e-06  eta: 5:27:02  time: 0.4760  data_time: 0.0106  memory: 4829  grad_norm: 142.3912  loss: 28.8744  decode.loss_cls: 1.1526  decode.loss_mask: 0.5780  decode.loss_dice: 0.8801  decode.d0.loss_cls: 3.0668  decode.d0.loss_mask: 0.5960  decode.d0.loss_dice: 1.0483  decode.d1.loss_cls: 1.3071  decode.d1.loss_mask: 0.5753  decode.d1.loss_dice: 0.9514  decode.d2.loss_cls: 1.3296  decode.d2.loss_mask: 0.5949  decode.d2.loss_dice: 0.9275  decode.d3.loss_cls: 1.2588  decode.d3.loss_mask: 0.5884  decode.d3.loss_dice: 0.9036  decode.d4.loss_cls: 1.2253  decode.d4.loss_mask: 0.5563  decode.d4.loss_dice: 0.8870  decode.d5.loss_cls: 1.1605  decode.d5.loss_mask: 0.5646  decode.d5.loss_dice: 0.8993  decode.d6.loss_cls: 1.1642  decode.d6.loss_mask: 0.5779  decode.d6.loss_dice: 0.8839  decode.d7.loss_cls: 1.1438  decode.d7.loss_mask: 0.5642  decode.d7.loss_dice: 0.9016  decode.d8.loss_cls: 1.1222  decode.d8.loss_mask: 0.5714  decode.d8.loss_dice: 0.8938
2023/05/24 08:27:26 - mmengine - INFO - Iter(train) [114650/160000]  lr: 3.2152e-06  eta: 5:26:42  time: 0.4789  data_time: 0.0111  memory: 4836  grad_norm: 85.5946  loss: 36.3547  decode.loss_cls: 1.1992  decode.loss_mask: 0.8531  decode.loss_dice: 1.3499  decode.d0.loss_cls: 3.1758  decode.d0.loss_mask: 0.8696  decode.d0.loss_dice: 1.5274  decode.d1.loss_cls: 1.3197  decode.d1.loss_mask: 0.8299  decode.d1.loss_dice: 1.4187  decode.d2.loss_cls: 1.2315  decode.d2.loss_mask: 0.8102  decode.d2.loss_dice: 1.3734  decode.d3.loss_cls: 1.2469  decode.d3.loss_mask: 0.8082  decode.d3.loss_dice: 1.3035  decode.d4.loss_cls: 1.2535  decode.d4.loss_mask: 0.8020  decode.d4.loss_dice: 1.3365  decode.d5.loss_cls: 1.2495  decode.d5.loss_mask: 0.8433  decode.d5.loss_dice: 1.3544  decode.d6.loss_cls: 1.1953  decode.d6.loss_mask: 0.8469  decode.d6.loss_dice: 1.3411  decode.d7.loss_cls: 1.2073  decode.d7.loss_mask: 0.8574  decode.d7.loss_dice: 1.3357  decode.d8.loss_cls: 1.2099  decode.d8.loss_mask: 0.8609  decode.d8.loss_dice: 1.3440
2023/05/24 08:27:48 - mmengine - INFO - Iter(train) [114700/160000]  lr: 3.2121e-06  eta: 5:26:20  time: 0.4270  data_time: 0.0105  memory: 4843  grad_norm: 173.5871  loss: 36.8877  decode.loss_cls: 1.4188  decode.loss_mask: 0.7548  decode.loss_dice: 1.2421  decode.d0.loss_cls: 3.2289  decode.d0.loss_mask: 0.8349  decode.d0.loss_dice: 1.4264  decode.d1.loss_cls: 1.3769  decode.d1.loss_mask: 0.8772  decode.d1.loss_dice: 1.3837  decode.d2.loss_cls: 1.4323  decode.d2.loss_mask: 0.8682  decode.d2.loss_dice: 1.3071  decode.d3.loss_cls: 1.3805  decode.d3.loss_mask: 0.8354  decode.d3.loss_dice: 1.2788  decode.d4.loss_cls: 1.3698  decode.d4.loss_mask: 0.8098  decode.d4.loss_dice: 1.2770  decode.d5.loss_cls: 1.4121  decode.d5.loss_mask: 0.7819  decode.d5.loss_dice: 1.2650  decode.d6.loss_cls: 1.3830  decode.d6.loss_mask: 0.7763  decode.d6.loss_dice: 1.2782  decode.d7.loss_cls: 1.3999  decode.d7.loss_mask: 0.7812  decode.d7.loss_dice: 1.2720  decode.d8.loss_cls: 1.4193  decode.d8.loss_mask: 0.7531  decode.d8.loss_dice: 1.2630
2023/05/24 08:28:09 - mmengine - INFO - Iter(train) [114750/160000]  lr: 3.2089e-06  eta: 5:25:58  time: 0.4249  data_time: 0.0110  memory: 4847  grad_norm: 89.8265  loss: 30.4736  decode.loss_cls: 0.7997  decode.loss_mask: 0.7060  decode.loss_dice: 1.2219  decode.d0.loss_cls: 2.8557  decode.d0.loss_mask: 0.7805  decode.d0.loss_dice: 1.4173  decode.d1.loss_cls: 0.9960  decode.d1.loss_mask: 0.7123  decode.d1.loss_dice: 1.3698  decode.d2.loss_cls: 0.8424  decode.d2.loss_mask: 0.6867  decode.d2.loss_dice: 1.2972  decode.d3.loss_cls: 0.8743  decode.d3.loss_mask: 0.7050  decode.d3.loss_dice: 1.2850  decode.d4.loss_cls: 0.8465  decode.d4.loss_mask: 0.7025  decode.d4.loss_dice: 1.2505  decode.d5.loss_cls: 0.8307  decode.d5.loss_mask: 0.7000  decode.d5.loss_dice: 1.2684  decode.d6.loss_cls: 0.8614  decode.d6.loss_mask: 0.6898  decode.d6.loss_dice: 1.2519  decode.d7.loss_cls: 0.7785  decode.d7.loss_mask: 0.7084  decode.d7.loss_dice: 1.2657  decode.d8.loss_cls: 0.8220  decode.d8.loss_mask: 0.7051  decode.d8.loss_dice: 1.2425
2023/05/24 08:28:30 - mmengine - INFO - Iter(train) [114800/160000]  lr: 3.2057e-06  eta: 5:25:37  time: 0.4219  data_time: 0.0108  memory: 4856  grad_norm: 84.9649  loss: 34.6895  decode.loss_cls: 1.0329  decode.loss_mask: 0.7268  decode.loss_dice: 1.3879  decode.d0.loss_cls: 3.1459  decode.d0.loss_mask: 0.7794  decode.d0.loss_dice: 1.5571  decode.d1.loss_cls: 1.1586  decode.d1.loss_mask: 0.8154  decode.d1.loss_dice: 1.4968  decode.d2.loss_cls: 1.1494  decode.d2.loss_mask: 0.7840  decode.d2.loss_dice: 1.4271  decode.d3.loss_cls: 1.1193  decode.d3.loss_mask: 0.7290  decode.d3.loss_dice: 1.3854  decode.d4.loss_cls: 1.0885  decode.d4.loss_mask: 0.7202  decode.d4.loss_dice: 1.3884  decode.d5.loss_cls: 1.0681  decode.d5.loss_mask: 0.7243  decode.d5.loss_dice: 1.3815  decode.d6.loss_cls: 1.0706  decode.d6.loss_mask: 0.7247  decode.d6.loss_dice: 1.3902  decode.d7.loss_cls: 1.0661  decode.d7.loss_mask: 0.7270  decode.d7.loss_dice: 1.4035  decode.d8.loss_cls: 1.1442  decode.d8.loss_mask: 0.7167  decode.d8.loss_dice: 1.3806
2023/05/24 08:28:51 - mmengine - INFO - Iter(train) [114850/160000]  lr: 3.2025e-06  eta: 5:25:15  time: 0.4158  data_time: 0.0105  memory: 4802  grad_norm: 77.3355  loss: 32.5060  decode.loss_cls: 1.0715  decode.loss_mask: 0.7045  decode.loss_dice: 1.1607  decode.d0.loss_cls: 2.8699  decode.d0.loss_mask: 0.7598  decode.d0.loss_dice: 1.3470  decode.d1.loss_cls: 1.3009  decode.d1.loss_mask: 0.7285  decode.d1.loss_dice: 1.2461  decode.d2.loss_cls: 1.1790  decode.d2.loss_mask: 0.7581  decode.d2.loss_dice: 1.2379  decode.d3.loss_cls: 1.1885  decode.d3.loss_mask: 0.7026  decode.d3.loss_dice: 1.1952  decode.d4.loss_cls: 1.1876  decode.d4.loss_mask: 0.6988  decode.d4.loss_dice: 1.1790  decode.d5.loss_cls: 1.1328  decode.d5.loss_mask: 0.6815  decode.d5.loss_dice: 1.1828  decode.d6.loss_cls: 1.1172  decode.d6.loss_mask: 0.6983  decode.d6.loss_dice: 1.1756  decode.d7.loss_cls: 1.1589  decode.d7.loss_mask: 0.7000  decode.d7.loss_dice: 1.1755  decode.d8.loss_cls: 1.1168  decode.d8.loss_mask: 0.6944  decode.d8.loss_dice: 1.1566
2023/05/24 08:29:13 - mmengine - INFO - Iter(train) [114900/160000]  lr: 3.1993e-06  eta: 5:24:53  time: 0.4250  data_time: 0.0105  memory: 4856  grad_norm: 84.8664  loss: 39.0150  decode.loss_cls: 1.2785  decode.loss_mask: 0.8170  decode.loss_dice: 1.4708  decode.d0.loss_cls: 3.3030  decode.d0.loss_mask: 0.9008  decode.d0.loss_dice: 1.7982  decode.d1.loss_cls: 1.3888  decode.d1.loss_mask: 0.9428  decode.d1.loss_dice: 1.7090  decode.d2.loss_cls: 1.3730  decode.d2.loss_mask: 0.8532  decode.d2.loss_dice: 1.5545  decode.d3.loss_cls: 1.3359  decode.d3.loss_mask: 0.8425  decode.d3.loss_dice: 1.5271  decode.d4.loss_cls: 1.3043  decode.d4.loss_mask: 0.8450  decode.d4.loss_dice: 1.4867  decode.d5.loss_cls: 1.2829  decode.d5.loss_mask: 0.8099  decode.d5.loss_dice: 1.5276  decode.d6.loss_cls: 1.2537  decode.d6.loss_mask: 0.7963  decode.d6.loss_dice: 1.5029  decode.d7.loss_cls: 1.2296  decode.d7.loss_mask: 0.8410  decode.d7.loss_dice: 1.4985  decode.d8.loss_cls: 1.2493  decode.d8.loss_mask: 0.8192  decode.d8.loss_dice: 1.4730
2023/05/24 08:29:34 - mmengine - INFO - Iter(train) [114950/160000]  lr: 3.1961e-06  eta: 5:24:31  time: 0.4169  data_time: 0.0104  memory: 4800  grad_norm: 99.7537  loss: 28.9916  decode.loss_cls: 1.0170  decode.loss_mask: 0.7318  decode.loss_dice: 0.9115  decode.d0.loss_cls: 2.7614  decode.d0.loss_mask: 0.7770  decode.d0.loss_dice: 0.9914  decode.d1.loss_cls: 1.1331  decode.d1.loss_mask: 0.7537  decode.d1.loss_dice: 0.9563  decode.d2.loss_cls: 1.0535  decode.d2.loss_mask: 0.7514  decode.d2.loss_dice: 0.9540  decode.d3.loss_cls: 1.1377  decode.d3.loss_mask: 0.7286  decode.d3.loss_dice: 0.9047  decode.d4.loss_cls: 1.0693  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 0.9113  decode.d5.loss_cls: 1.0639  decode.d5.loss_mask: 0.7212  decode.d5.loss_dice: 0.9082  decode.d6.loss_cls: 1.0055  decode.d6.loss_mask: 0.7490  decode.d6.loss_dice: 0.9276  decode.d7.loss_cls: 1.0334  decode.d7.loss_mask: 0.7318  decode.d7.loss_dice: 0.9240  decode.d8.loss_cls: 1.0028  decode.d8.loss_mask: 0.7205  decode.d8.loss_dice: 0.9132
2023/05/24 08:29:55 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 08:29:55 - mmengine - INFO - Iter(train) [115000/160000]  lr: 3.1929e-06  eta: 5:24:10  time: 0.4206  data_time: 0.0106  memory: 4888  grad_norm: 110.1446  loss: 29.7700  decode.loss_cls: 1.0796  decode.loss_mask: 0.5866  decode.loss_dice: 1.0621  decode.d0.loss_cls: 2.9324  decode.d0.loss_mask: 0.6150  decode.d0.loss_dice: 1.2344  decode.d1.loss_cls: 1.2511  decode.d1.loss_mask: 0.6079  decode.d1.loss_dice: 1.1881  decode.d2.loss_cls: 1.0632  decode.d2.loss_mask: 0.6048  decode.d2.loss_dice: 1.1556  decode.d3.loss_cls: 1.0312  decode.d3.loss_mask: 0.5897  decode.d3.loss_dice: 1.1339  decode.d4.loss_cls: 1.0421  decode.d4.loss_mask: 0.5743  decode.d4.loss_dice: 1.1094  decode.d5.loss_cls: 1.0482  decode.d5.loss_mask: 0.5760  decode.d5.loss_dice: 1.1126  decode.d6.loss_cls: 1.0961  decode.d6.loss_mask: 0.5738  decode.d6.loss_dice: 1.0722  decode.d7.loss_cls: 1.0490  decode.d7.loss_mask: 0.5889  decode.d7.loss_dice: 1.1045  decode.d8.loss_cls: 1.0012  decode.d8.loss_mask: 0.5925  decode.d8.loss_dice: 1.0935
2023/05/24 08:29:55 - mmengine - INFO - Saving checkpoint at 115000 iterations
2023/05/24 08:30:05 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:45  time: 0.0789  data_time: 0.0018  memory: 2167  
2023/05/24 08:30:09 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:42  time: 0.0890  data_time: 0.0018  memory: 2216  
2023/05/24 08:30:13 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:38  time: 0.0805  data_time: 0.0018  memory: 2167  
2023/05/24 08:30:17 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0947  data_time: 0.0019  memory: 2104  
2023/05/24 08:30:21 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0819  data_time: 0.0019  memory: 2831  
2023/05/24 08:30:26 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0805  data_time: 0.0020  memory: 2167  
2023/05/24 08:30:30 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0795  data_time: 0.0018  memory: 2167  
2023/05/24 08:30:34 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0799  data_time: 0.0021  memory: 2167  
2023/05/24 08:30:40 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0919  data_time: 0.0019  memory: 2944  
2023/05/24 08:30:44 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0796  data_time: 0.0018  memory: 2356  
2023/05/24 08:30:49 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0790  data_time: 0.0018  memory: 2217  
2023/05/24 08:30:53 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0776  data_time: 0.0017  memory: 2328  
2023/05/24 08:30:56 - mmengine - INFO - per class results:
2023/05/24 08:30:56 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 85.99 | 92.87 |
|     bicycle      | 70.99 | 83.03 |
|       car        | 60.27 | 84.03 |
|    motorcycle    | 82.93 | 89.35 |
|     airplane     | 86.36 | 93.03 |
|       bus        | 81.54 | 87.58 |
|      train       | 84.16 | 92.94 |
|      truck       | 55.75 | 75.69 |
|       boat       | 61.28 | 76.91 |
|  traffic light   | 67.66 |  84.8 |
|   fire hydrant   | 87.67 | 95.31 |
|    stop sign     | 91.72 | 96.84 |
|  parking meter   | 72.62 | 80.46 |
|      bench       | 47.52 | 70.82 |
|       bird       | 81.51 |  91.3 |
|       cat        | 84.92 | 91.48 |
|       dog        | 79.93 | 87.83 |
|      horse       | 79.03 | 89.59 |
|      sheep       | 87.59 | 94.43 |
|       cow        | 82.26 | 87.81 |
|     elephant     | 89.74 |  94.5 |
|       bear       | 91.98 | 94.92 |
|      zebra       | 89.97 |  93.2 |
|     giraffe      | 87.45 | 93.27 |
|     backpack     | 37.39 | 55.95 |
|     umbrella     | 78.95 | 88.34 |
|     handbag      | 33.97 | 55.83 |
|       tie        | 11.42 | 17.61 |
|     suitcase     | 78.54 | 92.27 |
|     frisbee      | 65.08 | 89.54 |
|       skis       | 43.17 |  58.1 |
|    snowboard     | 44.59 | 56.89 |
|   sports ball    | 53.65 | 73.75 |
|       kite       | 52.11 | 64.75 |
|   baseball bat   | 42.63 | 52.12 |
|  baseball glove  | 73.44 | 87.56 |
|    skateboard    | 75.74 | 87.87 |
|    surfboard     | 76.05 | 86.58 |
|  tennis racket   | 82.41 | 90.66 |
|      bottle      | 44.39 | 58.67 |
|    wine glass    | 57.93 | 76.65 |
|       cup        | 55.06 | 76.73 |
|       fork       | 33.57 | 42.62 |
|      knife       | 28.31 | 40.35 |
|      spoon       |  37.5 | 55.25 |
|       bowl       | 46.59 |  69.8 |
|      banana      | 67.97 | 89.13 |
|      apple       | 51.24 | 70.04 |
|     sandwich     | 35.71 | 46.21 |
|      orange      | 64.06 | 72.68 |
|     broccoli     | 52.54 | 62.48 |
|      carrot      | 53.24 | 59.27 |
|     hot dog      | 51.21 | 60.92 |
|      pizza       | 67.46 | 82.75 |
|      donut       | 68.12 | 79.85 |
|       cake       | 62.59 | 71.25 |
|      chair       | 45.45 | 59.98 |
|      couch       | 55.74 | 78.87 |
|   potted plant   | 29.65 | 41.05 |
|       bed        | 61.15 | 82.91 |
|   dining table   |  43.1 | 80.25 |
|      toilet      | 82.19 | 92.83 |
|        tv        | 70.81 | 84.41 |
|      laptop      | 73.81 | 89.79 |
|      mouse       | 75.85 | 89.36 |
|      remote      | 62.93 | 72.95 |
|     keyboard     | 63.49 | 79.96 |
|    cell phone    | 72.77 | 90.24 |
|    microwave     | 63.91 | 75.74 |
|       oven       | 55.56 | 73.67 |
|     toaster      | 42.05 | 54.11 |
|       sink       | 57.89 | 81.54 |
|   refrigerator   | 78.06 | 91.45 |
|       book       | 47.95 | 69.28 |
|      clock       | 72.12 | 82.78 |
|       vase       | 56.84 | 81.14 |
|     scissors     | 78.17 | 87.89 |
|    teddy bear    | 75.91 |  87.3 |
|    hair drier    |  50.6 | 55.64 |
|    toothbrush    | 50.74 | 77.53 |
|      banner      | 35.24 | 63.24 |
|     blanket      |  3.95 |  4.28 |
|      branch      | 17.79 | 22.35 |
|      bridge      | 32.73 | 48.21 |
|  building-other  |  53.2 | 69.67 |
|       bush       | 28.84 | 37.19 |
|     cabinet      | 54.86 | 69.64 |
|       cage       | 20.33 | 30.36 |
|    cardboard     | 43.49 | 52.15 |
|      carpet      | 50.63 | 73.18 |
|  ceiling-other   | 63.33 | 83.26 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 19.08 | 29.59 |
|      clouds      | 47.69 | 63.43 |
|     counter      |  28.3 | 46.24 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 63.36 | 79.73 |
|    desk-stuff    | 45.49 | 62.95 |
|       dirt       | 41.54 | 64.81 |
|    door-stuff    | 38.98 | 67.85 |
|      fence       | 31.55 | 56.85 |
|   floor-marble   |  7.69 |  8.86 |
|   floor-other    | 21.94 | 28.35 |
|   floor-stone    |  2.35 |  2.96 |
|    floor-tile    | 59.45 |  66.9 |
|    floor-wood    | 60.73 | 77.15 |
|      flower      | 43.43 | 65.34 |
|       fog        |  5.34 |  5.59 |
|    food-other    | 26.79 | 32.99 |
|      fruit       | 39.46 | 58.89 |
| furniture-other  | 15.33 |  20.9 |
|      grass       | 70.17 | 83.62 |
|      gravel      | 31.26 | 45.17 |
|   ground-other   |  3.56 |  4.29 |
|       hill       | 20.38 | 27.74 |
|      house       | 25.58 | 30.51 |
|      leaves      |  27.5 | 37.61 |
|      light       | 38.58 | 51.57 |
|       mat        |  1.35 |  1.41 |
|      metal       | 32.16 | 49.49 |
|   mirror-stuff   | 46.35 | 57.28 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 52.25 | 65.12 |
|       mud        |  6.29 |  7.57 |
|      napkin      | 11.55 | 11.64 |
|       net        | 42.59 | 60.97 |
|      paper       | 30.44 | 41.34 |
|     pavement     | 50.47 | 71.33 |
|      pillow      | 12.74 | 15.84 |
|   plant-other    | 19.29 | 34.21 |
|     plastic      | 20.97 |  27.4 |
|     platform     | 22.35 | 31.76 |
|   playingfield   | 68.04 | 87.37 |
|     railing      |  6.14 |  9.96 |
|     railroad     | 61.23 | 77.12 |
|      river       | 44.28 | 58.91 |
|       road       | 66.29 | 83.66 |
|       rock       | 44.52 |  69.4 |
|       roof       | 18.44 | 23.33 |
|       rug        | 29.52 | 44.19 |
|      salad       |  0.0  |  0.0  |
|       sand       | 64.72 | 69.73 |
|       sea        | 84.78 | 94.88 |
|      shelf       |  34.7 | 45.37 |
|    sky-other     | 70.64 | 86.82 |
|    skyscraper    | 34.19 | 44.44 |
|       snow       | 87.72 | 94.42 |
|   solid-other    |  0.24 |  0.26 |
|      stairs      | 24.14 | 41.06 |
|      stone       | 14.28 | 23.38 |
|      straw       | 25.56 | 31.18 |
| structural-other |  0.29 |  0.29 |
|      table       | 15.48 | 19.47 |
|       tent       |  7.6  |  9.85 |
|  textile-other   | 12.06 | 20.32 |
|      towel       | 31.71 | 43.43 |
|       tree       | 73.98 | 87.17 |
|    vegetable     | 30.61 | 39.02 |
|    wall-brick    | 48.65 | 65.68 |
|  wall-concrete   | 59.54 | 81.93 |
|    wall-other    | 18.58 | 28.41 |
|    wall-panel    |  0.62 |  0.67 |
|    wall-stone    | 29.54 | 37.73 |
|    wall-tile     | 65.35 | 81.84 |
|    wall-wood     | 40.14 | 55.79 |
|   water-other    | 22.33 | 31.67 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 50.02 | 56.83 |
|   window-other   |  46.2 | 74.57 |
|       wood       | 24.53 | 39.39 |
+------------------+-------+-------+
2023/05/24 08:30:56 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.1600  mIoU: 46.8400  mAcc: 58.8500  data_time: 0.0020  time: 0.0860
2023/05/24 08:31:17 - mmengine - INFO - Iter(train) [115050/160000]  lr: 3.1897e-06  eta: 5:23:48  time: 0.4254  data_time: 0.0106  memory: 4865  grad_norm: 99.0273  loss: 25.4038  decode.loss_cls: 0.8693  decode.loss_mask: 0.6046  decode.loss_dice: 0.8286  decode.d0.loss_cls: 2.5570  decode.d0.loss_mask: 0.6473  decode.d0.loss_dice: 0.9235  decode.d1.loss_cls: 1.0120  decode.d1.loss_mask: 0.6467  decode.d1.loss_dice: 0.8874  decode.d2.loss_cls: 0.9312  decode.d2.loss_mask: 0.6301  decode.d2.loss_dice: 0.8659  decode.d3.loss_cls: 0.9201  decode.d3.loss_mask: 0.6285  decode.d3.loss_dice: 0.8250  decode.d4.loss_cls: 0.8758  decode.d4.loss_mask: 0.6206  decode.d4.loss_dice: 0.8566  decode.d5.loss_cls: 0.8693  decode.d5.loss_mask: 0.6119  decode.d5.loss_dice: 0.8441  decode.d6.loss_cls: 0.8905  decode.d6.loss_mask: 0.6144  decode.d6.loss_dice: 0.8235  decode.d7.loss_cls: 0.8848  decode.d7.loss_mask: 0.6214  decode.d7.loss_dice: 0.8063  decode.d8.loss_cls: 0.8944  decode.d8.loss_mask: 0.6067  decode.d8.loss_dice: 0.8061
2023/05/24 08:31:39 - mmengine - INFO - Iter(train) [115100/160000]  lr: 3.1865e-06  eta: 5:23:27  time: 0.4258  data_time: 0.0104  memory: 4866  grad_norm: 104.5574  loss: 30.6206  decode.loss_cls: 1.0671  decode.loss_mask: 0.6671  decode.loss_dice: 1.0568  decode.d0.loss_cls: 2.9282  decode.d0.loss_mask: 0.7074  decode.d0.loss_dice: 1.2388  decode.d1.loss_cls: 1.1499  decode.d1.loss_mask: 0.7169  decode.d1.loss_dice: 1.1603  decode.d2.loss_cls: 1.1199  decode.d2.loss_mask: 0.6842  decode.d2.loss_dice: 1.1473  decode.d3.loss_cls: 1.0238  decode.d3.loss_mask: 0.6842  decode.d3.loss_dice: 1.1292  decode.d4.loss_cls: 1.0551  decode.d4.loss_mask: 0.6731  decode.d4.loss_dice: 1.0985  decode.d5.loss_cls: 1.0725  decode.d5.loss_mask: 0.6753  decode.d5.loss_dice: 1.0765  decode.d6.loss_cls: 1.0844  decode.d6.loss_mask: 0.6667  decode.d6.loss_dice: 1.0811  decode.d7.loss_cls: 1.0760  decode.d7.loss_mask: 0.6730  decode.d7.loss_dice: 1.0919  decode.d8.loss_cls: 1.0534  decode.d8.loss_mask: 0.6696  decode.d8.loss_dice: 1.0923
2023/05/24 08:32:00 - mmengine - INFO - Iter(train) [115150/160000]  lr: 3.1833e-06  eta: 5:23:05  time: 0.4139  data_time: 0.0104  memory: 4846  grad_norm: 94.3953  loss: 31.3555  decode.loss_cls: 1.1352  decode.loss_mask: 0.5735  decode.loss_dice: 1.1866  decode.d0.loss_cls: 2.8162  decode.d0.loss_mask: 0.6117  decode.d0.loss_dice: 1.3318  decode.d1.loss_cls: 1.2276  decode.d1.loss_mask: 0.5836  decode.d1.loss_dice: 1.2966  decode.d2.loss_cls: 1.1070  decode.d2.loss_mask: 0.6121  decode.d2.loss_dice: 1.2539  decode.d3.loss_cls: 1.1748  decode.d3.loss_mask: 0.5857  decode.d3.loss_dice: 1.2381  decode.d4.loss_cls: 1.1824  decode.d4.loss_mask: 0.5788  decode.d4.loss_dice: 1.2295  decode.d5.loss_cls: 1.1409  decode.d5.loss_mask: 0.5587  decode.d5.loss_dice: 1.1749  decode.d6.loss_cls: 1.1312  decode.d6.loss_mask: 0.5603  decode.d6.loss_dice: 1.2034  decode.d7.loss_cls: 1.1600  decode.d7.loss_mask: 0.5807  decode.d7.loss_dice: 1.1938  decode.d8.loss_cls: 1.1256  decode.d8.loss_mask: 0.6060  decode.d8.loss_dice: 1.1953
2023/05/24 08:32:22 - mmengine - INFO - Iter(train) [115200/160000]  lr: 3.1801e-06  eta: 5:22:43  time: 0.4236  data_time: 0.0105  memory: 4848  grad_norm: 86.7287  loss: 41.2418  decode.loss_cls: 1.4208  decode.loss_mask: 0.9675  decode.loss_dice: 1.4487  decode.d0.loss_cls: 3.3758  decode.d0.loss_mask: 0.9800  decode.d0.loss_dice: 1.7412  decode.d1.loss_cls: 1.5290  decode.d1.loss_mask: 0.9858  decode.d1.loss_dice: 1.5933  decode.d2.loss_cls: 1.4163  decode.d2.loss_mask: 0.9653  decode.d2.loss_dice: 1.5570  decode.d3.loss_cls: 1.4870  decode.d3.loss_mask: 0.9822  decode.d3.loss_dice: 1.5154  decode.d4.loss_cls: 1.3926  decode.d4.loss_mask: 0.9725  decode.d4.loss_dice: 1.4838  decode.d5.loss_cls: 1.4104  decode.d5.loss_mask: 0.9504  decode.d5.loss_dice: 1.4712  decode.d6.loss_cls: 1.4681  decode.d6.loss_mask: 0.9660  decode.d6.loss_dice: 1.4656  decode.d7.loss_cls: 1.4371  decode.d7.loss_mask: 0.9641  decode.d7.loss_dice: 1.4580  decode.d8.loss_cls: 1.3908  decode.d8.loss_mask: 0.9694  decode.d8.loss_dice: 1.4765
2023/05/24 08:32:43 - mmengine - INFO - Iter(train) [115250/160000]  lr: 3.1769e-06  eta: 5:22:22  time: 0.4232  data_time: 0.0103  memory: 4857  grad_norm: 96.9755  loss: 31.7914  decode.loss_cls: 1.1394  decode.loss_mask: 0.7243  decode.loss_dice: 1.0301  decode.d0.loss_cls: 3.1168  decode.d0.loss_mask: 0.8090  decode.d0.loss_dice: 1.2541  decode.d1.loss_cls: 1.3294  decode.d1.loss_mask: 0.7261  decode.d1.loss_dice: 1.1637  decode.d2.loss_cls: 1.1670  decode.d2.loss_mask: 0.6982  decode.d2.loss_dice: 1.0774  decode.d3.loss_cls: 1.1310  decode.d3.loss_mask: 0.7363  decode.d3.loss_dice: 1.0496  decode.d4.loss_cls: 1.1930  decode.d4.loss_mask: 0.6843  decode.d4.loss_dice: 1.0582  decode.d5.loss_cls: 1.1545  decode.d5.loss_mask: 0.6994  decode.d5.loss_dice: 1.0815  decode.d6.loss_cls: 1.2340  decode.d6.loss_mask: 0.6845  decode.d6.loss_dice: 1.0182  decode.d7.loss_cls: 1.1637  decode.d7.loss_mask: 0.7285  decode.d7.loss_dice: 1.0240  decode.d8.loss_cls: 1.1403  decode.d8.loss_mask: 0.7375  decode.d8.loss_dice: 1.0374
2023/05/24 08:33:05 - mmengine - INFO - Iter(train) [115300/160000]  lr: 3.1737e-06  eta: 5:22:00  time: 0.4365  data_time: 0.0106  memory: 4905  grad_norm: 89.8840  loss: 33.9773  decode.loss_cls: 1.3480  decode.loss_mask: 0.8179  decode.loss_dice: 1.0061  decode.d0.loss_cls: 2.9814  decode.d0.loss_mask: 0.8724  decode.d0.loss_dice: 1.1725  decode.d1.loss_cls: 1.4818  decode.d1.loss_mask: 0.8376  decode.d1.loss_dice: 1.1266  decode.d2.loss_cls: 1.4212  decode.d2.loss_mask: 0.8170  decode.d2.loss_dice: 1.0890  decode.d3.loss_cls: 1.3631  decode.d3.loss_mask: 0.8124  decode.d3.loss_dice: 1.0166  decode.d4.loss_cls: 1.3574  decode.d4.loss_mask: 0.8253  decode.d4.loss_dice: 0.9888  decode.d5.loss_cls: 1.3723  decode.d5.loss_mask: 0.8134  decode.d5.loss_dice: 0.9803  decode.d6.loss_cls: 1.3230  decode.d6.loss_mask: 0.8115  decode.d6.loss_dice: 0.9812  decode.d7.loss_cls: 1.3692  decode.d7.loss_mask: 0.8226  decode.d7.loss_dice: 0.9829  decode.d8.loss_cls: 1.3842  decode.d8.loss_mask: 0.8125  decode.d8.loss_dice: 0.9892
2023/05/24 08:33:26 - mmengine - INFO - Iter(train) [115350/160000]  lr: 3.1705e-06  eta: 5:21:38  time: 0.4225  data_time: 0.0106  memory: 4825  grad_norm: 111.0199  loss: 40.9490  decode.loss_cls: 1.3385  decode.loss_mask: 0.8708  decode.loss_dice: 1.5248  decode.d0.loss_cls: 3.3214  decode.d0.loss_mask: 0.8747  decode.d0.loss_dice: 1.8677  decode.d1.loss_cls: 1.5953  decode.d1.loss_mask: 0.8698  decode.d1.loss_dice: 1.6996  decode.d2.loss_cls: 1.4786  decode.d2.loss_mask: 0.9186  decode.d2.loss_dice: 1.5614  decode.d3.loss_cls: 1.4042  decode.d3.loss_mask: 0.9269  decode.d3.loss_dice: 1.5731  decode.d4.loss_cls: 1.4116  decode.d4.loss_mask: 0.9236  decode.d4.loss_dice: 1.6022  decode.d5.loss_cls: 1.3948  decode.d5.loss_mask: 0.8787  decode.d5.loss_dice: 1.5864  decode.d6.loss_cls: 1.3585  decode.d6.loss_mask: 0.8759  decode.d6.loss_dice: 1.5724  decode.d7.loss_cls: 1.3456  decode.d7.loss_mask: 0.8705  decode.d7.loss_dice: 1.5538  decode.d8.loss_cls: 1.3516  decode.d8.loss_mask: 0.8663  decode.d8.loss_dice: 1.5320
2023/05/24 08:33:47 - mmengine - INFO - Iter(train) [115400/160000]  lr: 3.1673e-06  eta: 5:21:17  time: 0.4246  data_time: 0.0113  memory: 4856  grad_norm: 89.4153  loss: 29.4359  decode.loss_cls: 1.0191  decode.loss_mask: 0.6737  decode.loss_dice: 0.9380  decode.d0.loss_cls: 3.0688  decode.d0.loss_mask: 0.7259  decode.d0.loss_dice: 1.1579  decode.d1.loss_cls: 1.1278  decode.d1.loss_mask: 0.7093  decode.d1.loss_dice: 1.0632  decode.d2.loss_cls: 1.1128  decode.d2.loss_mask: 0.6712  decode.d2.loss_dice: 0.9962  decode.d3.loss_cls: 1.0835  decode.d3.loss_mask: 0.6396  decode.d3.loss_dice: 0.9642  decode.d4.loss_cls: 1.1299  decode.d4.loss_mask: 0.6858  decode.d4.loss_dice: 0.9650  decode.d5.loss_cls: 1.0771  decode.d5.loss_mask: 0.6559  decode.d5.loss_dice: 0.9673  decode.d6.loss_cls: 1.0301  decode.d6.loss_mask: 0.6844  decode.d6.loss_dice: 0.9663  decode.d7.loss_cls: 1.0331  decode.d7.loss_mask: 0.7000  decode.d7.loss_dice: 0.9450  decode.d8.loss_cls: 1.0006  decode.d8.loss_mask: 0.6998  decode.d8.loss_dice: 0.9445
2023/05/24 08:34:08 - mmengine - INFO - Iter(train) [115450/160000]  lr: 3.1642e-06  eta: 5:20:55  time: 0.4258  data_time: 0.0108  memory: 4886  grad_norm: 100.6877  loss: 29.7821  decode.loss_cls: 1.0389  decode.loss_mask: 0.7032  decode.loss_dice: 1.0040  decode.d0.loss_cls: 2.8573  decode.d0.loss_mask: 0.7270  decode.d0.loss_dice: 1.1959  decode.d1.loss_cls: 1.0759  decode.d1.loss_mask: 0.7651  decode.d1.loss_dice: 1.1187  decode.d2.loss_cls: 1.0577  decode.d2.loss_mask: 0.7359  decode.d2.loss_dice: 1.0593  decode.d3.loss_cls: 1.0728  decode.d3.loss_mask: 0.7241  decode.d3.loss_dice: 1.0354  decode.d4.loss_cls: 1.0414  decode.d4.loss_mask: 0.7245  decode.d4.loss_dice: 0.9897  decode.d5.loss_cls: 1.0089  decode.d5.loss_mask: 0.7135  decode.d5.loss_dice: 1.0294  decode.d6.loss_cls: 1.0355  decode.d6.loss_mask: 0.6939  decode.d6.loss_dice: 0.9873  decode.d7.loss_cls: 0.9754  decode.d7.loss_mask: 0.6972  decode.d7.loss_dice: 1.0045  decode.d8.loss_cls: 1.0022  decode.d8.loss_mask: 0.7007  decode.d8.loss_dice: 1.0066
2023/05/24 08:34:31 - mmengine - INFO - Iter(train) [115500/160000]  lr: 3.1610e-06  eta: 5:20:33  time: 0.4216  data_time: 0.0115  memory: 4896  grad_norm: 91.9613  loss: 35.2751  decode.loss_cls: 1.0106  decode.loss_mask: 0.8426  decode.loss_dice: 1.3792  decode.d0.loss_cls: 2.9350  decode.d0.loss_mask: 0.9374  decode.d0.loss_dice: 1.6334  decode.d1.loss_cls: 1.1046  decode.d1.loss_mask: 0.8607  decode.d1.loss_dice: 1.5151  decode.d2.loss_cls: 0.9610  decode.d2.loss_mask: 0.8673  decode.d2.loss_dice: 1.4901  decode.d3.loss_cls: 1.0474  decode.d3.loss_mask: 0.8389  decode.d3.loss_dice: 1.4003  decode.d4.loss_cls: 1.0451  decode.d4.loss_mask: 0.8523  decode.d4.loss_dice: 1.4073  decode.d5.loss_cls: 1.0885  decode.d5.loss_mask: 0.8423  decode.d5.loss_dice: 1.4048  decode.d6.loss_cls: 1.0869  decode.d6.loss_mask: 0.8203  decode.d6.loss_dice: 1.3679  decode.d7.loss_cls: 1.0534  decode.d7.loss_mask: 0.8351  decode.d7.loss_dice: 1.3582  decode.d8.loss_cls: 1.1198  decode.d8.loss_mask: 0.8293  decode.d8.loss_dice: 1.3407
2023/05/24 08:34:52 - mmengine - INFO - Iter(train) [115550/160000]  lr: 3.1578e-06  eta: 5:20:12  time: 0.4196  data_time: 0.0108  memory: 4832  grad_norm: 98.4455  loss: 39.0943  decode.loss_cls: 1.2475  decode.loss_mask: 0.8670  decode.loss_dice: 1.4830  decode.d0.loss_cls: 3.2991  decode.d0.loss_mask: 0.9578  decode.d0.loss_dice: 1.7306  decode.d1.loss_cls: 1.2354  decode.d1.loss_mask: 0.9924  decode.d1.loss_dice: 1.6646  decode.d2.loss_cls: 1.2422  decode.d2.loss_mask: 0.9332  decode.d2.loss_dice: 1.5925  decode.d3.loss_cls: 1.3384  decode.d3.loss_mask: 0.9090  decode.d3.loss_dice: 1.4983  decode.d4.loss_cls: 1.2252  decode.d4.loss_mask: 0.9105  decode.d4.loss_dice: 1.5298  decode.d5.loss_cls: 1.2559  decode.d5.loss_mask: 0.8780  decode.d5.loss_dice: 1.5105  decode.d6.loss_cls: 1.2865  decode.d6.loss_mask: 0.8723  decode.d6.loss_dice: 1.4824  decode.d7.loss_cls: 1.1935  decode.d7.loss_mask: 0.8953  decode.d7.loss_dice: 1.4737  decode.d8.loss_cls: 1.2284  decode.d8.loss_mask: 0.8883  decode.d8.loss_dice: 1.4729
2023/05/24 08:35:14 - mmengine - INFO - Iter(train) [115600/160000]  lr: 3.1546e-06  eta: 5:19:50  time: 0.4449  data_time: 0.0103  memory: 4856  grad_norm: 106.1417  loss: 35.7550  decode.loss_cls: 1.0214  decode.loss_mask: 0.8617  decode.loss_dice: 1.3842  decode.d0.loss_cls: 2.9867  decode.d0.loss_mask: 0.9655  decode.d0.loss_dice: 1.5688  decode.d1.loss_cls: 1.1205  decode.d1.loss_mask: 0.8968  decode.d1.loss_dice: 1.4634  decode.d2.loss_cls: 1.1571  decode.d2.loss_mask: 0.8875  decode.d2.loss_dice: 1.4360  decode.d3.loss_cls: 1.0617  decode.d3.loss_mask: 0.8551  decode.d3.loss_dice: 1.4281  decode.d4.loss_cls: 1.0880  decode.d4.loss_mask: 0.8666  decode.d4.loss_dice: 1.4316  decode.d5.loss_cls: 1.0490  decode.d5.loss_mask: 0.8795  decode.d5.loss_dice: 1.4276  decode.d6.loss_cls: 1.0109  decode.d6.loss_mask: 0.8566  decode.d6.loss_dice: 1.4087  decode.d7.loss_cls: 1.0788  decode.d7.loss_mask: 0.8704  decode.d7.loss_dice: 1.3975  decode.d8.loss_cls: 1.0522  decode.d8.loss_mask: 0.8651  decode.d8.loss_dice: 1.3778
2023/05/24 08:35:35 - mmengine - INFO - Iter(train) [115650/160000]  lr: 3.1514e-06  eta: 5:19:28  time: 0.4232  data_time: 0.0111  memory: 4859  grad_norm: 89.2992  loss: 30.5388  decode.loss_cls: 1.0648  decode.loss_mask: 0.7769  decode.loss_dice: 0.9298  decode.d0.loss_cls: 2.9183  decode.d0.loss_mask: 0.8658  decode.d0.loss_dice: 1.0963  decode.d1.loss_cls: 1.2283  decode.d1.loss_mask: 0.8534  decode.d1.loss_dice: 1.0458  decode.d2.loss_cls: 1.1390  decode.d2.loss_mask: 0.7726  decode.d2.loss_dice: 0.9741  decode.d3.loss_cls: 1.1218  decode.d3.loss_mask: 0.7941  decode.d3.loss_dice: 0.9356  decode.d4.loss_cls: 1.0856  decode.d4.loss_mask: 0.8096  decode.d4.loss_dice: 0.9491  decode.d5.loss_cls: 1.0580  decode.d5.loss_mask: 0.8109  decode.d5.loss_dice: 0.9471  decode.d6.loss_cls: 1.0926  decode.d6.loss_mask: 0.7865  decode.d6.loss_dice: 0.9107  decode.d7.loss_cls: 1.0804  decode.d7.loss_mask: 0.7769  decode.d7.loss_dice: 0.9295  decode.d8.loss_cls: 1.0706  decode.d8.loss_mask: 0.7732  decode.d8.loss_dice: 0.9415
2023/05/24 08:35:56 - mmengine - INFO - Iter(train) [115700/160000]  lr: 3.1482e-06  eta: 5:19:07  time: 0.4184  data_time: 0.0106  memory: 5002  grad_norm: 90.6407  loss: 32.0588  decode.loss_cls: 1.0006  decode.loss_mask: 0.7229  decode.loss_dice: 1.2020  decode.d0.loss_cls: 3.1163  decode.d0.loss_mask: 0.7109  decode.d0.loss_dice: 1.3579  decode.d1.loss_cls: 1.0571  decode.d1.loss_mask: 0.7680  decode.d1.loss_dice: 1.3011  decode.d2.loss_cls: 1.0918  decode.d2.loss_mask: 0.7445  decode.d2.loss_dice: 1.2427  decode.d3.loss_cls: 1.1475  decode.d3.loss_mask: 0.6861  decode.d3.loss_dice: 1.1975  decode.d4.loss_cls: 1.0525  decode.d4.loss_mask: 0.7203  decode.d4.loss_dice: 1.2071  decode.d5.loss_cls: 1.0489  decode.d5.loss_mask: 0.7153  decode.d5.loss_dice: 1.2019  decode.d6.loss_cls: 1.0033  decode.d6.loss_mask: 0.7142  decode.d6.loss_dice: 1.1776  decode.d7.loss_cls: 1.0077  decode.d7.loss_mask: 0.7079  decode.d7.loss_dice: 1.2118  decode.d8.loss_cls: 1.0392  decode.d8.loss_mask: 0.7069  decode.d8.loss_dice: 1.1972
2023/05/24 08:36:19 - mmengine - INFO - Iter(train) [115750/160000]  lr: 3.1450e-06  eta: 5:18:46  time: 0.4791  data_time: 0.0105  memory: 4886  grad_norm: 93.4559  loss: 32.5266  decode.loss_cls: 1.0777  decode.loss_mask: 0.6977  decode.loss_dice: 1.1624  decode.d0.loss_cls: 3.0768  decode.d0.loss_mask: 0.7967  decode.d0.loss_dice: 1.4332  decode.d1.loss_cls: 1.2402  decode.d1.loss_mask: 0.7194  decode.d1.loss_dice: 1.2867  decode.d2.loss_cls: 1.2538  decode.d2.loss_mask: 0.6913  decode.d2.loss_dice: 1.2352  decode.d3.loss_cls: 1.1466  decode.d3.loss_mask: 0.6763  decode.d3.loss_dice: 1.1826  decode.d4.loss_cls: 1.1351  decode.d4.loss_mask: 0.7001  decode.d4.loss_dice: 1.1729  decode.d5.loss_cls: 1.1115  decode.d5.loss_mask: 0.7023  decode.d5.loss_dice: 1.1930  decode.d6.loss_cls: 1.1228  decode.d6.loss_mask: 0.6902  decode.d6.loss_dice: 1.1516  decode.d7.loss_cls: 1.0715  decode.d7.loss_mask: 0.7042  decode.d7.loss_dice: 1.1759  decode.d8.loss_cls: 1.0653  decode.d8.loss_mask: 0.6926  decode.d8.loss_dice: 1.1608
2023/05/24 08:36:41 - mmengine - INFO - Iter(train) [115800/160000]  lr: 3.1418e-06  eta: 5:18:24  time: 0.4159  data_time: 0.0103  memory: 4866  grad_norm: 125.0850  loss: 29.2424  decode.loss_cls: 1.1519  decode.loss_mask: 0.6126  decode.loss_dice: 0.9105  decode.d0.loss_cls: 3.2252  decode.d0.loss_mask: 0.7101  decode.d0.loss_dice: 1.0531  decode.d1.loss_cls: 1.2222  decode.d1.loss_mask: 0.6259  decode.d1.loss_dice: 1.0270  decode.d2.loss_cls: 1.1737  decode.d2.loss_mask: 0.6106  decode.d2.loss_dice: 0.9778  decode.d3.loss_cls: 1.1555  decode.d3.loss_mask: 0.6060  decode.d3.loss_dice: 0.9439  decode.d4.loss_cls: 1.1339  decode.d4.loss_mask: 0.6164  decode.d4.loss_dice: 0.9479  decode.d5.loss_cls: 1.1215  decode.d5.loss_mask: 0.6129  decode.d5.loss_dice: 0.9607  decode.d6.loss_cls: 1.0702  decode.d6.loss_mask: 0.6042  decode.d6.loss_dice: 0.9539  decode.d7.loss_cls: 1.0682  decode.d7.loss_mask: 0.6098  decode.d7.loss_dice: 0.9433  decode.d8.loss_cls: 1.0620  decode.d8.loss_mask: 0.6072  decode.d8.loss_dice: 0.9242
2023/05/24 08:37:03 - mmengine - INFO - Iter(train) [115850/160000]  lr: 3.1386e-06  eta: 5:18:02  time: 0.4285  data_time: 0.0105  memory: 4889  grad_norm: 99.1293  loss: 40.5575  decode.loss_cls: 1.3662  decode.loss_mask: 0.9138  decode.loss_dice: 1.5078  decode.d0.loss_cls: 3.3538  decode.d0.loss_mask: 0.9896  decode.d0.loss_dice: 1.7222  decode.d1.loss_cls: 1.4743  decode.d1.loss_mask: 0.9616  decode.d1.loss_dice: 1.5485  decode.d2.loss_cls: 1.3932  decode.d2.loss_mask: 0.9654  decode.d2.loss_dice: 1.5446  decode.d3.loss_cls: 1.3813  decode.d3.loss_mask: 0.9277  decode.d3.loss_dice: 1.5618  decode.d4.loss_cls: 1.3796  decode.d4.loss_mask: 0.9102  decode.d4.loss_dice: 1.5214  decode.d5.loss_cls: 1.3710  decode.d5.loss_mask: 0.9199  decode.d5.loss_dice: 1.5302  decode.d6.loss_cls: 1.3467  decode.d6.loss_mask: 0.9384  decode.d6.loss_dice: 1.4681  decode.d7.loss_cls: 1.3404  decode.d7.loss_mask: 0.9430  decode.d7.loss_dice: 1.5183  decode.d8.loss_cls: 1.3311  decode.d8.loss_mask: 0.9320  decode.d8.loss_dice: 1.4953
2023/05/24 08:37:24 - mmengine - INFO - Iter(train) [115900/160000]  lr: 3.1354e-06  eta: 5:17:41  time: 0.4186  data_time: 0.0104  memory: 4829  grad_norm: 128.5146  loss: 34.6479  decode.loss_cls: 1.1018  decode.loss_mask: 0.9129  decode.loss_dice: 1.1802  decode.d0.loss_cls: 2.9584  decode.d0.loss_mask: 0.9138  decode.d0.loss_dice: 1.3040  decode.d1.loss_cls: 1.3000  decode.d1.loss_mask: 0.9447  decode.d1.loss_dice: 1.3295  decode.d2.loss_cls: 1.2014  decode.d2.loss_mask: 0.9412  decode.d2.loss_dice: 1.2241  decode.d3.loss_cls: 1.1588  decode.d3.loss_mask: 0.9028  decode.d3.loss_dice: 1.1948  decode.d4.loss_cls: 1.0710  decode.d4.loss_mask: 0.9258  decode.d4.loss_dice: 1.1743  decode.d5.loss_cls: 1.0714  decode.d5.loss_mask: 0.9386  decode.d5.loss_dice: 1.2572  decode.d6.loss_cls: 1.1172  decode.d6.loss_mask: 0.9292  decode.d6.loss_dice: 1.2058  decode.d7.loss_cls: 1.0642  decode.d7.loss_mask: 0.9459  decode.d7.loss_dice: 1.1936  decode.d8.loss_cls: 1.0531  decode.d8.loss_mask: 0.9308  decode.d8.loss_dice: 1.2014
2023/05/24 08:37:46 - mmengine - INFO - Iter(train) [115950/160000]  lr: 3.1322e-06  eta: 5:17:19  time: 0.4122  data_time: 0.0105  memory: 4886  grad_norm: 85.9900  loss: 29.2190  decode.loss_cls: 0.9774  decode.loss_mask: 0.6351  decode.loss_dice: 1.0594  decode.d0.loss_cls: 2.8178  decode.d0.loss_mask: 0.6835  decode.d0.loss_dice: 1.1960  decode.d1.loss_cls: 1.0056  decode.d1.loss_mask: 0.7294  decode.d1.loss_dice: 1.1474  decode.d2.loss_cls: 0.9995  decode.d2.loss_mask: 0.7138  decode.d2.loss_dice: 1.1220  decode.d3.loss_cls: 1.0601  decode.d3.loss_mask: 0.6500  decode.d3.loss_dice: 1.0516  decode.d4.loss_cls: 0.9698  decode.d4.loss_mask: 0.6957  decode.d4.loss_dice: 1.0540  decode.d5.loss_cls: 0.9358  decode.d5.loss_mask: 0.6898  decode.d5.loss_dice: 1.0803  decode.d6.loss_cls: 0.9377  decode.d6.loss_mask: 0.6409  decode.d6.loss_dice: 1.0678  decode.d7.loss_cls: 0.9454  decode.d7.loss_mask: 0.6462  decode.d7.loss_dice: 1.0597  decode.d8.loss_cls: 0.9645  decode.d8.loss_mask: 0.6316  decode.d8.loss_dice: 1.0514
2023/05/24 08:38:07 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 08:38:07 - mmengine - INFO - Iter(train) [116000/160000]  lr: 3.1290e-06  eta: 5:16:57  time: 0.4198  data_time: 0.0104  memory: 4787  grad_norm: 97.2914  loss: 24.3933  decode.loss_cls: 0.8051  decode.loss_mask: 0.5016  decode.loss_dice: 0.9035  decode.d0.loss_cls: 2.5194  decode.d0.loss_mask: 0.5324  decode.d0.loss_dice: 0.9878  decode.d1.loss_cls: 0.8708  decode.d1.loss_mask: 0.5347  decode.d1.loss_dice: 0.9761  decode.d2.loss_cls: 0.8931  decode.d2.loss_mask: 0.5084  decode.d2.loss_dice: 0.9386  decode.d3.loss_cls: 0.8789  decode.d3.loss_mask: 0.5141  decode.d3.loss_dice: 0.9027  decode.d4.loss_cls: 0.8521  decode.d4.loss_mask: 0.5080  decode.d4.loss_dice: 0.9119  decode.d5.loss_cls: 0.8440  decode.d5.loss_mask: 0.5063  decode.d5.loss_dice: 0.9105  decode.d6.loss_cls: 0.8253  decode.d6.loss_mask: 0.5069  decode.d6.loss_dice: 0.8992  decode.d7.loss_cls: 0.7979  decode.d7.loss_mask: 0.4902  decode.d7.loss_dice: 0.8784  decode.d8.loss_cls: 0.8031  decode.d8.loss_mask: 0.4953  decode.d8.loss_dice: 0.8970
2023/05/24 08:38:07 - mmengine - INFO - Saving checkpoint at 116000 iterations
2023/05/24 08:38:35 - mmengine - INFO - Iter(train) [116050/160000]  lr: 3.1258e-06  eta: 5:16:38  time: 0.4189  data_time: 0.0114  memory: 4898  grad_norm: 95.6519  loss: 35.4968  decode.loss_cls: 1.3970  decode.loss_mask: 0.7228  decode.loss_dice: 1.1371  decode.d0.loss_cls: 3.2831  decode.d0.loss_mask: 0.7424  decode.d0.loss_dice: 1.4077  decode.d1.loss_cls: 1.6120  decode.d1.loss_mask: 0.7112  decode.d1.loss_dice: 1.2183  decode.d2.loss_cls: 1.6174  decode.d2.loss_mask: 0.6858  decode.d2.loss_dice: 1.1695  decode.d3.loss_cls: 1.5268  decode.d3.loss_mask: 0.6877  decode.d3.loss_dice: 1.1363  decode.d4.loss_cls: 1.4761  decode.d4.loss_mask: 0.7259  decode.d4.loss_dice: 1.1463  decode.d5.loss_cls: 1.4363  decode.d5.loss_mask: 0.7139  decode.d5.loss_dice: 1.1386  decode.d6.loss_cls: 1.4159  decode.d6.loss_mask: 0.7301  decode.d6.loss_dice: 1.1330  decode.d7.loss_cls: 1.3837  decode.d7.loss_mask: 0.7301  decode.d7.loss_dice: 1.1546  decode.d8.loss_cls: 1.3871  decode.d8.loss_mask: 0.7282  decode.d8.loss_dice: 1.1420
2023/05/24 08:38:56 - mmengine - INFO - Iter(train) [116100/160000]  lr: 3.1226e-06  eta: 5:16:16  time: 0.4131  data_time: 0.0106  memory: 4865  grad_norm: 109.6297  loss: 41.0361  decode.loss_cls: 1.4146  decode.loss_mask: 0.8399  decode.loss_dice: 1.4836  decode.d0.loss_cls: 3.3645  decode.d0.loss_mask: 0.9637  decode.d0.loss_dice: 1.9318  decode.d1.loss_cls: 1.5532  decode.d1.loss_mask: 0.9286  decode.d1.loss_dice: 1.7448  decode.d2.loss_cls: 1.4349  decode.d2.loss_mask: 0.9335  decode.d2.loss_dice: 1.6490  decode.d3.loss_cls: 1.4755  decode.d3.loss_mask: 0.8922  decode.d3.loss_dice: 1.5531  decode.d4.loss_cls: 1.4310  decode.d4.loss_mask: 0.8676  decode.d4.loss_dice: 1.5370  decode.d5.loss_cls: 1.4291  decode.d5.loss_mask: 0.8503  decode.d5.loss_dice: 1.5458  decode.d6.loss_cls: 1.3729  decode.d6.loss_mask: 0.8550  decode.d6.loss_dice: 1.5210  decode.d7.loss_cls: 1.4447  decode.d7.loss_mask: 0.8360  decode.d7.loss_dice: 1.4648  decode.d8.loss_cls: 1.3863  decode.d8.loss_mask: 0.8389  decode.d8.loss_dice: 1.4930
2023/05/24 08:39:17 - mmengine - INFO - Iter(train) [116150/160000]  lr: 3.1194e-06  eta: 5:15:54  time: 0.4210  data_time: 0.0111  memory: 4919  grad_norm: 84.0763  loss: 33.8598  decode.loss_cls: 1.2635  decode.loss_mask: 0.6220  decode.loss_dice: 1.2170  decode.d0.loss_cls: 3.1859  decode.d0.loss_mask: 0.6992  decode.d0.loss_dice: 1.4920  decode.d1.loss_cls: 1.3726  decode.d1.loss_mask: 0.7199  decode.d1.loss_dice: 1.3227  decode.d2.loss_cls: 1.2842  decode.d2.loss_mask: 0.6756  decode.d2.loss_dice: 1.2433  decode.d3.loss_cls: 1.2373  decode.d3.loss_mask: 0.6765  decode.d3.loss_dice: 1.2529  decode.d4.loss_cls: 1.2478  decode.d4.loss_mask: 0.6552  decode.d4.loss_dice: 1.2692  decode.d5.loss_cls: 1.2347  decode.d5.loss_mask: 0.6612  decode.d5.loss_dice: 1.2675  decode.d6.loss_cls: 1.2372  decode.d6.loss_mask: 0.6374  decode.d6.loss_dice: 1.2149  decode.d7.loss_cls: 1.2211  decode.d7.loss_mask: 0.6283  decode.d7.loss_dice: 1.2362  decode.d8.loss_cls: 1.2060  decode.d8.loss_mask: 0.6381  decode.d8.loss_dice: 1.2405
2023/05/24 08:39:38 - mmengine - INFO - Iter(train) [116200/160000]  lr: 3.1162e-06  eta: 5:15:33  time: 0.4164  data_time: 0.0105  memory: 4822  grad_norm: 90.5524  loss: 32.9200  decode.loss_cls: 1.0790  decode.loss_mask: 0.8837  decode.loss_dice: 1.0854  decode.d0.loss_cls: 2.7412  decode.d0.loss_mask: 0.9101  decode.d0.loss_dice: 1.1721  decode.d1.loss_cls: 1.1830  decode.d1.loss_mask: 0.9391  decode.d1.loss_dice: 1.1873  decode.d2.loss_cls: 1.2106  decode.d2.loss_mask: 0.9079  decode.d2.loss_dice: 1.1307  decode.d3.loss_cls: 1.2068  decode.d3.loss_mask: 0.8938  decode.d3.loss_dice: 1.0507  decode.d4.loss_cls: 1.1634  decode.d4.loss_mask: 0.8891  decode.d4.loss_dice: 1.0571  decode.d5.loss_cls: 1.1050  decode.d5.loss_mask: 0.9153  decode.d5.loss_dice: 1.0895  decode.d6.loss_cls: 1.0905  decode.d6.loss_mask: 0.8982  decode.d6.loss_dice: 1.0613  decode.d7.loss_cls: 1.1181  decode.d7.loss_mask: 0.8748  decode.d7.loss_dice: 1.0419  decode.d8.loss_cls: 1.0956  decode.d8.loss_mask: 0.8882  decode.d8.loss_dice: 1.0506
2023/05/24 08:40:00 - mmengine - INFO - Iter(train) [116250/160000]  lr: 3.1130e-06  eta: 5:15:11  time: 0.4392  data_time: 0.0104  memory: 4844  grad_norm: 99.4320  loss: 25.7959  decode.loss_cls: 0.8413  decode.loss_mask: 0.6464  decode.loss_dice: 0.8130  decode.d0.loss_cls: 2.7175  decode.d0.loss_mask: 0.6761  decode.d0.loss_dice: 0.9800  decode.d1.loss_cls: 0.9678  decode.d1.loss_mask: 0.7038  decode.d1.loss_dice: 0.9491  decode.d2.loss_cls: 0.9078  decode.d2.loss_mask: 0.6594  decode.d2.loss_dice: 0.9085  decode.d3.loss_cls: 0.8618  decode.d3.loss_mask: 0.6481  decode.d3.loss_dice: 0.8506  decode.d4.loss_cls: 0.8873  decode.d4.loss_mask: 0.6395  decode.d4.loss_dice: 0.8352  decode.d5.loss_cls: 0.9234  decode.d5.loss_mask: 0.6293  decode.d5.loss_dice: 0.8090  decode.d6.loss_cls: 0.8957  decode.d6.loss_mask: 0.6409  decode.d6.loss_dice: 0.8013  decode.d7.loss_cls: 0.8604  decode.d7.loss_mask: 0.6422  decode.d7.loss_dice: 0.8031  decode.d8.loss_cls: 0.8472  decode.d8.loss_mask: 0.6359  decode.d8.loss_dice: 0.8142
2023/05/24 08:40:22 - mmengine - INFO - Iter(train) [116300/160000]  lr: 3.1098e-06  eta: 5:14:49  time: 0.4351  data_time: 0.0106  memory: 4844  grad_norm: 89.8553  loss: 29.3643  decode.loss_cls: 0.9526  decode.loss_mask: 0.7884  decode.loss_dice: 0.9605  decode.d0.loss_cls: 2.8518  decode.d0.loss_mask: 0.7208  decode.d0.loss_dice: 1.0822  decode.d1.loss_cls: 1.1113  decode.d1.loss_mask: 0.7487  decode.d1.loss_dice: 1.0300  decode.d2.loss_cls: 1.0378  decode.d2.loss_mask: 0.7589  decode.d2.loss_dice: 0.9852  decode.d3.loss_cls: 0.9825  decode.d3.loss_mask: 0.7836  decode.d3.loss_dice: 0.9758  decode.d4.loss_cls: 0.9881  decode.d4.loss_mask: 0.7741  decode.d4.loss_dice: 0.9681  decode.d5.loss_cls: 0.9492  decode.d5.loss_mask: 0.7812  decode.d5.loss_dice: 0.9793  decode.d6.loss_cls: 0.9851  decode.d6.loss_mask: 0.7766  decode.d6.loss_dice: 0.9413  decode.d7.loss_cls: 0.9906  decode.d7.loss_mask: 0.7869  decode.d7.loss_dice: 0.9469  decode.d8.loss_cls: 0.9575  decode.d8.loss_mask: 0.7886  decode.d8.loss_dice: 0.9807
2023/05/24 08:40:43 - mmengine - INFO - Iter(train) [116350/160000]  lr: 3.1066e-06  eta: 5:14:28  time: 0.4394  data_time: 0.0108  memory: 4866  grad_norm: 98.7807  loss: 35.4914  decode.loss_cls: 1.1852  decode.loss_mask: 0.7967  decode.loss_dice: 1.2046  decode.d0.loss_cls: 3.1093  decode.d0.loss_mask: 0.9114  decode.d0.loss_dice: 1.4074  decode.d1.loss_cls: 1.3656  decode.d1.loss_mask: 0.8609  decode.d1.loss_dice: 1.3502  decode.d2.loss_cls: 1.4275  decode.d2.loss_mask: 0.7985  decode.d2.loss_dice: 1.2885  decode.d3.loss_cls: 1.3889  decode.d3.loss_mask: 0.7758  decode.d3.loss_dice: 1.2733  decode.d4.loss_cls: 1.2659  decode.d4.loss_mask: 0.7905  decode.d4.loss_dice: 1.2500  decode.d5.loss_cls: 1.2594  decode.d5.loss_mask: 0.8020  decode.d5.loss_dice: 1.2536  decode.d6.loss_cls: 1.2755  decode.d6.loss_mask: 0.7846  decode.d6.loss_dice: 1.2205  decode.d7.loss_cls: 1.2130  decode.d7.loss_mask: 0.7847  decode.d7.loss_dice: 1.2337  decode.d8.loss_cls: 1.1748  decode.d8.loss_mask: 0.7930  decode.d8.loss_dice: 1.2462
2023/05/24 08:41:04 - mmengine - INFO - Iter(train) [116400/160000]  lr: 3.1034e-06  eta: 5:14:06  time: 0.4172  data_time: 0.0109  memory: 4823  grad_norm: 120.4541  loss: 34.7585  decode.loss_cls: 1.2137  decode.loss_mask: 0.7471  decode.loss_dice: 1.2574  decode.d0.loss_cls: 3.0227  decode.d0.loss_mask: 0.8365  decode.d0.loss_dice: 1.4649  decode.d1.loss_cls: 1.3647  decode.d1.loss_mask: 0.8432  decode.d1.loss_dice: 1.3758  decode.d2.loss_cls: 1.3368  decode.d2.loss_mask: 0.7726  decode.d2.loss_dice: 1.2707  decode.d3.loss_cls: 1.2549  decode.d3.loss_mask: 0.7535  decode.d3.loss_dice: 1.2891  decode.d4.loss_cls: 1.1756  decode.d4.loss_mask: 0.7737  decode.d4.loss_dice: 1.2813  decode.d5.loss_cls: 1.1971  decode.d5.loss_mask: 0.7414  decode.d5.loss_dice: 1.2421  decode.d6.loss_cls: 1.1992  decode.d6.loss_mask: 0.7526  decode.d6.loss_dice: 1.2181  decode.d7.loss_cls: 1.1912  decode.d7.loss_mask: 0.7476  decode.d7.loss_dice: 1.2645  decode.d8.loss_cls: 1.1625  decode.d8.loss_mask: 0.7492  decode.d8.loss_dice: 1.2587
2023/05/24 08:41:26 - mmengine - INFO - Iter(train) [116450/160000]  lr: 3.1002e-06  eta: 5:13:44  time: 0.4230  data_time: 0.0108  memory: 4821  grad_norm: 95.9475  loss: 36.4332  decode.loss_cls: 1.3070  decode.loss_mask: 0.7528  decode.loss_dice: 1.2849  decode.d0.loss_cls: 3.4697  decode.d0.loss_mask: 0.8467  decode.d0.loss_dice: 1.5604  decode.d1.loss_cls: 1.4418  decode.d1.loss_mask: 0.8191  decode.d1.loss_dice: 1.3934  decode.d2.loss_cls: 1.3134  decode.d2.loss_mask: 0.8090  decode.d2.loss_dice: 1.3570  decode.d3.loss_cls: 1.3620  decode.d3.loss_mask: 0.7487  decode.d3.loss_dice: 1.3130  decode.d4.loss_cls: 1.2647  decode.d4.loss_mask: 0.7621  decode.d4.loss_dice: 1.2998  decode.d5.loss_cls: 1.2762  decode.d5.loss_mask: 0.7740  decode.d5.loss_dice: 1.3023  decode.d6.loss_cls: 1.2697  decode.d6.loss_mask: 0.7514  decode.d6.loss_dice: 1.2836  decode.d7.loss_cls: 1.2853  decode.d7.loss_mask: 0.7567  decode.d7.loss_dice: 1.2814  decode.d8.loss_cls: 1.3201  decode.d8.loss_mask: 0.7388  decode.d8.loss_dice: 1.2882
2023/05/24 08:41:47 - mmengine - INFO - Iter(train) [116500/160000]  lr: 3.0970e-06  eta: 5:13:23  time: 0.4174  data_time: 0.0103  memory: 4882  grad_norm: 98.6769  loss: 24.3883  decode.loss_cls: 0.8183  decode.loss_mask: 0.4866  decode.loss_dice: 0.8934  decode.d0.loss_cls: 2.5529  decode.d0.loss_mask: 0.4906  decode.d0.loss_dice: 1.0588  decode.d1.loss_cls: 0.9434  decode.d1.loss_mask: 0.5231  decode.d1.loss_dice: 0.9687  decode.d2.loss_cls: 0.8719  decode.d2.loss_mask: 0.5116  decode.d2.loss_dice: 0.9622  decode.d3.loss_cls: 0.8762  decode.d3.loss_mask: 0.5015  decode.d3.loss_dice: 0.9023  decode.d4.loss_cls: 0.8271  decode.d4.loss_mask: 0.4932  decode.d4.loss_dice: 0.9068  decode.d5.loss_cls: 0.8019  decode.d5.loss_mask: 0.4877  decode.d5.loss_dice: 0.9242  decode.d6.loss_cls: 0.7842  decode.d6.loss_mask: 0.4891  decode.d6.loss_dice: 0.9249  decode.d7.loss_cls: 0.8037  decode.d7.loss_mask: 0.4884  decode.d7.loss_dice: 0.9046  decode.d8.loss_cls: 0.7806  decode.d8.loss_mask: 0.5019  decode.d8.loss_dice: 0.9086
2023/05/24 08:42:08 - mmengine - INFO - Iter(train) [116550/160000]  lr: 3.0938e-06  eta: 5:13:01  time: 0.4126  data_time: 0.0104  memory: 5018  grad_norm: 86.2387  loss: 36.0399  decode.loss_cls: 1.2572  decode.loss_mask: 0.8056  decode.loss_dice: 1.2844  decode.d0.loss_cls: 3.1151  decode.d0.loss_mask: 0.8695  decode.d0.loss_dice: 1.4277  decode.d1.loss_cls: 1.4053  decode.d1.loss_mask: 0.8421  decode.d1.loss_dice: 1.3604  decode.d2.loss_cls: 1.2741  decode.d2.loss_mask: 0.8450  decode.d2.loss_dice: 1.3514  decode.d3.loss_cls: 1.2897  decode.d3.loss_mask: 0.8207  decode.d3.loss_dice: 1.3014  decode.d4.loss_cls: 1.2985  decode.d4.loss_mask: 0.8011  decode.d4.loss_dice: 1.2953  decode.d5.loss_cls: 1.3199  decode.d5.loss_mask: 0.7972  decode.d5.loss_dice: 1.2870  decode.d6.loss_cls: 1.2897  decode.d6.loss_mask: 0.8041  decode.d6.loss_dice: 1.2721  decode.d7.loss_cls: 1.2667  decode.d7.loss_mask: 0.8064  decode.d7.loss_dice: 1.2598  decode.d8.loss_cls: 1.2233  decode.d8.loss_mask: 0.8135  decode.d8.loss_dice: 1.2559
2023/05/24 08:42:29 - mmengine - INFO - Iter(train) [116600/160000]  lr: 3.0905e-06  eta: 5:12:39  time: 0.4198  data_time: 0.0109  memory: 4838  grad_norm: 93.3694  loss: 44.5641  decode.loss_cls: 1.4570  decode.loss_mask: 1.0431  decode.loss_dice: 1.5908  decode.d0.loss_cls: 3.4984  decode.d0.loss_mask: 1.0759  decode.d0.loss_dice: 1.8600  decode.d1.loss_cls: 1.6318  decode.d1.loss_mask: 1.0767  decode.d1.loss_dice: 1.7683  decode.d2.loss_cls: 1.5744  decode.d2.loss_mask: 1.0684  decode.d2.loss_dice: 1.6563  decode.d3.loss_cls: 1.5765  decode.d3.loss_mask: 1.0647  decode.d3.loss_dice: 1.6098  decode.d4.loss_cls: 1.5342  decode.d4.loss_mask: 1.0717  decode.d4.loss_dice: 1.6166  decode.d5.loss_cls: 1.5139  decode.d5.loss_mask: 1.0751  decode.d5.loss_dice: 1.6187  decode.d6.loss_cls: 1.5372  decode.d6.loss_mask: 1.0659  decode.d6.loss_dice: 1.6398  decode.d7.loss_cls: 1.5354  decode.d7.loss_mask: 1.0484  decode.d7.loss_dice: 1.6332  decode.d8.loss_cls: 1.4730  decode.d8.loss_mask: 1.0549  decode.d8.loss_dice: 1.5939
2023/05/24 08:42:52 - mmengine - INFO - Iter(train) [116650/160000]  lr: 3.0873e-06  eta: 5:12:18  time: 0.4827  data_time: 0.0111  memory: 4890  grad_norm: 88.9264  loss: 32.1523  decode.loss_cls: 1.0019  decode.loss_mask: 0.6354  decode.loss_dice: 1.3242  decode.d0.loss_cls: 2.8365  decode.d0.loss_mask: 0.7173  decode.d0.loss_dice: 1.5328  decode.d1.loss_cls: 1.0137  decode.d1.loss_mask: 0.7086  decode.d1.loss_dice: 1.4424  decode.d2.loss_cls: 0.9573  decode.d2.loss_mask: 0.7089  decode.d2.loss_dice: 1.3955  decode.d3.loss_cls: 0.9912  decode.d3.loss_mask: 0.7071  decode.d3.loss_dice: 1.3192  decode.d4.loss_cls: 1.0009  decode.d4.loss_mask: 0.6833  decode.d4.loss_dice: 1.3359  decode.d5.loss_cls: 0.9600  decode.d5.loss_mask: 0.6732  decode.d5.loss_dice: 1.3379  decode.d6.loss_cls: 0.9967  decode.d6.loss_mask: 0.6570  decode.d6.loss_dice: 1.3131  decode.d7.loss_cls: 0.9535  decode.d7.loss_mask: 0.6528  decode.d7.loss_dice: 1.3494  decode.d8.loss_cls: 0.9885  decode.d8.loss_mask: 0.6498  decode.d8.loss_dice: 1.3083
2023/05/24 08:43:16 - mmengine - INFO - Iter(train) [116700/160000]  lr: 3.0841e-06  eta: 5:11:57  time: 0.4785  data_time: 0.0103  memory: 4858  grad_norm: 91.5315  loss: 41.3947  decode.loss_cls: 1.3645  decode.loss_mask: 0.9123  decode.loss_dice: 1.4939  decode.d0.loss_cls: 3.5679  decode.d0.loss_mask: 1.0413  decode.d0.loss_dice: 1.9156  decode.d1.loss_cls: 1.4688  decode.d1.loss_mask: 1.0104  decode.d1.loss_dice: 1.6925  decode.d2.loss_cls: 1.4139  decode.d2.loss_mask: 0.9353  decode.d2.loss_dice: 1.5589  decode.d3.loss_cls: 1.3930  decode.d3.loss_mask: 0.9361  decode.d3.loss_dice: 1.5264  decode.d4.loss_cls: 1.4065  decode.d4.loss_mask: 0.9480  decode.d4.loss_dice: 1.5494  decode.d5.loss_cls: 1.3851  decode.d5.loss_mask: 0.9520  decode.d5.loss_dice: 1.5547  decode.d6.loss_cls: 1.3761  decode.d6.loss_mask: 0.9363  decode.d6.loss_dice: 1.5072  decode.d7.loss_cls: 1.3698  decode.d7.loss_mask: 0.9130  decode.d7.loss_dice: 1.5112  decode.d8.loss_cls: 1.3971  decode.d8.loss_mask: 0.8945  decode.d8.loss_dice: 1.4631
2023/05/24 08:43:37 - mmengine - INFO - Iter(train) [116750/160000]  lr: 3.0809e-06  eta: 5:11:35  time: 0.4190  data_time: 0.0105  memory: 4844  grad_norm: 96.4317  loss: 29.7373  decode.loss_cls: 0.8949  decode.loss_mask: 0.7170  decode.loss_dice: 1.0661  decode.d0.loss_cls: 3.0418  decode.d0.loss_mask: 0.7612  decode.d0.loss_dice: 1.2382  decode.d1.loss_cls: 1.1785  decode.d1.loss_mask: 0.7405  decode.d1.loss_dice: 1.1077  decode.d2.loss_cls: 0.9918  decode.d2.loss_mask: 0.7565  decode.d2.loss_dice: 1.0758  decode.d3.loss_cls: 0.9268  decode.d3.loss_mask: 0.7197  decode.d3.loss_dice: 1.0922  decode.d4.loss_cls: 0.9204  decode.d4.loss_mask: 0.7359  decode.d4.loss_dice: 1.0728  decode.d5.loss_cls: 0.9696  decode.d5.loss_mask: 0.7005  decode.d5.loss_dice: 1.0283  decode.d6.loss_cls: 0.9234  decode.d6.loss_mask: 0.7351  decode.d6.loss_dice: 1.0223  decode.d7.loss_cls: 0.8980  decode.d7.loss_mask: 0.7063  decode.d7.loss_dice: 1.0457  decode.d8.loss_cls: 0.9035  decode.d8.loss_mask: 0.7285  decode.d8.loss_dice: 1.0383
2023/05/24 08:43:58 - mmengine - INFO - Iter(train) [116800/160000]  lr: 3.0777e-06  eta: 5:11:13  time: 0.4241  data_time: 0.0106  memory: 4847  grad_norm: 90.2195  loss: 42.0497  decode.loss_cls: 1.4477  decode.loss_mask: 0.8338  decode.loss_dice: 1.5047  decode.d0.loss_cls: 3.3261  decode.d0.loss_mask: 1.0009  decode.d0.loss_dice: 1.9160  decode.d1.loss_cls: 1.6452  decode.d1.loss_mask: 0.9479  decode.d1.loss_dice: 1.7785  decode.d2.loss_cls: 1.6296  decode.d2.loss_mask: 0.9203  decode.d2.loss_dice: 1.6341  decode.d3.loss_cls: 1.5381  decode.d3.loss_mask: 0.8945  decode.d3.loss_dice: 1.5595  decode.d4.loss_cls: 1.5451  decode.d4.loss_mask: 0.8773  decode.d4.loss_dice: 1.5601  decode.d5.loss_cls: 1.5469  decode.d5.loss_mask: 0.8781  decode.d5.loss_dice: 1.5611  decode.d6.loss_cls: 1.5311  decode.d6.loss_mask: 0.8329  decode.d6.loss_dice: 1.5026  decode.d7.loss_cls: 1.4725  decode.d7.loss_mask: 0.8547  decode.d7.loss_dice: 1.5239  decode.d8.loss_cls: 1.4467  decode.d8.loss_mask: 0.8381  decode.d8.loss_dice: 1.5018
2023/05/24 08:44:21 - mmengine - INFO - Iter(train) [116850/160000]  lr: 3.0745e-06  eta: 5:10:52  time: 0.4254  data_time: 0.0114  memory: 4927  grad_norm: 89.7052  loss: 37.2347  decode.loss_cls: 1.3464  decode.loss_mask: 0.8273  decode.loss_dice: 1.1947  decode.d0.loss_cls: 3.6081  decode.d0.loss_mask: 0.9064  decode.d0.loss_dice: 1.4684  decode.d1.loss_cls: 1.4580  decode.d1.loss_mask: 0.9551  decode.d1.loss_dice: 1.3451  decode.d2.loss_cls: 1.4142  decode.d2.loss_mask: 0.8490  decode.d2.loss_dice: 1.2611  decode.d3.loss_cls: 1.3800  decode.d3.loss_mask: 0.8468  decode.d3.loss_dice: 1.2533  decode.d4.loss_cls: 1.3730  decode.d4.loss_mask: 0.8552  decode.d4.loss_dice: 1.2399  decode.d5.loss_cls: 1.3703  decode.d5.loss_mask: 0.8399  decode.d5.loss_dice: 1.2445  decode.d6.loss_cls: 1.3381  decode.d6.loss_mask: 0.8338  decode.d6.loss_dice: 1.2226  decode.d7.loss_cls: 1.3623  decode.d7.loss_mask: 0.8285  decode.d7.loss_dice: 1.2165  decode.d8.loss_cls: 1.3326  decode.d8.loss_mask: 0.8362  decode.d8.loss_dice: 1.2274
2023/05/24 08:44:42 - mmengine - INFO - Iter(train) [116900/160000]  lr: 3.0713e-06  eta: 5:10:31  time: 0.4157  data_time: 0.0105  memory: 4831  grad_norm: 88.9914  loss: 37.8295  decode.loss_cls: 1.4557  decode.loss_mask: 0.7555  decode.loss_dice: 1.3181  decode.d0.loss_cls: 3.2188  decode.d0.loss_mask: 0.8214  decode.d0.loss_dice: 1.6222  decode.d1.loss_cls: 1.6254  decode.d1.loss_mask: 0.7687  decode.d1.loss_dice: 1.3653  decode.d2.loss_cls: 1.5051  decode.d2.loss_mask: 0.7825  decode.d2.loss_dice: 1.3689  decode.d3.loss_cls: 1.4490  decode.d3.loss_mask: 0.7544  decode.d3.loss_dice: 1.3132  decode.d4.loss_cls: 1.4161  decode.d4.loss_mask: 0.7497  decode.d4.loss_dice: 1.3480  decode.d5.loss_cls: 1.4923  decode.d5.loss_mask: 0.7236  decode.d5.loss_dice: 1.3220  decode.d6.loss_cls: 1.5194  decode.d6.loss_mask: 0.7085  decode.d6.loss_dice: 1.3084  decode.d7.loss_cls: 1.5019  decode.d7.loss_mask: 0.7474  decode.d7.loss_dice: 1.3228  decode.d8.loss_cls: 1.4781  decode.d8.loss_mask: 0.7528  decode.d8.loss_dice: 1.3144
2023/05/24 08:45:03 - mmengine - INFO - Iter(train) [116950/160000]  lr: 3.0681e-06  eta: 5:10:09  time: 0.4241  data_time: 0.0106  memory: 4891  grad_norm: 93.6742  loss: 34.8605  decode.loss_cls: 1.2781  decode.loss_mask: 0.6834  decode.loss_dice: 1.2607  decode.d0.loss_cls: 3.3609  decode.d0.loss_mask: 0.7702  decode.d0.loss_dice: 1.3785  decode.d1.loss_cls: 1.3609  decode.d1.loss_mask: 0.7485  decode.d1.loss_dice: 1.4074  decode.d2.loss_cls: 1.2991  decode.d2.loss_mask: 0.7109  decode.d2.loss_dice: 1.3434  decode.d3.loss_cls: 1.3607  decode.d3.loss_mask: 0.6753  decode.d3.loss_dice: 1.2630  decode.d4.loss_cls: 1.3452  decode.d4.loss_mask: 0.6672  decode.d4.loss_dice: 1.2352  decode.d5.loss_cls: 1.2816  decode.d5.loss_mask: 0.6694  decode.d5.loss_dice: 1.2400  decode.d6.loss_cls: 1.3171  decode.d6.loss_mask: 0.6688  decode.d6.loss_dice: 1.1672  decode.d7.loss_cls: 1.2958  decode.d7.loss_mask: 0.6742  decode.d7.loss_dice: 1.2230  decode.d8.loss_cls: 1.2677  decode.d8.loss_mask: 0.6806  decode.d8.loss_dice: 1.2267
2023/05/24 08:45:24 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 08:45:24 - mmengine - INFO - Iter(train) [117000/160000]  lr: 3.0649e-06  eta: 5:09:47  time: 0.4210  data_time: 0.0106  memory: 4846  grad_norm: 92.3492  loss: 33.0516  decode.loss_cls: 1.1397  decode.loss_mask: 0.7251  decode.loss_dice: 1.1242  decode.d0.loss_cls: 3.0504  decode.d0.loss_mask: 0.7968  decode.d0.loss_dice: 1.3674  decode.d1.loss_cls: 1.2314  decode.d1.loss_mask: 0.8487  decode.d1.loss_dice: 1.2894  decode.d2.loss_cls: 1.1893  decode.d2.loss_mask: 0.7856  decode.d2.loss_dice: 1.1825  decode.d3.loss_cls: 1.2004  decode.d3.loss_mask: 0.7702  decode.d3.loss_dice: 1.1737  decode.d4.loss_cls: 1.1420  decode.d4.loss_mask: 0.7623  decode.d4.loss_dice: 1.1368  decode.d5.loss_cls: 1.1732  decode.d5.loss_mask: 0.7593  decode.d5.loss_dice: 1.1489  decode.d6.loss_cls: 1.1524  decode.d6.loss_mask: 0.7346  decode.d6.loss_dice: 1.1300  decode.d7.loss_cls: 1.1478  decode.d7.loss_mask: 0.7258  decode.d7.loss_dice: 1.1491  decode.d8.loss_cls: 1.1392  decode.d8.loss_mask: 0.7389  decode.d8.loss_dice: 1.1364
2023/05/24 08:45:24 - mmengine - INFO - Saving checkpoint at 117000 iterations
2023/05/24 08:45:53 - mmengine - INFO - Iter(train) [117050/160000]  lr: 3.0617e-06  eta: 5:09:28  time: 0.4848  data_time: 0.0112  memory: 4861  grad_norm: 103.3666  loss: 29.7277  decode.loss_cls: 0.9681  decode.loss_mask: 0.6961  decode.loss_dice: 1.0696  decode.d0.loss_cls: 3.0071  decode.d0.loss_mask: 0.6861  decode.d0.loss_dice: 1.1493  decode.d1.loss_cls: 1.0683  decode.d1.loss_mask: 0.7193  decode.d1.loss_dice: 1.1543  decode.d2.loss_cls: 0.9948  decode.d2.loss_mask: 0.7060  decode.d2.loss_dice: 1.0776  decode.d3.loss_cls: 0.9927  decode.d3.loss_mask: 0.6898  decode.d3.loss_dice: 1.0708  decode.d4.loss_cls: 0.9936  decode.d4.loss_mask: 0.6960  decode.d4.loss_dice: 1.0773  decode.d5.loss_cls: 0.9854  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 1.0593  decode.d6.loss_cls: 0.9778  decode.d6.loss_mask: 0.6881  decode.d6.loss_dice: 1.0409  decode.d7.loss_cls: 0.9766  decode.d7.loss_mask: 0.6878  decode.d7.loss_dice: 1.0625  decode.d8.loss_cls: 0.9963  decode.d8.loss_mask: 0.6738  decode.d8.loss_dice: 1.0684
2023/05/24 08:46:16 - mmengine - INFO - Iter(train) [117100/160000]  lr: 3.0585e-06  eta: 5:09:07  time: 0.4723  data_time: 0.0106  memory: 4829  grad_norm: 89.6259  loss: 42.4081  decode.loss_cls: 1.3386  decode.loss_mask: 0.9109  decode.loss_dice: 1.6188  decode.d0.loss_cls: 3.4145  decode.d0.loss_mask: 1.1031  decode.d0.loss_dice: 1.9602  decode.d1.loss_cls: 1.5113  decode.d1.loss_mask: 1.0207  decode.d1.loss_dice: 1.8121  decode.d2.loss_cls: 1.3825  decode.d2.loss_mask: 1.0065  decode.d2.loss_dice: 1.7708  decode.d3.loss_cls: 1.3563  decode.d3.loss_mask: 0.9472  decode.d3.loss_dice: 1.6692  decode.d4.loss_cls: 1.3498  decode.d4.loss_mask: 0.9273  decode.d4.loss_dice: 1.6752  decode.d5.loss_cls: 1.3704  decode.d5.loss_mask: 0.9372  decode.d5.loss_dice: 1.6248  decode.d6.loss_cls: 1.3567  decode.d6.loss_mask: 0.9261  decode.d6.loss_dice: 1.6024  decode.d7.loss_cls: 1.3842  decode.d7.loss_mask: 0.9317  decode.d7.loss_dice: 1.6079  decode.d8.loss_cls: 1.3551  decode.d8.loss_mask: 0.9341  decode.d8.loss_dice: 1.6026
2023/05/24 08:46:39 - mmengine - INFO - Iter(train) [117150/160000]  lr: 3.0553e-06  eta: 5:08:45  time: 0.4281  data_time: 0.0104  memory: 4863  grad_norm: 134.1847  loss: 32.4465  decode.loss_cls: 1.0192  decode.loss_mask: 0.7243  decode.loss_dice: 1.2759  decode.d0.loss_cls: 2.9665  decode.d0.loss_mask: 0.7381  decode.d0.loss_dice: 1.3792  decode.d1.loss_cls: 1.1145  decode.d1.loss_mask: 0.7518  decode.d1.loss_dice: 1.3951  decode.d2.loss_cls: 1.0670  decode.d2.loss_mask: 0.7364  decode.d2.loss_dice: 1.3101  decode.d3.loss_cls: 1.1106  decode.d3.loss_mask: 0.7009  decode.d3.loss_dice: 1.2402  decode.d4.loss_cls: 1.0476  decode.d4.loss_mask: 0.7007  decode.d4.loss_dice: 1.2265  decode.d5.loss_cls: 1.0767  decode.d5.loss_mask: 0.7069  decode.d5.loss_dice: 1.2570  decode.d6.loss_cls: 1.0367  decode.d6.loss_mask: 0.7239  decode.d6.loss_dice: 1.2311  decode.d7.loss_cls: 1.0179  decode.d7.loss_mask: 0.7033  decode.d7.loss_dice: 1.2586  decode.d8.loss_cls: 0.9801  decode.d8.loss_mask: 0.7189  decode.d8.loss_dice: 1.2308
2023/05/24 08:47:00 - mmengine - INFO - Iter(train) [117200/160000]  lr: 3.0521e-06  eta: 5:08:24  time: 0.4179  data_time: 0.0104  memory: 4899  grad_norm: 103.2986  loss: 36.4284  decode.loss_cls: 1.2403  decode.loss_mask: 0.8079  decode.loss_dice: 1.3123  decode.d0.loss_cls: 2.9163  decode.d0.loss_mask: 0.9065  decode.d0.loss_dice: 1.5508  decode.d1.loss_cls: 1.3858  decode.d1.loss_mask: 0.8506  decode.d1.loss_dice: 1.4344  decode.d2.loss_cls: 1.3318  decode.d2.loss_mask: 0.8181  decode.d2.loss_dice: 1.3669  decode.d3.loss_cls: 1.3077  decode.d3.loss_mask: 0.8152  decode.d3.loss_dice: 1.3152  decode.d4.loss_cls: 1.2765  decode.d4.loss_mask: 0.8124  decode.d4.loss_dice: 1.3479  decode.d5.loss_cls: 1.2346  decode.d5.loss_mask: 0.8116  decode.d5.loss_dice: 1.3509  decode.d6.loss_cls: 1.2179  decode.d6.loss_mask: 0.8575  decode.d6.loss_dice: 1.3392  decode.d7.loss_cls: 1.2136  decode.d7.loss_mask: 0.8610  decode.d7.loss_dice: 1.3600  decode.d8.loss_cls: 1.2269  decode.d8.loss_mask: 0.8224  decode.d8.loss_dice: 1.3361
2023/05/24 08:47:22 - mmengine - INFO - Iter(train) [117250/160000]  lr: 3.0489e-06  eta: 5:08:02  time: 0.4545  data_time: 0.0105  memory: 4970  grad_norm: 96.8334  loss: 28.5998  decode.loss_cls: 0.8967  decode.loss_mask: 0.7062  decode.loss_dice: 0.9516  decode.d0.loss_cls: 2.9571  decode.d0.loss_mask: 0.8241  decode.d0.loss_dice: 1.0837  decode.d1.loss_cls: 1.0421  decode.d1.loss_mask: 0.7039  decode.d1.loss_dice: 1.0835  decode.d2.loss_cls: 0.9901  decode.d2.loss_mask: 0.7022  decode.d2.loss_dice: 1.0469  decode.d3.loss_cls: 0.9913  decode.d3.loss_mask: 0.7021  decode.d3.loss_dice: 1.0013  decode.d4.loss_cls: 0.9292  decode.d4.loss_mask: 0.6875  decode.d4.loss_dice: 0.9920  decode.d5.loss_cls: 0.9200  decode.d5.loss_mask: 0.7004  decode.d5.loss_dice: 0.9361  decode.d6.loss_cls: 0.9641  decode.d6.loss_mask: 0.6884  decode.d6.loss_dice: 0.9599  decode.d7.loss_cls: 0.9252  decode.d7.loss_mask: 0.6875  decode.d7.loss_dice: 0.9523  decode.d8.loss_cls: 0.8905  decode.d8.loss_mask: 0.7110  decode.d8.loss_dice: 0.9727
2023/05/24 08:47:46 - mmengine - INFO - Iter(train) [117300/160000]  lr: 3.0456e-06  eta: 5:07:41  time: 0.4761  data_time: 0.0105  memory: 4793  grad_norm: 89.9327  loss: 34.5093  decode.loss_cls: 1.0143  decode.loss_mask: 0.8215  decode.loss_dice: 1.3253  decode.d0.loss_cls: 2.9886  decode.d0.loss_mask: 0.8653  decode.d0.loss_dice: 1.4702  decode.d1.loss_cls: 1.0646  decode.d1.loss_mask: 0.8944  decode.d1.loss_dice: 1.4362  decode.d2.loss_cls: 1.0284  decode.d2.loss_mask: 0.8787  decode.d2.loss_dice: 1.3899  decode.d3.loss_cls: 1.0997  decode.d3.loss_mask: 0.8329  decode.d3.loss_dice: 1.3600  decode.d4.loss_cls: 1.0296  decode.d4.loss_mask: 0.8427  decode.d4.loss_dice: 1.3697  decode.d5.loss_cls: 1.0058  decode.d5.loss_mask: 0.8561  decode.d5.loss_dice: 1.3800  decode.d6.loss_cls: 1.0278  decode.d6.loss_mask: 0.8495  decode.d6.loss_dice: 1.3138  decode.d7.loss_cls: 1.0101  decode.d7.loss_mask: 0.8442  decode.d7.loss_dice: 1.3327  decode.d8.loss_cls: 1.0182  decode.d8.loss_mask: 0.8435  decode.d8.loss_dice: 1.3158
2023/05/24 08:48:07 - mmengine - INFO - Iter(train) [117350/160000]  lr: 3.0424e-06  eta: 5:07:20  time: 0.4337  data_time: 0.0103  memory: 4835  grad_norm: 92.2823  loss: 35.4187  decode.loss_cls: 1.3030  decode.loss_mask: 0.6743  decode.loss_dice: 1.3173  decode.d0.loss_cls: 2.9962  decode.d0.loss_mask: 0.7175  decode.d0.loss_dice: 1.5167  decode.d1.loss_cls: 1.4568  decode.d1.loss_mask: 0.6833  decode.d1.loss_dice: 1.4468  decode.d2.loss_cls: 1.4002  decode.d2.loss_mask: 0.6523  decode.d2.loss_dice: 1.3530  decode.d3.loss_cls: 1.3764  decode.d3.loss_mask: 0.6797  decode.d3.loss_dice: 1.3323  decode.d4.loss_cls: 1.3295  decode.d4.loss_mask: 0.6680  decode.d4.loss_dice: 1.2833  decode.d5.loss_cls: 1.3443  decode.d5.loss_mask: 0.6570  decode.d5.loss_dice: 1.3051  decode.d6.loss_cls: 1.3840  decode.d6.loss_mask: 0.6613  decode.d6.loss_dice: 1.2780  decode.d7.loss_cls: 1.3310  decode.d7.loss_mask: 0.6507  decode.d7.loss_dice: 1.2958  decode.d8.loss_cls: 1.3514  decode.d8.loss_mask: 0.6563  decode.d8.loss_dice: 1.3174
2023/05/24 08:48:29 - mmengine - INFO - Iter(train) [117400/160000]  lr: 3.0392e-06  eta: 5:06:58  time: 0.4371  data_time: 0.0110  memory: 4839  grad_norm: 91.5784  loss: 35.0918  decode.loss_cls: 1.2450  decode.loss_mask: 0.7985  decode.loss_dice: 1.2150  decode.d0.loss_cls: 3.0599  decode.d0.loss_mask: 0.9362  decode.d0.loss_dice: 1.4542  decode.d1.loss_cls: 1.2450  decode.d1.loss_mask: 0.8775  decode.d1.loss_dice: 1.3500  decode.d2.loss_cls: 1.2874  decode.d2.loss_mask: 0.8375  decode.d2.loss_dice: 1.2860  decode.d3.loss_cls: 1.2520  decode.d3.loss_mask: 0.8164  decode.d3.loss_dice: 1.2153  decode.d4.loss_cls: 1.2362  decode.d4.loss_mask: 0.8056  decode.d4.loss_dice: 1.2153  decode.d5.loss_cls: 1.2425  decode.d5.loss_mask: 0.7941  decode.d5.loss_dice: 1.2077  decode.d6.loss_cls: 1.2422  decode.d6.loss_mask: 0.7968  decode.d6.loss_dice: 1.1993  decode.d7.loss_cls: 1.2452  decode.d7.loss_mask: 0.8051  decode.d7.loss_dice: 1.1772  decode.d8.loss_cls: 1.2416  decode.d8.loss_mask: 0.8048  decode.d8.loss_dice: 1.2027
2023/05/24 08:48:50 - mmengine - INFO - Iter(train) [117450/160000]  lr: 3.0360e-06  eta: 5:06:36  time: 0.4297  data_time: 0.0105  memory: 4885  grad_norm: 97.4202  loss: 34.9645  decode.loss_cls: 1.4693  decode.loss_mask: 0.6711  decode.loss_dice: 1.1032  decode.d0.loss_cls: 3.2892  decode.d0.loss_mask: 0.7005  decode.d0.loss_dice: 1.3165  decode.d1.loss_cls: 1.5923  decode.d1.loss_mask: 0.7015  decode.d1.loss_dice: 1.2117  decode.d2.loss_cls: 1.5168  decode.d2.loss_mask: 0.6932  decode.d2.loss_dice: 1.1564  decode.d3.loss_cls: 1.5321  decode.d3.loss_mask: 0.6746  decode.d3.loss_dice: 1.1061  decode.d4.loss_cls: 1.5802  decode.d4.loss_mask: 0.6604  decode.d4.loss_dice: 1.0842  decode.d5.loss_cls: 1.5301  decode.d5.loss_mask: 0.6620  decode.d5.loss_dice: 1.0766  decode.d6.loss_cls: 1.4842  decode.d6.loss_mask: 0.6710  decode.d6.loss_dice: 1.0651  decode.d7.loss_cls: 1.4972  decode.d7.loss_mask: 0.6473  decode.d7.loss_dice: 1.0622  decode.d8.loss_cls: 1.4812  decode.d8.loss_mask: 0.6604  decode.d8.loss_dice: 1.0678
2023/05/24 08:49:11 - mmengine - INFO - Iter(train) [117500/160000]  lr: 3.0328e-06  eta: 5:06:15  time: 0.4169  data_time: 0.0106  memory: 4856  grad_norm: 90.6702  loss: 39.1353  decode.loss_cls: 1.2557  decode.loss_mask: 0.8463  decode.loss_dice: 1.4768  decode.d0.loss_cls: 3.3123  decode.d0.loss_mask: 0.9325  decode.d0.loss_dice: 1.7198  decode.d1.loss_cls: 1.3584  decode.d1.loss_mask: 0.8510  decode.d1.loss_dice: 1.5504  decode.d2.loss_cls: 1.3614  decode.d2.loss_mask: 0.8695  decode.d2.loss_dice: 1.5247  decode.d3.loss_cls: 1.2859  decode.d3.loss_mask: 0.8764  decode.d3.loss_dice: 1.5278  decode.d4.loss_cls: 1.3420  decode.d4.loss_mask: 0.8605  decode.d4.loss_dice: 1.5163  decode.d5.loss_cls: 1.3620  decode.d5.loss_mask: 0.8444  decode.d5.loss_dice: 1.4848  decode.d6.loss_cls: 1.3063  decode.d6.loss_mask: 0.8761  decode.d6.loss_dice: 1.5181  decode.d7.loss_cls: 1.2853  decode.d7.loss_mask: 0.8568  decode.d7.loss_dice: 1.5144  decode.d8.loss_cls: 1.2940  decode.d8.loss_mask: 0.8188  decode.d8.loss_dice: 1.5066
2023/05/24 08:49:33 - mmengine - INFO - Iter(train) [117550/160000]  lr: 3.0296e-06  eta: 5:05:53  time: 0.4664  data_time: 0.0104  memory: 4886  grad_norm: 103.7849  loss: 29.6156  decode.loss_cls: 1.0329  decode.loss_mask: 0.6022  decode.loss_dice: 1.0988  decode.d0.loss_cls: 2.8899  decode.d0.loss_mask: 0.6270  decode.d0.loss_dice: 1.3326  decode.d1.loss_cls: 1.1263  decode.d1.loss_mask: 0.6087  decode.d1.loss_dice: 1.1998  decode.d2.loss_cls: 1.0218  decode.d2.loss_mask: 0.5901  decode.d2.loss_dice: 1.1685  decode.d3.loss_cls: 1.0169  decode.d3.loss_mask: 0.5707  decode.d3.loss_dice: 1.1585  decode.d4.loss_cls: 1.0113  decode.d4.loss_mask: 0.5695  decode.d4.loss_dice: 1.1298  decode.d5.loss_cls: 1.0528  decode.d5.loss_mask: 0.5771  decode.d5.loss_dice: 1.1054  decode.d6.loss_cls: 1.0023  decode.d6.loss_mask: 0.5799  decode.d6.loss_dice: 1.1122  decode.d7.loss_cls: 1.0030  decode.d7.loss_mask: 0.5796  decode.d7.loss_dice: 1.1258  decode.d8.loss_cls: 1.0017  decode.d8.loss_mask: 0.5982  decode.d8.loss_dice: 1.1224
2023/05/24 08:49:54 - mmengine - INFO - Iter(train) [117600/160000]  lr: 3.0264e-06  eta: 5:05:31  time: 0.4164  data_time: 0.0107  memory: 4936  grad_norm: 89.1724  loss: 27.1080  decode.loss_cls: 1.0038  decode.loss_mask: 0.5930  decode.loss_dice: 0.8742  decode.d0.loss_cls: 2.7827  decode.d0.loss_mask: 0.6291  decode.d0.loss_dice: 0.9820  decode.d1.loss_cls: 1.1454  decode.d1.loss_mask: 0.5732  decode.d1.loss_dice: 0.9712  decode.d2.loss_cls: 0.9790  decode.d2.loss_mask: 0.5974  decode.d2.loss_dice: 0.9511  decode.d3.loss_cls: 1.0364  decode.d3.loss_mask: 0.6294  decode.d3.loss_dice: 0.9324  decode.d4.loss_cls: 1.0086  decode.d4.loss_mask: 0.6143  decode.d4.loss_dice: 0.9036  decode.d5.loss_cls: 0.9701  decode.d5.loss_mask: 0.6110  decode.d5.loss_dice: 0.8922  decode.d6.loss_cls: 1.0072  decode.d6.loss_mask: 0.5975  decode.d6.loss_dice: 0.8703  decode.d7.loss_cls: 1.0110  decode.d7.loss_mask: 0.5945  decode.d7.loss_dice: 0.8606  decode.d8.loss_cls: 1.0260  decode.d8.loss_mask: 0.5881  decode.d8.loss_dice: 0.8726
2023/05/24 08:50:16 - mmengine - INFO - Iter(train) [117650/160000]  lr: 3.0232e-06  eta: 5:05:10  time: 0.4311  data_time: 0.0103  memory: 4846  grad_norm: 94.8227  loss: 28.2457  decode.loss_cls: 0.9787  decode.loss_mask: 0.6279  decode.loss_dice: 0.9497  decode.d0.loss_cls: 2.7332  decode.d0.loss_mask: 0.6984  decode.d0.loss_dice: 1.1409  decode.d1.loss_cls: 1.0153  decode.d1.loss_mask: 0.7405  decode.d1.loss_dice: 1.0936  decode.d2.loss_cls: 1.0887  decode.d2.loss_mask: 0.6658  decode.d2.loss_dice: 1.0095  decode.d3.loss_cls: 1.0268  decode.d3.loss_mask: 0.6373  decode.d3.loss_dice: 0.9692  decode.d4.loss_cls: 1.0339  decode.d4.loss_mask: 0.6249  decode.d4.loss_dice: 0.9493  decode.d5.loss_cls: 0.9806  decode.d5.loss_mask: 0.6259  decode.d5.loss_dice: 0.9673  decode.d6.loss_cls: 0.9997  decode.d6.loss_mask: 0.6194  decode.d6.loss_dice: 0.9510  decode.d7.loss_cls: 0.9913  decode.d7.loss_mask: 0.6287  decode.d7.loss_dice: 0.9512  decode.d8.loss_cls: 0.9519  decode.d8.loss_mask: 0.6353  decode.d8.loss_dice: 0.9598
2023/05/24 08:50:38 - mmengine - INFO - Iter(train) [117700/160000]  lr: 3.0200e-06  eta: 5:04:48  time: 0.4786  data_time: 0.0104  memory: 5011  grad_norm: 84.8634  loss: 38.9776  decode.loss_cls: 1.2012  decode.loss_mask: 1.0800  decode.loss_dice: 1.4056  decode.d0.loss_cls: 3.1750  decode.d0.loss_mask: 1.0695  decode.d0.loss_dice: 1.6146  decode.d1.loss_cls: 1.2374  decode.d1.loss_mask: 1.0522  decode.d1.loss_dice: 1.5112  decode.d2.loss_cls: 1.1983  decode.d2.loss_mask: 1.1108  decode.d2.loss_dice: 1.4618  decode.d3.loss_cls: 1.1175  decode.d3.loss_mask: 1.0891  decode.d3.loss_dice: 1.4485  decode.d4.loss_cls: 1.0569  decode.d4.loss_mask: 1.1069  decode.d4.loss_dice: 1.4081  decode.d5.loss_cls: 1.1775  decode.d5.loss_mask: 1.0438  decode.d5.loss_dice: 1.4100  decode.d6.loss_cls: 1.1450  decode.d6.loss_mask: 1.0745  decode.d6.loss_dice: 1.4072  decode.d7.loss_cls: 1.1668  decode.d7.loss_mask: 1.0729  decode.d7.loss_dice: 1.4118  decode.d8.loss_cls: 1.2320  decode.d8.loss_mask: 1.0787  decode.d8.loss_dice: 1.4127
2023/05/24 08:51:00 - mmengine - INFO - Iter(train) [117750/160000]  lr: 3.0167e-06  eta: 5:04:27  time: 0.4177  data_time: 0.0104  memory: 4991  grad_norm: 95.6113  loss: 39.8047  decode.loss_cls: 1.3811  decode.loss_mask: 0.6980  decode.loss_dice: 1.6566  decode.d0.loss_cls: 3.0085  decode.d0.loss_mask: 0.7758  decode.d0.loss_dice: 1.9137  decode.d1.loss_cls: 1.3875  decode.d1.loss_mask: 0.7507  decode.d1.loss_dice: 1.8419  decode.d2.loss_cls: 1.3198  decode.d2.loss_mask: 0.7683  decode.d2.loss_dice: 1.7481  decode.d3.loss_cls: 1.3621  decode.d3.loss_mask: 0.7233  decode.d3.loss_dice: 1.7108  decode.d4.loss_cls: 1.3456  decode.d4.loss_mask: 0.7325  decode.d4.loss_dice: 1.6913  decode.d5.loss_cls: 1.3902  decode.d5.loss_mask: 0.7050  decode.d5.loss_dice: 1.6649  decode.d6.loss_cls: 1.3498  decode.d6.loss_mask: 0.7197  decode.d6.loss_dice: 1.6640  decode.d7.loss_cls: 1.3509  decode.d7.loss_mask: 0.7344  decode.d7.loss_dice: 1.6864  decode.d8.loss_cls: 1.3246  decode.d8.loss_mask: 0.7281  decode.d8.loss_dice: 1.6710
2023/05/24 08:51:21 - mmengine - INFO - Iter(train) [117800/160000]  lr: 3.0135e-06  eta: 5:04:05  time: 0.4171  data_time: 0.0105  memory: 4869  grad_norm: 105.2891  loss: 28.9744  decode.loss_cls: 0.8943  decode.loss_mask: 0.6528  decode.loss_dice: 1.0263  decode.d0.loss_cls: 2.9022  decode.d0.loss_mask: 0.7255  decode.d0.loss_dice: 1.1840  decode.d1.loss_cls: 1.0401  decode.d1.loss_mask: 0.6538  decode.d1.loss_dice: 1.1488  decode.d2.loss_cls: 0.9821  decode.d2.loss_mask: 0.6998  decode.d2.loss_dice: 1.0981  decode.d3.loss_cls: 0.9583  decode.d3.loss_mask: 0.6734  decode.d3.loss_dice: 1.0673  decode.d4.loss_cls: 1.0082  decode.d4.loss_mask: 0.6850  decode.d4.loss_dice: 1.0678  decode.d5.loss_cls: 0.9711  decode.d5.loss_mask: 0.6544  decode.d5.loss_dice: 1.0479  decode.d6.loss_cls: 0.9660  decode.d6.loss_mask: 0.6486  decode.d6.loss_dice: 1.0026  decode.d7.loss_cls: 0.9300  decode.d7.loss_mask: 0.6538  decode.d7.loss_dice: 1.0289  decode.d8.loss_cls: 0.9161  decode.d8.loss_mask: 0.6595  decode.d8.loss_dice: 1.0279
2023/05/24 08:51:43 - mmengine - INFO - Iter(train) [117850/160000]  lr: 3.0103e-06  eta: 5:03:43  time: 0.4256  data_time: 0.0105  memory: 4800  grad_norm: 101.1955  loss: 35.1854  decode.loss_cls: 1.2582  decode.loss_mask: 0.7427  decode.loss_dice: 1.2162  decode.d0.loss_cls: 3.3184  decode.d0.loss_mask: 0.8239  decode.d0.loss_dice: 1.4886  decode.d1.loss_cls: 1.3092  decode.d1.loss_mask: 0.8035  decode.d1.loss_dice: 1.3739  decode.d2.loss_cls: 1.2774  decode.d2.loss_mask: 0.7786  decode.d2.loss_dice: 1.3068  decode.d3.loss_cls: 1.2769  decode.d3.loss_mask: 0.7614  decode.d3.loss_dice: 1.2648  decode.d4.loss_cls: 1.2047  decode.d4.loss_mask: 0.8033  decode.d4.loss_dice: 1.2839  decode.d5.loss_cls: 1.2073  decode.d5.loss_mask: 0.7615  decode.d5.loss_dice: 1.2858  decode.d6.loss_cls: 1.2453  decode.d6.loss_mask: 0.7481  decode.d6.loss_dice: 1.2325  decode.d7.loss_cls: 1.2056  decode.d7.loss_mask: 0.7537  decode.d7.loss_dice: 1.2463  decode.d8.loss_cls: 1.2364  decode.d8.loss_mask: 0.7527  decode.d8.loss_dice: 1.2176
2023/05/24 08:52:04 - mmengine - INFO - Iter(train) [117900/160000]  lr: 3.0071e-06  eta: 5:03:22  time: 0.4232  data_time: 0.0106  memory: 4875  grad_norm: 87.0780  loss: 34.2066  decode.loss_cls: 0.9773  decode.loss_mask: 0.7387  decode.loss_dice: 1.3797  decode.d0.loss_cls: 3.2662  decode.d0.loss_mask: 0.7999  decode.d0.loss_dice: 1.5682  decode.d1.loss_cls: 1.1376  decode.d1.loss_mask: 0.7747  decode.d1.loss_dice: 1.4378  decode.d2.loss_cls: 1.1268  decode.d2.loss_mask: 0.7448  decode.d2.loss_dice: 1.4194  decode.d3.loss_cls: 1.0446  decode.d3.loss_mask: 0.7305  decode.d3.loss_dice: 1.3956  decode.d4.loss_cls: 1.0619  decode.d4.loss_mask: 0.7324  decode.d4.loss_dice: 1.4109  decode.d5.loss_cls: 0.9908  decode.d5.loss_mask: 0.7269  decode.d5.loss_dice: 1.3917  decode.d6.loss_cls: 0.9936  decode.d6.loss_mask: 0.7471  decode.d6.loss_dice: 1.3864  decode.d7.loss_cls: 0.9566  decode.d7.loss_mask: 0.7475  decode.d7.loss_dice: 1.4132  decode.d8.loss_cls: 0.9430  decode.d8.loss_mask: 0.7415  decode.d8.loss_dice: 1.4212
2023/05/24 08:52:26 - mmengine - INFO - Iter(train) [117950/160000]  lr: 3.0039e-06  eta: 5:03:00  time: 0.4539  data_time: 0.0105  memory: 4819  grad_norm: 100.2411  loss: 35.0151  decode.loss_cls: 1.1941  decode.loss_mask: 0.7248  decode.loss_dice: 1.3524  decode.d0.loss_cls: 3.0790  decode.d0.loss_mask: 0.8029  decode.d0.loss_dice: 1.6190  decode.d1.loss_cls: 1.2006  decode.d1.loss_mask: 0.7906  decode.d1.loss_dice: 1.4443  decode.d2.loss_cls: 1.1697  decode.d2.loss_mask: 0.7397  decode.d2.loss_dice: 1.3750  decode.d3.loss_cls: 1.1353  decode.d3.loss_mask: 0.7569  decode.d3.loss_dice: 1.3443  decode.d4.loss_cls: 1.1823  decode.d4.loss_mask: 0.7367  decode.d4.loss_dice: 1.3728  decode.d5.loss_cls: 1.1777  decode.d5.loss_mask: 0.7454  decode.d5.loss_dice: 1.3498  decode.d6.loss_cls: 1.1430  decode.d6.loss_mask: 0.7350  decode.d6.loss_dice: 1.3440  decode.d7.loss_cls: 1.1560  decode.d7.loss_mask: 0.7258  decode.d7.loss_dice: 1.3502  decode.d8.loss_cls: 1.1466  decode.d8.loss_mask: 0.7469  decode.d8.loss_dice: 1.3744
2023/05/24 08:52:48 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 08:52:48 - mmengine - INFO - Iter(train) [118000/160000]  lr: 3.0007e-06  eta: 5:02:39  time: 0.4836  data_time: 0.0103  memory: 4835  grad_norm: 92.5609  loss: 32.8444  decode.loss_cls: 1.3535  decode.loss_mask: 0.7006  decode.loss_dice: 0.9708  decode.d0.loss_cls: 3.0409  decode.d0.loss_mask: 0.8344  decode.d0.loss_dice: 1.1528  decode.d1.loss_cls: 1.4597  decode.d1.loss_mask: 0.7527  decode.d1.loss_dice: 1.0136  decode.d2.loss_cls: 1.5113  decode.d2.loss_mask: 0.7213  decode.d2.loss_dice: 0.9590  decode.d3.loss_cls: 1.3938  decode.d3.loss_mask: 0.7141  decode.d3.loss_dice: 0.9560  decode.d4.loss_cls: 1.3445  decode.d4.loss_mask: 0.7644  decode.d4.loss_dice: 0.9612  decode.d5.loss_cls: 1.3830  decode.d5.loss_mask: 0.7278  decode.d5.loss_dice: 0.9787  decode.d6.loss_cls: 1.3415  decode.d6.loss_mask: 0.7343  decode.d6.loss_dice: 0.9968  decode.d7.loss_cls: 1.3398  decode.d7.loss_mask: 0.7354  decode.d7.loss_dice: 0.9487  decode.d8.loss_cls: 1.3459  decode.d8.loss_mask: 0.7268  decode.d8.loss_dice: 0.9810
2023/05/24 08:52:48 - mmengine - INFO - Saving checkpoint at 118000 iterations
2023/05/24 08:53:17 - mmengine - INFO - Iter(train) [118050/160000]  lr: 2.9975e-06  eta: 5:02:19  time: 0.4277  data_time: 0.0109  memory: 4856  grad_norm: 93.6943  loss: 35.1170  decode.loss_cls: 1.1595  decode.loss_mask: 0.8269  decode.loss_dice: 1.1832  decode.d0.loss_cls: 3.1144  decode.d0.loss_mask: 0.9243  decode.d0.loss_dice: 1.4462  decode.d1.loss_cls: 1.3352  decode.d1.loss_mask: 0.8745  decode.d1.loss_dice: 1.3492  decode.d2.loss_cls: 1.3037  decode.d2.loss_mask: 0.7972  decode.d2.loss_dice: 1.2288  decode.d3.loss_cls: 1.2407  decode.d3.loss_mask: 0.8413  decode.d3.loss_dice: 1.2484  decode.d4.loss_cls: 1.2343  decode.d4.loss_mask: 0.8375  decode.d4.loss_dice: 1.2663  decode.d5.loss_cls: 1.1978  decode.d5.loss_mask: 0.7987  decode.d5.loss_dice: 1.2272  decode.d6.loss_cls: 1.1812  decode.d6.loss_mask: 0.8102  decode.d6.loss_dice: 1.2360  decode.d7.loss_cls: 1.1280  decode.d7.loss_mask: 0.8420  decode.d7.loss_dice: 1.2570  decode.d8.loss_cls: 1.1154  decode.d8.loss_mask: 0.8307  decode.d8.loss_dice: 1.2813
2023/05/24 08:53:38 - mmengine - INFO - Iter(train) [118100/160000]  lr: 2.9942e-06  eta: 5:01:58  time: 0.4201  data_time: 0.0110  memory: 4849  grad_norm: 97.5938  loss: 39.4116  decode.loss_cls: 1.3440  decode.loss_mask: 0.9281  decode.loss_dice: 1.3410  decode.d0.loss_cls: 3.3318  decode.d0.loss_mask: 0.9982  decode.d0.loss_dice: 1.5916  decode.d1.loss_cls: 1.4550  decode.d1.loss_mask: 1.0487  decode.d1.loss_dice: 1.4760  decode.d2.loss_cls: 1.4697  decode.d2.loss_mask: 0.9981  decode.d2.loss_dice: 1.4552  decode.d3.loss_cls: 1.4067  decode.d3.loss_mask: 0.9448  decode.d3.loss_dice: 1.4055  decode.d4.loss_cls: 1.3503  decode.d4.loss_mask: 0.9304  decode.d4.loss_dice: 1.4054  decode.d5.loss_cls: 1.3438  decode.d5.loss_mask: 0.9543  decode.d5.loss_dice: 1.3614  decode.d6.loss_cls: 1.3322  decode.d6.loss_mask: 0.9306  decode.d6.loss_dice: 1.3278  decode.d7.loss_cls: 1.3103  decode.d7.loss_mask: 0.9319  decode.d7.loss_dice: 1.3810  decode.d8.loss_cls: 1.3363  decode.d8.loss_mask: 0.9320  decode.d8.loss_dice: 1.3895
2023/05/24 08:53:59 - mmengine - INFO - Iter(train) [118150/160000]  lr: 2.9910e-06  eta: 5:01:36  time: 0.4523  data_time: 0.0111  memory: 4847  grad_norm: 94.1504  loss: 28.9366  decode.loss_cls: 0.9275  decode.loss_mask: 0.7043  decode.loss_dice: 0.9845  decode.d0.loss_cls: 2.7754  decode.d0.loss_mask: 0.7985  decode.d0.loss_dice: 1.1741  decode.d1.loss_cls: 1.0554  decode.d1.loss_mask: 0.7176  decode.d1.loss_dice: 1.0555  decode.d2.loss_cls: 1.0305  decode.d2.loss_mask: 0.6761  decode.d2.loss_dice: 1.0023  decode.d3.loss_cls: 1.0329  decode.d3.loss_mask: 0.6681  decode.d3.loss_dice: 0.9837  decode.d4.loss_cls: 0.9942  decode.d4.loss_mask: 0.7133  decode.d4.loss_dice: 0.9883  decode.d5.loss_cls: 0.9861  decode.d5.loss_mask: 0.6893  decode.d5.loss_dice: 0.9744  decode.d6.loss_cls: 0.9990  decode.d6.loss_mask: 0.6904  decode.d6.loss_dice: 0.9802  decode.d7.loss_cls: 0.9704  decode.d7.loss_mask: 0.6966  decode.d7.loss_dice: 0.9977  decode.d8.loss_cls: 0.9772  decode.d8.loss_mask: 0.6974  decode.d8.loss_dice: 0.9958
2023/05/24 08:54:21 - mmengine - INFO - Iter(train) [118200/160000]  lr: 2.9878e-06  eta: 5:01:14  time: 0.4272  data_time: 0.0106  memory: 4821  grad_norm: 91.6250  loss: 27.4735  decode.loss_cls: 0.8365  decode.loss_mask: 0.7016  decode.loss_dice: 0.9573  decode.d0.loss_cls: 2.7073  decode.d0.loss_mask: 0.7150  decode.d0.loss_dice: 1.1202  decode.d1.loss_cls: 0.9650  decode.d1.loss_mask: 0.6932  decode.d1.loss_dice: 1.0078  decode.d2.loss_cls: 0.8758  decode.d2.loss_mask: 0.7017  decode.d2.loss_dice: 0.9869  decode.d3.loss_cls: 0.8701  decode.d3.loss_mask: 0.6900  decode.d3.loss_dice: 0.9956  decode.d4.loss_cls: 0.8630  decode.d4.loss_mask: 0.6819  decode.d4.loss_dice: 0.9990  decode.d5.loss_cls: 0.8843  decode.d5.loss_mask: 0.6924  decode.d5.loss_dice: 0.9905  decode.d6.loss_cls: 0.8623  decode.d6.loss_mask: 0.6868  decode.d6.loss_dice: 0.9675  decode.d7.loss_cls: 0.8522  decode.d7.loss_mask: 0.6908  decode.d7.loss_dice: 0.9617  decode.d8.loss_cls: 0.8428  decode.d8.loss_mask: 0.7031  decode.d8.loss_dice: 0.9714
2023/05/24 08:54:42 - mmengine - INFO - Iter(train) [118250/160000]  lr: 2.9846e-06  eta: 5:00:52  time: 0.4276  data_time: 0.0109  memory: 4888  grad_norm: 112.3426  loss: 31.2477  decode.loss_cls: 0.9343  decode.loss_mask: 0.7303  decode.loss_dice: 1.1255  decode.d0.loss_cls: 2.8895  decode.d0.loss_mask: 0.8340  decode.d0.loss_dice: 1.4010  decode.d1.loss_cls: 1.0703  decode.d1.loss_mask: 0.7642  decode.d1.loss_dice: 1.2827  decode.d2.loss_cls: 0.9987  decode.d2.loss_mask: 0.7411  decode.d2.loss_dice: 1.2540  decode.d3.loss_cls: 1.0109  decode.d3.loss_mask: 0.7367  decode.d3.loss_dice: 1.1999  decode.d4.loss_cls: 0.9398  decode.d4.loss_mask: 0.7535  decode.d4.loss_dice: 1.1752  decode.d5.loss_cls: 0.9756  decode.d5.loss_mask: 0.7421  decode.d5.loss_dice: 1.1785  decode.d6.loss_cls: 0.9938  decode.d6.loss_mask: 0.7443  decode.d6.loss_dice: 1.1254  decode.d7.loss_cls: 0.9303  decode.d7.loss_mask: 0.7405  decode.d7.loss_dice: 1.1366  decode.d8.loss_cls: 0.9703  decode.d8.loss_mask: 0.7280  decode.d8.loss_dice: 1.1407
2023/05/24 08:55:03 - mmengine - INFO - Iter(train) [118300/160000]  lr: 2.9814e-06  eta: 5:00:31  time: 0.4250  data_time: 0.0105  memory: 4877  grad_norm: 93.0088  loss: 37.8105  decode.loss_cls: 1.1246  decode.loss_mask: 0.9239  decode.loss_dice: 1.3893  decode.d0.loss_cls: 3.1393  decode.d0.loss_mask: 0.9447  decode.d0.loss_dice: 1.6570  decode.d1.loss_cls: 1.2927  decode.d1.loss_mask: 0.9643  decode.d1.loss_dice: 1.5838  decode.d2.loss_cls: 1.2449  decode.d2.loss_mask: 0.9484  decode.d2.loss_dice: 1.4619  decode.d3.loss_cls: 1.2124  decode.d3.loss_mask: 0.9256  decode.d3.loss_dice: 1.4302  decode.d4.loss_cls: 1.1980  decode.d4.loss_mask: 0.9306  decode.d4.loss_dice: 1.4291  decode.d5.loss_cls: 1.2016  decode.d5.loss_mask: 0.9339  decode.d5.loss_dice: 1.3904  decode.d6.loss_cls: 1.1184  decode.d6.loss_mask: 0.9377  decode.d6.loss_dice: 1.4146  decode.d7.loss_cls: 1.1510  decode.d7.loss_mask: 0.9244  decode.d7.loss_dice: 1.4187  decode.d8.loss_cls: 1.1368  decode.d8.loss_mask: 0.9564  decode.d8.loss_dice: 1.4260
2023/05/24 08:55:24 - mmengine - INFO - Iter(train) [118350/160000]  lr: 2.9782e-06  eta: 5:00:09  time: 0.4212  data_time: 0.0104  memory: 4875  grad_norm: 89.8661  loss: 36.2931  decode.loss_cls: 1.2659  decode.loss_mask: 0.6952  decode.loss_dice: 1.3486  decode.d0.loss_cls: 3.1721  decode.d0.loss_mask: 0.7493  decode.d0.loss_dice: 1.6099  decode.d1.loss_cls: 1.4102  decode.d1.loss_mask: 0.7590  decode.d1.loss_dice: 1.4603  decode.d2.loss_cls: 1.3630  decode.d2.loss_mask: 0.7402  decode.d2.loss_dice: 1.3935  decode.d3.loss_cls: 1.3397  decode.d3.loss_mask: 0.6979  decode.d3.loss_dice: 1.3899  decode.d4.loss_cls: 1.3976  decode.d4.loss_mask: 0.7064  decode.d4.loss_dice: 1.3358  decode.d5.loss_cls: 1.3547  decode.d5.loss_mask: 0.7098  decode.d5.loss_dice: 1.3489  decode.d6.loss_cls: 1.3115  decode.d6.loss_mask: 0.6811  decode.d6.loss_dice: 1.3427  decode.d7.loss_cls: 1.3113  decode.d7.loss_mask: 0.6957  decode.d7.loss_dice: 1.3764  decode.d8.loss_cls: 1.2735  decode.d8.loss_mask: 0.7014  decode.d8.loss_dice: 1.3515
2023/05/24 08:55:47 - mmengine - INFO - Iter(train) [118400/160000]  lr: 2.9749e-06  eta: 4:59:48  time: 0.4373  data_time: 0.0104  memory: 4896  grad_norm: 85.7104  loss: 36.8065  decode.loss_cls: 1.2182  decode.loss_mask: 0.7430  decode.loss_dice: 1.4168  decode.d0.loss_cls: 3.0856  decode.d0.loss_mask: 0.8322  decode.d0.loss_dice: 1.6118  decode.d1.loss_cls: 1.3835  decode.d1.loss_mask: 0.7297  decode.d1.loss_dice: 1.5515  decode.d2.loss_cls: 1.2172  decode.d2.loss_mask: 0.7782  decode.d2.loss_dice: 1.4247  decode.d3.loss_cls: 1.2669  decode.d3.loss_mask: 0.7858  decode.d3.loss_dice: 1.4585  decode.d4.loss_cls: 1.2478  decode.d4.loss_mask: 0.7814  decode.d4.loss_dice: 1.4212  decode.d5.loss_cls: 1.2859  decode.d5.loss_mask: 0.7712  decode.d5.loss_dice: 1.4354  decode.d6.loss_cls: 1.2760  decode.d6.loss_mask: 0.7755  decode.d6.loss_dice: 1.4245  decode.d7.loss_cls: 1.2640  decode.d7.loss_mask: 0.7613  decode.d7.loss_dice: 1.4216  decode.d8.loss_cls: 1.2370  decode.d8.loss_mask: 0.7728  decode.d8.loss_dice: 1.4273
2023/05/24 08:56:08 - mmengine - INFO - Iter(train) [118450/160000]  lr: 2.9717e-06  eta: 4:59:26  time: 0.4293  data_time: 0.0115  memory: 4845  grad_norm: 89.4776  loss: 37.5294  decode.loss_cls: 1.2407  decode.loss_mask: 0.7891  decode.loss_dice: 1.3383  decode.d0.loss_cls: 3.4786  decode.d0.loss_mask: 0.8844  decode.d0.loss_dice: 1.6361  decode.d1.loss_cls: 1.3581  decode.d1.loss_mask: 0.8725  decode.d1.loss_dice: 1.5502  decode.d2.loss_cls: 1.2468  decode.d2.loss_mask: 0.8815  decode.d2.loss_dice: 1.4843  decode.d3.loss_cls: 1.3138  decode.d3.loss_mask: 0.8239  decode.d3.loss_dice: 1.3687  decode.d4.loss_cls: 1.2656  decode.d4.loss_mask: 0.8308  decode.d4.loss_dice: 1.3936  decode.d5.loss_cls: 1.2252  decode.d5.loss_mask: 0.8449  decode.d5.loss_dice: 1.3963  decode.d6.loss_cls: 1.2344  decode.d6.loss_mask: 0.8303  decode.d6.loss_dice: 1.3493  decode.d7.loss_cls: 1.2644  decode.d7.loss_mask: 0.8298  decode.d7.loss_dice: 1.3713  decode.d8.loss_cls: 1.2949  decode.d8.loss_mask: 0.7799  decode.d8.loss_dice: 1.3516
2023/05/24 08:56:30 - mmengine - INFO - Iter(train) [118500/160000]  lr: 2.9685e-06  eta: 4:59:04  time: 0.4507  data_time: 0.0120  memory: 4829  grad_norm: 107.4237  loss: 35.2393  decode.loss_cls: 1.2462  decode.loss_mask: 0.7821  decode.loss_dice: 1.2129  decode.d0.loss_cls: 3.1799  decode.d0.loss_mask: 0.8697  decode.d0.loss_dice: 1.4280  decode.d1.loss_cls: 1.3630  decode.d1.loss_mask: 0.8906  decode.d1.loss_dice: 1.4036  decode.d2.loss_cls: 1.3294  decode.d2.loss_mask: 0.8011  decode.d2.loss_dice: 1.2616  decode.d3.loss_cls: 1.2382  decode.d3.loss_mask: 0.8152  decode.d3.loss_dice: 1.2534  decode.d4.loss_cls: 1.2166  decode.d4.loss_mask: 0.7796  decode.d4.loss_dice: 1.2474  decode.d5.loss_cls: 1.2700  decode.d5.loss_mask: 0.7715  decode.d5.loss_dice: 1.1948  decode.d6.loss_cls: 1.2431  decode.d6.loss_mask: 0.7865  decode.d6.loss_dice: 1.1893  decode.d7.loss_cls: 1.2115  decode.d7.loss_mask: 0.8010  decode.d7.loss_dice: 1.2204  decode.d8.loss_cls: 1.2493  decode.d8.loss_mask: 0.7845  decode.d8.loss_dice: 1.1988
2023/05/24 08:56:51 - mmengine - INFO - Iter(train) [118550/160000]  lr: 2.9653e-06  eta: 4:58:43  time: 0.4195  data_time: 0.0107  memory: 4846  grad_norm: 95.0199  loss: 37.5337  decode.loss_cls: 1.3143  decode.loss_mask: 0.6963  decode.loss_dice: 1.3359  decode.d0.loss_cls: 3.3536  decode.d0.loss_mask: 0.7850  decode.d0.loss_dice: 1.5933  decode.d1.loss_cls: 1.6163  decode.d1.loss_mask: 0.8220  decode.d1.loss_dice: 1.5243  decode.d2.loss_cls: 1.6132  decode.d2.loss_mask: 0.7728  decode.d2.loss_dice: 1.4130  decode.d3.loss_cls: 1.4724  decode.d3.loss_mask: 0.7739  decode.d3.loss_dice: 1.3701  decode.d4.loss_cls: 1.4265  decode.d4.loss_mask: 0.7493  decode.d4.loss_dice: 1.3628  decode.d5.loss_cls: 1.4177  decode.d5.loss_mask: 0.7139  decode.d5.loss_dice: 1.3460  decode.d6.loss_cls: 1.3364  decode.d6.loss_mask: 0.6813  decode.d6.loss_dice: 1.3139  decode.d7.loss_cls: 1.3139  decode.d7.loss_mask: 0.6865  decode.d7.loss_dice: 1.3200  decode.d8.loss_cls: 1.3484  decode.d8.loss_mask: 0.6985  decode.d8.loss_dice: 1.3625
2023/05/24 08:57:12 - mmengine - INFO - Iter(train) [118600/160000]  lr: 2.9621e-06  eta: 4:58:21  time: 0.4195  data_time: 0.0102  memory: 4887  grad_norm: 83.3250  loss: 30.0832  decode.loss_cls: 0.9584  decode.loss_mask: 0.6883  decode.loss_dice: 1.1063  decode.d0.loss_cls: 2.6800  decode.d0.loss_mask: 0.7661  decode.d0.loss_dice: 1.2614  decode.d1.loss_cls: 1.0500  decode.d1.loss_mask: 0.7675  decode.d1.loss_dice: 1.1996  decode.d2.loss_cls: 1.0134  decode.d2.loss_mask: 0.7167  decode.d2.loss_dice: 1.1715  decode.d3.loss_cls: 0.9672  decode.d3.loss_mask: 0.7385  decode.d3.loss_dice: 1.1348  decode.d4.loss_cls: 0.9805  decode.d4.loss_mask: 0.7092  decode.d4.loss_dice: 1.0965  decode.d5.loss_cls: 0.9666  decode.d5.loss_mask: 0.7159  decode.d5.loss_dice: 1.1261  decode.d6.loss_cls: 0.9715  decode.d6.loss_mask: 0.7031  decode.d6.loss_dice: 1.0798  decode.d7.loss_cls: 0.9336  decode.d7.loss_mask: 0.7217  decode.d7.loss_dice: 1.1071  decode.d8.loss_cls: 0.9435  decode.d8.loss_mask: 0.7147  decode.d8.loss_dice: 1.0938
2023/05/24 08:57:34 - mmengine - INFO - Iter(train) [118650/160000]  lr: 2.9588e-06  eta: 4:57:59  time: 0.4210  data_time: 0.0105  memory: 4847  grad_norm: 86.4802  loss: 41.6161  decode.loss_cls: 1.3512  decode.loss_mask: 0.8978  decode.loss_dice: 1.6094  decode.d0.loss_cls: 3.2179  decode.d0.loss_mask: 1.0579  decode.d0.loss_dice: 1.9172  decode.d1.loss_cls: 1.4900  decode.d1.loss_mask: 0.9449  decode.d1.loss_dice: 1.7351  decode.d2.loss_cls: 1.5417  decode.d2.loss_mask: 0.8982  decode.d2.loss_dice: 1.6445  decode.d3.loss_cls: 1.4127  decode.d3.loss_mask: 0.9326  decode.d3.loss_dice: 1.6267  decode.d4.loss_cls: 1.3672  decode.d4.loss_mask: 0.9265  decode.d4.loss_dice: 1.6494  decode.d5.loss_cls: 1.3068  decode.d5.loss_mask: 0.8851  decode.d5.loss_dice: 1.6476  decode.d6.loss_cls: 1.3416  decode.d6.loss_mask: 0.9044  decode.d6.loss_dice: 1.6022  decode.d7.loss_cls: 1.3311  decode.d7.loss_mask: 0.9110  decode.d7.loss_dice: 1.6119  decode.d8.loss_cls: 1.3781  decode.d8.loss_mask: 0.8696  decode.d8.loss_dice: 1.6055
2023/05/24 08:57:55 - mmengine - INFO - Iter(train) [118700/160000]  lr: 2.9556e-06  eta: 4:57:37  time: 0.4391  data_time: 0.0106  memory: 4830  grad_norm: 85.1418  loss: 34.3131  decode.loss_cls: 1.2591  decode.loss_mask: 0.6342  decode.loss_dice: 1.2492  decode.d0.loss_cls: 3.0208  decode.d0.loss_mask: 0.7711  decode.d0.loss_dice: 1.5125  decode.d1.loss_cls: 1.2521  decode.d1.loss_mask: 0.7227  decode.d1.loss_dice: 1.3858  decode.d2.loss_cls: 1.2790  decode.d2.loss_mask: 0.6546  decode.d2.loss_dice: 1.3373  decode.d3.loss_cls: 1.2639  decode.d3.loss_mask: 0.6659  decode.d3.loss_dice: 1.2870  decode.d4.loss_cls: 1.2142  decode.d4.loss_mask: 0.6648  decode.d4.loss_dice: 1.3337  decode.d5.loss_cls: 1.2356  decode.d5.loss_mask: 0.6816  decode.d5.loss_dice: 1.2642  decode.d6.loss_cls: 1.2938  decode.d6.loss_mask: 0.6717  decode.d6.loss_dice: 1.2828  decode.d7.loss_cls: 1.2089  decode.d7.loss_mask: 0.6675  decode.d7.loss_dice: 1.3243  decode.d8.loss_cls: 1.2568  decode.d8.loss_mask: 0.6294  decode.d8.loss_dice: 1.2888
2023/05/24 08:58:18 - mmengine - INFO - Iter(train) [118750/160000]  lr: 2.9524e-06  eta: 4:57:16  time: 0.4712  data_time: 0.0107  memory: 4830  grad_norm: 84.6245  loss: 32.5916  decode.loss_cls: 0.9913  decode.loss_mask: 0.8098  decode.loss_dice: 1.2301  decode.d0.loss_cls: 2.7647  decode.d0.loss_mask: 0.8634  decode.d0.loss_dice: 1.3575  decode.d1.loss_cls: 1.0186  decode.d1.loss_mask: 0.8038  decode.d1.loss_dice: 1.3631  decode.d2.loss_cls: 1.0258  decode.d2.loss_mask: 0.7969  decode.d2.loss_dice: 1.2983  decode.d3.loss_cls: 0.9177  decode.d3.loss_mask: 0.8170  decode.d3.loss_dice: 1.2947  decode.d4.loss_cls: 0.8871  decode.d4.loss_mask: 0.8287  decode.d4.loss_dice: 1.3237  decode.d5.loss_cls: 0.9291  decode.d5.loss_mask: 0.8247  decode.d5.loss_dice: 1.3001  decode.d6.loss_cls: 0.9625  decode.d6.loss_mask: 0.8213  decode.d6.loss_dice: 1.2602  decode.d7.loss_cls: 0.9481  decode.d7.loss_mask: 0.8354  decode.d7.loss_dice: 1.2774  decode.d8.loss_cls: 0.9477  decode.d8.loss_mask: 0.8320  decode.d8.loss_dice: 1.2609
2023/05/24 08:58:40 - mmengine - INFO - Iter(train) [118800/160000]  lr: 2.9492e-06  eta: 4:56:55  time: 0.4281  data_time: 0.0107  memory: 4917  grad_norm: 112.5223  loss: 30.6315  decode.loss_cls: 0.9769  decode.loss_mask: 0.6168  decode.loss_dice: 1.1937  decode.d0.loss_cls: 2.8504  decode.d0.loss_mask: 0.6904  decode.d0.loss_dice: 1.3733  decode.d1.loss_cls: 1.0072  decode.d1.loss_mask: 0.7016  decode.d1.loss_dice: 1.3566  decode.d2.loss_cls: 0.9828  decode.d2.loss_mask: 0.6830  decode.d2.loss_dice: 1.2522  decode.d3.loss_cls: 0.9308  decode.d3.loss_mask: 0.6718  decode.d3.loss_dice: 1.2494  decode.d4.loss_cls: 1.0303  decode.d4.loss_mask: 0.6629  decode.d4.loss_dice: 1.2118  decode.d5.loss_cls: 1.0055  decode.d5.loss_mask: 0.6364  decode.d5.loss_dice: 1.1712  decode.d6.loss_cls: 0.9951  decode.d6.loss_mask: 0.6382  decode.d6.loss_dice: 1.1768  decode.d7.loss_cls: 0.9256  decode.d7.loss_mask: 0.6484  decode.d7.loss_dice: 1.1914  decode.d8.loss_cls: 0.9903  decode.d8.loss_mask: 0.6353  decode.d8.loss_dice: 1.1756
2023/05/24 08:59:02 - mmengine - INFO - Iter(train) [118850/160000]  lr: 2.9460e-06  eta: 4:56:33  time: 0.4939  data_time: 0.0138  memory: 4949  grad_norm: 90.5668  loss: 31.3248  decode.loss_cls: 0.9876  decode.loss_mask: 0.7794  decode.loss_dice: 1.1349  decode.d0.loss_cls: 3.0338  decode.d0.loss_mask: 0.8678  decode.d0.loss_dice: 1.2710  decode.d1.loss_cls: 1.0212  decode.d1.loss_mask: 0.8053  decode.d1.loss_dice: 1.2737  decode.d2.loss_cls: 0.9066  decode.d2.loss_mask: 0.7824  decode.d2.loss_dice: 1.2246  decode.d3.loss_cls: 0.8897  decode.d3.loss_mask: 0.7845  decode.d3.loss_dice: 1.1984  decode.d4.loss_cls: 0.8962  decode.d4.loss_mask: 0.7736  decode.d4.loss_dice: 1.1784  decode.d5.loss_cls: 0.9214  decode.d5.loss_mask: 0.7835  decode.d5.loss_dice: 1.1727  decode.d6.loss_cls: 0.9199  decode.d6.loss_mask: 0.7745  decode.d6.loss_dice: 1.1625  decode.d7.loss_cls: 0.9639  decode.d7.loss_mask: 0.7840  decode.d7.loss_dice: 1.1424  decode.d8.loss_cls: 0.9448  decode.d8.loss_mask: 0.7921  decode.d8.loss_dice: 1.1542
2023/05/24 08:59:26 - mmengine - INFO - Iter(train) [118900/160000]  lr: 2.9427e-06  eta: 4:56:12  time: 0.4359  data_time: 0.0109  memory: 4864  grad_norm: 112.7744  loss: 34.3111  decode.loss_cls: 1.1377  decode.loss_mask: 0.8287  decode.loss_dice: 1.2364  decode.d0.loss_cls: 3.1331  decode.d0.loss_mask: 0.8331  decode.d0.loss_dice: 1.3737  decode.d1.loss_cls: 1.1374  decode.d1.loss_mask: 0.8300  decode.d1.loss_dice: 1.2936  decode.d2.loss_cls: 1.1202  decode.d2.loss_mask: 0.8732  decode.d2.loss_dice: 1.2473  decode.d3.loss_cls: 1.1647  decode.d3.loss_mask: 0.8070  decode.d3.loss_dice: 1.2190  decode.d4.loss_cls: 1.1457  decode.d4.loss_mask: 0.8555  decode.d4.loss_dice: 1.2633  decode.d5.loss_cls: 1.1100  decode.d5.loss_mask: 0.8211  decode.d5.loss_dice: 1.2296  decode.d6.loss_cls: 1.1479  decode.d6.loss_mask: 0.8220  decode.d6.loss_dice: 1.2142  decode.d7.loss_cls: 1.1833  decode.d7.loss_mask: 0.8200  decode.d7.loss_dice: 1.2042  decode.d8.loss_cls: 1.1829  decode.d8.loss_mask: 0.8151  decode.d8.loss_dice: 1.2614
2023/05/24 08:59:48 - mmengine - INFO - Iter(train) [118950/160000]  lr: 2.9395e-06  eta: 4:55:51  time: 0.4546  data_time: 0.0106  memory: 4876  grad_norm: 85.8343  loss: 41.3043  decode.loss_cls: 1.2977  decode.loss_mask: 1.0492  decode.loss_dice: 1.5251  decode.d0.loss_cls: 3.5136  decode.d0.loss_mask: 1.0348  decode.d0.loss_dice: 1.6906  decode.d1.loss_cls: 1.4500  decode.d1.loss_mask: 1.0192  decode.d1.loss_dice: 1.5523  decode.d2.loss_cls: 1.4181  decode.d2.loss_mask: 1.0329  decode.d2.loss_dice: 1.5499  decode.d3.loss_cls: 1.3695  decode.d3.loss_mask: 1.0038  decode.d3.loss_dice: 1.5040  decode.d4.loss_cls: 1.3495  decode.d4.loss_mask: 1.0195  decode.d4.loss_dice: 1.4935  decode.d5.loss_cls: 1.3807  decode.d5.loss_mask: 1.0171  decode.d5.loss_dice: 1.4982  decode.d6.loss_cls: 1.2877  decode.d6.loss_mask: 1.0552  decode.d6.loss_dice: 1.4716  decode.d7.loss_cls: 1.3608  decode.d7.loss_mask: 1.0517  decode.d7.loss_dice: 1.4798  decode.d8.loss_cls: 1.2985  decode.d8.loss_mask: 1.0475  decode.d8.loss_dice: 1.4824
2023/05/24 09:00:10 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 09:00:10 - mmengine - INFO - Iter(train) [119000/160000]  lr: 2.9363e-06  eta: 4:55:29  time: 0.4205  data_time: 0.0102  memory: 4828  grad_norm: 90.0421  loss: 31.6287  decode.loss_cls: 1.1597  decode.loss_mask: 0.7554  decode.loss_dice: 1.0094  decode.d0.loss_cls: 2.9579  decode.d0.loss_mask: 0.7198  decode.d0.loss_dice: 1.1784  decode.d1.loss_cls: 1.2672  decode.d1.loss_mask: 0.7655  decode.d1.loss_dice: 1.1203  decode.d2.loss_cls: 1.1987  decode.d2.loss_mask: 0.7457  decode.d2.loss_dice: 1.0874  decode.d3.loss_cls: 1.1622  decode.d3.loss_mask: 0.7373  decode.d3.loss_dice: 1.0706  decode.d4.loss_cls: 1.2107  decode.d4.loss_mask: 0.7331  decode.d4.loss_dice: 1.0203  decode.d5.loss_cls: 1.1464  decode.d5.loss_mask: 0.7455  decode.d5.loss_dice: 1.0288  decode.d6.loss_cls: 1.1517  decode.d6.loss_mask: 0.7514  decode.d6.loss_dice: 1.0206  decode.d7.loss_cls: 1.1450  decode.d7.loss_mask: 0.7553  decode.d7.loss_dice: 1.0333  decode.d8.loss_cls: 1.1638  decode.d8.loss_mask: 0.7459  decode.d8.loss_dice: 1.0416
2023/05/24 09:00:10 - mmengine - INFO - Saving checkpoint at 119000 iterations
2023/05/24 09:00:38 - mmengine - INFO - Iter(train) [119050/160000]  lr: 2.9331e-06  eta: 4:55:10  time: 0.4239  data_time: 0.0105  memory: 4905  grad_norm: 87.0716  loss: 35.3428  decode.loss_cls: 1.0592  decode.loss_mask: 0.7110  decode.loss_dice: 1.4463  decode.d0.loss_cls: 3.0208  decode.d0.loss_mask: 0.7984  decode.d0.loss_dice: 1.6414  decode.d1.loss_cls: 1.3261  decode.d1.loss_mask: 0.7764  decode.d1.loss_dice: 1.5766  decode.d2.loss_cls: 1.2719  decode.d2.loss_mask: 0.7387  decode.d2.loss_dice: 1.4601  decode.d3.loss_cls: 1.1560  decode.d3.loss_mask: 0.7071  decode.d3.loss_dice: 1.4155  decode.d4.loss_cls: 1.1307  decode.d4.loss_mask: 0.7082  decode.d4.loss_dice: 1.4410  decode.d5.loss_cls: 1.0516  decode.d5.loss_mask: 0.6980  decode.d5.loss_dice: 1.4751  decode.d6.loss_cls: 1.1385  decode.d6.loss_mask: 0.6852  decode.d6.loss_dice: 1.3926  decode.d7.loss_cls: 1.1775  decode.d7.loss_mask: 0.7038  decode.d7.loss_dice: 1.4218  decode.d8.loss_cls: 1.0938  decode.d8.loss_mask: 0.6864  decode.d8.loss_dice: 1.4332
2023/05/24 09:01:00 - mmengine - INFO - Iter(train) [119100/160000]  lr: 2.9299e-06  eta: 4:54:48  time: 0.4213  data_time: 0.0108  memory: 4865  grad_norm: 101.7293  loss: 39.3690  decode.loss_cls: 1.3738  decode.loss_mask: 0.8526  decode.loss_dice: 1.3827  decode.d0.loss_cls: 3.1959  decode.d0.loss_mask: 0.9338  decode.d0.loss_dice: 1.6829  decode.d1.loss_cls: 1.5824  decode.d1.loss_mask: 0.8287  decode.d1.loss_dice: 1.4766  decode.d2.loss_cls: 1.3972  decode.d2.loss_mask: 0.8616  decode.d2.loss_dice: 1.4850  decode.d3.loss_cls: 1.5475  decode.d3.loss_mask: 0.8412  decode.d3.loss_dice: 1.4310  decode.d4.loss_cls: 1.5269  decode.d4.loss_mask: 0.8576  decode.d4.loss_dice: 1.4201  decode.d5.loss_cls: 1.4151  decode.d5.loss_mask: 0.8555  decode.d5.loss_dice: 1.4234  decode.d6.loss_cls: 1.4989  decode.d6.loss_mask: 0.8380  decode.d6.loss_dice: 1.3912  decode.d7.loss_cls: 1.4232  decode.d7.loss_mask: 0.8363  decode.d7.loss_dice: 1.3877  decode.d8.loss_cls: 1.4030  decode.d8.loss_mask: 0.8456  decode.d8.loss_dice: 1.3735
2023/05/24 09:01:21 - mmengine - INFO - Iter(train) [119150/160000]  lr: 2.9266e-06  eta: 4:54:27  time: 0.4272  data_time: 0.0111  memory: 4790  grad_norm: 91.6278  loss: 36.1347  decode.loss_cls: 1.1466  decode.loss_mask: 0.8207  decode.loss_dice: 1.2463  decode.d0.loss_cls: 3.4724  decode.d0.loss_mask: 0.8466  decode.d0.loss_dice: 1.5160  decode.d1.loss_cls: 1.4900  decode.d1.loss_mask: 0.8019  decode.d1.loss_dice: 1.3698  decode.d2.loss_cls: 1.3715  decode.d2.loss_mask: 0.8245  decode.d2.loss_dice: 1.3239  decode.d3.loss_cls: 1.2848  decode.d3.loss_mask: 0.8519  decode.d3.loss_dice: 1.2752  decode.d4.loss_cls: 1.2409  decode.d4.loss_mask: 0.8543  decode.d4.loss_dice: 1.2954  decode.d5.loss_cls: 1.1686  decode.d5.loss_mask: 0.8490  decode.d5.loss_dice: 1.3038  decode.d6.loss_cls: 1.2130  decode.d6.loss_mask: 0.8249  decode.d6.loss_dice: 1.2570  decode.d7.loss_cls: 1.1754  decode.d7.loss_mask: 0.8191  decode.d7.loss_dice: 1.2536  decode.d8.loss_cls: 1.1598  decode.d8.loss_mask: 0.8197  decode.d8.loss_dice: 1.2578
2023/05/24 09:01:43 - mmengine - INFO - Iter(train) [119200/160000]  lr: 2.9234e-06  eta: 4:54:05  time: 0.4265  data_time: 0.0105  memory: 4838  grad_norm: 106.3672  loss: 38.4015  decode.loss_cls: 1.3013  decode.loss_mask: 0.9264  decode.loss_dice: 1.3683  decode.d0.loss_cls: 2.9679  decode.d0.loss_mask: 1.0911  decode.d0.loss_dice: 1.6314  decode.d1.loss_cls: 1.3493  decode.d1.loss_mask: 1.0112  decode.d1.loss_dice: 1.4767  decode.d2.loss_cls: 1.2611  decode.d2.loss_mask: 0.9830  decode.d2.loss_dice: 1.4410  decode.d3.loss_cls: 1.3468  decode.d3.loss_mask: 0.9186  decode.d3.loss_dice: 1.3471  decode.d4.loss_cls: 1.2583  decode.d4.loss_mask: 0.9625  decode.d4.loss_dice: 1.3905  decode.d5.loss_cls: 1.3107  decode.d5.loss_mask: 0.9084  decode.d5.loss_dice: 1.3895  decode.d6.loss_cls: 1.2338  decode.d6.loss_mask: 0.9420  decode.d6.loss_dice: 1.4322  decode.d7.loss_cls: 1.2432  decode.d7.loss_mask: 0.9412  decode.d7.loss_dice: 1.4157  decode.d8.loss_cls: 1.2334  decode.d8.loss_mask: 0.9535  decode.d8.loss_dice: 1.3654
2023/05/24 09:02:05 - mmengine - INFO - Iter(train) [119250/160000]  lr: 2.9202e-06  eta: 4:53:43  time: 0.4437  data_time: 0.0105  memory: 4857  grad_norm: 100.1793  loss: 36.5227  decode.loss_cls: 1.1931  decode.loss_mask: 0.8817  decode.loss_dice: 1.3094  decode.d0.loss_cls: 3.0352  decode.d0.loss_mask: 0.8798  decode.d0.loss_dice: 1.5443  decode.d1.loss_cls: 1.2614  decode.d1.loss_mask: 0.9039  decode.d1.loss_dice: 1.4369  decode.d2.loss_cls: 1.2796  decode.d2.loss_mask: 0.9207  decode.d2.loss_dice: 1.3921  decode.d3.loss_cls: 1.2429  decode.d3.loss_mask: 0.8780  decode.d3.loss_dice: 1.2784  decode.d4.loss_cls: 1.2118  decode.d4.loss_mask: 0.8919  decode.d4.loss_dice: 1.3557  decode.d5.loss_cls: 1.2581  decode.d5.loss_mask: 0.8251  decode.d5.loss_dice: 1.3263  decode.d6.loss_cls: 1.2204  decode.d6.loss_mask: 0.8880  decode.d6.loss_dice: 1.3036  decode.d7.loss_cls: 1.2249  decode.d7.loss_mask: 0.8905  decode.d7.loss_dice: 1.3086  decode.d8.loss_cls: 1.1493  decode.d8.loss_mask: 0.8795  decode.d8.loss_dice: 1.3514
2023/05/24 09:02:26 - mmengine - INFO - Iter(train) [119300/160000]  lr: 2.9170e-06  eta: 4:53:22  time: 0.4372  data_time: 0.0107  memory: 4876  grad_norm: 101.2265  loss: 41.3454  decode.loss_cls: 1.2250  decode.loss_mask: 0.8155  decode.loss_dice: 1.7307  decode.d0.loss_cls: 3.0432  decode.d0.loss_mask: 0.9211  decode.d0.loss_dice: 1.9970  decode.d1.loss_cls: 1.3325  decode.d1.loss_mask: 0.9689  decode.d1.loss_dice: 1.8763  decode.d2.loss_cls: 1.3004  decode.d2.loss_mask: 0.8786  decode.d2.loss_dice: 1.8322  decode.d3.loss_cls: 1.3660  decode.d3.loss_mask: 0.8500  decode.d3.loss_dice: 1.7505  decode.d4.loss_cls: 1.3683  decode.d4.loss_mask: 0.8318  decode.d4.loss_dice: 1.7370  decode.d5.loss_cls: 1.3529  decode.d5.loss_mask: 0.8210  decode.d5.loss_dice: 1.7488  decode.d6.loss_cls: 1.3075  decode.d6.loss_mask: 0.8282  decode.d6.loss_dice: 1.7174  decode.d7.loss_cls: 1.3018  decode.d7.loss_mask: 0.8388  decode.d7.loss_dice: 1.7423  decode.d8.loss_cls: 1.3178  decode.d8.loss_mask: 0.8012  decode.d8.loss_dice: 1.7428
2023/05/24 09:02:48 - mmengine - INFO - Iter(train) [119350/160000]  lr: 2.9137e-06  eta: 4:53:00  time: 0.4245  data_time: 0.0106  memory: 4876  grad_norm: 98.6397  loss: 33.7735  decode.loss_cls: 1.0800  decode.loss_mask: 0.7336  decode.loss_dice: 1.2725  decode.d0.loss_cls: 2.6855  decode.d0.loss_mask: 0.8641  decode.d0.loss_dice: 1.5227  decode.d1.loss_cls: 1.2107  decode.d1.loss_mask: 0.7473  decode.d1.loss_dice: 1.3772  decode.d2.loss_cls: 1.2464  decode.d2.loss_mask: 0.7505  decode.d2.loss_dice: 1.3513  decode.d3.loss_cls: 1.2055  decode.d3.loss_mask: 0.7135  decode.d3.loss_dice: 1.2719  decode.d4.loss_cls: 1.1615  decode.d4.loss_mask: 0.7166  decode.d4.loss_dice: 1.3150  decode.d5.loss_cls: 1.1519  decode.d5.loss_mask: 0.7214  decode.d5.loss_dice: 1.2888  decode.d6.loss_cls: 1.0892  decode.d6.loss_mask: 0.7447  decode.d6.loss_dice: 1.2664  decode.d7.loss_cls: 1.0971  decode.d7.loss_mask: 0.7375  decode.d7.loss_dice: 1.2681  decode.d8.loss_cls: 1.1236  decode.d8.loss_mask: 0.7605  decode.d8.loss_dice: 1.2985
2023/05/24 09:03:09 - mmengine - INFO - Iter(train) [119400/160000]  lr: 2.9105e-06  eta: 4:52:38  time: 0.4240  data_time: 0.0104  memory: 4824  grad_norm: 98.5036  loss: 29.2944  decode.loss_cls: 1.0165  decode.loss_mask: 0.6722  decode.loss_dice: 0.9879  decode.d0.loss_cls: 2.8745  decode.d0.loss_mask: 0.6778  decode.d0.loss_dice: 1.1612  decode.d1.loss_cls: 1.1586  decode.d1.loss_mask: 0.7391  decode.d1.loss_dice: 1.1092  decode.d2.loss_cls: 1.0509  decode.d2.loss_mask: 0.6798  decode.d2.loss_dice: 1.0574  decode.d3.loss_cls: 1.0565  decode.d3.loss_mask: 0.6537  decode.d3.loss_dice: 1.0296  decode.d4.loss_cls: 0.9739  decode.d4.loss_mask: 0.6635  decode.d4.loss_dice: 1.0150  decode.d5.loss_cls: 1.0141  decode.d5.loss_mask: 0.6567  decode.d5.loss_dice: 1.0076  decode.d6.loss_cls: 1.0005  decode.d6.loss_mask: 0.6694  decode.d6.loss_dice: 0.9966  decode.d7.loss_cls: 1.0423  decode.d7.loss_mask: 0.6685  decode.d7.loss_dice: 0.9898  decode.d8.loss_cls: 0.9959  decode.d8.loss_mask: 0.6819  decode.d8.loss_dice: 0.9938
2023/05/24 09:03:30 - mmengine - INFO - Iter(train) [119450/160000]  lr: 2.9073e-06  eta: 4:52:17  time: 0.4262  data_time: 0.0108  memory: 4791  grad_norm: 104.4294  loss: 32.2621  decode.loss_cls: 1.1782  decode.loss_mask: 0.8304  decode.loss_dice: 0.9730  decode.d0.loss_cls: 3.0503  decode.d0.loss_mask: 0.8863  decode.d0.loss_dice: 1.1167  decode.d1.loss_cls: 1.2614  decode.d1.loss_mask: 0.8164  decode.d1.loss_dice: 1.0556  decode.d2.loss_cls: 1.3178  decode.d2.loss_mask: 0.7921  decode.d2.loss_dice: 1.0062  decode.d3.loss_cls: 1.2579  decode.d3.loss_mask: 0.7719  decode.d3.loss_dice: 0.9891  decode.d4.loss_cls: 1.2606  decode.d4.loss_mask: 0.7762  decode.d4.loss_dice: 0.9963  decode.d5.loss_cls: 1.1994  decode.d5.loss_mask: 0.8160  decode.d5.loss_dice: 0.9830  decode.d6.loss_cls: 1.2473  decode.d6.loss_mask: 0.7684  decode.d6.loss_dice: 0.9798  decode.d7.loss_cls: 1.2158  decode.d7.loss_mask: 0.7842  decode.d7.loss_dice: 0.9587  decode.d8.loss_cls: 1.2047  decode.d8.loss_mask: 0.8053  decode.d8.loss_dice: 0.9632
2023/05/24 09:03:52 - mmengine - INFO - Iter(train) [119500/160000]  lr: 2.9040e-06  eta: 4:51:55  time: 0.4199  data_time: 0.0110  memory: 4847  grad_norm: 115.7439  loss: 35.0092  decode.loss_cls: 1.2705  decode.loss_mask: 0.7125  decode.loss_dice: 1.2286  decode.d0.loss_cls: 3.2141  decode.d0.loss_mask: 0.8025  decode.d0.loss_dice: 1.4513  decode.d1.loss_cls: 1.3069  decode.d1.loss_mask: 0.8149  decode.d1.loss_dice: 1.3542  decode.d2.loss_cls: 1.3075  decode.d2.loss_mask: 0.7632  decode.d2.loss_dice: 1.3177  decode.d3.loss_cls: 1.2517  decode.d3.loss_mask: 0.7997  decode.d3.loss_dice: 1.2688  decode.d4.loss_cls: 1.2857  decode.d4.loss_mask: 0.7392  decode.d4.loss_dice: 1.2621  decode.d5.loss_cls: 1.2869  decode.d5.loss_mask: 0.7190  decode.d5.loss_dice: 1.2407  decode.d6.loss_cls: 1.2363  decode.d6.loss_mask: 0.7363  decode.d6.loss_dice: 1.2122  decode.d7.loss_cls: 1.2247  decode.d7.loss_mask: 0.7465  decode.d7.loss_dice: 1.2182  decode.d8.loss_cls: 1.2682  decode.d8.loss_mask: 0.7359  decode.d8.loss_dice: 1.2331
2023/05/24 09:04:13 - mmengine - INFO - Iter(train) [119550/160000]  lr: 2.9008e-06  eta: 4:51:33  time: 0.4275  data_time: 0.0108  memory: 4857  grad_norm: 98.5690  loss: 32.6845  decode.loss_cls: 1.0732  decode.loss_mask: 0.6812  decode.loss_dice: 1.2157  decode.d0.loss_cls: 2.9701  decode.d0.loss_mask: 0.7894  decode.d0.loss_dice: 1.5363  decode.d1.loss_cls: 1.1630  decode.d1.loss_mask: 0.7720  decode.d1.loss_dice: 1.3190  decode.d2.loss_cls: 1.1481  decode.d2.loss_mask: 0.7731  decode.d2.loss_dice: 1.2661  decode.d3.loss_cls: 1.0361  decode.d3.loss_mask: 0.7318  decode.d3.loss_dice: 1.2661  decode.d4.loss_cls: 1.0379  decode.d4.loss_mask: 0.7217  decode.d4.loss_dice: 1.2464  decode.d5.loss_cls: 1.0309  decode.d5.loss_mask: 0.7053  decode.d5.loss_dice: 1.2612  decode.d6.loss_cls: 1.0548  decode.d6.loss_mask: 0.6864  decode.d6.loss_dice: 1.2465  decode.d7.loss_cls: 0.9899  decode.d7.loss_mask: 0.7411  decode.d7.loss_dice: 1.2537  decode.d8.loss_cls: 1.0424  decode.d8.loss_mask: 0.6960  decode.d8.loss_dice: 1.2287
2023/05/24 09:04:35 - mmengine - INFO - Iter(train) [119600/160000]  lr: 2.8976e-06  eta: 4:51:12  time: 0.4353  data_time: 0.0109  memory: 4806  grad_norm: 104.6254  loss: 40.4984  decode.loss_cls: 1.4105  decode.loss_mask: 0.8716  decode.loss_dice: 1.5540  decode.d0.loss_cls: 3.2240  decode.d0.loss_mask: 0.9624  decode.d0.loss_dice: 1.7874  decode.d1.loss_cls: 1.3894  decode.d1.loss_mask: 0.9176  decode.d1.loss_dice: 1.6775  decode.d2.loss_cls: 1.3427  decode.d2.loss_mask: 0.9234  decode.d2.loss_dice: 1.6428  decode.d3.loss_cls: 1.3414  decode.d3.loss_mask: 0.9161  decode.d3.loss_dice: 1.6236  decode.d4.loss_cls: 1.3106  decode.d4.loss_mask: 0.8834  decode.d4.loss_dice: 1.5996  decode.d5.loss_cls: 1.3363  decode.d5.loss_mask: 0.8726  decode.d5.loss_dice: 1.5860  decode.d6.loss_cls: 1.3315  decode.d6.loss_mask: 0.8889  decode.d6.loss_dice: 1.5727  decode.d7.loss_cls: 1.3015  decode.d7.loss_mask: 0.8944  decode.d7.loss_dice: 1.5499  decode.d8.loss_cls: 1.3473  decode.d8.loss_mask: 0.8860  decode.d8.loss_dice: 1.5534
2023/05/24 09:04:57 - mmengine - INFO - Iter(train) [119650/160000]  lr: 2.8944e-06  eta: 4:50:50  time: 0.4286  data_time: 0.0109  memory: 4859  grad_norm: 86.4796  loss: 34.2370  decode.loss_cls: 1.1631  decode.loss_mask: 0.7197  decode.loss_dice: 1.2245  decode.d0.loss_cls: 3.0041  decode.d0.loss_mask: 0.8243  decode.d0.loss_dice: 1.5067  decode.d1.loss_cls: 1.3728  decode.d1.loss_mask: 0.7939  decode.d1.loss_dice: 1.3046  decode.d2.loss_cls: 1.2861  decode.d2.loss_mask: 0.7576  decode.d2.loss_dice: 1.3021  decode.d3.loss_cls: 1.2442  decode.d3.loss_mask: 0.7478  decode.d3.loss_dice: 1.2514  decode.d4.loss_cls: 1.2062  decode.d4.loss_mask: 0.7399  decode.d4.loss_dice: 1.2387  decode.d5.loss_cls: 1.1756  decode.d5.loss_mask: 0.7374  decode.d5.loss_dice: 1.2572  decode.d6.loss_cls: 1.1470  decode.d6.loss_mask: 0.7257  decode.d6.loss_dice: 1.2295  decode.d7.loss_cls: 1.1791  decode.d7.loss_mask: 0.7160  decode.d7.loss_dice: 1.2431  decode.d8.loss_cls: 1.2108  decode.d8.loss_mask: 0.7166  decode.d8.loss_dice: 1.2114
2023/05/24 09:05:18 - mmengine - INFO - Iter(train) [119700/160000]  lr: 2.8911e-06  eta: 4:50:28  time: 0.4380  data_time: 0.0110  memory: 4852  grad_norm: 92.1211  loss: 31.9394  decode.loss_cls: 0.9800  decode.loss_mask: 0.6866  decode.loss_dice: 1.2321  decode.d0.loss_cls: 2.7253  decode.d0.loss_mask: 0.7273  decode.d0.loss_dice: 1.3460  decode.d1.loss_cls: 1.1455  decode.d1.loss_mask: 0.7448  decode.d1.loss_dice: 1.2975  decode.d2.loss_cls: 1.1200  decode.d2.loss_mask: 0.7136  decode.d2.loss_dice: 1.2461  decode.d3.loss_cls: 1.0208  decode.d3.loss_mask: 0.7400  decode.d3.loss_dice: 1.2325  decode.d4.loss_cls: 1.0311  decode.d4.loss_mask: 0.7383  decode.d4.loss_dice: 1.2643  decode.d5.loss_cls: 1.0207  decode.d5.loss_mask: 0.7162  decode.d5.loss_dice: 1.2641  decode.d6.loss_cls: 0.9868  decode.d6.loss_mask: 0.7312  decode.d6.loss_dice: 1.2400  decode.d7.loss_cls: 1.0318  decode.d7.loss_mask: 0.7292  decode.d7.loss_dice: 1.2474  decode.d8.loss_cls: 1.0239  decode.d8.loss_mask: 0.7287  decode.d8.loss_dice: 1.2278
2023/05/24 09:05:42 - mmengine - INFO - Iter(train) [119750/160000]  lr: 2.8879e-06  eta: 4:50:07  time: 0.4754  data_time: 0.0112  memory: 4896  grad_norm: 103.1757  loss: 36.9390  decode.loss_cls: 1.2660  decode.loss_mask: 0.7987  decode.loss_dice: 1.3316  decode.d0.loss_cls: 3.1402  decode.d0.loss_mask: 0.9357  decode.d0.loss_dice: 1.5399  decode.d1.loss_cls: 1.3748  decode.d1.loss_mask: 0.9280  decode.d1.loss_dice: 1.4466  decode.d2.loss_cls: 1.2943  decode.d2.loss_mask: 0.8032  decode.d2.loss_dice: 1.3747  decode.d3.loss_cls: 1.2424  decode.d3.loss_mask: 0.8436  decode.d3.loss_dice: 1.3837  decode.d4.loss_cls: 1.2630  decode.d4.loss_mask: 0.8434  decode.d4.loss_dice: 1.3553  decode.d5.loss_cls: 1.2735  decode.d5.loss_mask: 0.8259  decode.d5.loss_dice: 1.3692  decode.d6.loss_cls: 1.2830  decode.d6.loss_mask: 0.8385  decode.d6.loss_dice: 1.3223  decode.d7.loss_cls: 1.2740  decode.d7.loss_mask: 0.8107  decode.d7.loss_dice: 1.3360  decode.d8.loss_cls: 1.2941  decode.d8.loss_mask: 0.8128  decode.d8.loss_dice: 1.3342
2023/05/24 09:06:03 - mmengine - INFO - Iter(train) [119800/160000]  lr: 2.8847e-06  eta: 4:49:46  time: 0.4237  data_time: 0.0113  memory: 4839  grad_norm: 98.8560  loss: 38.9710  decode.loss_cls: 1.4963  decode.loss_mask: 0.7308  decode.loss_dice: 1.3647  decode.d0.loss_cls: 3.3881  decode.d0.loss_mask: 0.8176  decode.d0.loss_dice: 1.6962  decode.d1.loss_cls: 1.6032  decode.d1.loss_mask: 0.7601  decode.d1.loss_dice: 1.5251  decode.d2.loss_cls: 1.5018  decode.d2.loss_mask: 0.7717  decode.d2.loss_dice: 1.5073  decode.d3.loss_cls: 1.4756  decode.d3.loss_mask: 0.7508  decode.d3.loss_dice: 1.4574  decode.d4.loss_cls: 1.4314  decode.d4.loss_mask: 0.7720  decode.d4.loss_dice: 1.4605  decode.d5.loss_cls: 1.3964  decode.d5.loss_mask: 0.7785  decode.d5.loss_dice: 1.4484  decode.d6.loss_cls: 1.4527  decode.d6.loss_mask: 0.7457  decode.d6.loss_dice: 1.4206  decode.d7.loss_cls: 1.4484  decode.d7.loss_mask: 0.7381  decode.d7.loss_dice: 1.3924  decode.d8.loss_cls: 1.4772  decode.d8.loss_mask: 0.7545  decode.d8.loss_dice: 1.4072
2023/05/24 09:06:25 - mmengine - INFO - Iter(train) [119850/160000]  lr: 2.8815e-06  eta: 4:49:24  time: 0.4513  data_time: 0.0106  memory: 4889  grad_norm: 98.9196  loss: 40.2376  decode.loss_cls: 1.3538  decode.loss_mask: 0.8411  decode.loss_dice: 1.4660  decode.d0.loss_cls: 3.3982  decode.d0.loss_mask: 0.9469  decode.d0.loss_dice: 1.7759  decode.d1.loss_cls: 1.5440  decode.d1.loss_mask: 0.8963  decode.d1.loss_dice: 1.6925  decode.d2.loss_cls: 1.4554  decode.d2.loss_mask: 0.9130  decode.d2.loss_dice: 1.6148  decode.d3.loss_cls: 1.3674  decode.d3.loss_mask: 0.8853  decode.d3.loss_dice: 1.5713  decode.d4.loss_cls: 1.3927  decode.d4.loss_mask: 0.8609  decode.d4.loss_dice: 1.4968  decode.d5.loss_cls: 1.3799  decode.d5.loss_mask: 0.8641  decode.d5.loss_dice: 1.5017  decode.d6.loss_cls: 1.2593  decode.d6.loss_mask: 0.8742  decode.d6.loss_dice: 1.5406  decode.d7.loss_cls: 1.3078  decode.d7.loss_mask: 0.8680  decode.d7.loss_dice: 1.5002  decode.d8.loss_cls: 1.3166  decode.d8.loss_mask: 0.8515  decode.d8.loss_dice: 1.5013
2023/05/24 09:06:46 - mmengine - INFO - Iter(train) [119900/160000]  lr: 2.8782e-06  eta: 4:49:02  time: 0.4184  data_time: 0.0107  memory: 4981  grad_norm: 108.7589  loss: 26.5022  decode.loss_cls: 0.9485  decode.loss_mask: 0.6259  decode.loss_dice: 0.8355  decode.d0.loss_cls: 2.7457  decode.d0.loss_mask: 0.6485  decode.d0.loss_dice: 0.9970  decode.d1.loss_cls: 1.0426  decode.d1.loss_mask: 0.6573  decode.d1.loss_dice: 0.9322  decode.d2.loss_cls: 1.0304  decode.d2.loss_mask: 0.6245  decode.d2.loss_dice: 0.8369  decode.d3.loss_cls: 1.0312  decode.d3.loss_mask: 0.6260  decode.d3.loss_dice: 0.8686  decode.d4.loss_cls: 0.9638  decode.d4.loss_mask: 0.6213  decode.d4.loss_dice: 0.8438  decode.d5.loss_cls: 0.9985  decode.d5.loss_mask: 0.6022  decode.d5.loss_dice: 0.8110  decode.d6.loss_cls: 0.9506  decode.d6.loss_mask: 0.6269  decode.d6.loss_dice: 0.8338  decode.d7.loss_cls: 0.9400  decode.d7.loss_mask: 0.6159  decode.d7.loss_dice: 0.8549  decode.d8.loss_cls: 0.9489  decode.d8.loss_mask: 0.6058  decode.d8.loss_dice: 0.8339
2023/05/24 09:07:08 - mmengine - INFO - Iter(train) [119950/160000]  lr: 2.8750e-06  eta: 4:48:41  time: 0.4247  data_time: 0.0104  memory: 4845  grad_norm: 110.7128  loss: 34.0700  decode.loss_cls: 0.9425  decode.loss_mask: 0.8039  decode.loss_dice: 1.3568  decode.d0.loss_cls: 3.1341  decode.d0.loss_mask: 0.7760  decode.d0.loss_dice: 1.5866  decode.d1.loss_cls: 1.1882  decode.d1.loss_mask: 0.7798  decode.d1.loss_dice: 1.4566  decode.d2.loss_cls: 1.0963  decode.d2.loss_mask: 0.7518  decode.d2.loss_dice: 1.4142  decode.d3.loss_cls: 1.0347  decode.d3.loss_mask: 0.8020  decode.d3.loss_dice: 1.3585  decode.d4.loss_cls: 1.0245  decode.d4.loss_mask: 0.7916  decode.d4.loss_dice: 1.3498  decode.d5.loss_cls: 0.9490  decode.d5.loss_mask: 0.8148  decode.d5.loss_dice: 1.4040  decode.d6.loss_cls: 0.9273  decode.d6.loss_mask: 0.8137  decode.d6.loss_dice: 1.3573  decode.d7.loss_cls: 0.9223  decode.d7.loss_mask: 0.7937  decode.d7.loss_dice: 1.3578  decode.d8.loss_cls: 0.9320  decode.d8.loss_mask: 0.7999  decode.d8.loss_dice: 1.3502
2023/05/24 09:07:29 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 09:07:29 - mmengine - INFO - Iter(train) [120000/160000]  lr: 2.8718e-06  eta: 4:48:19  time: 0.4253  data_time: 0.0105  memory: 4861  grad_norm: 105.9984  loss: 40.0593  decode.loss_cls: 1.3296  decode.loss_mask: 0.8506  decode.loss_dice: 1.5190  decode.d0.loss_cls: 3.1867  decode.d0.loss_mask: 0.9197  decode.d0.loss_dice: 1.7902  decode.d1.loss_cls: 1.4009  decode.d1.loss_mask: 0.9261  decode.d1.loss_dice: 1.6300  decode.d2.loss_cls: 1.3664  decode.d2.loss_mask: 0.9341  decode.d2.loss_dice: 1.6145  decode.d3.loss_cls: 1.4159  decode.d3.loss_mask: 0.8934  decode.d3.loss_dice: 1.5417  decode.d4.loss_cls: 1.3718  decode.d4.loss_mask: 0.8723  decode.d4.loss_dice: 1.5523  decode.d5.loss_cls: 1.3450  decode.d5.loss_mask: 0.8787  decode.d5.loss_dice: 1.5099  decode.d6.loss_cls: 1.3939  decode.d6.loss_mask: 0.8587  decode.d6.loss_dice: 1.4934  decode.d7.loss_cls: 1.3781  decode.d7.loss_mask: 0.8524  decode.d7.loss_dice: 1.5041  decode.d8.loss_cls: 1.3372  decode.d8.loss_mask: 0.8497  decode.d8.loss_dice: 1.5429
2023/05/24 09:07:29 - mmengine - INFO - Saving checkpoint at 120000 iterations
2023/05/24 09:07:41 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:01:15  time: 0.1770  data_time: 0.0020  memory: 2167  
2023/05/24 09:07:46 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:57  time: 0.0800  data_time: 0.0018  memory: 2216  
2023/05/24 09:07:50 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:48  time: 0.0811  data_time: 0.0018  memory: 2167  
2023/05/24 09:07:54 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:40  time: 0.0789  data_time: 0.0018  memory: 2104  
2023/05/24 09:07:58 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:35  time: 0.0898  data_time: 0.0019  memory: 2831  
2023/05/24 09:08:02 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0959  data_time: 0.0018  memory: 2167  
2023/05/24 09:08:07 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:25  time: 0.0961  data_time: 0.0018  memory: 2167  
2023/05/24 09:08:12 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:20  time: 0.0950  data_time: 0.0019  memory: 2167  
2023/05/24 09:08:17 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:16  time: 0.0788  data_time: 0.0018  memory: 2944  
2023/05/24 09:08:22 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:11  time: 0.0998  data_time: 0.0020  memory: 2356  
2023/05/24 09:08:26 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:07  time: 0.0892  data_time: 0.0016  memory: 2217  
2023/05/24 09:08:30 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0789  data_time: 0.0017  memory: 2328  
2023/05/24 09:08:34 - mmengine - INFO - per class results:
2023/05/24 09:08:34 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.11 | 93.07 |
|     bicycle      | 69.66 | 85.56 |
|       car        | 58.94 | 86.44 |
|    motorcycle    | 82.99 |  91.1 |
|     airplane     | 85.04 | 94.09 |
|       bus        | 81.51 | 88.09 |
|      train       | 82.18 | 93.47 |
|      truck       | 54.59 | 72.07 |
|       boat       | 59.65 | 80.09 |
|  traffic light   | 67.85 | 85.69 |
|   fire hydrant   | 87.28 | 95.58 |
|    stop sign     |  88.7 | 96.33 |
|  parking meter   |  75.5 | 86.18 |
|      bench       | 46.16 | 67.96 |
|       bird       | 80.12 |  91.8 |
|       cat        | 83.41 | 89.63 |
|       dog        | 79.88 | 88.13 |
|      horse       | 78.12 | 91.17 |
|      sheep       | 85.99 | 92.56 |
|       cow        | 81.66 |  88.9 |
|     elephant     | 89.02 | 95.52 |
|       bear       | 92.58 | 95.42 |
|      zebra       |  90.4 | 93.97 |
|     giraffe      | 87.24 | 94.21 |
|     backpack     | 32.45 | 63.22 |
|     umbrella     | 75.92 | 89.02 |
|     handbag      | 32.77 | 56.04 |
|       tie        | 12.47 | 17.76 |
|     suitcase     | 77.57 | 93.46 |
|     frisbee      | 69.28 | 90.03 |
|       skis       | 46.34 | 66.89 |
|    snowboard     | 57.46 | 73.26 |
|   sports ball    | 52.59 | 74.44 |
|       kite       | 52.72 | 66.27 |
|   baseball bat   |  52.3 | 69.19 |
|  baseball glove  | 72.42 | 86.18 |
|    skateboard    | 75.61 | 85.22 |
|    surfboard     | 73.18 | 87.71 |
|  tennis racket   | 83.49 | 91.13 |
|      bottle      | 40.43 |  49.9 |
|    wine glass    | 56.26 | 74.67 |
|       cup        | 50.91 | 74.15 |
|       fork       | 35.78 | 45.43 |
|      knife       | 22.43 | 31.72 |
|      spoon       | 36.24 | 58.51 |
|       bowl       | 44.47 | 58.46 |
|      banana      | 67.67 | 86.71 |
|      apple       |  54.4 | 70.93 |
|     sandwich     | 42.55 | 56.95 |
|      orange      | 62.37 | 69.48 |
|     broccoli     |  58.2 | 66.84 |
|      carrot      | 44.64 | 49.56 |
|     hot dog      | 45.11 | 54.73 |
|      pizza       | 66.46 | 79.52 |
|      donut       | 68.04 | 81.56 |
|       cake       | 60.14 |  68.2 |
|      chair       | 46.55 | 65.14 |
|      couch       | 55.27 | 76.18 |
|   potted plant   | 31.44 | 52.85 |
|       bed        | 61.64 | 82.34 |
|   dining table   | 41.97 | 82.72 |
|      toilet      | 82.44 | 93.26 |
|        tv        | 72.39 | 87.45 |
|      laptop      | 72.73 | 83.84 |
|      mouse       | 75.39 | 89.64 |
|      remote      |  59.8 | 72.35 |
|     keyboard     | 62.41 | 80.47 |
|    cell phone    | 70.76 | 86.38 |
|    microwave     | 65.67 | 76.09 |
|       oven       | 55.02 | 79.23 |
|     toaster      | 44.57 | 74.65 |
|       sink       | 57.23 | 77.39 |
|   refrigerator   |  77.4 | 92.67 |
|       book       | 47.81 | 63.88 |
|      clock       | 73.87 | 83.77 |
|       vase       | 57.86 | 82.36 |
|     scissors     | 74.59 | 91.15 |
|    teddy bear    | 74.92 | 85.89 |
|    hair drier    | 44.32 | 56.18 |
|    toothbrush    | 38.76 | 70.02 |
|      banner      | 25.91 | 68.42 |
|     blanket      |  4.72 |  5.39 |
|      branch      |  19.9 | 34.25 |
|      bridge      | 31.09 | 57.52 |
|  building-other  | 53.39 | 74.14 |
|       bush       | 26.29 | 31.54 |
|     cabinet      | 53.79 | 70.76 |
|       cage       | 21.27 | 49.24 |
|    cardboard     | 42.53 |  56.0 |
|      carpet      | 51.99 |  70.9 |
|  ceiling-other   | 63.29 |  83.9 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      |  20.7 | 34.45 |
|      clouds      | 43.35 |  54.1 |
|     counter      | 27.24 | 50.52 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 65.12 | 78.29 |
|    desk-stuff    | 46.22 | 66.16 |
|       dirt       | 40.29 | 66.61 |
|    door-stuff    | 40.51 | 51.94 |
|      fence       | 22.23 | 35.36 |
|   floor-marble   |  7.14 |  9.57 |
|   floor-other    | 21.86 | 28.01 |
|   floor-stone    |  1.03 |  1.12 |
|    floor-tile    | 58.99 | 68.62 |
|    floor-wood    | 60.87 | 73.31 |
|      flower      | 30.07 | 41.74 |
|       fog        |  4.69 |  4.7  |
|    food-other    | 26.22 | 31.95 |
|      fruit       | 39.94 | 57.71 |
| furniture-other  | 17.88 | 26.58 |
|      grass       | 69.45 |  80.5 |
|      gravel      | 24.27 | 35.51 |
|   ground-other   |  0.11 |  0.11 |
|       hill       | 16.76 | 22.17 |
|      house       | 19.86 |  22.0 |
|      leaves      | 26.49 |  36.8 |
|      light       | 37.65 | 51.96 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.69 | 43.19 |
|   mirror-stuff   | 51.13 | 69.49 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 51.42 | 74.29 |
|       mud        |  5.41 |  8.66 |
|      napkin      |  2.86 |  2.9  |
|       net        | 43.17 | 63.27 |
|      paper       | 30.19 | 42.27 |
|     pavement     | 50.92 | 70.99 |
|      pillow      | 10.12 |  13.7 |
|   plant-other    | 19.94 | 38.41 |
|     plastic      | 20.13 | 27.12 |
|     platform     | 27.11 | 41.16 |
|   playingfield   | 68.66 | 88.97 |
|     railing      |  5.77 | 10.12 |
|     railroad     | 60.26 | 82.54 |
|      river       | 51.01 | 77.57 |
|       road       | 65.35 | 81.39 |
|       rock       | 29.35 | 41.23 |
|       roof       | 19.04 | 25.46 |
|       rug        | 36.64 | 55.76 |
|      salad       |  0.0  |  0.0  |
|       sand       | 61.44 | 68.58 |
|       sea        | 85.71 |  91.8 |
|      shelf       | 33.33 | 42.92 |
|    sky-other     |  70.1 | 88.65 |
|    skyscraper    | 27.94 | 33.26 |
|       snow       | 88.95 | 92.03 |
|   solid-other    |  0.25 |  0.25 |
|      stairs      | 22.17 | 36.34 |
|      stone       | 11.18 | 28.14 |
|      straw       | 27.36 | 35.37 |
| structural-other |  0.01 |  0.01 |
|      table       | 13.09 | 15.93 |
|       tent       |  8.99 | 12.77 |
|  textile-other   |  8.79 | 13.01 |
|      towel       | 35.14 | 43.25 |
|       tree       | 73.47 | 86.28 |
|    vegetable     | 32.32 | 42.34 |
|    wall-brick    | 46.33 | 60.86 |
|  wall-concrete   | 59.62 | 80.42 |
|    wall-other    | 19.14 | 31.33 |
|    wall-panel    |  6.08 |  7.08 |
|    wall-stone    | 31.93 | 38.38 |
|    wall-tile     | 64.37 | 76.75 |
|    wall-wood     | 41.92 | 56.15 |
|   water-other    |  18.0 | 25.66 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 48.14 | 59.96 |
|   window-other   | 47.41 | 71.76 |
|       wood       | 26.18 | 35.57 |
+------------------+-------+-------+
2023/05/24 09:08:34 - mmengine - INFO - Iter(val) [625/625]    aAcc: 70.5400  mIoU: 46.1700  mAcc: 58.9200  data_time: 0.0021  time: 0.0920
2023/05/24 09:08:56 - mmengine - INFO - Iter(train) [120050/160000]  lr: 2.8685e-06  eta: 4:47:58  time: 0.4158  data_time: 0.0105  memory: 4847  grad_norm: 88.8824  loss: 27.1647  decode.loss_cls: 0.9752  decode.loss_mask: 0.5769  decode.loss_dice: 0.8716  decode.d0.loss_cls: 2.9456  decode.d0.loss_mask: 0.6075  decode.d0.loss_dice: 1.0099  decode.d1.loss_cls: 1.1911  decode.d1.loss_mask: 0.6388  decode.d1.loss_dice: 0.9787  decode.d2.loss_cls: 1.1375  decode.d2.loss_mask: 0.5813  decode.d2.loss_dice: 0.9439  decode.d3.loss_cls: 1.0487  decode.d3.loss_mask: 0.5643  decode.d3.loss_dice: 0.8727  decode.d4.loss_cls: 1.0440  decode.d4.loss_mask: 0.5464  decode.d4.loss_dice: 0.8902  decode.d5.loss_cls: 1.0299  decode.d5.loss_mask: 0.5597  decode.d5.loss_dice: 0.8707  decode.d6.loss_cls: 0.9956  decode.d6.loss_mask: 0.5590  decode.d6.loss_dice: 0.8976  decode.d7.loss_cls: 0.9857  decode.d7.loss_mask: 0.5797  decode.d7.loss_dice: 0.8605  decode.d8.loss_cls: 0.9879  decode.d8.loss_mask: 0.5809  decode.d8.loss_dice: 0.8333
2023/05/24 09:09:17 - mmengine - INFO - Iter(train) [120100/160000]  lr: 2.8653e-06  eta: 4:47:36  time: 0.4209  data_time: 0.0107  memory: 4944  grad_norm: 95.6548  loss: 35.8643  decode.loss_cls: 1.3472  decode.loss_mask: 0.8126  decode.loss_dice: 1.1380  decode.d0.loss_cls: 3.1327  decode.d0.loss_mask: 0.8959  decode.d0.loss_dice: 1.3639  decode.d1.loss_cls: 1.4788  decode.d1.loss_mask: 0.8915  decode.d1.loss_dice: 1.2527  decode.d2.loss_cls: 1.4626  decode.d2.loss_mask: 0.8690  decode.d2.loss_dice: 1.1833  decode.d3.loss_cls: 1.3840  decode.d3.loss_mask: 0.8756  decode.d3.loss_dice: 1.1822  decode.d4.loss_cls: 1.3102  decode.d4.loss_mask: 0.8462  decode.d4.loss_dice: 1.1358  decode.d5.loss_cls: 1.3333  decode.d5.loss_mask: 0.8137  decode.d5.loss_dice: 1.1405  decode.d6.loss_cls: 1.3717  decode.d6.loss_mask: 0.8044  decode.d6.loss_dice: 1.1392  decode.d7.loss_cls: 1.3643  decode.d7.loss_mask: 0.8219  decode.d7.loss_dice: 1.1816  decode.d8.loss_cls: 1.3857  decode.d8.loss_mask: 0.8252  decode.d8.loss_dice: 1.1205
2023/05/24 09:09:38 - mmengine - INFO - Iter(train) [120150/160000]  lr: 2.8621e-06  eta: 4:47:14  time: 0.4167  data_time: 0.0105  memory: 4847  grad_norm: 86.4322  loss: 34.8304  decode.loss_cls: 1.1379  decode.loss_mask: 0.6535  decode.loss_dice: 1.3855  decode.d0.loss_cls: 3.2624  decode.d0.loss_mask: 0.7293  decode.d0.loss_dice: 1.5568  decode.d1.loss_cls: 1.3461  decode.d1.loss_mask: 0.7413  decode.d1.loss_dice: 1.5541  decode.d2.loss_cls: 1.1912  decode.d2.loss_mask: 0.6938  decode.d2.loss_dice: 1.4466  decode.d3.loss_cls: 1.2578  decode.d3.loss_mask: 0.7014  decode.d3.loss_dice: 1.3686  decode.d4.loss_cls: 1.1654  decode.d4.loss_mask: 0.6792  decode.d4.loss_dice: 1.3668  decode.d5.loss_cls: 1.1028  decode.d5.loss_mask: 0.6607  decode.d5.loss_dice: 1.3621  decode.d6.loss_cls: 1.2002  decode.d6.loss_mask: 0.6364  decode.d6.loss_dice: 1.3432  decode.d7.loss_cls: 1.2339  decode.d7.loss_mask: 0.6402  decode.d7.loss_dice: 1.3197  decode.d8.loss_cls: 1.1287  decode.d8.loss_mask: 0.6446  decode.d8.loss_dice: 1.3202
2023/05/24 09:09:59 - mmengine - INFO - Iter(train) [120200/160000]  lr: 2.8588e-06  eta: 4:46:52  time: 0.4282  data_time: 0.0110  memory: 4979  grad_norm: 96.9335  loss: 34.3086  decode.loss_cls: 0.9445  decode.loss_mask: 0.7838  decode.loss_dice: 1.3432  decode.d0.loss_cls: 3.0877  decode.d0.loss_mask: 0.8750  decode.d0.loss_dice: 1.6974  decode.d1.loss_cls: 1.1847  decode.d1.loss_mask: 0.8416  decode.d1.loss_dice: 1.5778  decode.d2.loss_cls: 1.0109  decode.d2.loss_mask: 0.8477  decode.d2.loss_dice: 1.4679  decode.d3.loss_cls: 0.9348  decode.d3.loss_mask: 0.7937  decode.d3.loss_dice: 1.4198  decode.d4.loss_cls: 0.9101  decode.d4.loss_mask: 0.8042  decode.d4.loss_dice: 1.3995  decode.d5.loss_cls: 0.9717  decode.d5.loss_mask: 0.7713  decode.d5.loss_dice: 1.3777  decode.d6.loss_cls: 0.9471  decode.d6.loss_mask: 0.7841  decode.d6.loss_dice: 1.3452  decode.d7.loss_cls: 0.9360  decode.d7.loss_mask: 0.7863  decode.d7.loss_dice: 1.3648  decode.d8.loss_cls: 0.9735  decode.d8.loss_mask: 0.7728  decode.d8.loss_dice: 1.3539
2023/05/24 09:10:20 - mmengine - INFO - Iter(train) [120250/160000]  lr: 2.8556e-06  eta: 4:46:31  time: 0.4192  data_time: 0.0109  memory: 4871  grad_norm: 90.8628  loss: 41.0203  decode.loss_cls: 1.3264  decode.loss_mask: 0.9143  decode.loss_dice: 1.5530  decode.d0.loss_cls: 3.3033  decode.d0.loss_mask: 0.8867  decode.d0.loss_dice: 1.7532  decode.d1.loss_cls: 1.5125  decode.d1.loss_mask: 0.9381  decode.d1.loss_dice: 1.6941  decode.d2.loss_cls: 1.4254  decode.d2.loss_mask: 0.9639  decode.d2.loss_dice: 1.6257  decode.d3.loss_cls: 1.3869  decode.d3.loss_mask: 0.9103  decode.d3.loss_dice: 1.5789  decode.d4.loss_cls: 1.3362  decode.d4.loss_mask: 0.9064  decode.d4.loss_dice: 1.5986  decode.d5.loss_cls: 1.3173  decode.d5.loss_mask: 0.9224  decode.d5.loss_dice: 1.6094  decode.d6.loss_cls: 1.3349  decode.d6.loss_mask: 0.9515  decode.d6.loss_dice: 1.5546  decode.d7.loss_cls: 1.3323  decode.d7.loss_mask: 0.9559  decode.d7.loss_dice: 1.5736  decode.d8.loss_cls: 1.3748  decode.d8.loss_mask: 0.9280  decode.d8.loss_dice: 1.5519
2023/05/24 09:10:43 - mmengine - INFO - Iter(train) [120300/160000]  lr: 2.8524e-06  eta: 4:46:09  time: 0.4838  data_time: 0.0104  memory: 4859  grad_norm: 95.9478  loss: 33.9709  decode.loss_cls: 1.2882  decode.loss_mask: 0.6653  decode.loss_dice: 1.1072  decode.d0.loss_cls: 3.1564  decode.d0.loss_mask: 0.7708  decode.d0.loss_dice: 1.3674  decode.d1.loss_cls: 1.3875  decode.d1.loss_mask: 0.7511  decode.d1.loss_dice: 1.2661  decode.d2.loss_cls: 1.3497  decode.d2.loss_mask: 0.7372  decode.d2.loss_dice: 1.2421  decode.d3.loss_cls: 1.3568  decode.d3.loss_mask: 0.7150  decode.d3.loss_dice: 1.1419  decode.d4.loss_cls: 1.3701  decode.d4.loss_mask: 0.6470  decode.d4.loss_dice: 1.1590  decode.d5.loss_cls: 1.3523  decode.d5.loss_mask: 0.6621  decode.d5.loss_dice: 1.1282  decode.d6.loss_cls: 1.3030  decode.d6.loss_mask: 0.6838  decode.d6.loss_dice: 1.1118  decode.d7.loss_cls: 1.3022  decode.d7.loss_mask: 0.6738  decode.d7.loss_dice: 1.1884  decode.d8.loss_cls: 1.2748  decode.d8.loss_mask: 0.6779  decode.d8.loss_dice: 1.1339
2023/05/24 09:11:06 - mmengine - INFO - Iter(train) [120350/160000]  lr: 2.8491e-06  eta: 4:45:48  time: 0.4467  data_time: 0.0108  memory: 4884  grad_norm: 125.9877  loss: 38.5873  decode.loss_cls: 1.2431  decode.loss_mask: 0.8903  decode.loss_dice: 1.4879  decode.d0.loss_cls: 3.0965  decode.d0.loss_mask: 0.8764  decode.d0.loss_dice: 1.6442  decode.d1.loss_cls: 1.3096  decode.d1.loss_mask: 0.9632  decode.d1.loss_dice: 1.5684  decode.d2.loss_cls: 1.2549  decode.d2.loss_mask: 0.9242  decode.d2.loss_dice: 1.5350  decode.d3.loss_cls: 1.2189  decode.d3.loss_mask: 0.8819  decode.d3.loss_dice: 1.5024  decode.d4.loss_cls: 1.2610  decode.d4.loss_mask: 0.8862  decode.d4.loss_dice: 1.4950  decode.d5.loss_cls: 1.2884  decode.d5.loss_mask: 0.8758  decode.d5.loss_dice: 1.4666  decode.d6.loss_cls: 1.3203  decode.d6.loss_mask: 0.8793  decode.d6.loss_dice: 1.4466  decode.d7.loss_cls: 1.3113  decode.d7.loss_mask: 0.8822  decode.d7.loss_dice: 1.4391  decode.d8.loss_cls: 1.2682  decode.d8.loss_mask: 0.8829  decode.d8.loss_dice: 1.4875
2023/05/24 09:11:28 - mmengine - INFO - Iter(train) [120400/160000]  lr: 2.8459e-06  eta: 4:45:27  time: 0.4254  data_time: 0.0109  memory: 4837  grad_norm: 98.0762  loss: 40.1289  decode.loss_cls: 1.5680  decode.loss_mask: 0.7524  decode.loss_dice: 1.4356  decode.d0.loss_cls: 3.3434  decode.d0.loss_mask: 0.8241  decode.d0.loss_dice: 1.7567  decode.d1.loss_cls: 1.7880  decode.d1.loss_mask: 0.7333  decode.d1.loss_dice: 1.4960  decode.d2.loss_cls: 1.7049  decode.d2.loss_mask: 0.7514  decode.d2.loss_dice: 1.4668  decode.d3.loss_cls: 1.5483  decode.d3.loss_mask: 0.7656  decode.d3.loss_dice: 1.4575  decode.d4.loss_cls: 1.5579  decode.d4.loss_mask: 0.7697  decode.d4.loss_dice: 1.4271  decode.d5.loss_cls: 1.5645  decode.d5.loss_mask: 0.7873  decode.d5.loss_dice: 1.4367  decode.d6.loss_cls: 1.5246  decode.d6.loss_mask: 0.7808  decode.d6.loss_dice: 1.4102  decode.d7.loss_cls: 1.5860  decode.d7.loss_mask: 0.7810  decode.d7.loss_dice: 1.3965  decode.d8.loss_cls: 1.5529  decode.d8.loss_mask: 0.7578  decode.d8.loss_dice: 1.4039
2023/05/24 09:11:50 - mmengine - INFO - Iter(train) [120450/160000]  lr: 2.8427e-06  eta: 4:45:05  time: 0.4848  data_time: 0.0104  memory: 4840  grad_norm: 85.8960  loss: 37.6290  decode.loss_cls: 1.2274  decode.loss_mask: 0.7832  decode.loss_dice: 1.3757  decode.d0.loss_cls: 3.4468  decode.d0.loss_mask: 0.8583  decode.d0.loss_dice: 1.7284  decode.d1.loss_cls: 1.3848  decode.d1.loss_mask: 0.8971  decode.d1.loss_dice: 1.6343  decode.d2.loss_cls: 1.3076  decode.d2.loss_mask: 0.8703  decode.d2.loss_dice: 1.5094  decode.d3.loss_cls: 1.3027  decode.d3.loss_mask: 0.7845  decode.d3.loss_dice: 1.3930  decode.d4.loss_cls: 1.2719  decode.d4.loss_mask: 0.7782  decode.d4.loss_dice: 1.4165  decode.d5.loss_cls: 1.2720  decode.d5.loss_mask: 0.7803  decode.d5.loss_dice: 1.3997  decode.d6.loss_cls: 1.2506  decode.d6.loss_mask: 0.7824  decode.d6.loss_dice: 1.3901  decode.d7.loss_cls: 1.2282  decode.d7.loss_mask: 0.7755  decode.d7.loss_dice: 1.3738  decode.d8.loss_cls: 1.2572  decode.d8.loss_mask: 0.7646  decode.d8.loss_dice: 1.3844
2023/05/24 09:12:13 - mmengine - INFO - Iter(train) [120500/160000]  lr: 2.8394e-06  eta: 4:44:44  time: 0.4260  data_time: 0.0106  memory: 4927  grad_norm: 109.9037  loss: 35.4111  decode.loss_cls: 1.1873  decode.loss_mask: 0.8275  decode.loss_dice: 1.2792  decode.d0.loss_cls: 3.2120  decode.d0.loss_mask: 0.8597  decode.d0.loss_dice: 1.4609  decode.d1.loss_cls: 1.2029  decode.d1.loss_mask: 0.8733  decode.d1.loss_dice: 1.4091  decode.d2.loss_cls: 1.2188  decode.d2.loss_mask: 0.8552  decode.d2.loss_dice: 1.3175  decode.d3.loss_cls: 1.1701  decode.d3.loss_mask: 0.8265  decode.d3.loss_dice: 1.2866  decode.d4.loss_cls: 1.1773  decode.d4.loss_mask: 0.8362  decode.d4.loss_dice: 1.2597  decode.d5.loss_cls: 1.2460  decode.d5.loss_mask: 0.8189  decode.d5.loss_dice: 1.2284  decode.d6.loss_cls: 1.1826  decode.d6.loss_mask: 0.8424  decode.d6.loss_dice: 1.2786  decode.d7.loss_cls: 1.1890  decode.d7.loss_mask: 0.8525  decode.d7.loss_dice: 1.2596  decode.d8.loss_cls: 1.1777  decode.d8.loss_mask: 0.8215  decode.d8.loss_dice: 1.2542
2023/05/24 09:12:34 - mmengine - INFO - Iter(train) [120550/160000]  lr: 2.8362e-06  eta: 4:44:22  time: 0.4233  data_time: 0.0108  memory: 4878  grad_norm: 258.6075  loss: 33.3279  decode.loss_cls: 1.1562  decode.loss_mask: 0.6896  decode.loss_dice: 1.2353  decode.d0.loss_cls: 3.1229  decode.d0.loss_mask: 0.7144  decode.d0.loss_dice: 1.3814  decode.d1.loss_cls: 1.1486  decode.d1.loss_mask: 0.7642  decode.d1.loss_dice: 1.3244  decode.d2.loss_cls: 1.1637  decode.d2.loss_mask: 0.7203  decode.d2.loss_dice: 1.3111  decode.d3.loss_cls: 1.1577  decode.d3.loss_mask: 0.7077  decode.d3.loss_dice: 1.2489  decode.d4.loss_cls: 1.1519  decode.d4.loss_mask: 0.7046  decode.d4.loss_dice: 1.2743  decode.d5.loss_cls: 1.1325  decode.d5.loss_mask: 0.7182  decode.d5.loss_dice: 1.2775  decode.d6.loss_cls: 1.1608  decode.d6.loss_mask: 0.7018  decode.d6.loss_dice: 1.2325  decode.d7.loss_cls: 1.1299  decode.d7.loss_mask: 0.6922  decode.d7.loss_dice: 1.2463  decode.d8.loss_cls: 1.1528  decode.d8.loss_mask: 0.6673  decode.d8.loss_dice: 1.2388
2023/05/24 09:12:55 - mmengine - INFO - Iter(train) [120600/160000]  lr: 2.8330e-06  eta: 4:44:00  time: 0.4239  data_time: 0.0116  memory: 4858  grad_norm: 138.4881  loss: 38.4333  decode.loss_cls: 1.1169  decode.loss_mask: 0.7800  decode.loss_dice: 1.6376  decode.d0.loss_cls: 2.8555  decode.d0.loss_mask: 0.8715  decode.d0.loss_dice: 1.9152  decode.d1.loss_cls: 1.2277  decode.d1.loss_mask: 0.9113  decode.d1.loss_dice: 1.8361  decode.d2.loss_cls: 1.2249  decode.d2.loss_mask: 0.8900  decode.d2.loss_dice: 1.7281  decode.d3.loss_cls: 1.2472  decode.d3.loss_mask: 0.7891  decode.d3.loss_dice: 1.6121  decode.d4.loss_cls: 1.2025  decode.d4.loss_mask: 0.7900  decode.d4.loss_dice: 1.6492  decode.d5.loss_cls: 1.1958  decode.d5.loss_mask: 0.7674  decode.d5.loss_dice: 1.6568  decode.d6.loss_cls: 1.1562  decode.d6.loss_mask: 0.7532  decode.d6.loss_dice: 1.5948  decode.d7.loss_cls: 1.1243  decode.d7.loss_mask: 0.7540  decode.d7.loss_dice: 1.6193  decode.d8.loss_cls: 1.1301  decode.d8.loss_mask: 0.7620  decode.d8.loss_dice: 1.6345
2023/05/24 09:13:17 - mmengine - INFO - Iter(train) [120650/160000]  lr: 2.8297e-06  eta: 4:43:39  time: 0.4369  data_time: 0.0105  memory: 4828  grad_norm: 125.3975  loss: 33.7245  decode.loss_cls: 1.0853  decode.loss_mask: 0.7730  decode.loss_dice: 1.2662  decode.d0.loss_cls: 2.9748  decode.d0.loss_mask: 0.7781  decode.d0.loss_dice: 1.5072  decode.d1.loss_cls: 1.2501  decode.d1.loss_mask: 0.8163  decode.d1.loss_dice: 1.3469  decode.d2.loss_cls: 1.1334  decode.d2.loss_mask: 0.8058  decode.d2.loss_dice: 1.3278  decode.d3.loss_cls: 1.1251  decode.d3.loss_mask: 0.7311  decode.d3.loss_dice: 1.2864  decode.d4.loss_cls: 1.0746  decode.d4.loss_mask: 0.7605  decode.d4.loss_dice: 1.2608  decode.d5.loss_cls: 1.0572  decode.d5.loss_mask: 0.7828  decode.d5.loss_dice: 1.2708  decode.d6.loss_cls: 1.1067  decode.d6.loss_mask: 0.7492  decode.d6.loss_dice: 1.2509  decode.d7.loss_cls: 1.0729  decode.d7.loss_mask: 0.7775  decode.d7.loss_dice: 1.2353  decode.d8.loss_cls: 1.0628  decode.d8.loss_mask: 0.7794  decode.d8.loss_dice: 1.2754
2023/05/24 09:13:38 - mmengine - INFO - Iter(train) [120700/160000]  lr: 2.8265e-06  eta: 4:43:17  time: 0.4376  data_time: 0.0106  memory: 4861  grad_norm: 100.4821  loss: 35.0835  decode.loss_cls: 1.2245  decode.loss_mask: 0.8166  decode.loss_dice: 1.1517  decode.d0.loss_cls: 3.4047  decode.d0.loss_mask: 0.8176  decode.d0.loss_dice: 1.3495  decode.d1.loss_cls: 1.4143  decode.d1.loss_mask: 0.8625  decode.d1.loss_dice: 1.2456  decode.d2.loss_cls: 1.3867  decode.d2.loss_mask: 0.7918  decode.d2.loss_dice: 1.1626  decode.d3.loss_cls: 1.3750  decode.d3.loss_mask: 0.7797  decode.d3.loss_dice: 1.1280  decode.d4.loss_cls: 1.3613  decode.d4.loss_mask: 0.7741  decode.d4.loss_dice: 1.1670  decode.d5.loss_cls: 1.2733  decode.d5.loss_mask: 0.7727  decode.d5.loss_dice: 1.1668  decode.d6.loss_cls: 1.3024  decode.d6.loss_mask: 0.7680  decode.d6.loss_dice: 1.1377  decode.d7.loss_cls: 1.2862  decode.d7.loss_mask: 0.7864  decode.d7.loss_dice: 1.1668  decode.d8.loss_cls: 1.2493  decode.d8.loss_mask: 0.8054  decode.d8.loss_dice: 1.1553
2023/05/24 09:14:00 - mmengine - INFO - Iter(train) [120750/160000]  lr: 2.8233e-06  eta: 4:42:55  time: 0.4218  data_time: 0.0109  memory: 4837  grad_norm: 106.7030  loss: 31.1686  decode.loss_cls: 0.8107  decode.loss_mask: 0.9095  decode.loss_dice: 1.1241  decode.d0.loss_cls: 3.0080  decode.d0.loss_mask: 0.8700  decode.d0.loss_dice: 1.1842  decode.d1.loss_cls: 0.9249  decode.d1.loss_mask: 0.9004  decode.d1.loss_dice: 1.1715  decode.d2.loss_cls: 0.8764  decode.d2.loss_mask: 0.9198  decode.d2.loss_dice: 1.1906  decode.d3.loss_cls: 0.8790  decode.d3.loss_mask: 0.9321  decode.d3.loss_dice: 1.1452  decode.d4.loss_cls: 0.8426  decode.d4.loss_mask: 0.8842  decode.d4.loss_dice: 1.1200  decode.d5.loss_cls: 0.8146  decode.d5.loss_mask: 0.9438  decode.d5.loss_dice: 1.1341  decode.d6.loss_cls: 0.8025  decode.d6.loss_mask: 0.9279  decode.d6.loss_dice: 1.1233  decode.d7.loss_cls: 0.8068  decode.d7.loss_mask: 0.9131  decode.d7.loss_dice: 1.1376  decode.d8.loss_cls: 0.7812  decode.d8.loss_mask: 0.9486  decode.d8.loss_dice: 1.1421
2023/05/24 09:14:21 - mmengine - INFO - Iter(train) [120800/160000]  lr: 2.8200e-06  eta: 4:42:34  time: 0.4244  data_time: 0.0108  memory: 4836  grad_norm: 82.7357  loss: 31.9920  decode.loss_cls: 1.0084  decode.loss_mask: 0.7322  decode.loss_dice: 1.1278  decode.d0.loss_cls: 2.9455  decode.d0.loss_mask: 0.8272  decode.d0.loss_dice: 1.3658  decode.d1.loss_cls: 1.1029  decode.d1.loss_mask: 0.8109  decode.d1.loss_dice: 1.2174  decode.d2.loss_cls: 1.1304  decode.d2.loss_mask: 0.7867  decode.d2.loss_dice: 1.1803  decode.d3.loss_cls: 1.1023  decode.d3.loss_mask: 0.7814  decode.d3.loss_dice: 1.1358  decode.d4.loss_cls: 1.0485  decode.d4.loss_mask: 0.7387  decode.d4.loss_dice: 1.1565  decode.d5.loss_cls: 1.0287  decode.d5.loss_mask: 0.7817  decode.d5.loss_dice: 1.1812  decode.d6.loss_cls: 1.0286  decode.d6.loss_mask: 0.7381  decode.d6.loss_dice: 1.1669  decode.d7.loss_cls: 1.0525  decode.d7.loss_mask: 0.7789  decode.d7.loss_dice: 1.1356  decode.d8.loss_cls: 1.0318  decode.d8.loss_mask: 0.7256  decode.d8.loss_dice: 1.1435
2023/05/24 09:14:42 - mmengine - INFO - Iter(train) [120850/160000]  lr: 2.8168e-06  eta: 4:42:12  time: 0.4218  data_time: 0.0104  memory: 4865  grad_norm: 98.8272  loss: 37.7372  decode.loss_cls: 1.3831  decode.loss_mask: 0.6830  decode.loss_dice: 1.4017  decode.d0.loss_cls: 3.3977  decode.d0.loss_mask: 0.7519  decode.d0.loss_dice: 1.5983  decode.d1.loss_cls: 1.5864  decode.d1.loss_mask: 0.8073  decode.d1.loss_dice: 1.4737  decode.d2.loss_cls: 1.5464  decode.d2.loss_mask: 0.6899  decode.d2.loss_dice: 1.4438  decode.d3.loss_cls: 1.5532  decode.d3.loss_mask: 0.6531  decode.d3.loss_dice: 1.3823  decode.d4.loss_cls: 1.4788  decode.d4.loss_mask: 0.6677  decode.d4.loss_dice: 1.3633  decode.d5.loss_cls: 1.4361  decode.d5.loss_mask: 0.6796  decode.d5.loss_dice: 1.3937  decode.d6.loss_cls: 1.4324  decode.d6.loss_mask: 0.6891  decode.d6.loss_dice: 1.3859  decode.d7.loss_cls: 1.3842  decode.d7.loss_mask: 0.6803  decode.d7.loss_dice: 1.3753  decode.d8.loss_cls: 1.3728  decode.d8.loss_mask: 0.6734  decode.d8.loss_dice: 1.3727
2023/05/24 09:15:04 - mmengine - INFO - Iter(train) [120900/160000]  lr: 2.8135e-06  eta: 4:41:50  time: 0.4334  data_time: 0.0115  memory: 4828  grad_norm: 95.1027  loss: 30.9828  decode.loss_cls: 0.9957  decode.loss_mask: 0.7728  decode.loss_dice: 1.0920  decode.d0.loss_cls: 2.6797  decode.d0.loss_mask: 0.7812  decode.d0.loss_dice: 1.2124  decode.d1.loss_cls: 1.1320  decode.d1.loss_mask: 0.7966  decode.d1.loss_dice: 1.1777  decode.d2.loss_cls: 1.0779  decode.d2.loss_mask: 0.7964  decode.d2.loss_dice: 1.1086  decode.d3.loss_cls: 1.0150  decode.d3.loss_mask: 0.7978  decode.d3.loss_dice: 1.1027  decode.d4.loss_cls: 0.9703  decode.d4.loss_mask: 0.7996  decode.d4.loss_dice: 1.1194  decode.d5.loss_cls: 0.9816  decode.d5.loss_mask: 0.7920  decode.d5.loss_dice: 1.1255  decode.d6.loss_cls: 1.0212  decode.d6.loss_mask: 0.7600  decode.d6.loss_dice: 1.1122  decode.d7.loss_cls: 1.0064  decode.d7.loss_mask: 0.7787  decode.d7.loss_dice: 1.1118  decode.d8.loss_cls: 0.9865  decode.d8.loss_mask: 0.7686  decode.d8.loss_dice: 1.1107
2023/05/24 09:15:25 - mmengine - INFO - Iter(train) [120950/160000]  lr: 2.8103e-06  eta: 4:41:29  time: 0.4336  data_time: 0.0105  memory: 4871  grad_norm: 93.4604  loss: 30.1255  decode.loss_cls: 0.9960  decode.loss_mask: 0.6445  decode.loss_dice: 1.1402  decode.d0.loss_cls: 2.8318  decode.d0.loss_mask: 0.7031  decode.d0.loss_dice: 1.2660  decode.d1.loss_cls: 1.0496  decode.d1.loss_mask: 0.7059  decode.d1.loss_dice: 1.2383  decode.d2.loss_cls: 1.0505  decode.d2.loss_mask: 0.6802  decode.d2.loss_dice: 1.1835  decode.d3.loss_cls: 1.0472  decode.d3.loss_mask: 0.6537  decode.d3.loss_dice: 1.1317  decode.d4.loss_cls: 0.9955  decode.d4.loss_mask: 0.6395  decode.d4.loss_dice: 1.1307  decode.d5.loss_cls: 0.9229  decode.d5.loss_mask: 0.6693  decode.d5.loss_dice: 1.1603  decode.d6.loss_cls: 0.9826  decode.d6.loss_mask: 0.6580  decode.d6.loss_dice: 1.1103  decode.d7.loss_cls: 0.9916  decode.d7.loss_mask: 0.6512  decode.d7.loss_dice: 1.1307  decode.d8.loss_cls: 0.9859  decode.d8.loss_mask: 0.6486  decode.d8.loss_dice: 1.1262
2023/05/24 09:15:47 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 09:15:47 - mmengine - INFO - Iter(train) [121000/160000]  lr: 2.8071e-06  eta: 4:41:07  time: 0.4182  data_time: 0.0107  memory: 4944  grad_norm: 79.2260  loss: 38.2965  decode.loss_cls: 1.2673  decode.loss_mask: 0.7325  decode.loss_dice: 1.5177  decode.d0.loss_cls: 3.2880  decode.d0.loss_mask: 0.8422  decode.d0.loss_dice: 1.7358  decode.d1.loss_cls: 1.4878  decode.d1.loss_mask: 0.7743  decode.d1.loss_dice: 1.6354  decode.d2.loss_cls: 1.4230  decode.d2.loss_mask: 0.7379  decode.d2.loss_dice: 1.5529  decode.d3.loss_cls: 1.3495  decode.d3.loss_mask: 0.7542  decode.d3.loss_dice: 1.5677  decode.d4.loss_cls: 1.3486  decode.d4.loss_mask: 0.7419  decode.d4.loss_dice: 1.5129  decode.d5.loss_cls: 1.2420  decode.d5.loss_mask: 0.7468  decode.d5.loss_dice: 1.5274  decode.d6.loss_cls: 1.2834  decode.d6.loss_mask: 0.7278  decode.d6.loss_dice: 1.4852  decode.d7.loss_cls: 1.2736  decode.d7.loss_mask: 0.7354  decode.d7.loss_dice: 1.5289  decode.d8.loss_cls: 1.2789  decode.d8.loss_mask: 0.7269  decode.d8.loss_dice: 1.4704
2023/05/24 09:15:47 - mmengine - INFO - Saving checkpoint at 121000 iterations
2023/05/24 09:16:13 - mmengine - INFO - Iter(train) [121050/160000]  lr: 2.8038e-06  eta: 4:40:47  time: 0.4277  data_time: 0.0102  memory: 4838  grad_norm: 101.6199  loss: 41.0948  decode.loss_cls: 1.5342  decode.loss_mask: 0.7133  decode.loss_dice: 1.5247  decode.d0.loss_cls: 3.6158  decode.d0.loss_mask: 0.7295  decode.d0.loss_dice: 1.7814  decode.d1.loss_cls: 1.8338  decode.d1.loss_mask: 0.6993  decode.d1.loss_dice: 1.6161  decode.d2.loss_cls: 1.6465  decode.d2.loss_mask: 0.7063  decode.d2.loss_dice: 1.6189  decode.d3.loss_cls: 1.6742  decode.d3.loss_mask: 0.7324  decode.d3.loss_dice: 1.6025  decode.d4.loss_cls: 1.5411  decode.d4.loss_mask: 0.7624  decode.d4.loss_dice: 1.5686  decode.d5.loss_cls: 1.5788  decode.d5.loss_mask: 0.7179  decode.d5.loss_dice: 1.5358  decode.d6.loss_cls: 1.5031  decode.d6.loss_mask: 0.7692  decode.d6.loss_dice: 1.5374  decode.d7.loss_cls: 1.5821  decode.d7.loss_mask: 0.6979  decode.d7.loss_dice: 1.5171  decode.d8.loss_cls: 1.5360  decode.d8.loss_mask: 0.7164  decode.d8.loss_dice: 1.5021
2023/05/24 09:16:34 - mmengine - INFO - Iter(train) [121100/160000]  lr: 2.8006e-06  eta: 4:40:25  time: 0.4211  data_time: 0.0106  memory: 4850  grad_norm: 99.8954  loss: 36.9380  decode.loss_cls: 1.2554  decode.loss_mask: 0.8964  decode.loss_dice: 1.2318  decode.d0.loss_cls: 3.0391  decode.d0.loss_mask: 1.0206  decode.d0.loss_dice: 1.4283  decode.d1.loss_cls: 1.4186  decode.d1.loss_mask: 0.9450  decode.d1.loss_dice: 1.3222  decode.d2.loss_cls: 1.3387  decode.d2.loss_mask: 0.9665  decode.d2.loss_dice: 1.3007  decode.d3.loss_cls: 1.2858  decode.d3.loss_mask: 0.9335  decode.d3.loss_dice: 1.2897  decode.d4.loss_cls: 1.3509  decode.d4.loss_mask: 0.9210  decode.d4.loss_dice: 1.2654  decode.d5.loss_cls: 1.2963  decode.d5.loss_mask: 0.9181  decode.d5.loss_dice: 1.2354  decode.d6.loss_cls: 1.2221  decode.d6.loss_mask: 0.9281  decode.d6.loss_dice: 1.2466  decode.d7.loss_cls: 1.2563  decode.d7.loss_mask: 0.9345  decode.d7.loss_dice: 1.2361  decode.d8.loss_cls: 1.3006  decode.d8.loss_mask: 0.9120  decode.d8.loss_dice: 1.2425
2023/05/24 09:16:56 - mmengine - INFO - Iter(train) [121150/160000]  lr: 2.7973e-06  eta: 4:40:03  time: 0.4322  data_time: 0.0106  memory: 4952  grad_norm: 103.7940  loss: 37.2763  decode.loss_cls: 1.1984  decode.loss_mask: 0.8644  decode.loss_dice: 1.3703  decode.d0.loss_cls: 3.1655  decode.d0.loss_mask: 0.8521  decode.d0.loss_dice: 1.5567  decode.d1.loss_cls: 1.2503  decode.d1.loss_mask: 0.9293  decode.d1.loss_dice: 1.5031  decode.d2.loss_cls: 1.2057  decode.d2.loss_mask: 0.9243  decode.d2.loss_dice: 1.4895  decode.d3.loss_cls: 1.2387  decode.d3.loss_mask: 0.8756  decode.d3.loss_dice: 1.4014  decode.d4.loss_cls: 1.1629  decode.d4.loss_mask: 0.9295  decode.d4.loss_dice: 1.4011  decode.d5.loss_cls: 1.2149  decode.d5.loss_mask: 0.8739  decode.d5.loss_dice: 1.4156  decode.d6.loss_cls: 1.2168  decode.d6.loss_mask: 0.9040  decode.d6.loss_dice: 1.4033  decode.d7.loss_cls: 1.1752  decode.d7.loss_mask: 0.9299  decode.d7.loss_dice: 1.3944  decode.d8.loss_cls: 1.1760  decode.d8.loss_mask: 0.8912  decode.d8.loss_dice: 1.3624
2023/05/24 09:17:17 - mmengine - INFO - Iter(train) [121200/160000]  lr: 2.7941e-06  eta: 4:39:42  time: 0.4270  data_time: 0.0111  memory: 4859  grad_norm: 95.6045  loss: 40.5110  decode.loss_cls: 1.4760  decode.loss_mask: 0.8618  decode.loss_dice: 1.3838  decode.d0.loss_cls: 3.3619  decode.d0.loss_mask: 0.9466  decode.d0.loss_dice: 1.7327  decode.d1.loss_cls: 1.7026  decode.d1.loss_mask: 0.9117  decode.d1.loss_dice: 1.5327  decode.d2.loss_cls: 1.5556  decode.d2.loss_mask: 0.9052  decode.d2.loss_dice: 1.4812  decode.d3.loss_cls: 1.5972  decode.d3.loss_mask: 0.8641  decode.d3.loss_dice: 1.4392  decode.d4.loss_cls: 1.5483  decode.d4.loss_mask: 0.8734  decode.d4.loss_dice: 1.4099  decode.d5.loss_cls: 1.5433  decode.d5.loss_mask: 0.8450  decode.d5.loss_dice: 1.3872  decode.d6.loss_cls: 1.4782  decode.d6.loss_mask: 0.8543  decode.d6.loss_dice: 1.3760  decode.d7.loss_cls: 1.5044  decode.d7.loss_mask: 0.8657  decode.d7.loss_dice: 1.3645  decode.d8.loss_cls: 1.5083  decode.d8.loss_mask: 0.8646  decode.d8.loss_dice: 1.3354
2023/05/24 09:17:40 - mmengine - INFO - Iter(train) [121250/160000]  lr: 2.7909e-06  eta: 4:39:21  time: 0.4781  data_time: 0.0103  memory: 4894  grad_norm: 99.1089  loss: 32.4488  decode.loss_cls: 1.0221  decode.loss_mask: 0.5868  decode.loss_dice: 1.3583  decode.d0.loss_cls: 2.9382  decode.d0.loss_mask: 0.5941  decode.d0.loss_dice: 1.4965  decode.d1.loss_cls: 1.2198  decode.d1.loss_mask: 0.5798  decode.d1.loss_dice: 1.3824  decode.d2.loss_cls: 1.2026  decode.d2.loss_mask: 0.6078  decode.d2.loss_dice: 1.4553  decode.d3.loss_cls: 1.1604  decode.d3.loss_mask: 0.5685  decode.d3.loss_dice: 1.3603  decode.d4.loss_cls: 1.0949  decode.d4.loss_mask: 0.5815  decode.d4.loss_dice: 1.3591  decode.d5.loss_cls: 1.0588  decode.d5.loss_mask: 0.5811  decode.d5.loss_dice: 1.3572  decode.d6.loss_cls: 1.0666  decode.d6.loss_mask: 0.5681  decode.d6.loss_dice: 1.3256  decode.d7.loss_cls: 1.0606  decode.d7.loss_mask: 0.5852  decode.d7.loss_dice: 1.3323  decode.d8.loss_cls: 1.0694  decode.d8.loss_mask: 0.5747  decode.d8.loss_dice: 1.3011
2023/05/24 09:18:03 - mmengine - INFO - Iter(train) [121300/160000]  lr: 2.7876e-06  eta: 4:38:59  time: 0.4221  data_time: 0.0105  memory: 4857  grad_norm: 95.4620  loss: 43.4339  decode.loss_cls: 1.7004  decode.loss_mask: 0.9048  decode.loss_dice: 1.4353  decode.d0.loss_cls: 3.7189  decode.d0.loss_mask: 0.9235  decode.d0.loss_dice: 1.8048  decode.d1.loss_cls: 1.8994  decode.d1.loss_mask: 0.9418  decode.d1.loss_dice: 1.5620  decode.d2.loss_cls: 1.8489  decode.d2.loss_mask: 0.9387  decode.d2.loss_dice: 1.5312  decode.d3.loss_cls: 1.7689  decode.d3.loss_mask: 0.8867  decode.d3.loss_dice: 1.4507  decode.d4.loss_cls: 1.6877  decode.d4.loss_mask: 0.9215  decode.d4.loss_dice: 1.4326  decode.d5.loss_cls: 1.6856  decode.d5.loss_mask: 0.9029  decode.d5.loss_dice: 1.4654  decode.d6.loss_cls: 1.6899  decode.d6.loss_mask: 0.8978  decode.d6.loss_dice: 1.4242  decode.d7.loss_cls: 1.6746  decode.d7.loss_mask: 0.9000  decode.d7.loss_dice: 1.3972  decode.d8.loss_cls: 1.7219  decode.d8.loss_mask: 0.9027  decode.d8.loss_dice: 1.4140
2023/05/24 09:18:25 - mmengine - INFO - Iter(train) [121350/160000]  lr: 2.7844e-06  eta: 4:38:38  time: 0.4248  data_time: 0.0106  memory: 4836  grad_norm: 87.2969  loss: 41.7431  decode.loss_cls: 1.3727  decode.loss_mask: 0.9775  decode.loss_dice: 1.5392  decode.d0.loss_cls: 3.0443  decode.d0.loss_mask: 1.0263  decode.d0.loss_dice: 1.7821  decode.d1.loss_cls: 1.4855  decode.d1.loss_mask: 1.0360  decode.d1.loss_dice: 1.6458  decode.d2.loss_cls: 1.4361  decode.d2.loss_mask: 1.0369  decode.d2.loss_dice: 1.6377  decode.d3.loss_cls: 1.4487  decode.d3.loss_mask: 1.0044  decode.d3.loss_dice: 1.5722  decode.d4.loss_cls: 1.4350  decode.d4.loss_mask: 0.9942  decode.d4.loss_dice: 1.5556  decode.d5.loss_cls: 1.3958  decode.d5.loss_mask: 0.9888  decode.d5.loss_dice: 1.5674  decode.d6.loss_cls: 1.3788  decode.d6.loss_mask: 0.9906  decode.d6.loss_dice: 1.5860  decode.d7.loss_cls: 1.3468  decode.d7.loss_mask: 0.9804  decode.d7.loss_dice: 1.5783  decode.d8.loss_cls: 1.3616  decode.d8.loss_mask: 0.9870  decode.d8.loss_dice: 1.5513
2023/05/24 09:18:46 - mmengine - INFO - Iter(train) [121400/160000]  lr: 2.7811e-06  eta: 4:38:16  time: 0.4294  data_time: 0.0105  memory: 4874  grad_norm: 91.7744  loss: 37.3951  decode.loss_cls: 1.3722  decode.loss_mask: 0.7293  decode.loss_dice: 1.3606  decode.d0.loss_cls: 3.2765  decode.d0.loss_mask: 0.8242  decode.d0.loss_dice: 1.6924  decode.d1.loss_cls: 1.5186  decode.d1.loss_mask: 0.7317  decode.d1.loss_dice: 1.4614  decode.d2.loss_cls: 1.4156  decode.d2.loss_mask: 0.7256  decode.d2.loss_dice: 1.4406  decode.d3.loss_cls: 1.4068  decode.d3.loss_mask: 0.7148  decode.d3.loss_dice: 1.3837  decode.d4.loss_cls: 1.3559  decode.d4.loss_mask: 0.7129  decode.d4.loss_dice: 1.3746  decode.d5.loss_cls: 1.4100  decode.d5.loss_mask: 0.7033  decode.d5.loss_dice: 1.3912  decode.d6.loss_cls: 1.3343  decode.d6.loss_mask: 0.7517  decode.d6.loss_dice: 1.3836  decode.d7.loss_cls: 1.3551  decode.d7.loss_mask: 0.7429  decode.d7.loss_dice: 1.3660  decode.d8.loss_cls: 1.3713  decode.d8.loss_mask: 0.7202  decode.d8.loss_dice: 1.3683
2023/05/24 09:19:08 - mmengine - INFO - Iter(train) [121450/160000]  lr: 2.7779e-06  eta: 4:37:54  time: 0.4235  data_time: 0.0108  memory: 4876  grad_norm: 105.1204  loss: 33.7922  decode.loss_cls: 1.0497  decode.loss_mask: 0.7714  decode.loss_dice: 1.2730  decode.d0.loss_cls: 2.9544  decode.d0.loss_mask: 0.8704  decode.d0.loss_dice: 1.4560  decode.d1.loss_cls: 1.2134  decode.d1.loss_mask: 0.8431  decode.d1.loss_dice: 1.3836  decode.d2.loss_cls: 1.2285  decode.d2.loss_mask: 0.7893  decode.d2.loss_dice: 1.3169  decode.d3.loss_cls: 1.1469  decode.d3.loss_mask: 0.7676  decode.d3.loss_dice: 1.2959  decode.d4.loss_cls: 1.0695  decode.d4.loss_mask: 0.7627  decode.d4.loss_dice: 1.2710  decode.d5.loss_cls: 1.0511  decode.d5.loss_mask: 0.7950  decode.d5.loss_dice: 1.2626  decode.d6.loss_cls: 1.0300  decode.d6.loss_mask: 0.7854  decode.d6.loss_dice: 1.2554  decode.d7.loss_cls: 1.0519  decode.d7.loss_mask: 0.7833  decode.d7.loss_dice: 1.2756  decode.d8.loss_cls: 1.0057  decode.d8.loss_mask: 0.7784  decode.d8.loss_dice: 1.2546
2023/05/24 09:19:29 - mmengine - INFO - Iter(train) [121500/160000]  lr: 2.7747e-06  eta: 4:37:32  time: 0.4274  data_time: 0.0105  memory: 4879  grad_norm: 93.0829  loss: 45.8764  decode.loss_cls: 1.5977  decode.loss_mask: 0.7620  decode.loss_dice: 1.8089  decode.d0.loss_cls: 3.6869  decode.d0.loss_mask: 0.8244  decode.d0.loss_dice: 2.1374  decode.d1.loss_cls: 1.7525  decode.d1.loss_mask: 0.8760  decode.d1.loss_dice: 2.0562  decode.d2.loss_cls: 1.7603  decode.d2.loss_mask: 0.8483  decode.d2.loss_dice: 1.9006  decode.d3.loss_cls: 1.6913  decode.d3.loss_mask: 0.8059  decode.d3.loss_dice: 1.8581  decode.d4.loss_cls: 1.7127  decode.d4.loss_mask: 0.8015  decode.d4.loss_dice: 1.8319  decode.d5.loss_cls: 1.6165  decode.d5.loss_mask: 0.7815  decode.d5.loss_dice: 1.8637  decode.d6.loss_cls: 1.7187  decode.d6.loss_mask: 0.8060  decode.d6.loss_dice: 1.8017  decode.d7.loss_cls: 1.7253  decode.d7.loss_mask: 0.7810  decode.d7.loss_dice: 1.7952  decode.d8.loss_cls: 1.6713  decode.d8.loss_mask: 0.7643  decode.d8.loss_dice: 1.8388
2023/05/24 09:19:50 - mmengine - INFO - Iter(train) [121550/160000]  lr: 2.7714e-06  eta: 4:37:11  time: 0.4289  data_time: 0.0105  memory: 4845  grad_norm: 101.1830  loss: 35.4369  decode.loss_cls: 1.2025  decode.loss_mask: 0.7947  decode.loss_dice: 1.2808  decode.d0.loss_cls: 3.1191  decode.d0.loss_mask: 0.8395  decode.d0.loss_dice: 1.5055  decode.d1.loss_cls: 1.4002  decode.d1.loss_mask: 0.7900  decode.d1.loss_dice: 1.4178  decode.d2.loss_cls: 1.2492  decode.d2.loss_mask: 0.7737  decode.d2.loss_dice: 1.3671  decode.d3.loss_cls: 1.2487  decode.d3.loss_mask: 0.7668  decode.d3.loss_dice: 1.3196  decode.d4.loss_cls: 1.2397  decode.d4.loss_mask: 0.7794  decode.d4.loss_dice: 1.3013  decode.d5.loss_cls: 1.2062  decode.d5.loss_mask: 0.7691  decode.d5.loss_dice: 1.2820  decode.d6.loss_cls: 1.1803  decode.d6.loss_mask: 0.7768  decode.d6.loss_dice: 1.3347  decode.d7.loss_cls: 1.1799  decode.d7.loss_mask: 0.7738  decode.d7.loss_dice: 1.2866  decode.d8.loss_cls: 1.1916  decode.d8.loss_mask: 0.7761  decode.d8.loss_dice: 1.2839
2023/05/24 09:20:11 - mmengine - INFO - Iter(train) [121600/160000]  lr: 2.7682e-06  eta: 4:36:49  time: 0.4123  data_time: 0.0103  memory: 4876  grad_norm: 94.7035  loss: 39.4717  decode.loss_cls: 1.4324  decode.loss_mask: 0.7713  decode.loss_dice: 1.4749  decode.d0.loss_cls: 3.1676  decode.d0.loss_mask: 0.8230  decode.d0.loss_dice: 1.7608  decode.d1.loss_cls: 1.5650  decode.d1.loss_mask: 0.8265  decode.d1.loss_dice: 1.6101  decode.d2.loss_cls: 1.5688  decode.d2.loss_mask: 0.8036  decode.d2.loss_dice: 1.5569  decode.d3.loss_cls: 1.4363  decode.d3.loss_mask: 0.7932  decode.d3.loss_dice: 1.5182  decode.d4.loss_cls: 1.4110  decode.d4.loss_mask: 0.7938  decode.d4.loss_dice: 1.5323  decode.d5.loss_cls: 1.4137  decode.d5.loss_mask: 0.7698  decode.d5.loss_dice: 1.4894  decode.d6.loss_cls: 1.3789  decode.d6.loss_mask: 0.7615  decode.d6.loss_dice: 1.4500  decode.d7.loss_cls: 1.4637  decode.d7.loss_mask: 0.7620  decode.d7.loss_dice: 1.4834  decode.d8.loss_cls: 1.3945  decode.d8.loss_mask: 0.7687  decode.d8.loss_dice: 1.4904
2023/05/24 09:20:33 - mmengine - INFO - Iter(train) [121650/160000]  lr: 2.7649e-06  eta: 4:36:27  time: 0.4238  data_time: 0.0105  memory: 4840  grad_norm: 86.3430  loss: 30.6355  decode.loss_cls: 1.1565  decode.loss_mask: 0.5599  decode.loss_dice: 1.0312  decode.d0.loss_cls: 3.3296  decode.d0.loss_mask: 0.6322  decode.d0.loss_dice: 1.1508  decode.d1.loss_cls: 1.2662  decode.d1.loss_mask: 0.6625  decode.d1.loss_dice: 1.1527  decode.d2.loss_cls: 1.1852  decode.d2.loss_mask: 0.6195  decode.d2.loss_dice: 1.0908  decode.d3.loss_cls: 1.1447  decode.d3.loss_mask: 0.6135  decode.d3.loss_dice: 1.0399  decode.d4.loss_cls: 1.1344  decode.d4.loss_mask: 0.6381  decode.d4.loss_dice: 1.0576  decode.d5.loss_cls: 1.1285  decode.d5.loss_mask: 0.6165  decode.d5.loss_dice: 1.0508  decode.d6.loss_cls: 1.1560  decode.d6.loss_mask: 0.5766  decode.d6.loss_dice: 1.0341  decode.d7.loss_cls: 1.1570  decode.d7.loss_mask: 0.5962  decode.d7.loss_dice: 1.0519  decode.d8.loss_cls: 1.1994  decode.d8.loss_mask: 0.5731  decode.d8.loss_dice: 1.0301
2023/05/24 09:20:54 - mmengine - INFO - Iter(train) [121700/160000]  lr: 2.7617e-06  eta: 4:36:06  time: 0.4263  data_time: 0.0105  memory: 4875  grad_norm: 98.1268  loss: 36.0022  decode.loss_cls: 1.1553  decode.loss_mask: 0.7650  decode.loss_dice: 1.3514  decode.d0.loss_cls: 3.0081  decode.d0.loss_mask: 0.7525  decode.d0.loss_dice: 1.6247  decode.d1.loss_cls: 1.3075  decode.d1.loss_mask: 0.7931  decode.d1.loss_dice: 1.4640  decode.d2.loss_cls: 1.1580  decode.d2.loss_mask: 0.7932  decode.d2.loss_dice: 1.5246  decode.d3.loss_cls: 1.2433  decode.d3.loss_mask: 0.7895  decode.d3.loss_dice: 1.4775  decode.d4.loss_cls: 1.2575  decode.d4.loss_mask: 0.7586  decode.d4.loss_dice: 1.4485  decode.d5.loss_cls: 1.2400  decode.d5.loss_mask: 0.7516  decode.d5.loss_dice: 1.3858  decode.d6.loss_cls: 1.1912  decode.d6.loss_mask: 0.7568  decode.d6.loss_dice: 1.3819  decode.d7.loss_cls: 1.1569  decode.d7.loss_mask: 0.7702  decode.d7.loss_dice: 1.3885  decode.d8.loss_cls: 1.1752  decode.d8.loss_mask: 0.7705  decode.d8.loss_dice: 1.3611
2023/05/24 09:21:16 - mmengine - INFO - Iter(train) [121750/160000]  lr: 2.7584e-06  eta: 4:35:44  time: 0.4280  data_time: 0.0106  memory: 4846  grad_norm: 81.4027  loss: 35.0043  decode.loss_cls: 1.2037  decode.loss_mask: 0.8290  decode.loss_dice: 1.1641  decode.d0.loss_cls: 3.1252  decode.d0.loss_mask: 0.9916  decode.d0.loss_dice: 1.4456  decode.d1.loss_cls: 1.2693  decode.d1.loss_mask: 0.9866  decode.d1.loss_dice: 1.3191  decode.d2.loss_cls: 1.3217  decode.d2.loss_mask: 0.8727  decode.d2.loss_dice: 1.2152  decode.d3.loss_cls: 1.2358  decode.d3.loss_mask: 0.8259  decode.d3.loss_dice: 1.1814  decode.d4.loss_cls: 1.2214  decode.d4.loss_mask: 0.8240  decode.d4.loss_dice: 1.1925  decode.d5.loss_cls: 1.1865  decode.d5.loss_mask: 0.8298  decode.d5.loss_dice: 1.1832  decode.d6.loss_cls: 1.2145  decode.d6.loss_mask: 0.8304  decode.d6.loss_dice: 1.1788  decode.d7.loss_cls: 1.1460  decode.d7.loss_mask: 0.8388  decode.d7.loss_dice: 1.1751  decode.d8.loss_cls: 1.2057  decode.d8.loss_mask: 0.8302  decode.d8.loss_dice: 1.1605
2023/05/24 09:21:37 - mmengine - INFO - Iter(train) [121800/160000]  lr: 2.7552e-06  eta: 4:35:22  time: 0.4264  data_time: 0.0105  memory: 4821  grad_norm: 99.1644  loss: 31.3110  decode.loss_cls: 1.0712  decode.loss_mask: 0.6792  decode.loss_dice: 1.0612  decode.d0.loss_cls: 3.1444  decode.d0.loss_mask: 0.6711  decode.d0.loss_dice: 1.2382  decode.d1.loss_cls: 1.2019  decode.d1.loss_mask: 0.7000  decode.d1.loss_dice: 1.1800  decode.d2.loss_cls: 1.1691  decode.d2.loss_mask: 0.6936  decode.d2.loss_dice: 1.1312  decode.d3.loss_cls: 1.1228  decode.d3.loss_mask: 0.6847  decode.d3.loss_dice: 1.1013  decode.d4.loss_cls: 1.1356  decode.d4.loss_mask: 0.6860  decode.d4.loss_dice: 1.0958  decode.d5.loss_cls: 1.1151  decode.d5.loss_mask: 0.6828  decode.d5.loss_dice: 1.1024  decode.d6.loss_cls: 1.0913  decode.d6.loss_mask: 0.6828  decode.d6.loss_dice: 1.1119  decode.d7.loss_cls: 1.1084  decode.d7.loss_mask: 0.6683  decode.d7.loss_dice: 1.0865  decode.d8.loss_cls: 1.1479  decode.d8.loss_mask: 0.6703  decode.d8.loss_dice: 1.0760
2023/05/24 09:22:00 - mmengine - INFO - Iter(train) [121850/160000]  lr: 2.7519e-06  eta: 4:35:01  time: 0.4840  data_time: 0.0106  memory: 4889  grad_norm: 91.4133  loss: 29.8491  decode.loss_cls: 0.7515  decode.loss_mask: 0.7123  decode.loss_dice: 1.2572  decode.d0.loss_cls: 2.8613  decode.d0.loss_mask: 0.7028  decode.d0.loss_dice: 1.4163  decode.d1.loss_cls: 0.9645  decode.d1.loss_mask: 0.6951  decode.d1.loss_dice: 1.3085  decode.d2.loss_cls: 0.8013  decode.d2.loss_mask: 0.7325  decode.d2.loss_dice: 1.3210  decode.d3.loss_cls: 0.8257  decode.d3.loss_mask: 0.7053  decode.d3.loss_dice: 1.2821  decode.d4.loss_cls: 0.7361  decode.d4.loss_mask: 0.7098  decode.d4.loss_dice: 1.2836  decode.d5.loss_cls: 0.7179  decode.d5.loss_mask: 0.7076  decode.d5.loss_dice: 1.2846  decode.d6.loss_cls: 0.7431  decode.d6.loss_mask: 0.6768  decode.d6.loss_dice: 1.2308  decode.d7.loss_cls: 0.7530  decode.d7.loss_mask: 0.7033  decode.d7.loss_dice: 1.2342  decode.d8.loss_cls: 0.7891  decode.d8.loss_mask: 0.6899  decode.d8.loss_dice: 1.2520
2023/05/24 09:22:21 - mmengine - INFO - Iter(train) [121900/160000]  lr: 2.7487e-06  eta: 4:34:39  time: 0.4216  data_time: 0.0106  memory: 4844  grad_norm: 99.8791  loss: 43.6090  decode.loss_cls: 1.4198  decode.loss_mask: 1.0305  decode.loss_dice: 1.5828  decode.d0.loss_cls: 3.1297  decode.d0.loss_mask: 1.1494  decode.d0.loss_dice: 1.7717  decode.d1.loss_cls: 1.6371  decode.d1.loss_mask: 1.1413  decode.d1.loss_dice: 1.7187  decode.d2.loss_cls: 1.5621  decode.d2.loss_mask: 1.0948  decode.d2.loss_dice: 1.7063  decode.d3.loss_cls: 1.5120  decode.d3.loss_mask: 1.1188  decode.d3.loss_dice: 1.5932  decode.d4.loss_cls: 1.4770  decode.d4.loss_mask: 1.1067  decode.d4.loss_dice: 1.5776  decode.d5.loss_cls: 1.4537  decode.d5.loss_mask: 1.0909  decode.d5.loss_dice: 1.5582  decode.d6.loss_cls: 1.4350  decode.d6.loss_mask: 1.0642  decode.d6.loss_dice: 1.5807  decode.d7.loss_cls: 1.4616  decode.d7.loss_mask: 1.0136  decode.d7.loss_dice: 1.5682  decode.d8.loss_cls: 1.4623  decode.d8.loss_mask: 1.0290  decode.d8.loss_dice: 1.5620
2023/05/24 09:22:42 - mmengine - INFO - Iter(train) [121950/160000]  lr: 2.7455e-06  eta: 4:34:17  time: 0.4180  data_time: 0.0109  memory: 4824  grad_norm: 88.2118  loss: 33.0350  decode.loss_cls: 1.0646  decode.loss_mask: 0.8473  decode.loss_dice: 1.1792  decode.d0.loss_cls: 3.0360  decode.d0.loss_mask: 0.8066  decode.d0.loss_dice: 1.3358  decode.d1.loss_cls: 1.2754  decode.d1.loss_mask: 0.8836  decode.d1.loss_dice: 1.2094  decode.d2.loss_cls: 1.1480  decode.d2.loss_mask: 0.8566  decode.d2.loss_dice: 1.2069  decode.d3.loss_cls: 1.0686  decode.d3.loss_mask: 0.8290  decode.d3.loss_dice: 1.1654  decode.d4.loss_cls: 1.0917  decode.d4.loss_mask: 0.8238  decode.d4.loss_dice: 1.1667  decode.d5.loss_cls: 1.0217  decode.d5.loss_mask: 0.8172  decode.d5.loss_dice: 1.1575  decode.d6.loss_cls: 1.0596  decode.d6.loss_mask: 0.8326  decode.d6.loss_dice: 1.1343  decode.d7.loss_cls: 1.0663  decode.d7.loss_mask: 0.7889  decode.d7.loss_dice: 1.1518  decode.d8.loss_cls: 1.0312  decode.d8.loss_mask: 0.8388  decode.d8.loss_dice: 1.1406
2023/05/24 09:23:04 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 09:23:04 - mmengine - INFO - Iter(train) [122000/160000]  lr: 2.7422e-06  eta: 4:33:56  time: 0.4322  data_time: 0.0107  memory: 4847  grad_norm: 111.8931  loss: 41.6475  decode.loss_cls: 1.5023  decode.loss_mask: 0.8316  decode.loss_dice: 1.4944  decode.d0.loss_cls: 3.6240  decode.d0.loss_mask: 0.9069  decode.d0.loss_dice: 1.7910  decode.d1.loss_cls: 1.6421  decode.d1.loss_mask: 0.8879  decode.d1.loss_dice: 1.5840  decode.d2.loss_cls: 1.5972  decode.d2.loss_mask: 0.8757  decode.d2.loss_dice: 1.5781  decode.d3.loss_cls: 1.5308  decode.d3.loss_mask: 0.8583  decode.d3.loss_dice: 1.5586  decode.d4.loss_cls: 1.5157  decode.d4.loss_mask: 0.8489  decode.d4.loss_dice: 1.5743  decode.d5.loss_cls: 1.5620  decode.d5.loss_mask: 0.8550  decode.d5.loss_dice: 1.4929  decode.d6.loss_cls: 1.5529  decode.d6.loss_mask: 0.8339  decode.d6.loss_dice: 1.5080  decode.d7.loss_cls: 1.5414  decode.d7.loss_mask: 0.8277  decode.d7.loss_dice: 1.4610  decode.d8.loss_cls: 1.5179  decode.d8.loss_mask: 0.8384  decode.d8.loss_dice: 1.4548
2023/05/24 09:23:04 - mmengine - INFO - Saving checkpoint at 122000 iterations
2023/05/24 09:23:31 - mmengine - INFO - Iter(train) [122050/160000]  lr: 2.7390e-06  eta: 4:33:36  time: 0.4444  data_time: 0.0105  memory: 4835  grad_norm: 84.1584  loss: 28.4153  decode.loss_cls: 0.9794  decode.loss_mask: 0.5656  decode.loss_dice: 1.0298  decode.d0.loss_cls: 2.8138  decode.d0.loss_mask: 0.5975  decode.d0.loss_dice: 1.2235  decode.d1.loss_cls: 1.1192  decode.d1.loss_mask: 0.5774  decode.d1.loss_dice: 1.1249  decode.d2.loss_cls: 1.0105  decode.d2.loss_mask: 0.5944  decode.d2.loss_dice: 1.1247  decode.d3.loss_cls: 1.0720  decode.d3.loss_mask: 0.5870  decode.d3.loss_dice: 1.0643  decode.d4.loss_cls: 1.0038  decode.d4.loss_mask: 0.5603  decode.d4.loss_dice: 1.0292  decode.d5.loss_cls: 0.9661  decode.d5.loss_mask: 0.5681  decode.d5.loss_dice: 1.0373  decode.d6.loss_cls: 0.9999  decode.d6.loss_mask: 0.5698  decode.d6.loss_dice: 1.0453  decode.d7.loss_cls: 0.9748  decode.d7.loss_mask: 0.5662  decode.d7.loss_dice: 1.0508  decode.d8.loss_cls: 0.9667  decode.d8.loss_mask: 0.5626  decode.d8.loss_dice: 1.0302
2023/05/24 09:23:52 - mmengine - INFO - Iter(train) [122100/160000]  lr: 2.7357e-06  eta: 4:33:14  time: 0.4213  data_time: 0.0105  memory: 4849  grad_norm: 120.6637  loss: 36.1873  decode.loss_cls: 1.2808  decode.loss_mask: 0.7445  decode.loss_dice: 1.2284  decode.d0.loss_cls: 3.3046  decode.d0.loss_mask: 0.7959  decode.d0.loss_dice: 1.4803  decode.d1.loss_cls: 1.4551  decode.d1.loss_mask: 0.8040  decode.d1.loss_dice: 1.3489  decode.d2.loss_cls: 1.4553  decode.d2.loss_mask: 0.7658  decode.d2.loss_dice: 1.3078  decode.d3.loss_cls: 1.4054  decode.d3.loss_mask: 0.7836  decode.d3.loss_dice: 1.3111  decode.d4.loss_cls: 1.3943  decode.d4.loss_mask: 0.7823  decode.d4.loss_dice: 1.2306  decode.d5.loss_cls: 1.3096  decode.d5.loss_mask: 0.7959  decode.d5.loss_dice: 1.2742  decode.d6.loss_cls: 1.3640  decode.d6.loss_mask: 0.7561  decode.d6.loss_dice: 1.2617  decode.d7.loss_cls: 1.3476  decode.d7.loss_mask: 0.7377  decode.d7.loss_dice: 1.2257  decode.d8.loss_cls: 1.2700  decode.d8.loss_mask: 0.7433  decode.d8.loss_dice: 1.2226
2023/05/24 09:24:14 - mmengine - INFO - Iter(train) [122150/160000]  lr: 2.7325e-06  eta: 4:32:52  time: 0.4283  data_time: 0.0106  memory: 4846  grad_norm: 100.5748  loss: 41.6516  decode.loss_cls: 1.4516  decode.loss_mask: 0.8642  decode.loss_dice: 1.5173  decode.d0.loss_cls: 3.2893  decode.d0.loss_mask: 0.9496  decode.d0.loss_dice: 1.7747  decode.d1.loss_cls: 1.6779  decode.d1.loss_mask: 0.9074  decode.d1.loss_dice: 1.6239  decode.d2.loss_cls: 1.6015  decode.d2.loss_mask: 0.8703  decode.d2.loss_dice: 1.6210  decode.d3.loss_cls: 1.5237  decode.d3.loss_mask: 0.9175  decode.d3.loss_dice: 1.6021  decode.d4.loss_cls: 1.4552  decode.d4.loss_mask: 0.8904  decode.d4.loss_dice: 1.5571  decode.d5.loss_cls: 1.4912  decode.d5.loss_mask: 0.8813  decode.d5.loss_dice: 1.5317  decode.d6.loss_cls: 1.4945  decode.d6.loss_mask: 0.8684  decode.d6.loss_dice: 1.5100  decode.d7.loss_cls: 1.5377  decode.d7.loss_mask: 0.8757  decode.d7.loss_dice: 1.5154  decode.d8.loss_cls: 1.4828  decode.d8.loss_mask: 0.8642  decode.d8.loss_dice: 1.5040
2023/05/24 09:24:35 - mmengine - INFO - Iter(train) [122200/160000]  lr: 2.7292e-06  eta: 4:32:31  time: 0.4260  data_time: 0.0105  memory: 4829  grad_norm: 77.8049  loss: 32.5477  decode.loss_cls: 1.1586  decode.loss_mask: 0.6401  decode.loss_dice: 1.1845  decode.d0.loss_cls: 2.9882  decode.d0.loss_mask: 0.7277  decode.d0.loss_dice: 1.2692  decode.d1.loss_cls: 1.3333  decode.d1.loss_mask: 0.6686  decode.d1.loss_dice: 1.2450  decode.d2.loss_cls: 1.2153  decode.d2.loss_mask: 0.6872  decode.d2.loss_dice: 1.2330  decode.d3.loss_cls: 1.2152  decode.d3.loss_mask: 0.6840  decode.d3.loss_dice: 1.2425  decode.d4.loss_cls: 1.2126  decode.d4.loss_mask: 0.6633  decode.d4.loss_dice: 1.1848  decode.d5.loss_cls: 1.2254  decode.d5.loss_mask: 0.6582  decode.d5.loss_dice: 1.1703  decode.d6.loss_cls: 1.1661  decode.d6.loss_mask: 0.6530  decode.d6.loss_dice: 1.1567  decode.d7.loss_cls: 1.1867  decode.d7.loss_mask: 0.6416  decode.d7.loss_dice: 1.1429  decode.d8.loss_cls: 1.1895  decode.d8.loss_mask: 0.6522  decode.d8.loss_dice: 1.1516
2023/05/24 09:24:56 - mmengine - INFO - Iter(train) [122250/160000]  lr: 2.7260e-06  eta: 4:32:09  time: 0.4246  data_time: 0.0113  memory: 4857  grad_norm: 96.6339  loss: 37.8659  decode.loss_cls: 1.2033  decode.loss_mask: 0.7602  decode.loss_dice: 1.5316  decode.d0.loss_cls: 3.0107  decode.d0.loss_mask: 0.7901  decode.d0.loss_dice: 1.7863  decode.d1.loss_cls: 1.3561  decode.d1.loss_mask: 0.7826  decode.d1.loss_dice: 1.6682  decode.d2.loss_cls: 1.2988  decode.d2.loss_mask: 0.7407  decode.d2.loss_dice: 1.6010  decode.d3.loss_cls: 1.2985  decode.d3.loss_mask: 0.7523  decode.d3.loss_dice: 1.5759  decode.d4.loss_cls: 1.2600  decode.d4.loss_mask: 0.7747  decode.d4.loss_dice: 1.5867  decode.d5.loss_cls: 1.2245  decode.d5.loss_mask: 0.7778  decode.d5.loss_dice: 1.5441  decode.d6.loss_cls: 1.2076  decode.d6.loss_mask: 0.7831  decode.d6.loss_dice: 1.5326  decode.d7.loss_cls: 1.1986  decode.d7.loss_mask: 0.7835  decode.d7.loss_dice: 1.5294  decode.d8.loss_cls: 1.1946  decode.d8.loss_mask: 0.7693  decode.d8.loss_dice: 1.5434
2023/05/24 09:25:19 - mmengine - INFO - Iter(train) [122300/160000]  lr: 2.7227e-06  eta: 4:31:48  time: 0.4771  data_time: 0.0107  memory: 4879  grad_norm: 108.0349  loss: 40.4204  decode.loss_cls: 1.2377  decode.loss_mask: 0.9153  decode.loss_dice: 1.5196  decode.d0.loss_cls: 3.3264  decode.d0.loss_mask: 0.9489  decode.d0.loss_dice: 1.8274  decode.d1.loss_cls: 1.5235  decode.d1.loss_mask: 0.9335  decode.d1.loss_dice: 1.7116  decode.d2.loss_cls: 1.3994  decode.d2.loss_mask: 0.9256  decode.d2.loss_dice: 1.6076  decode.d3.loss_cls: 1.3050  decode.d3.loss_mask: 0.9189  decode.d3.loss_dice: 1.5715  decode.d4.loss_cls: 1.2897  decode.d4.loss_mask: 0.9362  decode.d4.loss_dice: 1.5808  decode.d5.loss_cls: 1.3032  decode.d5.loss_mask: 0.9047  decode.d5.loss_dice: 1.5503  decode.d6.loss_cls: 1.2890  decode.d6.loss_mask: 0.8874  decode.d6.loss_dice: 1.5517  decode.d7.loss_cls: 1.2633  decode.d7.loss_mask: 0.8987  decode.d7.loss_dice: 1.5553  decode.d8.loss_cls: 1.2727  decode.d8.loss_mask: 0.9106  decode.d8.loss_dice: 1.5549
2023/05/24 09:25:40 - mmengine - INFO - Iter(train) [122350/160000]  lr: 2.7195e-06  eta: 4:31:26  time: 0.4214  data_time: 0.0105  memory: 4805  grad_norm: 98.7152  loss: 28.7221  decode.loss_cls: 0.8962  decode.loss_mask: 0.6904  decode.loss_dice: 1.0091  decode.d0.loss_cls: 2.8836  decode.d0.loss_mask: 0.6737  decode.d0.loss_dice: 1.1638  decode.d1.loss_cls: 0.9828  decode.d1.loss_mask: 0.7405  decode.d1.loss_dice: 1.1311  decode.d2.loss_cls: 0.8071  decode.d2.loss_mask: 0.7053  decode.d2.loss_dice: 1.1134  decode.d3.loss_cls: 0.9180  decode.d3.loss_mask: 0.6919  decode.d3.loss_dice: 1.0267  decode.d4.loss_cls: 0.8231  decode.d4.loss_mask: 0.7381  decode.d4.loss_dice: 1.0478  decode.d5.loss_cls: 0.9236  decode.d5.loss_mask: 0.7193  decode.d5.loss_dice: 1.0687  decode.d6.loss_cls: 0.9145  decode.d6.loss_mask: 0.7154  decode.d6.loss_dice: 1.0374  decode.d7.loss_cls: 0.9581  decode.d7.loss_mask: 0.6734  decode.d7.loss_dice: 1.0432  decode.d8.loss_cls: 0.8848  decode.d8.loss_mask: 0.7091  decode.d8.loss_dice: 1.0320
2023/05/24 09:26:02 - mmengine - INFO - Iter(train) [122400/160000]  lr: 2.7162e-06  eta: 4:31:04  time: 0.4471  data_time: 0.0098  memory: 4804  grad_norm: 109.1791  loss: 36.6756  decode.loss_cls: 1.1561  decode.loss_mask: 0.9406  decode.loss_dice: 1.2197  decode.d0.loss_cls: 3.1618  decode.d0.loss_mask: 1.0099  decode.d0.loss_dice: 1.4990  decode.d1.loss_cls: 1.4113  decode.d1.loss_mask: 0.9531  decode.d1.loss_dice: 1.4257  decode.d2.loss_cls: 1.3115  decode.d2.loss_mask: 0.9649  decode.d2.loss_dice: 1.3445  decode.d3.loss_cls: 1.2172  decode.d3.loss_mask: 0.9792  decode.d3.loss_dice: 1.2934  decode.d4.loss_cls: 1.1562  decode.d4.loss_mask: 0.9841  decode.d4.loss_dice: 1.2864  decode.d5.loss_cls: 1.1211  decode.d5.loss_mask: 0.9711  decode.d5.loss_dice: 1.2901  decode.d6.loss_cls: 1.1379  decode.d6.loss_mask: 0.9431  decode.d6.loss_dice: 1.2446  decode.d7.loss_cls: 1.1550  decode.d7.loss_mask: 0.9495  decode.d7.loss_dice: 1.2538  decode.d8.loss_cls: 1.1401  decode.d8.loss_mask: 0.9296  decode.d8.loss_dice: 1.2251
2023/05/24 09:26:24 - mmengine - INFO - Iter(train) [122450/160000]  lr: 2.7130e-06  eta: 4:30:43  time: 0.4210  data_time: 0.0100  memory: 4821  grad_norm: 117.1695  loss: 32.7017  decode.loss_cls: 1.0669  decode.loss_mask: 0.8096  decode.loss_dice: 1.1107  decode.d0.loss_cls: 2.9885  decode.d0.loss_mask: 0.8635  decode.d0.loss_dice: 1.3026  decode.d1.loss_cls: 1.2242  decode.d1.loss_mask: 0.8236  decode.d1.loss_dice: 1.2256  decode.d2.loss_cls: 1.1429  decode.d2.loss_mask: 0.8115  decode.d2.loss_dice: 1.1861  decode.d3.loss_cls: 1.1062  decode.d3.loss_mask: 0.7998  decode.d3.loss_dice: 1.1433  decode.d4.loss_cls: 1.1466  decode.d4.loss_mask: 0.7771  decode.d4.loss_dice: 1.1329  decode.d5.loss_cls: 1.1257  decode.d5.loss_mask: 0.7796  decode.d5.loss_dice: 1.1150  decode.d6.loss_cls: 1.1405  decode.d6.loss_mask: 0.7872  decode.d6.loss_dice: 1.1023  decode.d7.loss_cls: 1.1048  decode.d7.loss_mask: 0.7950  decode.d7.loss_dice: 1.1026  decode.d8.loss_cls: 1.0921  decode.d8.loss_mask: 0.7918  decode.d8.loss_dice: 1.1037
2023/05/24 09:26:45 - mmengine - INFO - Iter(train) [122500/160000]  lr: 2.7097e-06  eta: 4:30:21  time: 0.4269  data_time: 0.0103  memory: 4845  grad_norm: 133.7331  loss: 33.8361  decode.loss_cls: 1.1524  decode.loss_mask: 0.7320  decode.loss_dice: 1.2021  decode.d0.loss_cls: 3.2594  decode.d0.loss_mask: 0.7736  decode.d0.loss_dice: 1.3992  decode.d1.loss_cls: 1.3869  decode.d1.loss_mask: 0.7875  decode.d1.loss_dice: 1.2920  decode.d2.loss_cls: 1.3089  decode.d2.loss_mask: 0.7613  decode.d2.loss_dice: 1.1979  decode.d3.loss_cls: 1.2742  decode.d3.loss_mask: 0.7131  decode.d3.loss_dice: 1.1857  decode.d4.loss_cls: 1.1598  decode.d4.loss_mask: 0.7148  decode.d4.loss_dice: 1.1964  decode.d5.loss_cls: 1.1555  decode.d5.loss_mask: 0.7017  decode.d5.loss_dice: 1.1990  decode.d6.loss_cls: 1.1943  decode.d6.loss_mask: 0.7214  decode.d6.loss_dice: 1.1902  decode.d7.loss_cls: 1.1757  decode.d7.loss_mask: 0.7202  decode.d7.loss_dice: 1.2254  decode.d8.loss_cls: 1.1666  decode.d8.loss_mask: 0.7282  decode.d8.loss_dice: 1.1607
2023/05/24 09:27:07 - mmengine - INFO - Iter(train) [122550/160000]  lr: 2.7065e-06  eta: 4:29:59  time: 0.4228  data_time: 0.0109  memory: 4895  grad_norm: 92.9116  loss: 29.1878  decode.loss_cls: 0.9974  decode.loss_mask: 0.6526  decode.loss_dice: 0.9556  decode.d0.loss_cls: 2.9495  decode.d0.loss_mask: 0.7325  decode.d0.loss_dice: 1.2091  decode.d1.loss_cls: 1.0404  decode.d1.loss_mask: 0.7731  decode.d1.loss_dice: 1.1625  decode.d2.loss_cls: 1.0120  decode.d2.loss_mask: 0.7602  decode.d2.loss_dice: 1.0647  decode.d3.loss_cls: 0.9834  decode.d3.loss_mask: 0.6680  decode.d3.loss_dice: 1.0106  decode.d4.loss_cls: 0.9677  decode.d4.loss_mask: 0.6783  decode.d4.loss_dice: 0.9931  decode.d5.loss_cls: 0.9768  decode.d5.loss_mask: 0.6771  decode.d5.loss_dice: 0.9910  decode.d6.loss_cls: 1.0592  decode.d6.loss_mask: 0.6489  decode.d6.loss_dice: 0.9767  decode.d7.loss_cls: 1.0413  decode.d7.loss_mask: 0.6463  decode.d7.loss_dice: 0.9543  decode.d8.loss_cls: 0.9699  decode.d8.loss_mask: 0.6655  decode.d8.loss_dice: 0.9700
2023/05/24 09:27:29 - mmengine - INFO - Iter(train) [122600/160000]  lr: 2.7032e-06  eta: 4:29:38  time: 0.4728  data_time: 0.0099  memory: 4836  grad_norm: 111.0966  loss: 33.6024  decode.loss_cls: 1.1229  decode.loss_mask: 0.8181  decode.loss_dice: 1.1568  decode.d0.loss_cls: 3.1459  decode.d0.loss_mask: 0.8999  decode.d0.loss_dice: 1.4257  decode.d1.loss_cls: 1.1572  decode.d1.loss_mask: 0.8298  decode.d1.loss_dice: 1.3115  decode.d2.loss_cls: 1.1458  decode.d2.loss_mask: 0.8511  decode.d2.loss_dice: 1.2129  decode.d3.loss_cls: 1.1017  decode.d3.loss_mask: 0.8344  decode.d3.loss_dice: 1.1620  decode.d4.loss_cls: 1.0991  decode.d4.loss_mask: 0.8195  decode.d4.loss_dice: 1.1662  decode.d5.loss_cls: 1.0894  decode.d5.loss_mask: 0.8309  decode.d5.loss_dice: 1.1710  decode.d6.loss_cls: 1.1018  decode.d6.loss_mask: 0.8250  decode.d6.loss_dice: 1.1575  decode.d7.loss_cls: 1.1059  decode.d7.loss_mask: 0.8278  decode.d7.loss_dice: 1.1539  decode.d8.loss_cls: 1.0923  decode.d8.loss_mask: 0.8279  decode.d8.loss_dice: 1.1588
2023/05/24 09:27:51 - mmengine - INFO - Iter(train) [122650/160000]  lr: 2.7000e-06  eta: 4:29:16  time: 0.4198  data_time: 0.0097  memory: 4879  grad_norm: 115.0467  loss: 28.0804  decode.loss_cls: 0.9737  decode.loss_mask: 0.5716  decode.loss_dice: 0.9633  decode.d0.loss_cls: 2.8194  decode.d0.loss_mask: 0.6869  decode.d0.loss_dice: 1.0907  decode.d1.loss_cls: 1.0961  decode.d1.loss_mask: 0.6379  decode.d1.loss_dice: 1.0885  decode.d2.loss_cls: 1.1257  decode.d2.loss_mask: 0.6040  decode.d2.loss_dice: 0.9922  decode.d3.loss_cls: 1.0376  decode.d3.loss_mask: 0.5914  decode.d3.loss_dice: 0.9872  decode.d4.loss_cls: 1.0431  decode.d4.loss_mask: 0.5880  decode.d4.loss_dice: 0.9708  decode.d5.loss_cls: 1.0208  decode.d5.loss_mask: 0.5917  decode.d5.loss_dice: 0.9661  decode.d6.loss_cls: 1.0166  decode.d6.loss_mask: 0.5673  decode.d6.loss_dice: 0.9649  decode.d7.loss_cls: 1.0429  decode.d7.loss_mask: 0.5678  decode.d7.loss_dice: 0.9422  decode.d8.loss_cls: 1.0026  decode.d8.loss_mask: 0.5676  decode.d8.loss_dice: 0.9618
2023/05/24 09:28:12 - mmengine - INFO - Iter(train) [122700/160000]  lr: 2.6967e-06  eta: 4:28:55  time: 0.4234  data_time: 0.0100  memory: 4905  grad_norm: 92.6276  loss: 30.1314  decode.loss_cls: 0.9549  decode.loss_mask: 0.7285  decode.loss_dice: 1.0034  decode.d0.loss_cls: 2.9016  decode.d0.loss_mask: 0.7888  decode.d0.loss_dice: 1.1997  decode.d1.loss_cls: 1.1448  decode.d1.loss_mask: 0.7627  decode.d1.loss_dice: 1.1506  decode.d2.loss_cls: 1.0960  decode.d2.loss_mask: 0.7476  decode.d2.loss_dice: 1.0361  decode.d3.loss_cls: 1.0764  decode.d3.loss_mask: 0.7560  decode.d3.loss_dice: 1.0384  decode.d4.loss_cls: 1.1027  decode.d4.loss_mask: 0.7484  decode.d4.loss_dice: 1.0244  decode.d5.loss_cls: 0.9761  decode.d5.loss_mask: 0.7408  decode.d5.loss_dice: 1.0215  decode.d6.loss_cls: 0.9858  decode.d6.loss_mask: 0.7369  decode.d6.loss_dice: 0.9965  decode.d7.loss_cls: 0.9774  decode.d7.loss_mask: 0.7129  decode.d7.loss_dice: 1.0001  decode.d8.loss_cls: 1.0053  decode.d8.loss_mask: 0.7145  decode.d8.loss_dice: 1.0026
2023/05/24 09:28:34 - mmengine - INFO - Iter(train) [122750/160000]  lr: 2.6934e-06  eta: 4:28:33  time: 0.4293  data_time: 0.0107  memory: 4847  grad_norm: 84.8738  loss: 37.0526  decode.loss_cls: 1.3502  decode.loss_mask: 0.7581  decode.loss_dice: 1.3100  decode.d0.loss_cls: 3.1387  decode.d0.loss_mask: 0.8799  decode.d0.loss_dice: 1.6097  decode.d1.loss_cls: 1.4091  decode.d1.loss_mask: 0.8052  decode.d1.loss_dice: 1.4854  decode.d2.loss_cls: 1.2880  decode.d2.loss_mask: 0.8439  decode.d2.loss_dice: 1.4058  decode.d3.loss_cls: 1.3705  decode.d3.loss_mask: 0.8011  decode.d3.loss_dice: 1.3578  decode.d4.loss_cls: 1.3326  decode.d4.loss_mask: 0.7995  decode.d4.loss_dice: 1.3571  decode.d5.loss_cls: 1.2817  decode.d5.loss_mask: 0.8241  decode.d5.loss_dice: 1.3340  decode.d6.loss_cls: 1.3097  decode.d6.loss_mask: 0.8402  decode.d6.loss_dice: 1.3150  decode.d7.loss_cls: 1.3351  decode.d7.loss_mask: 0.7813  decode.d7.loss_dice: 1.3059  decode.d8.loss_cls: 1.3352  decode.d8.loss_mask: 0.7804  decode.d8.loss_dice: 1.3073
2023/05/24 09:28:55 - mmengine - INFO - Iter(train) [122800/160000]  lr: 2.6902e-06  eta: 4:28:11  time: 0.4297  data_time: 0.0100  memory: 4837  grad_norm: 97.5492  loss: 29.9175  decode.loss_cls: 1.0866  decode.loss_mask: 0.6796  decode.loss_dice: 0.9379  decode.d0.loss_cls: 2.8196  decode.d0.loss_mask: 0.8094  decode.d0.loss_dice: 1.2256  decode.d1.loss_cls: 1.2427  decode.d1.loss_mask: 0.7670  decode.d1.loss_dice: 1.0862  decode.d2.loss_cls: 1.1467  decode.d2.loss_mask: 0.6918  decode.d2.loss_dice: 1.0149  decode.d3.loss_cls: 1.0872  decode.d3.loss_mask: 0.6765  decode.d3.loss_dice: 0.9808  decode.d4.loss_cls: 1.0775  decode.d4.loss_mask: 0.6719  decode.d4.loss_dice: 0.9992  decode.d5.loss_cls: 1.0757  decode.d5.loss_mask: 0.6685  decode.d5.loss_dice: 0.9882  decode.d6.loss_cls: 1.0803  decode.d6.loss_mask: 0.7010  decode.d6.loss_dice: 0.9752  decode.d7.loss_cls: 1.0594  decode.d7.loss_mask: 0.6962  decode.d7.loss_dice: 0.9676  decode.d8.loss_cls: 1.0314  decode.d8.loss_mask: 0.6972  decode.d8.loss_dice: 0.9755
2023/05/24 09:29:16 - mmengine - INFO - Iter(train) [122850/160000]  lr: 2.6869e-06  eta: 4:27:49  time: 0.4183  data_time: 0.0096  memory: 4867  grad_norm: 88.6809  loss: 38.0333  decode.loss_cls: 1.2905  decode.loss_mask: 0.7988  decode.loss_dice: 1.4119  decode.d0.loss_cls: 3.2445  decode.d0.loss_mask: 0.8554  decode.d0.loss_dice: 1.6738  decode.d1.loss_cls: 1.5303  decode.d1.loss_mask: 0.8215  decode.d1.loss_dice: 1.5130  decode.d2.loss_cls: 1.4080  decode.d2.loss_mask: 0.7726  decode.d2.loss_dice: 1.4811  decode.d3.loss_cls: 1.3877  decode.d3.loss_mask: 0.7667  decode.d3.loss_dice: 1.4232  decode.d4.loss_cls: 1.3490  decode.d4.loss_mask: 0.8043  decode.d4.loss_dice: 1.4434  decode.d5.loss_cls: 1.3649  decode.d5.loss_mask: 0.7861  decode.d5.loss_dice: 1.4347  decode.d6.loss_cls: 1.3273  decode.d6.loss_mask: 0.7974  decode.d6.loss_dice: 1.3907  decode.d7.loss_cls: 1.2694  decode.d7.loss_mask: 0.8008  decode.d7.loss_dice: 1.4107  decode.d8.loss_cls: 1.2614  decode.d8.loss_mask: 0.7970  decode.d8.loss_dice: 1.4171
2023/05/24 09:29:38 - mmengine - INFO - Iter(train) [122900/160000]  lr: 2.6837e-06  eta: 4:27:28  time: 0.4747  data_time: 0.0096  memory: 4859  grad_norm: 79.8382  loss: 38.0456  decode.loss_cls: 1.2349  decode.loss_mask: 0.6519  decode.loss_dice: 1.5417  decode.d0.loss_cls: 3.4622  decode.d0.loss_mask: 0.7265  decode.d0.loss_dice: 1.8371  decode.d1.loss_cls: 1.4612  decode.d1.loss_mask: 0.6727  decode.d1.loss_dice: 1.7151  decode.d2.loss_cls: 1.3659  decode.d2.loss_mask: 0.6651  decode.d2.loss_dice: 1.6425  decode.d3.loss_cls: 1.3596  decode.d3.loss_mask: 0.6542  decode.d3.loss_dice: 1.5648  decode.d4.loss_cls: 1.2566  decode.d4.loss_mask: 0.6501  decode.d4.loss_dice: 1.6148  decode.d5.loss_cls: 1.2410  decode.d5.loss_mask: 0.6734  decode.d5.loss_dice: 1.5652  decode.d6.loss_cls: 1.2851  decode.d6.loss_mask: 0.6514  decode.d6.loss_dice: 1.5588  decode.d7.loss_cls: 1.2790  decode.d7.loss_mask: 0.6474  decode.d7.loss_dice: 1.5743  decode.d8.loss_cls: 1.2658  decode.d8.loss_mask: 0.6424  decode.d8.loss_dice: 1.5850
2023/05/24 09:30:00 - mmengine - INFO - Iter(train) [122950/160000]  lr: 2.6804e-06  eta: 4:27:06  time: 0.4280  data_time: 0.0099  memory: 4887  grad_norm: 101.6048  loss: 31.1582  decode.loss_cls: 1.0877  decode.loss_mask: 0.7104  decode.loss_dice: 0.9987  decode.d0.loss_cls: 3.0911  decode.d0.loss_mask: 0.7734  decode.d0.loss_dice: 1.2611  decode.d1.loss_cls: 1.2852  decode.d1.loss_mask: 0.7560  decode.d1.loss_dice: 1.1360  decode.d2.loss_cls: 1.2421  decode.d2.loss_mask: 0.7436  decode.d2.loss_dice: 1.0652  decode.d3.loss_cls: 1.1029  decode.d3.loss_mask: 0.7290  decode.d3.loss_dice: 1.0470  decode.d4.loss_cls: 1.1440  decode.d4.loss_mask: 0.7015  decode.d4.loss_dice: 1.0537  decode.d5.loss_cls: 1.0800  decode.d5.loss_mask: 0.6969  decode.d5.loss_dice: 1.0299  decode.d6.loss_cls: 1.0797  decode.d6.loss_mask: 0.6904  decode.d6.loss_dice: 1.0137  decode.d7.loss_cls: 1.0349  decode.d7.loss_mask: 0.7197  decode.d7.loss_dice: 1.0310  decode.d8.loss_cls: 1.1469  decode.d8.loss_mask: 0.6949  decode.d8.loss_dice: 1.0116
2023/05/24 09:30:21 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 09:30:21 - mmengine - INFO - Iter(train) [123000/160000]  lr: 2.6772e-06  eta: 4:26:45  time: 0.4512  data_time: 0.0098  memory: 4845  grad_norm: 95.2421  loss: 35.6317  decode.loss_cls: 1.0591  decode.loss_mask: 0.8562  decode.loss_dice: 1.3304  decode.d0.loss_cls: 3.2960  decode.d0.loss_mask: 0.9258  decode.d0.loss_dice: 1.5950  decode.d1.loss_cls: 1.1607  decode.d1.loss_mask: 0.8869  decode.d1.loss_dice: 1.4839  decode.d2.loss_cls: 1.1346  decode.d2.loss_mask: 0.8608  decode.d2.loss_dice: 1.3979  decode.d3.loss_cls: 1.1426  decode.d3.loss_mask: 0.8420  decode.d3.loss_dice: 1.3716  decode.d4.loss_cls: 1.0992  decode.d4.loss_mask: 0.8339  decode.d4.loss_dice: 1.3473  decode.d5.loss_cls: 1.0531  decode.d5.loss_mask: 0.8262  decode.d5.loss_dice: 1.3526  decode.d6.loss_cls: 1.0964  decode.d6.loss_mask: 0.8431  decode.d6.loss_dice: 1.3266  decode.d7.loss_cls: 1.0468  decode.d7.loss_mask: 0.8536  decode.d7.loss_dice: 1.3476  decode.d8.loss_cls: 1.0482  decode.d8.loss_mask: 0.8648  decode.d8.loss_dice: 1.3488
2023/05/24 09:30:21 - mmengine - INFO - Saving checkpoint at 123000 iterations
2023/05/24 09:30:51 - mmengine - INFO - Iter(train) [123050/160000]  lr: 2.6739e-06  eta: 4:26:25  time: 0.4870  data_time: 0.0106  memory: 4875  grad_norm: 108.7568  loss: 30.1480  decode.loss_cls: 1.0835  decode.loss_mask: 0.7363  decode.loss_dice: 0.9724  decode.d0.loss_cls: 2.9120  decode.d0.loss_mask: 0.7959  decode.d0.loss_dice: 1.1623  decode.d1.loss_cls: 1.1234  decode.d1.loss_mask: 0.7199  decode.d1.loss_dice: 1.0660  decode.d2.loss_cls: 1.1402  decode.d2.loss_mask: 0.7147  decode.d2.loss_dice: 0.9951  decode.d3.loss_cls: 1.0849  decode.d3.loss_mask: 0.7355  decode.d3.loss_dice: 0.9868  decode.d4.loss_cls: 1.0363  decode.d4.loss_mask: 0.7417  decode.d4.loss_dice: 0.9891  decode.d5.loss_cls: 1.0577  decode.d5.loss_mask: 0.7324  decode.d5.loss_dice: 1.0024  decode.d6.loss_cls: 1.0727  decode.d6.loss_mask: 0.7467  decode.d6.loss_dice: 0.9896  decode.d7.loss_cls: 1.0466  decode.d7.loss_mask: 0.7432  decode.d7.loss_dice: 0.9848  decode.d8.loss_cls: 1.0397  decode.d8.loss_mask: 0.7398  decode.d8.loss_dice: 0.9965
2023/05/24 09:31:16 - mmengine - INFO - Iter(train) [123100/160000]  lr: 2.6707e-06  eta: 4:26:05  time: 0.4861  data_time: 0.0099  memory: 4837  grad_norm: 96.3072  loss: 31.1930  decode.loss_cls: 1.0720  decode.loss_mask: 0.6227  decode.loss_dice: 1.1505  decode.d0.loss_cls: 2.8485  decode.d0.loss_mask: 0.6985  decode.d0.loss_dice: 1.3573  decode.d1.loss_cls: 1.2102  decode.d1.loss_mask: 0.6555  decode.d1.loss_dice: 1.2872  decode.d2.loss_cls: 1.1706  decode.d2.loss_mask: 0.6495  decode.d2.loss_dice: 1.2517  decode.d3.loss_cls: 1.1496  decode.d3.loss_mask: 0.6229  decode.d3.loss_dice: 1.1880  decode.d4.loss_cls: 1.0582  decode.d4.loss_mask: 0.6433  decode.d4.loss_dice: 1.2069  decode.d5.loss_cls: 1.0514  decode.d5.loss_mask: 0.6434  decode.d5.loss_dice: 1.2047  decode.d6.loss_cls: 1.0747  decode.d6.loss_mask: 0.6207  decode.d6.loss_dice: 1.1359  decode.d7.loss_cls: 0.9889  decode.d7.loss_mask: 0.6114  decode.d7.loss_dice: 1.1962  decode.d8.loss_cls: 1.0371  decode.d8.loss_mask: 0.6165  decode.d8.loss_dice: 1.1690
2023/05/24 09:31:39 - mmengine - INFO - Iter(train) [123150/160000]  lr: 2.6674e-06  eta: 4:25:43  time: 0.4295  data_time: 0.0107  memory: 4883  grad_norm: 108.4491  loss: 38.9177  decode.loss_cls: 1.3321  decode.loss_mask: 0.8639  decode.loss_dice: 1.3619  decode.d0.loss_cls: 3.4164  decode.d0.loss_mask: 0.8941  decode.d0.loss_dice: 1.8046  decode.d1.loss_cls: 1.5167  decode.d1.loss_mask: 0.8764  decode.d1.loss_dice: 1.5003  decode.d2.loss_cls: 1.4591  decode.d2.loss_mask: 0.8956  decode.d2.loss_dice: 1.3948  decode.d3.loss_cls: 1.4500  decode.d3.loss_mask: 0.8683  decode.d3.loss_dice: 1.3624  decode.d4.loss_cls: 1.4185  decode.d4.loss_mask: 0.8734  decode.d4.loss_dice: 1.3608  decode.d5.loss_cls: 1.4079  decode.d5.loss_mask: 0.8423  decode.d5.loss_dice: 1.3327  decode.d6.loss_cls: 1.3725  decode.d6.loss_mask: 0.8591  decode.d6.loss_dice: 1.3316  decode.d7.loss_cls: 1.3694  decode.d7.loss_mask: 0.8551  decode.d7.loss_dice: 1.3662  decode.d8.loss_cls: 1.3362  decode.d8.loss_mask: 0.8547  decode.d8.loss_dice: 1.3407
2023/05/24 09:32:02 - mmengine - INFO - Iter(train) [123200/160000]  lr: 2.6641e-06  eta: 4:25:22  time: 0.4798  data_time: 0.0104  memory: 4838  grad_norm: 91.7090  loss: 39.9010  decode.loss_cls: 1.3476  decode.loss_mask: 0.8558  decode.loss_dice: 1.4913  decode.d0.loss_cls: 3.3848  decode.d0.loss_mask: 0.8942  decode.d0.loss_dice: 1.7877  decode.d1.loss_cls: 1.4223  decode.d1.loss_mask: 0.8774  decode.d1.loss_dice: 1.5751  decode.d2.loss_cls: 1.4290  decode.d2.loss_mask: 0.9039  decode.d2.loss_dice: 1.5219  decode.d3.loss_cls: 1.4794  decode.d3.loss_mask: 0.8447  decode.d3.loss_dice: 1.4631  decode.d4.loss_cls: 1.3857  decode.d4.loss_mask: 0.8601  decode.d4.loss_dice: 1.4588  decode.d5.loss_cls: 1.4033  decode.d5.loss_mask: 0.8691  decode.d5.loss_dice: 1.4966  decode.d6.loss_cls: 1.3104  decode.d6.loss_mask: 0.8783  decode.d6.loss_dice: 1.4987  decode.d7.loss_cls: 1.3789  decode.d7.loss_mask: 0.8691  decode.d7.loss_dice: 1.4676  decode.d8.loss_cls: 1.3436  decode.d8.loss_mask: 0.8848  decode.d8.loss_dice: 1.5178
2023/05/24 09:32:24 - mmengine - INFO - Iter(train) [123250/160000]  lr: 2.6609e-06  eta: 4:25:01  time: 0.4282  data_time: 0.0102  memory: 4871  grad_norm: 99.9192  loss: 36.8511  decode.loss_cls: 1.3132  decode.loss_mask: 0.7885  decode.loss_dice: 1.2875  decode.d0.loss_cls: 3.1217  decode.d0.loss_mask: 0.9230  decode.d0.loss_dice: 1.4905  decode.d1.loss_cls: 1.4190  decode.d1.loss_mask: 0.8231  decode.d1.loss_dice: 1.4180  decode.d2.loss_cls: 1.3435  decode.d2.loss_mask: 0.8068  decode.d2.loss_dice: 1.3651  decode.d3.loss_cls: 1.2971  decode.d3.loss_mask: 0.8158  decode.d3.loss_dice: 1.3291  decode.d4.loss_cls: 1.3523  decode.d4.loss_mask: 0.8442  decode.d4.loss_dice: 1.3498  decode.d5.loss_cls: 1.3048  decode.d5.loss_mask: 0.8152  decode.d5.loss_dice: 1.3359  decode.d6.loss_cls: 1.3105  decode.d6.loss_mask: 0.8365  decode.d6.loss_dice: 1.3168  decode.d7.loss_cls: 1.2961  decode.d7.loss_mask: 0.8013  decode.d7.loss_dice: 1.3273  decode.d8.loss_cls: 1.3470  decode.d8.loss_mask: 0.7866  decode.d8.loss_dice: 1.2851
2023/05/24 09:32:45 - mmengine - INFO - Iter(train) [123300/160000]  lr: 2.6576e-06  eta: 4:24:39  time: 0.4143  data_time: 0.0097  memory: 4823  grad_norm: 88.5722  loss: 31.1867  decode.loss_cls: 1.0791  decode.loss_mask: 0.6483  decode.loss_dice: 1.0931  decode.d0.loss_cls: 2.9440  decode.d0.loss_mask: 0.6504  decode.d0.loss_dice: 1.3632  decode.d1.loss_cls: 1.2524  decode.d1.loss_mask: 0.6602  decode.d1.loss_dice: 1.1843  decode.d2.loss_cls: 1.1996  decode.d2.loss_mask: 0.6647  decode.d2.loss_dice: 1.1410  decode.d3.loss_cls: 1.1758  decode.d3.loss_mask: 0.6641  decode.d3.loss_dice: 1.1149  decode.d4.loss_cls: 1.1351  decode.d4.loss_mask: 0.6506  decode.d4.loss_dice: 1.1075  decode.d5.loss_cls: 1.1323  decode.d5.loss_mask: 0.6510  decode.d5.loss_dice: 1.1070  decode.d6.loss_cls: 1.1411  decode.d6.loss_mask: 0.6437  decode.d6.loss_dice: 1.0767  decode.d7.loss_cls: 1.1191  decode.d7.loss_mask: 0.6408  decode.d7.loss_dice: 1.0831  decode.d8.loss_cls: 1.1227  decode.d8.loss_mask: 0.6516  decode.d8.loss_dice: 1.0892
2023/05/24 09:33:06 - mmengine - INFO - Iter(train) [123350/160000]  lr: 2.6544e-06  eta: 4:24:17  time: 0.4238  data_time: 0.0099  memory: 4947  grad_norm: 84.3076  loss: 46.0173  decode.loss_cls: 1.3993  decode.loss_mask: 1.0048  decode.loss_dice: 1.8898  decode.d0.loss_cls: 3.5241  decode.d0.loss_mask: 1.0695  decode.d0.loss_dice: 2.2804  decode.d1.loss_cls: 1.4273  decode.d1.loss_mask: 1.0589  decode.d1.loss_dice: 2.1054  decode.d2.loss_cls: 1.4497  decode.d2.loss_mask: 1.0081  decode.d2.loss_dice: 1.9581  decode.d3.loss_cls: 1.4364  decode.d3.loss_mask: 0.9791  decode.d3.loss_dice: 1.9482  decode.d4.loss_cls: 1.3626  decode.d4.loss_mask: 0.9797  decode.d4.loss_dice: 1.9376  decode.d5.loss_cls: 1.4241  decode.d5.loss_mask: 0.9681  decode.d5.loss_dice: 1.9040  decode.d6.loss_cls: 1.4460  decode.d6.loss_mask: 0.9590  decode.d6.loss_dice: 1.8839  decode.d7.loss_cls: 1.4018  decode.d7.loss_mask: 0.9768  decode.d7.loss_dice: 1.8935  decode.d8.loss_cls: 1.4276  decode.d8.loss_mask: 0.9965  decode.d8.loss_dice: 1.9169
2023/05/24 09:33:27 - mmengine - INFO - Iter(train) [123400/160000]  lr: 2.6511e-06  eta: 4:23:55  time: 0.4256  data_time: 0.0100  memory: 4867  grad_norm: 118.7479  loss: 29.3557  decode.loss_cls: 0.9140  decode.loss_mask: 0.6167  decode.loss_dice: 1.0565  decode.d0.loss_cls: 2.9243  decode.d0.loss_mask: 0.7088  decode.d0.loss_dice: 1.2177  decode.d1.loss_cls: 1.1129  decode.d1.loss_mask: 0.6766  decode.d1.loss_dice: 1.1768  decode.d2.loss_cls: 1.0935  decode.d2.loss_mask: 0.6420  decode.d2.loss_dice: 1.1075  decode.d3.loss_cls: 1.0363  decode.d3.loss_mask: 0.6205  decode.d3.loss_dice: 1.0587  decode.d4.loss_cls: 1.0233  decode.d4.loss_mask: 0.6333  decode.d4.loss_dice: 1.0564  decode.d5.loss_cls: 1.0394  decode.d5.loss_mask: 0.6180  decode.d5.loss_dice: 1.0528  decode.d6.loss_cls: 0.9667  decode.d6.loss_mask: 0.6281  decode.d6.loss_dice: 1.0485  decode.d7.loss_cls: 1.0009  decode.d7.loss_mask: 0.6304  decode.d7.loss_dice: 1.0602  decode.d8.loss_cls: 0.9510  decode.d8.loss_mask: 0.6279  decode.d8.loss_dice: 1.0560
2023/05/24 09:33:48 - mmengine - INFO - Iter(train) [123450/160000]  lr: 2.6478e-06  eta: 4:23:33  time: 0.4277  data_time: 0.0103  memory: 4877  grad_norm: 83.2551  loss: 35.8973  decode.loss_cls: 1.1902  decode.loss_mask: 0.7304  decode.loss_dice: 1.3277  decode.d0.loss_cls: 3.2886  decode.d0.loss_mask: 0.8884  decode.d0.loss_dice: 1.5041  decode.d1.loss_cls: 1.3261  decode.d1.loss_mask: 0.8458  decode.d1.loss_dice: 1.4620  decode.d2.loss_cls: 1.3313  decode.d2.loss_mask: 0.7711  decode.d2.loss_dice: 1.3579  decode.d3.loss_cls: 1.2686  decode.d3.loss_mask: 0.7499  decode.d3.loss_dice: 1.3544  decode.d4.loss_cls: 1.2796  decode.d4.loss_mask: 0.7250  decode.d4.loss_dice: 1.3353  decode.d5.loss_cls: 1.2621  decode.d5.loss_mask: 0.7179  decode.d5.loss_dice: 1.3295  decode.d6.loss_cls: 1.2143  decode.d6.loss_mask: 0.7393  decode.d6.loss_dice: 1.3396  decode.d7.loss_cls: 1.2297  decode.d7.loss_mask: 0.7173  decode.d7.loss_dice: 1.3315  decode.d8.loss_cls: 1.2106  decode.d8.loss_mask: 0.7267  decode.d8.loss_dice: 1.3425
2023/05/24 09:34:10 - mmengine - INFO - Iter(train) [123500/160000]  lr: 2.6446e-06  eta: 4:23:12  time: 0.4289  data_time: 0.0101  memory: 4829  grad_norm: 92.2353  loss: 35.6755  decode.loss_cls: 1.2343  decode.loss_mask: 0.8147  decode.loss_dice: 1.2446  decode.d0.loss_cls: 2.9115  decode.d0.loss_mask: 0.9228  decode.d0.loss_dice: 1.5695  decode.d1.loss_cls: 1.2413  decode.d1.loss_mask: 0.8838  decode.d1.loss_dice: 1.4230  decode.d2.loss_cls: 1.2273  decode.d2.loss_mask: 0.8875  decode.d2.loss_dice: 1.3544  decode.d3.loss_cls: 1.2780  decode.d3.loss_mask: 0.8019  decode.d3.loss_dice: 1.2702  decode.d4.loss_cls: 1.3067  decode.d4.loss_mask: 0.7870  decode.d4.loss_dice: 1.2494  decode.d5.loss_cls: 1.2656  decode.d5.loss_mask: 0.7962  decode.d5.loss_dice: 1.2606  decode.d6.loss_cls: 1.3118  decode.d6.loss_mask: 0.7796  decode.d6.loss_dice: 1.2114  decode.d7.loss_cls: 1.2890  decode.d7.loss_mask: 0.7815  decode.d7.loss_dice: 1.2536  decode.d8.loss_cls: 1.2479  decode.d8.loss_mask: 0.8040  decode.d8.loss_dice: 1.2664
2023/05/24 09:34:34 - mmengine - INFO - Iter(train) [123550/160000]  lr: 2.6413e-06  eta: 4:22:51  time: 0.4797  data_time: 0.0100  memory: 4836  grad_norm: 96.9351  loss: 36.3412  decode.loss_cls: 1.2658  decode.loss_mask: 0.7277  decode.loss_dice: 1.2822  decode.d0.loss_cls: 3.5756  decode.d0.loss_mask: 0.8431  decode.d0.loss_dice: 1.5695  decode.d1.loss_cls: 1.3956  decode.d1.loss_mask: 0.8459  decode.d1.loss_dice: 1.4144  decode.d2.loss_cls: 1.3800  decode.d2.loss_mask: 0.7876  decode.d2.loss_dice: 1.3494  decode.d3.loss_cls: 1.2527  decode.d3.loss_mask: 0.7333  decode.d3.loss_dice: 1.3562  decode.d4.loss_cls: 1.2685  decode.d4.loss_mask: 0.7143  decode.d4.loss_dice: 1.3191  decode.d5.loss_cls: 1.3005  decode.d5.loss_mask: 0.7191  decode.d5.loss_dice: 1.3311  decode.d6.loss_cls: 1.3317  decode.d6.loss_mask: 0.7147  decode.d6.loss_dice: 1.3189  decode.d7.loss_cls: 1.2682  decode.d7.loss_mask: 0.7312  decode.d7.loss_dice: 1.3103  decode.d8.loss_cls: 1.2053  decode.d8.loss_mask: 0.7282  decode.d8.loss_dice: 1.3010
2023/05/24 09:34:55 - mmengine - INFO - Iter(train) [123600/160000]  lr: 2.6381e-06  eta: 4:22:29  time: 0.4264  data_time: 0.0101  memory: 4859  grad_norm: 101.1979  loss: 41.8337  decode.loss_cls: 1.3612  decode.loss_mask: 0.9158  decode.loss_dice: 1.6208  decode.d0.loss_cls: 3.2515  decode.d0.loss_mask: 1.0175  decode.d0.loss_dice: 1.9856  decode.d1.loss_cls: 1.4631  decode.d1.loss_mask: 0.9778  decode.d1.loss_dice: 1.8314  decode.d2.loss_cls: 1.3581  decode.d2.loss_mask: 0.9571  decode.d2.loss_dice: 1.7179  decode.d3.loss_cls: 1.3119  decode.d3.loss_mask: 0.9550  decode.d3.loss_dice: 1.6164  decode.d4.loss_cls: 1.3174  decode.d4.loss_mask: 0.9505  decode.d4.loss_dice: 1.6640  decode.d5.loss_cls: 1.3700  decode.d5.loss_mask: 0.9281  decode.d5.loss_dice: 1.6131  decode.d6.loss_cls: 1.3472  decode.d6.loss_mask: 0.9241  decode.d6.loss_dice: 1.5953  decode.d7.loss_cls: 1.3364  decode.d7.loss_mask: 0.9355  decode.d7.loss_dice: 1.6077  decode.d8.loss_cls: 1.3658  decode.d8.loss_mask: 0.9259  decode.d8.loss_dice: 1.6115
2023/05/24 09:35:16 - mmengine - INFO - Iter(train) [123650/160000]  lr: 2.6348e-06  eta: 4:22:07  time: 0.4152  data_time: 0.0099  memory: 4948  grad_norm: 101.6012  loss: 39.9737  decode.loss_cls: 1.1575  decode.loss_mask: 0.7755  decode.loss_dice: 1.7358  decode.d0.loss_cls: 3.4074  decode.d0.loss_mask: 0.8692  decode.d0.loss_dice: 1.9995  decode.d1.loss_cls: 1.3229  decode.d1.loss_mask: 0.8068  decode.d1.loss_dice: 1.8988  decode.d2.loss_cls: 1.2764  decode.d2.loss_mask: 0.7746  decode.d2.loss_dice: 1.7913  decode.d3.loss_cls: 1.2236  decode.d3.loss_mask: 0.7694  decode.d3.loss_dice: 1.8077  decode.d4.loss_cls: 1.2123  decode.d4.loss_mask: 0.7763  decode.d4.loss_dice: 1.7265  decode.d5.loss_cls: 1.2030  decode.d5.loss_mask: 0.7771  decode.d5.loss_dice: 1.7318  decode.d6.loss_cls: 1.1968  decode.d6.loss_mask: 0.7496  decode.d6.loss_dice: 1.6980  decode.d7.loss_cls: 1.1663  decode.d7.loss_mask: 0.7656  decode.d7.loss_dice: 1.7411  decode.d8.loss_cls: 1.1301  decode.d8.loss_mask: 0.7797  decode.d8.loss_dice: 1.7030
2023/05/24 09:35:38 - mmengine - INFO - Iter(train) [123700/160000]  lr: 2.6315e-06  eta: 4:21:46  time: 0.4154  data_time: 0.0097  memory: 4909  grad_norm: 100.7863  loss: 34.6209  decode.loss_cls: 1.1011  decode.loss_mask: 0.8118  decode.loss_dice: 1.2692  decode.d0.loss_cls: 3.1240  decode.d0.loss_mask: 0.8899  decode.d0.loss_dice: 1.4029  decode.d1.loss_cls: 1.2246  decode.d1.loss_mask: 0.8779  decode.d1.loss_dice: 1.4075  decode.d2.loss_cls: 1.1123  decode.d2.loss_mask: 0.8573  decode.d2.loss_dice: 1.3081  decode.d3.loss_cls: 1.1631  decode.d3.loss_mask: 0.8426  decode.d3.loss_dice: 1.3128  decode.d4.loss_cls: 1.1182  decode.d4.loss_mask: 0.8451  decode.d4.loss_dice: 1.2944  decode.d5.loss_cls: 1.0466  decode.d5.loss_mask: 0.8262  decode.d5.loss_dice: 1.3082  decode.d6.loss_cls: 1.0971  decode.d6.loss_mask: 0.8223  decode.d6.loss_dice: 1.2824  decode.d7.loss_cls: 1.0875  decode.d7.loss_mask: 0.8239  decode.d7.loss_dice: 1.2455  decode.d8.loss_cls: 1.0847  decode.d8.loss_mask: 0.8131  decode.d8.loss_dice: 1.2207
2023/05/24 09:35:59 - mmengine - INFO - Iter(train) [123750/160000]  lr: 2.6283e-06  eta: 4:21:24  time: 0.4320  data_time: 0.0104  memory: 4839  grad_norm: 83.9378  loss: 31.9000  decode.loss_cls: 1.1682  decode.loss_mask: 0.7726  decode.loss_dice: 0.9786  decode.d0.loss_cls: 2.9452  decode.d0.loss_mask: 0.9014  decode.d0.loss_dice: 1.1090  decode.d1.loss_cls: 1.1635  decode.d1.loss_mask: 0.8537  decode.d1.loss_dice: 1.0709  decode.d2.loss_cls: 1.1980  decode.d2.loss_mask: 0.8181  decode.d2.loss_dice: 1.0337  decode.d3.loss_cls: 1.2532  decode.d3.loss_mask: 0.8243  decode.d3.loss_dice: 1.0312  decode.d4.loss_cls: 1.1867  decode.d4.loss_mask: 0.7863  decode.d4.loss_dice: 1.0077  decode.d5.loss_cls: 1.1167  decode.d5.loss_mask: 0.8062  decode.d5.loss_dice: 0.9801  decode.d6.loss_cls: 1.2128  decode.d6.loss_mask: 0.7753  decode.d6.loss_dice: 1.0209  decode.d7.loss_cls: 1.1344  decode.d7.loss_mask: 0.8064  decode.d7.loss_dice: 1.0248  decode.d8.loss_cls: 1.1445  decode.d8.loss_mask: 0.7718  decode.d8.loss_dice: 1.0039
2023/05/24 09:36:20 - mmengine - INFO - Iter(train) [123800/160000]  lr: 2.6250e-06  eta: 4:21:02  time: 0.4192  data_time: 0.0100  memory: 4837  grad_norm: 105.5985  loss: 27.1250  decode.loss_cls: 0.8695  decode.loss_mask: 0.6563  decode.loss_dice: 0.8927  decode.d0.loss_cls: 2.8052  decode.d0.loss_mask: 0.7404  decode.d0.loss_dice: 1.1006  decode.d1.loss_cls: 0.9288  decode.d1.loss_mask: 0.6763  decode.d1.loss_dice: 1.0190  decode.d2.loss_cls: 0.9438  decode.d2.loss_mask: 0.6294  decode.d2.loss_dice: 0.9717  decode.d3.loss_cls: 0.9336  decode.d3.loss_mask: 0.6365  decode.d3.loss_dice: 0.9622  decode.d4.loss_cls: 0.9085  decode.d4.loss_mask: 0.6442  decode.d4.loss_dice: 0.9607  decode.d5.loss_cls: 0.8980  decode.d5.loss_mask: 0.6542  decode.d5.loss_dice: 0.9417  decode.d6.loss_cls: 0.8705  decode.d6.loss_mask: 0.6541  decode.d6.loss_dice: 0.9204  decode.d7.loss_cls: 0.8735  decode.d7.loss_mask: 0.6645  decode.d7.loss_dice: 0.9196  decode.d8.loss_cls: 0.8839  decode.d8.loss_mask: 0.6556  decode.d8.loss_dice: 0.9099
2023/05/24 09:36:42 - mmengine - INFO - Iter(train) [123850/160000]  lr: 2.6218e-06  eta: 4:20:40  time: 0.4232  data_time: 0.0098  memory: 4823  grad_norm: 129.8232  loss: 34.9974  decode.loss_cls: 1.2042  decode.loss_mask: 0.7401  decode.loss_dice: 1.1829  decode.d0.loss_cls: 3.3146  decode.d0.loss_mask: 0.8058  decode.d0.loss_dice: 1.3826  decode.d1.loss_cls: 1.4768  decode.d1.loss_mask: 0.8172  decode.d1.loss_dice: 1.2881  decode.d2.loss_cls: 1.3631  decode.d2.loss_mask: 0.7607  decode.d2.loss_dice: 1.2549  decode.d3.loss_cls: 1.3011  decode.d3.loss_mask: 0.7742  decode.d3.loss_dice: 1.2155  decode.d4.loss_cls: 1.2952  decode.d4.loss_mask: 0.7865  decode.d4.loss_dice: 1.2132  decode.d5.loss_cls: 1.2972  decode.d5.loss_mask: 0.7597  decode.d5.loss_dice: 1.2020  decode.d6.loss_cls: 1.3367  decode.d6.loss_mask: 0.7491  decode.d6.loss_dice: 1.1784  decode.d7.loss_cls: 1.2446  decode.d7.loss_mask: 0.7509  decode.d7.loss_dice: 1.1982  decode.d8.loss_cls: 1.1548  decode.d8.loss_mask: 0.7488  decode.d8.loss_dice: 1.2004
2023/05/24 09:37:03 - mmengine - INFO - Iter(train) [123900/160000]  lr: 2.6185e-06  eta: 4:20:19  time: 0.4285  data_time: 0.0098  memory: 4859  grad_norm: 97.8909  loss: 38.4563  decode.loss_cls: 1.3118  decode.loss_mask: 0.8177  decode.loss_dice: 1.4409  decode.d0.loss_cls: 3.1064  decode.d0.loss_mask: 0.8845  decode.d0.loss_dice: 1.5868  decode.d1.loss_cls: 1.3876  decode.d1.loss_mask: 0.9047  decode.d1.loss_dice: 1.6043  decode.d2.loss_cls: 1.3524  decode.d2.loss_mask: 0.8958  decode.d2.loss_dice: 1.5364  decode.d3.loss_cls: 1.3673  decode.d3.loss_mask: 0.8195  decode.d3.loss_dice: 1.4588  decode.d4.loss_cls: 1.3672  decode.d4.loss_mask: 0.8177  decode.d4.loss_dice: 1.4007  decode.d5.loss_cls: 1.3346  decode.d5.loss_mask: 0.8151  decode.d5.loss_dice: 1.4594  decode.d6.loss_cls: 1.3479  decode.d6.loss_mask: 0.8103  decode.d6.loss_dice: 1.4264  decode.d7.loss_cls: 1.3426  decode.d7.loss_mask: 0.8126  decode.d7.loss_dice: 1.4493  decode.d8.loss_cls: 1.3367  decode.d8.loss_mask: 0.8148  decode.d8.loss_dice: 1.4459
2023/05/24 09:37:24 - mmengine - INFO - Iter(train) [123950/160000]  lr: 2.6152e-06  eta: 4:19:57  time: 0.4286  data_time: 0.0100  memory: 4825  grad_norm: 94.3032  loss: 34.5698  decode.loss_cls: 1.1216  decode.loss_mask: 0.7128  decode.loss_dice: 1.2874  decode.d0.loss_cls: 3.1241  decode.d0.loss_mask: 0.8044  decode.d0.loss_dice: 1.5522  decode.d1.loss_cls: 1.2433  decode.d1.loss_mask: 0.8167  decode.d1.loss_dice: 1.4653  decode.d2.loss_cls: 1.1996  decode.d2.loss_mask: 0.7353  decode.d2.loss_dice: 1.3799  decode.d3.loss_cls: 1.1448  decode.d3.loss_mask: 0.7624  decode.d3.loss_dice: 1.3496  decode.d4.loss_cls: 1.1455  decode.d4.loss_mask: 0.7383  decode.d4.loss_dice: 1.3312  decode.d5.loss_cls: 1.1491  decode.d5.loss_mask: 0.7124  decode.d5.loss_dice: 1.3435  decode.d6.loss_cls: 1.1117  decode.d6.loss_mask: 0.7137  decode.d6.loss_dice: 1.2909  decode.d7.loss_cls: 1.1329  decode.d7.loss_mask: 0.7101  decode.d7.loss_dice: 1.3107  decode.d8.loss_cls: 1.1370  decode.d8.loss_mask: 0.7264  decode.d8.loss_dice: 1.3170
2023/05/24 09:37:45 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 09:37:45 - mmengine - INFO - Iter(train) [124000/160000]  lr: 2.6120e-06  eta: 4:19:35  time: 0.4162  data_time: 0.0097  memory: 4824  grad_norm: 95.2776  loss: 28.4067  decode.loss_cls: 1.0057  decode.loss_mask: 0.5901  decode.loss_dice: 0.9796  decode.d0.loss_cls: 2.6305  decode.d0.loss_mask: 0.5970  decode.d0.loss_dice: 1.1213  decode.d1.loss_cls: 1.2213  decode.d1.loss_mask: 0.5787  decode.d1.loss_dice: 1.0612  decode.d2.loss_cls: 1.1409  decode.d2.loss_mask: 0.5555  decode.d2.loss_dice: 1.0088  decode.d3.loss_cls: 1.1869  decode.d3.loss_mask: 0.5790  decode.d3.loss_dice: 0.9974  decode.d4.loss_cls: 1.0684  decode.d4.loss_mask: 0.5731  decode.d4.loss_dice: 0.9865  decode.d5.loss_cls: 1.0633  decode.d5.loss_mask: 0.6053  decode.d5.loss_dice: 1.0234  decode.d6.loss_cls: 1.0454  decode.d6.loss_mask: 0.6039  decode.d6.loss_dice: 1.0009  decode.d7.loss_cls: 1.0490  decode.d7.loss_mask: 0.5879  decode.d7.loss_dice: 1.0098  decode.d8.loss_cls: 0.9930  decode.d8.loss_mask: 0.5699  decode.d8.loss_dice: 0.9730
2023/05/24 09:37:45 - mmengine - INFO - Saving checkpoint at 124000 iterations
2023/05/24 09:38:12 - mmengine - INFO - Iter(train) [124050/160000]  lr: 2.6087e-06  eta: 4:19:15  time: 0.4250  data_time: 0.0105  memory: 4829  grad_norm: 94.0415  loss: 34.1618  decode.loss_cls: 0.9985  decode.loss_mask: 0.7879  decode.loss_dice: 1.3175  decode.d0.loss_cls: 2.9407  decode.d0.loss_mask: 0.8301  decode.d0.loss_dice: 1.5328  decode.d1.loss_cls: 1.2325  decode.d1.loss_mask: 0.8115  decode.d1.loss_dice: 1.4392  decode.d2.loss_cls: 1.1513  decode.d2.loss_mask: 0.8364  decode.d2.loss_dice: 1.3373  decode.d3.loss_cls: 1.1624  decode.d3.loss_mask: 0.7908  decode.d3.loss_dice: 1.3074  decode.d4.loss_cls: 1.0870  decode.d4.loss_mask: 0.8149  decode.d4.loss_dice: 1.3305  decode.d5.loss_cls: 1.0294  decode.d5.loss_mask: 0.7918  decode.d5.loss_dice: 1.3273  decode.d6.loss_cls: 1.0109  decode.d6.loss_mask: 0.7836  decode.d6.loss_dice: 1.2985  decode.d7.loss_cls: 1.0406  decode.d7.loss_mask: 0.7767  decode.d7.loss_dice: 1.2949  decode.d8.loss_cls: 1.0082  decode.d8.loss_mask: 0.7848  decode.d8.loss_dice: 1.3064
2023/05/24 09:38:33 - mmengine - INFO - Iter(train) [124100/160000]  lr: 2.6054e-06  eta: 4:18:53  time: 0.4230  data_time: 0.0102  memory: 4869  grad_norm: 87.8682  loss: 30.4052  decode.loss_cls: 0.9606  decode.loss_mask: 0.7295  decode.loss_dice: 1.1278  decode.d0.loss_cls: 2.8436  decode.d0.loss_mask: 0.7535  decode.d0.loss_dice: 1.2867  decode.d1.loss_cls: 0.9876  decode.d1.loss_mask: 0.7329  decode.d1.loss_dice: 1.2102  decode.d2.loss_cls: 1.0157  decode.d2.loss_mask: 0.7160  decode.d2.loss_dice: 1.1615  decode.d3.loss_cls: 0.9589  decode.d3.loss_mask: 0.7144  decode.d3.loss_dice: 1.1358  decode.d4.loss_cls: 1.0015  decode.d4.loss_mask: 0.7067  decode.d4.loss_dice: 1.1114  decode.d5.loss_cls: 0.9550  decode.d5.loss_mask: 0.7332  decode.d5.loss_dice: 1.1074  decode.d6.loss_cls: 0.9510  decode.d6.loss_mask: 0.7258  decode.d6.loss_dice: 1.1238  decode.d7.loss_cls: 0.9945  decode.d7.loss_mask: 0.7284  decode.d7.loss_dice: 1.1154  decode.d8.loss_cls: 1.0050  decode.d8.loss_mask: 0.7236  decode.d8.loss_dice: 1.0876
2023/05/24 09:38:54 - mmengine - INFO - Iter(train) [124150/160000]  lr: 2.6022e-06  eta: 4:18:31  time: 0.4279  data_time: 0.0099  memory: 4835  grad_norm: 90.5037  loss: 37.1055  decode.loss_cls: 1.2212  decode.loss_mask: 0.7560  decode.loss_dice: 1.4633  decode.d0.loss_cls: 3.1827  decode.d0.loss_mask: 0.8526  decode.d0.loss_dice: 1.7614  decode.d1.loss_cls: 1.2890  decode.d1.loss_mask: 0.8035  decode.d1.loss_dice: 1.6277  decode.d2.loss_cls: 1.1955  decode.d2.loss_mask: 0.8212  decode.d2.loss_dice: 1.5591  decode.d3.loss_cls: 1.1754  decode.d3.loss_mask: 0.7750  decode.d3.loss_dice: 1.4796  decode.d4.loss_cls: 1.2018  decode.d4.loss_mask: 0.7745  decode.d4.loss_dice: 1.4673  decode.d5.loss_cls: 1.2077  decode.d5.loss_mask: 0.7619  decode.d5.loss_dice: 1.4569  decode.d6.loss_cls: 1.2017  decode.d6.loss_mask: 0.7592  decode.d6.loss_dice: 1.4484  decode.d7.loss_cls: 1.1897  decode.d7.loss_mask: 0.7596  decode.d7.loss_dice: 1.4634  decode.d8.loss_cls: 1.1992  decode.d8.loss_mask: 0.7626  decode.d8.loss_dice: 1.4882
2023/05/24 09:39:16 - mmengine - INFO - Iter(train) [124200/160000]  lr: 2.5989e-06  eta: 4:18:10  time: 0.4362  data_time: 0.0099  memory: 4869  grad_norm: 91.9263  loss: 28.3068  decode.loss_cls: 0.9548  decode.loss_mask: 0.6600  decode.loss_dice: 0.9145  decode.d0.loss_cls: 2.8396  decode.d0.loss_mask: 0.7339  decode.d0.loss_dice: 1.1146  decode.d1.loss_cls: 1.0979  decode.d1.loss_mask: 0.6927  decode.d1.loss_dice: 1.0439  decode.d2.loss_cls: 1.0992  decode.d2.loss_mask: 0.6980  decode.d2.loss_dice: 0.9600  decode.d3.loss_cls: 1.0139  decode.d3.loss_mask: 0.7060  decode.d3.loss_dice: 0.9349  decode.d4.loss_cls: 1.0013  decode.d4.loss_mask: 0.6849  decode.d4.loss_dice: 0.9294  decode.d5.loss_cls: 0.9830  decode.d5.loss_mask: 0.7024  decode.d5.loss_dice: 0.9183  decode.d6.loss_cls: 0.9958  decode.d6.loss_mask: 0.6323  decode.d6.loss_dice: 0.9017  decode.d7.loss_cls: 0.9631  decode.d7.loss_mask: 0.6498  decode.d7.loss_dice: 0.9090  decode.d8.loss_cls: 0.9691  decode.d8.loss_mask: 0.6616  decode.d8.loss_dice: 0.9414
2023/05/24 09:39:40 - mmengine - INFO - Iter(train) [124250/160000]  lr: 2.5956e-06  eta: 4:17:49  time: 0.4776  data_time: 0.0096  memory: 4894  grad_norm: 96.6152  loss: 28.9592  decode.loss_cls: 0.8383  decode.loss_mask: 0.7262  decode.loss_dice: 1.0200  decode.d0.loss_cls: 3.0367  decode.d0.loss_mask: 0.7579  decode.d0.loss_dice: 1.1421  decode.d1.loss_cls: 0.9775  decode.d1.loss_mask: 0.7500  decode.d1.loss_dice: 1.1729  decode.d2.loss_cls: 0.8701  decode.d2.loss_mask: 0.7537  decode.d2.loss_dice: 1.1333  decode.d3.loss_cls: 0.8629  decode.d3.loss_mask: 0.7260  decode.d3.loss_dice: 1.0608  decode.d4.loss_cls: 0.8351  decode.d4.loss_mask: 0.7284  decode.d4.loss_dice: 1.0987  decode.d5.loss_cls: 0.7971  decode.d5.loss_mask: 0.7514  decode.d5.loss_dice: 1.0931  decode.d6.loss_cls: 0.8412  decode.d6.loss_mask: 0.7278  decode.d6.loss_dice: 1.0416  decode.d7.loss_cls: 0.8412  decode.d7.loss_mask: 0.7149  decode.d7.loss_dice: 1.0474  decode.d8.loss_cls: 0.8310  decode.d8.loss_mask: 0.7293  decode.d8.loss_dice: 1.0527
2023/05/24 09:40:02 - mmengine - INFO - Iter(train) [124300/160000]  lr: 2.5924e-06  eta: 4:17:27  time: 0.4330  data_time: 0.0099  memory: 4936  grad_norm: 106.4743  loss: 39.8100  decode.loss_cls: 1.3950  decode.loss_mask: 0.9282  decode.loss_dice: 1.3512  decode.d0.loss_cls: 3.4030  decode.d0.loss_mask: 0.9798  decode.d0.loss_dice: 1.6221  decode.d1.loss_cls: 1.5436  decode.d1.loss_mask: 0.9478  decode.d1.loss_dice: 1.5040  decode.d2.loss_cls: 1.5380  decode.d2.loss_mask: 0.9373  decode.d2.loss_dice: 1.4395  decode.d3.loss_cls: 1.4649  decode.d3.loss_mask: 0.9193  decode.d3.loss_dice: 1.3769  decode.d4.loss_cls: 1.4092  decode.d4.loss_mask: 0.9303  decode.d4.loss_dice: 1.3935  decode.d5.loss_cls: 1.4047  decode.d5.loss_mask: 0.9264  decode.d5.loss_dice: 1.3920  decode.d6.loss_cls: 1.3760  decode.d6.loss_mask: 0.9263  decode.d6.loss_dice: 1.3689  decode.d7.loss_cls: 1.3817  decode.d7.loss_mask: 0.9487  decode.d7.loss_dice: 1.3447  decode.d8.loss_cls: 1.3702  decode.d8.loss_mask: 0.9266  decode.d8.loss_dice: 1.3603
2023/05/24 09:40:24 - mmengine - INFO - Iter(train) [124350/160000]  lr: 2.5891e-06  eta: 4:17:06  time: 0.4213  data_time: 0.0105  memory: 4802  grad_norm: 86.1127  loss: 34.9543  decode.loss_cls: 1.1648  decode.loss_mask: 0.7330  decode.loss_dice: 1.3590  decode.d0.loss_cls: 2.9629  decode.d0.loss_mask: 0.6772  decode.d0.loss_dice: 1.4139  decode.d1.loss_cls: 1.3549  decode.d1.loss_mask: 0.7527  decode.d1.loss_dice: 1.3913  decode.d2.loss_cls: 1.3076  decode.d2.loss_mask: 0.7412  decode.d2.loss_dice: 1.3929  decode.d3.loss_cls: 1.2264  decode.d3.loss_mask: 0.7106  decode.d3.loss_dice: 1.3584  decode.d4.loss_cls: 1.1806  decode.d4.loss_mask: 0.7141  decode.d4.loss_dice: 1.3681  decode.d5.loss_cls: 1.2324  decode.d5.loss_mask: 0.7258  decode.d5.loss_dice: 1.3556  decode.d6.loss_cls: 1.1846  decode.d6.loss_mask: 0.7310  decode.d6.loss_dice: 1.3535  decode.d7.loss_cls: 1.1854  decode.d7.loss_mask: 0.7355  decode.d7.loss_dice: 1.3425  decode.d8.loss_cls: 1.2347  decode.d8.loss_mask: 0.7285  decode.d8.loss_dice: 1.3350
2023/05/24 09:40:45 - mmengine - INFO - Iter(train) [124400/160000]  lr: 2.5858e-06  eta: 4:16:44  time: 0.4198  data_time: 0.0099  memory: 4866  grad_norm: 85.9003  loss: 33.1100  decode.loss_cls: 1.2770  decode.loss_mask: 0.7498  decode.loss_dice: 1.0180  decode.d0.loss_cls: 3.1505  decode.d0.loss_mask: 0.8035  decode.d0.loss_dice: 1.2701  decode.d1.loss_cls: 1.2677  decode.d1.loss_mask: 0.8266  decode.d1.loss_dice: 1.1612  decode.d2.loss_cls: 1.2387  decode.d2.loss_mask: 0.8259  decode.d2.loss_dice: 1.0839  decode.d3.loss_cls: 1.2684  decode.d3.loss_mask: 0.8103  decode.d3.loss_dice: 1.0573  decode.d4.loss_cls: 1.2688  decode.d4.loss_mask: 0.7816  decode.d4.loss_dice: 1.0760  decode.d5.loss_cls: 1.2419  decode.d5.loss_mask: 0.8140  decode.d5.loss_dice: 1.0459  decode.d6.loss_cls: 1.2703  decode.d6.loss_mask: 0.7567  decode.d6.loss_dice: 1.0366  decode.d7.loss_cls: 1.2585  decode.d7.loss_mask: 0.7373  decode.d7.loss_dice: 1.0100  decode.d8.loss_cls: 1.2499  decode.d8.loss_mask: 0.7409  decode.d8.loss_dice: 1.0125
2023/05/24 09:41:07 - mmengine - INFO - Iter(train) [124450/160000]  lr: 2.5826e-06  eta: 4:16:22  time: 0.4267  data_time: 0.0098  memory: 4821  grad_norm: 86.6998  loss: 36.5855  decode.loss_cls: 1.2310  decode.loss_mask: 0.7224  decode.loss_dice: 1.3646  decode.d0.loss_cls: 3.2950  decode.d0.loss_mask: 0.7931  decode.d0.loss_dice: 1.5771  decode.d1.loss_cls: 1.4863  decode.d1.loss_mask: 0.7648  decode.d1.loss_dice: 1.4593  decode.d2.loss_cls: 1.2743  decode.d2.loss_mask: 0.7765  decode.d2.loss_dice: 1.4500  decode.d3.loss_cls: 1.2735  decode.d3.loss_mask: 0.7664  decode.d3.loss_dice: 1.4169  decode.d4.loss_cls: 1.3013  decode.d4.loss_mask: 0.7424  decode.d4.loss_dice: 1.4048  decode.d5.loss_cls: 1.2804  decode.d5.loss_mask: 0.7426  decode.d5.loss_dice: 1.4163  decode.d6.loss_cls: 1.2136  decode.d6.loss_mask: 0.7451  decode.d6.loss_dice: 1.3981  decode.d7.loss_cls: 1.2580  decode.d7.loss_mask: 0.7259  decode.d7.loss_dice: 1.3780  decode.d8.loss_cls: 1.2147  decode.d8.loss_mask: 0.7332  decode.d8.loss_dice: 1.3798
2023/05/24 09:41:29 - mmengine - INFO - Iter(train) [124500/160000]  lr: 2.5793e-06  eta: 4:16:01  time: 0.4207  data_time: 0.0103  memory: 4829  grad_norm: 90.8039  loss: 35.1475  decode.loss_cls: 1.1315  decode.loss_mask: 0.7971  decode.loss_dice: 1.3137  decode.d0.loss_cls: 3.1999  decode.d0.loss_mask: 0.8135  decode.d0.loss_dice: 1.5394  decode.d1.loss_cls: 1.1689  decode.d1.loss_mask: 0.8313  decode.d1.loss_dice: 1.4255  decode.d2.loss_cls: 1.1863  decode.d2.loss_mask: 0.8521  decode.d2.loss_dice: 1.4001  decode.d3.loss_cls: 1.2309  decode.d3.loss_mask: 0.7677  decode.d3.loss_dice: 1.3027  decode.d4.loss_cls: 1.1655  decode.d4.loss_mask: 0.7907  decode.d4.loss_dice: 1.3195  decode.d5.loss_cls: 1.1380  decode.d5.loss_mask: 0.8131  decode.d5.loss_dice: 1.3080  decode.d6.loss_cls: 1.1012  decode.d6.loss_mask: 0.7963  decode.d6.loss_dice: 1.3198  decode.d7.loss_cls: 1.1002  decode.d7.loss_mask: 0.7999  decode.d7.loss_dice: 1.3134  decode.d8.loss_cls: 1.1158  decode.d8.loss_mask: 0.7983  decode.d8.loss_dice: 1.3072
2023/05/24 09:41:50 - mmengine - INFO - Iter(train) [124550/160000]  lr: 2.5760e-06  eta: 4:15:39  time: 0.4161  data_time: 0.0100  memory: 4855  grad_norm: 89.7930  loss: 31.2495  decode.loss_cls: 1.0144  decode.loss_mask: 0.7220  decode.loss_dice: 1.0809  decode.d0.loss_cls: 3.0616  decode.d0.loss_mask: 0.8054  decode.d0.loss_dice: 1.2545  decode.d1.loss_cls: 1.2087  decode.d1.loss_mask: 0.7977  decode.d1.loss_dice: 1.1789  decode.d2.loss_cls: 1.0894  decode.d2.loss_mask: 0.7400  decode.d2.loss_dice: 1.1530  decode.d3.loss_cls: 1.0622  decode.d3.loss_mask: 0.7433  decode.d3.loss_dice: 1.0974  decode.d4.loss_cls: 1.0148  decode.d4.loss_mask: 0.7481  decode.d4.loss_dice: 1.1112  decode.d5.loss_cls: 1.0083  decode.d5.loss_mask: 0.7359  decode.d5.loss_dice: 1.0932  decode.d6.loss_cls: 1.0153  decode.d6.loss_mask: 0.7347  decode.d6.loss_dice: 1.1010  decode.d7.loss_cls: 1.0275  decode.d7.loss_mask: 0.7282  decode.d7.loss_dice: 1.1007  decode.d8.loss_cls: 0.9768  decode.d8.loss_mask: 0.7407  decode.d8.loss_dice: 1.1037
2023/05/24 09:42:11 - mmengine - INFO - Iter(train) [124600/160000]  lr: 2.5727e-06  eta: 4:15:17  time: 0.4262  data_time: 0.0095  memory: 4835  grad_norm: 90.3624  loss: 33.4819  decode.loss_cls: 1.1269  decode.loss_mask: 0.6252  decode.loss_dice: 1.3269  decode.d0.loss_cls: 3.2331  decode.d0.loss_mask: 0.6098  decode.d0.loss_dice: 1.4721  decode.d1.loss_cls: 1.2584  decode.d1.loss_mask: 0.6492  decode.d1.loss_dice: 1.4366  decode.d2.loss_cls: 1.1772  decode.d2.loss_mask: 0.6405  decode.d2.loss_dice: 1.3962  decode.d3.loss_cls: 1.1610  decode.d3.loss_mask: 0.6198  decode.d3.loss_dice: 1.3313  decode.d4.loss_cls: 1.1281  decode.d4.loss_mask: 0.6258  decode.d4.loss_dice: 1.3469  decode.d5.loss_cls: 1.1283  decode.d5.loss_mask: 0.6240  decode.d5.loss_dice: 1.3399  decode.d6.loss_cls: 1.1337  decode.d6.loss_mask: 0.6153  decode.d6.loss_dice: 1.3369  decode.d7.loss_cls: 1.1286  decode.d7.loss_mask: 0.6130  decode.d7.loss_dice: 1.3108  decode.d8.loss_cls: 1.1153  decode.d8.loss_mask: 0.6209  decode.d8.loss_dice: 1.3502
2023/05/24 09:42:32 - mmengine - INFO - Iter(train) [124650/160000]  lr: 2.5695e-06  eta: 4:14:56  time: 0.4276  data_time: 0.0102  memory: 4910  grad_norm: 92.9023  loss: 44.7551  decode.loss_cls: 1.6365  decode.loss_mask: 0.9831  decode.loss_dice: 1.5269  decode.d0.loss_cls: 3.7666  decode.d0.loss_mask: 0.9286  decode.d0.loss_dice: 1.8497  decode.d1.loss_cls: 1.7592  decode.d1.loss_mask: 0.9993  decode.d1.loss_dice: 1.7003  decode.d2.loss_cls: 1.7583  decode.d2.loss_mask: 0.9908  decode.d2.loss_dice: 1.6467  decode.d3.loss_cls: 1.6590  decode.d3.loss_mask: 1.0151  decode.d3.loss_dice: 1.5936  decode.d4.loss_cls: 1.6746  decode.d4.loss_mask: 0.9629  decode.d4.loss_dice: 1.5812  decode.d5.loss_cls: 1.6030  decode.d5.loss_mask: 0.9792  decode.d5.loss_dice: 1.5840  decode.d6.loss_cls: 1.6253  decode.d6.loss_mask: 0.9839  decode.d6.loss_dice: 1.5817  decode.d7.loss_cls: 1.5763  decode.d7.loss_mask: 1.0136  decode.d7.loss_dice: 1.6127  decode.d8.loss_cls: 1.6245  decode.d8.loss_mask: 0.9709  decode.d8.loss_dice: 1.5676
2023/05/24 09:42:53 - mmengine - INFO - Iter(train) [124700/160000]  lr: 2.5662e-06  eta: 4:14:34  time: 0.4139  data_time: 0.0098  memory: 4857  grad_norm: 89.6237  loss: 42.2237  decode.loss_cls: 1.3983  decode.loss_mask: 0.9648  decode.loss_dice: 1.5954  decode.d0.loss_cls: 3.3120  decode.d0.loss_mask: 1.0124  decode.d0.loss_dice: 1.8614  decode.d1.loss_cls: 1.4002  decode.d1.loss_mask: 1.0442  decode.d1.loss_dice: 1.7161  decode.d2.loss_cls: 1.4139  decode.d2.loss_mask: 1.0095  decode.d2.loss_dice: 1.6457  decode.d3.loss_cls: 1.4661  decode.d3.loss_mask: 0.9665  decode.d3.loss_dice: 1.5766  decode.d4.loss_cls: 1.4232  decode.d4.loss_mask: 0.9770  decode.d4.loss_dice: 1.5436  decode.d5.loss_cls: 1.3911  decode.d5.loss_mask: 1.0025  decode.d5.loss_dice: 1.5842  decode.d6.loss_cls: 1.4537  decode.d6.loss_mask: 0.9795  decode.d6.loss_dice: 1.5896  decode.d7.loss_cls: 1.3939  decode.d7.loss_mask: 0.9906  decode.d7.loss_dice: 1.5840  decode.d8.loss_cls: 1.3780  decode.d8.loss_mask: 0.9714  decode.d8.loss_dice: 1.5781
2023/05/24 09:43:15 - mmengine - INFO - Iter(train) [124750/160000]  lr: 2.5629e-06  eta: 4:14:12  time: 0.4226  data_time: 0.0100  memory: 4821  grad_norm: 101.3687  loss: 34.4692  decode.loss_cls: 1.2459  decode.loss_mask: 0.7012  decode.loss_dice: 1.2042  decode.d0.loss_cls: 3.1090  decode.d0.loss_mask: 0.7298  decode.d0.loss_dice: 1.4100  decode.d1.loss_cls: 1.5067  decode.d1.loss_mask: 0.6744  decode.d1.loss_dice: 1.2888  decode.d2.loss_cls: 1.3683  decode.d2.loss_mask: 0.6713  decode.d2.loss_dice: 1.2470  decode.d3.loss_cls: 1.3380  decode.d3.loss_mask: 0.7067  decode.d3.loss_dice: 1.2689  decode.d4.loss_cls: 1.3451  decode.d4.loss_mask: 0.6614  decode.d4.loss_dice: 1.2212  decode.d5.loss_cls: 1.2757  decode.d5.loss_mask: 0.6655  decode.d5.loss_dice: 1.2198  decode.d6.loss_cls: 1.3087  decode.d6.loss_mask: 0.7019  decode.d6.loss_dice: 1.2311  decode.d7.loss_cls: 1.2969  decode.d7.loss_mask: 0.6833  decode.d7.loss_dice: 1.2264  decode.d8.loss_cls: 1.2453  decode.d8.loss_mask: 0.7022  decode.d8.loss_dice: 1.2146
2023/05/24 09:43:36 - mmengine - INFO - Iter(train) [124800/160000]  lr: 2.5597e-06  eta: 4:13:50  time: 0.4211  data_time: 0.0098  memory: 4874  grad_norm: 87.4160  loss: 36.6442  decode.loss_cls: 1.1561  decode.loss_mask: 0.8350  decode.loss_dice: 1.3377  decode.d0.loss_cls: 3.0835  decode.d0.loss_mask: 0.8703  decode.d0.loss_dice: 1.6634  decode.d1.loss_cls: 1.4460  decode.d1.loss_mask: 0.8271  decode.d1.loss_dice: 1.4804  decode.d2.loss_cls: 1.3018  decode.d2.loss_mask: 0.8258  decode.d2.loss_dice: 1.4105  decode.d3.loss_cls: 1.1974  decode.d3.loss_mask: 0.8538  decode.d3.loss_dice: 1.3483  decode.d4.loss_cls: 1.2458  decode.d4.loss_mask: 0.8488  decode.d4.loss_dice: 1.3609  decode.d5.loss_cls: 1.2227  decode.d5.loss_mask: 0.8354  decode.d5.loss_dice: 1.3389  decode.d6.loss_cls: 1.1866  decode.d6.loss_mask: 0.8418  decode.d6.loss_dice: 1.3434  decode.d7.loss_cls: 1.1898  decode.d7.loss_mask: 0.8362  decode.d7.loss_dice: 1.3689  decode.d8.loss_cls: 1.1990  decode.d8.loss_mask: 0.8317  decode.d8.loss_dice: 1.3572
2023/05/24 09:43:57 - mmengine - INFO - Iter(train) [124850/160000]  lr: 2.5564e-06  eta: 4:13:29  time: 0.4205  data_time: 0.0102  memory: 4885  grad_norm: 78.5202  loss: 37.6380  decode.loss_cls: 1.1671  decode.loss_mask: 0.8022  decode.loss_dice: 1.5450  decode.d0.loss_cls: 3.2808  decode.d0.loss_mask: 0.8235  decode.d0.loss_dice: 1.7592  decode.d1.loss_cls: 1.2720  decode.d1.loss_mask: 0.8583  decode.d1.loss_dice: 1.6945  decode.d2.loss_cls: 1.2275  decode.d2.loss_mask: 0.7913  decode.d2.loss_dice: 1.5754  decode.d3.loss_cls: 1.1285  decode.d3.loss_mask: 0.8029  decode.d3.loss_dice: 1.5632  decode.d4.loss_cls: 1.1923  decode.d4.loss_mask: 0.7758  decode.d4.loss_dice: 1.4838  decode.d5.loss_cls: 1.1743  decode.d5.loss_mask: 0.7653  decode.d5.loss_dice: 1.5126  decode.d6.loss_cls: 1.1547  decode.d6.loss_mask: 0.7947  decode.d6.loss_dice: 1.5556  decode.d7.loss_cls: 1.1103  decode.d7.loss_mask: 0.7850  decode.d7.loss_dice: 1.5195  decode.d8.loss_cls: 1.1434  decode.d8.loss_mask: 0.8047  decode.d8.loss_dice: 1.5746
2023/05/24 09:44:19 - mmengine - INFO - Iter(train) [124900/160000]  lr: 2.5531e-06  eta: 4:13:07  time: 0.4190  data_time: 0.0102  memory: 4961  grad_norm: 111.1865  loss: 34.4022  decode.loss_cls: 1.4352  decode.loss_mask: 0.6607  decode.loss_dice: 1.0620  decode.d0.loss_cls: 3.2557  decode.d0.loss_mask: 0.7895  decode.d0.loss_dice: 1.2884  decode.d1.loss_cls: 1.6242  decode.d1.loss_mask: 0.7153  decode.d1.loss_dice: 1.1344  decode.d2.loss_cls: 1.4283  decode.d2.loss_mask: 0.7335  decode.d2.loss_dice: 1.0911  decode.d3.loss_cls: 1.5029  decode.d3.loss_mask: 0.6786  decode.d3.loss_dice: 1.0727  decode.d4.loss_cls: 1.4223  decode.d4.loss_mask: 0.7010  decode.d4.loss_dice: 1.0777  decode.d5.loss_cls: 1.4421  decode.d5.loss_mask: 0.7092  decode.d5.loss_dice: 1.0764  decode.d6.loss_cls: 1.4271  decode.d6.loss_mask: 0.6933  decode.d6.loss_dice: 1.0423  decode.d7.loss_cls: 1.4823  decode.d7.loss_mask: 0.6676  decode.d7.loss_dice: 1.0290  decode.d8.loss_cls: 1.4483  decode.d8.loss_mask: 0.6581  decode.d8.loss_dice: 1.0530
2023/05/24 09:44:40 - mmengine - INFO - Iter(train) [124950/160000]  lr: 2.5498e-06  eta: 4:12:45  time: 0.4379  data_time: 0.0108  memory: 4844  grad_norm: 89.4479  loss: 44.8844  decode.loss_cls: 1.4919  decode.loss_mask: 0.9779  decode.loss_dice: 1.7207  decode.d0.loss_cls: 3.5012  decode.d0.loss_mask: 1.0351  decode.d0.loss_dice: 1.9858  decode.d1.loss_cls: 1.6175  decode.d1.loss_mask: 0.9963  decode.d1.loss_dice: 1.8959  decode.d2.loss_cls: 1.5551  decode.d2.loss_mask: 1.0348  decode.d2.loss_dice: 1.7955  decode.d3.loss_cls: 1.5843  decode.d3.loss_mask: 0.9741  decode.d3.loss_dice: 1.7213  decode.d4.loss_cls: 1.5676  decode.d4.loss_mask: 1.0119  decode.d4.loss_dice: 1.6721  decode.d5.loss_cls: 1.5544  decode.d5.loss_mask: 0.9913  decode.d5.loss_dice: 1.6836  decode.d6.loss_cls: 1.5460  decode.d6.loss_mask: 0.9421  decode.d6.loss_dice: 1.6920  decode.d7.loss_cls: 1.5395  decode.d7.loss_mask: 0.9417  decode.d7.loss_dice: 1.6894  decode.d8.loss_cls: 1.4922  decode.d8.loss_mask: 0.9611  decode.d8.loss_dice: 1.7121
2023/05/24 09:45:02 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 09:45:02 - mmengine - INFO - Iter(train) [125000/160000]  lr: 2.5466e-06  eta: 4:12:23  time: 0.4219  data_time: 0.0105  memory: 4862  grad_norm: 86.2588  loss: 38.4893  decode.loss_cls: 1.0425  decode.loss_mask: 0.7459  decode.loss_dice: 1.7080  decode.d0.loss_cls: 3.4958  decode.d0.loss_mask: 0.7971  decode.d0.loss_dice: 1.9317  decode.d1.loss_cls: 1.2554  decode.d1.loss_mask: 0.7651  decode.d1.loss_dice: 1.7997  decode.d2.loss_cls: 1.2229  decode.d2.loss_mask: 0.7253  decode.d2.loss_dice: 1.7390  decode.d3.loss_cls: 1.1046  decode.d3.loss_mask: 0.7527  decode.d3.loss_dice: 1.7426  decode.d4.loss_cls: 1.1313  decode.d4.loss_mask: 0.6973  decode.d4.loss_dice: 1.6931  decode.d5.loss_cls: 1.0660  decode.d5.loss_mask: 0.7356  decode.d5.loss_dice: 1.7310  decode.d6.loss_cls: 1.0751  decode.d6.loss_mask: 0.7460  decode.d6.loss_dice: 1.7057  decode.d7.loss_cls: 1.0676  decode.d7.loss_mask: 0.7441  decode.d7.loss_dice: 1.7281  decode.d8.loss_cls: 1.0457  decode.d8.loss_mask: 0.7481  decode.d8.loss_dice: 1.7464
2023/05/24 09:45:02 - mmengine - INFO - Saving checkpoint at 125000 iterations
2023/05/24 09:45:12 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:45  time: 0.0767  data_time: 0.0018  memory: 2167  
2023/05/24 09:45:16 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:41  time: 0.0791  data_time: 0.0019  memory: 2216  
2023/05/24 09:45:20 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:37  time: 0.0844  data_time: 0.0018  memory: 2167  
2023/05/24 09:45:24 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:34  time: 0.0970  data_time: 0.0020  memory: 2104  
2023/05/24 09:45:28 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0788  data_time: 0.0020  memory: 2831  
2023/05/24 09:45:32 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0798  data_time: 0.0018  memory: 2167  
2023/05/24 09:45:36 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0878  data_time: 0.0018  memory: 2167  
2023/05/24 09:45:43 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.1024  data_time: 0.0021  memory: 2167  
2023/05/24 09:45:47 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0903  data_time: 0.0020  memory: 2944  
2023/05/24 09:45:51 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0807  data_time: 0.0019  memory: 2356  
2023/05/24 09:45:56 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0811  data_time: 0.0019  memory: 2217  
2023/05/24 09:46:00 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0782  data_time: 0.0018  memory: 2328  
2023/05/24 09:46:03 - mmengine - INFO - per class results:
2023/05/24 09:46:03 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.28 | 92.99 |
|     bicycle      | 70.65 | 83.87 |
|       car        | 62.48 | 86.78 |
|    motorcycle    | 83.17 | 90.49 |
|     airplane     | 84.05 | 94.12 |
|       bus        | 83.08 |  87.6 |
|      train       |  84.6 | 93.71 |
|      truck       | 56.47 | 73.91 |
|       boat       | 59.41 | 76.54 |
|  traffic light   | 68.66 | 85.39 |
|   fire hydrant   | 87.96 | 94.85 |
|    stop sign     | 90.56 | 96.87 |
|  parking meter   | 76.46 | 86.47 |
|      bench       | 48.87 | 70.56 |
|       bird       | 81.09 |  91.2 |
|       cat        | 86.76 |  92.7 |
|       dog        | 79.71 | 87.27 |
|      horse       |  78.7 |  90.8 |
|      sheep       |  86.6 | 93.05 |
|       cow        | 82.92 | 88.79 |
|     elephant     | 89.45 | 94.97 |
|       bear       | 92.37 | 95.16 |
|      zebra       |  90.0 | 93.41 |
|     giraffe      | 87.45 | 93.49 |
|     backpack     | 33.31 |  66.0 |
|     umbrella     | 82.59 | 87.98 |
|     handbag      | 33.13 | 54.71 |
|       tie        | 15.58 |  29.5 |
|     suitcase     | 77.01 | 89.98 |
|     frisbee      |  66.7 | 92.23 |
|       skis       | 47.56 | 67.27 |
|    snowboard     | 61.25 | 73.52 |
|   sports ball    | 53.95 | 74.69 |
|       kite       |  60.9 |  72.5 |
|   baseball bat   | 52.75 | 69.64 |
|  baseball glove  | 70.73 | 89.66 |
|    skateboard    | 74.99 | 85.62 |
|    surfboard     | 72.13 | 87.29 |
|  tennis racket   | 85.68 | 92.19 |
|      bottle      | 40.29 | 53.26 |
|    wine glass    | 56.83 | 77.29 |
|       cup        | 51.27 | 72.46 |
|       fork       |  37.9 | 48.09 |
|      knife       |  31.4 | 46.63 |
|      spoon       | 36.01 |  61.7 |
|       bowl       | 46.38 | 64.84 |
|      banana      | 66.62 | 89.65 |
|      apple       | 51.03 | 73.18 |
|     sandwich     | 43.25 | 56.35 |
|      orange      |  64.1 | 74.84 |
|     broccoli     | 58.25 | 70.71 |
|      carrot      | 52.32 | 60.78 |
|     hot dog      | 50.62 | 60.07 |
|      pizza       | 68.24 | 84.78 |
|      donut       |  69.3 | 83.89 |
|       cake       | 60.27 | 70.56 |
|      chair       | 46.93 | 68.15 |
|      couch       |  56.0 | 76.98 |
|   potted plant   | 32.02 | 45.66 |
|       bed        | 63.66 | 78.63 |
|   dining table   | 44.55 | 77.38 |
|      toilet      | 82.27 | 92.21 |
|        tv        | 73.27 | 88.11 |
|      laptop      | 74.41 | 89.17 |
|      mouse       | 72.75 | 89.65 |
|      remote      | 57.45 | 73.89 |
|     keyboard     | 63.33 | 74.34 |
|    cell phone    | 69.05 |  90.5 |
|    microwave     | 65.66 | 76.55 |
|       oven       | 57.41 | 76.04 |
|     toaster      | 39.53 | 52.62 |
|       sink       | 56.01 | 81.72 |
|   refrigerator   |  79.1 | 92.44 |
|       book       | 46.75 | 69.05 |
|      clock       | 70.63 | 85.43 |
|       vase       | 56.27 | 82.83 |
|     scissors     | 78.81 | 91.95 |
|    teddy bear    | 74.87 | 85.41 |
|    hair drier    | 40.48 | 55.09 |
|    toothbrush    | 37.61 | 78.65 |
|      banner      | 33.77 | 65.85 |
|     blanket      |  2.07 |  2.22 |
|      branch      | 20.82 |  37.1 |
|      bridge      | 32.91 | 43.58 |
|  building-other  | 53.34 | 74.57 |
|       bush       | 28.74 | 36.37 |
|     cabinet      |  54.3 | 69.58 |
|       cage       | 19.72 | 35.24 |
|    cardboard     | 45.26 | 54.92 |
|      carpet      | 53.69 | 72.29 |
|  ceiling-other   | 64.09 | 76.47 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 21.24 | 34.15 |
|      clouds      | 46.82 | 60.94 |
|     counter      | 28.34 | 47.46 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      |  65.5 | 78.98 |
|    desk-stuff    | 45.03 |  61.5 |
|       dirt       |  40.9 | 66.64 |
|    door-stuff    | 40.12 | 61.95 |
|      fence       | 29.26 | 50.72 |
|   floor-marble   |  1.72 |  1.91 |
|   floor-other    | 24.37 | 40.06 |
|   floor-stone    |  1.03 |  1.12 |
|    floor-tile    |  60.4 | 69.15 |
|    floor-wood    | 62.98 | 77.97 |
|      flower      | 44.13 | 67.29 |
|       fog        |  5.13 |  5.32 |
|    food-other    | 29.02 | 36.26 |
|      fruit       | 41.01 | 60.38 |
| furniture-other  | 17.82 | 25.81 |
|      grass       | 70.41 | 82.16 |
|      gravel      | 26.04 | 34.31 |
|   ground-other   |  6.06 |  8.9  |
|       hill       | 21.33 | 29.81 |
|      house       | 24.58 | 29.86 |
|      leaves      | 25.97 | 38.13 |
|      light       | 38.02 | 53.77 |
|       mat        |  0.0  |  0.0  |
|      metal       | 30.59 | 41.56 |
|   mirror-stuff   | 49.19 | 78.54 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 54.21 | 70.73 |
|       mud        |  6.22 |  7.25 |
|      napkin      |  5.2  |  5.2  |
|       net        |  41.2 | 64.77 |
|      paper       | 30.81 | 43.48 |
|     pavement     | 51.15 | 69.74 |
|      pillow      | 14.42 | 23.31 |
|   plant-other    | 19.12 |  37.1 |
|     plastic      |  20.8 | 28.11 |
|     platform     |  27.6 | 43.14 |
|   playingfield   |  70.4 | 91.04 |
|     railing      |  4.1  |  5.3  |
|     railroad     | 60.16 | 77.55 |
|      river       | 45.69 |  57.8 |
|       road       | 65.24 | 78.46 |
|       rock       |  39.7 |  60.2 |
|       roof       | 15.44 | 19.01 |
|       rug        | 32.01 | 45.19 |
|      salad       |  0.0  |  0.0  |
|       sand       | 60.84 | 67.16 |
|       sea        | 85.11 | 91.55 |
|      shelf       | 34.56 | 49.95 |
|    sky-other     | 70.43 | 87.55 |
|    skyscraper    | 32.01 | 40.65 |
|       snow       |  88.8 | 93.36 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 25.22 | 43.05 |
|      stone       |  9.99 |  16.6 |
|      straw       | 36.54 | 53.66 |
| structural-other |  0.0  |  0.0  |
|      table       | 18.91 | 25.32 |
|       tent       |  6.21 |  8.22 |
|  textile-other   | 13.84 | 25.13 |
|      towel       | 33.71 | 41.99 |
|       tree       | 73.82 | 84.94 |
|    vegetable     | 37.58 | 46.07 |
|    wall-brick    | 47.47 |  65.9 |
|  wall-concrete   | 60.83 |  80.0 |
|    wall-other    | 18.82 | 28.76 |
|    wall-panel    |  5.91 |  7.39 |
|    wall-stone    | 31.94 | 36.55 |
|    wall-tile     | 66.58 | 83.92 |
|    wall-wood     |  40.4 | 56.56 |
|   water-other    | 24.72 |  42.2 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 48.67 | 56.41 |
|   window-other   | 46.17 |  73.2 |
|       wood       | 24.49 | 40.93 |
+------------------+-------+-------+
2023/05/24 09:46:03 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.2000  mIoU: 47.1400  mAcc: 60.1000  data_time: 0.0021  time: 0.0858
2023/05/24 09:46:03 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_100000.pth is removed
2023/05/24 09:46:07 - mmengine - INFO - The best checkpoint with 47.1400 mIoU at 125000 iter is saved to best_mIoU_iter_125000.pth.
2023/05/24 09:46:28 - mmengine - INFO - Iter(train) [125050/160000]  lr: 2.5433e-06  eta: 4:12:03  time: 0.4250  data_time: 0.0106  memory: 4879  grad_norm: 82.9220  loss: 35.2368  decode.loss_cls: 1.2422  decode.loss_mask: 0.7568  decode.loss_dice: 1.1967  decode.d0.loss_cls: 3.1582  decode.d0.loss_mask: 0.8509  decode.d0.loss_dice: 1.5466  decode.d1.loss_cls: 1.4334  decode.d1.loss_mask: 0.8154  decode.d1.loss_dice: 1.3495  decode.d2.loss_cls: 1.3168  decode.d2.loss_mask: 0.7843  decode.d2.loss_dice: 1.2861  decode.d3.loss_cls: 1.3036  decode.d3.loss_mask: 0.7778  decode.d3.loss_dice: 1.2350  decode.d4.loss_cls: 1.2897  decode.d4.loss_mask: 0.7867  decode.d4.loss_dice: 1.2312  decode.d5.loss_cls: 1.2385  decode.d5.loss_mask: 0.7657  decode.d5.loss_dice: 1.2370  decode.d6.loss_cls: 1.2902  decode.d6.loss_mask: 0.7485  decode.d6.loss_dice: 1.1900  decode.d7.loss_cls: 1.2394  decode.d7.loss_mask: 0.7542  decode.d7.loss_dice: 1.2062  decode.d8.loss_cls: 1.2345  decode.d8.loss_mask: 0.7610  decode.d8.loss_dice: 1.2107
2023/05/24 09:46:50 - mmengine - INFO - Iter(train) [125100/160000]  lr: 2.5400e-06  eta: 4:11:42  time: 0.4191  data_time: 0.0104  memory: 4846  grad_norm: 102.0622  loss: 41.1484  decode.loss_cls: 1.2197  decode.loss_mask: 0.8573  decode.loss_dice: 1.7429  decode.d0.loss_cls: 3.2023  decode.d0.loss_mask: 0.9201  decode.d0.loss_dice: 2.0192  decode.d1.loss_cls: 1.2323  decode.d1.loss_mask: 0.9095  decode.d1.loss_dice: 1.9692  decode.d2.loss_cls: 1.2556  decode.d2.loss_mask: 0.8962  decode.d2.loss_dice: 1.8702  decode.d3.loss_cls: 1.2089  decode.d3.loss_mask: 0.8827  decode.d3.loss_dice: 1.7915  decode.d4.loss_cls: 1.2825  decode.d4.loss_mask: 0.8182  decode.d4.loss_dice: 1.7765  decode.d5.loss_cls: 1.2074  decode.d5.loss_mask: 0.8760  decode.d5.loss_dice: 1.7816  decode.d6.loss_cls: 1.2400  decode.d6.loss_mask: 0.8464  decode.d6.loss_dice: 1.7150  decode.d7.loss_cls: 1.2136  decode.d7.loss_mask: 0.8491  decode.d7.loss_dice: 1.7642  decode.d8.loss_cls: 1.2231  decode.d8.loss_mask: 0.8475  decode.d8.loss_dice: 1.7299
2023/05/24 09:47:12 - mmengine - INFO - Iter(train) [125150/160000]  lr: 2.5367e-06  eta: 4:11:20  time: 0.4821  data_time: 0.0107  memory: 4845  grad_norm: 89.3170  loss: 43.3901  decode.loss_cls: 1.4992  decode.loss_mask: 0.8594  decode.loss_dice: 1.6436  decode.d0.loss_cls: 3.5020  decode.d0.loss_mask: 0.9406  decode.d0.loss_dice: 1.9770  decode.d1.loss_cls: 1.6982  decode.d1.loss_mask: 0.9259  decode.d1.loss_dice: 1.8043  decode.d2.loss_cls: 1.5764  decode.d2.loss_mask: 0.9061  decode.d2.loss_dice: 1.7870  decode.d3.loss_cls: 1.5485  decode.d3.loss_mask: 0.8878  decode.d3.loss_dice: 1.7106  decode.d4.loss_cls: 1.4468  decode.d4.loss_mask: 0.8839  decode.d4.loss_dice: 1.7512  decode.d5.loss_cls: 1.5045  decode.d5.loss_mask: 0.8491  decode.d5.loss_dice: 1.7109  decode.d6.loss_cls: 1.4566  decode.d6.loss_mask: 0.8686  decode.d6.loss_dice: 1.6683  decode.d7.loss_cls: 1.4388  decode.d7.loss_mask: 0.8893  decode.d7.loss_dice: 1.6693  decode.d8.loss_cls: 1.4893  decode.d8.loss_mask: 0.8625  decode.d8.loss_dice: 1.6344
2023/05/24 09:47:36 - mmengine - INFO - Iter(train) [125200/160000]  lr: 2.5335e-06  eta: 4:10:59  time: 0.4779  data_time: 0.0105  memory: 4845  grad_norm: 87.6683  loss: 25.5185  decode.loss_cls: 0.8212  decode.loss_mask: 0.5369  decode.loss_dice: 0.9452  decode.d0.loss_cls: 2.5934  decode.d0.loss_mask: 0.5788  decode.d0.loss_dice: 1.0974  decode.d1.loss_cls: 0.9559  decode.d1.loss_mask: 0.5655  decode.d1.loss_dice: 1.0430  decode.d2.loss_cls: 0.8687  decode.d2.loss_mask: 0.5583  decode.d2.loss_dice: 0.9567  decode.d3.loss_cls: 0.8889  decode.d3.loss_mask: 0.5256  decode.d3.loss_dice: 0.9453  decode.d4.loss_cls: 0.8555  decode.d4.loss_mask: 0.5295  decode.d4.loss_dice: 0.9518  decode.d5.loss_cls: 0.8581  decode.d5.loss_mask: 0.5284  decode.d5.loss_dice: 0.9164  decode.d6.loss_cls: 0.8765  decode.d6.loss_mask: 0.5459  decode.d6.loss_dice: 0.9283  decode.d7.loss_cls: 0.8487  decode.d7.loss_mask: 0.5359  decode.d7.loss_dice: 0.9581  decode.d8.loss_cls: 0.8622  decode.d8.loss_mask: 0.5221  decode.d8.loss_dice: 0.9204
2023/05/24 09:48:00 - mmengine - INFO - Iter(train) [125250/160000]  lr: 2.5302e-06  eta: 4:10:38  time: 0.4747  data_time: 0.0105  memory: 4899  grad_norm: 96.8969  loss: 35.5069  decode.loss_cls: 1.3255  decode.loss_mask: 0.6691  decode.loss_dice: 1.3045  decode.d0.loss_cls: 3.2074  decode.d0.loss_mask: 0.6767  decode.d0.loss_dice: 1.5175  decode.d1.loss_cls: 1.4397  decode.d1.loss_mask: 0.6766  decode.d1.loss_dice: 1.3974  decode.d2.loss_cls: 1.3457  decode.d2.loss_mask: 0.6930  decode.d2.loss_dice: 1.3092  decode.d3.loss_cls: 1.3270  decode.d3.loss_mask: 0.6828  decode.d3.loss_dice: 1.3253  decode.d4.loss_cls: 1.3553  decode.d4.loss_mask: 0.6881  decode.d4.loss_dice: 1.3184  decode.d5.loss_cls: 1.3363  decode.d5.loss_mask: 0.6878  decode.d5.loss_dice: 1.3182  decode.d6.loss_cls: 1.3347  decode.d6.loss_mask: 0.6613  decode.d6.loss_dice: 1.2954  decode.d7.loss_cls: 1.3265  decode.d7.loss_mask: 0.6580  decode.d7.loss_dice: 1.3085  decode.d8.loss_cls: 1.3552  decode.d8.loss_mask: 0.6752  decode.d8.loss_dice: 1.2906
2023/05/24 09:48:22 - mmengine - INFO - Iter(train) [125300/160000]  lr: 2.5269e-06  eta: 4:10:17  time: 0.4256  data_time: 0.0099  memory: 4879  grad_norm: 85.9678  loss: 27.3195  decode.loss_cls: 0.9234  decode.loss_mask: 0.7135  decode.loss_dice: 0.8246  decode.d0.loss_cls: 2.6713  decode.d0.loss_mask: 0.7319  decode.d0.loss_dice: 0.9681  decode.d1.loss_cls: 1.0357  decode.d1.loss_mask: 0.7270  decode.d1.loss_dice: 0.9300  decode.d2.loss_cls: 1.0452  decode.d2.loss_mask: 0.6976  decode.d2.loss_dice: 0.8849  decode.d3.loss_cls: 0.9350  decode.d3.loss_mask: 0.7575  decode.d3.loss_dice: 0.8503  decode.d4.loss_cls: 0.9869  decode.d4.loss_mask: 0.7194  decode.d4.loss_dice: 0.8289  decode.d5.loss_cls: 1.0315  decode.d5.loss_mask: 0.6974  decode.d5.loss_dice: 0.8231  decode.d6.loss_cls: 0.9026  decode.d6.loss_mask: 0.7816  decode.d6.loss_dice: 0.8426  decode.d7.loss_cls: 0.9796  decode.d7.loss_mask: 0.6933  decode.d7.loss_dice: 0.8377  decode.d8.loss_cls: 0.9979  decode.d8.loss_mask: 0.6783  decode.d8.loss_dice: 0.8227
2023/05/24 09:48:44 - mmengine - INFO - Iter(train) [125350/160000]  lr: 2.5236e-06  eta: 4:09:55  time: 0.4283  data_time: 0.0102  memory: 4868  grad_norm: 86.3102  loss: 34.5722  decode.loss_cls: 1.1279  decode.loss_mask: 0.7217  decode.loss_dice: 1.2759  decode.d0.loss_cls: 3.3843  decode.d0.loss_mask: 0.7406  decode.d0.loss_dice: 1.5376  decode.d1.loss_cls: 1.3745  decode.d1.loss_mask: 0.7628  decode.d1.loss_dice: 1.4091  decode.d2.loss_cls: 1.3497  decode.d2.loss_mask: 0.7129  decode.d2.loss_dice: 1.3333  decode.d3.loss_cls: 1.1946  decode.d3.loss_mask: 0.7223  decode.d3.loss_dice: 1.2944  decode.d4.loss_cls: 1.1419  decode.d4.loss_mask: 0.7348  decode.d4.loss_dice: 1.2822  decode.d5.loss_cls: 1.1240  decode.d5.loss_mask: 0.7477  decode.d5.loss_dice: 1.2714  decode.d6.loss_cls: 1.1120  decode.d6.loss_mask: 0.7316  decode.d6.loss_dice: 1.2514  decode.d7.loss_cls: 1.1473  decode.d7.loss_mask: 0.7291  decode.d7.loss_dice: 1.2702  decode.d8.loss_cls: 1.1251  decode.d8.loss_mask: 0.7054  decode.d8.loss_dice: 1.2564
2023/05/24 09:49:05 - mmengine - INFO - Iter(train) [125400/160000]  lr: 2.5204e-06  eta: 4:09:33  time: 0.4257  data_time: 0.0102  memory: 4836  grad_norm: 93.5602  loss: 31.1785  decode.loss_cls: 0.9885  decode.loss_mask: 0.6967  decode.loss_dice: 1.1469  decode.d0.loss_cls: 3.0681  decode.d0.loss_mask: 0.7699  decode.d0.loss_dice: 1.3293  decode.d1.loss_cls: 1.1449  decode.d1.loss_mask: 0.7235  decode.d1.loss_dice: 1.2277  decode.d2.loss_cls: 1.1017  decode.d2.loss_mask: 0.6908  decode.d2.loss_dice: 1.1834  decode.d3.loss_cls: 1.0218  decode.d3.loss_mask: 0.7051  decode.d3.loss_dice: 1.1486  decode.d4.loss_cls: 1.0215  decode.d4.loss_mask: 0.7058  decode.d4.loss_dice: 1.1471  decode.d5.loss_cls: 0.9724  decode.d5.loss_mask: 0.7254  decode.d5.loss_dice: 1.1488  decode.d6.loss_cls: 0.9803  decode.d6.loss_mask: 0.7076  decode.d6.loss_dice: 1.1377  decode.d7.loss_cls: 1.0117  decode.d7.loss_mask: 0.6798  decode.d7.loss_dice: 1.1265  decode.d8.loss_cls: 0.9951  decode.d8.loss_mask: 0.7341  decode.d8.loss_dice: 1.1378
2023/05/24 09:49:26 - mmengine - INFO - Iter(train) [125450/160000]  lr: 2.5171e-06  eta: 4:09:11  time: 0.4257  data_time: 0.0099  memory: 4857  grad_norm: 104.8988  loss: 36.0924  decode.loss_cls: 1.2406  decode.loss_mask: 0.7391  decode.loss_dice: 1.3349  decode.d0.loss_cls: 3.2925  decode.d0.loss_mask: 0.8439  decode.d0.loss_dice: 1.5901  decode.d1.loss_cls: 1.3440  decode.d1.loss_mask: 0.7813  decode.d1.loss_dice: 1.4782  decode.d2.loss_cls: 1.3594  decode.d2.loss_mask: 0.7329  decode.d2.loss_dice: 1.3997  decode.d3.loss_cls: 1.2730  decode.d3.loss_mask: 0.7537  decode.d3.loss_dice: 1.3510  decode.d4.loss_cls: 1.2921  decode.d4.loss_mask: 0.7403  decode.d4.loss_dice: 1.3729  decode.d5.loss_cls: 1.2317  decode.d5.loss_mask: 0.7270  decode.d5.loss_dice: 1.3297  decode.d6.loss_cls: 1.2677  decode.d6.loss_mask: 0.7351  decode.d6.loss_dice: 1.2874  decode.d7.loss_cls: 1.2680  decode.d7.loss_mask: 0.7469  decode.d7.loss_dice: 1.3230  decode.d8.loss_cls: 1.2157  decode.d8.loss_mask: 0.7433  decode.d8.loss_dice: 1.2975
2023/05/24 09:49:50 - mmengine - INFO - Iter(train) [125500/160000]  lr: 2.5138e-06  eta: 4:08:50  time: 0.4853  data_time: 0.0100  memory: 4821  grad_norm: 90.2846  loss: 35.6675  decode.loss_cls: 1.0722  decode.loss_mask: 0.8960  decode.loss_dice: 1.3073  decode.d0.loss_cls: 3.1542  decode.d0.loss_mask: 0.8386  decode.d0.loss_dice: 1.5579  decode.d1.loss_cls: 1.2214  decode.d1.loss_mask: 0.9955  decode.d1.loss_dice: 1.3968  decode.d2.loss_cls: 1.1179  decode.d2.loss_mask: 0.9675  decode.d2.loss_dice: 1.3546  decode.d3.loss_cls: 1.1134  decode.d3.loss_mask: 0.8584  decode.d3.loss_dice: 1.3192  decode.d4.loss_cls: 1.1094  decode.d4.loss_mask: 0.8927  decode.d4.loss_dice: 1.3254  decode.d5.loss_cls: 1.0667  decode.d5.loss_mask: 0.8718  decode.d5.loss_dice: 1.3111  decode.d6.loss_cls: 1.1816  decode.d6.loss_mask: 0.8337  decode.d6.loss_dice: 1.2893  decode.d7.loss_cls: 1.1588  decode.d7.loss_mask: 0.8430  decode.d7.loss_dice: 1.3007  decode.d8.loss_cls: 1.1230  decode.d8.loss_mask: 0.9042  decode.d8.loss_dice: 1.2852
2023/05/24 09:50:12 - mmengine - INFO - Iter(train) [125550/160000]  lr: 2.5105e-06  eta: 4:08:29  time: 0.4234  data_time: 0.0096  memory: 4867  grad_norm: 78.9767  loss: 30.6006  decode.loss_cls: 1.1021  decode.loss_mask: 0.6833  decode.loss_dice: 1.0041  decode.d0.loss_cls: 2.9383  decode.d0.loss_mask: 0.7891  decode.d0.loss_dice: 1.2750  decode.d1.loss_cls: 1.2262  decode.d1.loss_mask: 0.7402  decode.d1.loss_dice: 1.1597  decode.d2.loss_cls: 1.1581  decode.d2.loss_mask: 0.6800  decode.d2.loss_dice: 1.0400  decode.d3.loss_cls: 1.1498  decode.d3.loss_mask: 0.6736  decode.d3.loss_dice: 1.0100  decode.d4.loss_cls: 1.1103  decode.d4.loss_mask: 0.6847  decode.d4.loss_dice: 1.0634  decode.d5.loss_cls: 1.1036  decode.d5.loss_mask: 0.6712  decode.d5.loss_dice: 1.0018  decode.d6.loss_cls: 1.0800  decode.d6.loss_mask: 0.6976  decode.d6.loss_dice: 1.0223  decode.d7.loss_cls: 1.0253  decode.d7.loss_mask: 0.6999  decode.d7.loss_dice: 1.0350  decode.d8.loss_cls: 1.0459  decode.d8.loss_mask: 0.6903  decode.d8.loss_dice: 1.0397
2023/05/24 09:50:34 - mmengine - INFO - Iter(train) [125600/160000]  lr: 2.5072e-06  eta: 4:08:07  time: 0.4332  data_time: 0.0101  memory: 4896  grad_norm: 446.7370  loss: 26.7282  decode.loss_cls: 1.0834  decode.loss_mask: 0.5647  decode.loss_dice: 0.7921  decode.d0.loss_cls: 2.7278  decode.d0.loss_mask: 0.6350  decode.d0.loss_dice: 0.9214  decode.d1.loss_cls: 1.0693  decode.d1.loss_mask: 0.6547  decode.d1.loss_dice: 0.9063  decode.d2.loss_cls: 1.0017  decode.d2.loss_mask: 0.6340  decode.d2.loss_dice: 0.8557  decode.d3.loss_cls: 1.1306  decode.d3.loss_mask: 0.5808  decode.d3.loss_dice: 0.8364  decode.d4.loss_cls: 0.9893  decode.d4.loss_mask: 0.6050  decode.d4.loss_dice: 0.8290  decode.d5.loss_cls: 1.0846  decode.d5.loss_mask: 0.5736  decode.d5.loss_dice: 0.8214  decode.d6.loss_cls: 1.0888  decode.d6.loss_mask: 0.5717  decode.d6.loss_dice: 0.8256  decode.d7.loss_cls: 1.0878  decode.d7.loss_mask: 0.5700  decode.d7.loss_dice: 0.8151  decode.d8.loss_cls: 1.0746  decode.d8.loss_mask: 0.5780  decode.d8.loss_dice: 0.8198
2023/05/24 09:50:55 - mmengine - INFO - Iter(train) [125650/160000]  lr: 2.5040e-06  eta: 4:07:46  time: 0.4300  data_time: 0.0104  memory: 4872  grad_norm: 100.8518  loss: 35.5372  decode.loss_cls: 1.2288  decode.loss_mask: 0.8841  decode.loss_dice: 1.1844  decode.d0.loss_cls: 3.2073  decode.d0.loss_mask: 0.9028  decode.d0.loss_dice: 1.3703  decode.d1.loss_cls: 1.2419  decode.d1.loss_mask: 0.9712  decode.d1.loss_dice: 1.3118  decode.d2.loss_cls: 1.2636  decode.d2.loss_mask: 0.9228  decode.d2.loss_dice: 1.2643  decode.d3.loss_cls: 1.2845  decode.d3.loss_mask: 0.8644  decode.d3.loss_dice: 1.1760  decode.d4.loss_cls: 1.2433  decode.d4.loss_mask: 0.8649  decode.d4.loss_dice: 1.2139  decode.d5.loss_cls: 1.2437  decode.d5.loss_mask: 0.8623  decode.d5.loss_dice: 1.1914  decode.d6.loss_cls: 1.2114  decode.d6.loss_mask: 0.8831  decode.d6.loss_dice: 1.1733  decode.d7.loss_cls: 1.2310  decode.d7.loss_mask: 0.8775  decode.d7.loss_dice: 1.1838  decode.d8.loss_cls: 1.2095  decode.d8.loss_mask: 0.8847  decode.d8.loss_dice: 1.1852
2023/05/24 09:51:17 - mmengine - INFO - Iter(train) [125700/160000]  lr: 2.5007e-06  eta: 4:07:24  time: 0.4319  data_time: 0.0100  memory: 4869  grad_norm: 77.2846  loss: 39.4188  decode.loss_cls: 1.2592  decode.loss_mask: 0.8056  decode.loss_dice: 1.5539  decode.d0.loss_cls: 3.3283  decode.d0.loss_mask: 0.8988  decode.d0.loss_dice: 1.9307  decode.d1.loss_cls: 1.3049  decode.d1.loss_mask: 0.9027  decode.d1.loss_dice: 1.7429  decode.d2.loss_cls: 1.2914  decode.d2.loss_mask: 0.8494  decode.d2.loss_dice: 1.6722  decode.d3.loss_cls: 1.2574  decode.d3.loss_mask: 0.8378  decode.d3.loss_dice: 1.6098  decode.d4.loss_cls: 1.2434  decode.d4.loss_mask: 0.8140  decode.d4.loss_dice: 1.5854  decode.d5.loss_cls: 1.1960  decode.d5.loss_mask: 0.8259  decode.d5.loss_dice: 1.6057  decode.d6.loss_cls: 1.2815  decode.d6.loss_mask: 0.8217  decode.d6.loss_dice: 1.5281  decode.d7.loss_cls: 1.2330  decode.d7.loss_mask: 0.8218  decode.d7.loss_dice: 1.5948  decode.d8.loss_cls: 1.2598  decode.d8.loss_mask: 0.8111  decode.d8.loss_dice: 1.5516
2023/05/24 09:51:39 - mmengine - INFO - Iter(train) [125750/160000]  lr: 2.4974e-06  eta: 4:07:02  time: 0.4810  data_time: 0.0098  memory: 4888  grad_norm: 91.7740  loss: 36.1408  decode.loss_cls: 1.2355  decode.loss_mask: 0.7216  decode.loss_dice: 1.3789  decode.d0.loss_cls: 3.0737  decode.d0.loss_mask: 0.7729  decode.d0.loss_dice: 1.6202  decode.d1.loss_cls: 1.2976  decode.d1.loss_mask: 0.7916  decode.d1.loss_dice: 1.5182  decode.d2.loss_cls: 1.3120  decode.d2.loss_mask: 0.7595  decode.d2.loss_dice: 1.4652  decode.d3.loss_cls: 1.2406  decode.d3.loss_mask: 0.7261  decode.d3.loss_dice: 1.4027  decode.d4.loss_cls: 1.2044  decode.d4.loss_mask: 0.7182  decode.d4.loss_dice: 1.4334  decode.d5.loss_cls: 1.2056  decode.d5.loss_mask: 0.7249  decode.d5.loss_dice: 1.3887  decode.d6.loss_cls: 1.2518  decode.d6.loss_mask: 0.7177  decode.d6.loss_dice: 1.4272  decode.d7.loss_cls: 1.1728  decode.d7.loss_mask: 0.7523  decode.d7.loss_dice: 1.4577  decode.d8.loss_cls: 1.2295  decode.d8.loss_mask: 0.7171  decode.d8.loss_dice: 1.4232
2023/05/24 09:52:01 - mmengine - INFO - Iter(train) [125800/160000]  lr: 2.4941e-06  eta: 4:06:41  time: 0.4218  data_time: 0.0099  memory: 4870  grad_norm: 111.7496  loss: 39.8336  decode.loss_cls: 1.1360  decode.loss_mask: 0.9642  decode.loss_dice: 1.5482  decode.d0.loss_cls: 3.0810  decode.d0.loss_mask: 1.0258  decode.d0.loss_dice: 1.8249  decode.d1.loss_cls: 1.3501  decode.d1.loss_mask: 0.9936  decode.d1.loss_dice: 1.7024  decode.d2.loss_cls: 1.2022  decode.d2.loss_mask: 1.0164  decode.d2.loss_dice: 1.6578  decode.d3.loss_cls: 1.2494  decode.d3.loss_mask: 0.9878  decode.d3.loss_dice: 1.6227  decode.d4.loss_cls: 1.2480  decode.d4.loss_mask: 0.9627  decode.d4.loss_dice: 1.5959  decode.d5.loss_cls: 1.2303  decode.d5.loss_mask: 0.9567  decode.d5.loss_dice: 1.5518  decode.d6.loss_cls: 1.1175  decode.d6.loss_mask: 0.9454  decode.d6.loss_dice: 1.5615  decode.d7.loss_cls: 1.1264  decode.d7.loss_mask: 0.9397  decode.d7.loss_dice: 1.5703  decode.d8.loss_cls: 1.2074  decode.d8.loss_mask: 0.9450  decode.d8.loss_dice: 1.5126
2023/05/24 09:52:23 - mmengine - INFO - Iter(train) [125850/160000]  lr: 2.4908e-06  eta: 4:06:19  time: 0.4169  data_time: 0.0100  memory: 4838  grad_norm: 106.0295  loss: 34.8638  decode.loss_cls: 1.2676  decode.loss_mask: 0.7151  decode.loss_dice: 1.2345  decode.d0.loss_cls: 3.2339  decode.d0.loss_mask: 0.7743  decode.d0.loss_dice: 1.4690  decode.d1.loss_cls: 1.3101  decode.d1.loss_mask: 0.7807  decode.d1.loss_dice: 1.4013  decode.d2.loss_cls: 1.3023  decode.d2.loss_mask: 0.7920  decode.d2.loss_dice: 1.3308  decode.d3.loss_cls: 1.3939  decode.d3.loss_mask: 0.6855  decode.d3.loss_dice: 1.2309  decode.d4.loss_cls: 1.2923  decode.d4.loss_mask: 0.6809  decode.d4.loss_dice: 1.2086  decode.d5.loss_cls: 1.3103  decode.d5.loss_mask: 0.6658  decode.d5.loss_dice: 1.2169  decode.d6.loss_cls: 1.2758  decode.d6.loss_mask: 0.6769  decode.d6.loss_dice: 1.2405  decode.d7.loss_cls: 1.2697  decode.d7.loss_mask: 0.6782  decode.d7.loss_dice: 1.2334  decode.d8.loss_cls: 1.2484  decode.d8.loss_mask: 0.6884  decode.d8.loss_dice: 1.2559
2023/05/24 09:52:44 - mmengine - INFO - Iter(train) [125900/160000]  lr: 2.4876e-06  eta: 4:05:57  time: 0.4223  data_time: 0.0094  memory: 4857  grad_norm: 93.9003  loss: 37.6522  decode.loss_cls: 1.3563  decode.loss_mask: 0.7423  decode.loss_dice: 1.3166  decode.d0.loss_cls: 3.1885  decode.d0.loss_mask: 0.9785  decode.d0.loss_dice: 1.6011  decode.d1.loss_cls: 1.5481  decode.d1.loss_mask: 0.8339  decode.d1.loss_dice: 1.4972  decode.d2.loss_cls: 1.4212  decode.d2.loss_mask: 0.8173  decode.d2.loss_dice: 1.4394  decode.d3.loss_cls: 1.4023  decode.d3.loss_mask: 0.7965  decode.d3.loss_dice: 1.3458  decode.d4.loss_cls: 1.4199  decode.d4.loss_mask: 0.8051  decode.d4.loss_dice: 1.3564  decode.d5.loss_cls: 1.4097  decode.d5.loss_mask: 0.7624  decode.d5.loss_dice: 1.3286  decode.d6.loss_cls: 1.3472  decode.d6.loss_mask: 0.7693  decode.d6.loss_dice: 1.3346  decode.d7.loss_cls: 1.3449  decode.d7.loss_mask: 0.7572  decode.d7.loss_dice: 1.2979  decode.d8.loss_cls: 1.3498  decode.d8.loss_mask: 0.7505  decode.d8.loss_dice: 1.3336
2023/05/24 09:53:05 - mmengine - INFO - Iter(train) [125950/160000]  lr: 2.4843e-06  eta: 4:05:36  time: 0.4279  data_time: 0.0103  memory: 4865  grad_norm: 117.4311  loss: 35.6084  decode.loss_cls: 1.1116  decode.loss_mask: 0.8365  decode.loss_dice: 1.3952  decode.d0.loss_cls: 2.5857  decode.d0.loss_mask: 0.8823  decode.d0.loss_dice: 1.6589  decode.d1.loss_cls: 1.1031  decode.d1.loss_mask: 0.8376  decode.d1.loss_dice: 1.5572  decode.d2.loss_cls: 1.1710  decode.d2.loss_mask: 0.8589  decode.d2.loss_dice: 1.4549  decode.d3.loss_cls: 1.1069  decode.d3.loss_mask: 0.8397  decode.d3.loss_dice: 1.4348  decode.d4.loss_cls: 1.0781  decode.d4.loss_mask: 0.8320  decode.d4.loss_dice: 1.4179  decode.d5.loss_cls: 1.1192  decode.d5.loss_mask: 0.8442  decode.d5.loss_dice: 1.4141  decode.d6.loss_cls: 1.1293  decode.d6.loss_mask: 0.8454  decode.d6.loss_dice: 1.3841  decode.d7.loss_cls: 1.1219  decode.d7.loss_mask: 0.8551  decode.d7.loss_dice: 1.4142  decode.d8.loss_cls: 1.0794  decode.d8.loss_mask: 0.8344  decode.d8.loss_dice: 1.4047
2023/05/24 09:53:27 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 09:53:27 - mmengine - INFO - Iter(train) [126000/160000]  lr: 2.4810e-06  eta: 4:05:14  time: 0.4286  data_time: 0.0096  memory: 4840  grad_norm: 79.8889  loss: 29.0922  decode.loss_cls: 1.0442  decode.loss_mask: 0.5907  decode.loss_dice: 1.0082  decode.d0.loss_cls: 2.6720  decode.d0.loss_mask: 0.7410  decode.d0.loss_dice: 1.2040  decode.d1.loss_cls: 1.1387  decode.d1.loss_mask: 0.6512  decode.d1.loss_dice: 1.1600  decode.d2.loss_cls: 1.1533  decode.d2.loss_mask: 0.6192  decode.d2.loss_dice: 1.0895  decode.d3.loss_cls: 1.1048  decode.d3.loss_mask: 0.6079  decode.d3.loss_dice: 1.0044  decode.d4.loss_cls: 1.0840  decode.d4.loss_mask: 0.6112  decode.d4.loss_dice: 1.0237  decode.d5.loss_cls: 1.0702  decode.d5.loss_mask: 0.5869  decode.d5.loss_dice: 0.9922  decode.d6.loss_cls: 1.0728  decode.d6.loss_mask: 0.5734  decode.d6.loss_dice: 1.0121  decode.d7.loss_cls: 1.0406  decode.d7.loss_mask: 0.5874  decode.d7.loss_dice: 1.0169  decode.d8.loss_cls: 1.0488  decode.d8.loss_mask: 0.5959  decode.d8.loss_dice: 0.9867
2023/05/24 09:53:27 - mmengine - INFO - Saving checkpoint at 126000 iterations
2023/05/24 09:53:54 - mmengine - INFO - Iter(train) [126050/160000]  lr: 2.4777e-06  eta: 4:04:54  time: 0.4189  data_time: 0.0099  memory: 4860  grad_norm: 85.1946  loss: 30.8484  decode.loss_cls: 1.0424  decode.loss_mask: 0.6529  decode.loss_dice: 1.1541  decode.d0.loss_cls: 2.9213  decode.d0.loss_mask: 0.6595  decode.d0.loss_dice: 1.3231  decode.d1.loss_cls: 1.1674  decode.d1.loss_mask: 0.6752  decode.d1.loss_dice: 1.2444  decode.d2.loss_cls: 1.0912  decode.d2.loss_mask: 0.6259  decode.d2.loss_dice: 1.1689  decode.d3.loss_cls: 1.0531  decode.d3.loss_mask: 0.6561  decode.d3.loss_dice: 1.1767  decode.d4.loss_cls: 1.0702  decode.d4.loss_mask: 0.6337  decode.d4.loss_dice: 1.1673  decode.d5.loss_cls: 1.0265  decode.d5.loss_mask: 0.6458  decode.d5.loss_dice: 1.1812  decode.d6.loss_cls: 1.0671  decode.d6.loss_mask: 0.6466  decode.d6.loss_dice: 1.1496  decode.d7.loss_cls: 1.0007  decode.d7.loss_mask: 0.6422  decode.d7.loss_dice: 1.1707  decode.d8.loss_cls: 1.0462  decode.d8.loss_mask: 0.6424  decode.d8.loss_dice: 1.1462
2023/05/24 09:54:15 - mmengine - INFO - Iter(train) [126100/160000]  lr: 2.4744e-06  eta: 4:04:32  time: 0.4257  data_time: 0.0097  memory: 4898  grad_norm: 98.5851  loss: 29.3403  decode.loss_cls: 0.9267  decode.loss_mask: 0.5974  decode.loss_dice: 1.1241  decode.d0.loss_cls: 2.8309  decode.d0.loss_mask: 0.6174  decode.d0.loss_dice: 1.3427  decode.d1.loss_cls: 1.0767  decode.d1.loss_mask: 0.5857  decode.d1.loss_dice: 1.2197  decode.d2.loss_cls: 1.0274  decode.d2.loss_mask: 0.5755  decode.d2.loss_dice: 1.1999  decode.d3.loss_cls: 0.9739  decode.d3.loss_mask: 0.5957  decode.d3.loss_dice: 1.1467  decode.d4.loss_cls: 0.9410  decode.d4.loss_mask: 0.5969  decode.d4.loss_dice: 1.1757  decode.d5.loss_cls: 0.9254  decode.d5.loss_mask: 0.5990  decode.d5.loss_dice: 1.1570  decode.d6.loss_cls: 0.9581  decode.d6.loss_mask: 0.5986  decode.d6.loss_dice: 1.1638  decode.d7.loss_cls: 0.9926  decode.d7.loss_mask: 0.5844  decode.d7.loss_dice: 1.1093  decode.d8.loss_cls: 0.9587  decode.d8.loss_mask: 0.5907  decode.d8.loss_dice: 1.1488
2023/05/24 09:54:36 - mmengine - INFO - Iter(train) [126150/160000]  lr: 2.4711e-06  eta: 4:04:10  time: 0.4202  data_time: 0.0098  memory: 4866  grad_norm: 95.0106  loss: 39.4629  decode.loss_cls: 1.3212  decode.loss_mask: 0.8686  decode.loss_dice: 1.4216  decode.d0.loss_cls: 3.0808  decode.d0.loss_mask: 0.9743  decode.d0.loss_dice: 1.7139  decode.d1.loss_cls: 1.4836  decode.d1.loss_mask: 0.9376  decode.d1.loss_dice: 1.5171  decode.d2.loss_cls: 1.4785  decode.d2.loss_mask: 0.9073  decode.d2.loss_dice: 1.4521  decode.d3.loss_cls: 1.4361  decode.d3.loss_mask: 0.9187  decode.d3.loss_dice: 1.4408  decode.d4.loss_cls: 1.4432  decode.d4.loss_mask: 0.8998  decode.d4.loss_dice: 1.4287  decode.d5.loss_cls: 1.3978  decode.d5.loss_mask: 0.8988  decode.d5.loss_dice: 1.4152  decode.d6.loss_cls: 1.3509  decode.d6.loss_mask: 0.8826  decode.d6.loss_dice: 1.4334  decode.d7.loss_cls: 1.4002  decode.d7.loss_mask: 0.8785  decode.d7.loss_dice: 1.4356  decode.d8.loss_cls: 1.3344  decode.d8.loss_mask: 0.8828  decode.d8.loss_dice: 1.4291
2023/05/24 09:54:57 - mmengine - INFO - Iter(train) [126200/160000]  lr: 2.4679e-06  eta: 4:03:48  time: 0.4179  data_time: 0.0098  memory: 4917  grad_norm: 96.8869  loss: 30.4948  decode.loss_cls: 1.0822  decode.loss_mask: 0.6294  decode.loss_dice: 1.1240  decode.d0.loss_cls: 2.8462  decode.d0.loss_mask: 0.6909  decode.d0.loss_dice: 1.2694  decode.d1.loss_cls: 1.1919  decode.d1.loss_mask: 0.6345  decode.d1.loss_dice: 1.2006  decode.d2.loss_cls: 1.0870  decode.d2.loss_mask: 0.6206  decode.d2.loss_dice: 1.1432  decode.d3.loss_cls: 1.1237  decode.d3.loss_mask: 0.6314  decode.d3.loss_dice: 1.0746  decode.d4.loss_cls: 1.0560  decode.d4.loss_mask: 0.6241  decode.d4.loss_dice: 1.1199  decode.d5.loss_cls: 1.0802  decode.d5.loss_mask: 0.6277  decode.d5.loss_dice: 1.1011  decode.d6.loss_cls: 1.1309  decode.d6.loss_mask: 0.6249  decode.d6.loss_dice: 1.1297  decode.d7.loss_cls: 1.1154  decode.d7.loss_mask: 0.6224  decode.d7.loss_dice: 1.0936  decode.d8.loss_cls: 1.1011  decode.d8.loss_mask: 0.6208  decode.d8.loss_dice: 1.0973
2023/05/24 09:55:18 - mmengine - INFO - Iter(train) [126250/160000]  lr: 2.4646e-06  eta: 4:03:27  time: 0.4232  data_time: 0.0097  memory: 4909  grad_norm: 92.5656  loss: 35.7564  decode.loss_cls: 1.2200  decode.loss_mask: 0.7010  decode.loss_dice: 1.3353  decode.d0.loss_cls: 3.3602  decode.d0.loss_mask: 0.8100  decode.d0.loss_dice: 1.5695  decode.d1.loss_cls: 1.3290  decode.d1.loss_mask: 0.7748  decode.d1.loss_dice: 1.4594  decode.d2.loss_cls: 1.2565  decode.d2.loss_mask: 0.7363  decode.d2.loss_dice: 1.4388  decode.d3.loss_cls: 1.2706  decode.d3.loss_mask: 0.7190  decode.d3.loss_dice: 1.3694  decode.d4.loss_cls: 1.2162  decode.d4.loss_mask: 0.7124  decode.d4.loss_dice: 1.3727  decode.d5.loss_cls: 1.2719  decode.d5.loss_mask: 0.7073  decode.d5.loss_dice: 1.3610  decode.d6.loss_cls: 1.2368  decode.d6.loss_mask: 0.7150  decode.d6.loss_dice: 1.3344  decode.d7.loss_cls: 1.1878  decode.d7.loss_mask: 0.7111  decode.d7.loss_dice: 1.3280  decode.d8.loss_cls: 1.2055  decode.d8.loss_mask: 0.6966  decode.d8.loss_dice: 1.3500
2023/05/24 09:55:39 - mmengine - INFO - Iter(train) [126300/160000]  lr: 2.4613e-06  eta: 4:03:05  time: 0.4156  data_time: 0.0099  memory: 4876  grad_norm: 89.2994  loss: 38.6844  decode.loss_cls: 1.1396  decode.loss_mask: 0.8673  decode.loss_dice: 1.5597  decode.d0.loss_cls: 3.1465  decode.d0.loss_mask: 0.9090  decode.d0.loss_dice: 1.7469  decode.d1.loss_cls: 1.3317  decode.d1.loss_mask: 0.8782  decode.d1.loss_dice: 1.6410  decode.d2.loss_cls: 1.2493  decode.d2.loss_mask: 0.8764  decode.d2.loss_dice: 1.6113  decode.d3.loss_cls: 1.2475  decode.d3.loss_mask: 0.8554  decode.d3.loss_dice: 1.5619  decode.d4.loss_cls: 1.1819  decode.d4.loss_mask: 0.8576  decode.d4.loss_dice: 1.6119  decode.d5.loss_cls: 1.1800  decode.d5.loss_mask: 0.8705  decode.d5.loss_dice: 1.5617  decode.d6.loss_cls: 1.1628  decode.d6.loss_mask: 0.8594  decode.d6.loss_dice: 1.5541  decode.d7.loss_cls: 1.2107  decode.d7.loss_mask: 0.8564  decode.d7.loss_dice: 1.5559  decode.d8.loss_cls: 1.2016  decode.d8.loss_mask: 0.8434  decode.d8.loss_dice: 1.5548
2023/05/24 09:56:01 - mmengine - INFO - Iter(train) [126350/160000]  lr: 2.4580e-06  eta: 4:02:43  time: 0.4308  data_time: 0.0099  memory: 4865  grad_norm: 96.3813  loss: 30.9834  decode.loss_cls: 0.9841  decode.loss_mask: 0.6143  decode.loss_dice: 1.1674  decode.d0.loss_cls: 3.0061  decode.d0.loss_mask: 0.6434  decode.d0.loss_dice: 1.3189  decode.d1.loss_cls: 1.1642  decode.d1.loss_mask: 0.6435  decode.d1.loss_dice: 1.2271  decode.d2.loss_cls: 1.1482  decode.d2.loss_mask: 0.6391  decode.d2.loss_dice: 1.1827  decode.d3.loss_cls: 1.1023  decode.d3.loss_mask: 0.6349  decode.d3.loss_dice: 1.1871  decode.d4.loss_cls: 1.0314  decode.d4.loss_mask: 0.6341  decode.d4.loss_dice: 1.1651  decode.d5.loss_cls: 1.0841  decode.d5.loss_mask: 0.6276  decode.d5.loss_dice: 1.1986  decode.d6.loss_cls: 1.0977  decode.d6.loss_mask: 0.6171  decode.d6.loss_dice: 1.1910  decode.d7.loss_cls: 1.0721  decode.d7.loss_mask: 0.6197  decode.d7.loss_dice: 1.1682  decode.d8.loss_cls: 1.0238  decode.d8.loss_mask: 0.6133  decode.d8.loss_dice: 1.1763
2023/05/24 09:56:22 - mmengine - INFO - Iter(train) [126400/160000]  lr: 2.4547e-06  eta: 4:02:22  time: 0.4168  data_time: 0.0099  memory: 4853  grad_norm: 98.8010  loss: 35.4812  decode.loss_cls: 1.1627  decode.loss_mask: 0.8404  decode.loss_dice: 1.2507  decode.d0.loss_cls: 3.1697  decode.d0.loss_mask: 0.9060  decode.d0.loss_dice: 1.5178  decode.d1.loss_cls: 1.2525  decode.d1.loss_mask: 0.8744  decode.d1.loss_dice: 1.4006  decode.d2.loss_cls: 1.2438  decode.d2.loss_mask: 0.8480  decode.d2.loss_dice: 1.3432  decode.d3.loss_cls: 1.1884  decode.d3.loss_mask: 0.8373  decode.d3.loss_dice: 1.2816  decode.d4.loss_cls: 1.1815  decode.d4.loss_mask: 0.8603  decode.d4.loss_dice: 1.2898  decode.d5.loss_cls: 1.1332  decode.d5.loss_mask: 0.8351  decode.d5.loss_dice: 1.2945  decode.d6.loss_cls: 1.1591  decode.d6.loss_mask: 0.8288  decode.d6.loss_dice: 1.2695  decode.d7.loss_cls: 1.1499  decode.d7.loss_mask: 0.8421  decode.d7.loss_dice: 1.2628  decode.d8.loss_cls: 1.1742  decode.d8.loss_mask: 0.8273  decode.d8.loss_dice: 1.2559
2023/05/24 09:56:43 - mmengine - INFO - Iter(train) [126450/160000]  lr: 2.4514e-06  eta: 4:02:00  time: 0.4289  data_time: 0.0101  memory: 4858  grad_norm: 91.9483  loss: 27.1908  decode.loss_cls: 0.7938  decode.loss_mask: 0.6645  decode.loss_dice: 0.9949  decode.d0.loss_cls: 2.6912  decode.d0.loss_mask: 0.7212  decode.d0.loss_dice: 1.2017  decode.d1.loss_cls: 0.8575  decode.d1.loss_mask: 0.7085  decode.d1.loss_dice: 1.1277  decode.d2.loss_cls: 0.8775  decode.d2.loss_mask: 0.6512  decode.d2.loss_dice: 1.0346  decode.d3.loss_cls: 0.8754  decode.d3.loss_mask: 0.6369  decode.d3.loss_dice: 0.9970  decode.d4.loss_cls: 0.8912  decode.d4.loss_mask: 0.6217  decode.d4.loss_dice: 0.9957  decode.d5.loss_cls: 0.8868  decode.d5.loss_mask: 0.6637  decode.d5.loss_dice: 0.9886  decode.d6.loss_cls: 0.7927  decode.d6.loss_mask: 0.6382  decode.d6.loss_dice: 1.0101  decode.d7.loss_cls: 0.7868  decode.d7.loss_mask: 0.6538  decode.d7.loss_dice: 1.0000  decode.d8.loss_cls: 0.7800  decode.d8.loss_mask: 0.6506  decode.d8.loss_dice: 0.9973
2023/05/24 09:57:05 - mmengine - INFO - Iter(train) [126500/160000]  lr: 2.4481e-06  eta: 4:01:38  time: 0.4260  data_time: 0.0100  memory: 4877  grad_norm: 93.1779  loss: 32.4992  decode.loss_cls: 1.0695  decode.loss_mask: 0.7480  decode.loss_dice: 1.1579  decode.d0.loss_cls: 3.0979  decode.d0.loss_mask: 0.8430  decode.d0.loss_dice: 1.3026  decode.d1.loss_cls: 1.3242  decode.d1.loss_mask: 0.7840  decode.d1.loss_dice: 1.2526  decode.d2.loss_cls: 1.1815  decode.d2.loss_mask: 0.7349  decode.d2.loss_dice: 1.1656  decode.d3.loss_cls: 1.1368  decode.d3.loss_mask: 0.7569  decode.d3.loss_dice: 1.1693  decode.d4.loss_cls: 1.0824  decode.d4.loss_mask: 0.7615  decode.d4.loss_dice: 1.1712  decode.d5.loss_cls: 1.0816  decode.d5.loss_mask: 0.7444  decode.d5.loss_dice: 1.1308  decode.d6.loss_cls: 1.0603  decode.d6.loss_mask: 0.7583  decode.d6.loss_dice: 1.1524  decode.d7.loss_cls: 1.0552  decode.d7.loss_mask: 0.7373  decode.d7.loss_dice: 1.1239  decode.d8.loss_cls: 1.0408  decode.d8.loss_mask: 0.7350  decode.d8.loss_dice: 1.1391
2023/05/24 09:57:27 - mmengine - INFO - Iter(train) [126550/160000]  lr: 2.4448e-06  eta: 4:01:17  time: 0.4778  data_time: 0.0100  memory: 4818  grad_norm: 100.2160  loss: 35.3835  decode.loss_cls: 1.1066  decode.loss_mask: 0.7486  decode.loss_dice: 1.4074  decode.d0.loss_cls: 2.8139  decode.d0.loss_mask: 0.7274  decode.d0.loss_dice: 1.5814  decode.d1.loss_cls: 1.2370  decode.d1.loss_mask: 0.7251  decode.d1.loss_dice: 1.4876  decode.d2.loss_cls: 1.1320  decode.d2.loss_mask: 0.7951  decode.d2.loss_dice: 1.4685  decode.d3.loss_cls: 1.2303  decode.d3.loss_mask: 0.7812  decode.d3.loss_dice: 1.4501  decode.d4.loss_cls: 1.1795  decode.d4.loss_mask: 0.7698  decode.d4.loss_dice: 1.4487  decode.d5.loss_cls: 1.1830  decode.d5.loss_mask: 0.7608  decode.d5.loss_dice: 1.4211  decode.d6.loss_cls: 1.1345  decode.d6.loss_mask: 0.7948  decode.d6.loss_dice: 1.4465  decode.d7.loss_cls: 1.1292  decode.d7.loss_mask: 0.7551  decode.d7.loss_dice: 1.4116  decode.d8.loss_cls: 1.0740  decode.d8.loss_mask: 0.7676  decode.d8.loss_dice: 1.4149
2023/05/24 09:57:49 - mmengine - INFO - Iter(train) [126600/160000]  lr: 2.4416e-06  eta: 4:00:55  time: 0.4299  data_time: 0.0099  memory: 4856  grad_norm: 228.6310  loss: 32.1203  decode.loss_cls: 1.0152  decode.loss_mask: 0.8086  decode.loss_dice: 1.0775  decode.d0.loss_cls: 2.9872  decode.d0.loss_mask: 0.8497  decode.d0.loss_dice: 1.2882  decode.d1.loss_cls: 1.1551  decode.d1.loss_mask: 0.8615  decode.d1.loss_dice: 1.2200  decode.d2.loss_cls: 1.0755  decode.d2.loss_mask: 0.8665  decode.d2.loss_dice: 1.1499  decode.d3.loss_cls: 1.0857  decode.d3.loss_mask: 0.8360  decode.d3.loss_dice: 1.1169  decode.d4.loss_cls: 1.0271  decode.d4.loss_mask: 0.8220  decode.d4.loss_dice: 1.1082  decode.d5.loss_cls: 1.0270  decode.d5.loss_mask: 0.8301  decode.d5.loss_dice: 1.1045  decode.d6.loss_cls: 1.0401  decode.d6.loss_mask: 0.8003  decode.d6.loss_dice: 1.0928  decode.d7.loss_cls: 1.0294  decode.d7.loss_mask: 0.7976  decode.d7.loss_dice: 1.1036  decode.d8.loss_cls: 1.0265  decode.d8.loss_mask: 0.8129  decode.d8.loss_dice: 1.1044
2023/05/24 09:58:12 - mmengine - INFO - Iter(train) [126650/160000]  lr: 2.4383e-06  eta: 4:00:34  time: 0.4740  data_time: 0.0097  memory: 4876  grad_norm: 91.2194  loss: 36.8802  decode.loss_cls: 1.1609  decode.loss_mask: 0.9051  decode.loss_dice: 1.4003  decode.d0.loss_cls: 2.7308  decode.d0.loss_mask: 1.0350  decode.d0.loss_dice: 1.6330  decode.d1.loss_cls: 1.1214  decode.d1.loss_mask: 1.0178  decode.d1.loss_dice: 1.5979  decode.d2.loss_cls: 1.1317  decode.d2.loss_mask: 0.9655  decode.d2.loss_dice: 1.4702  decode.d3.loss_cls: 1.1944  decode.d3.loss_mask: 0.8593  decode.d3.loss_dice: 1.4088  decode.d4.loss_cls: 1.1669  decode.d4.loss_mask: 0.8925  decode.d4.loss_dice: 1.4136  decode.d5.loss_cls: 1.1397  decode.d5.loss_mask: 0.8974  decode.d5.loss_dice: 1.4147  decode.d6.loss_cls: 1.1607  decode.d6.loss_mask: 0.8945  decode.d6.loss_dice: 1.3547  decode.d7.loss_cls: 1.1667  decode.d7.loss_mask: 0.9172  decode.d7.loss_dice: 1.3905  decode.d8.loss_cls: 1.1389  decode.d8.loss_mask: 0.9351  decode.d8.loss_dice: 1.3650
2023/05/24 09:58:34 - mmengine - INFO - Iter(train) [126700/160000]  lr: 2.4350e-06  eta: 4:00:12  time: 0.4255  data_time: 0.0100  memory: 4788  grad_norm: 110.0002  loss: 38.0054  decode.loss_cls: 1.0655  decode.loss_mask: 0.8813  decode.loss_dice: 1.4403  decode.d0.loss_cls: 3.3573  decode.d0.loss_mask: 0.9666  decode.d0.loss_dice: 1.7528  decode.d1.loss_cls: 1.3756  decode.d1.loss_mask: 0.9548  decode.d1.loss_dice: 1.6438  decode.d2.loss_cls: 1.2354  decode.d2.loss_mask: 0.9318  decode.d2.loss_dice: 1.5645  decode.d3.loss_cls: 1.1850  decode.d3.loss_mask: 0.9094  decode.d3.loss_dice: 1.4727  decode.d4.loss_cls: 1.1712  decode.d4.loss_mask: 0.9186  decode.d4.loss_dice: 1.4965  decode.d5.loss_cls: 1.1142  decode.d5.loss_mask: 0.9101  decode.d5.loss_dice: 1.4600  decode.d6.loss_cls: 1.1047  decode.d6.loss_mask: 0.8909  decode.d6.loss_dice: 1.4009  decode.d7.loss_cls: 1.1176  decode.d7.loss_mask: 0.8874  decode.d7.loss_dice: 1.3824  decode.d8.loss_cls: 1.1165  decode.d8.loss_mask: 0.8958  decode.d8.loss_dice: 1.4018
2023/05/24 09:58:55 - mmengine - INFO - Iter(train) [126750/160000]  lr: 2.4317e-06  eta: 3:59:50  time: 0.4181  data_time: 0.0099  memory: 4802  grad_norm: 115.4016  loss: 31.4436  decode.loss_cls: 0.9971  decode.loss_mask: 0.7686  decode.loss_dice: 1.1487  decode.d0.loss_cls: 2.7599  decode.d0.loss_mask: 0.8341  decode.d0.loss_dice: 1.2670  decode.d1.loss_cls: 1.0702  decode.d1.loss_mask: 0.7913  decode.d1.loss_dice: 1.2279  decode.d2.loss_cls: 0.9961  decode.d2.loss_mask: 0.7770  decode.d2.loss_dice: 1.1912  decode.d3.loss_cls: 1.0407  decode.d3.loss_mask: 0.7767  decode.d3.loss_dice: 1.1366  decode.d4.loss_cls: 0.9842  decode.d4.loss_mask: 0.7680  decode.d4.loss_dice: 1.1484  decode.d5.loss_cls: 1.0060  decode.d5.loss_mask: 0.7733  decode.d5.loss_dice: 1.1613  decode.d6.loss_cls: 1.0351  decode.d6.loss_mask: 0.7636  decode.d6.loss_dice: 1.1480  decode.d7.loss_cls: 1.0403  decode.d7.loss_mask: 0.7629  decode.d7.loss_dice: 1.1610  decode.d8.loss_cls: 1.0440  decode.d8.loss_mask: 0.7376  decode.d8.loss_dice: 1.1269
2023/05/24 09:59:16 - mmengine - INFO - Iter(train) [126800/160000]  lr: 2.4284e-06  eta: 3:59:28  time: 0.4196  data_time: 0.0098  memory: 4829  grad_norm: 106.8405  loss: 32.7778  decode.loss_cls: 1.0502  decode.loss_mask: 0.7921  decode.loss_dice: 1.1994  decode.d0.loss_cls: 3.0471  decode.d0.loss_mask: 0.8094  decode.d0.loss_dice: 1.3797  decode.d1.loss_cls: 1.0624  decode.d1.loss_mask: 0.7975  decode.d1.loss_dice: 1.2923  decode.d2.loss_cls: 1.0045  decode.d2.loss_mask: 0.7866  decode.d2.loss_dice: 1.2450  decode.d3.loss_cls: 1.0896  decode.d3.loss_mask: 0.7618  decode.d3.loss_dice: 1.2178  decode.d4.loss_cls: 1.0795  decode.d4.loss_mask: 0.7882  decode.d4.loss_dice: 1.2201  decode.d5.loss_cls: 1.0128  decode.d5.loss_mask: 0.7825  decode.d5.loss_dice: 1.2368  decode.d6.loss_cls: 1.0483  decode.d6.loss_mask: 0.7837  decode.d6.loss_dice: 1.2150  decode.d7.loss_cls: 1.0138  decode.d7.loss_mask: 0.7945  decode.d7.loss_dice: 1.2281  decode.d8.loss_cls: 1.0169  decode.d8.loss_mask: 0.7978  decode.d8.loss_dice: 1.2244
2023/05/24 09:59:38 - mmengine - INFO - Iter(train) [126850/160000]  lr: 2.4251e-06  eta: 3:59:07  time: 0.4501  data_time: 0.0102  memory: 4862  grad_norm: 103.8899  loss: 26.9785  decode.loss_cls: 0.7220  decode.loss_mask: 0.7573  decode.loss_dice: 0.9792  decode.d0.loss_cls: 2.4389  decode.d0.loss_mask: 0.8407  decode.d0.loss_dice: 1.1133  decode.d1.loss_cls: 0.8160  decode.d1.loss_mask: 0.8146  decode.d1.loss_dice: 1.0631  decode.d2.loss_cls: 0.7953  decode.d2.loss_mask: 0.7687  decode.d2.loss_dice: 0.9841  decode.d3.loss_cls: 0.7480  decode.d3.loss_mask: 0.7476  decode.d3.loss_dice: 0.9830  decode.d4.loss_cls: 0.7368  decode.d4.loss_mask: 0.7515  decode.d4.loss_dice: 0.9911  decode.d5.loss_cls: 0.7337  decode.d5.loss_mask: 0.7655  decode.d5.loss_dice: 0.9943  decode.d6.loss_cls: 0.7504  decode.d6.loss_mask: 0.7332  decode.d6.loss_dice: 0.9717  decode.d7.loss_cls: 0.7663  decode.d7.loss_mask: 0.7433  decode.d7.loss_dice: 0.9858  decode.d8.loss_cls: 0.7656  decode.d8.loss_mask: 0.7302  decode.d8.loss_dice: 0.9873
2023/05/24 09:59:59 - mmengine - INFO - Iter(train) [126900/160000]  lr: 2.4218e-06  eta: 3:58:45  time: 0.4206  data_time: 0.0100  memory: 4844  grad_norm: 113.6208  loss: 33.2395  decode.loss_cls: 1.2233  decode.loss_mask: 0.6947  decode.loss_dice: 1.1698  decode.d0.loss_cls: 2.9082  decode.d0.loss_mask: 0.6599  decode.d0.loss_dice: 1.3119  decode.d1.loss_cls: 1.2668  decode.d1.loss_mask: 0.7712  decode.d1.loss_dice: 1.2568  decode.d2.loss_cls: 1.3240  decode.d2.loss_mask: 0.6848  decode.d2.loss_dice: 1.2072  decode.d3.loss_cls: 1.2437  decode.d3.loss_mask: 0.7061  decode.d3.loss_dice: 1.2063  decode.d4.loss_cls: 1.2139  decode.d4.loss_mask: 0.7130  decode.d4.loss_dice: 1.2118  decode.d5.loss_cls: 1.1975  decode.d5.loss_mask: 0.6995  decode.d5.loss_dice: 1.2075  decode.d6.loss_cls: 1.2447  decode.d6.loss_mask: 0.7144  decode.d6.loss_dice: 1.1952  decode.d7.loss_cls: 1.1898  decode.d7.loss_mask: 0.6972  decode.d7.loss_dice: 1.1820  decode.d8.loss_cls: 1.2382  decode.d8.loss_mask: 0.7096  decode.d8.loss_dice: 1.1905
2023/05/24 10:00:21 - mmengine - INFO - Iter(train) [126950/160000]  lr: 2.4185e-06  eta: 3:58:24  time: 0.4185  data_time: 0.0099  memory: 4905  grad_norm: 102.0927  loss: 38.3045  decode.loss_cls: 1.3303  decode.loss_mask: 0.8188  decode.loss_dice: 1.4573  decode.d0.loss_cls: 3.1291  decode.d0.loss_mask: 0.9582  decode.d0.loss_dice: 1.6321  decode.d1.loss_cls: 1.2800  decode.d1.loss_mask: 0.9222  decode.d1.loss_dice: 1.5100  decode.d2.loss_cls: 1.2915  decode.d2.loss_mask: 0.8467  decode.d2.loss_dice: 1.5094  decode.d3.loss_cls: 1.2138  decode.d3.loss_mask: 0.8766  decode.d3.loss_dice: 1.4822  decode.d4.loss_cls: 1.2272  decode.d4.loss_mask: 0.8650  decode.d4.loss_dice: 1.4548  decode.d5.loss_cls: 1.2438  decode.d5.loss_mask: 0.8597  decode.d5.loss_dice: 1.4967  decode.d6.loss_cls: 1.2854  decode.d6.loss_mask: 0.8908  decode.d6.loss_dice: 1.4621  decode.d7.loss_cls: 1.2593  decode.d7.loss_mask: 0.8982  decode.d7.loss_dice: 1.4981  decode.d8.loss_cls: 1.3145  decode.d8.loss_mask: 0.8644  decode.d8.loss_dice: 1.4263
2023/05/24 10:00:42 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 10:00:42 - mmengine - INFO - Iter(train) [127000/160000]  lr: 2.4152e-06  eta: 3:58:02  time: 0.4191  data_time: 0.0099  memory: 4957  grad_norm: 100.1296  loss: 36.5721  decode.loss_cls: 1.3412  decode.loss_mask: 0.7510  decode.loss_dice: 1.2373  decode.d0.loss_cls: 3.3808  decode.d0.loss_mask: 0.7835  decode.d0.loss_dice: 1.4290  decode.d1.loss_cls: 1.4920  decode.d1.loss_mask: 0.8184  decode.d1.loss_dice: 1.3197  decode.d2.loss_cls: 1.5007  decode.d2.loss_mask: 0.7997  decode.d2.loss_dice: 1.2985  decode.d3.loss_cls: 1.4508  decode.d3.loss_mask: 0.7955  decode.d3.loss_dice: 1.2732  decode.d4.loss_cls: 1.4513  decode.d4.loss_mask: 0.7810  decode.d4.loss_dice: 1.2595  decode.d5.loss_cls: 1.3902  decode.d5.loss_mask: 0.7666  decode.d5.loss_dice: 1.2661  decode.d6.loss_cls: 1.3173  decode.d6.loss_mask: 0.7651  decode.d6.loss_dice: 1.2291  decode.d7.loss_cls: 1.3761  decode.d7.loss_mask: 0.7599  decode.d7.loss_dice: 1.2332  decode.d8.loss_cls: 1.3237  decode.d8.loss_mask: 0.7520  decode.d8.loss_dice: 1.2301
2023/05/24 10:00:42 - mmengine - INFO - Saving checkpoint at 127000 iterations
2023/05/24 10:01:09 - mmengine - INFO - Iter(train) [127050/160000]  lr: 2.4119e-06  eta: 3:57:42  time: 0.4255  data_time: 0.0101  memory: 4830  grad_norm: 102.1867  loss: 29.6045  decode.loss_cls: 1.1694  decode.loss_mask: 0.5915  decode.loss_dice: 0.9153  decode.d0.loss_cls: 2.9550  decode.d0.loss_mask: 0.6316  decode.d0.loss_dice: 1.1202  decode.d1.loss_cls: 1.3474  decode.d1.loss_mask: 0.6374  decode.d1.loss_dice: 1.0558  decode.d2.loss_cls: 1.2442  decode.d2.loss_mask: 0.6076  decode.d2.loss_dice: 0.9989  decode.d3.loss_cls: 1.2076  decode.d3.loss_mask: 0.5973  decode.d3.loss_dice: 0.9490  decode.d4.loss_cls: 1.1968  decode.d4.loss_mask: 0.6155  decode.d4.loss_dice: 0.9610  decode.d5.loss_cls: 1.1711  decode.d5.loss_mask: 0.6019  decode.d5.loss_dice: 0.9657  decode.d6.loss_cls: 1.1312  decode.d6.loss_mask: 0.6048  decode.d6.loss_dice: 0.9539  decode.d7.loss_cls: 1.1292  decode.d7.loss_mask: 0.5957  decode.d7.loss_dice: 0.9512  decode.d8.loss_cls: 1.1570  decode.d8.loss_mask: 0.6005  decode.d8.loss_dice: 0.9407
2023/05/24 10:01:31 - mmengine - INFO - Iter(train) [127100/160000]  lr: 2.4086e-06  eta: 3:57:20  time: 0.4438  data_time: 0.0101  memory: 4859  grad_norm: 93.1696  loss: 30.1977  decode.loss_cls: 0.8959  decode.loss_mask: 0.7213  decode.loss_dice: 1.1496  decode.d0.loss_cls: 2.5375  decode.d0.loss_mask: 0.8015  decode.d0.loss_dice: 1.3363  decode.d1.loss_cls: 1.0306  decode.d1.loss_mask: 0.7379  decode.d1.loss_dice: 1.2155  decode.d2.loss_cls: 1.0062  decode.d2.loss_mask: 0.7571  decode.d2.loss_dice: 1.2049  decode.d3.loss_cls: 0.9460  decode.d3.loss_mask: 0.7476  decode.d3.loss_dice: 1.1771  decode.d4.loss_cls: 0.9081  decode.d4.loss_mask: 0.7360  decode.d4.loss_dice: 1.1606  decode.d5.loss_cls: 0.9114  decode.d5.loss_mask: 0.7309  decode.d5.loss_dice: 1.1605  decode.d6.loss_cls: 0.8991  decode.d6.loss_mask: 0.7317  decode.d6.loss_dice: 1.1213  decode.d7.loss_cls: 0.9072  decode.d7.loss_mask: 0.7366  decode.d7.loss_dice: 1.1664  decode.d8.loss_cls: 0.8639  decode.d8.loss_mask: 0.7351  decode.d8.loss_dice: 1.1639
2023/05/24 10:01:52 - mmengine - INFO - Iter(train) [127150/160000]  lr: 2.4053e-06  eta: 3:56:58  time: 0.4220  data_time: 0.0101  memory: 4928  grad_norm: 81.0932  loss: 34.1719  decode.loss_cls: 1.3376  decode.loss_mask: 0.5898  decode.loss_dice: 1.1841  decode.d0.loss_cls: 3.0496  decode.d0.loss_mask: 0.6323  decode.d0.loss_dice: 1.4038  decode.d1.loss_cls: 1.4547  decode.d1.loss_mask: 0.6304  decode.d1.loss_dice: 1.2931  decode.d2.loss_cls: 1.4783  decode.d2.loss_mask: 0.6416  decode.d2.loss_dice: 1.3024  decode.d3.loss_cls: 1.4164  decode.d3.loss_mask: 0.6197  decode.d3.loss_dice: 1.2568  decode.d4.loss_cls: 1.3728  decode.d4.loss_mask: 0.6436  decode.d4.loss_dice: 1.2580  decode.d5.loss_cls: 1.3569  decode.d5.loss_mask: 0.6359  decode.d5.loss_dice: 1.2363  decode.d6.loss_cls: 1.3661  decode.d6.loss_mask: 0.5924  decode.d6.loss_dice: 1.1941  decode.d7.loss_cls: 1.2952  decode.d7.loss_mask: 0.5956  decode.d7.loss_dice: 1.2108  decode.d8.loss_cls: 1.3297  decode.d8.loss_mask: 0.5990  decode.d8.loss_dice: 1.1951
2023/05/24 10:02:13 - mmengine - INFO - Iter(train) [127200/160000]  lr: 2.4020e-06  eta: 3:56:37  time: 0.4211  data_time: 0.0098  memory: 4900  grad_norm: 103.1631  loss: 30.3909  decode.loss_cls: 0.9650  decode.loss_mask: 0.7826  decode.loss_dice: 1.0075  decode.d0.loss_cls: 2.7839  decode.d0.loss_mask: 0.8454  decode.d0.loss_dice: 1.1110  decode.d1.loss_cls: 1.1331  decode.d1.loss_mask: 0.7998  decode.d1.loss_dice: 1.1153  decode.d2.loss_cls: 1.1371  decode.d2.loss_mask: 0.8140  decode.d2.loss_dice: 1.0589  decode.d3.loss_cls: 0.9973  decode.d3.loss_mask: 0.7954  decode.d3.loss_dice: 1.0371  decode.d4.loss_cls: 0.9661  decode.d4.loss_mask: 0.7989  decode.d4.loss_dice: 1.0194  decode.d5.loss_cls: 0.9708  decode.d5.loss_mask: 0.8080  decode.d5.loss_dice: 1.0442  decode.d6.loss_cls: 0.9855  decode.d6.loss_mask: 0.8010  decode.d6.loss_dice: 1.0244  decode.d7.loss_cls: 0.9628  decode.d7.loss_mask: 0.8136  decode.d7.loss_dice: 1.0154  decode.d8.loss_cls: 0.9481  decode.d8.loss_mask: 0.8169  decode.d8.loss_dice: 1.0324
2023/05/24 10:02:35 - mmengine - INFO - Iter(train) [127250/160000]  lr: 2.3987e-06  eta: 3:56:15  time: 0.4206  data_time: 0.0097  memory: 4808  grad_norm: 93.6476  loss: 30.6581  decode.loss_cls: 0.9372  decode.loss_mask: 0.7864  decode.loss_dice: 1.1181  decode.d0.loss_cls: 2.7807  decode.d0.loss_mask: 0.8035  decode.d0.loss_dice: 1.2371  decode.d1.loss_cls: 1.0426  decode.d1.loss_mask: 0.7594  decode.d1.loss_dice: 1.1674  decode.d2.loss_cls: 1.0606  decode.d2.loss_mask: 0.7331  decode.d2.loss_dice: 1.1545  decode.d3.loss_cls: 1.0191  decode.d3.loss_mask: 0.7391  decode.d3.loss_dice: 1.1357  decode.d4.loss_cls: 0.9389  decode.d4.loss_mask: 0.7797  decode.d4.loss_dice: 1.1612  decode.d5.loss_cls: 0.9718  decode.d5.loss_mask: 0.7768  decode.d5.loss_dice: 1.1331  decode.d6.loss_cls: 0.9460  decode.d6.loss_mask: 0.7565  decode.d6.loss_dice: 1.0999  decode.d7.loss_cls: 0.9672  decode.d7.loss_mask: 0.7475  decode.d7.loss_dice: 1.0896  decode.d8.loss_cls: 0.9628  decode.d8.loss_mask: 0.7524  decode.d8.loss_dice: 1.1004
2023/05/24 10:02:59 - mmengine - INFO - Iter(train) [127300/160000]  lr: 2.3955e-06  eta: 3:55:54  time: 0.4830  data_time: 0.0108  memory: 4840  grad_norm: 89.6417  loss: 41.5963  decode.loss_cls: 1.3441  decode.loss_mask: 0.8655  decode.loss_dice: 1.5854  decode.d0.loss_cls: 3.5096  decode.d0.loss_mask: 1.0288  decode.d0.loss_dice: 1.9485  decode.d1.loss_cls: 1.5333  decode.d1.loss_mask: 0.9488  decode.d1.loss_dice: 1.7882  decode.d2.loss_cls: 1.4892  decode.d2.loss_mask: 0.8900  decode.d2.loss_dice: 1.6400  decode.d3.loss_cls: 1.4527  decode.d3.loss_mask: 0.8739  decode.d3.loss_dice: 1.5711  decode.d4.loss_cls: 1.4018  decode.d4.loss_mask: 0.8665  decode.d4.loss_dice: 1.6003  decode.d5.loss_cls: 1.3689  decode.d5.loss_mask: 0.8750  decode.d5.loss_dice: 1.5833  decode.d6.loss_cls: 1.3925  decode.d6.loss_mask: 0.8527  decode.d6.loss_dice: 1.5936  decode.d7.loss_cls: 1.3680  decode.d7.loss_mask: 0.8387  decode.d7.loss_dice: 1.5925  decode.d8.loss_cls: 1.3776  decode.d8.loss_mask: 0.8336  decode.d8.loss_dice: 1.5821
2023/05/24 10:03:22 - mmengine - INFO - Iter(train) [127350/160000]  lr: 2.3922e-06  eta: 3:55:32  time: 0.4217  data_time: 0.0101  memory: 4919  grad_norm: 100.3048  loss: 33.0536  decode.loss_cls: 1.1600  decode.loss_mask: 0.5961  decode.loss_dice: 1.2219  decode.d0.loss_cls: 3.2983  decode.d0.loss_mask: 0.6570  decode.d0.loss_dice: 1.4568  decode.d1.loss_cls: 1.4412  decode.d1.loss_mask: 0.5956  decode.d1.loss_dice: 1.3048  decode.d2.loss_cls: 1.2436  decode.d2.loss_mask: 0.6003  decode.d2.loss_dice: 1.2802  decode.d3.loss_cls: 1.2079  decode.d3.loss_mask: 0.5934  decode.d3.loss_dice: 1.2502  decode.d4.loss_cls: 1.2172  decode.d4.loss_mask: 0.5888  decode.d4.loss_dice: 1.2596  decode.d5.loss_cls: 1.1849  decode.d5.loss_mask: 0.5988  decode.d5.loss_dice: 1.2400  decode.d6.loss_cls: 1.2049  decode.d6.loss_mask: 0.6028  decode.d6.loss_dice: 1.2131  decode.d7.loss_cls: 1.1539  decode.d7.loss_mask: 0.6090  decode.d7.loss_dice: 1.2631  decode.d8.loss_cls: 1.1829  decode.d8.loss_mask: 0.5957  decode.d8.loss_dice: 1.2317
2023/05/24 10:03:43 - mmengine - INFO - Iter(train) [127400/160000]  lr: 2.3889e-06  eta: 3:55:11  time: 0.4152  data_time: 0.0099  memory: 4876  grad_norm: 78.8764  loss: 34.8018  decode.loss_cls: 1.1240  decode.loss_mask: 0.7423  decode.loss_dice: 1.2838  decode.d0.loss_cls: 3.2735  decode.d0.loss_mask: 0.8641  decode.d0.loss_dice: 1.6227  decode.d1.loss_cls: 1.2503  decode.d1.loss_mask: 0.8320  decode.d1.loss_dice: 1.4640  decode.d2.loss_cls: 1.1845  decode.d2.loss_mask: 0.7640  decode.d2.loss_dice: 1.3725  decode.d3.loss_cls: 1.1660  decode.d3.loss_mask: 0.7494  decode.d3.loss_dice: 1.3322  decode.d4.loss_cls: 1.1235  decode.d4.loss_mask: 0.7492  decode.d4.loss_dice: 1.3243  decode.d5.loss_cls: 1.1029  decode.d5.loss_mask: 0.7406  decode.d5.loss_dice: 1.3130  decode.d6.loss_cls: 1.1200  decode.d6.loss_mask: 0.7449  decode.d6.loss_dice: 1.3028  decode.d7.loss_cls: 1.0951  decode.d7.loss_mask: 0.7375  decode.d7.loss_dice: 1.2893  decode.d8.loss_cls: 1.1079  decode.d8.loss_mask: 0.7357  decode.d8.loss_dice: 1.2897
2023/05/24 10:04:04 - mmengine - INFO - Iter(train) [127450/160000]  lr: 2.3856e-06  eta: 3:54:49  time: 0.4230  data_time: 0.0101  memory: 4854  grad_norm: 85.7781  loss: 39.0811  decode.loss_cls: 1.6026  decode.loss_mask: 0.7593  decode.loss_dice: 1.2583  decode.d0.loss_cls: 3.1979  decode.d0.loss_mask: 0.8280  decode.d0.loss_dice: 1.6156  decode.d1.loss_cls: 1.7366  decode.d1.loss_mask: 0.8015  decode.d1.loss_dice: 1.4463  decode.d2.loss_cls: 1.7102  decode.d2.loss_mask: 0.7913  decode.d2.loss_dice: 1.3930  decode.d3.loss_cls: 1.5696  decode.d3.loss_mask: 0.7923  decode.d3.loss_dice: 1.3478  decode.d4.loss_cls: 1.5795  decode.d4.loss_mask: 0.7773  decode.d4.loss_dice: 1.3045  decode.d5.loss_cls: 1.6020  decode.d5.loss_mask: 0.7615  decode.d5.loss_dice: 1.3146  decode.d6.loss_cls: 1.5168  decode.d6.loss_mask: 0.7884  decode.d6.loss_dice: 1.2924  decode.d7.loss_cls: 1.5295  decode.d7.loss_mask: 0.7805  decode.d7.loss_dice: 1.3037  decode.d8.loss_cls: 1.6256  decode.d8.loss_mask: 0.7624  decode.d8.loss_dice: 1.2921
2023/05/24 10:04:25 - mmengine - INFO - Iter(train) [127500/160000]  lr: 2.3823e-06  eta: 3:54:27  time: 0.4215  data_time: 0.0103  memory: 4846  grad_norm: 138.0985  loss: 39.9880  decode.loss_cls: 1.3113  decode.loss_mask: 0.7851  decode.loss_dice: 1.6161  decode.d0.loss_cls: 3.0861  decode.d0.loss_mask: 0.8890  decode.d0.loss_dice: 1.8487  decode.d1.loss_cls: 1.4548  decode.d1.loss_mask: 0.8366  decode.d1.loss_dice: 1.7772  decode.d2.loss_cls: 1.4683  decode.d2.loss_mask: 0.8343  decode.d2.loss_dice: 1.6972  decode.d3.loss_cls: 1.4164  decode.d3.loss_mask: 0.7502  decode.d3.loss_dice: 1.6124  decode.d4.loss_cls: 1.3567  decode.d4.loss_mask: 0.7551  decode.d4.loss_dice: 1.6371  decode.d5.loss_cls: 1.3162  decode.d5.loss_mask: 0.7752  decode.d5.loss_dice: 1.6484  decode.d6.loss_cls: 1.3574  decode.d6.loss_mask: 0.7697  decode.d6.loss_dice: 1.6058  decode.d7.loss_cls: 1.2831  decode.d7.loss_mask: 0.7806  decode.d7.loss_dice: 1.6344  decode.d8.loss_cls: 1.3069  decode.d8.loss_mask: 0.7735  decode.d8.loss_dice: 1.6042
2023/05/24 10:04:46 - mmengine - INFO - Iter(train) [127550/160000]  lr: 2.3790e-06  eta: 3:54:05  time: 0.4208  data_time: 0.0099  memory: 4893  grad_norm: 79.6521  loss: 20.9678  decode.loss_cls: 0.6420  decode.loss_mask: 0.5427  decode.loss_dice: 0.6474  decode.d0.loss_cls: 2.7348  decode.d0.loss_mask: 0.5697  decode.d0.loss_dice: 0.7796  decode.d1.loss_cls: 0.6726  decode.d1.loss_mask: 0.5793  decode.d1.loss_dice: 0.7203  decode.d2.loss_cls: 0.6862  decode.d2.loss_mask: 0.5651  decode.d2.loss_dice: 0.6954  decode.d3.loss_cls: 0.6455  decode.d3.loss_mask: 0.5700  decode.d3.loss_dice: 0.6779  decode.d4.loss_cls: 0.6737  decode.d4.loss_mask: 0.5585  decode.d4.loss_dice: 0.6515  decode.d5.loss_cls: 0.6207  decode.d5.loss_mask: 0.5632  decode.d5.loss_dice: 0.6547  decode.d6.loss_cls: 0.6558  decode.d6.loss_mask: 0.5348  decode.d6.loss_dice: 0.6534  decode.d7.loss_cls: 0.6615  decode.d7.loss_mask: 0.5271  decode.d7.loss_dice: 0.6614  decode.d8.loss_cls: 0.6179  decode.d8.loss_mask: 0.5493  decode.d8.loss_dice: 0.6560
2023/05/24 10:05:08 - mmengine - INFO - Iter(train) [127600/160000]  lr: 2.3757e-06  eta: 3:53:44  time: 0.4345  data_time: 0.0099  memory: 4872  grad_norm: 100.8982  loss: 39.0759  decode.loss_cls: 1.2907  decode.loss_mask: 0.8617  decode.loss_dice: 1.4402  decode.d0.loss_cls: 3.4105  decode.d0.loss_mask: 0.8370  decode.d0.loss_dice: 1.6827  decode.d1.loss_cls: 1.5035  decode.d1.loss_mask: 0.8491  decode.d1.loss_dice: 1.5340  decode.d2.loss_cls: 1.4828  decode.d2.loss_mask: 0.8412  decode.d2.loss_dice: 1.4985  decode.d3.loss_cls: 1.3211  decode.d3.loss_mask: 0.8565  decode.d3.loss_dice: 1.4610  decode.d4.loss_cls: 1.3458  decode.d4.loss_mask: 0.8489  decode.d4.loss_dice: 1.4637  decode.d5.loss_cls: 1.3369  decode.d5.loss_mask: 0.8633  decode.d5.loss_dice: 1.4547  decode.d6.loss_cls: 1.2808  decode.d6.loss_mask: 0.8615  decode.d6.loss_dice: 1.4555  decode.d7.loss_cls: 1.3377  decode.d7.loss_mask: 0.8694  decode.d7.loss_dice: 1.4376  decode.d8.loss_cls: 1.3383  decode.d8.loss_mask: 0.8721  decode.d8.loss_dice: 1.4390
2023/05/24 10:05:29 - mmengine - INFO - Iter(train) [127650/160000]  lr: 2.3724e-06  eta: 3:53:22  time: 0.4213  data_time: 0.0101  memory: 4789  grad_norm: 95.0492  loss: 28.3166  decode.loss_cls: 0.8571  decode.loss_mask: 0.6204  decode.loss_dice: 1.0749  decode.d0.loss_cls: 2.7700  decode.d0.loss_mask: 0.7201  decode.d0.loss_dice: 1.2715  decode.d1.loss_cls: 0.9479  decode.d1.loss_mask: 0.6717  decode.d1.loss_dice: 1.1747  decode.d2.loss_cls: 0.9512  decode.d2.loss_mask: 0.6514  decode.d2.loss_dice: 1.1196  decode.d3.loss_cls: 0.8797  decode.d3.loss_mask: 0.6477  decode.d3.loss_dice: 1.1250  decode.d4.loss_cls: 0.8688  decode.d4.loss_mask: 0.6289  decode.d4.loss_dice: 1.0754  decode.d5.loss_cls: 0.8869  decode.d5.loss_mask: 0.6228  decode.d5.loss_dice: 1.0846  decode.d6.loss_cls: 0.8566  decode.d6.loss_mask: 0.6192  decode.d6.loss_dice: 1.0806  decode.d7.loss_cls: 0.8757  decode.d7.loss_mask: 0.6145  decode.d7.loss_dice: 1.0775  decode.d8.loss_cls: 0.8612  decode.d8.loss_mask: 0.6233  decode.d8.loss_dice: 1.0577
2023/05/24 10:05:50 - mmengine - INFO - Iter(train) [127700/160000]  lr: 2.3691e-06  eta: 3:53:00  time: 0.4133  data_time: 0.0099  memory: 4835  grad_norm: 123.6747  loss: 26.4363  decode.loss_cls: 0.9304  decode.loss_mask: 0.5685  decode.loss_dice: 0.8173  decode.d0.loss_cls: 2.8294  decode.d0.loss_mask: 0.6414  decode.d0.loss_dice: 1.0574  decode.d1.loss_cls: 1.0324  decode.d1.loss_mask: 0.6453  decode.d1.loss_dice: 0.9975  decode.d2.loss_cls: 1.0027  decode.d2.loss_mask: 0.6245  decode.d2.loss_dice: 0.9244  decode.d3.loss_cls: 0.9802  decode.d3.loss_mask: 0.6064  decode.d3.loss_dice: 0.8741  decode.d4.loss_cls: 0.9823  decode.d4.loss_mask: 0.6021  decode.d4.loss_dice: 0.8818  decode.d5.loss_cls: 0.9443  decode.d5.loss_mask: 0.5918  decode.d5.loss_dice: 0.8437  decode.d6.loss_cls: 0.9355  decode.d6.loss_mask: 0.5822  decode.d6.loss_dice: 0.8461  decode.d7.loss_cls: 0.9409  decode.d7.loss_mask: 0.5740  decode.d7.loss_dice: 0.8327  decode.d8.loss_cls: 0.9375  decode.d8.loss_mask: 0.5727  decode.d8.loss_dice: 0.8370
2023/05/24 10:06:12 - mmengine - INFO - Iter(train) [127750/160000]  lr: 2.3658e-06  eta: 3:52:38  time: 0.4197  data_time: 0.0098  memory: 4846  grad_norm: 99.9425  loss: 35.8558  decode.loss_cls: 1.0511  decode.loss_mask: 0.8305  decode.loss_dice: 1.4039  decode.d0.loss_cls: 3.1784  decode.d0.loss_mask: 0.8411  decode.d0.loss_dice: 1.6568  decode.d1.loss_cls: 1.1331  decode.d1.loss_mask: 0.8787  decode.d1.loss_dice: 1.5352  decode.d2.loss_cls: 1.0665  decode.d2.loss_mask: 0.8655  decode.d2.loss_dice: 1.4790  decode.d3.loss_cls: 1.0773  decode.d3.loss_mask: 0.8387  decode.d3.loss_dice: 1.4046  decode.d4.loss_cls: 1.0783  decode.d4.loss_mask: 0.8494  decode.d4.loss_dice: 1.4329  decode.d5.loss_cls: 1.0944  decode.d5.loss_mask: 0.8556  decode.d5.loss_dice: 1.4178  decode.d6.loss_cls: 1.0504  decode.d6.loss_mask: 0.8287  decode.d6.loss_dice: 1.4111  decode.d7.loss_cls: 1.0451  decode.d7.loss_mask: 0.8318  decode.d7.loss_dice: 1.4138  decode.d8.loss_cls: 1.0493  decode.d8.loss_mask: 0.8297  decode.d8.loss_dice: 1.4271
2023/05/24 10:06:33 - mmengine - INFO - Iter(train) [127800/160000]  lr: 2.3625e-06  eta: 3:52:17  time: 0.4265  data_time: 0.0105  memory: 4857  grad_norm: 120.6339  loss: 37.0124  decode.loss_cls: 1.2016  decode.loss_mask: 0.7453  decode.loss_dice: 1.4455  decode.d0.loss_cls: 3.1388  decode.d0.loss_mask: 0.7860  decode.d0.loss_dice: 1.6341  decode.d1.loss_cls: 1.3604  decode.d1.loss_mask: 0.7723  decode.d1.loss_dice: 1.5319  decode.d2.loss_cls: 1.2511  decode.d2.loss_mask: 0.7896  decode.d2.loss_dice: 1.5046  decode.d3.loss_cls: 1.2545  decode.d3.loss_mask: 0.7850  decode.d3.loss_dice: 1.4974  decode.d4.loss_cls: 1.2105  decode.d4.loss_mask: 0.7957  decode.d4.loss_dice: 1.4923  decode.d5.loss_cls: 1.2063  decode.d5.loss_mask: 0.8175  decode.d5.loss_dice: 1.4703  decode.d6.loss_cls: 1.2338  decode.d6.loss_mask: 0.7622  decode.d6.loss_dice: 1.4472  decode.d7.loss_cls: 1.2250  decode.d7.loss_mask: 0.7571  decode.d7.loss_dice: 1.4387  decode.d8.loss_cls: 1.2313  decode.d8.loss_mask: 0.7812  decode.d8.loss_dice: 1.4451
2023/05/24 10:06:54 - mmengine - INFO - Iter(train) [127850/160000]  lr: 2.3592e-06  eta: 3:51:55  time: 0.4292  data_time: 0.0106  memory: 4804  grad_norm: 93.0231  loss: 40.7750  decode.loss_cls: 1.3320  decode.loss_mask: 0.8982  decode.loss_dice: 1.5724  decode.d0.loss_cls: 3.1360  decode.d0.loss_mask: 0.9024  decode.d0.loss_dice: 1.8582  decode.d1.loss_cls: 1.5204  decode.d1.loss_mask: 0.9387  decode.d1.loss_dice: 1.7260  decode.d2.loss_cls: 1.3863  decode.d2.loss_mask: 0.9323  decode.d2.loss_dice: 1.6630  decode.d3.loss_cls: 1.3734  decode.d3.loss_mask: 0.8777  decode.d3.loss_dice: 1.6027  decode.d4.loss_cls: 1.3205  decode.d4.loss_mask: 0.8874  decode.d4.loss_dice: 1.6277  decode.d5.loss_cls: 1.3165  decode.d5.loss_mask: 0.8895  decode.d5.loss_dice: 1.5980  decode.d6.loss_cls: 1.2909  decode.d6.loss_mask: 0.9150  decode.d6.loss_dice: 1.6029  decode.d7.loss_cls: 1.3307  decode.d7.loss_mask: 0.9026  decode.d7.loss_dice: 1.5739  decode.d8.loss_cls: 1.3229  decode.d8.loss_mask: 0.9069  decode.d8.loss_dice: 1.5699
2023/05/24 10:07:17 - mmengine - INFO - Iter(train) [127900/160000]  lr: 2.3559e-06  eta: 3:51:34  time: 0.4799  data_time: 0.0098  memory: 4866  grad_norm: 98.9424  loss: 30.8806  decode.loss_cls: 0.9830  decode.loss_mask: 0.6731  decode.loss_dice: 1.1843  decode.d0.loss_cls: 2.8301  decode.d0.loss_mask: 0.6978  decode.d0.loss_dice: 1.3849  decode.d1.loss_cls: 1.1046  decode.d1.loss_mask: 0.7032  decode.d1.loss_dice: 1.2551  decode.d2.loss_cls: 1.0560  decode.d2.loss_mask: 0.7135  decode.d2.loss_dice: 1.2296  decode.d3.loss_cls: 1.0409  decode.d3.loss_mask: 0.6505  decode.d3.loss_dice: 1.2126  decode.d4.loss_cls: 0.9772  decode.d4.loss_mask: 0.6580  decode.d4.loss_dice: 1.2062  decode.d5.loss_cls: 0.9794  decode.d5.loss_mask: 0.6698  decode.d5.loss_dice: 1.1959  decode.d6.loss_cls: 0.9808  decode.d6.loss_mask: 0.6734  decode.d6.loss_dice: 1.1871  decode.d7.loss_cls: 0.9565  decode.d7.loss_mask: 0.6726  decode.d7.loss_dice: 1.1764  decode.d8.loss_cls: 0.9777  decode.d8.loss_mask: 0.6634  decode.d8.loss_dice: 1.1870
2023/05/24 10:07:40 - mmengine - INFO - Iter(train) [127950/160000]  lr: 2.3526e-06  eta: 3:51:12  time: 0.4150  data_time: 0.0099  memory: 4869  grad_norm: 93.7352  loss: 28.4171  decode.loss_cls: 1.1012  decode.loss_mask: 0.6060  decode.loss_dice: 0.8959  decode.d0.loss_cls: 2.8737  decode.d0.loss_mask: 0.6888  decode.d0.loss_dice: 1.0654  decode.d1.loss_cls: 1.1341  decode.d1.loss_mask: 0.6610  decode.d1.loss_dice: 0.9652  decode.d2.loss_cls: 1.1356  decode.d2.loss_mask: 0.6720  decode.d2.loss_dice: 0.9188  decode.d3.loss_cls: 1.2074  decode.d3.loss_mask: 0.6055  decode.d3.loss_dice: 0.9199  decode.d4.loss_cls: 1.1172  decode.d4.loss_mask: 0.6227  decode.d4.loss_dice: 0.9022  decode.d5.loss_cls: 1.0088  decode.d5.loss_mask: 0.6370  decode.d5.loss_dice: 0.9227  decode.d6.loss_cls: 1.0664  decode.d6.loss_mask: 0.6165  decode.d6.loss_dice: 0.8930  decode.d7.loss_cls: 1.1174  decode.d7.loss_mask: 0.5999  decode.d7.loss_dice: 0.8826  decode.d8.loss_cls: 1.0924  decode.d8.loss_mask: 0.6156  decode.d8.loss_dice: 0.8720
2023/05/24 10:08:01 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 10:08:01 - mmengine - INFO - Iter(train) [128000/160000]  lr: 2.3493e-06  eta: 3:50:50  time: 0.4433  data_time: 0.0100  memory: 4864  grad_norm: 87.4675  loss: 42.2294  decode.loss_cls: 1.2399  decode.loss_mask: 0.8591  decode.loss_dice: 1.7887  decode.d0.loss_cls: 3.4646  decode.d0.loss_mask: 0.8791  decode.d0.loss_dice: 2.0461  decode.d1.loss_cls: 1.2847  decode.d1.loss_mask: 0.8924  decode.d1.loss_dice: 1.9674  decode.d2.loss_cls: 1.2964  decode.d2.loss_mask: 0.9122  decode.d2.loss_dice: 1.8909  decode.d3.loss_cls: 1.3007  decode.d3.loss_mask: 0.8451  decode.d3.loss_dice: 1.8604  decode.d4.loss_cls: 1.2703  decode.d4.loss_mask: 0.8712  decode.d4.loss_dice: 1.8414  decode.d5.loss_cls: 1.2524  decode.d5.loss_mask: 0.8923  decode.d5.loss_dice: 1.8551  decode.d6.loss_cls: 1.2778  decode.d6.loss_mask: 0.8575  decode.d6.loss_dice: 1.8003  decode.d7.loss_cls: 1.2577  decode.d7.loss_mask: 0.8532  decode.d7.loss_dice: 1.7990  decode.d8.loss_cls: 1.2777  decode.d8.loss_mask: 0.8359  decode.d8.loss_dice: 1.7599
2023/05/24 10:08:01 - mmengine - INFO - Saving checkpoint at 128000 iterations
2023/05/24 10:08:28 - mmengine - INFO - Iter(train) [128050/160000]  lr: 2.3459e-06  eta: 3:50:30  time: 0.4189  data_time: 0.0102  memory: 4844  grad_norm: 97.2935  loss: 34.8181  decode.loss_cls: 1.1725  decode.loss_mask: 0.6767  decode.loss_dice: 1.3837  decode.d0.loss_cls: 2.9804  decode.d0.loss_mask: 0.7512  decode.d0.loss_dice: 1.6417  decode.d1.loss_cls: 1.2424  decode.d1.loss_mask: 0.7761  decode.d1.loss_dice: 1.5329  decode.d2.loss_cls: 1.2457  decode.d2.loss_mask: 0.7300  decode.d2.loss_dice: 1.4046  decode.d3.loss_cls: 1.1621  decode.d3.loss_mask: 0.6800  decode.d3.loss_dice: 1.3814  decode.d4.loss_cls: 1.0936  decode.d4.loss_mask: 0.7046  decode.d4.loss_dice: 1.3983  decode.d5.loss_cls: 1.1007  decode.d5.loss_mask: 0.6861  decode.d5.loss_dice: 1.4023  decode.d6.loss_cls: 1.1586  decode.d6.loss_mask: 0.6844  decode.d6.loss_dice: 1.3836  decode.d7.loss_cls: 1.1555  decode.d7.loss_mask: 0.6941  decode.d7.loss_dice: 1.3895  decode.d8.loss_cls: 1.1089  decode.d8.loss_mask: 0.7194  decode.d8.loss_dice: 1.3770
2023/05/24 10:08:49 - mmengine - INFO - Iter(train) [128100/160000]  lr: 2.3426e-06  eta: 3:50:08  time: 0.4188  data_time: 0.0098  memory: 4866  grad_norm: 91.3424  loss: 31.2242  decode.loss_cls: 1.0956  decode.loss_mask: 0.6146  decode.loss_dice: 1.1423  decode.d0.loss_cls: 3.2091  decode.d0.loss_mask: 0.6125  decode.d0.loss_dice: 1.3091  decode.d1.loss_cls: 1.0896  decode.d1.loss_mask: 0.6620  decode.d1.loss_dice: 1.2137  decode.d2.loss_cls: 1.1286  decode.d2.loss_mask: 0.6901  decode.d2.loss_dice: 1.2127  decode.d3.loss_cls: 1.1333  decode.d3.loss_mask: 0.6320  decode.d3.loss_dice: 1.1800  decode.d4.loss_cls: 1.1801  decode.d4.loss_mask: 0.6398  decode.d4.loss_dice: 1.1293  decode.d5.loss_cls: 1.1313  decode.d5.loss_mask: 0.6393  decode.d5.loss_dice: 1.1419  decode.d6.loss_cls: 1.0828  decode.d6.loss_mask: 0.6298  decode.d6.loss_dice: 1.1180  decode.d7.loss_cls: 1.1013  decode.d7.loss_mask: 0.6304  decode.d7.loss_dice: 1.0919  decode.d8.loss_cls: 1.0820  decode.d8.loss_mask: 0.6102  decode.d8.loss_dice: 1.0910
2023/05/24 10:09:10 - mmengine - INFO - Iter(train) [128150/160000]  lr: 2.3393e-06  eta: 3:49:47  time: 0.4301  data_time: 0.0103  memory: 4876  grad_norm: 94.1415  loss: 30.7327  decode.loss_cls: 0.8712  decode.loss_mask: 0.8140  decode.loss_dice: 1.1430  decode.d0.loss_cls: 2.7793  decode.d0.loss_mask: 0.8715  decode.d0.loss_dice: 1.3479  decode.d1.loss_cls: 0.9395  decode.d1.loss_mask: 0.8356  decode.d1.loss_dice: 1.1918  decode.d2.loss_cls: 0.9412  decode.d2.loss_mask: 0.8223  decode.d2.loss_dice: 1.1700  decode.d3.loss_cls: 0.8842  decode.d3.loss_mask: 0.7973  decode.d3.loss_dice: 1.1534  decode.d4.loss_cls: 0.8204  decode.d4.loss_mask: 0.8296  decode.d4.loss_dice: 1.1495  decode.d5.loss_cls: 0.8552  decode.d5.loss_mask: 0.8138  decode.d5.loss_dice: 1.1488  decode.d6.loss_cls: 0.9001  decode.d6.loss_mask: 0.8298  decode.d6.loss_dice: 1.1438  decode.d7.loss_cls: 0.9135  decode.d7.loss_mask: 0.7945  decode.d7.loss_dice: 1.1342  decode.d8.loss_cls: 0.8943  decode.d8.loss_mask: 0.8120  decode.d8.loss_dice: 1.1310
2023/05/24 10:09:32 - mmengine - INFO - Iter(train) [128200/160000]  lr: 2.3360e-06  eta: 3:49:25  time: 0.4221  data_time: 0.0097  memory: 4847  grad_norm: 82.2644  loss: 32.9209  decode.loss_cls: 1.1478  decode.loss_mask: 0.8067  decode.loss_dice: 1.0644  decode.d0.loss_cls: 3.1948  decode.d0.loss_mask: 0.8560  decode.d0.loss_dice: 1.2748  decode.d1.loss_cls: 1.2956  decode.d1.loss_mask: 0.8530  decode.d1.loss_dice: 1.2092  decode.d2.loss_cls: 1.2002  decode.d2.loss_mask: 0.8368  decode.d2.loss_dice: 1.1239  decode.d3.loss_cls: 1.1333  decode.d3.loss_mask: 0.8143  decode.d3.loss_dice: 1.0932  decode.d4.loss_cls: 1.1530  decode.d4.loss_mask: 0.7878  decode.d4.loss_dice: 1.1019  decode.d5.loss_cls: 1.1416  decode.d5.loss_mask: 0.7968  decode.d5.loss_dice: 1.0616  decode.d6.loss_cls: 1.1035  decode.d6.loss_mask: 0.8151  decode.d6.loss_dice: 1.0956  decode.d7.loss_cls: 1.0785  decode.d7.loss_mask: 0.8112  decode.d7.loss_dice: 1.0947  decode.d8.loss_cls: 1.1213  decode.d8.loss_mask: 0.7808  decode.d8.loss_dice: 1.0737
2023/05/24 10:09:53 - mmengine - INFO - Iter(train) [128250/160000]  lr: 2.3327e-06  eta: 3:49:03  time: 0.4284  data_time: 0.0099  memory: 4828  grad_norm: 90.2475  loss: 37.5445  decode.loss_cls: 1.4028  decode.loss_mask: 0.7512  decode.loss_dice: 1.2320  decode.d0.loss_cls: 3.3840  decode.d0.loss_mask: 0.8079  decode.d0.loss_dice: 1.5581  decode.d1.loss_cls: 1.5357  decode.d1.loss_mask: 0.8313  decode.d1.loss_dice: 1.4659  decode.d2.loss_cls: 1.4757  decode.d2.loss_mask: 0.7727  decode.d2.loss_dice: 1.3864  decode.d3.loss_cls: 1.4591  decode.d3.loss_mask: 0.7699  decode.d3.loss_dice: 1.3551  decode.d4.loss_cls: 1.4238  decode.d4.loss_mask: 0.7683  decode.d4.loss_dice: 1.3310  decode.d5.loss_cls: 1.3865  decode.d5.loss_mask: 0.7555  decode.d5.loss_dice: 1.3207  decode.d6.loss_cls: 1.3961  decode.d6.loss_mask: 0.7473  decode.d6.loss_dice: 1.3174  decode.d7.loss_cls: 1.4485  decode.d7.loss_mask: 0.7431  decode.d7.loss_dice: 1.2991  decode.d8.loss_cls: 1.3972  decode.d8.loss_mask: 0.7541  decode.d8.loss_dice: 1.2679
2023/05/24 10:10:15 - mmengine - INFO - Iter(train) [128300/160000]  lr: 2.3294e-06  eta: 3:48:42  time: 0.4392  data_time: 0.0098  memory: 4877  grad_norm: 102.9372  loss: 38.9079  decode.loss_cls: 1.1260  decode.loss_mask: 0.8148  decode.loss_dice: 1.6104  decode.d0.loss_cls: 3.3579  decode.d0.loss_mask: 0.8658  decode.d0.loss_dice: 1.9314  decode.d1.loss_cls: 1.3401  decode.d1.loss_mask: 0.8092  decode.d1.loss_dice: 1.7629  decode.d2.loss_cls: 1.1915  decode.d2.loss_mask: 0.8059  decode.d2.loss_dice: 1.6918  decode.d3.loss_cls: 1.2267  decode.d3.loss_mask: 0.7965  decode.d3.loss_dice: 1.6216  decode.d4.loss_cls: 1.1699  decode.d4.loss_mask: 0.8140  decode.d4.loss_dice: 1.6227  decode.d5.loss_cls: 1.1168  decode.d5.loss_mask: 0.8111  decode.d5.loss_dice: 1.6450  decode.d6.loss_cls: 1.1490  decode.d6.loss_mask: 0.8156  decode.d6.loss_dice: 1.6088  decode.d7.loss_cls: 1.1345  decode.d7.loss_mask: 0.8173  decode.d7.loss_dice: 1.6457  decode.d8.loss_cls: 1.1625  decode.d8.loss_mask: 0.8188  decode.d8.loss_dice: 1.6236
2023/05/24 10:10:36 - mmengine - INFO - Iter(train) [128350/160000]  lr: 2.3261e-06  eta: 3:48:20  time: 0.4323  data_time: 0.0099  memory: 4878  grad_norm: 111.8577  loss: 35.2625  decode.loss_cls: 1.1998  decode.loss_mask: 0.7706  decode.loss_dice: 1.2198  decode.d0.loss_cls: 3.2440  decode.d0.loss_mask: 0.8465  decode.d0.loss_dice: 1.5371  decode.d1.loss_cls: 1.3226  decode.d1.loss_mask: 0.8459  decode.d1.loss_dice: 1.4175  decode.d2.loss_cls: 1.2828  decode.d2.loss_mask: 0.8016  decode.d2.loss_dice: 1.3566  decode.d3.loss_cls: 1.2053  decode.d3.loss_mask: 0.7995  decode.d3.loss_dice: 1.2999  decode.d4.loss_cls: 1.1577  decode.d4.loss_mask: 0.8027  decode.d4.loss_dice: 1.2839  decode.d5.loss_cls: 1.2098  decode.d5.loss_mask: 0.7808  decode.d5.loss_dice: 1.2729  decode.d6.loss_cls: 1.1833  decode.d6.loss_mask: 0.7875  decode.d6.loss_dice: 1.2130  decode.d7.loss_cls: 1.1654  decode.d7.loss_mask: 0.7924  decode.d7.loss_dice: 1.2354  decode.d8.loss_cls: 1.1905  decode.d8.loss_mask: 0.7902  decode.d8.loss_dice: 1.2475
2023/05/24 10:10:58 - mmengine - INFO - Iter(train) [128400/160000]  lr: 2.3228e-06  eta: 3:47:58  time: 0.4274  data_time: 0.0102  memory: 4873  grad_norm: 98.3518  loss: 28.4390  decode.loss_cls: 0.9144  decode.loss_mask: 0.7110  decode.loss_dice: 0.8851  decode.d0.loss_cls: 2.8803  decode.d0.loss_mask: 0.7751  decode.d0.loss_dice: 1.0338  decode.d1.loss_cls: 1.0838  decode.d1.loss_mask: 0.8201  decode.d1.loss_dice: 0.9904  decode.d2.loss_cls: 1.0277  decode.d2.loss_mask: 0.8055  decode.d2.loss_dice: 0.9560  decode.d3.loss_cls: 1.0469  decode.d3.loss_mask: 0.7235  decode.d3.loss_dice: 0.8917  decode.d4.loss_cls: 1.0362  decode.d4.loss_mask: 0.6939  decode.d4.loss_dice: 0.8943  decode.d5.loss_cls: 1.0153  decode.d5.loss_mask: 0.6877  decode.d5.loss_dice: 0.8748  decode.d6.loss_cls: 1.0274  decode.d6.loss_mask: 0.6933  decode.d6.loss_dice: 0.8779  decode.d7.loss_cls: 0.9676  decode.d7.loss_mask: 0.7054  decode.d7.loss_dice: 0.8963  decode.d8.loss_cls: 0.9373  decode.d8.loss_mask: 0.7003  decode.d8.loss_dice: 0.8856
2023/05/24 10:11:20 - mmengine - INFO - Iter(train) [128450/160000]  lr: 2.3195e-06  eta: 3:47:37  time: 0.4486  data_time: 0.0097  memory: 4856  grad_norm: 114.7347  loss: 36.8546  decode.loss_cls: 1.1984  decode.loss_mask: 0.8449  decode.loss_dice: 1.3363  decode.d0.loss_cls: 3.2444  decode.d0.loss_mask: 0.9068  decode.d0.loss_dice: 1.5110  decode.d1.loss_cls: 1.4482  decode.d1.loss_mask: 0.9277  decode.d1.loss_dice: 1.4003  decode.d2.loss_cls: 1.3604  decode.d2.loss_mask: 0.8503  decode.d2.loss_dice: 1.3501  decode.d3.loss_cls: 1.2910  decode.d3.loss_mask: 0.8794  decode.d3.loss_dice: 1.3276  decode.d4.loss_cls: 1.2367  decode.d4.loss_mask: 0.8750  decode.d4.loss_dice: 1.3320  decode.d5.loss_cls: 1.2285  decode.d5.loss_mask: 0.8496  decode.d5.loss_dice: 1.3009  decode.d6.loss_cls: 1.2154  decode.d6.loss_mask: 0.8556  decode.d6.loss_dice: 1.3083  decode.d7.loss_cls: 1.2751  decode.d7.loss_mask: 0.8008  decode.d7.loss_dice: 1.2782  decode.d8.loss_cls: 1.2786  decode.d8.loss_mask: 0.8299  decode.d8.loss_dice: 1.3135
2023/05/24 10:11:41 - mmengine - INFO - Iter(train) [128500/160000]  lr: 2.3162e-06  eta: 3:47:15  time: 0.4219  data_time: 0.0102  memory: 4820  grad_norm: 98.3143  loss: 34.1132  decode.loss_cls: 1.2476  decode.loss_mask: 0.6914  decode.loss_dice: 1.1496  decode.d0.loss_cls: 3.2716  decode.d0.loss_mask: 0.7183  decode.d0.loss_dice: 1.3924  decode.d1.loss_cls: 1.4100  decode.d1.loss_mask: 0.7515  decode.d1.loss_dice: 1.2365  decode.d2.loss_cls: 1.2949  decode.d2.loss_mask: 0.7479  decode.d2.loss_dice: 1.2256  decode.d3.loss_cls: 1.3183  decode.d3.loss_mask: 0.7291  decode.d3.loss_dice: 1.1770  decode.d4.loss_cls: 1.2684  decode.d4.loss_mask: 0.7143  decode.d4.loss_dice: 1.1907  decode.d5.loss_cls: 1.2643  decode.d5.loss_mask: 0.7174  decode.d5.loss_dice: 1.1413  decode.d6.loss_cls: 1.2770  decode.d6.loss_mask: 0.7137  decode.d6.loss_dice: 1.1917  decode.d7.loss_cls: 1.2639  decode.d7.loss_mask: 0.7080  decode.d7.loss_dice: 1.1623  decode.d8.loss_cls: 1.3015  decode.d8.loss_mask: 0.6757  decode.d8.loss_dice: 1.1615
2023/05/24 10:12:03 - mmengine - INFO - Iter(train) [128550/160000]  lr: 2.3129e-06  eta: 3:46:53  time: 0.4279  data_time: 0.0100  memory: 4880  grad_norm: 94.8478  loss: 36.9505  decode.loss_cls: 1.1449  decode.loss_mask: 0.7866  decode.loss_dice: 1.5117  decode.d0.loss_cls: 3.0774  decode.d0.loss_mask: 0.8386  decode.d0.loss_dice: 1.7244  decode.d1.loss_cls: 1.2660  decode.d1.loss_mask: 0.8037  decode.d1.loss_dice: 1.6549  decode.d2.loss_cls: 1.1733  decode.d2.loss_mask: 0.8099  decode.d2.loss_dice: 1.5665  decode.d3.loss_cls: 1.0972  decode.d3.loss_mask: 0.8151  decode.d3.loss_dice: 1.5320  decode.d4.loss_cls: 1.0942  decode.d4.loss_mask: 0.8018  decode.d4.loss_dice: 1.5742  decode.d5.loss_cls: 1.0581  decode.d5.loss_mask: 0.8155  decode.d5.loss_dice: 1.5355  decode.d6.loss_cls: 1.0872  decode.d6.loss_mask: 0.8510  decode.d6.loss_dice: 1.5605  decode.d7.loss_cls: 1.0745  decode.d7.loss_mask: 0.8063  decode.d7.loss_dice: 1.5164  decode.d8.loss_cls: 1.0774  decode.d8.loss_mask: 0.7994  decode.d8.loss_dice: 1.4962
2023/05/24 10:12:25 - mmengine - INFO - Iter(train) [128600/160000]  lr: 2.3096e-06  eta: 3:46:32  time: 0.4184  data_time: 0.0100  memory: 4845  grad_norm: 94.9765  loss: 35.2136  decode.loss_cls: 1.1849  decode.loss_mask: 0.7110  decode.loss_dice: 1.2820  decode.d0.loss_cls: 3.1529  decode.d0.loss_mask: 0.7828  decode.d0.loss_dice: 1.4812  decode.d1.loss_cls: 1.3453  decode.d1.loss_mask: 0.7803  decode.d1.loss_dice: 1.4654  decode.d2.loss_cls: 1.2471  decode.d2.loss_mask: 0.7651  decode.d2.loss_dice: 1.3947  decode.d3.loss_cls: 1.1608  decode.d3.loss_mask: 0.7501  decode.d3.loss_dice: 1.3994  decode.d4.loss_cls: 1.1871  decode.d4.loss_mask: 0.7599  decode.d4.loss_dice: 1.3519  decode.d5.loss_cls: 1.1392  decode.d5.loss_mask: 0.7564  decode.d5.loss_dice: 1.3714  decode.d6.loss_cls: 1.1683  decode.d6.loss_mask: 0.7520  decode.d6.loss_dice: 1.3454  decode.d7.loss_cls: 1.2109  decode.d7.loss_mask: 0.7382  decode.d7.loss_dice: 1.3332  decode.d8.loss_cls: 1.1579  decode.d8.loss_mask: 0.7203  decode.d8.loss_dice: 1.3184
2023/05/24 10:12:47 - mmengine - INFO - Iter(train) [128650/160000]  lr: 2.3063e-06  eta: 3:46:10  time: 0.4268  data_time: 0.0101  memory: 4886  grad_norm: 97.8599  loss: 31.7547  decode.loss_cls: 0.9242  decode.loss_mask: 0.7610  decode.loss_dice: 1.2234  decode.d0.loss_cls: 2.8800  decode.d0.loss_mask: 0.8351  decode.d0.loss_dice: 1.3651  decode.d1.loss_cls: 1.0317  decode.d1.loss_mask: 0.8215  decode.d1.loss_dice: 1.3310  decode.d2.loss_cls: 1.0605  decode.d2.loss_mask: 0.7638  decode.d2.loss_dice: 1.2561  decode.d3.loss_cls: 1.0277  decode.d3.loss_mask: 0.7214  decode.d3.loss_dice: 1.2422  decode.d4.loss_cls: 0.9668  decode.d4.loss_mask: 0.7075  decode.d4.loss_dice: 1.2325  decode.d5.loss_cls: 0.9213  decode.d5.loss_mask: 0.7420  decode.d5.loss_dice: 1.2235  decode.d6.loss_cls: 0.9278  decode.d6.loss_mask: 0.7472  decode.d6.loss_dice: 1.2609  decode.d7.loss_cls: 0.9122  decode.d7.loss_mask: 0.7501  decode.d7.loss_dice: 1.2279  decode.d8.loss_cls: 0.9021  decode.d8.loss_mask: 0.7516  decode.d8.loss_dice: 1.2365
2023/05/24 10:13:08 - mmengine - INFO - Iter(train) [128700/160000]  lr: 2.3029e-06  eta: 3:45:48  time: 0.4200  data_time: 0.0099  memory: 4878  grad_norm: 85.9849  loss: 34.8310  decode.loss_cls: 1.0637  decode.loss_mask: 0.8049  decode.loss_dice: 1.3699  decode.d0.loss_cls: 2.8090  decode.d0.loss_mask: 0.8765  decode.d0.loss_dice: 1.5286  decode.d1.loss_cls: 1.2153  decode.d1.loss_mask: 0.8038  decode.d1.loss_dice: 1.4193  decode.d2.loss_cls: 1.1585  decode.d2.loss_mask: 0.7785  decode.d2.loss_dice: 1.3609  decode.d3.loss_cls: 1.1303  decode.d3.loss_mask: 0.8049  decode.d3.loss_dice: 1.3578  decode.d4.loss_cls: 1.0766  decode.d4.loss_mask: 0.8109  decode.d4.loss_dice: 1.3482  decode.d5.loss_cls: 1.0956  decode.d5.loss_mask: 0.8179  decode.d5.loss_dice: 1.3344  decode.d6.loss_cls: 1.1097  decode.d6.loss_mask: 0.8157  decode.d6.loss_dice: 1.3610  decode.d7.loss_cls: 1.0821  decode.d7.loss_mask: 0.8272  decode.d7.loss_dice: 1.3775  decode.d8.loss_cls: 1.0691  decode.d8.loss_mask: 0.8271  decode.d8.loss_dice: 1.3961
2023/05/24 10:13:29 - mmengine - INFO - Iter(train) [128750/160000]  lr: 2.2996e-06  eta: 3:45:27  time: 0.4214  data_time: 0.0100  memory: 4836  grad_norm: 93.5575  loss: 32.1018  decode.loss_cls: 1.1321  decode.loss_mask: 0.7321  decode.loss_dice: 1.1026  decode.d0.loss_cls: 2.8232  decode.d0.loss_mask: 0.8229  decode.d0.loss_dice: 1.3266  decode.d1.loss_cls: 1.3068  decode.d1.loss_mask: 0.7587  decode.d1.loss_dice: 1.1455  decode.d2.loss_cls: 1.1797  decode.d2.loss_mask: 0.7360  decode.d2.loss_dice: 1.1583  decode.d3.loss_cls: 1.1648  decode.d3.loss_mask: 0.7241  decode.d3.loss_dice: 1.1286  decode.d4.loss_cls: 1.1203  decode.d4.loss_mask: 0.7401  decode.d4.loss_dice: 1.1208  decode.d5.loss_cls: 1.0900  decode.d5.loss_mask: 0.7297  decode.d5.loss_dice: 1.1210  decode.d6.loss_cls: 1.0843  decode.d6.loss_mask: 0.7263  decode.d6.loss_dice: 1.1272  decode.d7.loss_cls: 1.1554  decode.d7.loss_mask: 0.7305  decode.d7.loss_dice: 1.1313  decode.d8.loss_cls: 1.1389  decode.d8.loss_mask: 0.7302  decode.d8.loss_dice: 1.1141
2023/05/24 10:13:51 - mmengine - INFO - Iter(train) [128800/160000]  lr: 2.2963e-06  eta: 3:45:05  time: 0.4307  data_time: 0.0099  memory: 4843  grad_norm: 87.4195  loss: 32.1289  decode.loss_cls: 1.2256  decode.loss_mask: 0.6378  decode.loss_dice: 1.0804  decode.d0.loss_cls: 3.1335  decode.d0.loss_mask: 0.7548  decode.d0.loss_dice: 1.2586  decode.d1.loss_cls: 1.3145  decode.d1.loss_mask: 0.7039  decode.d1.loss_dice: 1.1615  decode.d2.loss_cls: 1.3316  decode.d2.loss_mask: 0.6840  decode.d2.loss_dice: 1.1350  decode.d3.loss_cls: 1.2542  decode.d3.loss_mask: 0.6643  decode.d3.loss_dice: 1.0989  decode.d4.loss_cls: 1.1818  decode.d4.loss_mask: 0.6882  decode.d4.loss_dice: 1.1464  decode.d5.loss_cls: 1.1575  decode.d5.loss_mask: 0.6646  decode.d5.loss_dice: 1.0965  decode.d6.loss_cls: 1.1664  decode.d6.loss_mask: 0.6615  decode.d6.loss_dice: 1.0884  decode.d7.loss_cls: 1.1731  decode.d7.loss_mask: 0.6624  decode.d7.loss_dice: 1.0789  decode.d8.loss_cls: 1.2064  decode.d8.loss_mask: 0.6350  decode.d8.loss_dice: 1.0833
2023/05/24 10:14:12 - mmengine - INFO - Iter(train) [128850/160000]  lr: 2.2930e-06  eta: 3:44:43  time: 0.4219  data_time: 0.0098  memory: 4821  grad_norm: 98.1233  loss: 35.3313  decode.loss_cls: 1.2255  decode.loss_mask: 0.7650  decode.loss_dice: 1.2059  decode.d0.loss_cls: 3.2325  decode.d0.loss_mask: 0.7630  decode.d0.loss_dice: 1.3929  decode.d1.loss_cls: 1.4023  decode.d1.loss_mask: 0.7968  decode.d1.loss_dice: 1.2838  decode.d2.loss_cls: 1.4344  decode.d2.loss_mask: 0.8061  decode.d2.loss_dice: 1.2770  decode.d3.loss_cls: 1.3340  decode.d3.loss_mask: 0.8030  decode.d3.loss_dice: 1.2538  decode.d4.loss_cls: 1.2812  decode.d4.loss_mask: 0.8082  decode.d4.loss_dice: 1.2540  decode.d5.loss_cls: 1.2631  decode.d5.loss_mask: 0.8308  decode.d5.loss_dice: 1.2261  decode.d6.loss_cls: 1.2702  decode.d6.loss_mask: 0.7753  decode.d6.loss_dice: 1.2211  decode.d7.loss_cls: 1.2207  decode.d7.loss_mask: 0.7923  decode.d7.loss_dice: 1.1995  decode.d8.loss_cls: 1.2393  decode.d8.loss_mask: 0.7593  decode.d8.loss_dice: 1.2142
2023/05/24 10:14:33 - mmengine - INFO - Iter(train) [128900/160000]  lr: 2.2897e-06  eta: 3:44:22  time: 0.4233  data_time: 0.0101  memory: 4829  grad_norm: 94.8634  loss: 31.4882  decode.loss_cls: 0.9319  decode.loss_mask: 0.8236  decode.loss_dice: 1.1814  decode.d0.loss_cls: 2.5005  decode.d0.loss_mask: 0.9001  decode.d0.loss_dice: 1.3942  decode.d1.loss_cls: 0.9481  decode.d1.loss_mask: 0.8397  decode.d1.loss_dice: 1.3008  decode.d2.loss_cls: 0.9645  decode.d2.loss_mask: 0.8451  decode.d2.loss_dice: 1.2307  decode.d3.loss_cls: 0.8950  decode.d3.loss_mask: 0.8479  decode.d3.loss_dice: 1.2388  decode.d4.loss_cls: 0.8926  decode.d4.loss_mask: 0.8208  decode.d4.loss_dice: 1.2379  decode.d5.loss_cls: 0.8802  decode.d5.loss_mask: 0.8352  decode.d5.loss_dice: 1.2017  decode.d6.loss_cls: 0.9007  decode.d6.loss_mask: 0.8180  decode.d6.loss_dice: 1.1972  decode.d7.loss_cls: 0.9201  decode.d7.loss_mask: 0.8356  decode.d7.loss_dice: 1.1733  decode.d8.loss_cls: 0.8962  decode.d8.loss_mask: 0.8371  decode.d8.loss_dice: 1.1988
2023/05/24 10:14:55 - mmengine - INFO - Iter(train) [128950/160000]  lr: 2.2864e-06  eta: 3:44:00  time: 0.4219  data_time: 0.0099  memory: 4822  grad_norm: 100.2135  loss: 26.8292  decode.loss_cls: 0.9243  decode.loss_mask: 0.6240  decode.loss_dice: 0.8302  decode.d0.loss_cls: 2.7533  decode.d0.loss_mask: 0.5989  decode.d0.loss_dice: 0.9421  decode.d1.loss_cls: 1.1398  decode.d1.loss_mask: 0.6734  decode.d1.loss_dice: 0.9099  decode.d2.loss_cls: 1.0875  decode.d2.loss_mask: 0.6321  decode.d2.loss_dice: 0.8842  decode.d3.loss_cls: 0.9719  decode.d3.loss_mask: 0.6528  decode.d3.loss_dice: 0.8844  decode.d4.loss_cls: 0.9504  decode.d4.loss_mask: 0.6695  decode.d4.loss_dice: 0.8657  decode.d5.loss_cls: 0.9983  decode.d5.loss_mask: 0.6483  decode.d5.loss_dice: 0.8498  decode.d6.loss_cls: 1.0073  decode.d6.loss_mask: 0.6238  decode.d6.loss_dice: 0.8308  decode.d7.loss_cls: 0.9951  decode.d7.loss_mask: 0.6269  decode.d7.loss_dice: 0.8421  decode.d8.loss_cls: 0.9513  decode.d8.loss_mask: 0.6285  decode.d8.loss_dice: 0.8324
2023/05/24 10:15:16 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 10:15:16 - mmengine - INFO - Iter(train) [129000/160000]  lr: 2.2831e-06  eta: 3:43:38  time: 0.4230  data_time: 0.0102  memory: 4846  grad_norm: 96.3604  loss: 27.8265  decode.loss_cls: 0.8036  decode.loss_mask: 0.7314  decode.loss_dice: 0.9599  decode.d0.loss_cls: 2.6769  decode.d0.loss_mask: 0.7942  decode.d0.loss_dice: 1.0871  decode.d1.loss_cls: 0.7971  decode.d1.loss_mask: 0.8219  decode.d1.loss_dice: 1.0582  decode.d2.loss_cls: 0.8421  decode.d2.loss_mask: 0.7625  decode.d2.loss_dice: 1.0346  decode.d3.loss_cls: 0.8397  decode.d3.loss_mask: 0.7639  decode.d3.loss_dice: 1.0107  decode.d4.loss_cls: 0.8021  decode.d4.loss_mask: 0.7692  decode.d4.loss_dice: 1.0177  decode.d5.loss_cls: 0.8075  decode.d5.loss_mask: 0.7860  decode.d5.loss_dice: 1.0412  decode.d6.loss_cls: 0.8112  decode.d6.loss_mask: 0.7599  decode.d6.loss_dice: 0.9944  decode.d7.loss_cls: 0.7933  decode.d7.loss_mask: 0.7519  decode.d7.loss_dice: 0.9825  decode.d8.loss_cls: 0.7993  decode.d8.loss_mask: 0.7443  decode.d8.loss_dice: 0.9822
2023/05/24 10:15:16 - mmengine - INFO - Saving checkpoint at 129000 iterations
2023/05/24 10:15:43 - mmengine - INFO - Iter(train) [129050/160000]  lr: 2.2798e-06  eta: 3:43:18  time: 0.4224  data_time: 0.0099  memory: 4856  grad_norm: 90.9279  loss: 36.1578  decode.loss_cls: 1.0907  decode.loss_mask: 0.8194  decode.loss_dice: 1.3904  decode.d0.loss_cls: 2.9012  decode.d0.loss_mask: 0.9699  decode.d0.loss_dice: 1.7407  decode.d1.loss_cls: 1.2726  decode.d1.loss_mask: 0.8837  decode.d1.loss_dice: 1.5985  decode.d2.loss_cls: 1.1964  decode.d2.loss_mask: 0.8669  decode.d2.loss_dice: 1.4675  decode.d3.loss_cls: 1.1418  decode.d3.loss_mask: 0.8450  decode.d3.loss_dice: 1.4406  decode.d4.loss_cls: 1.0701  decode.d4.loss_mask: 0.8496  decode.d4.loss_dice: 1.4221  decode.d5.loss_cls: 1.0888  decode.d5.loss_mask: 0.8564  decode.d5.loss_dice: 1.4279  decode.d6.loss_cls: 1.0660  decode.d6.loss_mask: 0.8268  decode.d6.loss_dice: 1.3784  decode.d7.loss_cls: 1.0826  decode.d7.loss_mask: 0.8347  decode.d7.loss_dice: 1.3961  decode.d8.loss_cls: 1.0262  decode.d8.loss_mask: 0.8470  decode.d8.loss_dice: 1.3598
2023/05/24 10:16:05 - mmengine - INFO - Iter(train) [129100/160000]  lr: 2.2764e-06  eta: 3:42:56  time: 0.4359  data_time: 0.0104  memory: 4917  grad_norm: 102.0883  loss: 33.2654  decode.loss_cls: 1.0241  decode.loss_mask: 0.7005  decode.loss_dice: 1.2998  decode.d0.loss_cls: 3.1393  decode.d0.loss_mask: 0.7666  decode.d0.loss_dice: 1.5880  decode.d1.loss_cls: 1.1909  decode.d1.loss_mask: 0.7747  decode.d1.loss_dice: 1.4206  decode.d2.loss_cls: 1.0390  decode.d2.loss_mask: 0.7296  decode.d2.loss_dice: 1.3577  decode.d3.loss_cls: 1.1036  decode.d3.loss_mask: 0.6831  decode.d3.loss_dice: 1.2939  decode.d4.loss_cls: 1.0597  decode.d4.loss_mask: 0.6818  decode.d4.loss_dice: 1.3162  decode.d5.loss_cls: 1.0600  decode.d5.loss_mask: 0.6800  decode.d5.loss_dice: 1.3017  decode.d6.loss_cls: 1.0393  decode.d6.loss_mask: 0.6995  decode.d6.loss_dice: 1.3125  decode.d7.loss_cls: 1.0157  decode.d7.loss_mask: 0.6969  decode.d7.loss_dice: 1.2973  decode.d8.loss_cls: 1.0123  decode.d8.loss_mask: 0.7002  decode.d8.loss_dice: 1.2810
2023/05/24 10:16:28 - mmengine - INFO - Iter(train) [129150/160000]  lr: 2.2731e-06  eta: 3:42:35  time: 0.4775  data_time: 0.0101  memory: 4846  grad_norm: 101.2471  loss: 33.5193  decode.loss_cls: 1.1458  decode.loss_mask: 0.8354  decode.loss_dice: 1.1789  decode.d0.loss_cls: 2.9297  decode.d0.loss_mask: 0.9021  decode.d0.loss_dice: 1.3021  decode.d1.loss_cls: 1.3480  decode.d1.loss_mask: 0.8505  decode.d1.loss_dice: 1.2095  decode.d2.loss_cls: 1.2345  decode.d2.loss_mask: 0.8013  decode.d2.loss_dice: 1.1426  decode.d3.loss_cls: 1.2187  decode.d3.loss_mask: 0.8075  decode.d3.loss_dice: 1.1473  decode.d4.loss_cls: 1.1645  decode.d4.loss_mask: 0.7867  decode.d4.loss_dice: 1.1354  decode.d5.loss_cls: 1.1446  decode.d5.loss_mask: 0.8199  decode.d5.loss_dice: 1.1468  decode.d6.loss_cls: 1.1554  decode.d6.loss_mask: 0.8101  decode.d6.loss_dice: 1.1398  decode.d7.loss_cls: 1.1251  decode.d7.loss_mask: 0.8087  decode.d7.loss_dice: 1.1346  decode.d8.loss_cls: 1.1174  decode.d8.loss_mask: 0.8300  decode.d8.loss_dice: 1.1465
2023/05/24 10:16:51 - mmengine - INFO - Iter(train) [129200/160000]  lr: 2.2698e-06  eta: 3:42:13  time: 0.4773  data_time: 0.0106  memory: 4815  grad_norm: 161.1934  loss: 33.0367  decode.loss_cls: 1.1351  decode.loss_mask: 0.7093  decode.loss_dice: 1.1903  decode.d0.loss_cls: 3.1409  decode.d0.loss_mask: 0.6748  decode.d0.loss_dice: 1.3561  decode.d1.loss_cls: 1.1784  decode.d1.loss_mask: 0.7135  decode.d1.loss_dice: 1.3147  decode.d2.loss_cls: 1.1116  decode.d2.loss_mask: 0.7099  decode.d2.loss_dice: 1.2587  decode.d3.loss_cls: 1.1089  decode.d3.loss_mask: 0.7618  decode.d3.loss_dice: 1.2324  decode.d4.loss_cls: 1.1630  decode.d4.loss_mask: 0.7530  decode.d4.loss_dice: 1.2055  decode.d5.loss_cls: 1.1421  decode.d5.loss_mask: 0.7450  decode.d5.loss_dice: 1.2396  decode.d6.loss_cls: 1.1979  decode.d6.loss_mask: 0.7048  decode.d6.loss_dice: 1.1840  decode.d7.loss_cls: 1.1437  decode.d7.loss_mask: 0.7036  decode.d7.loss_dice: 1.1968  decode.d8.loss_cls: 1.1411  decode.d8.loss_mask: 0.7127  decode.d8.loss_dice: 1.2074
2023/05/24 10:17:14 - mmengine - INFO - Iter(train) [129250/160000]  lr: 2.2665e-06  eta: 3:41:52  time: 0.4158  data_time: 0.0097  memory: 4789  grad_norm: 95.4773  loss: 37.2469  decode.loss_cls: 1.3065  decode.loss_mask: 0.8243  decode.loss_dice: 1.2553  decode.d0.loss_cls: 3.4124  decode.d0.loss_mask: 0.9075  decode.d0.loss_dice: 1.5294  decode.d1.loss_cls: 1.5156  decode.d1.loss_mask: 0.8860  decode.d1.loss_dice: 1.4118  decode.d2.loss_cls: 1.4494  decode.d2.loss_mask: 0.8264  decode.d2.loss_dice: 1.2998  decode.d3.loss_cls: 1.4374  decode.d3.loss_mask: 0.8123  decode.d3.loss_dice: 1.2457  decode.d4.loss_cls: 1.3905  decode.d4.loss_mask: 0.8083  decode.d4.loss_dice: 1.2560  decode.d5.loss_cls: 1.3818  decode.d5.loss_mask: 0.8172  decode.d5.loss_dice: 1.2561  decode.d6.loss_cls: 1.3185  decode.d6.loss_mask: 0.8221  decode.d6.loss_dice: 1.2844  decode.d7.loss_cls: 1.3444  decode.d7.loss_mask: 0.8119  decode.d7.loss_dice: 1.2672  decode.d8.loss_cls: 1.2945  decode.d8.loss_mask: 0.8245  decode.d8.loss_dice: 1.2495
2023/05/24 10:17:35 - mmengine - INFO - Iter(train) [129300/160000]  lr: 2.2632e-06  eta: 3:41:30  time: 0.4179  data_time: 0.0098  memory: 4815  grad_norm: 78.5166  loss: 29.3818  decode.loss_cls: 1.0684  decode.loss_mask: 0.5902  decode.loss_dice: 0.9862  decode.d0.loss_cls: 2.9830  decode.d0.loss_mask: 0.6939  decode.d0.loss_dice: 1.1880  decode.d1.loss_cls: 1.1976  decode.d1.loss_mask: 0.6416  decode.d1.loss_dice: 1.1102  decode.d2.loss_cls: 1.1572  decode.d2.loss_mask: 0.6155  decode.d2.loss_dice: 1.0367  decode.d3.loss_cls: 1.0457  decode.d3.loss_mask: 0.6161  decode.d3.loss_dice: 1.0430  decode.d4.loss_cls: 1.0671  decode.d4.loss_mask: 0.6014  decode.d4.loss_dice: 1.0185  decode.d5.loss_cls: 1.0187  decode.d5.loss_mask: 0.6138  decode.d5.loss_dice: 1.0145  decode.d6.loss_cls: 1.0850  decode.d6.loss_mask: 0.6187  decode.d6.loss_dice: 1.0110  decode.d7.loss_cls: 1.0889  decode.d7.loss_mask: 0.6078  decode.d7.loss_dice: 0.9977  decode.d8.loss_cls: 1.0862  decode.d8.loss_mask: 0.5930  decode.d8.loss_dice: 0.9861
2023/05/24 10:17:56 - mmengine - INFO - Iter(train) [129350/160000]  lr: 2.2599e-06  eta: 3:41:09  time: 0.4215  data_time: 0.0103  memory: 4835  grad_norm: 103.7230  loss: 33.1850  decode.loss_cls: 1.0167  decode.loss_mask: 0.7276  decode.loss_dice: 1.2619  decode.d0.loss_cls: 2.8146  decode.d0.loss_mask: 0.8260  decode.d0.loss_dice: 1.4162  decode.d1.loss_cls: 1.1657  decode.d1.loss_mask: 0.8247  decode.d1.loss_dice: 1.3990  decode.d2.loss_cls: 1.0903  decode.d2.loss_mask: 0.7810  decode.d2.loss_dice: 1.3681  decode.d3.loss_cls: 1.0617  decode.d3.loss_mask: 0.7601  decode.d3.loss_dice: 1.3170  decode.d4.loss_cls: 1.0236  decode.d4.loss_mask: 0.7720  decode.d4.loss_dice: 1.3385  decode.d5.loss_cls: 1.0455  decode.d5.loss_mask: 0.7575  decode.d5.loss_dice: 1.2909  decode.d6.loss_cls: 1.0120  decode.d6.loss_mask: 0.7445  decode.d6.loss_dice: 1.2995  decode.d7.loss_cls: 1.0140  decode.d7.loss_mask: 0.7251  decode.d7.loss_dice: 1.2728  decode.d8.loss_cls: 1.0836  decode.d8.loss_mask: 0.7181  decode.d8.loss_dice: 1.2568
2023/05/24 10:18:17 - mmengine - INFO - Iter(train) [129400/160000]  lr: 2.2565e-06  eta: 3:40:47  time: 0.4164  data_time: 0.0105  memory: 4837  grad_norm: 94.1281  loss: 30.6884  decode.loss_cls: 1.1019  decode.loss_mask: 0.6500  decode.loss_dice: 0.9809  decode.d0.loss_cls: 3.2364  decode.d0.loss_mask: 0.7467  decode.d0.loss_dice: 1.2044  decode.d1.loss_cls: 1.2455  decode.d1.loss_mask: 0.7155  decode.d1.loss_dice: 1.1341  decode.d2.loss_cls: 1.1236  decode.d2.loss_mask: 0.6843  decode.d2.loss_dice: 1.0795  decode.d3.loss_cls: 1.1368  decode.d3.loss_mask: 0.6582  decode.d3.loss_dice: 1.0382  decode.d4.loss_cls: 1.1792  decode.d4.loss_mask: 0.6573  decode.d4.loss_dice: 1.0319  decode.d5.loss_cls: 1.1248  decode.d5.loss_mask: 0.6567  decode.d5.loss_dice: 1.0206  decode.d6.loss_cls: 1.0754  decode.d6.loss_mask: 0.6584  decode.d6.loss_dice: 1.0166  decode.d7.loss_cls: 1.1222  decode.d7.loss_mask: 0.6458  decode.d7.loss_dice: 0.9910  decode.d8.loss_cls: 1.1115  decode.d8.loss_mask: 0.6516  decode.d8.loss_dice: 1.0093
2023/05/24 10:18:39 - mmengine - INFO - Iter(train) [129450/160000]  lr: 2.2532e-06  eta: 3:40:25  time: 0.4158  data_time: 0.0100  memory: 4835  grad_norm: 95.8422  loss: 32.3388  decode.loss_cls: 1.2860  decode.loss_mask: 0.5870  decode.loss_dice: 1.0693  decode.d0.loss_cls: 3.2852  decode.d0.loss_mask: 0.6460  decode.d0.loss_dice: 1.2979  decode.d1.loss_cls: 1.3755  decode.d1.loss_mask: 0.6118  decode.d1.loss_dice: 1.1876  decode.d2.loss_cls: 1.3298  decode.d2.loss_mask: 0.6066  decode.d2.loss_dice: 1.1220  decode.d3.loss_cls: 1.2885  decode.d3.loss_mask: 0.6054  decode.d3.loss_dice: 1.0982  decode.d4.loss_cls: 1.2954  decode.d4.loss_mask: 0.6095  decode.d4.loss_dice: 1.1039  decode.d5.loss_cls: 1.2985  decode.d5.loss_mask: 0.6155  decode.d5.loss_dice: 1.1235  decode.d6.loss_cls: 1.2765  decode.d6.loss_mask: 0.6184  decode.d6.loss_dice: 1.0635  decode.d7.loss_cls: 1.2897  decode.d7.loss_mask: 0.5986  decode.d7.loss_dice: 1.0793  decode.d8.loss_cls: 1.2761  decode.d8.loss_mask: 0.5974  decode.d8.loss_dice: 1.0961
2023/05/24 10:19:00 - mmengine - INFO - Iter(train) [129500/160000]  lr: 2.2499e-06  eta: 3:40:03  time: 0.4266  data_time: 0.0107  memory: 4861  grad_norm: 95.7640  loss: 37.5600  decode.loss_cls: 1.1588  decode.loss_mask: 0.8573  decode.loss_dice: 1.4828  decode.d0.loss_cls: 3.0870  decode.d0.loss_mask: 0.8699  decode.d0.loss_dice: 1.6978  decode.d1.loss_cls: 1.2784  decode.d1.loss_mask: 0.9268  decode.d1.loss_dice: 1.6117  decode.d2.loss_cls: 1.2153  decode.d2.loss_mask: 0.8553  decode.d2.loss_dice: 1.5428  decode.d3.loss_cls: 1.1400  decode.d3.loss_mask: 0.8840  decode.d3.loss_dice: 1.4841  decode.d4.loss_cls: 1.1426  decode.d4.loss_mask: 0.8871  decode.d4.loss_dice: 1.5074  decode.d5.loss_cls: 1.1287  decode.d5.loss_mask: 0.8558  decode.d5.loss_dice: 1.5079  decode.d6.loss_cls: 1.1104  decode.d6.loss_mask: 0.8665  decode.d6.loss_dice: 1.5101  decode.d7.loss_cls: 1.1248  decode.d7.loss_mask: 0.8456  decode.d7.loss_dice: 1.5128  decode.d8.loss_cls: 1.1381  decode.d8.loss_mask: 0.8509  decode.d8.loss_dice: 1.4793
2023/05/24 10:19:22 - mmengine - INFO - Iter(train) [129550/160000]  lr: 2.2466e-06  eta: 3:39:42  time: 0.4295  data_time: 0.0101  memory: 4846  grad_norm: 91.1085  loss: 23.3116  decode.loss_cls: 0.8106  decode.loss_mask: 0.5715  decode.loss_dice: 0.7965  decode.d0.loss_cls: 2.6307  decode.d0.loss_mask: 0.6407  decode.d0.loss_dice: 0.8925  decode.d1.loss_cls: 0.7624  decode.d1.loss_mask: 0.6254  decode.d1.loss_dice: 0.8953  decode.d2.loss_cls: 0.7032  decode.d2.loss_mask: 0.5862  decode.d2.loss_dice: 0.8208  decode.d3.loss_cls: 0.7163  decode.d3.loss_mask: 0.5885  decode.d3.loss_dice: 0.8175  decode.d4.loss_cls: 0.6493  decode.d4.loss_mask: 0.5922  decode.d4.loss_dice: 0.8260  decode.d5.loss_cls: 0.6307  decode.d5.loss_mask: 0.5823  decode.d5.loss_dice: 0.8354  decode.d6.loss_cls: 0.7282  decode.d6.loss_mask: 0.5681  decode.d6.loss_dice: 0.8136  decode.d7.loss_cls: 0.7267  decode.d7.loss_mask: 0.5762  decode.d7.loss_dice: 0.8038  decode.d8.loss_cls: 0.7110  decode.d8.loss_mask: 0.5794  decode.d8.loss_dice: 0.8307
2023/05/24 10:19:43 - mmengine - INFO - Iter(train) [129600/160000]  lr: 2.2433e-06  eta: 3:39:20  time: 0.4294  data_time: 0.0104  memory: 4863  grad_norm: 103.0884  loss: 27.9946  decode.loss_cls: 0.9031  decode.loss_mask: 0.6577  decode.loss_dice: 0.9746  decode.d0.loss_cls: 2.8351  decode.d0.loss_mask: 0.6991  decode.d0.loss_dice: 1.1333  decode.d1.loss_cls: 0.9765  decode.d1.loss_mask: 0.6946  decode.d1.loss_dice: 1.0510  decode.d2.loss_cls: 0.9488  decode.d2.loss_mask: 0.6871  decode.d2.loss_dice: 1.0022  decode.d3.loss_cls: 0.9902  decode.d3.loss_mask: 0.6639  decode.d3.loss_dice: 0.9797  decode.d4.loss_cls: 0.9274  decode.d4.loss_mask: 0.6775  decode.d4.loss_dice: 0.9934  decode.d5.loss_cls: 0.8970  decode.d5.loss_mask: 0.6852  decode.d5.loss_dice: 0.9941  decode.d6.loss_cls: 0.9248  decode.d6.loss_mask: 0.6553  decode.d6.loss_dice: 0.9715  decode.d7.loss_cls: 0.8995  decode.d7.loss_mask: 0.6610  decode.d7.loss_dice: 0.9622  decode.d8.loss_cls: 0.9263  decode.d8.loss_mask: 0.6547  decode.d8.loss_dice: 0.9675
2023/05/24 10:20:05 - mmengine - INFO - Iter(train) [129650/160000]  lr: 2.2399e-06  eta: 3:38:58  time: 0.4234  data_time: 0.0103  memory: 4875  grad_norm: 104.6638  loss: 34.3845  decode.loss_cls: 1.0799  decode.loss_mask: 0.7658  decode.loss_dice: 1.2252  decode.d0.loss_cls: 3.2209  decode.d0.loss_mask: 0.8587  decode.d0.loss_dice: 1.4160  decode.d1.loss_cls: 1.2586  decode.d1.loss_mask: 0.8521  decode.d1.loss_dice: 1.3575  decode.d2.loss_cls: 1.2565  decode.d2.loss_mask: 0.8051  decode.d2.loss_dice: 1.2911  decode.d3.loss_cls: 1.1836  decode.d3.loss_mask: 0.7742  decode.d3.loss_dice: 1.2820  decode.d4.loss_cls: 1.1540  decode.d4.loss_mask: 0.7785  decode.d4.loss_dice: 1.2692  decode.d5.loss_cls: 1.1184  decode.d5.loss_mask: 0.7628  decode.d5.loss_dice: 1.2432  decode.d6.loss_cls: 1.1711  decode.d6.loss_mask: 0.7474  decode.d6.loss_dice: 1.2040  decode.d7.loss_cls: 1.1623  decode.d7.loss_mask: 0.7528  decode.d7.loss_dice: 1.2328  decode.d8.loss_cls: 1.1599  decode.d8.loss_mask: 0.7671  decode.d8.loss_dice: 1.2337
2023/05/24 10:20:27 - mmengine - INFO - Iter(train) [129700/160000]  lr: 2.2366e-06  eta: 3:38:37  time: 0.4197  data_time: 0.0101  memory: 4860  grad_norm: 104.4442  loss: 30.0239  decode.loss_cls: 0.9980  decode.loss_mask: 0.6883  decode.loss_dice: 1.0609  decode.d0.loss_cls: 2.8723  decode.d0.loss_mask: 0.7841  decode.d0.loss_dice: 1.2840  decode.d1.loss_cls: 1.1502  decode.d1.loss_mask: 0.7071  decode.d1.loss_dice: 1.1129  decode.d2.loss_cls: 1.0727  decode.d2.loss_mask: 0.7036  decode.d2.loss_dice: 1.0605  decode.d3.loss_cls: 1.0105  decode.d3.loss_mask: 0.6934  decode.d3.loss_dice: 1.0856  decode.d4.loss_cls: 1.0159  decode.d4.loss_mask: 0.6893  decode.d4.loss_dice: 1.0522  decode.d5.loss_cls: 1.0263  decode.d5.loss_mask: 0.6769  decode.d5.loss_dice: 1.0478  decode.d6.loss_cls: 0.9874  decode.d6.loss_mask: 0.6866  decode.d6.loss_dice: 1.0524  decode.d7.loss_cls: 1.0297  decode.d7.loss_mask: 0.6871  decode.d7.loss_dice: 1.0738  decode.d8.loss_cls: 0.9847  decode.d8.loss_mask: 0.6882  decode.d8.loss_dice: 1.0415
2023/05/24 10:20:48 - mmengine - INFO - Iter(train) [129750/160000]  lr: 2.2333e-06  eta: 3:38:15  time: 0.4336  data_time: 0.0100  memory: 4845  grad_norm: 83.2969  loss: 34.4182  decode.loss_cls: 1.4087  decode.loss_mask: 0.8159  decode.loss_dice: 0.9735  decode.d0.loss_cls: 3.2397  decode.d0.loss_mask: 0.8516  decode.d0.loss_dice: 1.1650  decode.d1.loss_cls: 1.5546  decode.d1.loss_mask: 0.8454  decode.d1.loss_dice: 1.0763  decode.d2.loss_cls: 1.4789  decode.d2.loss_mask: 0.8057  decode.d2.loss_dice: 1.0212  decode.d3.loss_cls: 1.4226  decode.d3.loss_mask: 0.8002  decode.d3.loss_dice: 0.9734  decode.d4.loss_cls: 1.4358  decode.d4.loss_mask: 0.8012  decode.d4.loss_dice: 0.9818  decode.d5.loss_cls: 1.4226  decode.d5.loss_mask: 0.8111  decode.d5.loss_dice: 0.9919  decode.d6.loss_cls: 1.3589  decode.d6.loss_mask: 0.8252  decode.d6.loss_dice: 0.9841  decode.d7.loss_cls: 1.3951  decode.d7.loss_mask: 0.8085  decode.d7.loss_dice: 0.9762  decode.d8.loss_cls: 1.3815  decode.d8.loss_mask: 0.8227  decode.d8.loss_dice: 0.9889
2023/05/24 10:21:11 - mmengine - INFO - Iter(train) [129800/160000]  lr: 2.2300e-06  eta: 3:37:54  time: 0.4832  data_time: 0.0099  memory: 4804  grad_norm: 94.6724  loss: 31.9870  decode.loss_cls: 0.9892  decode.loss_mask: 0.8338  decode.loss_dice: 1.1178  decode.d0.loss_cls: 2.8780  decode.d0.loss_mask: 0.8888  decode.d0.loss_dice: 1.2414  decode.d1.loss_cls: 1.1322  decode.d1.loss_mask: 0.8723  decode.d1.loss_dice: 1.1869  decode.d2.loss_cls: 1.0552  decode.d2.loss_mask: 0.8354  decode.d2.loss_dice: 1.1560  decode.d3.loss_cls: 1.0623  decode.d3.loss_mask: 0.8418  decode.d3.loss_dice: 1.1635  decode.d4.loss_cls: 1.0141  decode.d4.loss_mask: 0.8087  decode.d4.loss_dice: 1.1221  decode.d5.loss_cls: 1.0594  decode.d5.loss_mask: 0.8167  decode.d5.loss_dice: 1.1266  decode.d6.loss_cls: 1.0004  decode.d6.loss_mask: 0.8000  decode.d6.loss_dice: 1.1125  decode.d7.loss_cls: 1.0189  decode.d7.loss_mask: 0.8048  decode.d7.loss_dice: 1.1135  decode.d8.loss_cls: 1.0087  decode.d8.loss_mask: 0.8181  decode.d8.loss_dice: 1.1081
2023/05/24 10:21:33 - mmengine - INFO - Iter(train) [129850/160000]  lr: 2.2267e-06  eta: 3:37:32  time: 0.4316  data_time: 0.0100  memory: 4829  grad_norm: 97.5939  loss: 34.2562  decode.loss_cls: 0.8786  decode.loss_mask: 0.9077  decode.loss_dice: 1.2917  decode.d0.loss_cls: 3.2057  decode.d0.loss_mask: 0.9803  decode.d0.loss_dice: 1.5321  decode.d1.loss_cls: 1.1107  decode.d1.loss_mask: 0.9860  decode.d1.loss_dice: 1.4169  decode.d2.loss_cls: 0.9623  decode.d2.loss_mask: 0.9436  decode.d2.loss_dice: 1.3464  decode.d3.loss_cls: 0.9718  decode.d3.loss_mask: 0.9194  decode.d3.loss_dice: 1.3019  decode.d4.loss_cls: 0.9392  decode.d4.loss_mask: 0.9395  decode.d4.loss_dice: 1.2908  decode.d5.loss_cls: 0.8952  decode.d5.loss_mask: 0.9298  decode.d5.loss_dice: 1.2590  decode.d6.loss_cls: 0.8733  decode.d6.loss_mask: 0.9261  decode.d6.loss_dice: 1.2799  decode.d7.loss_cls: 0.8889  decode.d7.loss_mask: 0.9111  decode.d7.loss_dice: 1.2598  decode.d8.loss_cls: 0.8613  decode.d8.loss_mask: 0.9392  decode.d8.loss_dice: 1.3081
2023/05/24 10:21:55 - mmengine - INFO - Iter(train) [129900/160000]  lr: 2.2233e-06  eta: 3:37:11  time: 0.4261  data_time: 0.0102  memory: 4805  grad_norm: 81.5904  loss: 34.1544  decode.loss_cls: 1.1503  decode.loss_mask: 0.8439  decode.loss_dice: 1.1310  decode.d0.loss_cls: 3.2910  decode.d0.loss_mask: 0.8775  decode.d0.loss_dice: 1.2218  decode.d1.loss_cls: 1.2857  decode.d1.loss_mask: 0.9019  decode.d1.loss_dice: 1.2405  decode.d2.loss_cls: 1.2580  decode.d2.loss_mask: 0.9121  decode.d2.loss_dice: 1.1604  decode.d3.loss_cls: 1.3011  decode.d3.loss_mask: 0.8453  decode.d3.loss_dice: 1.1313  decode.d4.loss_cls: 1.1919  decode.d4.loss_mask: 0.8314  decode.d4.loss_dice: 1.1592  decode.d5.loss_cls: 1.1375  decode.d5.loss_mask: 0.8685  decode.d5.loss_dice: 1.1218  decode.d6.loss_cls: 1.1590  decode.d6.loss_mask: 0.8196  decode.d6.loss_dice: 1.1383  decode.d7.loss_cls: 1.1219  decode.d7.loss_mask: 0.8422  decode.d7.loss_dice: 1.1460  decode.d8.loss_cls: 1.1175  decode.d8.loss_mask: 0.8345  decode.d8.loss_dice: 1.1135
2023/05/24 10:22:17 - mmengine - INFO - Iter(train) [129950/160000]  lr: 2.2200e-06  eta: 3:36:49  time: 0.4277  data_time: 0.0099  memory: 4796  grad_norm: 109.3251  loss: 33.5108  decode.loss_cls: 1.0878  decode.loss_mask: 0.7330  decode.loss_dice: 1.2852  decode.d0.loss_cls: 3.0693  decode.d0.loss_mask: 0.7565  decode.d0.loss_dice: 1.3463  decode.d1.loss_cls: 1.2511  decode.d1.loss_mask: 0.7589  decode.d1.loss_dice: 1.3258  decode.d2.loss_cls: 1.2130  decode.d2.loss_mask: 0.7677  decode.d2.loss_dice: 1.3105  decode.d3.loss_cls: 1.1495  decode.d3.loss_mask: 0.7166  decode.d3.loss_dice: 1.2715  decode.d4.loss_cls: 1.1311  decode.d4.loss_mask: 0.7132  decode.d4.loss_dice: 1.2504  decode.d5.loss_cls: 1.0815  decode.d5.loss_mask: 0.7500  decode.d5.loss_dice: 1.2498  decode.d6.loss_cls: 1.1014  decode.d6.loss_mask: 0.7582  decode.d6.loss_dice: 1.2759  decode.d7.loss_cls: 1.0231  decode.d7.loss_mask: 0.7679  decode.d7.loss_dice: 1.2805  decode.d8.loss_cls: 1.0576  decode.d8.loss_mask: 0.7559  decode.d8.loss_dice: 1.2716
2023/05/24 10:22:38 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 10:22:38 - mmengine - INFO - Iter(train) [130000/160000]  lr: 2.2167e-06  eta: 3:36:27  time: 0.4146  data_time: 0.0102  memory: 4863  grad_norm: 90.9351  loss: 33.9381  decode.loss_cls: 1.2091  decode.loss_mask: 0.6133  decode.loss_dice: 1.3323  decode.d0.loss_cls: 2.9310  decode.d0.loss_mask: 0.6356  decode.d0.loss_dice: 1.4367  decode.d1.loss_cls: 1.2603  decode.d1.loss_mask: 0.7096  decode.d1.loss_dice: 1.3804  decode.d2.loss_cls: 1.2446  decode.d2.loss_mask: 0.6106  decode.d2.loss_dice: 1.3657  decode.d3.loss_cls: 1.2264  decode.d3.loss_mask: 0.7043  decode.d3.loss_dice: 1.3380  decode.d4.loss_cls: 1.2503  decode.d4.loss_mask: 0.6231  decode.d4.loss_dice: 1.3483  decode.d5.loss_cls: 1.2024  decode.d5.loss_mask: 0.6995  decode.d5.loss_dice: 1.3492  decode.d6.loss_cls: 1.1436  decode.d6.loss_mask: 0.6878  decode.d6.loss_dice: 1.3117  decode.d7.loss_cls: 1.1773  decode.d7.loss_mask: 0.6628  decode.d7.loss_dice: 1.3152  decode.d8.loss_cls: 1.1811  decode.d8.loss_mask: 0.6678  decode.d8.loss_dice: 1.3199
2023/05/24 10:22:38 - mmengine - INFO - Saving checkpoint at 130000 iterations
2023/05/24 10:22:48 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:49  time: 0.0800  data_time: 0.0019  memory: 2167  
2023/05/24 10:22:52 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0782  data_time: 0.0017  memory: 2216  
2023/05/24 10:22:56 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:39  time: 0.1044  data_time: 0.0019  memory: 2167  
2023/05/24 10:23:00 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0801  data_time: 0.0018  memory: 2104  
2023/05/24 10:23:04 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:30  time: 0.0786  data_time: 0.0019  memory: 2831  
2023/05/24 10:23:08 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0791  data_time: 0.0017  memory: 2167  
2023/05/24 10:23:12 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0801  data_time: 0.0017  memory: 2167  
2023/05/24 10:23:16 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0794  data_time: 0.0018  memory: 2167  
2023/05/24 10:23:20 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0958  data_time: 0.0025  memory: 2944  
2023/05/24 10:23:25 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0800  data_time: 0.0018  memory: 2356  
2023/05/24 10:23:29 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0806  data_time: 0.0019  memory: 2217  
2023/05/24 10:23:33 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0805  data_time: 0.0018  memory: 2328  
2023/05/24 10:23:36 - mmengine - INFO - per class results:
2023/05/24 10:23:37 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      |  86.4 | 93.53 |
|     bicycle      | 71.18 | 84.04 |
|       car        | 61.45 | 86.03 |
|    motorcycle    | 82.79 | 90.41 |
|     airplane     | 87.55 | 93.68 |
|       bus        | 82.16 | 88.39 |
|      train       | 85.29 | 92.99 |
|      truck       | 54.51 | 70.45 |
|       boat       | 60.56 | 77.34 |
|  traffic light   | 68.29 | 85.81 |
|   fire hydrant   |  86.8 | 95.21 |
|    stop sign     | 88.88 | 94.15 |
|  parking meter   | 76.47 | 86.23 |
|      bench       | 47.84 | 72.42 |
|       bird       | 81.18 |  91.7 |
|       cat        | 85.77 | 93.65 |
|       dog        | 80.38 | 87.61 |
|      horse       | 79.04 | 91.31 |
|      sheep       | 86.31 | 92.84 |
|       cow        | 82.37 | 88.85 |
|     elephant     | 89.88 | 95.03 |
|       bear       | 92.55 | 95.29 |
|      zebra       |  90.0 | 93.44 |
|     giraffe      | 87.45 | 93.73 |
|     backpack     | 32.06 | 66.69 |
|     umbrella     | 81.05 | 88.73 |
|     handbag      |  33.8 | 52.43 |
|       tie        | 15.86 | 22.64 |
|     suitcase     | 78.03 | 92.13 |
|     frisbee      | 81.21 | 91.73 |
|       skis       | 43.35 | 57.97 |
|    snowboard     | 44.67 |  60.2 |
|   sports ball    |  52.5 | 73.99 |
|       kite       | 65.12 | 80.56 |
|   baseball bat   | 46.35 |  56.1 |
|  baseball glove  | 73.19 | 88.14 |
|    skateboard    | 76.96 | 88.97 |
|    surfboard     | 75.43 | 87.31 |
|  tennis racket   | 82.73 | 92.26 |
|      bottle      | 44.36 |  58.8 |
|    wine glass    | 56.38 | 80.78 |
|       cup        | 52.27 | 77.01 |
|       fork       | 39.59 | 53.42 |
|      knife       |  34.9 | 49.25 |
|      spoon       |  41.2 |  60.0 |
|       bowl       | 44.79 | 62.69 |
|      banana      | 66.62 | 88.92 |
|      apple       | 48.85 | 73.61 |
|     sandwich     | 41.54 | 57.04 |
|      orange      | 65.17 | 71.99 |
|     broccoli     | 56.86 | 71.16 |
|      carrot      | 55.15 | 65.92 |
|     hot dog      | 51.59 | 61.43 |
|      pizza       | 68.48 | 85.43 |
|      donut       | 69.37 | 84.89 |
|       cake       | 62.68 | 72.63 |
|      chair       | 46.02 | 65.44 |
|      couch       | 56.45 | 83.34 |
|   potted plant   | 30.61 | 47.45 |
|       bed        | 63.84 |  80.4 |
|   dining table   | 44.63 | 78.56 |
|      toilet      | 80.93 | 94.01 |
|        tv        | 77.04 | 87.67 |
|      laptop      | 74.05 | 85.65 |
|      mouse       | 75.57 | 90.19 |
|      remote      | 61.74 |  73.5 |
|     keyboard     | 64.75 | 80.09 |
|    cell phone    | 69.63 | 90.05 |
|    microwave     | 64.96 |  76.0 |
|       oven       | 56.44 | 77.08 |
|     toaster      |  56.3 | 73.65 |
|       sink       | 57.23 |  80.3 |
|   refrigerator   | 78.16 | 91.36 |
|       book       |  51.2 | 68.76 |
|      clock       | 71.97 | 77.78 |
|       vase       |  58.0 | 80.96 |
|     scissors     | 78.86 | 90.33 |
|    teddy bear    | 75.53 | 86.71 |
|    hair drier    | 43.99 |  47.7 |
|    toothbrush    | 39.11 | 79.91 |
|      banner      |  33.0 | 55.39 |
|     blanket      |  9.52 | 10.88 |
|      branch      | 24.07 | 34.03 |
|      bridge      | 32.07 | 42.34 |
|  building-other  | 54.13 | 73.15 |
|       bush       | 33.11 |  46.4 |
|     cabinet      | 52.77 | 68.34 |
|       cage       | 13.45 | 15.69 |
|    cardboard     | 48.79 | 59.39 |
|      carpet      | 49.21 | 71.82 |
|  ceiling-other   | 64.18 | 83.46 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 21.31 | 34.76 |
|      clouds      | 44.45 |  55.4 |
|     counter      | 27.47 |  46.2 |
|     cupboard     |  8.5  | 13.48 |
|     curtain      | 64.09 | 80.83 |
|    desk-stuff    | 46.86 | 63.48 |
|       dirt       | 40.79 | 60.22 |
|    door-stuff    | 40.87 | 59.23 |
|      fence       | 33.09 | 61.41 |
|   floor-marble   |  5.82 |  6.65 |
|   floor-other    | 21.68 | 28.55 |
|   floor-stone    |  4.7  |  6.37 |
|    floor-tile    | 60.83 |  70.0 |
|    floor-wood    | 58.57 |  80.7 |
|      flower      | 39.12 | 60.56 |
|       fog        |  4.62 |  4.64 |
|    food-other    | 28.12 | 33.85 |
|      fruit       | 39.19 | 55.41 |
| furniture-other  | 14.96 | 18.61 |
|      grass       | 70.09 | 82.36 |
|      gravel      | 27.11 | 36.81 |
|   ground-other   |  7.81 |  9.08 |
|       hill       | 24.44 | 31.79 |
|      house       | 25.48 | 32.29 |
|      leaves      | 21.44 | 29.22 |
|      light       | 37.65 | 51.02 |
|       mat        |  0.0  |  0.0  |
|      metal       | 31.71 | 46.15 |
|   mirror-stuff   | 48.11 | 59.87 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 52.76 |  64.3 |
|       mud        |  7.1  |  8.13 |
|      napkin      | 12.37 | 12.56 |
|       net        | 37.64 | 67.81 |
|      paper       | 29.55 | 42.99 |
|     pavement     | 48.37 | 66.81 |
|      pillow      | 12.98 | 16.58 |
|   plant-other    | 17.77 | 30.89 |
|     plastic      | 23.06 | 32.16 |
|     platform     | 27.55 | 42.65 |
|   playingfield   | 71.18 | 92.39 |
|     railing      |  6.19 |  8.18 |
|     railroad     | 62.28 | 81.71 |
|      river       | 51.31 | 67.46 |
|       road       | 65.61 |  85.0 |
|       rock       | 46.09 | 75.14 |
|       roof       |  14.6 | 18.58 |
|       rug        | 31.35 | 48.54 |
|      salad       |  0.0  |  0.0  |
|       sand       | 63.18 | 72.87 |
|       sea        | 86.61 |  92.2 |
|      shelf       | 34.93 | 50.14 |
|    sky-other     | 70.47 | 89.37 |
|    skyscraper    | 32.92 | 40.28 |
|       snow       | 88.06 | 93.61 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 21.91 | 36.43 |
|      stone       |  4.85 |  7.09 |
|      straw       | 31.37 | 53.08 |
| structural-other |  0.02 |  0.02 |
|      table       |  18.4 | 24.01 |
|       tent       |  8.91 | 11.59 |
|  textile-other   |  9.82 | 15.15 |
|      towel       |  33.2 |  42.7 |
|       tree       | 73.87 | 86.04 |
|    vegetable     | 36.02 | 45.88 |
|    wall-brick    | 46.19 | 63.83 |
|  wall-concrete   | 60.63 | 81.82 |
|    wall-other    | 19.02 | 29.34 |
|    wall-panel    |  0.06 |  0.07 |
|    wall-stone    |  30.6 | 37.03 |
|    wall-tile     | 64.24 | 81.48 |
|    wall-wood     | 37.15 | 61.49 |
|   water-other    | 26.43 | 42.07 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 51.49 | 60.27 |
|   window-other   | 48.72 | 71.39 |
|       wood       | 24.31 | 43.37 |
+------------------+-------+-------+
2023/05/24 10:23:37 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.4700  mIoU: 47.4200  mAcc: 60.0600  data_time: 0.0020  time: 0.0820
2023/05/24 10:23:37 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_125000.pth is removed
2023/05/24 10:23:40 - mmengine - INFO - The best checkpoint with 47.4200 mIoU at 130000 iter is saved to best_mIoU_iter_130000.pth.
2023/05/24 10:24:02 - mmengine - INFO - Iter(train) [130050/160000]  lr: 2.2134e-06  eta: 3:36:07  time: 0.4288  data_time: 0.0102  memory: 4899  grad_norm: 86.4152  loss: 26.3505  decode.loss_cls: 0.8734  decode.loss_mask: 0.6581  decode.loss_dice: 0.8027  decode.d0.loss_cls: 2.7608  decode.d0.loss_mask: 0.7153  decode.d0.loss_dice: 0.9788  decode.d1.loss_cls: 0.9629  decode.d1.loss_mask: 0.6720  decode.d1.loss_dice: 0.9696  decode.d2.loss_cls: 0.9130  decode.d2.loss_mask: 0.7128  decode.d2.loss_dice: 0.8947  decode.d3.loss_cls: 0.9262  decode.d3.loss_mask: 0.6921  decode.d3.loss_dice: 0.8653  decode.d4.loss_cls: 0.9628  decode.d4.loss_mask: 0.6504  decode.d4.loss_dice: 0.8595  decode.d5.loss_cls: 0.8895  decode.d5.loss_mask: 0.6683  decode.d5.loss_dice: 0.8251  decode.d6.loss_cls: 0.9768  decode.d6.loss_mask: 0.6386  decode.d6.loss_dice: 0.7768  decode.d7.loss_cls: 0.8755  decode.d7.loss_mask: 0.6648  decode.d7.loss_dice: 0.7935  decode.d8.loss_cls: 0.9214  decode.d8.loss_mask: 0.6715  decode.d8.loss_dice: 0.7783
2023/05/24 10:24:23 - mmengine - INFO - Iter(train) [130100/160000]  lr: 2.2100e-06  eta: 3:35:45  time: 0.4305  data_time: 0.0111  memory: 4829  grad_norm: 136.0954  loss: 24.7510  decode.loss_cls: 0.8129  decode.loss_mask: 0.6617  decode.loss_dice: 0.8058  decode.d0.loss_cls: 2.5562  decode.d0.loss_mask: 0.7214  decode.d0.loss_dice: 0.9121  decode.d1.loss_cls: 0.8132  decode.d1.loss_mask: 0.6601  decode.d1.loss_dice: 0.8637  decode.d2.loss_cls: 0.7117  decode.d2.loss_mask: 0.6816  decode.d2.loss_dice: 0.8677  decode.d3.loss_cls: 0.7412  decode.d3.loss_mask: 0.6848  decode.d3.loss_dice: 0.8446  decode.d4.loss_cls: 0.7570  decode.d4.loss_mask: 0.6593  decode.d4.loss_dice: 0.8459  decode.d5.loss_cls: 0.7154  decode.d5.loss_mask: 0.7314  decode.d5.loss_dice: 0.8399  decode.d6.loss_cls: 0.7392  decode.d6.loss_mask: 0.7389  decode.d6.loss_dice: 0.8274  decode.d7.loss_cls: 0.7769  decode.d7.loss_mask: 0.6966  decode.d7.loss_dice: 0.8241  decode.d8.loss_cls: 0.7626  decode.d8.loss_mask: 0.6890  decode.d8.loss_dice: 0.8088
2023/05/24 10:24:46 - mmengine - INFO - Iter(train) [130150/160000]  lr: 2.2067e-06  eta: 3:35:24  time: 0.4806  data_time: 0.0109  memory: 4876  grad_norm: 96.1646  loss: 30.9284  decode.loss_cls: 1.0109  decode.loss_mask: 0.6282  decode.loss_dice: 1.1720  decode.d0.loss_cls: 2.7833  decode.d0.loss_mask: 0.6877  decode.d0.loss_dice: 1.3740  decode.d1.loss_cls: 1.1543  decode.d1.loss_mask: 0.6576  decode.d1.loss_dice: 1.2959  decode.d2.loss_cls: 1.1172  decode.d2.loss_mask: 0.6146  decode.d2.loss_dice: 1.2263  decode.d3.loss_cls: 1.1254  decode.d3.loss_mask: 0.6111  decode.d3.loss_dice: 1.1806  decode.d4.loss_cls: 1.0757  decode.d4.loss_mask: 0.6146  decode.d4.loss_dice: 1.1974  decode.d5.loss_cls: 1.0437  decode.d5.loss_mask: 0.6245  decode.d5.loss_dice: 1.2183  decode.d6.loss_cls: 1.0704  decode.d6.loss_mask: 0.6296  decode.d6.loss_dice: 1.1681  decode.d7.loss_cls: 0.9935  decode.d7.loss_mask: 0.6262  decode.d7.loss_dice: 1.1936  decode.d8.loss_cls: 1.0374  decode.d8.loss_mask: 0.6235  decode.d8.loss_dice: 1.1727
2023/05/24 10:25:07 - mmengine - INFO - Iter(train) [130200/160000]  lr: 2.2034e-06  eta: 3:35:02  time: 0.4253  data_time: 0.0101  memory: 4908  grad_norm: 98.8172  loss: 33.2554  decode.loss_cls: 1.1516  decode.loss_mask: 0.6385  decode.loss_dice: 1.1808  decode.d0.loss_cls: 2.9560  decode.d0.loss_mask: 0.6292  decode.d0.loss_dice: 1.4279  decode.d1.loss_cls: 1.3138  decode.d1.loss_mask: 0.6714  decode.d1.loss_dice: 1.3478  decode.d2.loss_cls: 1.3117  decode.d2.loss_mask: 0.6803  decode.d2.loss_dice: 1.3173  decode.d3.loss_cls: 1.2451  decode.d3.loss_mask: 0.6820  decode.d3.loss_dice: 1.2588  decode.d4.loss_cls: 1.2810  decode.d4.loss_mask: 0.6646  decode.d4.loss_dice: 1.2240  decode.d5.loss_cls: 1.3039  decode.d5.loss_mask: 0.6311  decode.d5.loss_dice: 1.2341  decode.d6.loss_cls: 1.2119  decode.d6.loss_mask: 0.6325  decode.d6.loss_dice: 1.2039  decode.d7.loss_cls: 1.1841  decode.d7.loss_mask: 0.6359  decode.d7.loss_dice: 1.2155  decode.d8.loss_cls: 1.1757  decode.d8.loss_mask: 0.6356  decode.d8.loss_dice: 1.2096
2023/05/24 10:25:29 - mmengine - INFO - Iter(train) [130250/160000]  lr: 2.2001e-06  eta: 3:34:40  time: 0.4281  data_time: 0.0106  memory: 4847  grad_norm: 91.0288  loss: 33.3036  decode.loss_cls: 1.1816  decode.loss_mask: 0.7514  decode.loss_dice: 1.0643  decode.d0.loss_cls: 3.0624  decode.d0.loss_mask: 0.8591  decode.d0.loss_dice: 1.2474  decode.d1.loss_cls: 1.3761  decode.d1.loss_mask: 0.8325  decode.d1.loss_dice: 1.1905  decode.d2.loss_cls: 1.3303  decode.d2.loss_mask: 0.8145  decode.d2.loss_dice: 1.1575  decode.d3.loss_cls: 1.2143  decode.d3.loss_mask: 0.8290  decode.d3.loss_dice: 1.1525  decode.d4.loss_cls: 1.1632  decode.d4.loss_mask: 0.8129  decode.d4.loss_dice: 1.1293  decode.d5.loss_cls: 1.1942  decode.d5.loss_mask: 0.7702  decode.d5.loss_dice: 1.0810  decode.d6.loss_cls: 1.2068  decode.d6.loss_mask: 0.7705  decode.d6.loss_dice: 1.0813  decode.d7.loss_cls: 1.1577  decode.d7.loss_mask: 0.7683  decode.d7.loss_dice: 1.0882  decode.d8.loss_cls: 1.1537  decode.d8.loss_mask: 0.7666  decode.d8.loss_dice: 1.0963
2023/05/24 10:25:51 - mmengine - INFO - Iter(train) [130300/160000]  lr: 2.1967e-06  eta: 3:34:19  time: 0.4273  data_time: 0.0100  memory: 4896  grad_norm: 78.6306  loss: 31.1585  decode.loss_cls: 1.1630  decode.loss_mask: 0.6029  decode.loss_dice: 1.1123  decode.d0.loss_cls: 2.9808  decode.d0.loss_mask: 0.6160  decode.d0.loss_dice: 1.2501  decode.d1.loss_cls: 1.3367  decode.d1.loss_mask: 0.6405  decode.d1.loss_dice: 1.2445  decode.d2.loss_cls: 1.2001  decode.d2.loss_mask: 0.5933  decode.d2.loss_dice: 1.1485  decode.d3.loss_cls: 1.1628  decode.d3.loss_mask: 0.6215  decode.d3.loss_dice: 1.1331  decode.d4.loss_cls: 1.1183  decode.d4.loss_mask: 0.6068  decode.d4.loss_dice: 1.1217  decode.d5.loss_cls: 1.1417  decode.d5.loss_mask: 0.6128  decode.d5.loss_dice: 1.1798  decode.d6.loss_cls: 1.1415  decode.d6.loss_mask: 0.6022  decode.d6.loss_dice: 1.1274  decode.d7.loss_cls: 1.1553  decode.d7.loss_mask: 0.6062  decode.d7.loss_dice: 1.1209  decode.d8.loss_cls: 1.1307  decode.d8.loss_mask: 0.5961  decode.d8.loss_dice: 1.0911
2023/05/24 10:26:12 - mmengine - INFO - Iter(train) [130350/160000]  lr: 2.1934e-06  eta: 3:33:57  time: 0.4249  data_time: 0.0097  memory: 4857  grad_norm: 110.3399  loss: 33.1551  decode.loss_cls: 1.0449  decode.loss_mask: 0.8490  decode.loss_dice: 1.1742  decode.d0.loss_cls: 2.9360  decode.d0.loss_mask: 0.9164  decode.d0.loss_dice: 1.3717  decode.d1.loss_cls: 1.0558  decode.d1.loss_mask: 0.8849  decode.d1.loss_dice: 1.2624  decode.d2.loss_cls: 1.0105  decode.d2.loss_mask: 0.8715  decode.d2.loss_dice: 1.2072  decode.d3.loss_cls: 1.0780  decode.d3.loss_mask: 0.8467  decode.d3.loss_dice: 1.1755  decode.d4.loss_cls: 1.1025  decode.d4.loss_mask: 0.8352  decode.d4.loss_dice: 1.1853  decode.d5.loss_cls: 1.0882  decode.d5.loss_mask: 0.8592  decode.d5.loss_dice: 1.1782  decode.d6.loss_cls: 1.0948  decode.d6.loss_mask: 0.8680  decode.d6.loss_dice: 1.1650  decode.d7.loss_cls: 1.0581  decode.d7.loss_mask: 0.8494  decode.d7.loss_dice: 1.1321  decode.d8.loss_cls: 1.0808  decode.d8.loss_mask: 0.8446  decode.d8.loss_dice: 1.1292
2023/05/24 10:26:33 - mmengine - INFO - Iter(train) [130400/160000]  lr: 2.1901e-06  eta: 3:33:35  time: 0.4311  data_time: 0.0104  memory: 4899  grad_norm: 102.4463  loss: 39.6826  decode.loss_cls: 1.2521  decode.loss_mask: 0.9534  decode.loss_dice: 1.4603  decode.d0.loss_cls: 3.4438  decode.d0.loss_mask: 0.9760  decode.d0.loss_dice: 1.6654  decode.d1.loss_cls: 1.4515  decode.d1.loss_mask: 1.0275  decode.d1.loss_dice: 1.5675  decode.d2.loss_cls: 1.3653  decode.d2.loss_mask: 0.9801  decode.d2.loss_dice: 1.4983  decode.d3.loss_cls: 1.3204  decode.d3.loss_mask: 0.9761  decode.d3.loss_dice: 1.4455  decode.d4.loss_cls: 1.2633  decode.d4.loss_mask: 0.9747  decode.d4.loss_dice: 1.4694  decode.d5.loss_cls: 1.2872  decode.d5.loss_mask: 0.9640  decode.d5.loss_dice: 1.4495  decode.d6.loss_cls: 1.2513  decode.d6.loss_mask: 0.9437  decode.d6.loss_dice: 1.4272  decode.d7.loss_cls: 1.2610  decode.d7.loss_mask: 0.9401  decode.d7.loss_dice: 1.4362  decode.d8.loss_cls: 1.2961  decode.d8.loss_mask: 0.9314  decode.d8.loss_dice: 1.4039
2023/05/24 10:26:56 - mmengine - INFO - Iter(train) [130450/160000]  lr: 2.1867e-06  eta: 3:33:14  time: 0.4229  data_time: 0.0100  memory: 4857  grad_norm: 88.5967  loss: 41.6214  decode.loss_cls: 1.4533  decode.loss_mask: 0.7629  decode.loss_dice: 1.6078  decode.d0.loss_cls: 3.4700  decode.d0.loss_mask: 0.8108  decode.d0.loss_dice: 1.9071  decode.d1.loss_cls: 1.5187  decode.d1.loss_mask: 0.7781  decode.d1.loss_dice: 1.7592  decode.d2.loss_cls: 1.5382  decode.d2.loss_mask: 0.7883  decode.d2.loss_dice: 1.7128  decode.d3.loss_cls: 1.5386  decode.d3.loss_mask: 0.7954  decode.d3.loss_dice: 1.6553  decode.d4.loss_cls: 1.5470  decode.d4.loss_mask: 0.7798  decode.d4.loss_dice: 1.6554  decode.d5.loss_cls: 1.5559  decode.d5.loss_mask: 0.7580  decode.d5.loss_dice: 1.6066  decode.d6.loss_cls: 1.5534  decode.d6.loss_mask: 0.7547  decode.d6.loss_dice: 1.5886  decode.d7.loss_cls: 1.4784  decode.d7.loss_mask: 0.7758  decode.d7.loss_dice: 1.5982  decode.d8.loss_cls: 1.4997  decode.d8.loss_mask: 0.7508  decode.d8.loss_dice: 1.6223
2023/05/24 10:27:18 - mmengine - INFO - Iter(train) [130500/160000]  lr: 2.1834e-06  eta: 3:32:52  time: 0.4842  data_time: 0.0106  memory: 4864  grad_norm: 99.0738  loss: 36.9462  decode.loss_cls: 1.3713  decode.loss_mask: 0.6991  decode.loss_dice: 1.3393  decode.d0.loss_cls: 3.3947  decode.d0.loss_mask: 0.7579  decode.d0.loss_dice: 1.6042  decode.d1.loss_cls: 1.6336  decode.d1.loss_mask: 0.7266  decode.d1.loss_dice: 1.4206  decode.d2.loss_cls: 1.4675  decode.d2.loss_mask: 0.7098  decode.d2.loss_dice: 1.3589  decode.d3.loss_cls: 1.3342  decode.d3.loss_mask: 0.7069  decode.d3.loss_dice: 1.3678  decode.d4.loss_cls: 1.3722  decode.d4.loss_mask: 0.6927  decode.d4.loss_dice: 1.3660  decode.d5.loss_cls: 1.3666  decode.d5.loss_mask: 0.7118  decode.d5.loss_dice: 1.3688  decode.d6.loss_cls: 1.3254  decode.d6.loss_mask: 0.7041  decode.d6.loss_dice: 1.3199  decode.d7.loss_cls: 1.3834  decode.d7.loss_mask: 0.7199  decode.d7.loss_dice: 1.3265  decode.d8.loss_cls: 1.3549  decode.d8.loss_mask: 0.7189  decode.d8.loss_dice: 1.3228
2023/05/24 10:27:39 - mmengine - INFO - Iter(train) [130550/160000]  lr: 2.1801e-06  eta: 3:32:31  time: 0.4359  data_time: 0.0104  memory: 4857  grad_norm: 114.3647  loss: 35.3553  decode.loss_cls: 1.2147  decode.loss_mask: 0.7901  decode.loss_dice: 1.2545  decode.d0.loss_cls: 3.0827  decode.d0.loss_mask: 0.7703  decode.d0.loss_dice: 1.4422  decode.d1.loss_cls: 1.4894  decode.d1.loss_mask: 0.7652  decode.d1.loss_dice: 1.3105  decode.d2.loss_cls: 1.3282  decode.d2.loss_mask: 0.8126  decode.d2.loss_dice: 1.2915  decode.d3.loss_cls: 1.3220  decode.d3.loss_mask: 0.7759  decode.d3.loss_dice: 1.2589  decode.d4.loss_cls: 1.2700  decode.d4.loss_mask: 0.7687  decode.d4.loss_dice: 1.2644  decode.d5.loss_cls: 1.3382  decode.d5.loss_mask: 0.7645  decode.d5.loss_dice: 1.2171  decode.d6.loss_cls: 1.2568  decode.d6.loss_mask: 0.7798  decode.d6.loss_dice: 1.2224  decode.d7.loss_cls: 1.2605  decode.d7.loss_mask: 0.7963  decode.d7.loss_dice: 1.2372  decode.d8.loss_cls: 1.2470  decode.d8.loss_mask: 0.7880  decode.d8.loss_dice: 1.2357
2023/05/24 10:28:02 - mmengine - INFO - Iter(train) [130600/160000]  lr: 2.1767e-06  eta: 3:32:09  time: 0.4667  data_time: 0.0110  memory: 4879  grad_norm: 101.6710  loss: 25.1063  decode.loss_cls: 1.0163  decode.loss_mask: 0.5113  decode.loss_dice: 0.8046  decode.d0.loss_cls: 2.6526  decode.d0.loss_mask: 0.5361  decode.d0.loss_dice: 0.9203  decode.d1.loss_cls: 1.0885  decode.d1.loss_mask: 0.5260  decode.d1.loss_dice: 0.8330  decode.d2.loss_cls: 1.0654  decode.d2.loss_mask: 0.5166  decode.d2.loss_dice: 0.7964  decode.d3.loss_cls: 1.0410  decode.d3.loss_mask: 0.4694  decode.d3.loss_dice: 0.8070  decode.d4.loss_cls: 0.9613  decode.d4.loss_mask: 0.4934  decode.d4.loss_dice: 0.8106  decode.d5.loss_cls: 1.0377  decode.d5.loss_mask: 0.5009  decode.d5.loss_dice: 0.7965  decode.d6.loss_cls: 1.0046  decode.d6.loss_mask: 0.5104  decode.d6.loss_dice: 0.7974  decode.d7.loss_cls: 1.0296  decode.d7.loss_mask: 0.5077  decode.d7.loss_dice: 0.7771  decode.d8.loss_cls: 1.0379  decode.d8.loss_mask: 0.5019  decode.d8.loss_dice: 0.7546
2023/05/24 10:28:25 - mmengine - INFO - Iter(train) [130650/160000]  lr: 2.1734e-06  eta: 3:31:48  time: 0.4258  data_time: 0.0102  memory: 4868  grad_norm: 99.5075  loss: 36.5621  decode.loss_cls: 1.1483  decode.loss_mask: 0.9261  decode.loss_dice: 1.3080  decode.d0.loss_cls: 3.1050  decode.d0.loss_mask: 0.9818  decode.d0.loss_dice: 1.4402  decode.d1.loss_cls: 1.3704  decode.d1.loss_mask: 0.9131  decode.d1.loss_dice: 1.3695  decode.d2.loss_cls: 1.2707  decode.d2.loss_mask: 0.8945  decode.d2.loss_dice: 1.3714  decode.d3.loss_cls: 1.2642  decode.d3.loss_mask: 0.8939  decode.d3.loss_dice: 1.3294  decode.d4.loss_cls: 1.2147  decode.d4.loss_mask: 0.8844  decode.d4.loss_dice: 1.3262  decode.d5.loss_cls: 1.1779  decode.d5.loss_mask: 0.9294  decode.d5.loss_dice: 1.3282  decode.d6.loss_cls: 1.1943  decode.d6.loss_mask: 0.9138  decode.d6.loss_dice: 1.2900  decode.d7.loss_cls: 1.1151  decode.d7.loss_mask: 0.9384  decode.d7.loss_dice: 1.3102  decode.d8.loss_cls: 1.1454  decode.d8.loss_mask: 0.9304  decode.d8.loss_dice: 1.2772
2023/05/24 10:28:46 - mmengine - INFO - Iter(train) [130700/160000]  lr: 2.1701e-06  eta: 3:31:26  time: 0.4279  data_time: 0.0097  memory: 4838  grad_norm: 96.2827  loss: 26.6936  decode.loss_cls: 0.9286  decode.loss_mask: 0.5863  decode.loss_dice: 0.8440  decode.d0.loss_cls: 3.0037  decode.d0.loss_mask: 0.6403  decode.d0.loss_dice: 1.0289  decode.d1.loss_cls: 1.0852  decode.d1.loss_mask: 0.6134  decode.d1.loss_dice: 0.9527  decode.d2.loss_cls: 1.1267  decode.d2.loss_mask: 0.5997  decode.d2.loss_dice: 0.8938  decode.d3.loss_cls: 1.0365  decode.d3.loss_mask: 0.5827  decode.d3.loss_dice: 0.8716  decode.d4.loss_cls: 0.9613  decode.d4.loss_mask: 0.6043  decode.d4.loss_dice: 0.8609  decode.d5.loss_cls: 0.9400  decode.d5.loss_mask: 0.5902  decode.d5.loss_dice: 0.8525  decode.d6.loss_cls: 0.9765  decode.d6.loss_mask: 0.5789  decode.d6.loss_dice: 0.8333  decode.d7.loss_cls: 0.9046  decode.d7.loss_mask: 0.5974  decode.d7.loss_dice: 0.8515  decode.d8.loss_cls: 0.9389  decode.d8.loss_mask: 0.5800  decode.d8.loss_dice: 0.8288
2023/05/24 10:29:07 - mmengine - INFO - Iter(train) [130750/160000]  lr: 2.1667e-06  eta: 3:31:04  time: 0.4279  data_time: 0.0101  memory: 4866  grad_norm: 96.0837  loss: 36.9360  decode.loss_cls: 1.3224  decode.loss_mask: 0.7201  decode.loss_dice: 1.3596  decode.d0.loss_cls: 3.3750  decode.d0.loss_mask: 0.7521  decode.d0.loss_dice: 1.5976  decode.d1.loss_cls: 1.4675  decode.d1.loss_mask: 0.7671  decode.d1.loss_dice: 1.5357  decode.d2.loss_cls: 1.4010  decode.d2.loss_mask: 0.7183  decode.d2.loss_dice: 1.3893  decode.d3.loss_cls: 1.3370  decode.d3.loss_mask: 0.7324  decode.d3.loss_dice: 1.3645  decode.d4.loss_cls: 1.3488  decode.d4.loss_mask: 0.7278  decode.d4.loss_dice: 1.3831  decode.d5.loss_cls: 1.3278  decode.d5.loss_mask: 0.7356  decode.d5.loss_dice: 1.3749  decode.d6.loss_cls: 1.2605  decode.d6.loss_mask: 0.7315  decode.d6.loss_dice: 1.3887  decode.d7.loss_cls: 1.3129  decode.d7.loss_mask: 0.7181  decode.d7.loss_dice: 1.3770  decode.d8.loss_cls: 1.3026  decode.d8.loss_mask: 0.7275  decode.d8.loss_dice: 1.3796
2023/05/24 10:29:28 - mmengine - INFO - Iter(train) [130800/160000]  lr: 2.1634e-06  eta: 3:30:43  time: 0.4227  data_time: 0.0099  memory: 4864  grad_norm: 94.5477  loss: 30.6863  decode.loss_cls: 1.0505  decode.loss_mask: 0.8380  decode.loss_dice: 0.9738  decode.d0.loss_cls: 2.8224  decode.d0.loss_mask: 0.8140  decode.d0.loss_dice: 1.0361  decode.d1.loss_cls: 1.0786  decode.d1.loss_mask: 0.8820  decode.d1.loss_dice: 1.0447  decode.d2.loss_cls: 1.0129  decode.d2.loss_mask: 0.8547  decode.d2.loss_dice: 1.0287  decode.d3.loss_cls: 1.0598  decode.d3.loss_mask: 0.8449  decode.d3.loss_dice: 0.9869  decode.d4.loss_cls: 1.0047  decode.d4.loss_mask: 0.8591  decode.d4.loss_dice: 0.9946  decode.d5.loss_cls: 0.9863  decode.d5.loss_mask: 0.8564  decode.d5.loss_dice: 1.0109  decode.d6.loss_cls: 1.0845  decode.d6.loss_mask: 0.8682  decode.d6.loss_dice: 0.9715  decode.d7.loss_cls: 1.0439  decode.d7.loss_mask: 0.8329  decode.d7.loss_dice: 0.9780  decode.d8.loss_cls: 1.0237  decode.d8.loss_mask: 0.8467  decode.d8.loss_dice: 0.9970
2023/05/24 10:29:50 - mmengine - INFO - Iter(train) [130850/160000]  lr: 2.1601e-06  eta: 3:30:21  time: 0.4341  data_time: 0.0107  memory: 4845  grad_norm: 89.3029  loss: 40.6015  decode.loss_cls: 1.2727  decode.loss_mask: 0.8232  decode.loss_dice: 1.6483  decode.d0.loss_cls: 3.2210  decode.d0.loss_mask: 0.9191  decode.d0.loss_dice: 1.9333  decode.d1.loss_cls: 1.4340  decode.d1.loss_mask: 0.8787  decode.d1.loss_dice: 1.8354  decode.d2.loss_cls: 1.3822  decode.d2.loss_mask: 0.8400  decode.d2.loss_dice: 1.7509  decode.d3.loss_cls: 1.3837  decode.d3.loss_mask: 0.8245  decode.d3.loss_dice: 1.6764  decode.d4.loss_cls: 1.3015  decode.d4.loss_mask: 0.8287  decode.d4.loss_dice: 1.6856  decode.d5.loss_cls: 1.3139  decode.d5.loss_mask: 0.8262  decode.d5.loss_dice: 1.6470  decode.d6.loss_cls: 1.2561  decode.d6.loss_mask: 0.8269  decode.d6.loss_dice: 1.6292  decode.d7.loss_cls: 1.2972  decode.d7.loss_mask: 0.8223  decode.d7.loss_dice: 1.6363  decode.d8.loss_cls: 1.2496  decode.d8.loss_mask: 0.8212  decode.d8.loss_dice: 1.6363
2023/05/24 10:30:12 - mmengine - INFO - Iter(train) [130900/160000]  lr: 2.1567e-06  eta: 3:29:59  time: 0.4173  data_time: 0.0100  memory: 4875  grad_norm: 89.3167  loss: 36.5350  decode.loss_cls: 1.3272  decode.loss_mask: 0.8568  decode.loss_dice: 1.1803  decode.d0.loss_cls: 3.0618  decode.d0.loss_mask: 0.9272  decode.d0.loss_dice: 1.4182  decode.d1.loss_cls: 1.4539  decode.d1.loss_mask: 0.8826  decode.d1.loss_dice: 1.2853  decode.d2.loss_cls: 1.4734  decode.d2.loss_mask: 0.8310  decode.d2.loss_dice: 1.2242  decode.d3.loss_cls: 1.3994  decode.d3.loss_mask: 0.8525  decode.d3.loss_dice: 1.2274  decode.d4.loss_cls: 1.4260  decode.d4.loss_mask: 0.8406  decode.d4.loss_dice: 1.1595  decode.d5.loss_cls: 1.3930  decode.d5.loss_mask: 0.8467  decode.d5.loss_dice: 1.2096  decode.d6.loss_cls: 1.4210  decode.d6.loss_mask: 0.8436  decode.d6.loss_dice: 1.1784  decode.d7.loss_cls: 1.3566  decode.d7.loss_mask: 0.8495  decode.d7.loss_dice: 1.2091  decode.d8.loss_cls: 1.3040  decode.d8.loss_mask: 0.8525  decode.d8.loss_dice: 1.2435
2023/05/24 10:30:33 - mmengine - INFO - Iter(train) [130950/160000]  lr: 2.1534e-06  eta: 3:29:38  time: 0.4205  data_time: 0.0098  memory: 4836  grad_norm: 99.9787  loss: 34.7485  decode.loss_cls: 1.2384  decode.loss_mask: 0.7818  decode.loss_dice: 1.1608  decode.d0.loss_cls: 2.9594  decode.d0.loss_mask: 0.8368  decode.d0.loss_dice: 1.4261  decode.d1.loss_cls: 1.4195  decode.d1.loss_mask: 0.8583  decode.d1.loss_dice: 1.3103  decode.d2.loss_cls: 1.3740  decode.d2.loss_mask: 0.7881  decode.d2.loss_dice: 1.2136  decode.d3.loss_cls: 1.2976  decode.d3.loss_mask: 0.8032  decode.d3.loss_dice: 1.1982  decode.d4.loss_cls: 1.2681  decode.d4.loss_mask: 0.7782  decode.d4.loss_dice: 1.1766  decode.d5.loss_cls: 1.2845  decode.d5.loss_mask: 0.7853  decode.d5.loss_dice: 1.1832  decode.d6.loss_cls: 1.2407  decode.d6.loss_mask: 0.7828  decode.d6.loss_dice: 1.1622  decode.d7.loss_cls: 1.2958  decode.d7.loss_mask: 0.7734  decode.d7.loss_dice: 1.1446  decode.d8.loss_cls: 1.2302  decode.d8.loss_mask: 0.7896  decode.d8.loss_dice: 1.1872
2023/05/24 10:30:54 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 10:30:54 - mmengine - INFO - Iter(train) [131000/160000]  lr: 2.1501e-06  eta: 3:29:16  time: 0.4258  data_time: 0.0098  memory: 4876  grad_norm: 88.8771  loss: 26.0669  decode.loss_cls: 0.6833  decode.loss_mask: 0.5714  decode.loss_dice: 1.0072  decode.d0.loss_cls: 2.8568  decode.d0.loss_mask: 0.6468  decode.d0.loss_dice: 1.2776  decode.d1.loss_cls: 0.8019  decode.d1.loss_mask: 0.6559  decode.d1.loss_dice: 1.1972  decode.d2.loss_cls: 0.7142  decode.d2.loss_mask: 0.6080  decode.d2.loss_dice: 1.1100  decode.d3.loss_cls: 0.7138  decode.d3.loss_mask: 0.6006  decode.d3.loss_dice: 1.0898  decode.d4.loss_cls: 0.6837  decode.d4.loss_mask: 0.5974  decode.d4.loss_dice: 1.0728  decode.d5.loss_cls: 0.6907  decode.d5.loss_mask: 0.5831  decode.d5.loss_dice: 1.0554  decode.d6.loss_cls: 0.6600  decode.d6.loss_mask: 0.5754  decode.d6.loss_dice: 1.0543  decode.d7.loss_cls: 0.6398  decode.d7.loss_mask: 0.5789  decode.d7.loss_dice: 1.0416  decode.d8.loss_cls: 0.7035  decode.d8.loss_mask: 0.5675  decode.d8.loss_dice: 1.0280
2023/05/24 10:30:54 - mmengine - INFO - Saving checkpoint at 131000 iterations
2023/05/24 10:31:22 - mmengine - INFO - Iter(train) [131050/160000]  lr: 2.1467e-06  eta: 3:28:55  time: 0.4262  data_time: 0.0099  memory: 4824  grad_norm: 96.7978  loss: 35.6045  decode.loss_cls: 1.2230  decode.loss_mask: 0.6796  decode.loss_dice: 1.4575  decode.d0.loss_cls: 3.0033  decode.d0.loss_mask: 0.7762  decode.d0.loss_dice: 1.6759  decode.d1.loss_cls: 1.3814  decode.d1.loss_mask: 0.6870  decode.d1.loss_dice: 1.5208  decode.d2.loss_cls: 1.2144  decode.d2.loss_mask: 0.7075  decode.d2.loss_dice: 1.4818  decode.d3.loss_cls: 1.1921  decode.d3.loss_mask: 0.6949  decode.d3.loss_dice: 1.4631  decode.d4.loss_cls: 1.1876  decode.d4.loss_mask: 0.6791  decode.d4.loss_dice: 1.4748  decode.d5.loss_cls: 1.1352  decode.d5.loss_mask: 0.6854  decode.d5.loss_dice: 1.4717  decode.d6.loss_cls: 1.1350  decode.d6.loss_mask: 0.6776  decode.d6.loss_dice: 1.4590  decode.d7.loss_cls: 1.1799  decode.d7.loss_mask: 0.6678  decode.d7.loss_dice: 1.4397  decode.d8.loss_cls: 1.1403  decode.d8.loss_mask: 0.6748  decode.d8.loss_dice: 1.4380
2023/05/24 10:31:43 - mmengine - INFO - Iter(train) [131100/160000]  lr: 2.1434e-06  eta: 3:28:34  time: 0.4331  data_time: 0.0098  memory: 4857  grad_norm: 107.9799  loss: 33.4004  decode.loss_cls: 1.1585  decode.loss_mask: 0.8165  decode.loss_dice: 1.0620  decode.d0.loss_cls: 3.1827  decode.d0.loss_mask: 0.8162  decode.d0.loss_dice: 1.2243  decode.d1.loss_cls: 1.3715  decode.d1.loss_mask: 0.8753  decode.d1.loss_dice: 1.1605  decode.d2.loss_cls: 1.3073  decode.d2.loss_mask: 0.8256  decode.d2.loss_dice: 1.0854  decode.d3.loss_cls: 1.2187  decode.d3.loss_mask: 0.8262  decode.d3.loss_dice: 1.0921  decode.d4.loss_cls: 1.2716  decode.d4.loss_mask: 0.8026  decode.d4.loss_dice: 1.0569  decode.d5.loss_cls: 1.2135  decode.d5.loss_mask: 0.8049  decode.d5.loss_dice: 1.0609  decode.d6.loss_cls: 1.2169  decode.d6.loss_mask: 0.8285  decode.d6.loss_dice: 1.0166  decode.d7.loss_cls: 1.2286  decode.d7.loss_mask: 0.8096  decode.d7.loss_dice: 1.0428  decode.d8.loss_cls: 1.1569  decode.d8.loss_mask: 0.8124  decode.d8.loss_dice: 1.0549
2023/05/24 10:32:04 - mmengine - INFO - Iter(train) [131150/160000]  lr: 2.1401e-06  eta: 3:28:12  time: 0.4260  data_time: 0.0100  memory: 4855  grad_norm: 96.8605  loss: 39.7814  decode.loss_cls: 1.5383  decode.loss_mask: 0.7590  decode.loss_dice: 1.3757  decode.d0.loss_cls: 3.2708  decode.d0.loss_mask: 0.8548  decode.d0.loss_dice: 1.7151  decode.d1.loss_cls: 1.6603  decode.d1.loss_mask: 0.8362  decode.d1.loss_dice: 1.5742  decode.d2.loss_cls: 1.6449  decode.d2.loss_mask: 0.8084  decode.d2.loss_dice: 1.4911  decode.d3.loss_cls: 1.5639  decode.d3.loss_mask: 0.8007  decode.d3.loss_dice: 1.3854  decode.d4.loss_cls: 1.5249  decode.d4.loss_mask: 0.8471  decode.d4.loss_dice: 1.4337  decode.d5.loss_cls: 1.4725  decode.d5.loss_mask: 0.7931  decode.d5.loss_dice: 1.4158  decode.d6.loss_cls: 1.4636  decode.d6.loss_mask: 0.7939  decode.d6.loss_dice: 1.4558  decode.d7.loss_cls: 1.4699  decode.d7.loss_mask: 0.7552  decode.d7.loss_dice: 1.3968  decode.d8.loss_cls: 1.5223  decode.d8.loss_mask: 0.7460  decode.d8.loss_dice: 1.4121
2023/05/24 10:32:25 - mmengine - INFO - Iter(train) [131200/160000]  lr: 2.1367e-06  eta: 3:27:50  time: 0.4176  data_time: 0.0098  memory: 4818  grad_norm: 98.9976  loss: 44.8314  decode.loss_cls: 1.4387  decode.loss_mask: 0.9967  decode.loss_dice: 1.6208  decode.d0.loss_cls: 3.5379  decode.d0.loss_mask: 1.0812  decode.d0.loss_dice: 2.1005  decode.d1.loss_cls: 1.6338  decode.d1.loss_mask: 1.1169  decode.d1.loss_dice: 1.9343  decode.d2.loss_cls: 1.5729  decode.d2.loss_mask: 1.0857  decode.d2.loss_dice: 1.7724  decode.d3.loss_cls: 1.4889  decode.d3.loss_mask: 1.0466  decode.d3.loss_dice: 1.7084  decode.d4.loss_cls: 1.5009  decode.d4.loss_mask: 1.0470  decode.d4.loss_dice: 1.7001  decode.d5.loss_cls: 1.4413  decode.d5.loss_mask: 1.0155  decode.d5.loss_dice: 1.7020  decode.d6.loss_cls: 1.4733  decode.d6.loss_mask: 1.0000  decode.d6.loss_dice: 1.6577  decode.d7.loss_cls: 1.4472  decode.d7.loss_mask: 0.9862  decode.d7.loss_dice: 1.6580  decode.d8.loss_cls: 1.4290  decode.d8.loss_mask: 0.9962  decode.d8.loss_dice: 1.6414
2023/05/24 10:32:47 - mmengine - INFO - Iter(train) [131250/160000]  lr: 2.1334e-06  eta: 3:27:28  time: 0.4181  data_time: 0.0098  memory: 4896  grad_norm: 90.7975  loss: 38.4330  decode.loss_cls: 1.4366  decode.loss_mask: 0.7060  decode.loss_dice: 1.4095  decode.d0.loss_cls: 3.4395  decode.d0.loss_mask: 0.8004  decode.d0.loss_dice: 1.6278  decode.d1.loss_cls: 1.5488  decode.d1.loss_mask: 0.7005  decode.d1.loss_dice: 1.4739  decode.d2.loss_cls: 1.5206  decode.d2.loss_mask: 0.7114  decode.d2.loss_dice: 1.4511  decode.d3.loss_cls: 1.5042  decode.d3.loss_mask: 0.7086  decode.d3.loss_dice: 1.4580  decode.d4.loss_cls: 1.5007  decode.d4.loss_mask: 0.7200  decode.d4.loss_dice: 1.4434  decode.d5.loss_cls: 1.4895  decode.d5.loss_mask: 0.6778  decode.d5.loss_dice: 1.4250  decode.d6.loss_cls: 1.4230  decode.d6.loss_mask: 0.7134  decode.d6.loss_dice: 1.4218  decode.d7.loss_cls: 1.4243  decode.d7.loss_mask: 0.7090  decode.d7.loss_dice: 1.4189  decode.d8.loss_cls: 1.4601  decode.d8.loss_mask: 0.7024  decode.d8.loss_dice: 1.4070
2023/05/24 10:33:08 - mmengine - INFO - Iter(train) [131300/160000]  lr: 2.1300e-06  eta: 3:27:07  time: 0.4342  data_time: 0.0098  memory: 4835  grad_norm: 84.2151  loss: 31.0979  decode.loss_cls: 0.9797  decode.loss_mask: 0.7031  decode.loss_dice: 1.1187  decode.d0.loss_cls: 2.8256  decode.d0.loss_mask: 0.7530  decode.d0.loss_dice: 1.3238  decode.d1.loss_cls: 1.1393  decode.d1.loss_mask: 0.7030  decode.d1.loss_dice: 1.2440  decode.d2.loss_cls: 1.1544  decode.d2.loss_mask: 0.6584  decode.d2.loss_dice: 1.2142  decode.d3.loss_cls: 1.0609  decode.d3.loss_mask: 0.6531  decode.d3.loss_dice: 1.1429  decode.d4.loss_cls: 1.0332  decode.d4.loss_mask: 0.6987  decode.d4.loss_dice: 1.1349  decode.d5.loss_cls: 1.0491  decode.d5.loss_mask: 0.7006  decode.d5.loss_dice: 1.1562  decode.d6.loss_cls: 1.0300  decode.d6.loss_mask: 0.7120  decode.d6.loss_dice: 1.1636  decode.d7.loss_cls: 1.0379  decode.d7.loss_mask: 0.7044  decode.d7.loss_dice: 1.1575  decode.d8.loss_cls: 1.0024  decode.d8.loss_mask: 0.7143  decode.d8.loss_dice: 1.1292
2023/05/24 10:33:30 - mmengine - INFO - Iter(train) [131350/160000]  lr: 2.1267e-06  eta: 3:26:45  time: 0.4255  data_time: 0.0098  memory: 4821  grad_norm: 101.0452  loss: 37.0861  decode.loss_cls: 1.1545  decode.loss_mask: 0.9622  decode.loss_dice: 1.3221  decode.d0.loss_cls: 3.1897  decode.d0.loss_mask: 0.9130  decode.d0.loss_dice: 1.5047  decode.d1.loss_cls: 1.3713  decode.d1.loss_mask: 0.9276  decode.d1.loss_dice: 1.3606  decode.d2.loss_cls: 1.2652  decode.d2.loss_mask: 0.9144  decode.d2.loss_dice: 1.3821  decode.d3.loss_cls: 1.2556  decode.d3.loss_mask: 0.9339  decode.d3.loss_dice: 1.3086  decode.d4.loss_cls: 1.2612  decode.d4.loss_mask: 0.9614  decode.d4.loss_dice: 1.3419  decode.d5.loss_cls: 1.2156  decode.d5.loss_mask: 0.9481  decode.d5.loss_dice: 1.3049  decode.d6.loss_cls: 1.2121  decode.d6.loss_mask: 0.9527  decode.d6.loss_dice: 1.3112  decode.d7.loss_cls: 1.0971  decode.d7.loss_mask: 0.9630  decode.d7.loss_dice: 1.3485  decode.d8.loss_cls: 1.1338  decode.d8.loss_mask: 0.9477  decode.d8.loss_dice: 1.3216
2023/05/24 10:33:51 - mmengine - INFO - Iter(train) [131400/160000]  lr: 2.1234e-06  eta: 3:26:23  time: 0.4366  data_time: 0.0105  memory: 4885  grad_norm: 106.5783  loss: 33.4568  decode.loss_cls: 1.1278  decode.loss_mask: 0.6914  decode.loss_dice: 1.3067  decode.d0.loss_cls: 3.0138  decode.d0.loss_mask: 0.7398  decode.d0.loss_dice: 1.4815  decode.d1.loss_cls: 1.1997  decode.d1.loss_mask: 0.7118  decode.d1.loss_dice: 1.3893  decode.d2.loss_cls: 1.1528  decode.d2.loss_mask: 0.7015  decode.d2.loss_dice: 1.3000  decode.d3.loss_cls: 1.1153  decode.d3.loss_mask: 0.7060  decode.d3.loss_dice: 1.3090  decode.d4.loss_cls: 1.1136  decode.d4.loss_mask: 0.7080  decode.d4.loss_dice: 1.3093  decode.d5.loss_cls: 1.1028  decode.d5.loss_mask: 0.6825  decode.d5.loss_dice: 1.2999  decode.d6.loss_cls: 1.1071  decode.d6.loss_mask: 0.6937  decode.d6.loss_dice: 1.2621  decode.d7.loss_cls: 1.1248  decode.d7.loss_mask: 0.6939  decode.d7.loss_dice: 1.2831  decode.d8.loss_cls: 1.1649  decode.d8.loss_mask: 0.6796  decode.d8.loss_dice: 1.2850
2023/05/24 10:34:13 - mmengine - INFO - Iter(train) [131450/160000]  lr: 2.1200e-06  eta: 3:26:02  time: 0.4273  data_time: 0.0102  memory: 4823  grad_norm: 85.0468  loss: 34.7073  decode.loss_cls: 1.0362  decode.loss_mask: 0.7423  decode.loss_dice: 1.3755  decode.d0.loss_cls: 3.1919  decode.d0.loss_mask: 0.7959  decode.d0.loss_dice: 1.5645  decode.d1.loss_cls: 1.2399  decode.d1.loss_mask: 0.7647  decode.d1.loss_dice: 1.4320  decode.d2.loss_cls: 1.1975  decode.d2.loss_mask: 0.7451  decode.d2.loss_dice: 1.4285  decode.d3.loss_cls: 1.0619  decode.d3.loss_mask: 0.7661  decode.d3.loss_dice: 1.3629  decode.d4.loss_cls: 1.0638  decode.d4.loss_mask: 0.7589  decode.d4.loss_dice: 1.4155  decode.d5.loss_cls: 1.0193  decode.d5.loss_mask: 0.7778  decode.d5.loss_dice: 1.3873  decode.d6.loss_cls: 1.0709  decode.d6.loss_mask: 0.7556  decode.d6.loss_dice: 1.3803  decode.d7.loss_cls: 1.0568  decode.d7.loss_mask: 0.7600  decode.d7.loss_dice: 1.3972  decode.d8.loss_cls: 1.0989  decode.d8.loss_mask: 0.7536  decode.d8.loss_dice: 1.3065
2023/05/24 10:34:34 - mmengine - INFO - Iter(train) [131500/160000]  lr: 2.1167e-06  eta: 3:25:40  time: 0.4193  data_time: 0.0102  memory: 4918  grad_norm: 90.8908  loss: 35.6422  decode.loss_cls: 1.0823  decode.loss_mask: 0.8339  decode.loss_dice: 1.3586  decode.d0.loss_cls: 3.1186  decode.d0.loss_mask: 0.8812  decode.d0.loss_dice: 1.4958  decode.d1.loss_cls: 1.1988  decode.d1.loss_mask: 0.8723  decode.d1.loss_dice: 1.4542  decode.d2.loss_cls: 1.1903  decode.d2.loss_mask: 0.8271  decode.d2.loss_dice: 1.4026  decode.d3.loss_cls: 1.1344  decode.d3.loss_mask: 0.8367  decode.d3.loss_dice: 1.3945  decode.d4.loss_cls: 1.1378  decode.d4.loss_mask: 0.8321  decode.d4.loss_dice: 1.3802  decode.d5.loss_cls: 1.1087  decode.d5.loss_mask: 0.8162  decode.d5.loss_dice: 1.4125  decode.d6.loss_cls: 1.0728  decode.d6.loss_mask: 0.8126  decode.d6.loss_dice: 1.3949  decode.d7.loss_cls: 1.0760  decode.d7.loss_mask: 0.8339  decode.d7.loss_dice: 1.3846  decode.d8.loss_cls: 1.0976  decode.d8.loss_mask: 0.8331  decode.d8.loss_dice: 1.3679
2023/05/24 10:34:55 - mmengine - INFO - Iter(train) [131550/160000]  lr: 2.1133e-06  eta: 3:25:18  time: 0.4263  data_time: 0.0108  memory: 4859  grad_norm: 122.0967  loss: 33.1917  decode.loss_cls: 1.0254  decode.loss_mask: 0.7623  decode.loss_dice: 1.2252  decode.d0.loss_cls: 3.0133  decode.d0.loss_mask: 0.8460  decode.d0.loss_dice: 1.5037  decode.d1.loss_cls: 1.1633  decode.d1.loss_mask: 0.7745  decode.d1.loss_dice: 1.3531  decode.d2.loss_cls: 1.0830  decode.d2.loss_mask: 0.8063  decode.d2.loss_dice: 1.3791  decode.d3.loss_cls: 1.1197  decode.d3.loss_mask: 0.7478  decode.d3.loss_dice: 1.2227  decode.d4.loss_cls: 1.0580  decode.d4.loss_mask: 0.7677  decode.d4.loss_dice: 1.2686  decode.d5.loss_cls: 1.0469  decode.d5.loss_mask: 0.7613  decode.d5.loss_dice: 1.2324  decode.d6.loss_cls: 1.0760  decode.d6.loss_mask: 0.7504  decode.d6.loss_dice: 1.2182  decode.d7.loss_cls: 1.0146  decode.d7.loss_mask: 0.7523  decode.d7.loss_dice: 1.2515  decode.d8.loss_cls: 1.0461  decode.d8.loss_mask: 0.7400  decode.d8.loss_dice: 1.1823
2023/05/24 10:35:16 - mmengine - INFO - Iter(train) [131600/160000]  lr: 2.1100e-06  eta: 3:24:56  time: 0.4123  data_time: 0.0098  memory: 4857  grad_norm: 87.2795  loss: 34.3885  decode.loss_cls: 1.0062  decode.loss_mask: 0.8089  decode.loss_dice: 1.3149  decode.d0.loss_cls: 3.1157  decode.d0.loss_mask: 0.8850  decode.d0.loss_dice: 1.5589  decode.d1.loss_cls: 1.1543  decode.d1.loss_mask: 0.8584  decode.d1.loss_dice: 1.3970  decode.d2.loss_cls: 1.1155  decode.d2.loss_mask: 0.8317  decode.d2.loss_dice: 1.3697  decode.d3.loss_cls: 1.0625  decode.d3.loss_mask: 0.8244  decode.d3.loss_dice: 1.3285  decode.d4.loss_cls: 1.0563  decode.d4.loss_mask: 0.8187  decode.d4.loss_dice: 1.3225  decode.d5.loss_cls: 1.0182  decode.d5.loss_mask: 0.8085  decode.d5.loss_dice: 1.3291  decode.d6.loss_cls: 1.0134  decode.d6.loss_mask: 0.7935  decode.d6.loss_dice: 1.3192  decode.d7.loss_cls: 1.0106  decode.d7.loss_mask: 0.8044  decode.d7.loss_dice: 1.3247  decode.d8.loss_cls: 1.0151  decode.d8.loss_mask: 0.8102  decode.d8.loss_dice: 1.3128
2023/05/24 10:35:38 - mmengine - INFO - Iter(train) [131650/160000]  lr: 2.1066e-06  eta: 3:24:35  time: 0.4335  data_time: 0.0104  memory: 4820  grad_norm: 108.4652  loss: 28.2629  decode.loss_cls: 1.0902  decode.loss_mask: 0.6259  decode.loss_dice: 0.8100  decode.d0.loss_cls: 3.0199  decode.d0.loss_mask: 0.6737  decode.d0.loss_dice: 0.9470  decode.d1.loss_cls: 1.3412  decode.d1.loss_mask: 0.6654  decode.d1.loss_dice: 0.8988  decode.d2.loss_cls: 1.1614  decode.d2.loss_mask: 0.6919  decode.d2.loss_dice: 0.8744  decode.d3.loss_cls: 1.1179  decode.d3.loss_mask: 0.6591  decode.d3.loss_dice: 0.8117  decode.d4.loss_cls: 1.0811  decode.d4.loss_mask: 0.6542  decode.d4.loss_dice: 0.8512  decode.d5.loss_cls: 1.0724  decode.d5.loss_mask: 0.6857  decode.d5.loss_dice: 0.8454  decode.d6.loss_cls: 1.1290  decode.d6.loss_mask: 0.6294  decode.d6.loss_dice: 0.8237  decode.d7.loss_cls: 1.0899  decode.d7.loss_mask: 0.6257  decode.d7.loss_dice: 0.8520  decode.d8.loss_cls: 1.1154  decode.d8.loss_mask: 0.6214  decode.d8.loss_dice: 0.7979
2023/05/24 10:35:59 - mmengine - INFO - Iter(train) [131700/160000]  lr: 2.1033e-06  eta: 3:24:13  time: 0.4228  data_time: 0.0104  memory: 4906  grad_norm: 93.2183  loss: 36.7030  decode.loss_cls: 1.1632  decode.loss_mask: 0.7493  decode.loss_dice: 1.4377  decode.d0.loss_cls: 2.9575  decode.d0.loss_mask: 0.8126  decode.d0.loss_dice: 1.7182  decode.d1.loss_cls: 1.3467  decode.d1.loss_mask: 0.8358  decode.d1.loss_dice: 1.6036  decode.d2.loss_cls: 1.2006  decode.d2.loss_mask: 0.8117  decode.d2.loss_dice: 1.5593  decode.d3.loss_cls: 1.1651  decode.d3.loss_mask: 0.8087  decode.d3.loss_dice: 1.5081  decode.d4.loss_cls: 1.1805  decode.d4.loss_mask: 0.7881  decode.d4.loss_dice: 1.5292  decode.d5.loss_cls: 1.1489  decode.d5.loss_mask: 0.7706  decode.d5.loss_dice: 1.4904  decode.d6.loss_cls: 1.1905  decode.d6.loss_mask: 0.7529  decode.d6.loss_dice: 1.4628  decode.d7.loss_cls: 1.1363  decode.d7.loss_mask: 0.7573  decode.d7.loss_dice: 1.4773  decode.d8.loss_cls: 1.1437  decode.d8.loss_mask: 0.7567  decode.d8.loss_dice: 1.4398
2023/05/24 10:36:20 - mmengine - INFO - Iter(train) [131750/160000]  lr: 2.1000e-06  eta: 3:23:51  time: 0.4419  data_time: 0.0099  memory: 4811  grad_norm: 96.1150  loss: 35.2335  decode.loss_cls: 1.2037  decode.loss_mask: 0.7321  decode.loss_dice: 1.3449  decode.d0.loss_cls: 3.0692  decode.d0.loss_mask: 0.7471  decode.d0.loss_dice: 1.5766  decode.d1.loss_cls: 1.3352  decode.d1.loss_mask: 0.7105  decode.d1.loss_dice: 1.4556  decode.d2.loss_cls: 1.2478  decode.d2.loss_mask: 0.7115  decode.d2.loss_dice: 1.3967  decode.d3.loss_cls: 1.2100  decode.d3.loss_mask: 0.7174  decode.d3.loss_dice: 1.3685  decode.d4.loss_cls: 1.2744  decode.d4.loss_mask: 0.6822  decode.d4.loss_dice: 1.3336  decode.d5.loss_cls: 1.2360  decode.d5.loss_mask: 0.6929  decode.d5.loss_dice: 1.3377  decode.d6.loss_cls: 1.2079  decode.d6.loss_mask: 0.7056  decode.d6.loss_dice: 1.3574  decode.d7.loss_cls: 1.1765  decode.d7.loss_mask: 0.7357  decode.d7.loss_dice: 1.3774  decode.d8.loss_cls: 1.1773  decode.d8.loss_mask: 0.7359  decode.d8.loss_dice: 1.3763
2023/05/24 10:36:44 - mmengine - INFO - Iter(train) [131800/160000]  lr: 2.0966e-06  eta: 3:23:30  time: 0.4728  data_time: 0.0097  memory: 4802  grad_norm: 105.5242  loss: 35.5028  decode.loss_cls: 1.1648  decode.loss_mask: 0.8807  decode.loss_dice: 1.2052  decode.d0.loss_cls: 3.1661  decode.d0.loss_mask: 0.8955  decode.d0.loss_dice: 1.4389  decode.d1.loss_cls: 1.3088  decode.d1.loss_mask: 0.8571  decode.d1.loss_dice: 1.3350  decode.d2.loss_cls: 1.2608  decode.d2.loss_mask: 0.8611  decode.d2.loss_dice: 1.2867  decode.d3.loss_cls: 1.2713  decode.d3.loss_mask: 0.8638  decode.d3.loss_dice: 1.2351  decode.d4.loss_cls: 1.2142  decode.d4.loss_mask: 0.8769  decode.d4.loss_dice: 1.2431  decode.d5.loss_cls: 1.2006  decode.d5.loss_mask: 0.8757  decode.d5.loss_dice: 1.2601  decode.d6.loss_cls: 1.1849  decode.d6.loss_mask: 0.8836  decode.d6.loss_dice: 1.2021  decode.d7.loss_cls: 1.1665  decode.d7.loss_mask: 0.8988  decode.d7.loss_dice: 1.2126  decode.d8.loss_cls: 1.1580  decode.d8.loss_mask: 0.8764  decode.d8.loss_dice: 1.2181
2023/05/24 10:37:05 - mmengine - INFO - Iter(train) [131850/160000]  lr: 2.0933e-06  eta: 3:23:08  time: 0.4315  data_time: 0.0103  memory: 4801  grad_norm: 93.8036  loss: 29.0662  decode.loss_cls: 0.9883  decode.loss_mask: 0.6358  decode.loss_dice: 0.9434  decode.d0.loss_cls: 3.0935  decode.d0.loss_mask: 0.7645  decode.d0.loss_dice: 1.1198  decode.d1.loss_cls: 1.1342  decode.d1.loss_mask: 0.6594  decode.d1.loss_dice: 1.0059  decode.d2.loss_cls: 1.1363  decode.d2.loss_mask: 0.6971  decode.d2.loss_dice: 0.9852  decode.d3.loss_cls: 1.1380  decode.d3.loss_mask: 0.6818  decode.d3.loss_dice: 0.9576  decode.d4.loss_cls: 1.0371  decode.d4.loss_mask: 0.6430  decode.d4.loss_dice: 0.9796  decode.d5.loss_cls: 1.0520  decode.d5.loss_mask: 0.6374  decode.d5.loss_dice: 0.9643  decode.d6.loss_cls: 1.0075  decode.d6.loss_mask: 0.6376  decode.d6.loss_dice: 0.9542  decode.d7.loss_cls: 1.0238  decode.d7.loss_mask: 0.6414  decode.d7.loss_dice: 0.9487  decode.d8.loss_cls: 1.0308  decode.d8.loss_mask: 0.6330  decode.d8.loss_dice: 0.9354
2023/05/24 10:37:26 - mmengine - INFO - Iter(train) [131900/160000]  lr: 2.0899e-06  eta: 3:22:47  time: 0.4230  data_time: 0.0108  memory: 4838  grad_norm: 116.5468  loss: 30.6010  decode.loss_cls: 0.9417  decode.loss_mask: 0.7958  decode.loss_dice: 1.0234  decode.d0.loss_cls: 2.6782  decode.d0.loss_mask: 0.9197  decode.d0.loss_dice: 1.2214  decode.d1.loss_cls: 1.1590  decode.d1.loss_mask: 0.8185  decode.d1.loss_dice: 1.1400  decode.d2.loss_cls: 1.0703  decode.d2.loss_mask: 0.7931  decode.d2.loss_dice: 1.0775  decode.d3.loss_cls: 1.0246  decode.d3.loss_mask: 0.7830  decode.d3.loss_dice: 1.0418  decode.d4.loss_cls: 1.0271  decode.d4.loss_mask: 0.7897  decode.d4.loss_dice: 1.0267  decode.d5.loss_cls: 0.9814  decode.d5.loss_mask: 0.8119  decode.d5.loss_dice: 1.0305  decode.d6.loss_cls: 0.9614  decode.d6.loss_mask: 0.8179  decode.d6.loss_dice: 1.0256  decode.d7.loss_cls: 0.9623  decode.d7.loss_mask: 0.8128  decode.d7.loss_dice: 1.0375  decode.d8.loss_cls: 0.9845  decode.d8.loss_mask: 0.8109  decode.d8.loss_dice: 1.0328
2023/05/24 10:37:48 - mmengine - INFO - Iter(train) [131950/160000]  lr: 2.0866e-06  eta: 3:22:25  time: 0.4279  data_time: 0.0103  memory: 4859  grad_norm: 100.3320  loss: 34.2992  decode.loss_cls: 1.0209  decode.loss_mask: 0.7577  decode.loss_dice: 1.3210  decode.d0.loss_cls: 2.9886  decode.d0.loss_mask: 0.8666  decode.d0.loss_dice: 1.5815  decode.d1.loss_cls: 1.2251  decode.d1.loss_mask: 0.8242  decode.d1.loss_dice: 1.4733  decode.d2.loss_cls: 1.1223  decode.d2.loss_mask: 0.7877  decode.d2.loss_dice: 1.4015  decode.d3.loss_cls: 1.1019  decode.d3.loss_mask: 0.7776  decode.d3.loss_dice: 1.3602  decode.d4.loss_cls: 1.0567  decode.d4.loss_mask: 0.7845  decode.d4.loss_dice: 1.3486  decode.d5.loss_cls: 1.0216  decode.d5.loss_mask: 0.7692  decode.d5.loss_dice: 1.3364  decode.d6.loss_cls: 1.0183  decode.d6.loss_mask: 0.7580  decode.d6.loss_dice: 1.3301  decode.d7.loss_cls: 1.0631  decode.d7.loss_mask: 0.7554  decode.d7.loss_dice: 1.3313  decode.d8.loss_cls: 1.0277  decode.d8.loss_mask: 0.7558  decode.d8.loss_dice: 1.3323
2023/05/24 10:38:09 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 10:38:09 - mmengine - INFO - Iter(train) [132000/160000]  lr: 2.0832e-06  eta: 3:22:03  time: 0.4522  data_time: 0.0114  memory: 4844  grad_norm: 128.0521  loss: 38.8784  decode.loss_cls: 1.2517  decode.loss_mask: 0.8967  decode.loss_dice: 1.5177  decode.d0.loss_cls: 2.9619  decode.d0.loss_mask: 0.9306  decode.d0.loss_dice: 1.6645  decode.d1.loss_cls: 1.3384  decode.d1.loss_mask: 0.9754  decode.d1.loss_dice: 1.6304  decode.d2.loss_cls: 1.3954  decode.d2.loss_mask: 0.9326  decode.d2.loss_dice: 1.5083  decode.d3.loss_cls: 1.2598  decode.d3.loss_mask: 0.9262  decode.d3.loss_dice: 1.4905  decode.d4.loss_cls: 1.2849  decode.d4.loss_mask: 0.9083  decode.d4.loss_dice: 1.5006  decode.d5.loss_cls: 1.2209  decode.d5.loss_mask: 0.8906  decode.d5.loss_dice: 1.5260  decode.d6.loss_cls: 1.2418  decode.d6.loss_mask: 0.9015  decode.d6.loss_dice: 1.4781  decode.d7.loss_cls: 1.2003  decode.d7.loss_mask: 0.9032  decode.d7.loss_dice: 1.5303  decode.d8.loss_cls: 1.2340  decode.d8.loss_mask: 0.9038  decode.d8.loss_dice: 1.4740
2023/05/24 10:38:09 - mmengine - INFO - Saving checkpoint at 132000 iterations
2023/05/24 10:38:37 - mmengine - INFO - Iter(train) [132050/160000]  lr: 2.0799e-06  eta: 3:21:43  time: 0.4229  data_time: 0.0098  memory: 4821  grad_norm: 93.0815  loss: 29.9646  decode.loss_cls: 0.8970  decode.loss_mask: 0.7323  decode.loss_dice: 1.1084  decode.d0.loss_cls: 2.7169  decode.d0.loss_mask: 0.7652  decode.d0.loss_dice: 1.2601  decode.d1.loss_cls: 1.0624  decode.d1.loss_mask: 0.8138  decode.d1.loss_dice: 1.1633  decode.d2.loss_cls: 1.0166  decode.d2.loss_mask: 0.7304  decode.d2.loss_dice: 1.1451  decode.d3.loss_cls: 0.9649  decode.d3.loss_mask: 0.7338  decode.d3.loss_dice: 1.1462  decode.d4.loss_cls: 0.9414  decode.d4.loss_mask: 0.7222  decode.d4.loss_dice: 1.1092  decode.d5.loss_cls: 0.9308  decode.d5.loss_mask: 0.7287  decode.d5.loss_dice: 1.1017  decode.d6.loss_cls: 0.8850  decode.d6.loss_mask: 0.7334  decode.d6.loss_dice: 1.1115  decode.d7.loss_cls: 0.8906  decode.d7.loss_mask: 0.7290  decode.d7.loss_dice: 1.1079  decode.d8.loss_cls: 0.8907  decode.d8.loss_mask: 0.7253  decode.d8.loss_dice: 1.1009
2023/05/24 10:38:58 - mmengine - INFO - Iter(train) [132100/160000]  lr: 2.0765e-06  eta: 3:21:21  time: 0.4173  data_time: 0.0106  memory: 4857  grad_norm: 96.6154  loss: 34.8426  decode.loss_cls: 1.2183  decode.loss_mask: 0.7552  decode.loss_dice: 1.2047  decode.d0.loss_cls: 3.1535  decode.d0.loss_mask: 0.7879  decode.d0.loss_dice: 1.4364  decode.d1.loss_cls: 1.4273  decode.d1.loss_mask: 0.8325  decode.d1.loss_dice: 1.3331  decode.d2.loss_cls: 1.2950  decode.d2.loss_mask: 0.8212  decode.d2.loss_dice: 1.3160  decode.d3.loss_cls: 1.2656  decode.d3.loss_mask: 0.7169  decode.d3.loss_dice: 1.2344  decode.d4.loss_cls: 1.2147  decode.d4.loss_mask: 0.7539  decode.d4.loss_dice: 1.2447  decode.d5.loss_cls: 1.2214  decode.d5.loss_mask: 0.7424  decode.d5.loss_dice: 1.2458  decode.d6.loss_cls: 1.2343  decode.d6.loss_mask: 0.7413  decode.d6.loss_dice: 1.2231  decode.d7.loss_cls: 1.2347  decode.d7.loss_mask: 0.7555  decode.d7.loss_dice: 1.2434  decode.d8.loss_cls: 1.2094  decode.d8.loss_mask: 0.7552  decode.d8.loss_dice: 1.2248
2023/05/24 10:39:20 - mmengine - INFO - Iter(train) [132150/160000]  lr: 2.0732e-06  eta: 3:20:59  time: 0.4719  data_time: 0.0098  memory: 4836  grad_norm: 89.4328  loss: 30.7286  decode.loss_cls: 0.9771  decode.loss_mask: 0.7277  decode.loss_dice: 1.0340  decode.d0.loss_cls: 2.9292  decode.d0.loss_mask: 0.7818  decode.d0.loss_dice: 1.2971  decode.d1.loss_cls: 1.2351  decode.d1.loss_mask: 0.7586  decode.d1.loss_dice: 1.1826  decode.d2.loss_cls: 1.1046  decode.d2.loss_mask: 0.7290  decode.d2.loss_dice: 1.1563  decode.d3.loss_cls: 1.0373  decode.d3.loss_mask: 0.7176  decode.d3.loss_dice: 1.0963  decode.d4.loss_cls: 0.9940  decode.d4.loss_mask: 0.7372  decode.d4.loss_dice: 1.0806  decode.d5.loss_cls: 0.9953  decode.d5.loss_mask: 0.7401  decode.d5.loss_dice: 1.0789  decode.d6.loss_cls: 0.9707  decode.d6.loss_mask: 0.7363  decode.d6.loss_dice: 1.0610  decode.d7.loss_cls: 0.9760  decode.d7.loss_mask: 0.7259  decode.d7.loss_dice: 1.1030  decode.d8.loss_cls: 0.9668  decode.d8.loss_mask: 0.7205  decode.d8.loss_dice: 1.0782
2023/05/24 10:39:43 - mmengine - INFO - Iter(train) [132200/160000]  lr: 2.0698e-06  eta: 3:20:38  time: 0.4706  data_time: 0.0096  memory: 4847  grad_norm: 175.1323  loss: 30.2882  decode.loss_cls: 1.0011  decode.loss_mask: 0.7485  decode.loss_dice: 0.9292  decode.d0.loss_cls: 3.2359  decode.d0.loss_mask: 0.7600  decode.d0.loss_dice: 1.0949  decode.d1.loss_cls: 1.2080  decode.d1.loss_mask: 0.8028  decode.d1.loss_dice: 1.0071  decode.d2.loss_cls: 1.0464  decode.d2.loss_mask: 0.8124  decode.d2.loss_dice: 0.9908  decode.d3.loss_cls: 1.0731  decode.d3.loss_mask: 0.7922  decode.d3.loss_dice: 0.9786  decode.d4.loss_cls: 1.0986  decode.d4.loss_mask: 0.7807  decode.d4.loss_dice: 0.9779  decode.d5.loss_cls: 0.9915  decode.d5.loss_mask: 0.7772  decode.d5.loss_dice: 0.9556  decode.d6.loss_cls: 1.0291  decode.d6.loss_mask: 0.7768  decode.d6.loss_dice: 0.9546  decode.d7.loss_cls: 0.9793  decode.d7.loss_mask: 0.7730  decode.d7.loss_dice: 0.9801  decode.d8.loss_cls: 1.0165  decode.d8.loss_mask: 0.7622  decode.d8.loss_dice: 0.9543
2023/05/24 10:40:06 - mmengine - INFO - Iter(train) [132250/160000]  lr: 2.0665e-06  eta: 3:20:17  time: 0.4190  data_time: 0.0100  memory: 4802  grad_norm: 93.6280  loss: 39.6901  decode.loss_cls: 1.4039  decode.loss_mask: 0.8255  decode.loss_dice: 1.4106  decode.d0.loss_cls: 3.5711  decode.d0.loss_mask: 0.9142  decode.d0.loss_dice: 1.7689  decode.d1.loss_cls: 1.5508  decode.d1.loss_mask: 0.8397  decode.d1.loss_dice: 1.4998  decode.d2.loss_cls: 1.5459  decode.d2.loss_mask: 0.8288  decode.d2.loss_dice: 1.4389  decode.d3.loss_cls: 1.5131  decode.d3.loss_mask: 0.8788  decode.d3.loss_dice: 1.4066  decode.d4.loss_cls: 1.4618  decode.d4.loss_mask: 0.8450  decode.d4.loss_dice: 1.3927  decode.d5.loss_cls: 1.4766  decode.d5.loss_mask: 0.8311  decode.d5.loss_dice: 1.3888  decode.d6.loss_cls: 1.4743  decode.d6.loss_mask: 0.7991  decode.d6.loss_dice: 1.3801  decode.d7.loss_cls: 1.4753  decode.d7.loss_mask: 0.7820  decode.d7.loss_dice: 1.3570  decode.d8.loss_cls: 1.4476  decode.d8.loss_mask: 0.8105  decode.d8.loss_dice: 1.3718
2023/05/24 10:40:29 - mmengine - INFO - Iter(train) [132300/160000]  lr: 2.0631e-06  eta: 3:19:55  time: 0.4260  data_time: 0.0099  memory: 4875  grad_norm: 92.0376  loss: 23.0686  decode.loss_cls: 0.8558  decode.loss_mask: 0.4692  decode.loss_dice: 0.7094  decode.d0.loss_cls: 2.6510  decode.d0.loss_mask: 0.4856  decode.d0.loss_dice: 0.8756  decode.d1.loss_cls: 0.9963  decode.d1.loss_mask: 0.5028  decode.d1.loss_dice: 0.8398  decode.d2.loss_cls: 0.9006  decode.d2.loss_mask: 0.5275  decode.d2.loss_dice: 0.8036  decode.d3.loss_cls: 0.8662  decode.d3.loss_mask: 0.4554  decode.d3.loss_dice: 0.7447  decode.d4.loss_cls: 0.8857  decode.d4.loss_mask: 0.4726  decode.d4.loss_dice: 0.7924  decode.d5.loss_cls: 0.8655  decode.d5.loss_mask: 0.4714  decode.d5.loss_dice: 0.7387  decode.d6.loss_cls: 0.8411  decode.d6.loss_mask: 0.4942  decode.d6.loss_dice: 0.7361  decode.d7.loss_cls: 0.8121  decode.d7.loss_mask: 0.4875  decode.d7.loss_dice: 0.7326  decode.d8.loss_cls: 0.8325  decode.d8.loss_mask: 0.4894  decode.d8.loss_dice: 0.7334
2023/05/24 10:40:51 - mmengine - INFO - Iter(train) [132350/160000]  lr: 2.0598e-06  eta: 3:19:34  time: 0.4637  data_time: 0.0102  memory: 4860  grad_norm: 86.8995  loss: 35.5484  decode.loss_cls: 1.0444  decode.loss_mask: 0.9153  decode.loss_dice: 1.2927  decode.d0.loss_cls: 2.8968  decode.d0.loss_mask: 0.9443  decode.d0.loss_dice: 1.5104  decode.d1.loss_cls: 1.2841  decode.d1.loss_mask: 0.9634  decode.d1.loss_dice: 1.3888  decode.d2.loss_cls: 1.0784  decode.d2.loss_mask: 0.9869  decode.d2.loss_dice: 1.3454  decode.d3.loss_cls: 1.0680  decode.d3.loss_mask: 0.9488  decode.d3.loss_dice: 1.3461  decode.d4.loss_cls: 1.0708  decode.d4.loss_mask: 0.9711  decode.d4.loss_dice: 1.3062  decode.d5.loss_cls: 1.1045  decode.d5.loss_mask: 0.9458  decode.d5.loss_dice: 1.3364  decode.d6.loss_cls: 1.0361  decode.d6.loss_mask: 0.9242  decode.d6.loss_dice: 1.2847  decode.d7.loss_cls: 1.1056  decode.d7.loss_mask: 0.9143  decode.d7.loss_dice: 1.2891  decode.d8.loss_cls: 1.0534  decode.d8.loss_mask: 0.9286  decode.d8.loss_dice: 1.2638
2023/05/24 10:41:12 - mmengine - INFO - Iter(train) [132400/160000]  lr: 2.0564e-06  eta: 3:19:12  time: 0.4166  data_time: 0.0098  memory: 4879  grad_norm: 99.1996  loss: 34.1450  decode.loss_cls: 1.1090  decode.loss_mask: 0.7985  decode.loss_dice: 1.1461  decode.d0.loss_cls: 3.1980  decode.d0.loss_mask: 0.7714  decode.d0.loss_dice: 1.3816  decode.d1.loss_cls: 1.3130  decode.d1.loss_mask: 0.8134  decode.d1.loss_dice: 1.3143  decode.d2.loss_cls: 1.3191  decode.d2.loss_mask: 0.7929  decode.d2.loss_dice: 1.2572  decode.d3.loss_cls: 1.3290  decode.d3.loss_mask: 0.7723  decode.d3.loss_dice: 1.1889  decode.d4.loss_cls: 1.2421  decode.d4.loss_mask: 0.8079  decode.d4.loss_dice: 1.2009  decode.d5.loss_cls: 1.1447  decode.d5.loss_mask: 0.7737  decode.d5.loss_dice: 1.1785  decode.d6.loss_cls: 1.1855  decode.d6.loss_mask: 0.8053  decode.d6.loss_dice: 1.1580  decode.d7.loss_cls: 1.1476  decode.d7.loss_mask: 0.8012  decode.d7.loss_dice: 1.1632  decode.d8.loss_cls: 1.0765  decode.d8.loss_mask: 0.7954  decode.d8.loss_dice: 1.1597
2023/05/24 10:41:36 - mmengine - INFO - Iter(train) [132450/160000]  lr: 2.0531e-06  eta: 3:18:51  time: 0.4770  data_time: 0.0098  memory: 4828  grad_norm: 90.4156  loss: 37.9037  decode.loss_cls: 1.2462  decode.loss_mask: 0.7564  decode.loss_dice: 1.4634  decode.d0.loss_cls: 3.3247  decode.d0.loss_mask: 0.9035  decode.d0.loss_dice: 1.7010  decode.d1.loss_cls: 1.3988  decode.d1.loss_mask: 0.8721  decode.d1.loss_dice: 1.5962  decode.d2.loss_cls: 1.2810  decode.d2.loss_mask: 0.8285  decode.d2.loss_dice: 1.5418  decode.d3.loss_cls: 1.2897  decode.d3.loss_mask: 0.7903  decode.d3.loss_dice: 1.4779  decode.d4.loss_cls: 1.2619  decode.d4.loss_mask: 0.7779  decode.d4.loss_dice: 1.4946  decode.d5.loss_cls: 1.2441  decode.d5.loss_mask: 0.7800  decode.d5.loss_dice: 1.4991  decode.d6.loss_cls: 1.2227  decode.d6.loss_mask: 0.7575  decode.d6.loss_dice: 1.4690  decode.d7.loss_cls: 1.2816  decode.d7.loss_mask: 0.7629  decode.d7.loss_dice: 1.4653  decode.d8.loss_cls: 1.2198  decode.d8.loss_mask: 0.7558  decode.d8.loss_dice: 1.4398
2023/05/24 10:41:59 - mmengine - INFO - Iter(train) [132500/160000]  lr: 2.0497e-06  eta: 3:18:29  time: 0.4515  data_time: 0.0099  memory: 4841  grad_norm: 98.8788  loss: 41.8006  decode.loss_cls: 1.4184  decode.loss_mask: 0.9070  decode.loss_dice: 1.5037  decode.d0.loss_cls: 3.5060  decode.d0.loss_mask: 1.0404  decode.d0.loss_dice: 1.8124  decode.d1.loss_cls: 1.5763  decode.d1.loss_mask: 0.9885  decode.d1.loss_dice: 1.7007  decode.d2.loss_cls: 1.6017  decode.d2.loss_mask: 0.9159  decode.d2.loss_dice: 1.5796  decode.d3.loss_cls: 1.5156  decode.d3.loss_mask: 0.9519  decode.d3.loss_dice: 1.5339  decode.d4.loss_cls: 1.4394  decode.d4.loss_mask: 0.9393  decode.d4.loss_dice: 1.5194  decode.d5.loss_cls: 1.4929  decode.d5.loss_mask: 0.9290  decode.d5.loss_dice: 1.4938  decode.d6.loss_cls: 1.4568  decode.d6.loss_mask: 0.9217  decode.d6.loss_dice: 1.4987  decode.d7.loss_cls: 1.4130  decode.d7.loss_mask: 0.9008  decode.d7.loss_dice: 1.4803  decode.d8.loss_cls: 1.3994  decode.d8.loss_mask: 0.8888  decode.d8.loss_dice: 1.4754
2023/05/24 10:42:20 - mmengine - INFO - Iter(train) [132550/160000]  lr: 2.0464e-06  eta: 3:18:08  time: 0.4199  data_time: 0.0102  memory: 4859  grad_norm: 107.9240  loss: 40.8974  decode.loss_cls: 1.4615  decode.loss_mask: 0.8035  decode.loss_dice: 1.4688  decode.d0.loss_cls: 3.5645  decode.d0.loss_mask: 0.9027  decode.d0.loss_dice: 1.6849  decode.d1.loss_cls: 1.6590  decode.d1.loss_mask: 0.8502  decode.d1.loss_dice: 1.6501  decode.d2.loss_cls: 1.5974  decode.d2.loss_mask: 0.8489  decode.d2.loss_dice: 1.5500  decode.d3.loss_cls: 1.5333  decode.d3.loss_mask: 0.8323  decode.d3.loss_dice: 1.5150  decode.d4.loss_cls: 1.5062  decode.d4.loss_mask: 0.7994  decode.d4.loss_dice: 1.5143  decode.d5.loss_cls: 1.5654  decode.d5.loss_mask: 0.7940  decode.d5.loss_dice: 1.4524  decode.d6.loss_cls: 1.5146  decode.d6.loss_mask: 0.8125  decode.d6.loss_dice: 1.4744  decode.d7.loss_cls: 1.4970  decode.d7.loss_mask: 0.8132  decode.d7.loss_dice: 1.5040  decode.d8.loss_cls: 1.4488  decode.d8.loss_mask: 0.8045  decode.d8.loss_dice: 1.4745
2023/05/24 10:42:41 - mmengine - INFO - Iter(train) [132600/160000]  lr: 2.0430e-06  eta: 3:17:46  time: 0.4265  data_time: 0.0103  memory: 5009  grad_norm: 114.9720  loss: 35.4533  decode.loss_cls: 1.2844  decode.loss_mask: 0.6765  decode.loss_dice: 1.2501  decode.d0.loss_cls: 3.2775  decode.d0.loss_mask: 0.7816  decode.d0.loss_dice: 1.6463  decode.d1.loss_cls: 1.4730  decode.d1.loss_mask: 0.6875  decode.d1.loss_dice: 1.4474  decode.d2.loss_cls: 1.3811  decode.d2.loss_mask: 0.7503  decode.d2.loss_dice: 1.3712  decode.d3.loss_cls: 1.3712  decode.d3.loss_mask: 0.6631  decode.d3.loss_dice: 1.2912  decode.d4.loss_cls: 1.2700  decode.d4.loss_mask: 0.6598  decode.d4.loss_dice: 1.3143  decode.d5.loss_cls: 1.3363  decode.d5.loss_mask: 0.6343  decode.d5.loss_dice: 1.3158  decode.d6.loss_cls: 1.3541  decode.d6.loss_mask: 0.6290  decode.d6.loss_dice: 1.1954  decode.d7.loss_cls: 1.2297  decode.d7.loss_mask: 0.6772  decode.d7.loss_dice: 1.2878  decode.d8.loss_cls: 1.2532  decode.d8.loss_mask: 0.6766  decode.d8.loss_dice: 1.2673
2023/05/24 10:43:03 - mmengine - INFO - Iter(train) [132650/160000]  lr: 2.0397e-06  eta: 3:17:24  time: 0.4477  data_time: 0.0103  memory: 4845  grad_norm: 92.2426  loss: 30.3510  decode.loss_cls: 1.0512  decode.loss_mask: 0.6954  decode.loss_dice: 1.0219  decode.d0.loss_cls: 2.8312  decode.d0.loss_mask: 0.7119  decode.d0.loss_dice: 1.1758  decode.d1.loss_cls: 1.1789  decode.d1.loss_mask: 0.7472  decode.d1.loss_dice: 1.1111  decode.d2.loss_cls: 1.1488  decode.d2.loss_mask: 0.6794  decode.d2.loss_dice: 1.0873  decode.d3.loss_cls: 1.1277  decode.d3.loss_mask: 0.6658  decode.d3.loss_dice: 1.0348  decode.d4.loss_cls: 1.1734  decode.d4.loss_mask: 0.6738  decode.d4.loss_dice: 1.0605  decode.d5.loss_cls: 1.0679  decode.d5.loss_mask: 0.6933  decode.d5.loss_dice: 1.0289  decode.d6.loss_cls: 0.9831  decode.d6.loss_mask: 0.7191  decode.d6.loss_dice: 1.0501  decode.d7.loss_cls: 1.0267  decode.d7.loss_mask: 0.7082  decode.d7.loss_dice: 1.0803  decode.d8.loss_cls: 1.1145  decode.d8.loss_mask: 0.6959  decode.d8.loss_dice: 1.0070
2023/05/24 10:43:26 - mmengine - INFO - Iter(train) [132700/160000]  lr: 2.0363e-06  eta: 3:17:03  time: 0.4206  data_time: 0.0104  memory: 4856  grad_norm: 84.9619  loss: 32.9450  decode.loss_cls: 1.0884  decode.loss_mask: 0.7961  decode.loss_dice: 1.1808  decode.d0.loss_cls: 3.1643  decode.d0.loss_mask: 0.8494  decode.d0.loss_dice: 1.3220  decode.d1.loss_cls: 1.1032  decode.d1.loss_mask: 0.8645  decode.d1.loss_dice: 1.2507  decode.d2.loss_cls: 1.1892  decode.d2.loss_mask: 0.7999  decode.d2.loss_dice: 1.1620  decode.d3.loss_cls: 1.0640  decode.d3.loss_mask: 0.7892  decode.d3.loss_dice: 1.1723  decode.d4.loss_cls: 1.1182  decode.d4.loss_mask: 0.7844  decode.d4.loss_dice: 1.1279  decode.d5.loss_cls: 1.0313  decode.d5.loss_mask: 0.8228  decode.d5.loss_dice: 1.1687  decode.d6.loss_cls: 1.1116  decode.d6.loss_mask: 0.7889  decode.d6.loss_dice: 1.1477  decode.d7.loss_cls: 1.0739  decode.d7.loss_mask: 0.7912  decode.d7.loss_dice: 1.1581  decode.d8.loss_cls: 1.0891  decode.d8.loss_mask: 0.7811  decode.d8.loss_dice: 1.1539
2023/05/24 10:43:48 - mmengine - INFO - Iter(train) [132750/160000]  lr: 2.0329e-06  eta: 3:16:41  time: 0.4279  data_time: 0.0098  memory: 4829  grad_norm: 93.1666  loss: 39.1106  decode.loss_cls: 1.3254  decode.loss_mask: 0.8593  decode.loss_dice: 1.3945  decode.d0.loss_cls: 3.5342  decode.d0.loss_mask: 1.0095  decode.d0.loss_dice: 1.7204  decode.d1.loss_cls: 1.5038  decode.d1.loss_mask: 0.8644  decode.d1.loss_dice: 1.5172  decode.d2.loss_cls: 1.4157  decode.d2.loss_mask: 0.8827  decode.d2.loss_dice: 1.4526  decode.d3.loss_cls: 1.3716  decode.d3.loss_mask: 0.8501  decode.d3.loss_dice: 1.4185  decode.d4.loss_cls: 1.3615  decode.d4.loss_mask: 0.8662  decode.d4.loss_dice: 1.4225  decode.d5.loss_cls: 1.3000  decode.d5.loss_mask: 0.8594  decode.d5.loss_dice: 1.4247  decode.d6.loss_cls: 1.3796  decode.d6.loss_mask: 0.8352  decode.d6.loss_dice: 1.4057  decode.d7.loss_cls: 1.3753  decode.d7.loss_mask: 0.8146  decode.d7.loss_dice: 1.4129  decode.d8.loss_cls: 1.3155  decode.d8.loss_mask: 0.8287  decode.d8.loss_dice: 1.3887
2023/05/24 10:44:11 - mmengine - INFO - Iter(train) [132800/160000]  lr: 2.0296e-06  eta: 3:16:20  time: 0.4286  data_time: 0.0102  memory: 4862  grad_norm: 115.3002  loss: 31.9552  decode.loss_cls: 1.0345  decode.loss_mask: 0.6378  decode.loss_dice: 1.2071  decode.d0.loss_cls: 2.8036  decode.d0.loss_mask: 0.7630  decode.d0.loss_dice: 1.4863  decode.d1.loss_cls: 1.1678  decode.d1.loss_mask: 0.7145  decode.d1.loss_dice: 1.3723  decode.d2.loss_cls: 1.1255  decode.d2.loss_mask: 0.6636  decode.d2.loss_dice: 1.2884  decode.d3.loss_cls: 1.1132  decode.d3.loss_mask: 0.6578  decode.d3.loss_dice: 1.2723  decode.d4.loss_cls: 1.0840  decode.d4.loss_mask: 0.6585  decode.d4.loss_dice: 1.2539  decode.d5.loss_cls: 1.0676  decode.d5.loss_mask: 0.6464  decode.d5.loss_dice: 1.2420  decode.d6.loss_cls: 1.0570  decode.d6.loss_mask: 0.6321  decode.d6.loss_dice: 1.2032  decode.d7.loss_cls: 1.0477  decode.d7.loss_mask: 0.6351  decode.d7.loss_dice: 1.2433  decode.d8.loss_cls: 1.0333  decode.d8.loss_mask: 0.6349  decode.d8.loss_dice: 1.2086
2023/05/24 10:44:32 - mmengine - INFO - Iter(train) [132850/160000]  lr: 2.0262e-06  eta: 3:15:58  time: 0.4227  data_time: 0.0101  memory: 4859  grad_norm: 119.7950  loss: 34.9119  decode.loss_cls: 1.2824  decode.loss_mask: 0.7062  decode.loss_dice: 1.1783  decode.d0.loss_cls: 3.1604  decode.d0.loss_mask: 0.7922  decode.d0.loss_dice: 1.4748  decode.d1.loss_cls: 1.4737  decode.d1.loss_mask: 0.7617  decode.d1.loss_dice: 1.3360  decode.d2.loss_cls: 1.4110  decode.d2.loss_mask: 0.7336  decode.d2.loss_dice: 1.2643  decode.d3.loss_cls: 1.3601  decode.d3.loss_mask: 0.7054  decode.d3.loss_dice: 1.2104  decode.d4.loss_cls: 1.3504  decode.d4.loss_mask: 0.6975  decode.d4.loss_dice: 1.2146  decode.d5.loss_cls: 1.3337  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 1.2160  decode.d6.loss_cls: 1.2489  decode.d6.loss_mask: 0.7218  decode.d6.loss_dice: 1.1931  decode.d7.loss_cls: 1.3139  decode.d7.loss_mask: 0.7044  decode.d7.loss_dice: 1.1823  decode.d8.loss_cls: 1.2784  decode.d8.loss_mask: 0.7124  decode.d8.loss_dice: 1.1998
2023/05/24 10:44:54 - mmengine - INFO - Iter(train) [132900/160000]  lr: 2.0229e-06  eta: 3:15:36  time: 0.4471  data_time: 0.0099  memory: 4876  grad_norm: 86.6337  loss: 32.2277  decode.loss_cls: 1.0548  decode.loss_mask: 0.6692  decode.loss_dice: 1.1828  decode.d0.loss_cls: 3.2254  decode.d0.loss_mask: 0.6579  decode.d0.loss_dice: 1.4378  decode.d1.loss_cls: 1.3261  decode.d1.loss_mask: 0.6810  decode.d1.loss_dice: 1.2824  decode.d2.loss_cls: 1.1496  decode.d2.loss_mask: 0.7021  decode.d2.loss_dice: 1.2514  decode.d3.loss_cls: 1.0880  decode.d3.loss_mask: 0.6735  decode.d3.loss_dice: 1.2067  decode.d4.loss_cls: 1.0887  decode.d4.loss_mask: 0.6736  decode.d4.loss_dice: 1.1969  decode.d5.loss_cls: 1.0475  decode.d5.loss_mask: 0.6728  decode.d5.loss_dice: 1.2165  decode.d6.loss_cls: 1.0652  decode.d6.loss_mask: 0.6842  decode.d6.loss_dice: 1.1605  decode.d7.loss_cls: 1.0448  decode.d7.loss_mask: 0.6787  decode.d7.loss_dice: 1.1782  decode.d8.loss_cls: 1.0832  decode.d8.loss_mask: 0.6716  decode.d8.loss_dice: 1.1767
2023/05/24 10:45:17 - mmengine - INFO - Iter(train) [132950/160000]  lr: 2.0195e-06  eta: 3:15:15  time: 0.4463  data_time: 0.0098  memory: 4821  grad_norm: 92.7652  loss: 38.1784  decode.loss_cls: 1.2363  decode.loss_mask: 0.9231  decode.loss_dice: 1.4080  decode.d0.loss_cls: 3.1652  decode.d0.loss_mask: 0.8967  decode.d0.loss_dice: 1.5678  decode.d1.loss_cls: 1.3422  decode.d1.loss_mask: 0.9139  decode.d1.loss_dice: 1.5265  decode.d2.loss_cls: 1.2705  decode.d2.loss_mask: 0.9165  decode.d2.loss_dice: 1.4840  decode.d3.loss_cls: 1.2863  decode.d3.loss_mask: 0.9080  decode.d3.loss_dice: 1.3667  decode.d4.loss_cls: 1.2541  decode.d4.loss_mask: 0.9079  decode.d4.loss_dice: 1.4268  decode.d5.loss_cls: 1.2788  decode.d5.loss_mask: 0.8884  decode.d5.loss_dice: 1.3830  decode.d6.loss_cls: 1.2510  decode.d6.loss_mask: 0.9406  decode.d6.loss_dice: 1.4226  decode.d7.loss_cls: 1.2659  decode.d7.loss_mask: 0.9280  decode.d7.loss_dice: 1.4225  decode.d8.loss_cls: 1.2336  decode.d8.loss_mask: 0.9566  decode.d8.loss_dice: 1.4068
2023/05/24 10:45:38 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 10:45:38 - mmengine - INFO - Iter(train) [133000/160000]  lr: 2.0161e-06  eta: 3:14:53  time: 0.4245  data_time: 0.0097  memory: 4830  grad_norm: 91.7119  loss: 36.3965  decode.loss_cls: 1.3518  decode.loss_mask: 0.6964  decode.loss_dice: 1.2693  decode.d0.loss_cls: 3.2765  decode.d0.loss_mask: 0.6986  decode.d0.loss_dice: 1.5246  decode.d1.loss_cls: 1.5204  decode.d1.loss_mask: 0.6646  decode.d1.loss_dice: 1.4552  decode.d2.loss_cls: 1.4871  decode.d2.loss_mask: 0.6635  decode.d2.loss_dice: 1.3902  decode.d3.loss_cls: 1.5143  decode.d3.loss_mask: 0.6626  decode.d3.loss_dice: 1.3380  decode.d4.loss_cls: 1.4496  decode.d4.loss_mask: 0.6946  decode.d4.loss_dice: 1.3446  decode.d5.loss_cls: 1.4451  decode.d5.loss_mask: 0.6790  decode.d5.loss_dice: 1.2961  decode.d6.loss_cls: 1.3888  decode.d6.loss_mask: 0.6623  decode.d6.loss_dice: 1.2596  decode.d7.loss_cls: 1.3994  decode.d7.loss_mask: 0.6355  decode.d7.loss_dice: 1.2754  decode.d8.loss_cls: 1.3785  decode.d8.loss_mask: 0.6836  decode.d8.loss_dice: 1.2913
2023/05/24 10:45:38 - mmengine - INFO - Saving checkpoint at 133000 iterations
2023/05/24 10:46:05 - mmengine - INFO - Iter(train) [133050/160000]  lr: 2.0128e-06  eta: 3:14:33  time: 0.4299  data_time: 0.0101  memory: 4864  grad_norm: 122.2338  loss: 31.8665  decode.loss_cls: 1.0669  decode.loss_mask: 0.6640  decode.loss_dice: 1.1440  decode.d0.loss_cls: 2.8490  decode.d0.loss_mask: 0.7606  decode.d0.loss_dice: 1.4144  decode.d1.loss_cls: 1.2095  decode.d1.loss_mask: 0.6976  decode.d1.loss_dice: 1.3022  decode.d2.loss_cls: 1.1396  decode.d2.loss_mask: 0.7423  decode.d2.loss_dice: 1.2602  decode.d3.loss_cls: 1.1319  decode.d3.loss_mask: 0.6833  decode.d3.loss_dice: 1.2273  decode.d4.loss_cls: 1.0776  decode.d4.loss_mask: 0.6800  decode.d4.loss_dice: 1.2195  decode.d5.loss_cls: 1.0369  decode.d5.loss_mask: 0.6903  decode.d5.loss_dice: 1.2049  decode.d6.loss_cls: 1.0459  decode.d6.loss_mask: 0.6637  decode.d6.loss_dice: 1.1544  decode.d7.loss_cls: 1.0532  decode.d7.loss_mask: 0.6710  decode.d7.loss_dice: 1.1791  decode.d8.loss_cls: 1.0634  decode.d8.loss_mask: 0.6751  decode.d8.loss_dice: 1.1589
2023/05/24 10:46:26 - mmengine - INFO - Iter(train) [133100/160000]  lr: 2.0094e-06  eta: 3:14:11  time: 0.4296  data_time: 0.0105  memory: 4831  grad_norm: 100.1428  loss: 28.1292  decode.loss_cls: 0.8166  decode.loss_mask: 0.6582  decode.loss_dice: 1.0251  decode.d0.loss_cls: 3.0062  decode.d0.loss_mask: 0.7299  decode.d0.loss_dice: 1.2219  decode.d1.loss_cls: 0.8811  decode.d1.loss_mask: 0.6871  decode.d1.loss_dice: 1.1369  decode.d2.loss_cls: 0.8810  decode.d2.loss_mask: 0.6608  decode.d2.loss_dice: 1.0810  decode.d3.loss_cls: 0.8197  decode.d3.loss_mask: 0.6955  decode.d3.loss_dice: 1.0741  decode.d4.loss_cls: 0.8073  decode.d4.loss_mask: 0.6910  decode.d4.loss_dice: 1.0600  decode.d5.loss_cls: 0.8657  decode.d5.loss_mask: 0.6456  decode.d5.loss_dice: 1.0408  decode.d6.loss_cls: 0.8122  decode.d6.loss_mask: 0.6607  decode.d6.loss_dice: 1.0688  decode.d7.loss_cls: 0.7902  decode.d7.loss_mask: 0.6874  decode.d7.loss_dice: 1.0944  decode.d8.loss_cls: 0.7954  decode.d8.loss_mask: 0.6622  decode.d8.loss_dice: 1.0724
2023/05/24 10:46:48 - mmengine - INFO - Iter(train) [133150/160000]  lr: 2.0061e-06  eta: 3:13:49  time: 0.4335  data_time: 0.0105  memory: 4973  grad_norm: 106.2325  loss: 32.3766  decode.loss_cls: 1.0676  decode.loss_mask: 0.7126  decode.loss_dice: 1.1961  decode.d0.loss_cls: 2.8815  decode.d0.loss_mask: 0.8219  decode.d0.loss_dice: 1.4870  decode.d1.loss_cls: 1.1754  decode.d1.loss_mask: 0.7593  decode.d1.loss_dice: 1.3868  decode.d2.loss_cls: 1.0839  decode.d2.loss_mask: 0.7360  decode.d2.loss_dice: 1.3063  decode.d3.loss_cls: 1.0567  decode.d3.loss_mask: 0.7321  decode.d3.loss_dice: 1.2454  decode.d4.loss_cls: 0.9857  decode.d4.loss_mask: 0.7297  decode.d4.loss_dice: 1.2643  decode.d5.loss_cls: 0.9944  decode.d5.loss_mask: 0.7441  decode.d5.loss_dice: 1.2104  decode.d6.loss_cls: 0.9990  decode.d6.loss_mask: 0.7435  decode.d6.loss_dice: 1.2122  decode.d7.loss_cls: 0.9633  decode.d7.loss_mask: 0.7391  decode.d7.loss_dice: 1.2167  decode.d8.loss_cls: 1.0025  decode.d8.loss_mask: 0.7311  decode.d8.loss_dice: 1.1921
2023/05/24 10:47:09 - mmengine - INFO - Iter(train) [133200/160000]  lr: 2.0027e-06  eta: 3:13:27  time: 0.4246  data_time: 0.0103  memory: 4807  grad_norm: 94.9590  loss: 30.0477  decode.loss_cls: 1.1212  decode.loss_mask: 0.5691  decode.loss_dice: 1.0073  decode.d0.loss_cls: 3.1309  decode.d0.loss_mask: 0.6093  decode.d0.loss_dice: 1.2105  decode.d1.loss_cls: 1.2601  decode.d1.loss_mask: 0.6324  decode.d1.loss_dice: 1.1457  decode.d2.loss_cls: 1.2931  decode.d2.loss_mask: 0.6275  decode.d2.loss_dice: 1.0575  decode.d3.loss_cls: 1.1741  decode.d3.loss_mask: 0.6003  decode.d3.loss_dice: 1.0478  decode.d4.loss_cls: 1.1204  decode.d4.loss_mask: 0.5873  decode.d4.loss_dice: 1.0268  decode.d5.loss_cls: 1.0774  decode.d5.loss_mask: 0.5862  decode.d5.loss_dice: 1.0441  decode.d6.loss_cls: 1.1368  decode.d6.loss_mask: 0.5873  decode.d6.loss_dice: 1.0336  decode.d7.loss_cls: 1.0861  decode.d7.loss_mask: 0.5809  decode.d7.loss_dice: 1.0138  decode.d8.loss_cls: 1.0769  decode.d8.loss_mask: 0.5851  decode.d8.loss_dice: 1.0182
2023/05/24 10:47:30 - mmengine - INFO - Iter(train) [133250/160000]  lr: 1.9993e-06  eta: 3:13:06  time: 0.4269  data_time: 0.0101  memory: 4847  grad_norm: 83.9302  loss: 39.1357  decode.loss_cls: 1.2088  decode.loss_mask: 0.8290  decode.loss_dice: 1.5116  decode.d0.loss_cls: 3.3676  decode.d0.loss_mask: 0.8888  decode.d0.loss_dice: 1.7557  decode.d1.loss_cls: 1.3913  decode.d1.loss_mask: 0.9111  decode.d1.loss_dice: 1.7029  decode.d2.loss_cls: 1.2945  decode.d2.loss_mask: 0.8795  decode.d2.loss_dice: 1.6371  decode.d3.loss_cls: 1.3014  decode.d3.loss_mask: 0.8252  decode.d3.loss_dice: 1.5971  decode.d4.loss_cls: 1.2755  decode.d4.loss_mask: 0.8488  decode.d4.loss_dice: 1.5745  decode.d5.loss_cls: 1.2656  decode.d5.loss_mask: 0.8059  decode.d5.loss_dice: 1.5361  decode.d6.loss_cls: 1.2514  decode.d6.loss_mask: 0.8035  decode.d6.loss_dice: 1.5081  decode.d7.loss_cls: 1.2393  decode.d7.loss_mask: 0.8353  decode.d7.loss_dice: 1.5340  decode.d8.loss_cls: 1.2303  decode.d8.loss_mask: 0.8295  decode.d8.loss_dice: 1.4963
2023/05/24 10:47:53 - mmengine - INFO - Iter(train) [133300/160000]  lr: 1.9960e-06  eta: 3:12:44  time: 0.4266  data_time: 0.0099  memory: 4839  grad_norm: 84.4866  loss: 31.8492  decode.loss_cls: 0.9611  decode.loss_mask: 0.6886  decode.loss_dice: 1.2412  decode.d0.loss_cls: 3.0282  decode.d0.loss_mask: 0.7683  decode.d0.loss_dice: 1.4712  decode.d1.loss_cls: 1.0625  decode.d1.loss_mask: 0.7563  decode.d1.loss_dice: 1.3178  decode.d2.loss_cls: 1.0226  decode.d2.loss_mask: 0.7240  decode.d2.loss_dice: 1.2534  decode.d3.loss_cls: 0.9767  decode.d3.loss_mask: 0.7048  decode.d3.loss_dice: 1.2447  decode.d4.loss_cls: 0.9385  decode.d4.loss_mask: 0.7210  decode.d4.loss_dice: 1.2669  decode.d5.loss_cls: 0.9863  decode.d5.loss_mask: 0.6989  decode.d5.loss_dice: 1.2506  decode.d6.loss_cls: 0.9872  decode.d6.loss_mask: 0.7198  decode.d6.loss_dice: 1.2284  decode.d7.loss_cls: 0.9889  decode.d7.loss_mask: 0.7152  decode.d7.loss_dice: 1.2293  decode.d8.loss_cls: 0.9454  decode.d8.loss_mask: 0.7123  decode.d8.loss_dice: 1.2391
2023/05/24 10:48:14 - mmengine - INFO - Iter(train) [133350/160000]  lr: 1.9926e-06  eta: 3:12:23  time: 0.4163  data_time: 0.0097  memory: 4887  grad_norm: 104.5573  loss: 32.5411  decode.loss_cls: 1.1384  decode.loss_mask: 0.6051  decode.loss_dice: 1.2475  decode.d0.loss_cls: 2.8578  decode.d0.loss_mask: 0.7485  decode.d0.loss_dice: 1.5020  decode.d1.loss_cls: 1.2207  decode.d1.loss_mask: 0.7096  decode.d1.loss_dice: 1.3631  decode.d2.loss_cls: 1.1437  decode.d2.loss_mask: 0.6715  decode.d2.loss_dice: 1.3734  decode.d3.loss_cls: 1.1059  decode.d3.loss_mask: 0.6530  decode.d3.loss_dice: 1.3032  decode.d4.loss_cls: 1.1316  decode.d4.loss_mask: 0.6268  decode.d4.loss_dice: 1.2523  decode.d5.loss_cls: 1.0523  decode.d5.loss_mask: 0.6488  decode.d5.loss_dice: 1.2574  decode.d6.loss_cls: 1.0899  decode.d6.loss_mask: 0.6260  decode.d6.loss_dice: 1.2604  decode.d7.loss_cls: 1.0800  decode.d7.loss_mask: 0.6295  decode.d7.loss_dice: 1.2645  decode.d8.loss_cls: 1.0801  decode.d8.loss_mask: 0.6206  decode.d8.loss_dice: 1.2774
2023/05/24 10:48:36 - mmengine - INFO - Iter(train) [133400/160000]  lr: 1.9892e-06  eta: 3:12:01  time: 0.4676  data_time: 0.0106  memory: 4920  grad_norm: 99.6706  loss: 30.1237  decode.loss_cls: 0.9112  decode.loss_mask: 0.8325  decode.loss_dice: 1.0738  decode.d0.loss_cls: 2.6434  decode.d0.loss_mask: 0.8579  decode.d0.loss_dice: 1.1962  decode.d1.loss_cls: 0.9774  decode.d1.loss_mask: 0.8401  decode.d1.loss_dice: 1.1702  decode.d2.loss_cls: 0.9047  decode.d2.loss_mask: 0.8550  decode.d2.loss_dice: 1.1000  decode.d3.loss_cls: 0.9414  decode.d3.loss_mask: 0.8522  decode.d3.loss_dice: 1.0759  decode.d4.loss_cls: 0.8525  decode.d4.loss_mask: 0.8261  decode.d4.loss_dice: 1.0770  decode.d5.loss_cls: 0.8487  decode.d5.loss_mask: 0.8504  decode.d5.loss_dice: 1.0692  decode.d6.loss_cls: 0.8594  decode.d6.loss_mask: 0.8643  decode.d6.loss_dice: 1.0807  decode.d7.loss_cls: 0.8753  decode.d7.loss_mask: 0.8442  decode.d7.loss_dice: 1.0528  decode.d8.loss_cls: 0.8849  decode.d8.loss_mask: 0.8426  decode.d8.loss_dice: 1.0637
2023/05/24 10:48:57 - mmengine - INFO - Iter(train) [133450/160000]  lr: 1.9859e-06  eta: 3:11:39  time: 0.4195  data_time: 0.0099  memory: 4983  grad_norm: 89.1228  loss: 27.2000  decode.loss_cls: 0.9687  decode.loss_mask: 0.5737  decode.loss_dice: 0.8794  decode.d0.loss_cls: 2.7715  decode.d0.loss_mask: 0.6893  decode.d0.loss_dice: 1.0557  decode.d1.loss_cls: 1.0171  decode.d1.loss_mask: 0.6671  decode.d1.loss_dice: 1.0032  decode.d2.loss_cls: 1.0928  decode.d2.loss_mask: 0.6179  decode.d2.loss_dice: 0.9516  decode.d3.loss_cls: 1.0325  decode.d3.loss_mask: 0.5910  decode.d3.loss_dice: 0.8808  decode.d4.loss_cls: 1.0770  decode.d4.loss_mask: 0.6099  decode.d4.loss_dice: 0.8947  decode.d5.loss_cls: 0.9802  decode.d5.loss_mask: 0.5908  decode.d5.loss_dice: 0.8930  decode.d6.loss_cls: 1.0109  decode.d6.loss_mask: 0.5807  decode.d6.loss_dice: 0.8822  decode.d7.loss_cls: 0.9816  decode.d7.loss_mask: 0.5782  decode.d7.loss_dice: 0.9010  decode.d8.loss_cls: 0.9678  decode.d8.loss_mask: 0.5783  decode.d8.loss_dice: 0.8814
2023/05/24 10:49:18 - mmengine - INFO - Iter(train) [133500/160000]  lr: 1.9825e-06  eta: 3:11:17  time: 0.4214  data_time: 0.0101  memory: 4878  grad_norm: 163.0882  loss: 48.1216  decode.loss_cls: 1.4128  decode.loss_mask: 1.1189  decode.loss_dice: 1.9032  decode.d0.loss_cls: 3.4749  decode.d0.loss_mask: 1.2587  decode.d0.loss_dice: 2.2251  decode.d1.loss_cls: 1.7061  decode.d1.loss_mask: 1.1368  decode.d1.loss_dice: 2.0659  decode.d2.loss_cls: 1.6585  decode.d2.loss_mask: 1.1520  decode.d2.loss_dice: 1.9436  decode.d3.loss_cls: 1.5534  decode.d3.loss_mask: 1.1417  decode.d3.loss_dice: 1.9017  decode.d4.loss_cls: 1.5262  decode.d4.loss_mask: 1.1433  decode.d4.loss_dice: 1.9010  decode.d5.loss_cls: 1.4937  decode.d5.loss_mask: 1.1312  decode.d5.loss_dice: 1.8948  decode.d6.loss_cls: 1.4423  decode.d6.loss_mask: 1.1356  decode.d6.loss_dice: 1.8902  decode.d7.loss_cls: 1.4535  decode.d7.loss_mask: 1.1313  decode.d7.loss_dice: 1.8784  decode.d8.loss_cls: 1.4215  decode.d8.loss_mask: 1.1393  decode.d8.loss_dice: 1.8859
2023/05/24 10:49:40 - mmengine - INFO - Iter(train) [133550/160000]  lr: 1.9791e-06  eta: 3:10:56  time: 0.4215  data_time: 0.0098  memory: 4857  grad_norm: 105.2364  loss: 35.2118  decode.loss_cls: 1.1045  decode.loss_mask: 0.8022  decode.loss_dice: 1.3436  decode.d0.loss_cls: 2.9317  decode.d0.loss_mask: 0.8393  decode.d0.loss_dice: 1.5589  decode.d1.loss_cls: 1.3378  decode.d1.loss_mask: 0.8006  decode.d1.loss_dice: 1.4638  decode.d2.loss_cls: 1.2427  decode.d2.loss_mask: 0.7918  decode.d2.loss_dice: 1.4013  decode.d3.loss_cls: 1.1640  decode.d3.loss_mask: 0.7821  decode.d3.loss_dice: 1.3807  decode.d4.loss_cls: 1.1958  decode.d4.loss_mask: 0.7408  decode.d4.loss_dice: 1.3329  decode.d5.loss_cls: 1.1456  decode.d5.loss_mask: 0.7759  decode.d5.loss_dice: 1.3502  decode.d6.loss_cls: 1.1241  decode.d6.loss_mask: 0.7921  decode.d6.loss_dice: 1.3492  decode.d7.loss_cls: 1.1258  decode.d7.loss_mask: 0.7899  decode.d7.loss_dice: 1.3317  decode.d8.loss_cls: 1.1058  decode.d8.loss_mask: 0.7849  decode.d8.loss_dice: 1.3221
2023/05/24 10:50:01 - mmengine - INFO - Iter(train) [133600/160000]  lr: 1.9758e-06  eta: 3:10:34  time: 0.4218  data_time: 0.0101  memory: 4867  grad_norm: 100.7899  loss: 35.0338  decode.loss_cls: 1.2766  decode.loss_mask: 0.6960  decode.loss_dice: 1.3005  decode.d0.loss_cls: 2.9404  decode.d0.loss_mask: 0.8139  decode.d0.loss_dice: 1.4471  decode.d1.loss_cls: 1.3698  decode.d1.loss_mask: 0.7261  decode.d1.loss_dice: 1.3784  decode.d2.loss_cls: 1.3366  decode.d2.loss_mask: 0.7055  decode.d2.loss_dice: 1.3369  decode.d3.loss_cls: 1.3671  decode.d3.loss_mask: 0.6762  decode.d3.loss_dice: 1.2992  decode.d4.loss_cls: 1.2721  decode.d4.loss_mask: 0.6794  decode.d4.loss_dice: 1.3509  decode.d5.loss_cls: 1.2732  decode.d5.loss_mask: 0.7010  decode.d5.loss_dice: 1.3166  decode.d6.loss_cls: 1.2585  decode.d6.loss_mask: 0.6881  decode.d6.loss_dice: 1.2839  decode.d7.loss_cls: 1.2887  decode.d7.loss_mask: 0.6944  decode.d7.loss_dice: 1.2910  decode.d8.loss_cls: 1.2878  decode.d8.loss_mask: 0.6935  decode.d8.loss_dice: 1.2844
2023/05/24 10:50:22 - mmengine - INFO - Iter(train) [133650/160000]  lr: 1.9724e-06  eta: 3:10:12  time: 0.4401  data_time: 0.0103  memory: 4821  grad_norm: 86.4547  loss: 37.3247  decode.loss_cls: 1.2112  decode.loss_mask: 0.9241  decode.loss_dice: 1.2190  decode.d0.loss_cls: 3.1857  decode.d0.loss_mask: 0.9839  decode.d0.loss_dice: 1.4281  decode.d1.loss_cls: 1.3624  decode.d1.loss_mask: 0.9541  decode.d1.loss_dice: 1.3867  decode.d2.loss_cls: 1.3395  decode.d2.loss_mask: 0.9654  decode.d2.loss_dice: 1.3394  decode.d3.loss_cls: 1.3150  decode.d3.loss_mask: 0.9746  decode.d3.loss_dice: 1.3215  decode.d4.loss_cls: 1.3552  decode.d4.loss_mask: 0.9393  decode.d4.loss_dice: 1.2788  decode.d5.loss_cls: 1.3090  decode.d5.loss_mask: 0.9329  decode.d5.loss_dice: 1.2877  decode.d6.loss_cls: 1.2246  decode.d6.loss_mask: 0.9428  decode.d6.loss_dice: 1.2542  decode.d7.loss_cls: 1.2940  decode.d7.loss_mask: 0.9270  decode.d7.loss_dice: 1.2263  decode.d8.loss_cls: 1.2956  decode.d8.loss_mask: 0.9250  decode.d8.loss_dice: 1.2218
2023/05/24 10:50:46 - mmengine - INFO - Iter(train) [133700/160000]  lr: 1.9690e-06  eta: 3:09:51  time: 0.4747  data_time: 0.0095  memory: 4838  grad_norm: 93.7931  loss: 31.2928  decode.loss_cls: 0.8830  decode.loss_mask: 0.7793  decode.loss_dice: 1.1685  decode.d0.loss_cls: 2.9605  decode.d0.loss_mask: 0.7801  decode.d0.loss_dice: 1.3286  decode.d1.loss_cls: 1.0929  decode.d1.loss_mask: 0.7850  decode.d1.loss_dice: 1.2795  decode.d2.loss_cls: 1.0125  decode.d2.loss_mask: 0.7832  decode.d2.loss_dice: 1.2114  decode.d3.loss_cls: 0.9421  decode.d3.loss_mask: 0.7750  decode.d3.loss_dice: 1.2028  decode.d4.loss_cls: 0.8971  decode.d4.loss_mask: 0.7862  decode.d4.loss_dice: 1.1995  decode.d5.loss_cls: 0.8925  decode.d5.loss_mask: 0.7749  decode.d5.loss_dice: 1.2052  decode.d6.loss_cls: 0.9032  decode.d6.loss_mask: 0.7655  decode.d6.loss_dice: 1.1983  decode.d7.loss_cls: 0.9014  decode.d7.loss_mask: 0.7705  decode.d7.loss_dice: 1.1794  decode.d8.loss_cls: 0.8576  decode.d8.loss_mask: 0.7830  decode.d8.loss_dice: 1.1945
2023/05/24 10:51:10 - mmengine - INFO - Iter(train) [133750/160000]  lr: 1.9657e-06  eta: 3:09:30  time: 0.4761  data_time: 0.0099  memory: 4847  grad_norm: 95.1218  loss: 35.6080  decode.loss_cls: 1.0706  decode.loss_mask: 0.9166  decode.loss_dice: 1.2263  decode.d0.loss_cls: 3.2456  decode.d0.loss_mask: 0.9456  decode.d0.loss_dice: 1.4139  decode.d1.loss_cls: 1.1695  decode.d1.loss_mask: 0.9437  decode.d1.loss_dice: 1.3790  decode.d2.loss_cls: 1.2092  decode.d2.loss_mask: 0.9639  decode.d2.loss_dice: 1.2671  decode.d3.loss_cls: 1.1988  decode.d3.loss_mask: 0.9173  decode.d3.loss_dice: 1.2609  decode.d4.loss_cls: 1.1579  decode.d4.loss_mask: 0.9299  decode.d4.loss_dice: 1.2860  decode.d5.loss_cls: 1.1600  decode.d5.loss_mask: 0.9185  decode.d5.loss_dice: 1.2567  decode.d6.loss_cls: 1.1394  decode.d6.loss_mask: 0.9140  decode.d6.loss_dice: 1.2174  decode.d7.loss_cls: 1.0906  decode.d7.loss_mask: 0.9192  decode.d7.loss_dice: 1.2454  decode.d8.loss_cls: 1.0986  decode.d8.loss_mask: 0.9064  decode.d8.loss_dice: 1.2399
2023/05/24 10:51:34 - mmengine - INFO - Iter(train) [133800/160000]  lr: 1.9623e-06  eta: 3:09:09  time: 0.4683  data_time: 0.0100  memory: 4837  grad_norm: 89.0622  loss: 32.1059  decode.loss_cls: 0.9649  decode.loss_mask: 0.7405  decode.loss_dice: 1.1862  decode.d0.loss_cls: 3.1320  decode.d0.loss_mask: 0.7667  decode.d0.loss_dice: 1.3292  decode.d1.loss_cls: 1.1292  decode.d1.loss_mask: 0.8437  decode.d1.loss_dice: 1.3636  decode.d2.loss_cls: 1.0686  decode.d2.loss_mask: 0.7831  decode.d2.loss_dice: 1.2841  decode.d3.loss_cls: 0.9998  decode.d3.loss_mask: 0.7308  decode.d3.loss_dice: 1.2116  decode.d4.loss_cls: 0.9656  decode.d4.loss_mask: 0.7486  decode.d4.loss_dice: 1.2388  decode.d5.loss_cls: 0.9546  decode.d5.loss_mask: 0.7362  decode.d5.loss_dice: 1.2075  decode.d6.loss_cls: 0.9555  decode.d6.loss_mask: 0.7461  decode.d6.loss_dice: 1.2020  decode.d7.loss_cls: 0.9999  decode.d7.loss_mask: 0.7424  decode.d7.loss_dice: 1.1895  decode.d8.loss_cls: 0.9634  decode.d8.loss_mask: 0.7316  decode.d8.loss_dice: 1.1903
2023/05/24 10:51:55 - mmengine - INFO - Iter(train) [133850/160000]  lr: 1.9589e-06  eta: 3:08:47  time: 0.4347  data_time: 0.0099  memory: 4818  grad_norm: 93.5882  loss: 32.5153  decode.loss_cls: 1.1692  decode.loss_mask: 0.6021  decode.loss_dice: 1.1753  decode.d0.loss_cls: 3.1677  decode.d0.loss_mask: 0.6721  decode.d0.loss_dice: 1.4327  decode.d1.loss_cls: 1.2220  decode.d1.loss_mask: 0.7340  decode.d1.loss_dice: 1.3187  decode.d2.loss_cls: 1.2178  decode.d2.loss_mask: 0.6576  decode.d2.loss_dice: 1.2710  decode.d3.loss_cls: 1.1929  decode.d3.loss_mask: 0.6076  decode.d3.loss_dice: 1.1897  decode.d4.loss_cls: 1.1700  decode.d4.loss_mask: 0.6295  decode.d4.loss_dice: 1.1854  decode.d5.loss_cls: 1.2085  decode.d5.loss_mask: 0.6249  decode.d5.loss_dice: 1.1583  decode.d6.loss_cls: 1.1802  decode.d6.loss_mask: 0.6085  decode.d6.loss_dice: 1.1730  decode.d7.loss_cls: 1.1903  decode.d7.loss_mask: 0.6211  decode.d7.loss_dice: 1.1848  decode.d8.loss_cls: 1.1422  decode.d8.loss_mask: 0.6177  decode.d8.loss_dice: 1.1905
2023/05/24 10:52:17 - mmengine - INFO - Iter(train) [133900/160000]  lr: 1.9556e-06  eta: 3:08:25  time: 0.4363  data_time: 0.0100  memory: 4839  grad_norm: 86.4308  loss: 29.1096  decode.loss_cls: 1.0516  decode.loss_mask: 0.6390  decode.loss_dice: 0.9032  decode.d0.loss_cls: 3.1220  decode.d0.loss_mask: 0.7208  decode.d0.loss_dice: 1.1570  decode.d1.loss_cls: 1.1101  decode.d1.loss_mask: 0.7321  decode.d1.loss_dice: 1.0309  decode.d2.loss_cls: 1.0719  decode.d2.loss_mask: 0.6796  decode.d2.loss_dice: 1.0156  decode.d3.loss_cls: 1.1128  decode.d3.loss_mask: 0.6684  decode.d3.loss_dice: 0.9602  decode.d4.loss_cls: 1.0474  decode.d4.loss_mask: 0.6540  decode.d4.loss_dice: 0.9489  decode.d5.loss_cls: 1.0449  decode.d5.loss_mask: 0.6577  decode.d5.loss_dice: 0.9145  decode.d6.loss_cls: 1.0501  decode.d6.loss_mask: 0.6544  decode.d6.loss_dice: 0.9264  decode.d7.loss_cls: 1.0366  decode.d7.loss_mask: 0.6540  decode.d7.loss_dice: 0.9144  decode.d8.loss_cls: 1.0474  decode.d8.loss_mask: 0.6479  decode.d8.loss_dice: 0.9359
2023/05/24 10:52:38 - mmengine - INFO - Iter(train) [133950/160000]  lr: 1.9522e-06  eta: 3:08:03  time: 0.4189  data_time: 0.0098  memory: 4876  grad_norm: 112.0375  loss: 42.0167  decode.loss_cls: 1.3498  decode.loss_mask: 0.9042  decode.loss_dice: 1.6021  decode.d0.loss_cls: 3.4641  decode.d0.loss_mask: 0.9546  decode.d0.loss_dice: 1.9218  decode.d1.loss_cls: 1.4444  decode.d1.loss_mask: 0.9041  decode.d1.loss_dice: 1.7616  decode.d2.loss_cls: 1.5161  decode.d2.loss_mask: 0.8979  decode.d2.loss_dice: 1.7140  decode.d3.loss_cls: 1.4199  decode.d3.loss_mask: 0.9396  decode.d3.loss_dice: 1.6794  decode.d4.loss_cls: 1.3331  decode.d4.loss_mask: 0.9278  decode.d4.loss_dice: 1.6720  decode.d5.loss_cls: 1.3668  decode.d5.loss_mask: 0.9237  decode.d5.loss_dice: 1.6651  decode.d6.loss_cls: 1.3406  decode.d6.loss_mask: 0.9155  decode.d6.loss_dice: 1.6579  decode.d7.loss_cls: 1.2956  decode.d7.loss_mask: 0.9400  decode.d7.loss_dice: 1.6415  decode.d8.loss_cls: 1.3173  decode.d8.loss_mask: 0.9187  decode.d8.loss_dice: 1.6274
2023/05/24 10:53:00 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 10:53:00 - mmengine - INFO - Iter(train) [134000/160000]  lr: 1.9488e-06  eta: 3:07:42  time: 0.4258  data_time: 0.0104  memory: 4836  grad_norm: 97.9923  loss: 33.2045  decode.loss_cls: 0.9984  decode.loss_mask: 0.7018  decode.loss_dice: 1.3178  decode.d0.loss_cls: 3.2081  decode.d0.loss_mask: 0.7009  decode.d0.loss_dice: 1.5097  decode.d1.loss_cls: 1.0989  decode.d1.loss_mask: 0.7024  decode.d1.loss_dice: 1.4780  decode.d2.loss_cls: 1.1131  decode.d2.loss_mask: 0.7058  decode.d2.loss_dice: 1.4164  decode.d3.loss_cls: 0.9819  decode.d3.loss_mask: 0.6938  decode.d3.loss_dice: 1.3443  decode.d4.loss_cls: 0.9955  decode.d4.loss_mask: 0.7043  decode.d4.loss_dice: 1.3615  decode.d5.loss_cls: 1.0541  decode.d5.loss_mask: 0.7012  decode.d5.loss_dice: 1.3171  decode.d6.loss_cls: 1.0156  decode.d6.loss_mask: 0.6837  decode.d6.loss_dice: 1.3009  decode.d7.loss_cls: 1.0366  decode.d7.loss_mask: 0.6892  decode.d7.loss_dice: 1.3495  decode.d8.loss_cls: 0.9944  decode.d8.loss_mask: 0.7015  decode.d8.loss_dice: 1.3284
2023/05/24 10:53:00 - mmengine - INFO - Saving checkpoint at 134000 iterations
2023/05/24 10:53:26 - mmengine - INFO - Iter(train) [134050/160000]  lr: 1.9454e-06  eta: 3:07:21  time: 0.4364  data_time: 0.0100  memory: 4805  grad_norm: 99.1699  loss: 33.8079  decode.loss_cls: 1.3111  decode.loss_mask: 0.7368  decode.loss_dice: 1.0525  decode.d0.loss_cls: 3.0239  decode.d0.loss_mask: 0.8128  decode.d0.loss_dice: 1.3310  decode.d1.loss_cls: 1.5501  decode.d1.loss_mask: 0.7939  decode.d1.loss_dice: 1.1490  decode.d2.loss_cls: 1.4344  decode.d2.loss_mask: 0.7514  decode.d2.loss_dice: 1.0980  decode.d3.loss_cls: 1.3462  decode.d3.loss_mask: 0.7505  decode.d3.loss_dice: 1.0765  decode.d4.loss_cls: 1.3602  decode.d4.loss_mask: 0.7377  decode.d4.loss_dice: 1.0558  decode.d5.loss_cls: 1.2946  decode.d5.loss_mask: 0.7673  decode.d5.loss_dice: 1.0761  decode.d6.loss_cls: 1.2916  decode.d6.loss_mask: 0.7465  decode.d6.loss_dice: 1.0702  decode.d7.loss_cls: 1.2972  decode.d7.loss_mask: 0.7429  decode.d7.loss_dice: 1.0567  decode.d8.loss_cls: 1.3121  decode.d8.loss_mask: 0.7285  decode.d8.loss_dice: 1.0524
2023/05/24 10:53:48 - mmengine - INFO - Iter(train) [134100/160000]  lr: 1.9421e-06  eta: 3:06:59  time: 0.4754  data_time: 0.0097  memory: 4829  grad_norm: 87.9767  loss: 32.4859  decode.loss_cls: 1.2422  decode.loss_mask: 0.6669  decode.loss_dice: 1.0283  decode.d0.loss_cls: 3.2726  decode.d0.loss_mask: 0.7080  decode.d0.loss_dice: 1.2383  decode.d1.loss_cls: 1.3240  decode.d1.loss_mask: 0.7221  decode.d1.loss_dice: 1.1470  decode.d2.loss_cls: 1.3201  decode.d2.loss_mask: 0.7205  decode.d2.loss_dice: 1.0473  decode.d3.loss_cls: 1.2700  decode.d3.loss_mask: 0.6966  decode.d3.loss_dice: 1.0396  decode.d4.loss_cls: 1.3294  decode.d4.loss_mask: 0.6757  decode.d4.loss_dice: 1.0378  decode.d5.loss_cls: 1.2895  decode.d5.loss_mask: 0.6816  decode.d5.loss_dice: 1.0652  decode.d6.loss_cls: 1.3292  decode.d6.loss_mask: 0.6511  decode.d6.loss_dice: 1.0315  decode.d7.loss_cls: 1.2933  decode.d7.loss_mask: 0.6790  decode.d7.loss_dice: 1.0193  decode.d8.loss_cls: 1.2576  decode.d8.loss_mask: 0.6706  decode.d8.loss_dice: 1.0314
2023/05/24 10:54:09 - mmengine - INFO - Iter(train) [134150/160000]  lr: 1.9387e-06  eta: 3:06:38  time: 0.4249  data_time: 0.0099  memory: 4877  grad_norm: 97.1494  loss: 35.6547  decode.loss_cls: 1.1539  decode.loss_mask: 0.7854  decode.loss_dice: 1.2846  decode.d0.loss_cls: 3.1901  decode.d0.loss_mask: 0.8518  decode.d0.loss_dice: 1.6546  decode.d1.loss_cls: 1.3305  decode.d1.loss_mask: 0.8063  decode.d1.loss_dice: 1.4662  decode.d2.loss_cls: 1.2299  decode.d2.loss_mask: 0.8106  decode.d2.loss_dice: 1.3776  decode.d3.loss_cls: 1.2598  decode.d3.loss_mask: 0.7552  decode.d3.loss_dice: 1.3462  decode.d4.loss_cls: 1.2106  decode.d4.loss_mask: 0.7566  decode.d4.loss_dice: 1.3759  decode.d5.loss_cls: 1.2194  decode.d5.loss_mask: 0.7728  decode.d5.loss_dice: 1.2653  decode.d6.loss_cls: 1.2194  decode.d6.loss_mask: 0.7558  decode.d6.loss_dice: 1.2977  decode.d7.loss_cls: 1.2029  decode.d7.loss_mask: 0.7513  decode.d7.loss_dice: 1.2744  decode.d8.loss_cls: 1.1818  decode.d8.loss_mask: 0.7669  decode.d8.loss_dice: 1.3013
2023/05/24 10:54:30 - mmengine - INFO - Iter(train) [134200/160000]  lr: 1.9353e-06  eta: 3:06:16  time: 0.4204  data_time: 0.0098  memory: 4971  grad_norm: 88.2320  loss: 29.3531  decode.loss_cls: 1.1562  decode.loss_mask: 0.5808  decode.loss_dice: 0.9304  decode.d0.loss_cls: 3.0523  decode.d0.loss_mask: 0.6340  decode.d0.loss_dice: 1.0967  decode.d1.loss_cls: 1.3028  decode.d1.loss_mask: 0.5749  decode.d1.loss_dice: 1.0323  decode.d2.loss_cls: 1.2921  decode.d2.loss_mask: 0.5603  decode.d2.loss_dice: 0.9593  decode.d3.loss_cls: 1.1924  decode.d3.loss_mask: 0.5648  decode.d3.loss_dice: 0.9434  decode.d4.loss_cls: 1.1645  decode.d4.loss_mask: 0.5816  decode.d4.loss_dice: 0.9579  decode.d5.loss_cls: 1.1517  decode.d5.loss_mask: 0.5808  decode.d5.loss_dice: 0.9483  decode.d6.loss_cls: 1.1862  decode.d6.loss_mask: 0.5807  decode.d6.loss_dice: 0.9296  decode.d7.loss_cls: 1.1846  decode.d7.loss_mask: 0.5832  decode.d7.loss_dice: 0.9503  decode.d8.loss_cls: 1.1449  decode.d8.loss_mask: 0.5820  decode.d8.loss_dice: 0.9543
2023/05/24 10:54:52 - mmengine - INFO - Iter(train) [134250/160000]  lr: 1.9319e-06  eta: 3:05:54  time: 0.4225  data_time: 0.0104  memory: 4874  grad_norm: 97.0242  loss: 35.7443  decode.loss_cls: 1.0684  decode.loss_mask: 0.8325  decode.loss_dice: 1.3413  decode.d0.loss_cls: 3.1893  decode.d0.loss_mask: 0.8576  decode.d0.loss_dice: 1.6137  decode.d1.loss_cls: 1.2587  decode.d1.loss_mask: 0.8825  decode.d1.loss_dice: 1.4922  decode.d2.loss_cls: 1.1653  decode.d2.loss_mask: 0.8577  decode.d2.loss_dice: 1.4075  decode.d3.loss_cls: 1.1540  decode.d3.loss_mask: 0.8413  decode.d3.loss_dice: 1.3555  decode.d4.loss_cls: 1.1688  decode.d4.loss_mask: 0.8529  decode.d4.loss_dice: 1.3384  decode.d5.loss_cls: 1.0762  decode.d5.loss_mask: 0.8323  decode.d5.loss_dice: 1.3908  decode.d6.loss_cls: 1.0264  decode.d6.loss_mask: 0.8442  decode.d6.loss_dice: 1.3683  decode.d7.loss_cls: 1.0551  decode.d7.loss_mask: 0.8424  decode.d7.loss_dice: 1.3505  decode.d8.loss_cls: 1.0702  decode.d8.loss_mask: 0.8427  decode.d8.loss_dice: 1.3676
2023/05/24 10:55:13 - mmengine - INFO - Iter(train) [134300/160000]  lr: 1.9286e-06  eta: 3:05:32  time: 0.4218  data_time: 0.0104  memory: 4860  grad_norm: 80.3013  loss: 40.4246  decode.loss_cls: 1.3984  decode.loss_mask: 0.9283  decode.loss_dice: 1.4590  decode.d0.loss_cls: 3.2392  decode.d0.loss_mask: 0.9954  decode.d0.loss_dice: 1.6816  decode.d1.loss_cls: 1.4578  decode.d1.loss_mask: 1.0295  decode.d1.loss_dice: 1.5631  decode.d2.loss_cls: 1.3616  decode.d2.loss_mask: 1.0094  decode.d2.loss_dice: 1.5215  decode.d3.loss_cls: 1.3809  decode.d3.loss_mask: 0.9853  decode.d3.loss_dice: 1.4240  decode.d4.loss_cls: 1.3775  decode.d4.loss_mask: 0.9821  decode.d4.loss_dice: 1.4697  decode.d5.loss_cls: 1.4329  decode.d5.loss_mask: 0.9928  decode.d5.loss_dice: 1.4245  decode.d6.loss_cls: 1.4016  decode.d6.loss_mask: 0.9268  decode.d6.loss_dice: 1.4449  decode.d7.loss_cls: 1.3795  decode.d7.loss_mask: 0.9276  decode.d7.loss_dice: 1.4373  decode.d8.loss_cls: 1.4012  decode.d8.loss_mask: 0.9263  decode.d8.loss_dice: 1.4649
2023/05/24 10:55:34 - mmengine - INFO - Iter(train) [134350/160000]  lr: 1.9252e-06  eta: 3:05:11  time: 0.4253  data_time: 0.0100  memory: 4864  grad_norm: 98.5205  loss: 35.7491  decode.loss_cls: 1.0439  decode.loss_mask: 0.9827  decode.loss_dice: 1.3211  decode.d0.loss_cls: 2.9160  decode.d0.loss_mask: 1.0059  decode.d0.loss_dice: 1.5101  decode.d1.loss_cls: 1.1006  decode.d1.loss_mask: 1.0524  decode.d1.loss_dice: 1.4371  decode.d2.loss_cls: 1.1311  decode.d2.loss_mask: 0.9341  decode.d2.loss_dice: 1.3564  decode.d3.loss_cls: 1.0729  decode.d3.loss_mask: 0.9641  decode.d3.loss_dice: 1.3108  decode.d4.loss_cls: 1.0637  decode.d4.loss_mask: 0.9635  decode.d4.loss_dice: 1.3054  decode.d5.loss_cls: 1.0503  decode.d5.loss_mask: 0.9665  decode.d5.loss_dice: 1.3064  decode.d6.loss_cls: 1.0000  decode.d6.loss_mask: 0.9948  decode.d6.loss_dice: 1.3429  decode.d7.loss_cls: 1.0143  decode.d7.loss_mask: 0.9563  decode.d7.loss_dice: 1.3412  decode.d8.loss_cls: 1.0308  decode.d8.loss_mask: 0.9772  decode.d8.loss_dice: 1.2967
2023/05/24 10:55:55 - mmengine - INFO - Iter(train) [134400/160000]  lr: 1.9218e-06  eta: 3:04:49  time: 0.4265  data_time: 0.0099  memory: 4880  grad_norm: 120.6162  loss: 33.7182  decode.loss_cls: 1.0972  decode.loss_mask: 0.6632  decode.loss_dice: 1.2641  decode.d0.loss_cls: 3.1452  decode.d0.loss_mask: 0.7958  decode.d0.loss_dice: 1.5274  decode.d1.loss_cls: 1.1952  decode.d1.loss_mask: 0.7455  decode.d1.loss_dice: 1.4515  decode.d2.loss_cls: 1.2683  decode.d2.loss_mask: 0.6949  decode.d2.loss_dice: 1.3472  decode.d3.loss_cls: 1.1470  decode.d3.loss_mask: 0.6537  decode.d3.loss_dice: 1.2781  decode.d4.loss_cls: 1.1193  decode.d4.loss_mask: 0.6923  decode.d4.loss_dice: 1.3048  decode.d5.loss_cls: 1.1183  decode.d5.loss_mask: 0.6831  decode.d5.loss_dice: 1.2908  decode.d6.loss_cls: 1.1509  decode.d6.loss_mask: 0.6809  decode.d6.loss_dice: 1.2732  decode.d7.loss_cls: 1.1273  decode.d7.loss_mask: 0.6675  decode.d7.loss_dice: 1.2712  decode.d8.loss_cls: 1.1361  decode.d8.loss_mask: 0.6596  decode.d8.loss_dice: 1.2685
2023/05/24 10:56:17 - mmengine - INFO - Iter(train) [134450/160000]  lr: 1.9184e-06  eta: 3:04:27  time: 0.4214  data_time: 0.0102  memory: 4829  grad_norm: 93.1855  loss: 32.7734  decode.loss_cls: 1.2907  decode.loss_mask: 0.7237  decode.loss_dice: 1.0229  decode.d0.loss_cls: 3.0101  decode.d0.loss_mask: 0.7634  decode.d0.loss_dice: 1.2219  decode.d1.loss_cls: 1.4278  decode.d1.loss_mask: 0.7479  decode.d1.loss_dice: 1.1349  decode.d2.loss_cls: 1.3612  decode.d2.loss_mask: 0.6939  decode.d2.loss_dice: 1.0655  decode.d3.loss_cls: 1.3072  decode.d3.loss_mask: 0.7170  decode.d3.loss_dice: 1.0414  decode.d4.loss_cls: 1.2798  decode.d4.loss_mask: 0.7073  decode.d4.loss_dice: 1.0444  decode.d5.loss_cls: 1.2836  decode.d5.loss_mask: 0.7136  decode.d5.loss_dice: 1.0556  decode.d6.loss_cls: 1.2583  decode.d6.loss_mask: 0.7360  decode.d6.loss_dice: 1.0439  decode.d7.loss_cls: 1.3265  decode.d7.loss_mask: 0.7124  decode.d7.loss_dice: 1.0191  decode.d8.loss_cls: 1.3000  decode.d8.loss_mask: 0.7153  decode.d8.loss_dice: 1.0478
2023/05/24 10:56:38 - mmengine - INFO - Iter(train) [134500/160000]  lr: 1.9151e-06  eta: 3:04:05  time: 0.4163  data_time: 0.0098  memory: 4837  grad_norm: 92.9433  loss: 31.9289  decode.loss_cls: 1.0653  decode.loss_mask: 0.7516  decode.loss_dice: 1.1559  decode.d0.loss_cls: 2.7529  decode.d0.loss_mask: 0.8102  decode.d0.loss_dice: 1.2429  decode.d1.loss_cls: 1.1268  decode.d1.loss_mask: 0.8441  decode.d1.loss_dice: 1.2617  decode.d2.loss_cls: 1.1540  decode.d2.loss_mask: 0.7804  decode.d2.loss_dice: 1.1685  decode.d3.loss_cls: 1.1557  decode.d3.loss_mask: 0.7213  decode.d3.loss_dice: 1.1344  decode.d4.loss_cls: 1.1588  decode.d4.loss_mask: 0.7158  decode.d4.loss_dice: 1.0855  decode.d5.loss_cls: 1.0600  decode.d5.loss_mask: 0.7415  decode.d5.loss_dice: 1.1420  decode.d6.loss_cls: 1.0093  decode.d6.loss_mask: 0.7889  decode.d6.loss_dice: 1.1501  decode.d7.loss_cls: 1.0252  decode.d7.loss_mask: 0.7875  decode.d7.loss_dice: 1.1643  decode.d8.loss_cls: 1.0486  decode.d8.loss_mask: 0.7616  decode.d8.loss_dice: 1.1640
2023/05/24 10:56:59 - mmengine - INFO - Iter(train) [134550/160000]  lr: 1.9117e-06  eta: 3:03:44  time: 0.4255  data_time: 0.0100  memory: 4836  grad_norm: 109.4771  loss: 28.1629  decode.loss_cls: 0.9380  decode.loss_mask: 0.6747  decode.loss_dice: 0.9735  decode.d0.loss_cls: 2.7017  decode.d0.loss_mask: 0.7233  decode.d0.loss_dice: 1.1325  decode.d1.loss_cls: 1.0099  decode.d1.loss_mask: 0.7302  decode.d1.loss_dice: 1.0700  decode.d2.loss_cls: 0.9868  decode.d2.loss_mask: 0.6622  decode.d2.loss_dice: 1.0202  decode.d3.loss_cls: 0.9344  decode.d3.loss_mask: 0.6631  decode.d3.loss_dice: 0.9940  decode.d4.loss_cls: 0.9610  decode.d4.loss_mask: 0.6639  decode.d4.loss_dice: 0.9789  decode.d5.loss_cls: 0.9507  decode.d5.loss_mask: 0.6667  decode.d5.loss_dice: 0.9790  decode.d6.loss_cls: 0.9445  decode.d6.loss_mask: 0.6781  decode.d6.loss_dice: 0.9546  decode.d7.loss_cls: 0.9410  decode.d7.loss_mask: 0.6770  decode.d7.loss_dice: 0.9944  decode.d8.loss_cls: 0.9141  decode.d8.loss_mask: 0.6782  decode.d8.loss_dice: 0.9664
2023/05/24 10:57:21 - mmengine - INFO - Iter(train) [134600/160000]  lr: 1.9083e-06  eta: 3:03:22  time: 0.4516  data_time: 0.0097  memory: 4821  grad_norm: 111.9194  loss: 31.1587  decode.loss_cls: 1.1216  decode.loss_mask: 0.6651  decode.loss_dice: 1.0424  decode.d0.loss_cls: 3.0691  decode.d0.loss_mask: 0.7051  decode.d0.loss_dice: 1.2109  decode.d1.loss_cls: 1.2274  decode.d1.loss_mask: 0.7482  decode.d1.loss_dice: 1.1625  decode.d2.loss_cls: 1.1915  decode.d2.loss_mask: 0.6642  decode.d2.loss_dice: 1.0803  decode.d3.loss_cls: 1.1684  decode.d3.loss_mask: 0.6630  decode.d3.loss_dice: 1.0692  decode.d4.loss_cls: 1.2031  decode.d4.loss_mask: 0.6471  decode.d4.loss_dice: 1.0398  decode.d5.loss_cls: 1.2121  decode.d5.loss_mask: 0.6561  decode.d5.loss_dice: 1.0474  decode.d6.loss_cls: 1.1717  decode.d6.loss_mask: 0.6754  decode.d6.loss_dice: 1.0674  decode.d7.loss_cls: 1.1255  decode.d7.loss_mask: 0.6585  decode.d7.loss_dice: 1.0486  decode.d8.loss_cls: 1.1126  decode.d8.loss_mask: 0.6523  decode.d8.loss_dice: 1.0522
2023/05/24 10:57:43 - mmengine - INFO - Iter(train) [134650/160000]  lr: 1.9049e-06  eta: 3:03:00  time: 0.4252  data_time: 0.0107  memory: 4903  grad_norm: 106.8971  loss: 33.9788  decode.loss_cls: 1.1436  decode.loss_mask: 0.8230  decode.loss_dice: 1.1538  decode.d0.loss_cls: 3.0835  decode.d0.loss_mask: 0.8635  decode.d0.loss_dice: 1.3572  decode.d1.loss_cls: 1.1661  decode.d1.loss_mask: 0.8886  decode.d1.loss_dice: 1.3454  decode.d2.loss_cls: 1.0636  decode.d2.loss_mask: 0.8793  decode.d2.loss_dice: 1.3001  decode.d3.loss_cls: 1.0763  decode.d3.loss_mask: 0.8683  decode.d3.loss_dice: 1.2098  decode.d4.loss_cls: 1.1016  decode.d4.loss_mask: 0.8539  decode.d4.loss_dice: 1.1809  decode.d5.loss_cls: 1.1621  decode.d5.loss_mask: 0.8216  decode.d5.loss_dice: 1.1801  decode.d6.loss_cls: 1.1632  decode.d6.loss_mask: 0.8428  decode.d6.loss_dice: 1.1642  decode.d7.loss_cls: 1.1503  decode.d7.loss_mask: 0.8377  decode.d7.loss_dice: 1.1641  decode.d8.loss_cls: 1.1257  decode.d8.loss_mask: 0.8248  decode.d8.loss_dice: 1.1838
2023/05/24 10:58:05 - mmengine - INFO - Iter(train) [134700/160000]  lr: 1.9015e-06  eta: 3:02:39  time: 0.4368  data_time: 0.0100  memory: 4899  grad_norm: 103.2097  loss: 33.7977  decode.loss_cls: 0.9861  decode.loss_mask: 0.8378  decode.loss_dice: 1.3083  decode.d0.loss_cls: 2.9597  decode.d0.loss_mask: 0.9263  decode.d0.loss_dice: 1.5387  decode.d1.loss_cls: 1.0342  decode.d1.loss_mask: 0.8593  decode.d1.loss_dice: 1.4067  decode.d2.loss_cls: 1.0131  decode.d2.loss_mask: 0.8378  decode.d2.loss_dice: 1.3766  decode.d3.loss_cls: 0.9506  decode.d3.loss_mask: 0.8497  decode.d3.loss_dice: 1.3320  decode.d4.loss_cls: 0.9739  decode.d4.loss_mask: 0.8292  decode.d4.loss_dice: 1.3136  decode.d5.loss_cls: 0.9491  decode.d5.loss_mask: 0.8361  decode.d5.loss_dice: 1.3394  decode.d6.loss_cls: 0.9599  decode.d6.loss_mask: 0.8412  decode.d6.loss_dice: 1.3263  decode.d7.loss_cls: 0.9211  decode.d7.loss_mask: 0.8472  decode.d7.loss_dice: 1.3421  decode.d8.loss_cls: 0.9232  decode.d8.loss_mask: 0.8441  decode.d8.loss_dice: 1.3345
2023/05/24 10:58:26 - mmengine - INFO - Iter(train) [134750/160000]  lr: 1.8981e-06  eta: 3:02:17  time: 0.4658  data_time: 0.0098  memory: 4869  grad_norm: 99.7465  loss: 39.4985  decode.loss_cls: 1.3103  decode.loss_mask: 0.8381  decode.loss_dice: 1.5379  decode.d0.loss_cls: 3.4286  decode.d0.loss_mask: 0.9237  decode.d0.loss_dice: 1.7326  decode.d1.loss_cls: 1.3865  decode.d1.loss_mask: 0.8531  decode.d1.loss_dice: 1.6383  decode.d2.loss_cls: 1.3132  decode.d2.loss_mask: 0.8404  decode.d2.loss_dice: 1.5648  decode.d3.loss_cls: 1.2679  decode.d3.loss_mask: 0.8287  decode.d3.loss_dice: 1.5650  decode.d4.loss_cls: 1.2966  decode.d4.loss_mask: 0.8594  decode.d4.loss_dice: 1.5747  decode.d5.loss_cls: 1.2235  decode.d5.loss_mask: 0.8660  decode.d5.loss_dice: 1.5691  decode.d6.loss_cls: 1.2946  decode.d6.loss_mask: 0.8425  decode.d6.loss_dice: 1.5468  decode.d7.loss_cls: 1.3256  decode.d7.loss_mask: 0.8253  decode.d7.loss_dice: 1.5369  decode.d8.loss_cls: 1.3334  decode.d8.loss_mask: 0.8295  decode.d8.loss_dice: 1.5455
2023/05/24 10:58:49 - mmengine - INFO - Iter(train) [134800/160000]  lr: 1.8948e-06  eta: 3:01:56  time: 0.4830  data_time: 0.0108  memory: 4876  grad_norm: 89.1133  loss: 33.6055  decode.loss_cls: 1.1285  decode.loss_mask: 0.6214  decode.loss_dice: 1.3249  decode.d0.loss_cls: 3.1984  decode.d0.loss_mask: 0.6597  decode.d0.loss_dice: 1.5646  decode.d1.loss_cls: 1.2487  decode.d1.loss_mask: 0.6228  decode.d1.loss_dice: 1.5381  decode.d2.loss_cls: 1.1944  decode.d2.loss_mask: 0.6037  decode.d2.loss_dice: 1.3718  decode.d3.loss_cls: 1.1759  decode.d3.loss_mask: 0.6395  decode.d3.loss_dice: 1.3118  decode.d4.loss_cls: 1.1428  decode.d4.loss_mask: 0.5944  decode.d4.loss_dice: 1.3100  decode.d5.loss_cls: 1.1785  decode.d5.loss_mask: 0.6037  decode.d5.loss_dice: 1.3102  decode.d6.loss_cls: 1.1435  decode.d6.loss_mask: 0.6442  decode.d6.loss_dice: 1.3271  decode.d7.loss_cls: 1.0959  decode.d7.loss_mask: 0.6324  decode.d7.loss_dice: 1.3534  decode.d8.loss_cls: 1.1093  decode.d8.loss_mask: 0.6309  decode.d8.loss_dice: 1.3247
2023/05/24 10:59:11 - mmengine - INFO - Iter(train) [134850/160000]  lr: 1.8914e-06  eta: 3:01:34  time: 0.4425  data_time: 0.0099  memory: 4839  grad_norm: 133.4977  loss: 34.8860  decode.loss_cls: 1.2862  decode.loss_mask: 0.7354  decode.loss_dice: 1.1999  decode.d0.loss_cls: 3.0096  decode.d0.loss_mask: 0.7885  decode.d0.loss_dice: 1.3720  decode.d1.loss_cls: 1.3996  decode.d1.loss_mask: 0.7931  decode.d1.loss_dice: 1.2663  decode.d2.loss_cls: 1.4408  decode.d2.loss_mask: 0.7680  decode.d2.loss_dice: 1.2114  decode.d3.loss_cls: 1.3005  decode.d3.loss_mask: 0.7675  decode.d3.loss_dice: 1.2424  decode.d4.loss_cls: 1.3325  decode.d4.loss_mask: 0.7412  decode.d4.loss_dice: 1.2182  decode.d5.loss_cls: 1.3502  decode.d5.loss_mask: 0.7375  decode.d5.loss_dice: 1.2088  decode.d6.loss_cls: 1.2844  decode.d6.loss_mask: 0.7585  decode.d6.loss_dice: 1.2249  decode.d7.loss_cls: 1.2596  decode.d7.loss_mask: 0.7488  decode.d7.loss_dice: 1.1882  decode.d8.loss_cls: 1.3067  decode.d8.loss_mask: 0.7510  decode.d8.loss_dice: 1.1943
2023/05/24 10:59:33 - mmengine - INFO - Iter(train) [134900/160000]  lr: 1.8880e-06  eta: 3:01:12  time: 0.4171  data_time: 0.0100  memory: 4824  grad_norm: 99.9661  loss: 31.3086  decode.loss_cls: 1.0245  decode.loss_mask: 0.7251  decode.loss_dice: 1.1179  decode.d0.loss_cls: 2.9447  decode.d0.loss_mask: 0.7281  decode.d0.loss_dice: 1.2810  decode.d1.loss_cls: 1.1275  decode.d1.loss_mask: 0.7533  decode.d1.loss_dice: 1.2184  decode.d2.loss_cls: 1.0346  decode.d2.loss_mask: 0.7760  decode.d2.loss_dice: 1.1969  decode.d3.loss_cls: 1.0257  decode.d3.loss_mask: 0.7384  decode.d3.loss_dice: 1.1145  decode.d4.loss_cls: 1.0574  decode.d4.loss_mask: 0.7334  decode.d4.loss_dice: 1.1216  decode.d5.loss_cls: 1.0752  decode.d5.loss_mask: 0.7205  decode.d5.loss_dice: 1.1399  decode.d6.loss_cls: 1.0525  decode.d6.loss_mask: 0.7029  decode.d6.loss_dice: 1.1201  decode.d7.loss_cls: 1.0327  decode.d7.loss_mask: 0.7231  decode.d7.loss_dice: 1.1291  decode.d8.loss_cls: 1.0611  decode.d8.loss_mask: 0.7100  decode.d8.loss_dice: 1.1225
2023/05/24 10:59:54 - mmengine - INFO - Iter(train) [134950/160000]  lr: 1.8846e-06  eta: 3:00:51  time: 0.4369  data_time: 0.0101  memory: 4918  grad_norm: 124.1967  loss: 32.2012  decode.loss_cls: 1.1130  decode.loss_mask: 0.6787  decode.loss_dice: 1.1862  decode.d0.loss_cls: 2.9082  decode.d0.loss_mask: 0.7040  decode.d0.loss_dice: 1.3451  decode.d1.loss_cls: 1.0831  decode.d1.loss_mask: 0.7154  decode.d1.loss_dice: 1.2995  decode.d2.loss_cls: 1.0954  decode.d2.loss_mask: 0.7081  decode.d2.loss_dice: 1.2806  decode.d3.loss_cls: 1.0608  decode.d3.loss_mask: 0.7311  decode.d3.loss_dice: 1.2563  decode.d4.loss_cls: 1.0776  decode.d4.loss_mask: 0.7229  decode.d4.loss_dice: 1.2489  decode.d5.loss_cls: 1.1000  decode.d5.loss_mask: 0.7135  decode.d5.loss_dice: 1.2182  decode.d6.loss_cls: 1.0847  decode.d6.loss_mask: 0.7209  decode.d6.loss_dice: 1.2025  decode.d7.loss_cls: 1.0976  decode.d7.loss_mask: 0.6908  decode.d7.loss_dice: 1.1811  decode.d8.loss_cls: 1.1110  decode.d8.loss_mask: 0.6825  decode.d8.loss_dice: 1.1835
2023/05/24 11:00:16 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 11:00:16 - mmengine - INFO - Iter(train) [135000/160000]  lr: 1.8812e-06  eta: 3:00:29  time: 0.4226  data_time: 0.0103  memory: 4835  grad_norm: 99.7158  loss: 35.5358  decode.loss_cls: 1.1740  decode.loss_mask: 0.7344  decode.loss_dice: 1.3237  decode.d0.loss_cls: 3.1615  decode.d0.loss_mask: 0.7779  decode.d0.loss_dice: 1.6031  decode.d1.loss_cls: 1.3236  decode.d1.loss_mask: 0.7487  decode.d1.loss_dice: 1.4728  decode.d2.loss_cls: 1.2236  decode.d2.loss_mask: 0.7470  decode.d2.loss_dice: 1.4421  decode.d3.loss_cls: 1.2178  decode.d3.loss_mask: 0.7581  decode.d3.loss_dice: 1.3930  decode.d4.loss_cls: 1.1992  decode.d4.loss_mask: 0.7625  decode.d4.loss_dice: 1.3888  decode.d5.loss_cls: 1.1577  decode.d5.loss_mask: 0.7811  decode.d5.loss_dice: 1.3864  decode.d6.loss_cls: 1.1920  decode.d6.loss_mask: 0.7253  decode.d6.loss_dice: 1.3212  decode.d7.loss_cls: 1.2013  decode.d7.loss_mask: 0.7192  decode.d7.loss_dice: 1.3343  decode.d8.loss_cls: 1.2137  decode.d8.loss_mask: 0.7334  decode.d8.loss_dice: 1.3183
2023/05/24 11:00:16 - mmengine - INFO - Saving checkpoint at 135000 iterations
2023/05/24 11:00:26 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:50  time: 0.0774  data_time: 0.0018  memory: 2167  
2023/05/24 11:00:30 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:44  time: 0.0791  data_time: 0.0019  memory: 2216  
2023/05/24 11:00:34 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:39  time: 0.0795  data_time: 0.0018  memory: 2167  
2023/05/24 11:00:40 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:39  time: 0.0855  data_time: 0.0017  memory: 2104  
2023/05/24 11:00:44 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:34  time: 0.0791  data_time: 0.0018  memory: 2831  
2023/05/24 11:00:48 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0812  data_time: 0.0018  memory: 2167  
2023/05/24 11:00:52 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0831  data_time: 0.0024  memory: 2167  
2023/05/24 11:00:56 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0799  data_time: 0.0020  memory: 2167  
2023/05/24 11:01:01 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0789  data_time: 0.0018  memory: 2944  
2023/05/24 11:01:05 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0787  data_time: 0.0017  memory: 2356  
2023/05/24 11:01:08 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0773  data_time: 0.0017  memory: 2217  
2023/05/24 11:01:13 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0780  data_time: 0.0017  memory: 2328  
2023/05/24 11:01:16 - mmengine - INFO - per class results:
2023/05/24 11:01:16 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.07 | 93.62 |
|     bicycle      | 69.94 | 83.13 |
|       car        |  61.4 | 84.97 |
|    motorcycle    | 83.66 | 90.72 |
|     airplane     |  87.3 | 93.96 |
|       bus        | 82.95 | 87.89 |
|      train       | 83.34 | 93.83 |
|      truck       | 56.57 | 76.61 |
|       boat       | 59.83 | 79.18 |
|  traffic light   |  68.0 | 86.36 |
|   fire hydrant   | 88.13 | 95.37 |
|    stop sign     | 90.92 | 97.06 |
|  parking meter   | 75.43 | 86.27 |
|      bench       | 48.72 | 70.87 |
|       bird       | 81.83 | 91.26 |
|       cat        | 79.76 | 84.98 |
|       dog        | 79.06 | 86.11 |
|      horse       | 78.17 | 89.66 |
|      sheep       | 86.03 | 92.25 |
|       cow        | 81.26 | 89.01 |
|     elephant     | 89.77 | 95.31 |
|       bear       |  92.2 | 95.41 |
|      zebra       | 90.27 | 93.33 |
|     giraffe      | 87.42 |  93.6 |
|     backpack     | 35.95 | 64.58 |
|     umbrella     | 81.34 | 88.08 |
|     handbag      |  35.0 | 52.62 |
|       tie        | 10.83 | 13.23 |
|     suitcase     | 76.86 |  91.1 |
|     frisbee      | 68.79 | 89.95 |
|       skis       | 42.69 | 56.71 |
|    snowboard     | 42.91 | 60.98 |
|   sports ball    | 59.74 | 76.27 |
|       kite       | 57.57 | 70.55 |
|   baseball bat   | 53.63 | 68.39 |
|  baseball glove  | 74.18 | 87.13 |
|    skateboard    | 76.42 | 88.97 |
|    surfboard     | 71.88 | 87.42 |
|  tennis racket   | 86.17 | 92.69 |
|      bottle      | 42.58 |  55.9 |
|    wine glass    | 55.61 | 78.84 |
|       cup        | 50.96 | 69.06 |
|       fork       | 25.53 | 31.34 |
|      knife       | 25.28 | 32.66 |
|      spoon       | 39.11 | 53.13 |
|       bowl       | 46.08 | 68.64 |
|      banana      | 67.59 | 86.29 |
|      apple       | 54.39 |  71.3 |
|     sandwich     | 43.44 | 56.72 |
|      orange      | 62.01 | 71.53 |
|     broccoli     | 44.46 | 50.05 |
|      carrot      | 47.18 | 51.27 |
|     hot dog      | 50.55 | 59.85 |
|      pizza       | 64.83 | 79.54 |
|      donut       | 68.47 |  84.4 |
|       cake       | 56.36 | 70.45 |
|      chair       | 47.64 | 65.46 |
|      couch       | 56.51 | 80.87 |
|   potted plant   |  35.2 | 54.83 |
|       bed        | 63.25 | 82.75 |
|   dining table   |  44.7 |  78.6 |
|      toilet      | 80.34 | 93.45 |
|        tv        |  73.8 | 87.86 |
|      laptop      | 76.14 | 90.85 |
|      mouse       | 76.95 | 89.92 |
|      remote      | 63.34 | 72.53 |
|     keyboard     |  59.9 | 70.84 |
|    cell phone    | 71.91 | 90.25 |
|    microwave     | 61.23 | 76.22 |
|       oven       | 58.05 | 78.94 |
|     toaster      | 43.02 | 54.14 |
|       sink       | 53.92 | 80.14 |
|   refrigerator   | 76.42 | 91.59 |
|       book       | 50.04 | 71.04 |
|      clock       | 73.62 | 83.73 |
|       vase       | 57.86 | 84.32 |
|     scissors     | 78.61 | 89.43 |
|    teddy bear    | 74.29 |  84.1 |
|    hair drier    | 45.94 | 56.78 |
|    toothbrush    |  40.2 | 78.38 |
|      banner      | 33.72 | 63.46 |
|     blanket      |  5.65 |  6.06 |
|      branch      | 15.19 |  21.0 |
|      bridge      | 31.05 | 44.63 |
|  building-other  | 53.97 | 71.17 |
|       bush       | 32.78 | 45.84 |
|     cabinet      | 52.26 |  72.6 |
|       cage       |  8.92 | 10.59 |
|    cardboard     | 47.01 | 61.22 |
|      carpet      | 54.03 | 75.05 |
|  ceiling-other   | 63.54 | 82.95 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      |  21.0 | 30.29 |
|      clouds      |  47.3 | 61.46 |
|     counter      | 27.96 | 45.65 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 65.04 | 77.87 |
|    desk-stuff    | 44.53 | 63.01 |
|       dirt       | 41.47 | 61.83 |
|    door-stuff    | 39.63 | 63.41 |
|      fence       | 33.78 | 62.18 |
|   floor-marble   |  8.26 |  9.65 |
|   floor-other    | 22.63 | 29.87 |
|   floor-stone    |  2.75 |  3.28 |
|    floor-tile    | 60.86 | 69.01 |
|    floor-wood    | 62.65 | 79.73 |
|      flower      | 42.06 | 59.01 |
|       fog        |  4.61 |  4.72 |
|    food-other    | 23.29 | 26.75 |
|      fruit       |  39.0 | 54.42 |
| furniture-other  | 17.49 | 23.02 |
|      grass       | 70.05 | 82.77 |
|      gravel      | 29.49 | 40.96 |
|   ground-other   |  1.75 |  2.31 |
|       hill       | 20.67 | 27.84 |
|      house       | 22.69 | 27.64 |
|      leaves      | 23.13 | 29.37 |
|      light       | 37.23 | 55.46 |
|       mat        |  0.0  |  0.0  |
|      metal       | 32.59 | 48.71 |
|   mirror-stuff   |  50.7 | 67.85 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 53.45 | 68.42 |
|       mud        |  7.12 |  7.48 |
|      napkin      |  5.85 |  5.86 |
|       net        | 41.74 | 66.38 |
|      paper       | 30.59 | 40.98 |
|     pavement     |  50.7 | 69.86 |
|      pillow      | 15.02 | 18.15 |
|   plant-other    | 20.15 | 31.23 |
|     plastic      | 23.05 | 32.85 |
|     platform     | 29.85 | 46.99 |
|   playingfield   | 70.85 | 91.51 |
|     railing      |  9.17 | 22.75 |
|     railroad     | 59.74 | 73.64 |
|      river       | 56.84 | 83.17 |
|       road       | 65.19 | 82.73 |
|       rock       | 42.12 | 60.14 |
|       roof       | 15.08 | 20.19 |
|       rug        |  35.7 | 51.42 |
|      salad       |  0.0  |  0.0  |
|       sand       | 63.02 | 71.65 |
|       sea        | 85.71 | 91.73 |
|      shelf       | 33.99 | 47.92 |
|    sky-other     | 70.67 | 87.64 |
|    skyscraper    | 34.23 | 42.75 |
|       snow       | 88.47 | 93.36 |
|   solid-other    |  0.23 |  0.24 |
|      stairs      | 24.69 | 43.22 |
|      stone       |  18.0 | 34.56 |
|      straw       |  25.0 | 29.65 |
| structural-other |  0.06 |  0.06 |
|      table       | 19.37 | 26.46 |
|       tent       |  7.68 |  10.2 |
|  textile-other   | 11.76 | 19.45 |
|      towel       | 33.66 | 43.14 |
|       tree       | 72.83 | 87.23 |
|    vegetable     | 33.96 | 44.53 |
|    wall-brick    | 45.86 | 64.56 |
|  wall-concrete   | 59.65 |  81.2 |
|    wall-other    | 20.21 |  34.5 |
|    wall-panel    |  2.76 |  3.06 |
|    wall-stone    | 27.11 | 31.73 |
|    wall-tile     | 63.49 | 74.95 |
|    wall-wood     |  38.4 | 54.72 |
|   water-other    |  16.8 | 22.61 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 50.65 |  60.0 |
|   window-other   | 46.35 | 68.31 |
|       wood       | 25.01 | 37.19 |
+------------------+-------+-------+
2023/05/24 11:01:16 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.3400  mIoU: 46.8500  mAcc: 59.1800  data_time: 0.0021  time: 0.0851
2023/05/24 11:01:39 - mmengine - INFO - Iter(train) [135050/160000]  lr: 1.8778e-06  eta: 3:00:08  time: 0.4329  data_time: 0.0097  memory: 4890  grad_norm: 92.7729  loss: 24.8314  decode.loss_cls: 0.7835  decode.loss_mask: 0.6195  decode.loss_dice: 0.7933  decode.d0.loss_cls: 2.7510  decode.d0.loss_mask: 0.6305  decode.d0.loss_dice: 0.8398  decode.d1.loss_cls: 0.9832  decode.d1.loss_mask: 0.6382  decode.d1.loss_dice: 0.8493  decode.d2.loss_cls: 0.9783  decode.d2.loss_mask: 0.6197  decode.d2.loss_dice: 0.8160  decode.d3.loss_cls: 0.8957  decode.d3.loss_mask: 0.6148  decode.d3.loss_dice: 0.7743  decode.d4.loss_cls: 0.9165  decode.d4.loss_mask: 0.6067  decode.d4.loss_dice: 0.7805  decode.d5.loss_cls: 0.8844  decode.d5.loss_mask: 0.6094  decode.d5.loss_dice: 0.7795  decode.d6.loss_cls: 0.8487  decode.d6.loss_mask: 0.6034  decode.d6.loss_dice: 0.7718  decode.d7.loss_cls: 0.8496  decode.d7.loss_mask: 0.6092  decode.d7.loss_dice: 0.7634  decode.d8.loss_cls: 0.8157  decode.d8.loss_mask: 0.6102  decode.d8.loss_dice: 0.7953
2023/05/24 11:02:00 - mmengine - INFO - Iter(train) [135100/160000]  lr: 1.8745e-06  eta: 2:59:46  time: 0.4290  data_time: 0.0100  memory: 4871  grad_norm: 99.4783  loss: 30.7258  decode.loss_cls: 1.0431  decode.loss_mask: 0.8251  decode.loss_dice: 0.9973  decode.d0.loss_cls: 2.8337  decode.d0.loss_mask: 0.7840  decode.d0.loss_dice: 1.1026  decode.d1.loss_cls: 1.1291  decode.d1.loss_mask: 0.8315  decode.d1.loss_dice: 1.0322  decode.d2.loss_cls: 1.0812  decode.d2.loss_mask: 0.8021  decode.d2.loss_dice: 0.9883  decode.d3.loss_cls: 1.0626  decode.d3.loss_mask: 0.8001  decode.d3.loss_dice: 0.9829  decode.d4.loss_cls: 1.0376  decode.d4.loss_mask: 0.8242  decode.d4.loss_dice: 1.0040  decode.d5.loss_cls: 1.1093  decode.d5.loss_mask: 0.7928  decode.d5.loss_dice: 1.0233  decode.d6.loss_cls: 1.0990  decode.d6.loss_mask: 0.8096  decode.d6.loss_dice: 0.9681  decode.d7.loss_cls: 1.1177  decode.d7.loss_mask: 0.8064  decode.d7.loss_dice: 0.9728  decode.d8.loss_cls: 1.0544  decode.d8.loss_mask: 0.8235  decode.d8.loss_dice: 0.9873
2023/05/24 11:02:22 - mmengine - INFO - Iter(train) [135150/160000]  lr: 1.8711e-06  eta: 2:59:24  time: 0.4306  data_time: 0.0107  memory: 4866  grad_norm: 101.7580  loss: 39.8015  decode.loss_cls: 1.3079  decode.loss_mask: 0.8605  decode.loss_dice: 1.4921  decode.d0.loss_cls: 3.2925  decode.d0.loss_mask: 0.9123  decode.d0.loss_dice: 1.7425  decode.d1.loss_cls: 1.3901  decode.d1.loss_mask: 0.8861  decode.d1.loss_dice: 1.6525  decode.d2.loss_cls: 1.4111  decode.d2.loss_mask: 0.8581  decode.d2.loss_dice: 1.5728  decode.d3.loss_cls: 1.3356  decode.d3.loss_mask: 0.8451  decode.d3.loss_dice: 1.6084  decode.d4.loss_cls: 1.3937  decode.d4.loss_mask: 0.8536  decode.d4.loss_dice: 1.5509  decode.d5.loss_cls: 1.3581  decode.d5.loss_mask: 0.8685  decode.d5.loss_dice: 1.5394  decode.d6.loss_cls: 1.2538  decode.d6.loss_mask: 0.9054  decode.d6.loss_dice: 1.5401  decode.d7.loss_cls: 1.2177  decode.d7.loss_mask: 0.9105  decode.d7.loss_dice: 1.5191  decode.d8.loss_cls: 1.3222  decode.d8.loss_mask: 0.8778  decode.d8.loss_dice: 1.5229
2023/05/24 11:02:44 - mmengine - INFO - Iter(train) [135200/160000]  lr: 1.8677e-06  eta: 2:59:03  time: 0.4268  data_time: 0.0097  memory: 4847  grad_norm: 134.1459  loss: 32.9174  decode.loss_cls: 1.1724  decode.loss_mask: 0.7762  decode.loss_dice: 1.0814  decode.d0.loss_cls: 3.0336  decode.d0.loss_mask: 0.8219  decode.d0.loss_dice: 1.2697  decode.d1.loss_cls: 1.3506  decode.d1.loss_mask: 0.7947  decode.d1.loss_dice: 1.1824  decode.d2.loss_cls: 1.2802  decode.d2.loss_mask: 0.8370  decode.d2.loss_dice: 1.1431  decode.d3.loss_cls: 1.2134  decode.d3.loss_mask: 0.7547  decode.d3.loss_dice: 1.0996  decode.d4.loss_cls: 1.2062  decode.d4.loss_mask: 0.7696  decode.d4.loss_dice: 1.0843  decode.d5.loss_cls: 1.1585  decode.d5.loss_mask: 0.7712  decode.d5.loss_dice: 1.0743  decode.d6.loss_cls: 1.1649  decode.d6.loss_mask: 0.7806  decode.d6.loss_dice: 1.0621  decode.d7.loss_cls: 1.1509  decode.d7.loss_mask: 0.7894  decode.d7.loss_dice: 1.0848  decode.d8.loss_cls: 1.1387  decode.d8.loss_mask: 0.7762  decode.d8.loss_dice: 1.0949
2023/05/24 11:03:05 - mmengine - INFO - Iter(train) [135250/160000]  lr: 1.8643e-06  eta: 2:58:41  time: 0.4287  data_time: 0.0103  memory: 4867  grad_norm: 91.2408  loss: 30.2736  decode.loss_cls: 0.9039  decode.loss_mask: 0.7684  decode.loss_dice: 1.1221  decode.d0.loss_cls: 2.8670  decode.d0.loss_mask: 0.8383  decode.d0.loss_dice: 1.2126  decode.d1.loss_cls: 0.9626  decode.d1.loss_mask: 0.7747  decode.d1.loss_dice: 1.1645  decode.d2.loss_cls: 0.9232  decode.d2.loss_mask: 0.7672  decode.d2.loss_dice: 1.1523  decode.d3.loss_cls: 0.9830  decode.d3.loss_mask: 0.7748  decode.d3.loss_dice: 1.1063  decode.d4.loss_cls: 0.9044  decode.d4.loss_mask: 0.7842  decode.d4.loss_dice: 1.1328  decode.d5.loss_cls: 0.8581  decode.d5.loss_mask: 0.7714  decode.d5.loss_dice: 1.1310  decode.d6.loss_cls: 0.9081  decode.d6.loss_mask: 0.7685  decode.d6.loss_dice: 1.1094  decode.d7.loss_cls: 0.8960  decode.d7.loss_mask: 0.7630  decode.d7.loss_dice: 1.1373  decode.d8.loss_cls: 0.9338  decode.d8.loss_mask: 0.7468  decode.d8.loss_dice: 1.1081
2023/05/24 11:03:27 - mmengine - INFO - Iter(train) [135300/160000]  lr: 1.8609e-06  eta: 2:58:19  time: 0.4748  data_time: 0.0099  memory: 4889  grad_norm: 96.5565  loss: 37.4802  decode.loss_cls: 1.1626  decode.loss_mask: 0.7579  decode.loss_dice: 1.5420  decode.d0.loss_cls: 3.1395  decode.d0.loss_mask: 0.8135  decode.d0.loss_dice: 1.7730  decode.d1.loss_cls: 1.2800  decode.d1.loss_mask: 0.7528  decode.d1.loss_dice: 1.6244  decode.d2.loss_cls: 1.3097  decode.d2.loss_mask: 0.7396  decode.d2.loss_dice: 1.5728  decode.d3.loss_cls: 1.1482  decode.d3.loss_mask: 0.7877  decode.d3.loss_dice: 1.6235  decode.d4.loss_cls: 1.2265  decode.d4.loss_mask: 0.7725  decode.d4.loss_dice: 1.5333  decode.d5.loss_cls: 1.1971  decode.d5.loss_mask: 0.7573  decode.d5.loss_dice: 1.5438  decode.d6.loss_cls: 1.1851  decode.d6.loss_mask: 0.7706  decode.d6.loss_dice: 1.5388  decode.d7.loss_cls: 1.1355  decode.d7.loss_mask: 0.7984  decode.d7.loss_dice: 1.5844  decode.d8.loss_cls: 1.1096  decode.d8.loss_mask: 0.7782  decode.d8.loss_dice: 1.5219
2023/05/24 11:03:51 - mmengine - INFO - Iter(train) [135350/160000]  lr: 1.8575e-06  eta: 2:57:58  time: 0.4730  data_time: 0.0101  memory: 4894  grad_norm: 86.1323  loss: 41.7868  decode.loss_cls: 1.2720  decode.loss_mask: 0.9269  decode.loss_dice: 1.7233  decode.d0.loss_cls: 3.0653  decode.d0.loss_mask: 0.9274  decode.d0.loss_dice: 1.9889  decode.d1.loss_cls: 1.4175  decode.d1.loss_mask: 0.9107  decode.d1.loss_dice: 1.8510  decode.d2.loss_cls: 1.4055  decode.d2.loss_mask: 0.9164  decode.d2.loss_dice: 1.7959  decode.d3.loss_cls: 1.3820  decode.d3.loss_mask: 0.8899  decode.d3.loss_dice: 1.6924  decode.d4.loss_cls: 1.3616  decode.d4.loss_mask: 0.8842  decode.d4.loss_dice: 1.7069  decode.d5.loss_cls: 1.3676  decode.d5.loss_mask: 0.8714  decode.d5.loss_dice: 1.6829  decode.d6.loss_cls: 1.3594  decode.d6.loss_mask: 0.8810  decode.d6.loss_dice: 1.6650  decode.d7.loss_cls: 1.2838  decode.d7.loss_mask: 0.9040  decode.d7.loss_dice: 1.6973  decode.d8.loss_cls: 1.3062  decode.d8.loss_mask: 0.9331  decode.d8.loss_dice: 1.7170
2023/05/24 11:04:13 - mmengine - INFO - Iter(train) [135400/160000]  lr: 1.8541e-06  eta: 2:57:37  time: 0.4235  data_time: 0.0097  memory: 4884  grad_norm: 84.3220  loss: 37.0430  decode.loss_cls: 1.2189  decode.loss_mask: 0.7096  decode.loss_dice: 1.5621  decode.d0.loss_cls: 3.0013  decode.d0.loss_mask: 0.7228  decode.d0.loss_dice: 1.7454  decode.d1.loss_cls: 1.2690  decode.d1.loss_mask: 0.7177  decode.d1.loss_dice: 1.6510  decode.d2.loss_cls: 1.2473  decode.d2.loss_mask: 0.7280  decode.d2.loss_dice: 1.6416  decode.d3.loss_cls: 1.2247  decode.d3.loss_mask: 0.7192  decode.d3.loss_dice: 1.6130  decode.d4.loss_cls: 1.1282  decode.d4.loss_mask: 0.7166  decode.d4.loss_dice: 1.6018  decode.d5.loss_cls: 1.1673  decode.d5.loss_mask: 0.7247  decode.d5.loss_dice: 1.5636  decode.d6.loss_cls: 1.1725  decode.d6.loss_mask: 0.7104  decode.d6.loss_dice: 1.5613  decode.d7.loss_cls: 1.1412  decode.d7.loss_mask: 0.7083  decode.d7.loss_dice: 1.5736  decode.d8.loss_cls: 1.1695  decode.d8.loss_mask: 0.7276  decode.d8.loss_dice: 1.6045
2023/05/24 11:04:34 - mmengine - INFO - Iter(train) [135450/160000]  lr: 1.8507e-06  eta: 2:57:15  time: 0.4266  data_time: 0.0102  memory: 4844  grad_norm: 100.4543  loss: 29.2312  decode.loss_cls: 1.0662  decode.loss_mask: 0.6832  decode.loss_dice: 0.8406  decode.d0.loss_cls: 2.9740  decode.d0.loss_mask: 0.7164  decode.d0.loss_dice: 1.0337  decode.d1.loss_cls: 1.2918  decode.d1.loss_mask: 0.6771  decode.d1.loss_dice: 0.9667  decode.d2.loss_cls: 1.3015  decode.d2.loss_mask: 0.6902  decode.d2.loss_dice: 0.8981  decode.d3.loss_cls: 1.1772  decode.d3.loss_mask: 0.7065  decode.d3.loss_dice: 0.8776  decode.d4.loss_cls: 1.1399  decode.d4.loss_mask: 0.6947  decode.d4.loss_dice: 0.8636  decode.d5.loss_cls: 1.1154  decode.d5.loss_mask: 0.6825  decode.d5.loss_dice: 0.8587  decode.d6.loss_cls: 1.1548  decode.d6.loss_mask: 0.6943  decode.d6.loss_dice: 0.8626  decode.d7.loss_cls: 1.1058  decode.d7.loss_mask: 0.7097  decode.d7.loss_dice: 0.8386  decode.d8.loss_cls: 1.0896  decode.d8.loss_mask: 0.6907  decode.d8.loss_dice: 0.8295
2023/05/24 11:04:56 - mmengine - INFO - Iter(train) [135500/160000]  lr: 1.8473e-06  eta: 2:56:53  time: 0.4351  data_time: 0.0102  memory: 4837  grad_norm: 93.0101  loss: 30.5015  decode.loss_cls: 1.3236  decode.loss_mask: 0.5908  decode.loss_dice: 0.9085  decode.d0.loss_cls: 3.0756  decode.d0.loss_mask: 0.6546  decode.d0.loss_dice: 1.0985  decode.d1.loss_cls: 1.4444  decode.d1.loss_mask: 0.6509  decode.d1.loss_dice: 0.9270  decode.d2.loss_cls: 1.3764  decode.d2.loss_mask: 0.6646  decode.d2.loss_dice: 0.9364  decode.d3.loss_cls: 1.3998  decode.d3.loss_mask: 0.6167  decode.d3.loss_dice: 0.9285  decode.d4.loss_cls: 1.3082  decode.d4.loss_mask: 0.6035  decode.d4.loss_dice: 0.9277  decode.d5.loss_cls: 1.2907  decode.d5.loss_mask: 0.5993  decode.d5.loss_dice: 0.8994  decode.d6.loss_cls: 1.2914  decode.d6.loss_mask: 0.5927  decode.d6.loss_dice: 0.8807  decode.d7.loss_cls: 1.2724  decode.d7.loss_mask: 0.6008  decode.d7.loss_dice: 0.8826  decode.d8.loss_cls: 1.2612  decode.d8.loss_mask: 0.5968  decode.d8.loss_dice: 0.8977
2023/05/24 11:05:17 - mmengine - INFO - Iter(train) [135550/160000]  lr: 1.8439e-06  eta: 2:56:31  time: 0.4280  data_time: 0.0099  memory: 4864  grad_norm: 84.2838  loss: 30.6527  decode.loss_cls: 0.9969  decode.loss_mask: 0.7607  decode.loss_dice: 1.0276  decode.d0.loss_cls: 3.0376  decode.d0.loss_mask: 0.7658  decode.d0.loss_dice: 1.2222  decode.d1.loss_cls: 1.0764  decode.d1.loss_mask: 0.8327  decode.d1.loss_dice: 1.1383  decode.d2.loss_cls: 1.1238  decode.d2.loss_mask: 0.8004  decode.d2.loss_dice: 1.0436  decode.d3.loss_cls: 1.0242  decode.d3.loss_mask: 0.7939  decode.d3.loss_dice: 1.0551  decode.d4.loss_cls: 0.9910  decode.d4.loss_mask: 0.7633  decode.d4.loss_dice: 1.0650  decode.d5.loss_cls: 0.9897  decode.d5.loss_mask: 0.8045  decode.d5.loss_dice: 0.9815  decode.d6.loss_cls: 0.9533  decode.d6.loss_mask: 0.7787  decode.d6.loss_dice: 1.0558  decode.d7.loss_cls: 0.9624  decode.d7.loss_mask: 0.7742  decode.d7.loss_dice: 1.0629  decode.d8.loss_cls: 0.9938  decode.d8.loss_mask: 0.7523  decode.d8.loss_dice: 1.0250
2023/05/24 11:05:38 - mmengine - INFO - Iter(train) [135600/160000]  lr: 1.8405e-06  eta: 2:56:10  time: 0.4328  data_time: 0.0098  memory: 4841  grad_norm: 87.8562  loss: 34.9521  decode.loss_cls: 1.1022  decode.loss_mask: 0.7052  decode.loss_dice: 1.3504  decode.d0.loss_cls: 3.0400  decode.d0.loss_mask: 0.7367  decode.d0.loss_dice: 1.6454  decode.d1.loss_cls: 1.3154  decode.d1.loss_mask: 0.7247  decode.d1.loss_dice: 1.5217  decode.d2.loss_cls: 1.1794  decode.d2.loss_mask: 0.7351  decode.d2.loss_dice: 1.4719  decode.d3.loss_cls: 1.1283  decode.d3.loss_mask: 0.7592  decode.d3.loss_dice: 1.4178  decode.d4.loss_cls: 1.0559  decode.d4.loss_mask: 0.7392  decode.d4.loss_dice: 1.4018  decode.d5.loss_cls: 1.1312  decode.d5.loss_mask: 0.7194  decode.d5.loss_dice: 1.3900  decode.d6.loss_cls: 1.1377  decode.d6.loss_mask: 0.7370  decode.d6.loss_dice: 1.4030  decode.d7.loss_cls: 1.1068  decode.d7.loss_mask: 0.7289  decode.d7.loss_dice: 1.3902  decode.d8.loss_cls: 1.0792  decode.d8.loss_mask: 0.7200  decode.d8.loss_dice: 1.3785
2023/05/24 11:06:00 - mmengine - INFO - Iter(train) [135650/160000]  lr: 1.8371e-06  eta: 2:55:48  time: 0.4315  data_time: 0.0103  memory: 4885  grad_norm: 103.3884  loss: 40.2476  decode.loss_cls: 1.2024  decode.loss_mask: 0.8444  decode.loss_dice: 1.5687  decode.d0.loss_cls: 3.2285  decode.d0.loss_mask: 0.9605  decode.d0.loss_dice: 1.9017  decode.d1.loss_cls: 1.5155  decode.d1.loss_mask: 0.8665  decode.d1.loss_dice: 1.7393  decode.d2.loss_cls: 1.3738  decode.d2.loss_mask: 0.8758  decode.d2.loss_dice: 1.6816  decode.d3.loss_cls: 1.3976  decode.d3.loss_mask: 0.8333  decode.d3.loss_dice: 1.6347  decode.d4.loss_cls: 1.3528  decode.d4.loss_mask: 0.8393  decode.d4.loss_dice: 1.5764  decode.d5.loss_cls: 1.2941  decode.d5.loss_mask: 0.8534  decode.d5.loss_dice: 1.5785  decode.d6.loss_cls: 1.2978  decode.d6.loss_mask: 0.8527  decode.d6.loss_dice: 1.5513  decode.d7.loss_cls: 1.2837  decode.d7.loss_mask: 0.8490  decode.d7.loss_dice: 1.5857  decode.d8.loss_cls: 1.2606  decode.d8.loss_mask: 0.8635  decode.d8.loss_dice: 1.5843
2023/05/24 11:06:21 - mmengine - INFO - Iter(train) [135700/160000]  lr: 1.8337e-06  eta: 2:55:26  time: 0.4218  data_time: 0.0105  memory: 4823  grad_norm: 97.3767  loss: 33.5117  decode.loss_cls: 1.0638  decode.loss_mask: 0.8333  decode.loss_dice: 1.1688  decode.d0.loss_cls: 3.1142  decode.d0.loss_mask: 0.8004  decode.d0.loss_dice: 1.3424  decode.d1.loss_cls: 1.1984  decode.d1.loss_mask: 0.8909  decode.d1.loss_dice: 1.2811  decode.d2.loss_cls: 1.0561  decode.d2.loss_mask: 0.9052  decode.d2.loss_dice: 1.2393  decode.d3.loss_cls: 1.1341  decode.d3.loss_mask: 0.8181  decode.d3.loss_dice: 1.2054  decode.d4.loss_cls: 1.1008  decode.d4.loss_mask: 0.8269  decode.d4.loss_dice: 1.1594  decode.d5.loss_cls: 1.0916  decode.d5.loss_mask: 0.8225  decode.d5.loss_dice: 1.1964  decode.d6.loss_cls: 1.0888  decode.d6.loss_mask: 0.8347  decode.d6.loss_dice: 1.1927  decode.d7.loss_cls: 1.0500  decode.d7.loss_mask: 0.8447  decode.d7.loss_dice: 1.1547  decode.d8.loss_cls: 1.0852  decode.d8.loss_mask: 0.8328  decode.d8.loss_dice: 1.1790
2023/05/24 11:06:45 - mmengine - INFO - Iter(train) [135750/160000]  lr: 1.8304e-06  eta: 2:55:05  time: 0.4797  data_time: 0.0096  memory: 4845  grad_norm: 105.1114  loss: 36.9876  decode.loss_cls: 1.2683  decode.loss_mask: 0.7846  decode.loss_dice: 1.3963  decode.d0.loss_cls: 3.0217  decode.d0.loss_mask: 0.7752  decode.d0.loss_dice: 1.6002  decode.d1.loss_cls: 1.4186  decode.d1.loss_mask: 0.8547  decode.d1.loss_dice: 1.5083  decode.d2.loss_cls: 1.2882  decode.d2.loss_mask: 0.8264  decode.d2.loss_dice: 1.5153  decode.d3.loss_cls: 1.2554  decode.d3.loss_mask: 0.8049  decode.d3.loss_dice: 1.4107  decode.d4.loss_cls: 1.2804  decode.d4.loss_mask: 0.7968  decode.d4.loss_dice: 1.4044  decode.d5.loss_cls: 1.2559  decode.d5.loss_mask: 0.7886  decode.d5.loss_dice: 1.4018  decode.d6.loss_cls: 1.2785  decode.d6.loss_mask: 0.7908  decode.d6.loss_dice: 1.3783  decode.d7.loss_cls: 1.2753  decode.d7.loss_mask: 0.7926  decode.d7.loss_dice: 1.3994  decode.d8.loss_cls: 1.2548  decode.d8.loss_mask: 0.7764  decode.d8.loss_dice: 1.3847
2023/05/24 11:07:06 - mmengine - INFO - Iter(train) [135800/160000]  lr: 1.8270e-06  eta: 2:54:43  time: 0.4279  data_time: 0.0099  memory: 4857  grad_norm: 136.3706  loss: 31.5405  decode.loss_cls: 1.0274  decode.loss_mask: 0.7383  decode.loss_dice: 1.1307  decode.d0.loss_cls: 2.8522  decode.d0.loss_mask: 0.8448  decode.d0.loss_dice: 1.3569  decode.d1.loss_cls: 1.0790  decode.d1.loss_mask: 0.8044  decode.d1.loss_dice: 1.2998  decode.d2.loss_cls: 1.0243  decode.d2.loss_mask: 0.7788  decode.d2.loss_dice: 1.2451  decode.d3.loss_cls: 0.9917  decode.d3.loss_mask: 0.7759  decode.d3.loss_dice: 1.1812  decode.d4.loss_cls: 0.9887  decode.d4.loss_mask: 0.7804  decode.d4.loss_dice: 1.1954  decode.d5.loss_cls: 0.9631  decode.d5.loss_mask: 0.7475  decode.d5.loss_dice: 1.1670  decode.d6.loss_cls: 0.9698  decode.d6.loss_mask: 0.7377  decode.d6.loss_dice: 1.1450  decode.d7.loss_cls: 0.9433  decode.d7.loss_mask: 0.7365  decode.d7.loss_dice: 1.1417  decode.d8.loss_cls: 1.0108  decode.d8.loss_mask: 0.7405  decode.d8.loss_dice: 1.1424
2023/05/24 11:07:27 - mmengine - INFO - Iter(train) [135850/160000]  lr: 1.8236e-06  eta: 2:54:22  time: 0.4305  data_time: 0.0098  memory: 4869  grad_norm: 90.3775  loss: 39.3438  decode.loss_cls: 1.5830  decode.loss_mask: 0.7783  decode.loss_dice: 1.2636  decode.d0.loss_cls: 3.4456  decode.d0.loss_mask: 0.9413  decode.d0.loss_dice: 1.5233  decode.d1.loss_cls: 1.6281  decode.d1.loss_mask: 0.8316  decode.d1.loss_dice: 1.4819  decode.d2.loss_cls: 1.4760  decode.d2.loss_mask: 0.8580  decode.d2.loss_dice: 1.4073  decode.d3.loss_cls: 1.6258  decode.d3.loss_mask: 0.8107  decode.d3.loss_dice: 1.3224  decode.d4.loss_cls: 1.5822  decode.d4.loss_mask: 0.8128  decode.d4.loss_dice: 1.3309  decode.d5.loss_cls: 1.5800  decode.d5.loss_mask: 0.7791  decode.d5.loss_dice: 1.2881  decode.d6.loss_cls: 1.5946  decode.d6.loss_mask: 0.7784  decode.d6.loss_dice: 1.3085  decode.d7.loss_cls: 1.5733  decode.d7.loss_mask: 0.7704  decode.d7.loss_dice: 1.3042  decode.d8.loss_cls: 1.5599  decode.d8.loss_mask: 0.7936  decode.d8.loss_dice: 1.3111
2023/05/24 11:07:49 - mmengine - INFO - Iter(train) [135900/160000]  lr: 1.8202e-06  eta: 2:54:00  time: 0.4262  data_time: 0.0102  memory: 4845  grad_norm: 90.3364  loss: 29.1195  decode.loss_cls: 0.9672  decode.loss_mask: 0.6523  decode.loss_dice: 0.9804  decode.d0.loss_cls: 2.9632  decode.d0.loss_mask: 0.7245  decode.d0.loss_dice: 1.1835  decode.d1.loss_cls: 1.1821  decode.d1.loss_mask: 0.7059  decode.d1.loss_dice: 1.0901  decode.d2.loss_cls: 1.0446  decode.d2.loss_mask: 0.6818  decode.d2.loss_dice: 1.0254  decode.d3.loss_cls: 1.0617  decode.d3.loss_mask: 0.6647  decode.d3.loss_dice: 0.9927  decode.d4.loss_cls: 1.0030  decode.d4.loss_mask: 0.6725  decode.d4.loss_dice: 0.9939  decode.d5.loss_cls: 1.0012  decode.d5.loss_mask: 0.6696  decode.d5.loss_dice: 0.9849  decode.d6.loss_cls: 0.9994  decode.d6.loss_mask: 0.6622  decode.d6.loss_dice: 0.9665  decode.d7.loss_cls: 0.9855  decode.d7.loss_mask: 0.6564  decode.d7.loss_dice: 0.9826  decode.d8.loss_cls: 1.0032  decode.d8.loss_mask: 0.6516  decode.d8.loss_dice: 0.9667
2023/05/24 11:08:10 - mmengine - INFO - Iter(train) [135950/160000]  lr: 1.8168e-06  eta: 2:53:38  time: 0.4207  data_time: 0.0099  memory: 4837  grad_norm: 102.5556  loss: 37.8341  decode.loss_cls: 1.3360  decode.loss_mask: 0.7274  decode.loss_dice: 1.3839  decode.d0.loss_cls: 3.2785  decode.d0.loss_mask: 0.7931  decode.d0.loss_dice: 1.5779  decode.d1.loss_cls: 1.5957  decode.d1.loss_mask: 0.8817  decode.d1.loss_dice: 1.5544  decode.d2.loss_cls: 1.4934  decode.d2.loss_mask: 0.7728  decode.d2.loss_dice: 1.4465  decode.d3.loss_cls: 1.3915  decode.d3.loss_mask: 0.7648  decode.d3.loss_dice: 1.4330  decode.d4.loss_cls: 1.4007  decode.d4.loss_mask: 0.7463  decode.d4.loss_dice: 1.4114  decode.d5.loss_cls: 1.3369  decode.d5.loss_mask: 0.7667  decode.d5.loss_dice: 1.4149  decode.d6.loss_cls: 1.3454  decode.d6.loss_mask: 0.7420  decode.d6.loss_dice: 1.4047  decode.d7.loss_cls: 1.3096  decode.d7.loss_mask: 0.7422  decode.d7.loss_dice: 1.3915  decode.d8.loss_cls: 1.2858  decode.d8.loss_mask: 0.7412  decode.d8.loss_dice: 1.3646
2023/05/24 11:08:31 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 11:08:31 - mmengine - INFO - Iter(train) [136000/160000]  lr: 1.8134e-06  eta: 2:53:16  time: 0.4191  data_time: 0.0102  memory: 4829  grad_norm: 95.3438  loss: 39.3261  decode.loss_cls: 1.3401  decode.loss_mask: 0.9130  decode.loss_dice: 1.3275  decode.d0.loss_cls: 3.2175  decode.d0.loss_mask: 1.0516  decode.d0.loss_dice: 1.6602  decode.d1.loss_cls: 1.5796  decode.d1.loss_mask: 0.9927  decode.d1.loss_dice: 1.4772  decode.d2.loss_cls: 1.4909  decode.d2.loss_mask: 0.9670  decode.d2.loss_dice: 1.3864  decode.d3.loss_cls: 1.4531  decode.d3.loss_mask: 0.9343  decode.d3.loss_dice: 1.3896  decode.d4.loss_cls: 1.3945  decode.d4.loss_mask: 0.9222  decode.d4.loss_dice: 1.3671  decode.d5.loss_cls: 1.4282  decode.d5.loss_mask: 0.8979  decode.d5.loss_dice: 1.3221  decode.d6.loss_cls: 1.3897  decode.d6.loss_mask: 0.8953  decode.d6.loss_dice: 1.3262  decode.d7.loss_cls: 1.4044  decode.d7.loss_mask: 0.8941  decode.d7.loss_dice: 1.3171  decode.d8.loss_cls: 1.3778  decode.d8.loss_mask: 0.8859  decode.d8.loss_dice: 1.3229
2023/05/24 11:08:31 - mmengine - INFO - Saving checkpoint at 136000 iterations
2023/05/24 11:09:00 - mmengine - INFO - Iter(train) [136050/160000]  lr: 1.8100e-06  eta: 2:52:56  time: 0.4772  data_time: 0.0101  memory: 4944  grad_norm: 116.2466  loss: 42.5479  decode.loss_cls: 1.6120  decode.loss_mask: 0.8434  decode.loss_dice: 1.3852  decode.d0.loss_cls: 3.7858  decode.d0.loss_mask: 0.9089  decode.d0.loss_dice: 1.7492  decode.d1.loss_cls: 1.6674  decode.d1.loss_mask: 1.0150  decode.d1.loss_dice: 1.5971  decode.d2.loss_cls: 1.7100  decode.d2.loss_mask: 0.9324  decode.d2.loss_dice: 1.5459  decode.d3.loss_cls: 1.6137  decode.d3.loss_mask: 0.9304  decode.d3.loss_dice: 1.5203  decode.d4.loss_cls: 1.5983  decode.d4.loss_mask: 0.9066  decode.d4.loss_dice: 1.4802  decode.d5.loss_cls: 1.6841  decode.d5.loss_mask: 0.8540  decode.d5.loss_dice: 1.4518  decode.d6.loss_cls: 1.6869  decode.d6.loss_mask: 0.8249  decode.d6.loss_dice: 1.4117  decode.d7.loss_cls: 1.6787  decode.d7.loss_mask: 0.8152  decode.d7.loss_dice: 1.4088  decode.d8.loss_cls: 1.6443  decode.d8.loss_mask: 0.8383  decode.d8.loss_dice: 1.4474
2023/05/24 11:09:23 - mmengine - INFO - Iter(train) [136100/160000]  lr: 1.8066e-06  eta: 2:52:34  time: 0.4273  data_time: 0.0104  memory: 4856  grad_norm: 87.2609  loss: 35.3633  decode.loss_cls: 1.2556  decode.loss_mask: 0.7241  decode.loss_dice: 1.1957  decode.d0.loss_cls: 3.3443  decode.d0.loss_mask: 0.8171  decode.d0.loss_dice: 1.4585  decode.d1.loss_cls: 1.5342  decode.d1.loss_mask: 0.6981  decode.d1.loss_dice: 1.3550  decode.d2.loss_cls: 1.3875  decode.d2.loss_mask: 0.6880  decode.d2.loss_dice: 1.2571  decode.d3.loss_cls: 1.3793  decode.d3.loss_mask: 0.7515  decode.d3.loss_dice: 1.2271  decode.d4.loss_cls: 1.3451  decode.d4.loss_mask: 0.7448  decode.d4.loss_dice: 1.2672  decode.d5.loss_cls: 1.2671  decode.d5.loss_mask: 0.7487  decode.d5.loss_dice: 1.2643  decode.d6.loss_cls: 1.2666  decode.d6.loss_mask: 0.7410  decode.d6.loss_dice: 1.2151  decode.d7.loss_cls: 1.2734  decode.d7.loss_mask: 0.7357  decode.d7.loss_dice: 1.2156  decode.d8.loss_cls: 1.2921  decode.d8.loss_mask: 0.7166  decode.d8.loss_dice: 1.1968
2023/05/24 11:09:43 - mmengine - INFO - Iter(train) [136150/160000]  lr: 1.8032e-06  eta: 2:52:13  time: 0.4230  data_time: 0.0106  memory: 4825  grad_norm: 94.5825  loss: 25.1297  decode.loss_cls: 0.9349  decode.loss_mask: 0.5487  decode.loss_dice: 0.7687  decode.d0.loss_cls: 2.7126  decode.d0.loss_mask: 0.5883  decode.d0.loss_dice: 0.8957  decode.d1.loss_cls: 1.0378  decode.d1.loss_mask: 0.6081  decode.d1.loss_dice: 0.8442  decode.d2.loss_cls: 1.0792  decode.d2.loss_mask: 0.5688  decode.d2.loss_dice: 0.7854  decode.d3.loss_cls: 1.0405  decode.d3.loss_mask: 0.5536  decode.d3.loss_dice: 0.7835  decode.d4.loss_cls: 0.9828  decode.d4.loss_mask: 0.5476  decode.d4.loss_dice: 0.7649  decode.d5.loss_cls: 0.9497  decode.d5.loss_mask: 0.5542  decode.d5.loss_dice: 0.7736  decode.d6.loss_cls: 0.9612  decode.d6.loss_mask: 0.5531  decode.d6.loss_dice: 0.7692  decode.d7.loss_cls: 0.9544  decode.d7.loss_mask: 0.5525  decode.d7.loss_dice: 0.7436  decode.d8.loss_cls: 0.9478  decode.d8.loss_mask: 0.5500  decode.d8.loss_dice: 0.7749
2023/05/24 11:10:05 - mmengine - INFO - Iter(train) [136200/160000]  lr: 1.7998e-06  eta: 2:51:51  time: 0.4326  data_time: 0.0099  memory: 4918  grad_norm: 88.9487  loss: 30.3676  decode.loss_cls: 0.8753  decode.loss_mask: 0.7852  decode.loss_dice: 1.1009  decode.d0.loss_cls: 2.8434  decode.d0.loss_mask: 0.7549  decode.d0.loss_dice: 1.2225  decode.d1.loss_cls: 0.9999  decode.d1.loss_mask: 0.7914  decode.d1.loss_dice: 1.2361  decode.d2.loss_cls: 0.9207  decode.d2.loss_mask: 0.8156  decode.d2.loss_dice: 1.1659  decode.d3.loss_cls: 0.9052  decode.d3.loss_mask: 0.8083  decode.d3.loss_dice: 1.1356  decode.d4.loss_cls: 0.9001  decode.d4.loss_mask: 0.7777  decode.d4.loss_dice: 1.1020  decode.d5.loss_cls: 0.9026  decode.d5.loss_mask: 0.8015  decode.d5.loss_dice: 1.1120  decode.d6.loss_cls: 0.9866  decode.d6.loss_mask: 0.7501  decode.d6.loss_dice: 1.0865  decode.d7.loss_cls: 0.9169  decode.d7.loss_mask: 0.7921  decode.d7.loss_dice: 1.0949  decode.d8.loss_cls: 0.9279  decode.d8.loss_mask: 0.7630  decode.d8.loss_dice: 1.0930
2023/05/24 11:10:26 - mmengine - INFO - Iter(train) [136250/160000]  lr: 1.7964e-06  eta: 2:51:29  time: 0.4342  data_time: 0.0102  memory: 4880  grad_norm: 94.6943  loss: 34.9472  decode.loss_cls: 1.2985  decode.loss_mask: 0.7263  decode.loss_dice: 1.1722  decode.d0.loss_cls: 3.2548  decode.d0.loss_mask: 0.7630  decode.d0.loss_dice: 1.4062  decode.d1.loss_cls: 1.3094  decode.d1.loss_mask: 0.7743  decode.d1.loss_dice: 1.3203  decode.d2.loss_cls: 1.3275  decode.d2.loss_mask: 0.7541  decode.d2.loss_dice: 1.2698  decode.d3.loss_cls: 1.3558  decode.d3.loss_mask: 0.7348  decode.d3.loss_dice: 1.2200  decode.d4.loss_cls: 1.3559  decode.d4.loss_mask: 0.7317  decode.d4.loss_dice: 1.1848  decode.d5.loss_cls: 1.3593  decode.d5.loss_mask: 0.7397  decode.d5.loss_dice: 1.2166  decode.d6.loss_cls: 1.3102  decode.d6.loss_mask: 0.7267  decode.d6.loss_dice: 1.1824  decode.d7.loss_cls: 1.3266  decode.d7.loss_mask: 0.7400  decode.d7.loss_dice: 1.1746  decode.d8.loss_cls: 1.2938  decode.d8.loss_mask: 0.7324  decode.d8.loss_dice: 1.1854
2023/05/24 11:10:48 - mmengine - INFO - Iter(train) [136300/160000]  lr: 1.7929e-06  eta: 2:51:08  time: 0.4293  data_time: 0.0101  memory: 4821  grad_norm: 121.4056  loss: 36.9817  decode.loss_cls: 1.4610  decode.loss_mask: 0.7916  decode.loss_dice: 1.1248  decode.d0.loss_cls: 3.3098  decode.d0.loss_mask: 0.9201  decode.d0.loss_dice: 1.3998  decode.d1.loss_cls: 1.5718  decode.d1.loss_mask: 0.8533  decode.d1.loss_dice: 1.3465  decode.d2.loss_cls: 1.6064  decode.d2.loss_mask: 0.7967  decode.d2.loss_dice: 1.2115  decode.d3.loss_cls: 1.5609  decode.d3.loss_mask: 0.7785  decode.d3.loss_dice: 1.1837  decode.d4.loss_cls: 1.5101  decode.d4.loss_mask: 0.7750  decode.d4.loss_dice: 1.1709  decode.d5.loss_cls: 1.4606  decode.d5.loss_mask: 0.7735  decode.d5.loss_dice: 1.1370  decode.d6.loss_cls: 1.4770  decode.d6.loss_mask: 0.7981  decode.d6.loss_dice: 1.1729  decode.d7.loss_cls: 1.4555  decode.d7.loss_mask: 0.7876  decode.d7.loss_dice: 1.1759  decode.d8.loss_cls: 1.4481  decode.d8.loss_mask: 0.7811  decode.d8.loss_dice: 1.1419
2023/05/24 11:11:09 - mmengine - INFO - Iter(train) [136350/160000]  lr: 1.7895e-06  eta: 2:50:46  time: 0.4217  data_time: 0.0097  memory: 4898  grad_norm: 101.0331  loss: 35.2481  decode.loss_cls: 1.3605  decode.loss_mask: 0.6975  decode.loss_dice: 1.1414  decode.d0.loss_cls: 3.4464  decode.d0.loss_mask: 0.8072  decode.d0.loss_dice: 1.4475  decode.d1.loss_cls: 1.5224  decode.d1.loss_mask: 0.7457  decode.d1.loss_dice: 1.3286  decode.d2.loss_cls: 1.4175  decode.d2.loss_mask: 0.7515  decode.d2.loss_dice: 1.2012  decode.d3.loss_cls: 1.3243  decode.d3.loss_mask: 0.7428  decode.d3.loss_dice: 1.2206  decode.d4.loss_cls: 1.2775  decode.d4.loss_mask: 0.7510  decode.d4.loss_dice: 1.2217  decode.d5.loss_cls: 1.2773  decode.d5.loss_mask: 0.7739  decode.d5.loss_dice: 1.1964  decode.d6.loss_cls: 1.3511  decode.d6.loss_mask: 0.7060  decode.d6.loss_dice: 1.1778  decode.d7.loss_cls: 1.3087  decode.d7.loss_mask: 0.7147  decode.d7.loss_dice: 1.1497  decode.d8.loss_cls: 1.3266  decode.d8.loss_mask: 0.7075  decode.d8.loss_dice: 1.1534
2023/05/24 11:11:31 - mmengine - INFO - Iter(train) [136400/160000]  lr: 1.7861e-06  eta: 2:50:24  time: 0.4351  data_time: 0.0101  memory: 4857  grad_norm: 108.4450  loss: 35.7260  decode.loss_cls: 1.2367  decode.loss_mask: 0.8321  decode.loss_dice: 1.2036  decode.d0.loss_cls: 3.3768  decode.d0.loss_mask: 0.8824  decode.d0.loss_dice: 1.4067  decode.d1.loss_cls: 1.3190  decode.d1.loss_mask: 0.9271  decode.d1.loss_dice: 1.3114  decode.d2.loss_cls: 1.3128  decode.d2.loss_mask: 0.8917  decode.d2.loss_dice: 1.2711  decode.d3.loss_cls: 1.2822  decode.d3.loss_mask: 0.8611  decode.d3.loss_dice: 1.2199  decode.d4.loss_cls: 1.3135  decode.d4.loss_mask: 0.8353  decode.d4.loss_dice: 1.2280  decode.d5.loss_cls: 1.2340  decode.d5.loss_mask: 0.8389  decode.d5.loss_dice: 1.2238  decode.d6.loss_cls: 1.1954  decode.d6.loss_mask: 0.8267  decode.d6.loss_dice: 1.2113  decode.d7.loss_cls: 1.2103  decode.d7.loss_mask: 0.8193  decode.d7.loss_dice: 1.2196  decode.d8.loss_cls: 1.2196  decode.d8.loss_mask: 0.8030  decode.d8.loss_dice: 1.2126
2023/05/24 11:11:53 - mmengine - INFO - Iter(train) [136450/160000]  lr: 1.7827e-06  eta: 2:50:03  time: 0.4272  data_time: 0.0100  memory: 4897  grad_norm: 118.0449  loss: 32.3005  decode.loss_cls: 1.1131  decode.loss_mask: 0.6448  decode.loss_dice: 1.1471  decode.d0.loss_cls: 3.0556  decode.d0.loss_mask: 0.7703  decode.d0.loss_dice: 1.4007  decode.d1.loss_cls: 1.3470  decode.d1.loss_mask: 0.7272  decode.d1.loss_dice: 1.2861  decode.d2.loss_cls: 1.1641  decode.d2.loss_mask: 0.6816  decode.d2.loss_dice: 1.2243  decode.d3.loss_cls: 1.1862  decode.d3.loss_mask: 0.6622  decode.d3.loss_dice: 1.1723  decode.d4.loss_cls: 1.1997  decode.d4.loss_mask: 0.6451  decode.d4.loss_dice: 1.1641  decode.d5.loss_cls: 1.1833  decode.d5.loss_mask: 0.6507  decode.d5.loss_dice: 1.2037  decode.d6.loss_cls: 1.0961  decode.d6.loss_mask: 0.6414  decode.d6.loss_dice: 1.1570  decode.d7.loss_cls: 1.0958  decode.d7.loss_mask: 0.6444  decode.d7.loss_dice: 1.1510  decode.d8.loss_cls: 1.1064  decode.d8.loss_mask: 0.6466  decode.d8.loss_dice: 1.1325
2023/05/24 11:12:14 - mmengine - INFO - Iter(train) [136500/160000]  lr: 1.7793e-06  eta: 2:49:41  time: 0.4300  data_time: 0.0103  memory: 4851  grad_norm: 95.3799  loss: 31.3389  decode.loss_cls: 0.9134  decode.loss_mask: 0.6731  decode.loss_dice: 1.2333  decode.d0.loss_cls: 2.7847  decode.d0.loss_mask: 0.6940  decode.d0.loss_dice: 1.4553  decode.d1.loss_cls: 1.0584  decode.d1.loss_mask: 0.7341  decode.d1.loss_dice: 1.3891  decode.d2.loss_cls: 1.0188  decode.d2.loss_mask: 0.6925  decode.d2.loss_dice: 1.2445  decode.d3.loss_cls: 1.0431  decode.d3.loss_mask: 0.6719  decode.d3.loss_dice: 1.2701  decode.d4.loss_cls: 0.9990  decode.d4.loss_mask: 0.6623  decode.d4.loss_dice: 1.2508  decode.d5.loss_cls: 0.9881  decode.d5.loss_mask: 0.6690  decode.d5.loss_dice: 1.2456  decode.d6.loss_cls: 0.9712  decode.d6.loss_mask: 0.6753  decode.d6.loss_dice: 1.2386  decode.d7.loss_cls: 0.9670  decode.d7.loss_mask: 0.6720  decode.d7.loss_dice: 1.2371  decode.d8.loss_cls: 0.9973  decode.d8.loss_mask: 0.6746  decode.d8.loss_dice: 1.2146
2023/05/24 11:12:37 - mmengine - INFO - Iter(train) [136550/160000]  lr: 1.7759e-06  eta: 2:49:19  time: 0.4170  data_time: 0.0097  memory: 4878  grad_norm: 113.3828  loss: 31.9090  decode.loss_cls: 0.9688  decode.loss_mask: 0.7405  decode.loss_dice: 1.2182  decode.d0.loss_cls: 2.9005  decode.d0.loss_mask: 0.7187  decode.d0.loss_dice: 1.4516  decode.d1.loss_cls: 1.1126  decode.d1.loss_mask: 0.7364  decode.d1.loss_dice: 1.3138  decode.d2.loss_cls: 1.0965  decode.d2.loss_mask: 0.7407  decode.d2.loss_dice: 1.2427  decode.d3.loss_cls: 1.0109  decode.d3.loss_mask: 0.7202  decode.d3.loss_dice: 1.2561  decode.d4.loss_cls: 0.9947  decode.d4.loss_mask: 0.7204  decode.d4.loss_dice: 1.2635  decode.d5.loss_cls: 0.9510  decode.d5.loss_mask: 0.7446  decode.d5.loss_dice: 1.2267  decode.d6.loss_cls: 0.9670  decode.d6.loss_mask: 0.7468  decode.d6.loss_dice: 1.2290  decode.d7.loss_cls: 0.9290  decode.d7.loss_mask: 0.7451  decode.d7.loss_dice: 1.2531  decode.d8.loss_cls: 0.9458  decode.d8.loss_mask: 0.7359  decode.d8.loss_dice: 1.2283
2023/05/24 11:12:59 - mmengine - INFO - Iter(train) [136600/160000]  lr: 1.7725e-06  eta: 2:48:58  time: 0.4374  data_time: 0.0099  memory: 4790  grad_norm: 92.5266  loss: 31.9599  decode.loss_cls: 1.0467  decode.loss_mask: 0.6930  decode.loss_dice: 1.2091  decode.d0.loss_cls: 2.7126  decode.d0.loss_mask: 0.7214  decode.d0.loss_dice: 1.3536  decode.d1.loss_cls: 1.1289  decode.d1.loss_mask: 0.7195  decode.d1.loss_dice: 1.3153  decode.d2.loss_cls: 1.1115  decode.d2.loss_mask: 0.7147  decode.d2.loss_dice: 1.2864  decode.d3.loss_cls: 1.1544  decode.d3.loss_mask: 0.6769  decode.d3.loss_dice: 1.2117  decode.d4.loss_cls: 1.0706  decode.d4.loss_mask: 0.6724  decode.d4.loss_dice: 1.2330  decode.d5.loss_cls: 1.0909  decode.d5.loss_mask: 0.6857  decode.d5.loss_dice: 1.2099  decode.d6.loss_cls: 1.0616  decode.d6.loss_mask: 0.6919  decode.d6.loss_dice: 1.2303  decode.d7.loss_cls: 1.0836  decode.d7.loss_mask: 0.6914  decode.d7.loss_dice: 1.2184  decode.d8.loss_cls: 1.0658  decode.d8.loss_mask: 0.6881  decode.d8.loss_dice: 1.2107
2023/05/24 11:13:20 - mmengine - INFO - Iter(train) [136650/160000]  lr: 1.7691e-06  eta: 2:48:36  time: 0.4284  data_time: 0.0100  memory: 4859  grad_norm: 92.4080  loss: 35.5238  decode.loss_cls: 1.3320  decode.loss_mask: 0.7066  decode.loss_dice: 1.1632  decode.d0.loss_cls: 3.3031  decode.d0.loss_mask: 0.7578  decode.d0.loss_dice: 1.3316  decode.d1.loss_cls: 1.7110  decode.d1.loss_mask: 0.7766  decode.d1.loss_dice: 1.2881  decode.d2.loss_cls: 1.4907  decode.d2.loss_mask: 0.8299  decode.d2.loss_dice: 1.2497  decode.d3.loss_cls: 1.4314  decode.d3.loss_mask: 0.7362  decode.d3.loss_dice: 1.1769  decode.d4.loss_cls: 1.4107  decode.d4.loss_mask: 0.7104  decode.d4.loss_dice: 1.1618  decode.d5.loss_cls: 1.4088  decode.d5.loss_mask: 0.6972  decode.d5.loss_dice: 1.1571  decode.d6.loss_cls: 1.3781  decode.d6.loss_mask: 0.7165  decode.d6.loss_dice: 1.1562  decode.d7.loss_cls: 1.3407  decode.d7.loss_mask: 0.7162  decode.d7.loss_dice: 1.1994  decode.d8.loss_cls: 1.3207  decode.d8.loss_mask: 0.7197  decode.d8.loss_dice: 1.1454
2023/05/24 11:13:42 - mmengine - INFO - Iter(train) [136700/160000]  lr: 1.7657e-06  eta: 2:48:14  time: 0.4290  data_time: 0.0099  memory: 4856  grad_norm: 106.4153  loss: 40.6893  decode.loss_cls: 1.3244  decode.loss_mask: 1.0293  decode.loss_dice: 1.4323  decode.d0.loss_cls: 3.2396  decode.d0.loss_mask: 1.1309  decode.d0.loss_dice: 1.6958  decode.d1.loss_cls: 1.4724  decode.d1.loss_mask: 1.0935  decode.d1.loss_dice: 1.5012  decode.d2.loss_cls: 1.3931  decode.d2.loss_mask: 1.0896  decode.d2.loss_dice: 1.5138  decode.d3.loss_cls: 1.3481  decode.d3.loss_mask: 1.0548  decode.d3.loss_dice: 1.4457  decode.d4.loss_cls: 1.3847  decode.d4.loss_mask: 1.0580  decode.d4.loss_dice: 1.4269  decode.d5.loss_cls: 1.3673  decode.d5.loss_mask: 1.0428  decode.d5.loss_dice: 1.4437  decode.d6.loss_cls: 1.3238  decode.d6.loss_mask: 1.0218  decode.d6.loss_dice: 1.3932  decode.d7.loss_cls: 1.2952  decode.d7.loss_mask: 1.0166  decode.d7.loss_dice: 1.3994  decode.d8.loss_cls: 1.3325  decode.d8.loss_mask: 1.0225  decode.d8.loss_dice: 1.3968
2023/05/24 11:14:04 - mmengine - INFO - Iter(train) [136750/160000]  lr: 1.7623e-06  eta: 2:47:53  time: 0.4307  data_time: 0.0099  memory: 4850  grad_norm: 113.9287  loss: 28.1218  decode.loss_cls: 1.0191  decode.loss_mask: 0.5640  decode.loss_dice: 0.9387  decode.d0.loss_cls: 2.8781  decode.d0.loss_mask: 0.6670  decode.d0.loss_dice: 1.1034  decode.d1.loss_cls: 1.2367  decode.d1.loss_mask: 0.6421  decode.d1.loss_dice: 1.0388  decode.d2.loss_cls: 1.1708  decode.d2.loss_mask: 0.6028  decode.d2.loss_dice: 0.9798  decode.d3.loss_cls: 1.0604  decode.d3.loss_mask: 0.5753  decode.d3.loss_dice: 0.9476  decode.d4.loss_cls: 1.0478  decode.d4.loss_mask: 0.5571  decode.d4.loss_dice: 0.9269  decode.d5.loss_cls: 1.0543  decode.d5.loss_mask: 0.5869  decode.d5.loss_dice: 0.9153  decode.d6.loss_cls: 1.0445  decode.d6.loss_mask: 0.5747  decode.d6.loss_dice: 0.9087  decode.d7.loss_cls: 1.0461  decode.d7.loss_mask: 0.5695  decode.d7.loss_dice: 0.9164  decode.d8.loss_cls: 1.0527  decode.d8.loss_mask: 0.5706  decode.d8.loss_dice: 0.9258
2023/05/24 11:14:25 - mmengine - INFO - Iter(train) [136800/160000]  lr: 1.7589e-06  eta: 2:47:31  time: 0.4419  data_time: 0.0099  memory: 4886  grad_norm: 92.7680  loss: 39.3446  decode.loss_cls: 1.1336  decode.loss_mask: 0.9165  decode.loss_dice: 1.5163  decode.d0.loss_cls: 3.1514  decode.d0.loss_mask: 1.0596  decode.d0.loss_dice: 1.7074  decode.d1.loss_cls: 1.2891  decode.d1.loss_mask: 1.0053  decode.d1.loss_dice: 1.6662  decode.d2.loss_cls: 1.2288  decode.d2.loss_mask: 0.9681  decode.d2.loss_dice: 1.5947  decode.d3.loss_cls: 1.2881  decode.d3.loss_mask: 0.9463  decode.d3.loss_dice: 1.5425  decode.d4.loss_cls: 1.2460  decode.d4.loss_mask: 0.9872  decode.d4.loss_dice: 1.5694  decode.d5.loss_cls: 1.1841  decode.d5.loss_mask: 0.9722  decode.d5.loss_dice: 1.5512  decode.d6.loss_cls: 1.1593  decode.d6.loss_mask: 0.9356  decode.d6.loss_dice: 1.5199  decode.d7.loss_cls: 1.1222  decode.d7.loss_mask: 0.9419  decode.d7.loss_dice: 1.5316  decode.d8.loss_cls: 1.1068  decode.d8.loss_mask: 0.9574  decode.d8.loss_dice: 1.5462
2023/05/24 11:14:47 - mmengine - INFO - Iter(train) [136850/160000]  lr: 1.7555e-06  eta: 2:47:09  time: 0.4258  data_time: 0.0097  memory: 4859  grad_norm: 90.9754  loss: 34.9226  decode.loss_cls: 1.1171  decode.loss_mask: 0.8366  decode.loss_dice: 1.2349  decode.d0.loss_cls: 3.1348  decode.d0.loss_mask: 0.9141  decode.d0.loss_dice: 1.4181  decode.d1.loss_cls: 1.3714  decode.d1.loss_mask: 0.8843  decode.d1.loss_dice: 1.3454  decode.d2.loss_cls: 1.2394  decode.d2.loss_mask: 0.8731  decode.d2.loss_dice: 1.2762  decode.d3.loss_cls: 1.1786  decode.d3.loss_mask: 0.8415  decode.d3.loss_dice: 1.2524  decode.d4.loss_cls: 1.1669  decode.d4.loss_mask: 0.8003  decode.d4.loss_dice: 1.2286  decode.d5.loss_cls: 1.1618  decode.d5.loss_mask: 0.8003  decode.d5.loss_dice: 1.2196  decode.d6.loss_cls: 1.1709  decode.d6.loss_mask: 0.8083  decode.d6.loss_dice: 1.2464  decode.d7.loss_cls: 1.1613  decode.d7.loss_mask: 0.7994  decode.d7.loss_dice: 1.2583  decode.d8.loss_cls: 1.1723  decode.d8.loss_mask: 0.7980  decode.d8.loss_dice: 1.2119
2023/05/24 11:15:08 - mmengine - INFO - Iter(train) [136900/160000]  lr: 1.7520e-06  eta: 2:46:48  time: 0.4249  data_time: 0.0099  memory: 4883  grad_norm: 101.5149  loss: 38.2170  decode.loss_cls: 1.0841  decode.loss_mask: 0.7986  decode.loss_dice: 1.6718  decode.d0.loss_cls: 3.1962  decode.d0.loss_mask: 0.8590  decode.d0.loss_dice: 1.9297  decode.d1.loss_cls: 1.1932  decode.d1.loss_mask: 0.8273  decode.d1.loss_dice: 1.7978  decode.d2.loss_cls: 1.1642  decode.d2.loss_mask: 0.7988  decode.d2.loss_dice: 1.6939  decode.d3.loss_cls: 1.0947  decode.d3.loss_mask: 0.7876  decode.d3.loss_dice: 1.6692  decode.d4.loss_cls: 1.0957  decode.d4.loss_mask: 0.7919  decode.d4.loss_dice: 1.6712  decode.d5.loss_cls: 1.0679  decode.d5.loss_mask: 0.7868  decode.d5.loss_dice: 1.6540  decode.d6.loss_cls: 1.0818  decode.d6.loss_mask: 0.7887  decode.d6.loss_dice: 1.6513  decode.d7.loss_cls: 1.0743  decode.d7.loss_mask: 0.7832  decode.d7.loss_dice: 1.6485  decode.d8.loss_cls: 1.1061  decode.d8.loss_mask: 0.7882  decode.d8.loss_dice: 1.6614
2023/05/24 11:15:29 - mmengine - INFO - Iter(train) [136950/160000]  lr: 1.7486e-06  eta: 2:46:26  time: 0.4341  data_time: 0.0100  memory: 4961  grad_norm: 83.1465  loss: 32.4508  decode.loss_cls: 1.0755  decode.loss_mask: 0.7391  decode.loss_dice: 1.0653  decode.d0.loss_cls: 3.3672  decode.d0.loss_mask: 0.8063  decode.d0.loss_dice: 1.2949  decode.d1.loss_cls: 1.2975  decode.d1.loss_mask: 0.8224  decode.d1.loss_dice: 1.1945  decode.d2.loss_cls: 1.1549  decode.d2.loss_mask: 0.8130  decode.d2.loss_dice: 1.1510  decode.d3.loss_cls: 1.1443  decode.d3.loss_mask: 0.7767  decode.d3.loss_dice: 1.1025  decode.d4.loss_cls: 1.1583  decode.d4.loss_mask: 0.7596  decode.d4.loss_dice: 1.1107  decode.d5.loss_cls: 1.1321  decode.d5.loss_mask: 0.7414  decode.d5.loss_dice: 1.0960  decode.d6.loss_cls: 1.1095  decode.d6.loss_mask: 0.7194  decode.d6.loss_dice: 1.0599  decode.d7.loss_cls: 1.0841  decode.d7.loss_mask: 0.7332  decode.d7.loss_dice: 1.0558  decode.d8.loss_cls: 1.0730  decode.d8.loss_mask: 0.7375  decode.d8.loss_dice: 1.0752
2023/05/24 11:15:51 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 11:15:51 - mmengine - INFO - Iter(train) [137000/160000]  lr: 1.7452e-06  eta: 2:46:04  time: 0.4541  data_time: 0.0103  memory: 4876  grad_norm: 127.2613  loss: 35.9735  decode.loss_cls: 1.1742  decode.loss_mask: 0.5134  decode.loss_dice: 1.5557  decode.d0.loss_cls: 3.3036  decode.d0.loss_mask: 0.6441  decode.d0.loss_dice: 1.8904  decode.d1.loss_cls: 1.3763  decode.d1.loss_mask: 0.5439  decode.d1.loss_dice: 1.6742  decode.d2.loss_cls: 1.2635  decode.d2.loss_mask: 0.5376  decode.d2.loss_dice: 1.6655  decode.d3.loss_cls: 1.2054  decode.d3.loss_mask: 0.5224  decode.d3.loss_dice: 1.5688  decode.d4.loss_cls: 1.1603  decode.d4.loss_mask: 0.5345  decode.d4.loss_dice: 1.6156  decode.d5.loss_cls: 1.2286  decode.d5.loss_mask: 0.5189  decode.d5.loss_dice: 1.6163  decode.d6.loss_cls: 1.1562  decode.d6.loss_mask: 0.5076  decode.d6.loss_dice: 1.5526  decode.d7.loss_cls: 1.2230  decode.d7.loss_mask: 0.5112  decode.d7.loss_dice: 1.6085  decode.d8.loss_cls: 1.1883  decode.d8.loss_mask: 0.5257  decode.d8.loss_dice: 1.5870
2023/05/24 11:15:51 - mmengine - INFO - Saving checkpoint at 137000 iterations
2023/05/24 11:16:19 - mmengine - INFO - Iter(train) [137050/160000]  lr: 1.7418e-06  eta: 2:45:44  time: 0.4344  data_time: 0.0102  memory: 4835  grad_norm: 86.9253  loss: 42.2253  decode.loss_cls: 1.3645  decode.loss_mask: 0.8566  decode.loss_dice: 1.6608  decode.d0.loss_cls: 3.4390  decode.d0.loss_mask: 0.9733  decode.d0.loss_dice: 1.9386  decode.d1.loss_cls: 1.4982  decode.d1.loss_mask: 0.9205  decode.d1.loss_dice: 1.7930  decode.d2.loss_cls: 1.4386  decode.d2.loss_mask: 0.9315  decode.d2.loss_dice: 1.7427  decode.d3.loss_cls: 1.4790  decode.d3.loss_mask: 0.8510  decode.d3.loss_dice: 1.6971  decode.d4.loss_cls: 1.3849  decode.d4.loss_mask: 0.8938  decode.d4.loss_dice: 1.6949  decode.d5.loss_cls: 1.4088  decode.d5.loss_mask: 0.8509  decode.d5.loss_dice: 1.6549  decode.d6.loss_cls: 1.3844  decode.d6.loss_mask: 0.8459  decode.d6.loss_dice: 1.6580  decode.d7.loss_cls: 1.3887  decode.d7.loss_mask: 0.8730  decode.d7.loss_dice: 1.6743  decode.d8.loss_cls: 1.4161  decode.d8.loss_mask: 0.8446  decode.d8.loss_dice: 1.6677
2023/05/24 11:16:41 - mmengine - INFO - Iter(train) [137100/160000]  lr: 1.7384e-06  eta: 2:45:22  time: 0.4283  data_time: 0.0104  memory: 4918  grad_norm: 91.6997  loss: 33.6054  decode.loss_cls: 0.8908  decode.loss_mask: 0.9267  decode.loss_dice: 1.2591  decode.d0.loss_cls: 2.9374  decode.d0.loss_mask: 0.9747  decode.d0.loss_dice: 1.4663  decode.d1.loss_cls: 1.0464  decode.d1.loss_mask: 0.9736  decode.d1.loss_dice: 1.3847  decode.d2.loss_cls: 1.0284  decode.d2.loss_mask: 0.9279  decode.d2.loss_dice: 1.2677  decode.d3.loss_cls: 1.0102  decode.d3.loss_mask: 0.8745  decode.d3.loss_dice: 1.2672  decode.d4.loss_cls: 0.9734  decode.d4.loss_mask: 0.8825  decode.d4.loss_dice: 1.2608  decode.d5.loss_cls: 0.9299  decode.d5.loss_mask: 0.9128  decode.d5.loss_dice: 1.2440  decode.d6.loss_cls: 0.9126  decode.d6.loss_mask: 0.8876  decode.d6.loss_dice: 1.2523  decode.d7.loss_cls: 0.9263  decode.d7.loss_mask: 0.8945  decode.d7.loss_dice: 1.2277  decode.d8.loss_cls: 0.9260  decode.d8.loss_mask: 0.8975  decode.d8.loss_dice: 1.2417
2023/05/24 11:17:02 - mmengine - INFO - Iter(train) [137150/160000]  lr: 1.7350e-06  eta: 2:45:00  time: 0.4301  data_time: 0.0104  memory: 4878  grad_norm: 120.1480  loss: 37.6811  decode.loss_cls: 1.2576  decode.loss_mask: 0.8200  decode.loss_dice: 1.3225  decode.d0.loss_cls: 3.3028  decode.d0.loss_mask: 0.9200  decode.d0.loss_dice: 1.6753  decode.d1.loss_cls: 1.3979  decode.d1.loss_mask: 0.8907  decode.d1.loss_dice: 1.4678  decode.d2.loss_cls: 1.3819  decode.d2.loss_mask: 0.8939  decode.d2.loss_dice: 1.4307  decode.d3.loss_cls: 1.3451  decode.d3.loss_mask: 0.8497  decode.d3.loss_dice: 1.3623  decode.d4.loss_cls: 1.3072  decode.d4.loss_mask: 0.8570  decode.d4.loss_dice: 1.3414  decode.d5.loss_cls: 1.2732  decode.d5.loss_mask: 0.8682  decode.d5.loss_dice: 1.3830  decode.d6.loss_cls: 1.2485  decode.d6.loss_mask: 0.8697  decode.d6.loss_dice: 1.3618  decode.d7.loss_cls: 1.2558  decode.d7.loss_mask: 0.8457  decode.d7.loss_dice: 1.3305  decode.d8.loss_cls: 1.2417  decode.d8.loss_mask: 0.8465  decode.d8.loss_dice: 1.3328
2023/05/24 11:17:26 - mmengine - INFO - Iter(train) [137200/160000]  lr: 1.7316e-06  eta: 2:44:39  time: 0.4799  data_time: 0.0102  memory: 4787  grad_norm: 90.8516  loss: 35.0318  decode.loss_cls: 1.1364  decode.loss_mask: 0.7671  decode.loss_dice: 1.2649  decode.d0.loss_cls: 3.1140  decode.d0.loss_mask: 0.8890  decode.d0.loss_dice: 1.5271  decode.d1.loss_cls: 1.4029  decode.d1.loss_mask: 0.8044  decode.d1.loss_dice: 1.4283  decode.d2.loss_cls: 1.2289  decode.d2.loss_mask: 0.8020  decode.d2.loss_dice: 1.3750  decode.d3.loss_cls: 1.1787  decode.d3.loss_mask: 0.7852  decode.d3.loss_dice: 1.3483  decode.d4.loss_cls: 1.1748  decode.d4.loss_mask: 0.7845  decode.d4.loss_dice: 1.2982  decode.d5.loss_cls: 1.0992  decode.d5.loss_mask: 0.7855  decode.d5.loss_dice: 1.3074  decode.d6.loss_cls: 1.1099  decode.d6.loss_mask: 0.7766  decode.d6.loss_dice: 1.2970  decode.d7.loss_cls: 1.1120  decode.d7.loss_mask: 0.7727  decode.d7.loss_dice: 1.2751  decode.d8.loss_cls: 1.0944  decode.d8.loss_mask: 0.7778  decode.d8.loss_dice: 1.3144
2023/05/24 11:17:48 - mmengine - INFO - Iter(train) [137250/160000]  lr: 1.7281e-06  eta: 2:44:17  time: 0.4216  data_time: 0.0100  memory: 4876  grad_norm: 103.7819  loss: 39.7208  decode.loss_cls: 1.4028  decode.loss_mask: 0.8737  decode.loss_dice: 1.4641  decode.d0.loss_cls: 2.9376  decode.d0.loss_mask: 0.8914  decode.d0.loss_dice: 1.7661  decode.d1.loss_cls: 1.3428  decode.d1.loss_mask: 0.9757  decode.d1.loss_dice: 1.6748  decode.d2.loss_cls: 1.4677  decode.d2.loss_mask: 0.8980  decode.d2.loss_dice: 1.5169  decode.d3.loss_cls: 1.4331  decode.d3.loss_mask: 0.8686  decode.d3.loss_dice: 1.4384  decode.d4.loss_cls: 1.4265  decode.d4.loss_mask: 0.8606  decode.d4.loss_dice: 1.5203  decode.d5.loss_cls: 1.4145  decode.d5.loss_mask: 0.8584  decode.d5.loss_dice: 1.4881  decode.d6.loss_cls: 1.4348  decode.d6.loss_mask: 0.8692  decode.d6.loss_dice: 1.4800  decode.d7.loss_cls: 1.4127  decode.d7.loss_mask: 0.8689  decode.d7.loss_dice: 1.4360  decode.d8.loss_cls: 1.4035  decode.d8.loss_mask: 0.8670  decode.d8.loss_dice: 1.4286
2023/05/24 11:18:10 - mmengine - INFO - Iter(train) [137300/160000]  lr: 1.7247e-06  eta: 2:43:56  time: 0.4218  data_time: 0.0099  memory: 4889  grad_norm: 116.4908  loss: 29.0487  decode.loss_cls: 0.9292  decode.loss_mask: 0.6804  decode.loss_dice: 1.0378  decode.d0.loss_cls: 2.7542  decode.d0.loss_mask: 0.6883  decode.d0.loss_dice: 1.2078  decode.d1.loss_cls: 1.0328  decode.d1.loss_mask: 0.7033  decode.d1.loss_dice: 1.1544  decode.d2.loss_cls: 1.0314  decode.d2.loss_mask: 0.7023  decode.d2.loss_dice: 1.1550  decode.d3.loss_cls: 0.9894  decode.d3.loss_mask: 0.6737  decode.d3.loss_dice: 1.0742  decode.d4.loss_cls: 0.9769  decode.d4.loss_mask: 0.6819  decode.d4.loss_dice: 1.0443  decode.d5.loss_cls: 0.8984  decode.d5.loss_mask: 0.6993  decode.d5.loss_dice: 1.0604  decode.d6.loss_cls: 0.9190  decode.d6.loss_mask: 0.6830  decode.d6.loss_dice: 1.0434  decode.d7.loss_cls: 0.8518  decode.d7.loss_mask: 0.6900  decode.d7.loss_dice: 1.0763  decode.d8.loss_cls: 0.8789  decode.d8.loss_mask: 0.6836  decode.d8.loss_dice: 1.0474
2023/05/24 11:18:31 - mmengine - INFO - Iter(train) [137350/160000]  lr: 1.7213e-06  eta: 2:43:34  time: 0.4174  data_time: 0.0104  memory: 4876  grad_norm: 97.1626  loss: 41.9675  decode.loss_cls: 1.6812  decode.loss_mask: 0.8066  decode.loss_dice: 1.4545  decode.d0.loss_cls: 3.3565  decode.d0.loss_mask: 0.8659  decode.d0.loss_dice: 1.6914  decode.d1.loss_cls: 1.8385  decode.d1.loss_mask: 0.8361  decode.d1.loss_dice: 1.5738  decode.d2.loss_cls: 1.6894  decode.d2.loss_mask: 0.8609  decode.d2.loss_dice: 1.5001  decode.d3.loss_cls: 1.6860  decode.d3.loss_mask: 0.8321  decode.d3.loss_dice: 1.4674  decode.d4.loss_cls: 1.7507  decode.d4.loss_mask: 0.8124  decode.d4.loss_dice: 1.4722  decode.d5.loss_cls: 1.7658  decode.d5.loss_mask: 0.8137  decode.d5.loss_dice: 1.4655  decode.d6.loss_cls: 1.7421  decode.d6.loss_mask: 0.8082  decode.d6.loss_dice: 1.4118  decode.d7.loss_cls: 1.6553  decode.d7.loss_mask: 0.8065  decode.d7.loss_dice: 1.4364  decode.d8.loss_cls: 1.6476  decode.d8.loss_mask: 0.7972  decode.d8.loss_dice: 1.4417
2023/05/24 11:18:52 - mmengine - INFO - Iter(train) [137400/160000]  lr: 1.7179e-06  eta: 2:43:12  time: 0.4225  data_time: 0.0103  memory: 4836  grad_norm: 95.0722  loss: 26.3861  decode.loss_cls: 0.7508  decode.loss_mask: 0.6354  decode.loss_dice: 1.0605  decode.d0.loss_cls: 2.4117  decode.d0.loss_mask: 0.6121  decode.d0.loss_dice: 1.1363  decode.d1.loss_cls: 0.7699  decode.d1.loss_mask: 0.6364  decode.d1.loss_dice: 1.1090  decode.d2.loss_cls: 0.7951  decode.d2.loss_mask: 0.6320  decode.d2.loss_dice: 1.0985  decode.d3.loss_cls: 0.7898  decode.d3.loss_mask: 0.6293  decode.d3.loss_dice: 1.0730  decode.d4.loss_cls: 0.7302  decode.d4.loss_mask: 0.6320  decode.d4.loss_dice: 1.0663  decode.d5.loss_cls: 0.7735  decode.d5.loss_mask: 0.6204  decode.d5.loss_dice: 1.0548  decode.d6.loss_cls: 0.7698  decode.d6.loss_mask: 0.6096  decode.d6.loss_dice: 1.0539  decode.d7.loss_cls: 0.7872  decode.d7.loss_mask: 0.6343  decode.d7.loss_dice: 1.0763  decode.d8.loss_cls: 0.7377  decode.d8.loss_mask: 0.6402  decode.d8.loss_dice: 1.0600
2023/05/24 11:19:13 - mmengine - INFO - Iter(train) [137450/160000]  lr: 1.7145e-06  eta: 2:42:50  time: 0.4230  data_time: 0.0100  memory: 4808  grad_norm: 96.1706  loss: 30.5058  decode.loss_cls: 0.8233  decode.loss_mask: 0.7446  decode.loss_dice: 1.1921  decode.d0.loss_cls: 2.6883  decode.d0.loss_mask: 0.8245  decode.d0.loss_dice: 1.3593  decode.d1.loss_cls: 0.8934  decode.d1.loss_mask: 0.7916  decode.d1.loss_dice: 1.3306  decode.d2.loss_cls: 0.9159  decode.d2.loss_mask: 0.7627  decode.d2.loss_dice: 1.2682  decode.d3.loss_cls: 0.8402  decode.d3.loss_mask: 0.7846  decode.d3.loss_dice: 1.2702  decode.d4.loss_cls: 0.8540  decode.d4.loss_mask: 0.7931  decode.d4.loss_dice: 1.2022  decode.d5.loss_cls: 0.8416  decode.d5.loss_mask: 0.7704  decode.d5.loss_dice: 1.2445  decode.d6.loss_cls: 0.8331  decode.d6.loss_mask: 0.7432  decode.d6.loss_dice: 1.1995  decode.d7.loss_cls: 0.8319  decode.d7.loss_mask: 0.7368  decode.d7.loss_dice: 1.2045  decode.d8.loss_cls: 0.8419  decode.d8.loss_mask: 0.7456  decode.d8.loss_dice: 1.1741
2023/05/24 11:19:34 - mmengine - INFO - Iter(train) [137500/160000]  lr: 1.7110e-06  eta: 2:42:29  time: 0.4173  data_time: 0.0098  memory: 4879  grad_norm: 86.1870  loss: 29.9883  decode.loss_cls: 1.1494  decode.loss_mask: 0.6799  decode.loss_dice: 0.9317  decode.d0.loss_cls: 2.5674  decode.d0.loss_mask: 0.7875  decode.d0.loss_dice: 1.1112  decode.d1.loss_cls: 1.2001  decode.d1.loss_mask: 0.7763  decode.d1.loss_dice: 1.0951  decode.d2.loss_cls: 1.1505  decode.d2.loss_mask: 0.7388  decode.d2.loss_dice: 0.9887  decode.d3.loss_cls: 1.1433  decode.d3.loss_mask: 0.7033  decode.d3.loss_dice: 0.9633  decode.d4.loss_cls: 1.1705  decode.d4.loss_mask: 0.7021  decode.d4.loss_dice: 0.9877  decode.d5.loss_cls: 1.1381  decode.d5.loss_mask: 0.7004  decode.d5.loss_dice: 0.9828  decode.d6.loss_cls: 1.0823  decode.d6.loss_mask: 0.6797  decode.d6.loss_dice: 0.9981  decode.d7.loss_cls: 1.1451  decode.d7.loss_mask: 0.6826  decode.d7.loss_dice: 0.9558  decode.d8.loss_cls: 1.1623  decode.d8.loss_mask: 0.6703  decode.d8.loss_dice: 0.9443
2023/05/24 11:19:55 - mmengine - INFO - Iter(train) [137550/160000]  lr: 1.7076e-06  eta: 2:42:07  time: 0.4266  data_time: 0.0102  memory: 4844  grad_norm: 101.3257  loss: 24.3572  decode.loss_cls: 0.8755  decode.loss_mask: 0.5878  decode.loss_dice: 0.7536  decode.d0.loss_cls: 2.5772  decode.d0.loss_mask: 0.6709  decode.d0.loss_dice: 0.9059  decode.d1.loss_cls: 0.9273  decode.d1.loss_mask: 0.6286  decode.d1.loss_dice: 0.8155  decode.d2.loss_cls: 0.8706  decode.d2.loss_mask: 0.6148  decode.d2.loss_dice: 0.7635  decode.d3.loss_cls: 0.8731  decode.d3.loss_mask: 0.6036  decode.d3.loss_dice: 0.8097  decode.d4.loss_cls: 0.8619  decode.d4.loss_mask: 0.6103  decode.d4.loss_dice: 0.7787  decode.d5.loss_cls: 0.8610  decode.d5.loss_mask: 0.5894  decode.d5.loss_dice: 0.7748  decode.d6.loss_cls: 0.8202  decode.d6.loss_mask: 0.5858  decode.d6.loss_dice: 0.7723  decode.d7.loss_cls: 0.8529  decode.d7.loss_mask: 0.5767  decode.d7.loss_dice: 0.7560  decode.d8.loss_cls: 0.8692  decode.d8.loss_mask: 0.5901  decode.d8.loss_dice: 0.7805
2023/05/24 11:20:17 - mmengine - INFO - Iter(train) [137600/160000]  lr: 1.7042e-06  eta: 2:41:45  time: 0.4301  data_time: 0.0100  memory: 4795  grad_norm: 113.2983  loss: 31.2513  decode.loss_cls: 0.9629  decode.loss_mask: 0.8406  decode.loss_dice: 1.0149  decode.d0.loss_cls: 3.1160  decode.d0.loss_mask: 0.8706  decode.d0.loss_dice: 1.1907  decode.d1.loss_cls: 1.0603  decode.d1.loss_mask: 0.9254  decode.d1.loss_dice: 1.1156  decode.d2.loss_cls: 1.0208  decode.d2.loss_mask: 0.8905  decode.d2.loss_dice: 1.1007  decode.d3.loss_cls: 0.9844  decode.d3.loss_mask: 0.8674  decode.d3.loss_dice: 1.0861  decode.d4.loss_cls: 0.9730  decode.d4.loss_mask: 0.8413  decode.d4.loss_dice: 1.0290  decode.d5.loss_cls: 0.9424  decode.d5.loss_mask: 0.8607  decode.d5.loss_dice: 1.0812  decode.d6.loss_cls: 0.9687  decode.d6.loss_mask: 0.8473  decode.d6.loss_dice: 1.0352  decode.d7.loss_cls: 0.9415  decode.d7.loss_mask: 0.8401  decode.d7.loss_dice: 1.0270  decode.d8.loss_cls: 0.9515  decode.d8.loss_mask: 0.8429  decode.d8.loss_dice: 1.0224
2023/05/24 11:20:39 - mmengine - INFO - Iter(train) [137650/160000]  lr: 1.7008e-06  eta: 2:41:24  time: 0.4268  data_time: 0.0100  memory: 4819  grad_norm: 83.0406  loss: 35.3654  decode.loss_cls: 1.1396  decode.loss_mask: 0.7525  decode.loss_dice: 1.3841  decode.d0.loss_cls: 3.1404  decode.d0.loss_mask: 0.7610  decode.d0.loss_dice: 1.5868  decode.d1.loss_cls: 1.2726  decode.d1.loss_mask: 0.8002  decode.d1.loss_dice: 1.4390  decode.d2.loss_cls: 1.2446  decode.d2.loss_mask: 0.7376  decode.d2.loss_dice: 1.4182  decode.d3.loss_cls: 1.0801  decode.d3.loss_mask: 0.7829  decode.d3.loss_dice: 1.4167  decode.d4.loss_cls: 1.0461  decode.d4.loss_mask: 0.7948  decode.d4.loss_dice: 1.4216  decode.d5.loss_cls: 1.1369  decode.d5.loss_mask: 0.7756  decode.d5.loss_dice: 1.4067  decode.d6.loss_cls: 1.1331  decode.d6.loss_mask: 0.7560  decode.d6.loss_dice: 1.3984  decode.d7.loss_cls: 1.1061  decode.d7.loss_mask: 0.7420  decode.d7.loss_dice: 1.4219  decode.d8.loss_cls: 1.1738  decode.d8.loss_mask: 0.7214  decode.d8.loss_dice: 1.3747
2023/05/24 11:21:00 - mmengine - INFO - Iter(train) [137700/160000]  lr: 1.6973e-06  eta: 2:41:02  time: 0.4220  data_time: 0.0102  memory: 4831  grad_norm: 145.5224  loss: 28.2511  decode.loss_cls: 0.8943  decode.loss_mask: 0.7106  decode.loss_dice: 0.9636  decode.d0.loss_cls: 2.7084  decode.d0.loss_mask: 0.6867  decode.d0.loss_dice: 1.0548  decode.d1.loss_cls: 1.0271  decode.d1.loss_mask: 0.7182  decode.d1.loss_dice: 1.0484  decode.d2.loss_cls: 0.9814  decode.d2.loss_mask: 0.7160  decode.d2.loss_dice: 1.0115  decode.d3.loss_cls: 0.9448  decode.d3.loss_mask: 0.7285  decode.d3.loss_dice: 0.9960  decode.d4.loss_cls: 0.9382  decode.d4.loss_mask: 0.7226  decode.d4.loss_dice: 1.0092  decode.d5.loss_cls: 0.9574  decode.d5.loss_mask: 0.7153  decode.d5.loss_dice: 0.9906  decode.d6.loss_cls: 0.9085  decode.d6.loss_mask: 0.7235  decode.d6.loss_dice: 0.9573  decode.d7.loss_cls: 0.9186  decode.d7.loss_mask: 0.7107  decode.d7.loss_dice: 0.9288  decode.d8.loss_cls: 0.9105  decode.d8.loss_mask: 0.7096  decode.d8.loss_dice: 0.9601
2023/05/24 11:21:22 - mmengine - INFO - Iter(train) [137750/160000]  lr: 1.6939e-06  eta: 2:40:40  time: 0.4381  data_time: 0.0098  memory: 4876  grad_norm: 105.6963  loss: 37.6863  decode.loss_cls: 1.2041  decode.loss_mask: 0.8689  decode.loss_dice: 1.3782  decode.d0.loss_cls: 3.1846  decode.d0.loss_mask: 0.9138  decode.d0.loss_dice: 1.6111  decode.d1.loss_cls: 1.3176  decode.d1.loss_mask: 0.9645  decode.d1.loss_dice: 1.5395  decode.d2.loss_cls: 1.1900  decode.d2.loss_mask: 0.9654  decode.d2.loss_dice: 1.4925  decode.d3.loss_cls: 1.2104  decode.d3.loss_mask: 0.9223  decode.d3.loss_dice: 1.4225  decode.d4.loss_cls: 1.1953  decode.d4.loss_mask: 0.9293  decode.d4.loss_dice: 1.4153  decode.d5.loss_cls: 1.1709  decode.d5.loss_mask: 0.9266  decode.d5.loss_dice: 1.4227  decode.d6.loss_cls: 1.2131  decode.d6.loss_mask: 0.8699  decode.d6.loss_dice: 1.3879  decode.d7.loss_cls: 1.1904  decode.d7.loss_mask: 0.8728  decode.d7.loss_dice: 1.4130  decode.d8.loss_cls: 1.2241  decode.d8.loss_mask: 0.8664  decode.d8.loss_dice: 1.4029
2023/05/24 11:21:43 - mmengine - INFO - Iter(train) [137800/160000]  lr: 1.6905e-06  eta: 2:40:18  time: 0.4225  data_time: 0.0097  memory: 4847  grad_norm: 93.7829  loss: 31.0690  decode.loss_cls: 1.2476  decode.loss_mask: 0.5731  decode.loss_dice: 1.0344  decode.d0.loss_cls: 3.0830  decode.d0.loss_mask: 0.6186  decode.d0.loss_dice: 1.1977  decode.d1.loss_cls: 1.4011  decode.d1.loss_mask: 0.6202  decode.d1.loss_dice: 1.0832  decode.d2.loss_cls: 1.2692  decode.d2.loss_mask: 0.5915  decode.d2.loss_dice: 1.1000  decode.d3.loss_cls: 1.2381  decode.d3.loss_mask: 0.6086  decode.d3.loss_dice: 1.0631  decode.d4.loss_cls: 1.2570  decode.d4.loss_mask: 0.5960  decode.d4.loss_dice: 1.0346  decode.d5.loss_cls: 1.2844  decode.d5.loss_mask: 0.5765  decode.d5.loss_dice: 1.0371  decode.d6.loss_cls: 1.2183  decode.d6.loss_mask: 0.5800  decode.d6.loss_dice: 1.0537  decode.d7.loss_cls: 1.2493  decode.d7.loss_mask: 0.5640  decode.d7.loss_dice: 1.0399  decode.d8.loss_cls: 1.2438  decode.d8.loss_mask: 0.5685  decode.d8.loss_dice: 1.0365
2023/05/24 11:22:04 - mmengine - INFO - Iter(train) [137850/160000]  lr: 1.6871e-06  eta: 2:39:57  time: 0.4256  data_time: 0.0103  memory: 4857  grad_norm: 89.6000  loss: 30.5830  decode.loss_cls: 0.9521  decode.loss_mask: 0.6845  decode.loss_dice: 1.0899  decode.d0.loss_cls: 2.9431  decode.d0.loss_mask: 0.8012  decode.d0.loss_dice: 1.3700  decode.d1.loss_cls: 1.1749  decode.d1.loss_mask: 0.7393  decode.d1.loss_dice: 1.2402  decode.d2.loss_cls: 1.0383  decode.d2.loss_mask: 0.6985  decode.d2.loss_dice: 1.1855  decode.d3.loss_cls: 1.0182  decode.d3.loss_mask: 0.6916  decode.d3.loss_dice: 1.1402  decode.d4.loss_cls: 1.0075  decode.d4.loss_mask: 0.6877  decode.d4.loss_dice: 1.1417  decode.d5.loss_cls: 0.9752  decode.d5.loss_mask: 0.6678  decode.d5.loss_dice: 1.0984  decode.d6.loss_cls: 0.9880  decode.d6.loss_mask: 0.6761  decode.d6.loss_dice: 1.0831  decode.d7.loss_cls: 0.9725  decode.d7.loss_mask: 0.6654  decode.d7.loss_dice: 1.1043  decode.d8.loss_cls: 0.9673  decode.d8.loss_mask: 0.6672  decode.d8.loss_dice: 1.1135
2023/05/24 11:22:26 - mmengine - INFO - Iter(train) [137900/160000]  lr: 1.6836e-06  eta: 2:39:35  time: 0.4205  data_time: 0.0101  memory: 4917  grad_norm: 85.5613  loss: 45.1126  decode.loss_cls: 1.3973  decode.loss_mask: 0.8712  decode.loss_dice: 1.8527  decode.d0.loss_cls: 3.5845  decode.d0.loss_mask: 1.0511  decode.d0.loss_dice: 2.2630  decode.d1.loss_cls: 1.5019  decode.d1.loss_mask: 0.9704  decode.d1.loss_dice: 2.0423  decode.d2.loss_cls: 1.5564  decode.d2.loss_mask: 0.9163  decode.d2.loss_dice: 1.9317  decode.d3.loss_cls: 1.4529  decode.d3.loss_mask: 0.8833  decode.d3.loss_dice: 1.8917  decode.d4.loss_cls: 1.3677  decode.d4.loss_mask: 0.8803  decode.d4.loss_dice: 1.9205  decode.d5.loss_cls: 1.4183  decode.d5.loss_mask: 0.8795  decode.d5.loss_dice: 1.9020  decode.d6.loss_cls: 1.4137  decode.d6.loss_mask: 0.8829  decode.d6.loss_dice: 1.9172  decode.d7.loss_cls: 1.4103  decode.d7.loss_mask: 0.8701  decode.d7.loss_dice: 1.8829  decode.d8.loss_cls: 1.4128  decode.d8.loss_mask: 0.8692  decode.d8.loss_dice: 1.9183
2023/05/24 11:22:48 - mmengine - INFO - Iter(train) [137950/160000]  lr: 1.6802e-06  eta: 2:39:13  time: 0.4790  data_time: 0.0098  memory: 4865  grad_norm: 110.4271  loss: 27.9205  decode.loss_cls: 0.8727  decode.loss_mask: 0.6531  decode.loss_dice: 0.9879  decode.d0.loss_cls: 2.8646  decode.d0.loss_mask: 0.7186  decode.d0.loss_dice: 1.1553  decode.d1.loss_cls: 0.9776  decode.d1.loss_mask: 0.6851  decode.d1.loss_dice: 1.0643  decode.d2.loss_cls: 1.0034  decode.d2.loss_mask: 0.6500  decode.d2.loss_dice: 1.0187  decode.d3.loss_cls: 0.9124  decode.d3.loss_mask: 0.6608  decode.d3.loss_dice: 1.0321  decode.d4.loss_cls: 0.9029  decode.d4.loss_mask: 0.6548  decode.d4.loss_dice: 0.9921  decode.d5.loss_cls: 0.8708  decode.d5.loss_mask: 0.6702  decode.d5.loss_dice: 1.0216  decode.d6.loss_cls: 0.8465  decode.d6.loss_mask: 0.6565  decode.d6.loss_dice: 1.0008  decode.d7.loss_cls: 0.8705  decode.d7.loss_mask: 0.6593  decode.d7.loss_dice: 1.0044  decode.d8.loss_cls: 0.8580  decode.d8.loss_mask: 0.6599  decode.d8.loss_dice: 0.9959
2023/05/24 11:23:11 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 11:23:11 - mmengine - INFO - Iter(train) [138000/160000]  lr: 1.6768e-06  eta: 2:38:52  time: 0.4334  data_time: 0.0096  memory: 4837  grad_norm: 94.8837  loss: 33.8515  decode.loss_cls: 1.0792  decode.loss_mask: 0.7827  decode.loss_dice: 1.1790  decode.d0.loss_cls: 3.2818  decode.d0.loss_mask: 0.9206  decode.d0.loss_dice: 1.4480  decode.d1.loss_cls: 1.2807  decode.d1.loss_mask: 0.8055  decode.d1.loss_dice: 1.2986  decode.d2.loss_cls: 1.2423  decode.d2.loss_mask: 0.8096  decode.d2.loss_dice: 1.2093  decode.d3.loss_cls: 1.1726  decode.d3.loss_mask: 0.7789  decode.d3.loss_dice: 1.1995  decode.d4.loss_cls: 1.1141  decode.d4.loss_mask: 0.7897  decode.d4.loss_dice: 1.1690  decode.d5.loss_cls: 1.1185  decode.d5.loss_mask: 0.7819  decode.d5.loss_dice: 1.1794  decode.d6.loss_cls: 1.0912  decode.d6.loss_mask: 0.8110  decode.d6.loss_dice: 1.1847  decode.d7.loss_cls: 1.0960  decode.d7.loss_mask: 0.7991  decode.d7.loss_dice: 1.1709  decode.d8.loss_cls: 1.0897  decode.d8.loss_mask: 0.8008  decode.d8.loss_dice: 1.1673
2023/05/24 11:23:11 - mmengine - INFO - Saving checkpoint at 138000 iterations
2023/05/24 11:23:39 - mmengine - INFO - Iter(train) [138050/160000]  lr: 1.6733e-06  eta: 2:38:31  time: 0.4260  data_time: 0.0100  memory: 4829  grad_norm: 87.1251  loss: 32.6109  decode.loss_cls: 1.0393  decode.loss_mask: 0.7104  decode.loss_dice: 1.2066  decode.d0.loss_cls: 3.0653  decode.d0.loss_mask: 0.7836  decode.d0.loss_dice: 1.4266  decode.d1.loss_cls: 1.2326  decode.d1.loss_mask: 0.7054  decode.d1.loss_dice: 1.3230  decode.d2.loss_cls: 1.1935  decode.d2.loss_mask: 0.7062  decode.d2.loss_dice: 1.2237  decode.d3.loss_cls: 1.1131  decode.d3.loss_mask: 0.7256  decode.d3.loss_dice: 1.2124  decode.d4.loss_cls: 1.1039  decode.d4.loss_mask: 0.7314  decode.d4.loss_dice: 1.2184  decode.d5.loss_cls: 1.0473  decode.d5.loss_mask: 0.7123  decode.d5.loss_dice: 1.2052  decode.d6.loss_cls: 1.0596  decode.d6.loss_mask: 0.7108  decode.d6.loss_dice: 1.2125  decode.d7.loss_cls: 1.0153  decode.d7.loss_mask: 0.7112  decode.d7.loss_dice: 1.2322  decode.d8.loss_cls: 1.0471  decode.d8.loss_mask: 0.7156  decode.d8.loss_dice: 1.2207
2023/05/24 11:24:00 - mmengine - INFO - Iter(train) [138100/160000]  lr: 1.6699e-06  eta: 2:38:10  time: 0.4172  data_time: 0.0101  memory: 4846  grad_norm: 100.8892  loss: 39.2146  decode.loss_cls: 1.4376  decode.loss_mask: 0.9348  decode.loss_dice: 1.2872  decode.d0.loss_cls: 3.3077  decode.d0.loss_mask: 1.0011  decode.d0.loss_dice: 1.4949  decode.d1.loss_cls: 1.5576  decode.d1.loss_mask: 0.9748  decode.d1.loss_dice: 1.3863  decode.d2.loss_cls: 1.4107  decode.d2.loss_mask: 1.0060  decode.d2.loss_dice: 1.3799  decode.d3.loss_cls: 1.4910  decode.d3.loss_mask: 0.9370  decode.d3.loss_dice: 1.3129  decode.d4.loss_cls: 1.3900  decode.d4.loss_mask: 0.9484  decode.d4.loss_dice: 1.3127  decode.d5.loss_cls: 1.4365  decode.d5.loss_mask: 0.9393  decode.d5.loss_dice: 1.3113  decode.d6.loss_cls: 1.4513  decode.d6.loss_mask: 0.9452  decode.d6.loss_dice: 1.2571  decode.d7.loss_cls: 1.4338  decode.d7.loss_mask: 0.9433  decode.d7.loss_dice: 1.2884  decode.d8.loss_cls: 1.4161  decode.d8.loss_mask: 0.9451  decode.d8.loss_dice: 1.2768
2023/05/24 11:24:21 - mmengine - INFO - Iter(train) [138150/160000]  lr: 1.6665e-06  eta: 2:37:48  time: 0.4162  data_time: 0.0100  memory: 4885  grad_norm: 96.2261  loss: 45.9583  decode.loss_cls: 1.5455  decode.loss_mask: 0.8854  decode.loss_dice: 1.8147  decode.d0.loss_cls: 3.6111  decode.d0.loss_mask: 1.0032  decode.d0.loss_dice: 2.1282  decode.d1.loss_cls: 1.6896  decode.d1.loss_mask: 0.9262  decode.d1.loss_dice: 1.9890  decode.d2.loss_cls: 1.6664  decode.d2.loss_mask: 0.8943  decode.d2.loss_dice: 1.8989  decode.d3.loss_cls: 1.5683  decode.d3.loss_mask: 0.9461  decode.d3.loss_dice: 1.8939  decode.d4.loss_cls: 1.4845  decode.d4.loss_mask: 0.9108  decode.d4.loss_dice: 1.9154  decode.d5.loss_cls: 1.5463  decode.d5.loss_mask: 0.8822  decode.d5.loss_dice: 1.8645  decode.d6.loss_cls: 1.5897  decode.d6.loss_mask: 0.8948  decode.d6.loss_dice: 1.8423  decode.d7.loss_cls: 1.6112  decode.d7.loss_mask: 0.8653  decode.d7.loss_dice: 1.8472  decode.d8.loss_cls: 1.5139  decode.d8.loss_mask: 0.8844  decode.d8.loss_dice: 1.8450
2023/05/24 11:24:44 - mmengine - INFO - Iter(train) [138200/160000]  lr: 1.6630e-06  eta: 2:37:26  time: 0.4774  data_time: 0.0100  memory: 4826  grad_norm: 100.1443  loss: 34.1587  decode.loss_cls: 1.2666  decode.loss_mask: 0.7561  decode.loss_dice: 1.0969  decode.d0.loss_cls: 3.2603  decode.d0.loss_mask: 0.8957  decode.d0.loss_dice: 1.4360  decode.d1.loss_cls: 1.3733  decode.d1.loss_mask: 0.8309  decode.d1.loss_dice: 1.2474  decode.d2.loss_cls: 1.2826  decode.d2.loss_mask: 0.7788  decode.d2.loss_dice: 1.1932  decode.d3.loss_cls: 1.1909  decode.d3.loss_mask: 0.7687  decode.d3.loss_dice: 1.1330  decode.d4.loss_cls: 1.2607  decode.d4.loss_mask: 0.7430  decode.d4.loss_dice: 1.1007  decode.d5.loss_cls: 1.2328  decode.d5.loss_mask: 0.7583  decode.d5.loss_dice: 1.1212  decode.d6.loss_cls: 1.2649  decode.d6.loss_mask: 0.7814  decode.d6.loss_dice: 1.1093  decode.d7.loss_cls: 1.2211  decode.d7.loss_mask: 0.7763  decode.d7.loss_dice: 1.1339  decode.d8.loss_cls: 1.2746  decode.d8.loss_mask: 0.7683  decode.d8.loss_dice: 1.1016
2023/05/24 11:25:06 - mmengine - INFO - Iter(train) [138250/160000]  lr: 1.6596e-06  eta: 2:37:05  time: 0.4209  data_time: 0.0098  memory: 4833  grad_norm: 87.9519  loss: 34.0368  decode.loss_cls: 1.2190  decode.loss_mask: 0.6886  decode.loss_dice: 1.1393  decode.d0.loss_cls: 3.2482  decode.d0.loss_mask: 0.7707  decode.d0.loss_dice: 1.5411  decode.d1.loss_cls: 1.4578  decode.d1.loss_mask: 0.6623  decode.d1.loss_dice: 1.2481  decode.d2.loss_cls: 1.3737  decode.d2.loss_mask: 0.6772  decode.d2.loss_dice: 1.2323  decode.d3.loss_cls: 1.3033  decode.d3.loss_mask: 0.6966  decode.d3.loss_dice: 1.1895  decode.d4.loss_cls: 1.3477  decode.d4.loss_mask: 0.6617  decode.d4.loss_dice: 1.1859  decode.d5.loss_cls: 1.2361  decode.d5.loss_mask: 0.6781  decode.d5.loss_dice: 1.2022  decode.d6.loss_cls: 1.2478  decode.d6.loss_mask: 0.6874  decode.d6.loss_dice: 1.1865  decode.d7.loss_cls: 1.2434  decode.d7.loss_mask: 0.6805  decode.d7.loss_dice: 1.1683  decode.d8.loss_cls: 1.2020  decode.d8.loss_mask: 0.6805  decode.d8.loss_dice: 1.1810
2023/05/24 11:25:27 - mmengine - INFO - Iter(train) [138300/160000]  lr: 1.6562e-06  eta: 2:36:43  time: 0.4715  data_time: 0.0107  memory: 4834  grad_norm: 76.0607  loss: 30.6129  decode.loss_cls: 0.9442  decode.loss_mask: 0.6764  decode.loss_dice: 1.1280  decode.d0.loss_cls: 2.9706  decode.d0.loss_mask: 0.7786  decode.d0.loss_dice: 1.4084  decode.d1.loss_cls: 1.0970  decode.d1.loss_mask: 0.7656  decode.d1.loss_dice: 1.3179  decode.d2.loss_cls: 1.0385  decode.d2.loss_mask: 0.7141  decode.d2.loss_dice: 1.2052  decode.d3.loss_cls: 0.9615  decode.d3.loss_mask: 0.6976  decode.d3.loss_dice: 1.1490  decode.d4.loss_cls: 0.9406  decode.d4.loss_mask: 0.6929  decode.d4.loss_dice: 1.1056  decode.d5.loss_cls: 0.9299  decode.d5.loss_mask: 0.6776  decode.d5.loss_dice: 1.1749  decode.d6.loss_cls: 0.9319  decode.d6.loss_mask: 0.6778  decode.d6.loss_dice: 1.1223  decode.d7.loss_cls: 0.9261  decode.d7.loss_mask: 0.6820  decode.d7.loss_dice: 1.1467  decode.d8.loss_cls: 0.9345  decode.d8.loss_mask: 0.6780  decode.d8.loss_dice: 1.1397
2023/05/24 11:25:50 - mmengine - INFO - Iter(train) [138350/160000]  lr: 1.6527e-06  eta: 2:36:21  time: 0.4251  data_time: 0.0106  memory: 4847  grad_norm: 99.2199  loss: 35.2068  decode.loss_cls: 1.2162  decode.loss_mask: 0.6394  decode.loss_dice: 1.3986  decode.d0.loss_cls: 3.0991  decode.d0.loss_mask: 0.6342  decode.d0.loss_dice: 1.5824  decode.d1.loss_cls: 1.4185  decode.d1.loss_mask: 0.6942  decode.d1.loss_dice: 1.4807  decode.d2.loss_cls: 1.3139  decode.d2.loss_mask: 0.6554  decode.d2.loss_dice: 1.4307  decode.d3.loss_cls: 1.2022  decode.d3.loss_mask: 0.6432  decode.d3.loss_dice: 1.4031  decode.d4.loss_cls: 1.2873  decode.d4.loss_mask: 0.6507  decode.d4.loss_dice: 1.4004  decode.d5.loss_cls: 1.2664  decode.d5.loss_mask: 0.6316  decode.d5.loss_dice: 1.4010  decode.d6.loss_cls: 1.2502  decode.d6.loss_mask: 0.6539  decode.d6.loss_dice: 1.3552  decode.d7.loss_cls: 1.2452  decode.d7.loss_mask: 0.6492  decode.d7.loss_dice: 1.3586  decode.d8.loss_cls: 1.2738  decode.d8.loss_mask: 0.6214  decode.d8.loss_dice: 1.3500
2023/05/24 11:26:11 - mmengine - INFO - Iter(train) [138400/160000]  lr: 1.6493e-06  eta: 2:36:00  time: 0.4222  data_time: 0.0105  memory: 4869  grad_norm: 82.4912  loss: 31.0092  decode.loss_cls: 0.8748  decode.loss_mask: 0.8350  decode.loss_dice: 1.1061  decode.d0.loss_cls: 2.8178  decode.d0.loss_mask: 0.8332  decode.d0.loss_dice: 1.2702  decode.d1.loss_cls: 1.0425  decode.d1.loss_mask: 0.8695  decode.d1.loss_dice: 1.1747  decode.d2.loss_cls: 0.9183  decode.d2.loss_mask: 0.8343  decode.d2.loss_dice: 1.1958  decode.d3.loss_cls: 0.9320  decode.d3.loss_mask: 0.8692  decode.d3.loss_dice: 1.1263  decode.d4.loss_cls: 0.9556  decode.d4.loss_mask: 0.8126  decode.d4.loss_dice: 1.1257  decode.d5.loss_cls: 0.9565  decode.d5.loss_mask: 0.8061  decode.d5.loss_dice: 1.1100  decode.d6.loss_cls: 0.8988  decode.d6.loss_mask: 0.8252  decode.d6.loss_dice: 1.1221  decode.d7.loss_cls: 0.9539  decode.d7.loss_mask: 0.7983  decode.d7.loss_dice: 1.1031  decode.d8.loss_cls: 0.8779  decode.d8.loss_mask: 0.8390  decode.d8.loss_dice: 1.1248
2023/05/24 11:26:33 - mmengine - INFO - Iter(train) [138450/160000]  lr: 1.6459e-06  eta: 2:35:38  time: 0.4310  data_time: 0.0105  memory: 4847  grad_norm: 92.8334  loss: 34.6096  decode.loss_cls: 1.1475  decode.loss_mask: 0.7534  decode.loss_dice: 1.1862  decode.d0.loss_cls: 3.1846  decode.d0.loss_mask: 0.7888  decode.d0.loss_dice: 1.3587  decode.d1.loss_cls: 1.3172  decode.d1.loss_mask: 0.8376  decode.d1.loss_dice: 1.3734  decode.d2.loss_cls: 1.1958  decode.d2.loss_mask: 0.8596  decode.d2.loss_dice: 1.3622  decode.d3.loss_cls: 1.2560  decode.d3.loss_mask: 0.7955  decode.d3.loss_dice: 1.2383  decode.d4.loss_cls: 1.2155  decode.d4.loss_mask: 0.7938  decode.d4.loss_dice: 1.2517  decode.d5.loss_cls: 1.2167  decode.d5.loss_mask: 0.7766  decode.d5.loss_dice: 1.2319  decode.d6.loss_cls: 1.1937  decode.d6.loss_mask: 0.7612  decode.d6.loss_dice: 1.1903  decode.d7.loss_cls: 1.1937  decode.d7.loss_mask: 0.7653  decode.d7.loss_dice: 1.2198  decode.d8.loss_cls: 1.1703  decode.d8.loss_mask: 0.7584  decode.d8.loss_dice: 1.2160
2023/05/24 11:26:55 - mmengine - INFO - Iter(train) [138500/160000]  lr: 1.6424e-06  eta: 2:35:16  time: 0.4253  data_time: 0.0102  memory: 4904  grad_norm: 91.8120  loss: 37.3819  decode.loss_cls: 1.2081  decode.loss_mask: 0.9417  decode.loss_dice: 1.3104  decode.d0.loss_cls: 3.0696  decode.d0.loss_mask: 1.0315  decode.d0.loss_dice: 1.4769  decode.d1.loss_cls: 1.2938  decode.d1.loss_mask: 0.9682  decode.d1.loss_dice: 1.4462  decode.d2.loss_cls: 1.3072  decode.d2.loss_mask: 0.9269  decode.d2.loss_dice: 1.3710  decode.d3.loss_cls: 1.2676  decode.d3.loss_mask: 0.9364  decode.d3.loss_dice: 1.3589  decode.d4.loss_cls: 1.2334  decode.d4.loss_mask: 0.9415  decode.d4.loss_dice: 1.3427  decode.d5.loss_cls: 1.2026  decode.d5.loss_mask: 0.9381  decode.d5.loss_dice: 1.3582  decode.d6.loss_cls: 1.2203  decode.d6.loss_mask: 0.9468  decode.d6.loss_dice: 1.3319  decode.d7.loss_cls: 1.2238  decode.d7.loss_mask: 0.9483  decode.d7.loss_dice: 1.3236  decode.d8.loss_cls: 1.1981  decode.d8.loss_mask: 0.9497  decode.d8.loss_dice: 1.3085
2023/05/24 11:27:16 - mmengine - INFO - Iter(train) [138550/160000]  lr: 1.6390e-06  eta: 2:34:55  time: 0.4173  data_time: 0.0098  memory: 4830  grad_norm: 84.7387  loss: 39.7933  decode.loss_cls: 1.4086  decode.loss_mask: 0.7911  decode.loss_dice: 1.5035  decode.d0.loss_cls: 3.2858  decode.d0.loss_mask: 0.8147  decode.d0.loss_dice: 1.8161  decode.d1.loss_cls: 1.5668  decode.d1.loss_mask: 0.7602  decode.d1.loss_dice: 1.6706  decode.d2.loss_cls: 1.5010  decode.d2.loss_mask: 0.7476  decode.d2.loss_dice: 1.5851  decode.d3.loss_cls: 1.4640  decode.d3.loss_mask: 0.7683  decode.d3.loss_dice: 1.5246  decode.d4.loss_cls: 1.4451  decode.d4.loss_mask: 0.7682  decode.d4.loss_dice: 1.5252  decode.d5.loss_cls: 1.4059  decode.d5.loss_mask: 0.7518  decode.d5.loss_dice: 1.5241  decode.d6.loss_cls: 1.3767  decode.d6.loss_mask: 0.7935  decode.d6.loss_dice: 1.5146  decode.d7.loss_cls: 1.4261  decode.d7.loss_mask: 0.8036  decode.d7.loss_dice: 1.5114  decode.d8.loss_cls: 1.4221  decode.d8.loss_mask: 0.7983  decode.d8.loss_dice: 1.5188
2023/05/24 11:27:38 - mmengine - INFO - Iter(train) [138600/160000]  lr: 1.6356e-06  eta: 2:34:33  time: 0.4216  data_time: 0.0098  memory: 4847  grad_norm: 97.7130  loss: 38.5981  decode.loss_cls: 1.1824  decode.loss_mask: 0.8811  decode.loss_dice: 1.5118  decode.d0.loss_cls: 3.3806  decode.d0.loss_mask: 0.9375  decode.d0.loss_dice: 1.6903  decode.d1.loss_cls: 1.3749  decode.d1.loss_mask: 0.9339  decode.d1.loss_dice: 1.6406  decode.d2.loss_cls: 1.2616  decode.d2.loss_mask: 0.8786  decode.d2.loss_dice: 1.5624  decode.d3.loss_cls: 1.2162  decode.d3.loss_mask: 0.8693  decode.d3.loss_dice: 1.5592  decode.d4.loss_cls: 1.1765  decode.d4.loss_mask: 0.8809  decode.d4.loss_dice: 1.4987  decode.d5.loss_cls: 1.2173  decode.d5.loss_mask: 0.8561  decode.d5.loss_dice: 1.4730  decode.d6.loss_cls: 1.1863  decode.d6.loss_mask: 0.8650  decode.d6.loss_dice: 1.5063  decode.d7.loss_cls: 1.1701  decode.d7.loss_mask: 0.8845  decode.d7.loss_dice: 1.4465  decode.d8.loss_cls: 1.2190  decode.d8.loss_mask: 0.8560  decode.d8.loss_dice: 1.4816
2023/05/24 11:27:59 - mmengine - INFO - Iter(train) [138650/160000]  lr: 1.6321e-06  eta: 2:34:11  time: 0.4342  data_time: 0.0102  memory: 4839  grad_norm: 102.3030  loss: 37.7822  decode.loss_cls: 1.2061  decode.loss_mask: 0.8410  decode.loss_dice: 1.4367  decode.d0.loss_cls: 3.1834  decode.d0.loss_mask: 0.8496  decode.d0.loss_dice: 1.6945  decode.d1.loss_cls: 1.2621  decode.d1.loss_mask: 0.8437  decode.d1.loss_dice: 1.5876  decode.d2.loss_cls: 1.2215  decode.d2.loss_mask: 0.8567  decode.d2.loss_dice: 1.5596  decode.d3.loss_cls: 1.3006  decode.d3.loss_mask: 0.8570  decode.d3.loss_dice: 1.4692  decode.d4.loss_cls: 1.2327  decode.d4.loss_mask: 0.8628  decode.d4.loss_dice: 1.4822  decode.d5.loss_cls: 1.3031  decode.d5.loss_mask: 0.8371  decode.d5.loss_dice: 1.4756  decode.d6.loss_cls: 1.2206  decode.d6.loss_mask: 0.8427  decode.d6.loss_dice: 1.4429  decode.d7.loss_cls: 1.2335  decode.d7.loss_mask: 0.7994  decode.d7.loss_dice: 1.4205  decode.d8.loss_cls: 1.1672  decode.d8.loss_mask: 0.8299  decode.d8.loss_dice: 1.4627
2023/05/24 11:28:21 - mmengine - INFO - Iter(train) [138700/160000]  lr: 1.6287e-06  eta: 2:33:50  time: 0.4229  data_time: 0.0098  memory: 4889  grad_norm: 89.5229  loss: 33.3586  decode.loss_cls: 1.2177  decode.loss_mask: 0.7254  decode.loss_dice: 1.0418  decode.d0.loss_cls: 3.0755  decode.d0.loss_mask: 0.8233  decode.d0.loss_dice: 1.2680  decode.d1.loss_cls: 1.3126  decode.d1.loss_mask: 0.8439  decode.d1.loss_dice: 1.2324  decode.d2.loss_cls: 1.3610  decode.d2.loss_mask: 0.8038  decode.d2.loss_dice: 1.1248  decode.d3.loss_cls: 1.3400  decode.d3.loss_mask: 0.7568  decode.d3.loss_dice: 1.0958  decode.d4.loss_cls: 1.2981  decode.d4.loss_mask: 0.7526  decode.d4.loss_dice: 1.0706  decode.d5.loss_cls: 1.2666  decode.d5.loss_mask: 0.7544  decode.d5.loss_dice: 1.0859  decode.d6.loss_cls: 1.2242  decode.d6.loss_mask: 0.7418  decode.d6.loss_dice: 1.0683  decode.d7.loss_cls: 1.2515  decode.d7.loss_mask: 0.7245  decode.d7.loss_dice: 1.0544  decode.d8.loss_cls: 1.2777  decode.d8.loss_mask: 0.7246  decode.d8.loss_dice: 1.0404
2023/05/24 11:28:42 - mmengine - INFO - Iter(train) [138750/160000]  lr: 1.6252e-06  eta: 2:33:28  time: 0.4331  data_time: 0.0103  memory: 4879  grad_norm: 88.6209  loss: 41.4604  decode.loss_cls: 1.2733  decode.loss_mask: 0.9372  decode.loss_dice: 1.6305  decode.d0.loss_cls: 3.3790  decode.d0.loss_mask: 0.9567  decode.d0.loss_dice: 1.9067  decode.d1.loss_cls: 1.2818  decode.d1.loss_mask: 0.9402  decode.d1.loss_dice: 1.8388  decode.d2.loss_cls: 1.3579  decode.d2.loss_mask: 0.9208  decode.d2.loss_dice: 1.7044  decode.d3.loss_cls: 1.2702  decode.d3.loss_mask: 0.9664  decode.d3.loss_dice: 1.6974  decode.d4.loss_cls: 1.2903  decode.d4.loss_mask: 0.9617  decode.d4.loss_dice: 1.6744  decode.d5.loss_cls: 1.2495  decode.d5.loss_mask: 0.9543  decode.d5.loss_dice: 1.6554  decode.d6.loss_cls: 1.2565  decode.d6.loss_mask: 0.9267  decode.d6.loss_dice: 1.6795  decode.d7.loss_cls: 1.2681  decode.d7.loss_mask: 0.9514  decode.d7.loss_dice: 1.6642  decode.d8.loss_cls: 1.2674  decode.d8.loss_mask: 0.9706  decode.d8.loss_dice: 1.6292
2023/05/24 11:29:04 - mmengine - INFO - Iter(train) [138800/160000]  lr: 1.6218e-06  eta: 2:33:06  time: 0.4250  data_time: 0.0099  memory: 4832  grad_norm: 95.6720  loss: 30.7711  decode.loss_cls: 1.0439  decode.loss_mask: 0.6691  decode.loss_dice: 1.0392  decode.d0.loss_cls: 3.0184  decode.d0.loss_mask: 0.7886  decode.d0.loss_dice: 1.3490  decode.d1.loss_cls: 1.1853  decode.d1.loss_mask: 0.7432  decode.d1.loss_dice: 1.2331  decode.d2.loss_cls: 1.1111  decode.d2.loss_mask: 0.6767  decode.d2.loss_dice: 1.1091  decode.d3.loss_cls: 1.0342  decode.d3.loss_mask: 0.6937  decode.d3.loss_dice: 1.0988  decode.d4.loss_cls: 1.0738  decode.d4.loss_mask: 0.6759  decode.d4.loss_dice: 1.0859  decode.d5.loss_cls: 1.0603  decode.d5.loss_mask: 0.6649  decode.d5.loss_dice: 1.0841  decode.d6.loss_cls: 1.0611  decode.d6.loss_mask: 0.6756  decode.d6.loss_dice: 1.0541  decode.d7.loss_cls: 1.0539  decode.d7.loss_mask: 0.6751  decode.d7.loss_dice: 1.0622  decode.d8.loss_cls: 1.0589  decode.d8.loss_mask: 0.6561  decode.d8.loss_dice: 1.0356
2023/05/24 11:29:26 - mmengine - INFO - Iter(train) [138850/160000]  lr: 1.6184e-06  eta: 2:32:45  time: 0.4277  data_time: 0.0102  memory: 4868  grad_norm: 90.9158  loss: 34.7996  decode.loss_cls: 1.1512  decode.loss_mask: 0.7760  decode.loss_dice: 1.2079  decode.d0.loss_cls: 3.3582  decode.d0.loss_mask: 0.8633  decode.d0.loss_dice: 1.4858  decode.d1.loss_cls: 1.3195  decode.d1.loss_mask: 0.8749  decode.d1.loss_dice: 1.4347  decode.d2.loss_cls: 1.2449  decode.d2.loss_mask: 0.8220  decode.d2.loss_dice: 1.2584  decode.d3.loss_cls: 1.2036  decode.d3.loss_mask: 0.7906  decode.d3.loss_dice: 1.2482  decode.d4.loss_cls: 1.1809  decode.d4.loss_mask: 0.7850  decode.d4.loss_dice: 1.2261  decode.d5.loss_cls: 1.1662  decode.d5.loss_mask: 0.7732  decode.d5.loss_dice: 1.2447  decode.d6.loss_cls: 1.1466  decode.d6.loss_mask: 0.7567  decode.d6.loss_dice: 1.2400  decode.d7.loss_cls: 1.1388  decode.d7.loss_mask: 0.7603  decode.d7.loss_dice: 1.1982  decode.d8.loss_cls: 1.1129  decode.d8.loss_mask: 0.7855  decode.d8.loss_dice: 1.2454
2023/05/24 11:29:47 - mmengine - INFO - Iter(train) [138900/160000]  lr: 1.6149e-06  eta: 2:32:23  time: 0.4246  data_time: 0.0098  memory: 4821  grad_norm: 97.0242  loss: 28.5997  decode.loss_cls: 0.8730  decode.loss_mask: 0.6966  decode.loss_dice: 1.0372  decode.d0.loss_cls: 2.5751  decode.d0.loss_mask: 0.7272  decode.d0.loss_dice: 1.1884  decode.d1.loss_cls: 1.0364  decode.d1.loss_mask: 0.7528  decode.d1.loss_dice: 1.1261  decode.d2.loss_cls: 0.9316  decode.d2.loss_mask: 0.7239  decode.d2.loss_dice: 1.0878  decode.d3.loss_cls: 0.9453  decode.d3.loss_mask: 0.6994  decode.d3.loss_dice: 1.0662  decode.d4.loss_cls: 0.9371  decode.d4.loss_mask: 0.7196  decode.d4.loss_dice: 1.0591  decode.d5.loss_cls: 0.8855  decode.d5.loss_mask: 0.6911  decode.d5.loss_dice: 1.0708  decode.d6.loss_cls: 0.8859  decode.d6.loss_mask: 0.6847  decode.d6.loss_dice: 1.0243  decode.d7.loss_cls: 0.8962  decode.d7.loss_mask: 0.6714  decode.d7.loss_dice: 1.0082  decode.d8.loss_cls: 0.8857  decode.d8.loss_mask: 0.6836  decode.d8.loss_dice: 1.0294
2023/05/24 11:30:09 - mmengine - INFO - Iter(train) [138950/160000]  lr: 1.6115e-06  eta: 2:32:01  time: 0.4380  data_time: 0.0108  memory: 4871  grad_norm: 86.2668  loss: 36.3297  decode.loss_cls: 1.1379  decode.loss_mask: 0.7904  decode.loss_dice: 1.4056  decode.d0.loss_cls: 3.1972  decode.d0.loss_mask: 0.8177  decode.d0.loss_dice: 1.5917  decode.d1.loss_cls: 1.1973  decode.d1.loss_mask: 0.8223  decode.d1.loss_dice: 1.5509  decode.d2.loss_cls: 1.1683  decode.d2.loss_mask: 0.8235  decode.d2.loss_dice: 1.4878  decode.d3.loss_cls: 1.1598  decode.d3.loss_mask: 0.7983  decode.d3.loss_dice: 1.4676  decode.d4.loss_cls: 1.1567  decode.d4.loss_mask: 0.7871  decode.d4.loss_dice: 1.4366  decode.d5.loss_cls: 1.1750  decode.d5.loss_mask: 0.8081  decode.d5.loss_dice: 1.4061  decode.d6.loss_cls: 1.2393  decode.d6.loss_mask: 0.7992  decode.d6.loss_dice: 1.3997  decode.d7.loss_cls: 1.1054  decode.d7.loss_mask: 0.8259  decode.d7.loss_dice: 1.4435  decode.d8.loss_cls: 1.1342  decode.d8.loss_mask: 0.7825  decode.d8.loss_dice: 1.4141
2023/05/24 11:30:30 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 11:30:30 - mmengine - INFO - Iter(train) [139000/160000]  lr: 1.6080e-06  eta: 2:31:40  time: 0.4383  data_time: 0.0101  memory: 4847  grad_norm: 86.8950  loss: 34.4892  decode.loss_cls: 1.0338  decode.loss_mask: 0.6878  decode.loss_dice: 1.3868  decode.d0.loss_cls: 3.2243  decode.d0.loss_mask: 0.7240  decode.d0.loss_dice: 1.6335  decode.d1.loss_cls: 1.2641  decode.d1.loss_mask: 0.6827  decode.d1.loss_dice: 1.5125  decode.d2.loss_cls: 1.1674  decode.d2.loss_mask: 0.6757  decode.d2.loss_dice: 1.3836  decode.d3.loss_cls: 1.1329  decode.d3.loss_mask: 0.6733  decode.d3.loss_dice: 1.3741  decode.d4.loss_cls: 1.1613  decode.d4.loss_mask: 0.6671  decode.d4.loss_dice: 1.3876  decode.d5.loss_cls: 1.1252  decode.d5.loss_mask: 0.6682  decode.d5.loss_dice: 1.4116  decode.d6.loss_cls: 1.0695  decode.d6.loss_mask: 0.6971  decode.d6.loss_dice: 1.4288  decode.d7.loss_cls: 1.0480  decode.d7.loss_mask: 0.6938  decode.d7.loss_dice: 1.4366  decode.d8.loss_cls: 1.0678  decode.d8.loss_mask: 0.6844  decode.d8.loss_dice: 1.3856
2023/05/24 11:30:30 - mmengine - INFO - Saving checkpoint at 139000 iterations
2023/05/24 11:30:56 - mmengine - INFO - Iter(train) [139050/160000]  lr: 1.6046e-06  eta: 2:31:19  time: 0.4204  data_time: 0.0099  memory: 4879  grad_norm: 101.8953  loss: 40.4440  decode.loss_cls: 1.3146  decode.loss_mask: 0.7044  decode.loss_dice: 1.7708  decode.d0.loss_cls: 3.1282  decode.d0.loss_mask: 0.7412  decode.d0.loss_dice: 2.0319  decode.d1.loss_cls: 1.5469  decode.d1.loss_mask: 0.6996  decode.d1.loss_dice: 1.8793  decode.d2.loss_cls: 1.4161  decode.d2.loss_mask: 0.6989  decode.d2.loss_dice: 1.8088  decode.d3.loss_cls: 1.3454  decode.d3.loss_mask: 0.7124  decode.d3.loss_dice: 1.7531  decode.d4.loss_cls: 1.3378  decode.d4.loss_mask: 0.7135  decode.d4.loss_dice: 1.7705  decode.d5.loss_cls: 1.2886  decode.d5.loss_mask: 0.7121  decode.d5.loss_dice: 1.7918  decode.d6.loss_cls: 1.2864  decode.d6.loss_mask: 0.7280  decode.d6.loss_dice: 1.7611  decode.d7.loss_cls: 1.3140  decode.d7.loss_mask: 0.7123  decode.d7.loss_dice: 1.7554  decode.d8.loss_cls: 1.2358  decode.d8.loss_mask: 0.7028  decode.d8.loss_dice: 1.7824
2023/05/24 11:31:18 - mmengine - INFO - Iter(train) [139100/160000]  lr: 1.6011e-06  eta: 2:30:57  time: 0.4216  data_time: 0.0099  memory: 4865  grad_norm: 113.5159  loss: 37.5766  decode.loss_cls: 1.1808  decode.loss_mask: 0.8071  decode.loss_dice: 1.3968  decode.d0.loss_cls: 3.2817  decode.d0.loss_mask: 0.8639  decode.d0.loss_dice: 1.7111  decode.d1.loss_cls: 1.3756  decode.d1.loss_mask: 0.8483  decode.d1.loss_dice: 1.5794  decode.d2.loss_cls: 1.2650  decode.d2.loss_mask: 0.8534  decode.d2.loss_dice: 1.4860  decode.d3.loss_cls: 1.2397  decode.d3.loss_mask: 0.8333  decode.d3.loss_dice: 1.4813  decode.d4.loss_cls: 1.2720  decode.d4.loss_mask: 0.8201  decode.d4.loss_dice: 1.4622  decode.d5.loss_cls: 1.2014  decode.d5.loss_mask: 0.8198  decode.d5.loss_dice: 1.4546  decode.d6.loss_cls: 1.2459  decode.d6.loss_mask: 0.8140  decode.d6.loss_dice: 1.4058  decode.d7.loss_cls: 1.1883  decode.d7.loss_mask: 0.8127  decode.d7.loss_dice: 1.4406  decode.d8.loss_cls: 1.1872  decode.d8.loss_mask: 0.8182  decode.d8.loss_dice: 1.4304
2023/05/24 11:31:39 - mmengine - INFO - Iter(train) [139150/160000]  lr: 1.5977e-06  eta: 2:30:35  time: 0.4211  data_time: 0.0097  memory: 4871  grad_norm: 102.1840  loss: 35.3141  decode.loss_cls: 1.2436  decode.loss_mask: 0.7731  decode.loss_dice: 1.2701  decode.d0.loss_cls: 2.9178  decode.d0.loss_mask: 0.8187  decode.d0.loss_dice: 1.4861  decode.d1.loss_cls: 1.3900  decode.d1.loss_mask: 0.7798  decode.d1.loss_dice: 1.3686  decode.d2.loss_cls: 1.2516  decode.d2.loss_mask: 0.7719  decode.d2.loss_dice: 1.3581  decode.d3.loss_cls: 1.2555  decode.d3.loss_mask: 0.7534  decode.d3.loss_dice: 1.2754  decode.d4.loss_cls: 1.2784  decode.d4.loss_mask: 0.7695  decode.d4.loss_dice: 1.2980  decode.d5.loss_cls: 1.2673  decode.d5.loss_mask: 0.7563  decode.d5.loss_dice: 1.2783  decode.d6.loss_cls: 1.2876  decode.d6.loss_mask: 0.7679  decode.d6.loss_dice: 1.2868  decode.d7.loss_cls: 1.2760  decode.d7.loss_mask: 0.7676  decode.d7.loss_dice: 1.2880  decode.d8.loss_cls: 1.2318  decode.d8.loss_mask: 0.7577  decode.d8.loss_dice: 1.2893
2023/05/24 11:32:02 - mmengine - INFO - Iter(train) [139200/160000]  lr: 1.5942e-06  eta: 2:30:14  time: 0.4433  data_time: 0.0101  memory: 4792  grad_norm: 104.3140  loss: 30.1071  decode.loss_cls: 1.0030  decode.loss_mask: 0.6897  decode.loss_dice: 1.0526  decode.d0.loss_cls: 2.9669  decode.d0.loss_mask: 0.8414  decode.d0.loss_dice: 1.2036  decode.d1.loss_cls: 1.1178  decode.d1.loss_mask: 0.7604  decode.d1.loss_dice: 1.1567  decode.d2.loss_cls: 1.0414  decode.d2.loss_mask: 0.7258  decode.d2.loss_dice: 1.0619  decode.d3.loss_cls: 0.9996  decode.d3.loss_mask: 0.7010  decode.d3.loss_dice: 1.0500  decode.d4.loss_cls: 0.9642  decode.d4.loss_mask: 0.7277  decode.d4.loss_dice: 1.0753  decode.d5.loss_cls: 0.9511  decode.d5.loss_mask: 0.7140  decode.d5.loss_dice: 1.0643  decode.d6.loss_cls: 0.9686  decode.d6.loss_mask: 0.7203  decode.d6.loss_dice: 1.0602  decode.d7.loss_cls: 1.0065  decode.d7.loss_mask: 0.7051  decode.d7.loss_dice: 1.0433  decode.d8.loss_cls: 0.9642  decode.d8.loss_mask: 0.7065  decode.d8.loss_dice: 1.0640
2023/05/24 11:32:23 - mmengine - INFO - Iter(train) [139250/160000]  lr: 1.5908e-06  eta: 2:29:52  time: 0.4201  data_time: 0.0100  memory: 4805  grad_norm: 87.5845  loss: 20.3446  decode.loss_cls: 0.6656  decode.loss_mask: 0.5230  decode.loss_dice: 0.5930  decode.d0.loss_cls: 2.3246  decode.d0.loss_mask: 0.5890  decode.d0.loss_dice: 0.6778  decode.d1.loss_cls: 0.7397  decode.d1.loss_mask: 0.5771  decode.d1.loss_dice: 0.6797  decode.d2.loss_cls: 0.6916  decode.d2.loss_mask: 0.5734  decode.d2.loss_dice: 0.6742  decode.d3.loss_cls: 0.6577  decode.d3.loss_mask: 0.5520  decode.d3.loss_dice: 0.6254  decode.d4.loss_cls: 0.6843  decode.d4.loss_mask: 0.5479  decode.d4.loss_dice: 0.6451  decode.d5.loss_cls: 0.6939  decode.d5.loss_mask: 0.5576  decode.d5.loss_dice: 0.6259  decode.d6.loss_cls: 0.6836  decode.d6.loss_mask: 0.5454  decode.d6.loss_dice: 0.6096  decode.d7.loss_cls: 0.6876  decode.d7.loss_mask: 0.5247  decode.d7.loss_dice: 0.6030  decode.d8.loss_cls: 0.6693  decode.d8.loss_mask: 0.5229  decode.d8.loss_dice: 0.5997
2023/05/24 11:32:45 - mmengine - INFO - Iter(train) [139300/160000]  lr: 1.5873e-06  eta: 2:29:30  time: 0.4197  data_time: 0.0099  memory: 4824  grad_norm: 90.6679  loss: 33.4520  decode.loss_cls: 1.1154  decode.loss_mask: 0.6861  decode.loss_dice: 1.1680  decode.d0.loss_cls: 3.3508  decode.d0.loss_mask: 0.7687  decode.d0.loss_dice: 1.3513  decode.d1.loss_cls: 1.2105  decode.d1.loss_mask: 0.7469  decode.d1.loss_dice: 1.3495  decode.d2.loss_cls: 1.2023  decode.d2.loss_mask: 0.7194  decode.d2.loss_dice: 1.2944  decode.d3.loss_cls: 1.1424  decode.d3.loss_mask: 0.7194  decode.d3.loss_dice: 1.2881  decode.d4.loss_cls: 1.1694  decode.d4.loss_mask: 0.7106  decode.d4.loss_dice: 1.2557  decode.d5.loss_cls: 1.1681  decode.d5.loss_mask: 0.6944  decode.d5.loss_dice: 1.2160  decode.d6.loss_cls: 1.1513  decode.d6.loss_mask: 0.6956  decode.d6.loss_dice: 1.2146  decode.d7.loss_cls: 1.1278  decode.d7.loss_mask: 0.6855  decode.d7.loss_dice: 1.2054  decode.d8.loss_cls: 1.1597  decode.d8.loss_mask: 0.6786  decode.d8.loss_dice: 1.2060
2023/05/24 11:33:06 - mmengine - INFO - Iter(train) [139350/160000]  lr: 1.5839e-06  eta: 2:29:08  time: 0.4229  data_time: 0.0100  memory: 4857  grad_norm: 94.5343  loss: 26.3487  decode.loss_cls: 0.9132  decode.loss_mask: 0.6373  decode.loss_dice: 0.8445  decode.d0.loss_cls: 2.8782  decode.d0.loss_mask: 0.6590  decode.d0.loss_dice: 0.9636  decode.d1.loss_cls: 1.0910  decode.d1.loss_mask: 0.6142  decode.d1.loss_dice: 0.9437  decode.d2.loss_cls: 0.9005  decode.d2.loss_mask: 0.6532  decode.d2.loss_dice: 0.8776  decode.d3.loss_cls: 0.9491  decode.d3.loss_mask: 0.6635  decode.d3.loss_dice: 0.8550  decode.d4.loss_cls: 0.9195  decode.d4.loss_mask: 0.6533  decode.d4.loss_dice: 0.8507  decode.d5.loss_cls: 0.8737  decode.d5.loss_mask: 0.6725  decode.d5.loss_dice: 0.8462  decode.d6.loss_cls: 0.8822  decode.d6.loss_mask: 0.6385  decode.d6.loss_dice: 0.8551  decode.d7.loss_cls: 0.9144  decode.d7.loss_mask: 0.6377  decode.d7.loss_dice: 0.8338  decode.d8.loss_cls: 0.8581  decode.d8.loss_mask: 0.6314  decode.d8.loss_dice: 0.8377
2023/05/24 11:33:28 - mmengine - INFO - Iter(train) [139400/160000]  lr: 1.5804e-06  eta: 2:28:47  time: 0.4265  data_time: 0.0101  memory: 4856  grad_norm: 87.2666  loss: 32.0710  decode.loss_cls: 1.1003  decode.loss_mask: 0.6638  decode.loss_dice: 1.1542  decode.d0.loss_cls: 3.0955  decode.d0.loss_mask: 0.7526  decode.d0.loss_dice: 1.4041  decode.d1.loss_cls: 1.2644  decode.d1.loss_mask: 0.7276  decode.d1.loss_dice: 1.2853  decode.d2.loss_cls: 1.0333  decode.d2.loss_mask: 0.7253  decode.d2.loss_dice: 1.2630  decode.d3.loss_cls: 1.0940  decode.d3.loss_mask: 0.6811  decode.d3.loss_dice: 1.2271  decode.d4.loss_cls: 1.0064  decode.d4.loss_mask: 0.6858  decode.d4.loss_dice: 1.2365  decode.d5.loss_cls: 1.0733  decode.d5.loss_mask: 0.6769  decode.d5.loss_dice: 1.2032  decode.d6.loss_cls: 1.0619  decode.d6.loss_mask: 0.6660  decode.d6.loss_dice: 1.2023  decode.d7.loss_cls: 1.0389  decode.d7.loss_mask: 0.6589  decode.d7.loss_dice: 1.1833  decode.d8.loss_cls: 1.0430  decode.d8.loss_mask: 0.6723  decode.d8.loss_dice: 1.1908
2023/05/24 11:33:50 - mmengine - INFO - Iter(train) [139450/160000]  lr: 1.5770e-06  eta: 2:28:25  time: 0.4227  data_time: 0.0099  memory: 4886  grad_norm: 108.4940  loss: 35.7511  decode.loss_cls: 1.0996  decode.loss_mask: 0.7511  decode.loss_dice: 1.3948  decode.d0.loss_cls: 3.1135  decode.d0.loss_mask: 0.7732  decode.d0.loss_dice: 1.6410  decode.d1.loss_cls: 1.2065  decode.d1.loss_mask: 0.8015  decode.d1.loss_dice: 1.5926  decode.d2.loss_cls: 1.1427  decode.d2.loss_mask: 0.7919  decode.d2.loss_dice: 1.5357  decode.d3.loss_cls: 1.1009  decode.d3.loss_mask: 0.7875  decode.d3.loss_dice: 1.5204  decode.d4.loss_cls: 1.1127  decode.d4.loss_mask: 0.7775  decode.d4.loss_dice: 1.4926  decode.d5.loss_cls: 1.1115  decode.d5.loss_mask: 0.7468  decode.d5.loss_dice: 1.4701  decode.d6.loss_cls: 1.1039  decode.d6.loss_mask: 0.7511  decode.d6.loss_dice: 1.4277  decode.d7.loss_cls: 1.0665  decode.d7.loss_mask: 0.7589  decode.d7.loss_dice: 1.4169  decode.d8.loss_cls: 1.0798  decode.d8.loss_mask: 0.7490  decode.d8.loss_dice: 1.4329
2023/05/24 11:34:11 - mmengine - INFO - Iter(train) [139500/160000]  lr: 1.5735e-06  eta: 2:28:03  time: 0.4178  data_time: 0.0096  memory: 4919  grad_norm: 116.4528  loss: 35.1584  decode.loss_cls: 1.1777  decode.loss_mask: 0.7594  decode.loss_dice: 1.3463  decode.d0.loss_cls: 3.0453  decode.d0.loss_mask: 0.7834  decode.d0.loss_dice: 1.5187  decode.d1.loss_cls: 1.2606  decode.d1.loss_mask: 0.7896  decode.d1.loss_dice: 1.4361  decode.d2.loss_cls: 1.2285  decode.d2.loss_mask: 0.7510  decode.d2.loss_dice: 1.3794  decode.d3.loss_cls: 1.2025  decode.d3.loss_mask: 0.7676  decode.d3.loss_dice: 1.3352  decode.d4.loss_cls: 1.1638  decode.d4.loss_mask: 0.7483  decode.d4.loss_dice: 1.3497  decode.d5.loss_cls: 1.1943  decode.d5.loss_mask: 0.7436  decode.d5.loss_dice: 1.3853  decode.d6.loss_cls: 1.1861  decode.d6.loss_mask: 0.7518  decode.d6.loss_dice: 1.3536  decode.d7.loss_cls: 1.2040  decode.d7.loss_mask: 0.7420  decode.d7.loss_dice: 1.3341  decode.d8.loss_cls: 1.1872  decode.d8.loss_mask: 0.7380  decode.d8.loss_dice: 1.2954
2023/05/24 11:34:33 - mmengine - INFO - Iter(train) [139550/160000]  lr: 1.5701e-06  eta: 2:27:42  time: 0.4249  data_time: 0.0099  memory: 4855  grad_norm: 98.7309  loss: 41.6604  decode.loss_cls: 1.3966  decode.loss_mask: 0.7985  decode.loss_dice: 1.6420  decode.d0.loss_cls: 3.3361  decode.d0.loss_mask: 0.8955  decode.d0.loss_dice: 1.9328  decode.d1.loss_cls: 1.6239  decode.d1.loss_mask: 0.8297  decode.d1.loss_dice: 1.7894  decode.d2.loss_cls: 1.4953  decode.d2.loss_mask: 0.8446  decode.d2.loss_dice: 1.6934  decode.d3.loss_cls: 1.4263  decode.d3.loss_mask: 0.8216  decode.d3.loss_dice: 1.6917  decode.d4.loss_cls: 1.4184  decode.d4.loss_mask: 0.8096  decode.d4.loss_dice: 1.6787  decode.d5.loss_cls: 1.4386  decode.d5.loss_mask: 0.7950  decode.d5.loss_dice: 1.6762  decode.d6.loss_cls: 1.3787  decode.d6.loss_mask: 0.8042  decode.d6.loss_dice: 1.6719  decode.d7.loss_cls: 1.3961  decode.d7.loss_mask: 0.8056  decode.d7.loss_dice: 1.6689  decode.d8.loss_cls: 1.4582  decode.d8.loss_mask: 0.8025  decode.d8.loss_dice: 1.6405
2023/05/24 11:34:54 - mmengine - INFO - Iter(train) [139600/160000]  lr: 1.5666e-06  eta: 2:27:20  time: 0.4281  data_time: 0.0099  memory: 4891  grad_norm: 117.4904  loss: 28.9762  decode.loss_cls: 1.0109  decode.loss_mask: 0.5704  decode.loss_dice: 1.0500  decode.d0.loss_cls: 2.8022  decode.d0.loss_mask: 0.6816  decode.d0.loss_dice: 1.3221  decode.d1.loss_cls: 1.0788  decode.d1.loss_mask: 0.5967  decode.d1.loss_dice: 1.2095  decode.d2.loss_cls: 1.0017  decode.d2.loss_mask: 0.5949  decode.d2.loss_dice: 1.1169  decode.d3.loss_cls: 1.0128  decode.d3.loss_mask: 0.5818  decode.d3.loss_dice: 1.0881  decode.d4.loss_cls: 0.9899  decode.d4.loss_mask: 0.5741  decode.d4.loss_dice: 1.0940  decode.d5.loss_cls: 0.9563  decode.d5.loss_mask: 0.5923  decode.d5.loss_dice: 1.1036  decode.d6.loss_cls: 0.9921  decode.d6.loss_mask: 0.5918  decode.d6.loss_dice: 1.0784  decode.d7.loss_cls: 1.0283  decode.d7.loss_mask: 0.5871  decode.d7.loss_dice: 1.0605  decode.d8.loss_cls: 0.9826  decode.d8.loss_mask: 0.5732  decode.d8.loss_dice: 1.0535
2023/05/24 11:35:16 - mmengine - INFO - Iter(train) [139650/160000]  lr: 1.5632e-06  eta: 2:26:58  time: 0.4380  data_time: 0.0099  memory: 4829  grad_norm: 94.3660  loss: 31.2534  decode.loss_cls: 1.1486  decode.loss_mask: 0.6429  decode.loss_dice: 1.0235  decode.d0.loss_cls: 2.8546  decode.d0.loss_mask: 0.7318  decode.d0.loss_dice: 1.2250  decode.d1.loss_cls: 1.3073  decode.d1.loss_mask: 0.6832  decode.d1.loss_dice: 1.1784  decode.d2.loss_cls: 1.2531  decode.d2.loss_mask: 0.6381  decode.d2.loss_dice: 1.0725  decode.d3.loss_cls: 1.2437  decode.d3.loss_mask: 0.6138  decode.d3.loss_dice: 1.0740  decode.d4.loss_cls: 1.1874  decode.d4.loss_mask: 0.6610  decode.d4.loss_dice: 1.1084  decode.d5.loss_cls: 1.1991  decode.d5.loss_mask: 0.6717  decode.d5.loss_dice: 1.0682  decode.d6.loss_cls: 1.2204  decode.d6.loss_mask: 0.6428  decode.d6.loss_dice: 1.0488  decode.d7.loss_cls: 1.1726  decode.d7.loss_mask: 0.6424  decode.d7.loss_dice: 1.0303  decode.d8.loss_cls: 1.2568  decode.d8.loss_mask: 0.6163  decode.d8.loss_dice: 1.0365
2023/05/24 11:35:38 - mmengine - INFO - Iter(train) [139700/160000]  lr: 1.5597e-06  eta: 2:26:37  time: 0.4286  data_time: 0.0101  memory: 4858  grad_norm: 87.1276  loss: 37.3309  decode.loss_cls: 1.2373  decode.loss_mask: 0.8726  decode.loss_dice: 1.2683  decode.d0.loss_cls: 3.1573  decode.d0.loss_mask: 1.0567  decode.d0.loss_dice: 1.5670  decode.d1.loss_cls: 1.3944  decode.d1.loss_mask: 1.0278  decode.d1.loss_dice: 1.3662  decode.d2.loss_cls: 1.3747  decode.d2.loss_mask: 0.9365  decode.d2.loss_dice: 1.3656  decode.d3.loss_cls: 1.3105  decode.d3.loss_mask: 0.9129  decode.d3.loss_dice: 1.3318  decode.d4.loss_cls: 1.2321  decode.d4.loss_mask: 0.9292  decode.d4.loss_dice: 1.3258  decode.d5.loss_cls: 1.2146  decode.d5.loss_mask: 0.9147  decode.d5.loss_dice: 1.3171  decode.d6.loss_cls: 1.2004  decode.d6.loss_mask: 0.9256  decode.d6.loss_dice: 1.3029  decode.d7.loss_cls: 1.2110  decode.d7.loss_mask: 0.9052  decode.d7.loss_dice: 1.2958  decode.d8.loss_cls: 1.1941  decode.d8.loss_mask: 0.9032  decode.d8.loss_dice: 1.2796
2023/05/24 11:35:59 - mmengine - INFO - Iter(train) [139750/160000]  lr: 1.5562e-06  eta: 2:26:15  time: 0.4345  data_time: 0.0101  memory: 4859  grad_norm: 89.6028  loss: 35.4308  decode.loss_cls: 1.1313  decode.loss_mask: 0.8640  decode.loss_dice: 1.2230  decode.d0.loss_cls: 3.3701  decode.d0.loss_mask: 0.8928  decode.d0.loss_dice: 1.5219  decode.d1.loss_cls: 1.3174  decode.d1.loss_mask: 0.9286  decode.d1.loss_dice: 1.3370  decode.d2.loss_cls: 1.2311  decode.d2.loss_mask: 0.8679  decode.d2.loss_dice: 1.2944  decode.d3.loss_cls: 1.1835  decode.d3.loss_mask: 0.8400  decode.d3.loss_dice: 1.2754  decode.d4.loss_cls: 1.1124  decode.d4.loss_mask: 0.8602  decode.d4.loss_dice: 1.2645  decode.d5.loss_cls: 1.1830  decode.d5.loss_mask: 0.8471  decode.d5.loss_dice: 1.2592  decode.d6.loss_cls: 1.1550  decode.d6.loss_mask: 0.8266  decode.d6.loss_dice: 1.2108  decode.d7.loss_cls: 1.1849  decode.d7.loss_mask: 0.8399  decode.d7.loss_dice: 1.2172  decode.d8.loss_cls: 1.0947  decode.d8.loss_mask: 0.8609  decode.d8.loss_dice: 1.2359
2023/05/24 11:36:20 - mmengine - INFO - Iter(train) [139800/160000]  lr: 1.5528e-06  eta: 2:25:53  time: 0.4304  data_time: 0.0103  memory: 4837  grad_norm: 92.8308  loss: 38.2892  decode.loss_cls: 1.3401  decode.loss_mask: 0.7240  decode.loss_dice: 1.5284  decode.d0.loss_cls: 3.1825  decode.d0.loss_mask: 0.7516  decode.d0.loss_dice: 1.7281  decode.d1.loss_cls: 1.4458  decode.d1.loss_mask: 0.7486  decode.d1.loss_dice: 1.5938  decode.d2.loss_cls: 1.3973  decode.d2.loss_mask: 0.7384  decode.d2.loss_dice: 1.5517  decode.d3.loss_cls: 1.4156  decode.d3.loss_mask: 0.7148  decode.d3.loss_dice: 1.5039  decode.d4.loss_cls: 1.4150  decode.d4.loss_mask: 0.7097  decode.d4.loss_dice: 1.4917  decode.d5.loss_cls: 1.3850  decode.d5.loss_mask: 0.7095  decode.d5.loss_dice: 1.4884  decode.d6.loss_cls: 1.3676  decode.d6.loss_mask: 0.7232  decode.d6.loss_dice: 1.5033  decode.d7.loss_cls: 1.3645  decode.d7.loss_mask: 0.7038  decode.d7.loss_dice: 1.5053  decode.d8.loss_cls: 1.3397  decode.d8.loss_mask: 0.7082  decode.d8.loss_dice: 1.5096
2023/05/24 11:36:42 - mmengine - INFO - Iter(train) [139850/160000]  lr: 1.5493e-06  eta: 2:25:32  time: 0.4222  data_time: 0.0098  memory: 4894  grad_norm: 106.2367  loss: 29.4826  decode.loss_cls: 1.0344  decode.loss_mask: 0.6484  decode.loss_dice: 0.9964  decode.d0.loss_cls: 2.9125  decode.d0.loss_mask: 0.7366  decode.d0.loss_dice: 1.2120  decode.d1.loss_cls: 1.1159  decode.d1.loss_mask: 0.6937  decode.d1.loss_dice: 1.1412  decode.d2.loss_cls: 1.1020  decode.d2.loss_mask: 0.6676  decode.d2.loss_dice: 1.0609  decode.d3.loss_cls: 1.0773  decode.d3.loss_mask: 0.6249  decode.d3.loss_dice: 0.9903  decode.d4.loss_cls: 1.0511  decode.d4.loss_mask: 0.6283  decode.d4.loss_dice: 1.0204  decode.d5.loss_cls: 1.0495  decode.d5.loss_mask: 0.6633  decode.d5.loss_dice: 1.0291  decode.d6.loss_cls: 1.0753  decode.d6.loss_mask: 0.6399  decode.d6.loss_dice: 0.9869  decode.d7.loss_cls: 1.0503  decode.d7.loss_mask: 0.6378  decode.d7.loss_dice: 0.9936  decode.d8.loss_cls: 1.0037  decode.d8.loss_mask: 0.6401  decode.d8.loss_dice: 0.9991
2023/05/24 11:37:03 - mmengine - INFO - Iter(train) [139900/160000]  lr: 1.5459e-06  eta: 2:25:10  time: 0.4297  data_time: 0.0105  memory: 4972  grad_norm: 121.4878  loss: 32.5928  decode.loss_cls: 0.9119  decode.loss_mask: 0.7477  decode.loss_dice: 1.3321  decode.d0.loss_cls: 2.9356  decode.d0.loss_mask: 0.7947  decode.d0.loss_dice: 1.4953  decode.d1.loss_cls: 1.1144  decode.d1.loss_mask: 0.7222  decode.d1.loss_dice: 1.4520  decode.d2.loss_cls: 0.9245  decode.d2.loss_mask: 0.7404  decode.d2.loss_dice: 1.4180  decode.d3.loss_cls: 0.8929  decode.d3.loss_mask: 0.7662  decode.d3.loss_dice: 1.3330  decode.d4.loss_cls: 0.8805  decode.d4.loss_mask: 0.7507  decode.d4.loss_dice: 1.3433  decode.d5.loss_cls: 0.8561  decode.d5.loss_mask: 0.7703  decode.d5.loss_dice: 1.3883  decode.d6.loss_cls: 0.9158  decode.d6.loss_mask: 0.7625  decode.d6.loss_dice: 1.3448  decode.d7.loss_cls: 0.9029  decode.d7.loss_mask: 0.7560  decode.d7.loss_dice: 1.3335  decode.d8.loss_cls: 0.8801  decode.d8.loss_mask: 0.7486  decode.d8.loss_dice: 1.3785
2023/05/24 11:37:24 - mmengine - INFO - Iter(train) [139950/160000]  lr: 1.5424e-06  eta: 2:24:48  time: 0.4234  data_time: 0.0099  memory: 4832  grad_norm: 89.0335  loss: 31.9683  decode.loss_cls: 1.1030  decode.loss_mask: 0.7719  decode.loss_dice: 1.0731  decode.d0.loss_cls: 2.8337  decode.d0.loss_mask: 0.9101  decode.d0.loss_dice: 1.2903  decode.d1.loss_cls: 1.2223  decode.d1.loss_mask: 0.8284  decode.d1.loss_dice: 1.1838  decode.d2.loss_cls: 1.1580  decode.d2.loss_mask: 0.7763  decode.d2.loss_dice: 1.1181  decode.d3.loss_cls: 1.0881  decode.d3.loss_mask: 0.7463  decode.d3.loss_dice: 1.0982  decode.d4.loss_cls: 1.0887  decode.d4.loss_mask: 0.7621  decode.d4.loss_dice: 1.0908  decode.d5.loss_cls: 1.1490  decode.d5.loss_mask: 0.7547  decode.d5.loss_dice: 1.0791  decode.d6.loss_cls: 1.1112  decode.d6.loss_mask: 0.7647  decode.d6.loss_dice: 1.0799  decode.d7.loss_cls: 1.0892  decode.d7.loss_mask: 0.7573  decode.d7.loss_dice: 1.0867  decode.d8.loss_cls: 1.1131  decode.d8.loss_mask: 0.7685  decode.d8.loss_dice: 1.0717
2023/05/24 11:37:46 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 11:37:46 - mmengine - INFO - Iter(train) [140000/160000]  lr: 1.5389e-06  eta: 2:24:26  time: 0.4353  data_time: 0.0098  memory: 4877  grad_norm: 99.1876  loss: 49.8814  decode.loss_cls: 1.6905  decode.loss_mask: 0.8952  decode.loss_dice: 2.0306  decode.d0.loss_cls: 3.8443  decode.d0.loss_mask: 0.9782  decode.d0.loss_dice: 2.4560  decode.d1.loss_cls: 1.8382  decode.d1.loss_mask: 0.9485  decode.d1.loss_dice: 2.2742  decode.d2.loss_cls: 1.8402  decode.d2.loss_mask: 0.9311  decode.d2.loss_dice: 2.2009  decode.d3.loss_cls: 1.7789  decode.d3.loss_mask: 0.9307  decode.d3.loss_dice: 2.0973  decode.d4.loss_cls: 1.6879  decode.d4.loss_mask: 0.9119  decode.d4.loss_dice: 2.1380  decode.d5.loss_cls: 1.6673  decode.d5.loss_mask: 0.8892  decode.d5.loss_dice: 2.0372  decode.d6.loss_cls: 1.7236  decode.d6.loss_mask: 0.9006  decode.d6.loss_dice: 2.0142  decode.d7.loss_cls: 1.6386  decode.d7.loss_mask: 0.9043  decode.d7.loss_dice: 2.0656  decode.d8.loss_cls: 1.6264  decode.d8.loss_mask: 0.8942  decode.d8.loss_dice: 2.0476
2023/05/24 11:37:46 - mmengine - INFO - Saving checkpoint at 140000 iterations
2023/05/24 11:37:57 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:48  time: 0.0907  data_time: 0.0020  memory: 2167  
2023/05/24 11:38:01 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0795  data_time: 0.0018  memory: 2216  
2023/05/24 11:38:05 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:38  time: 0.0785  data_time: 0.0017  memory: 2167  
2023/05/24 11:38:09 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.1010  data_time: 0.0019  memory: 2104  
2023/05/24 11:38:13 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0796  data_time: 0.0017  memory: 2831  
2023/05/24 11:38:17 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:27  time: 0.0842  data_time: 0.0021  memory: 2167  
2023/05/24 11:38:21 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0797  data_time: 0.0019  memory: 2167  
2023/05/24 11:38:26 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0955  data_time: 0.0019  memory: 2167  
2023/05/24 11:38:31 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0948  data_time: 0.0018  memory: 2944  
2023/05/24 11:38:36 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.1025  data_time: 0.0020  memory: 2356  
2023/05/24 11:38:42 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0809  data_time: 0.0017  memory: 2217  
2023/05/24 11:38:46 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0795  data_time: 0.0017  memory: 2328  
2023/05/24 11:38:50 - mmengine - INFO - per class results:
2023/05/24 11:38:50 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.44 | 94.21 |
|     bicycle      | 71.51 | 82.86 |
|       car        | 60.99 | 85.59 |
|    motorcycle    | 83.22 | 90.13 |
|     airplane     | 85.75 | 92.86 |
|       bus        | 82.76 | 88.27 |
|      train       | 83.36 | 94.17 |
|      truck       | 55.18 | 73.36 |
|       boat       | 62.44 | 80.04 |
|  traffic light   | 68.75 | 84.85 |
|   fire hydrant   | 88.34 | 95.44 |
|    stop sign     | 91.16 | 97.02 |
|  parking meter   | 76.14 | 86.12 |
|      bench       | 48.64 | 70.64 |
|       bird       | 79.69 | 91.42 |
|       cat        | 84.97 | 91.63 |
|       dog        | 81.45 |  87.9 |
|      horse       | 78.03 | 90.03 |
|      sheep       | 85.38 | 91.55 |
|       cow        | 80.42 | 89.18 |
|     elephant     |  89.3 | 95.05 |
|       bear       | 92.61 | 95.36 |
|      zebra       | 90.34 |  93.7 |
|     giraffe      | 87.57 | 93.99 |
|     backpack     |  37.7 | 61.39 |
|     umbrella     | 80.71 | 88.06 |
|     handbag      | 36.63 | 55.65 |
|       tie        | 12.23 | 15.96 |
|     suitcase     | 76.89 | 89.78 |
|     frisbee      | 76.73 | 89.78 |
|       skis       |  43.0 | 55.07 |
|    snowboard     | 54.34 | 74.38 |
|   sports ball    |  58.5 | 73.87 |
|       kite       | 57.44 | 69.27 |
|   baseball bat   | 53.04 | 66.12 |
|  baseball glove  |  73.7 | 87.21 |
|    skateboard    | 75.77 | 84.59 |
|    surfboard     | 74.11 |  87.2 |
|  tennis racket   | 86.27 | 92.16 |
|      bottle      | 42.06 | 53.77 |
|    wine glass    | 55.78 | 76.83 |
|       cup        | 54.99 | 75.33 |
|       fork       | 39.47 | 48.99 |
|      knife       | 31.03 |  39.1 |
|      spoon       | 37.94 |  52.8 |
|       bowl       | 47.57 | 68.61 |
|      banana      | 68.83 | 90.55 |
|      apple       | 46.61 | 72.17 |
|     sandwich     | 46.97 |  64.4 |
|      orange      | 59.67 | 63.88 |
|     broccoli     | 54.21 | 66.88 |
|      carrot      | 50.43 | 54.69 |
|     hot dog      | 50.66 | 59.76 |
|      pizza       | 68.74 | 85.65 |
|      donut       | 70.27 | 85.77 |
|       cake       | 61.58 | 73.45 |
|      chair       | 46.35 | 67.35 |
|      couch       | 54.61 | 79.72 |
|   potted plant   | 31.21 | 47.32 |
|       bed        | 63.96 | 79.34 |
|   dining table   | 44.08 | 76.87 |
|      toilet      |  81.2 | 93.21 |
|        tv        | 73.74 | 87.39 |
|      laptop      | 75.17 | 89.68 |
|      mouse       | 76.79 | 89.38 |
|      remote      | 56.69 | 72.52 |
|     keyboard     |  63.1 | 69.84 |
|    cell phone    | 72.22 | 88.31 |
|    microwave     | 63.97 | 76.06 |
|       oven       | 56.61 |  81.1 |
|     toaster      | 38.87 |  54.6 |
|       sink       | 55.04 | 79.18 |
|   refrigerator   | 77.75 | 92.35 |
|       book       | 49.52 | 69.55 |
|      clock       | 73.51 |  84.8 |
|       vase       | 58.07 | 86.65 |
|     scissors     | 77.34 | 90.56 |
|    teddy bear    | 75.04 |  87.7 |
|    hair drier    | 51.39 | 53.52 |
|    toothbrush    | 42.94 | 76.43 |
|      banner      | 32.39 | 63.76 |
|     blanket      |  4.37 |  5.02 |
|      branch      | 19.43 | 29.95 |
|      bridge      |  35.4 | 48.18 |
|  building-other  | 52.67 | 72.62 |
|       bush       | 29.92 |  37.7 |
|     cabinet      | 56.36 | 73.31 |
|       cage       | 19.94 | 38.67 |
|    cardboard     | 46.65 | 56.91 |
|      carpet      | 53.82 | 72.86 |
|  ceiling-other   | 64.88 | 81.91 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      |  19.7 | 27.12 |
|      clouds      | 44.19 | 55.15 |
|     counter      | 26.97 |  43.9 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      |  64.5 | 77.24 |
|    desk-stuff    | 44.23 | 56.91 |
|       dirt       | 40.29 |  58.2 |
|    door-stuff    | 39.96 |  64.4 |
|      fence       | 26.69 | 44.77 |
|   floor-marble   |  6.67 |  7.45 |
|   floor-other    | 22.53 | 29.99 |
|   floor-stone    |  5.12 |  6.88 |
|    floor-tile    | 61.23 | 70.47 |
|    floor-wood    | 63.04 |  77.5 |
|      flower      |  37.8 | 55.63 |
|       fog        |  6.7  |  6.86 |
|    food-other    | 29.78 | 37.89 |
|      fruit       | 41.14 | 60.98 |
| furniture-other  | 17.57 | 25.47 |
|      grass       | 70.83 | 83.49 |
|      gravel      | 28.27 | 39.86 |
|   ground-other   |  4.34 |  5.46 |
|       hill       | 22.38 |  30.5 |
|      house       | 23.17 | 27.25 |
|      leaves      |  22.2 | 28.41 |
|      light       | 37.49 | 51.65 |
|       mat        |  0.0  |  0.0  |
|      metal       | 32.81 | 50.08 |
|   mirror-stuff   | 51.31 | 69.51 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 53.55 | 66.26 |
|       mud        |  6.98 | 10.26 |
|      napkin      | 11.61 | 12.75 |
|       net        | 41.49 | 66.72 |
|      paper       |  30.2 | 40.87 |
|     pavement     | 51.86 | 68.99 |
|      pillow      | 12.97 | 18.25 |
|   plant-other    | 19.31 | 36.97 |
|     plastic      | 22.42 | 30.09 |
|     platform     | 33.25 | 62.82 |
|   playingfield   | 71.21 |  93.0 |
|     railing      |  7.58 | 11.93 |
|     railroad     | 62.31 | 80.18 |
|      river       | 39.77 | 47.14 |
|       road       | 67.38 | 83.06 |
|       rock       | 38.09 | 56.49 |
|       roof       | 19.76 | 27.12 |
|       rug        | 37.52 | 55.69 |
|      salad       |  0.16 |  0.19 |
|       sand       | 60.62 | 70.06 |
|       sea        | 84.98 | 92.35 |
|      shelf       | 34.16 | 45.06 |
|    sky-other     | 70.67 | 89.42 |
|    skyscraper    |  31.7 |  41.4 |
|       snow       |  88.2 | 93.37 |
|   solid-other    |  0.26 |  0.26 |
|      stairs      | 23.62 |  39.0 |
|      stone       | 13.29 | 29.32 |
|      straw       | 29.04 | 39.01 |
| structural-other |  0.1  |  0.11 |
|      table       | 18.36 | 24.32 |
|       tent       |  7.89 | 10.12 |
|  textile-other   | 11.47 | 20.06 |
|      towel       | 33.82 | 42.33 |
|       tree       | 73.93 |  87.2 |
|    vegetable     | 38.82 |  54.4 |
|    wall-brick    | 47.35 | 61.89 |
|  wall-concrete   | 60.85 | 79.57 |
|    wall-other    | 19.97 | 30.59 |
|    wall-panel    |  2.32 |  2.53 |
|    wall-stone    | 30.65 | 36.37 |
|    wall-tile     | 67.13 | 81.76 |
|    wall-wood     | 40.52 | 57.15 |
|   water-other    | 27.63 | 48.33 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 49.04 | 55.54 |
|   window-other   | 47.33 | 73.23 |
|       wood       |  25.7 | 40.78 |
+------------------+-------+-------+
2023/05/24 11:38:50 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.4200  mIoU: 47.4300  mAcc: 59.7700  data_time: 0.0021  time: 0.0891
2023/05/24 11:38:50 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_130000.pth is removed
2023/05/24 11:38:54 - mmengine - INFO - The best checkpoint with 47.4300 mIoU at 140000 iter is saved to best_mIoU_iter_140000.pth.
2023/05/24 11:39:15 - mmengine - INFO - Iter(train) [140050/160000]  lr: 1.5355e-06  eta: 2:24:05  time: 0.4270  data_time: 0.0101  memory: 4907  grad_norm: 89.2326  loss: 27.3301  decode.loss_cls: 0.7866  decode.loss_mask: 0.6799  decode.loss_dice: 0.9755  decode.d0.loss_cls: 2.6407  decode.d0.loss_mask: 0.7512  decode.d0.loss_dice: 1.1191  decode.d1.loss_cls: 0.9017  decode.d1.loss_mask: 0.7375  decode.d1.loss_dice: 1.0621  decode.d2.loss_cls: 0.9115  decode.d2.loss_mask: 0.7141  decode.d2.loss_dice: 1.0004  decode.d3.loss_cls: 0.8408  decode.d3.loss_mask: 0.6811  decode.d3.loss_dice: 1.0069  decode.d4.loss_cls: 0.8176  decode.d4.loss_mask: 0.6848  decode.d4.loss_dice: 1.0130  decode.d5.loss_cls: 0.7727  decode.d5.loss_mask: 0.7079  decode.d5.loss_dice: 1.0223  decode.d6.loss_cls: 0.8216  decode.d6.loss_mask: 0.6964  decode.d6.loss_dice: 1.0001  decode.d7.loss_cls: 0.8472  decode.d7.loss_mask: 0.6814  decode.d7.loss_dice: 0.9819  decode.d8.loss_cls: 0.8201  decode.d8.loss_mask: 0.6999  decode.d8.loss_dice: 0.9542
2023/05/24 11:39:36 - mmengine - INFO - Iter(train) [140100/160000]  lr: 1.5320e-06  eta: 2:23:44  time: 0.4272  data_time: 0.0105  memory: 4857  grad_norm: 89.2124  loss: 34.5586  decode.loss_cls: 1.2061  decode.loss_mask: 0.6391  decode.loss_dice: 1.3158  decode.d0.loss_cls: 3.0562  decode.d0.loss_mask: 0.7014  decode.d0.loss_dice: 1.4966  decode.d1.loss_cls: 1.3802  decode.d1.loss_mask: 0.6592  decode.d1.loss_dice: 1.4218  decode.d2.loss_cls: 1.3319  decode.d2.loss_mask: 0.6647  decode.d2.loss_dice: 1.3643  decode.d3.loss_cls: 1.2879  decode.d3.loss_mask: 0.6463  decode.d3.loss_dice: 1.3351  decode.d4.loss_cls: 1.2717  decode.d4.loss_mask: 0.6334  decode.d4.loss_dice: 1.2970  decode.d5.loss_cls: 1.2496  decode.d5.loss_mask: 0.6329  decode.d5.loss_dice: 1.3225  decode.d6.loss_cls: 1.2904  decode.d6.loss_mask: 0.6287  decode.d6.loss_dice: 1.3011  decode.d7.loss_cls: 1.2618  decode.d7.loss_mask: 0.6414  decode.d7.loss_dice: 1.3154  decode.d8.loss_cls: 1.2696  decode.d8.loss_mask: 0.6438  decode.d8.loss_dice: 1.2926
2023/05/24 11:39:57 - mmengine - INFO - Iter(train) [140150/160000]  lr: 1.5285e-06  eta: 2:23:22  time: 0.4300  data_time: 0.0105  memory: 4888  grad_norm: 86.9787  loss: 38.2941  decode.loss_cls: 1.2709  decode.loss_mask: 0.8553  decode.loss_dice: 1.4491  decode.d0.loss_cls: 3.2970  decode.d0.loss_mask: 0.8844  decode.d0.loss_dice: 1.7218  decode.d1.loss_cls: 1.4014  decode.d1.loss_mask: 0.8718  decode.d1.loss_dice: 1.5630  decode.d2.loss_cls: 1.3630  decode.d2.loss_mask: 0.8448  decode.d2.loss_dice: 1.5061  decode.d3.loss_cls: 1.2970  decode.d3.loss_mask: 0.8228  decode.d3.loss_dice: 1.4312  decode.d4.loss_cls: 1.2783  decode.d4.loss_mask: 0.8424  decode.d4.loss_dice: 1.4490  decode.d5.loss_cls: 1.2858  decode.d5.loss_mask: 0.8254  decode.d5.loss_dice: 1.4412  decode.d6.loss_cls: 1.2735  decode.d6.loss_mask: 0.8361  decode.d6.loss_dice: 1.4213  decode.d7.loss_cls: 1.2617  decode.d7.loss_mask: 0.8432  decode.d7.loss_dice: 1.4077  decode.d8.loss_cls: 1.2734  decode.d8.loss_mask: 0.8463  decode.d8.loss_dice: 1.4291
2023/05/24 11:40:19 - mmengine - INFO - Iter(train) [140200/160000]  lr: 1.5251e-06  eta: 2:23:00  time: 0.4254  data_time: 0.0100  memory: 4837  grad_norm: 93.9835  loss: 32.0363  decode.loss_cls: 1.0748  decode.loss_mask: 0.7476  decode.loss_dice: 1.1689  decode.d0.loss_cls: 3.1028  decode.d0.loss_mask: 0.7562  decode.d0.loss_dice: 1.3242  decode.d1.loss_cls: 1.1382  decode.d1.loss_mask: 0.7350  decode.d1.loss_dice: 1.2673  decode.d2.loss_cls: 1.0502  decode.d2.loss_mask: 0.7438  decode.d2.loss_dice: 1.2104  decode.d3.loss_cls: 1.0817  decode.d3.loss_mask: 0.7113  decode.d3.loss_dice: 1.1554  decode.d4.loss_cls: 1.0380  decode.d4.loss_mask: 0.7358  decode.d4.loss_dice: 1.1871  decode.d5.loss_cls: 1.0744  decode.d5.loss_mask: 0.7187  decode.d5.loss_dice: 1.1603  decode.d6.loss_cls: 1.0460  decode.d6.loss_mask: 0.7356  decode.d6.loss_dice: 1.1861  decode.d7.loss_cls: 1.0687  decode.d7.loss_mask: 0.7100  decode.d7.loss_dice: 1.1106  decode.d8.loss_cls: 1.1040  decode.d8.loss_mask: 0.7461  decode.d8.loss_dice: 1.1469
2023/05/24 11:40:40 - mmengine - INFO - Iter(train) [140250/160000]  lr: 1.5216e-06  eta: 2:22:39  time: 0.4351  data_time: 0.0106  memory: 4855  grad_norm: 106.3744  loss: 36.6800  decode.loss_cls: 1.1302  decode.loss_mask: 0.7739  decode.loss_dice: 1.4247  decode.d0.loss_cls: 3.0080  decode.d0.loss_mask: 0.8582  decode.d0.loss_dice: 1.6259  decode.d1.loss_cls: 1.2766  decode.d1.loss_mask: 0.8899  decode.d1.loss_dice: 1.5722  decode.d2.loss_cls: 1.1655  decode.d2.loss_mask: 0.8681  decode.d2.loss_dice: 1.5002  decode.d3.loss_cls: 1.1966  decode.d3.loss_mask: 0.8501  decode.d3.loss_dice: 1.4680  decode.d4.loss_cls: 1.1157  decode.d4.loss_mask: 0.8382  decode.d4.loss_dice: 1.5259  decode.d5.loss_cls: 1.1837  decode.d5.loss_mask: 0.8032  decode.d5.loss_dice: 1.4903  decode.d6.loss_cls: 1.1662  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 1.4251  decode.d7.loss_cls: 1.1111  decode.d7.loss_mask: 0.8095  decode.d7.loss_dice: 1.4445  decode.d8.loss_cls: 1.1163  decode.d8.loss_mask: 0.8009  decode.d8.loss_dice: 1.4325
2023/05/24 11:41:02 - mmengine - INFO - Iter(train) [140300/160000]  lr: 1.5181e-06  eta: 2:22:17  time: 0.4274  data_time: 0.0100  memory: 4804  grad_norm: 99.9568  loss: 39.3259  decode.loss_cls: 1.1924  decode.loss_mask: 0.9520  decode.loss_dice: 1.5393  decode.d0.loss_cls: 3.2214  decode.d0.loss_mask: 0.9144  decode.d0.loss_dice: 1.7036  decode.d1.loss_cls: 1.3536  decode.d1.loss_mask: 0.9928  decode.d1.loss_dice: 1.6232  decode.d2.loss_cls: 1.2304  decode.d2.loss_mask: 0.9875  decode.d2.loss_dice: 1.5403  decode.d3.loss_cls: 1.1722  decode.d3.loss_mask: 0.9832  decode.d3.loss_dice: 1.5422  decode.d4.loss_cls: 1.2114  decode.d4.loss_mask: 0.9838  decode.d4.loss_dice: 1.5380  decode.d5.loss_cls: 1.1757  decode.d5.loss_mask: 0.9722  decode.d5.loss_dice: 1.5112  decode.d6.loss_cls: 1.2048  decode.d6.loss_mask: 0.9523  decode.d6.loss_dice: 1.5129  decode.d7.loss_cls: 1.1883  decode.d7.loss_mask: 0.9487  decode.d7.loss_dice: 1.5262  decode.d8.loss_cls: 1.1803  decode.d8.loss_mask: 0.9644  decode.d8.loss_dice: 1.5070
2023/05/24 11:41:24 - mmengine - INFO - Iter(train) [140350/160000]  lr: 1.5147e-06  eta: 2:21:55  time: 0.4211  data_time: 0.0103  memory: 4905  grad_norm: 88.4660  loss: 46.3167  decode.loss_cls: 1.4881  decode.loss_mask: 0.9314  decode.loss_dice: 1.8148  decode.d0.loss_cls: 3.7211  decode.d0.loss_mask: 1.0042  decode.d0.loss_dice: 2.1200  decode.d1.loss_cls: 1.6992  decode.d1.loss_mask: 0.9462  decode.d1.loss_dice: 1.9466  decode.d2.loss_cls: 1.6217  decode.d2.loss_mask: 0.9309  decode.d2.loss_dice: 1.9995  decode.d3.loss_cls: 1.6299  decode.d3.loss_mask: 0.9277  decode.d3.loss_dice: 1.9011  decode.d4.loss_cls: 1.5245  decode.d4.loss_mask: 0.9453  decode.d4.loss_dice: 1.9099  decode.d5.loss_cls: 1.4858  decode.d5.loss_mask: 0.9397  decode.d5.loss_dice: 1.8907  decode.d6.loss_cls: 1.6073  decode.d6.loss_mask: 0.9337  decode.d6.loss_dice: 1.8683  decode.d7.loss_cls: 1.4823  decode.d7.loss_mask: 0.9526  decode.d7.loss_dice: 1.8284  decode.d8.loss_cls: 1.5291  decode.d8.loss_mask: 0.9480  decode.d8.loss_dice: 1.7885
2023/05/24 11:41:46 - mmengine - INFO - Iter(train) [140400/160000]  lr: 1.5112e-06  eta: 2:21:34  time: 0.4486  data_time: 0.0098  memory: 4800  grad_norm: 104.2500  loss: 37.4516  decode.loss_cls: 1.4747  decode.loss_mask: 0.7078  decode.loss_dice: 1.2773  decode.d0.loss_cls: 3.5923  decode.d0.loss_mask: 0.7039  decode.d0.loss_dice: 1.4568  decode.d1.loss_cls: 1.6634  decode.d1.loss_mask: 0.6971  decode.d1.loss_dice: 1.3574  decode.d2.loss_cls: 1.5179  decode.d2.loss_mask: 0.6710  decode.d2.loss_dice: 1.3420  decode.d3.loss_cls: 1.5938  decode.d3.loss_mask: 0.6746  decode.d3.loss_dice: 1.3181  decode.d4.loss_cls: 1.5344  decode.d4.loss_mask: 0.6874  decode.d4.loss_dice: 1.2951  decode.d5.loss_cls: 1.5467  decode.d5.loss_mask: 0.6694  decode.d5.loss_dice: 1.3134  decode.d6.loss_cls: 1.4452  decode.d6.loss_mask: 0.7196  decode.d6.loss_dice: 1.2907  decode.d7.loss_cls: 1.5121  decode.d7.loss_mask: 0.6959  decode.d7.loss_dice: 1.2624  decode.d8.loss_cls: 1.4201  decode.d8.loss_mask: 0.7063  decode.d8.loss_dice: 1.3048
2023/05/24 11:42:07 - mmengine - INFO - Iter(train) [140450/160000]  lr: 1.5077e-06  eta: 2:21:12  time: 0.4186  data_time: 0.0100  memory: 4907  grad_norm: 96.2203  loss: 27.4815  decode.loss_cls: 0.8372  decode.loss_mask: 0.6746  decode.loss_dice: 0.9384  decode.d0.loss_cls: 2.8892  decode.d0.loss_mask: 0.7630  decode.d0.loss_dice: 1.0723  decode.d1.loss_cls: 0.9089  decode.d1.loss_mask: 0.7589  decode.d1.loss_dice: 1.0625  decode.d2.loss_cls: 0.8362  decode.d2.loss_mask: 0.6989  decode.d2.loss_dice: 1.0080  decode.d3.loss_cls: 0.8554  decode.d3.loss_mask: 0.7012  decode.d3.loss_dice: 0.9807  decode.d4.loss_cls: 0.8292  decode.d4.loss_mask: 0.7041  decode.d4.loss_dice: 0.9621  decode.d5.loss_cls: 0.8330  decode.d5.loss_mask: 0.6980  decode.d5.loss_dice: 0.9693  decode.d6.loss_cls: 0.8325  decode.d6.loss_mask: 0.7190  decode.d6.loss_dice: 0.9828  decode.d7.loss_cls: 0.8193  decode.d7.loss_mask: 0.6915  decode.d7.loss_dice: 0.9695  decode.d8.loss_cls: 0.8564  decode.d8.loss_mask: 0.6782  decode.d8.loss_dice: 0.9510
2023/05/24 11:42:28 - mmengine - INFO - Iter(train) [140500/160000]  lr: 1.5043e-06  eta: 2:20:50  time: 0.4208  data_time: 0.0100  memory: 4874  grad_norm: 113.0235  loss: 34.5971  decode.loss_cls: 1.1876  decode.loss_mask: 0.7060  decode.loss_dice: 1.3022  decode.d0.loss_cls: 3.1519  decode.d0.loss_mask: 0.8054  decode.d0.loss_dice: 1.4986  decode.d1.loss_cls: 1.2465  decode.d1.loss_mask: 0.7237  decode.d1.loss_dice: 1.4178  decode.d2.loss_cls: 1.2468  decode.d2.loss_mask: 0.7133  decode.d2.loss_dice: 1.3375  decode.d3.loss_cls: 1.2603  decode.d3.loss_mask: 0.7210  decode.d3.loss_dice: 1.3182  decode.d4.loss_cls: 1.2479  decode.d4.loss_mask: 0.7233  decode.d4.loss_dice: 1.3123  decode.d5.loss_cls: 1.2386  decode.d5.loss_mask: 0.7020  decode.d5.loss_dice: 1.3078  decode.d6.loss_cls: 1.2101  decode.d6.loss_mask: 0.7058  decode.d6.loss_dice: 1.2566  decode.d7.loss_cls: 1.1895  decode.d7.loss_mask: 0.7087  decode.d7.loss_dice: 1.2394  decode.d8.loss_cls: 1.1930  decode.d8.loss_mask: 0.7103  decode.d8.loss_dice: 1.2149
2023/05/24 11:42:49 - mmengine - INFO - Iter(train) [140550/160000]  lr: 1.5008e-06  eta: 2:20:28  time: 0.4197  data_time: 0.0100  memory: 4825  grad_norm: 82.2481  loss: 41.5988  decode.loss_cls: 1.4114  decode.loss_mask: 0.7267  decode.loss_dice: 1.6374  decode.d0.loss_cls: 3.5319  decode.d0.loss_mask: 0.7914  decode.d0.loss_dice: 1.8663  decode.d1.loss_cls: 1.7020  decode.d1.loss_mask: 0.7588  decode.d1.loss_dice: 1.7567  decode.d2.loss_cls: 1.6244  decode.d2.loss_mask: 0.7398  decode.d2.loss_dice: 1.7360  decode.d3.loss_cls: 1.5326  decode.d3.loss_mask: 0.7513  decode.d3.loss_dice: 1.6932  decode.d4.loss_cls: 1.4999  decode.d4.loss_mask: 0.7563  decode.d4.loss_dice: 1.6752  decode.d5.loss_cls: 1.4995  decode.d5.loss_mask: 0.7454  decode.d5.loss_dice: 1.6732  decode.d6.loss_cls: 1.4355  decode.d6.loss_mask: 0.7318  decode.d6.loss_dice: 1.6609  decode.d7.loss_cls: 1.4268  decode.d7.loss_mask: 0.7263  decode.d7.loss_dice: 1.6653  decode.d8.loss_cls: 1.4152  decode.d8.loss_mask: 0.7393  decode.d8.loss_dice: 1.6883
2023/05/24 11:43:10 - mmengine - INFO - Iter(train) [140600/160000]  lr: 1.4973e-06  eta: 2:20:07  time: 0.4193  data_time: 0.0098  memory: 4836  grad_norm: 87.4031  loss: 35.1935  decode.loss_cls: 1.1160  decode.loss_mask: 0.7035  decode.loss_dice: 1.3985  decode.d0.loss_cls: 3.1228  decode.d0.loss_mask: 0.8837  decode.d0.loss_dice: 1.5931  decode.d1.loss_cls: 1.1599  decode.d1.loss_mask: 0.7727  decode.d1.loss_dice: 1.4970  decode.d2.loss_cls: 1.1088  decode.d2.loss_mask: 0.7243  decode.d2.loss_dice: 1.4751  decode.d3.loss_cls: 1.1699  decode.d3.loss_mask: 0.7539  decode.d3.loss_dice: 1.4622  decode.d4.loss_cls: 1.1696  decode.d4.loss_mask: 0.7266  decode.d4.loss_dice: 1.4223  decode.d5.loss_cls: 1.1125  decode.d5.loss_mask: 0.7160  decode.d5.loss_dice: 1.4261  decode.d6.loss_cls: 1.1092  decode.d6.loss_mask: 0.7070  decode.d6.loss_dice: 1.4447  decode.d7.loss_cls: 1.0531  decode.d7.loss_mask: 0.7182  decode.d7.loss_dice: 1.4109  decode.d8.loss_cls: 1.1168  decode.d8.loss_mask: 0.7136  decode.d8.loss_dice: 1.4056
2023/05/24 11:43:32 - mmengine - INFO - Iter(train) [140650/160000]  lr: 1.4939e-06  eta: 2:19:45  time: 0.4257  data_time: 0.0100  memory: 4829  grad_norm: 90.5970  loss: 34.8217  decode.loss_cls: 1.0951  decode.loss_mask: 0.7774  decode.loss_dice: 1.3299  decode.d0.loss_cls: 3.1137  decode.d0.loss_mask: 0.8115  decode.d0.loss_dice: 1.5166  decode.d1.loss_cls: 1.1811  decode.d1.loss_mask: 0.8675  decode.d1.loss_dice: 1.4187  decode.d2.loss_cls: 1.1115  decode.d2.loss_mask: 0.8208  decode.d2.loss_dice: 1.3799  decode.d3.loss_cls: 1.0749  decode.d3.loss_mask: 0.8174  decode.d3.loss_dice: 1.3660  decode.d4.loss_cls: 1.0736  decode.d4.loss_mask: 0.8033  decode.d4.loss_dice: 1.3661  decode.d5.loss_cls: 1.1114  decode.d5.loss_mask: 0.8210  decode.d5.loss_dice: 1.3400  decode.d6.loss_cls: 1.1315  decode.d6.loss_mask: 0.7862  decode.d6.loss_dice: 1.3261  decode.d7.loss_cls: 1.0442  decode.d7.loss_mask: 0.7767  decode.d7.loss_dice: 1.3210  decode.d8.loss_cls: 1.0702  decode.d8.loss_mask: 0.8180  decode.d8.loss_dice: 1.3504
2023/05/24 11:43:54 - mmengine - INFO - Iter(train) [140700/160000]  lr: 1.4904e-06  eta: 2:19:23  time: 0.4472  data_time: 0.0100  memory: 4888  grad_norm: 86.4151  loss: 42.8605  decode.loss_cls: 1.4410  decode.loss_mask: 0.8878  decode.loss_dice: 1.7092  decode.d0.loss_cls: 3.0849  decode.d0.loss_mask: 0.9182  decode.d0.loss_dice: 2.0129  decode.d1.loss_cls: 1.5755  decode.d1.loss_mask: 0.9050  decode.d1.loss_dice: 1.8566  decode.d2.loss_cls: 1.4428  decode.d2.loss_mask: 0.9205  decode.d2.loss_dice: 1.7679  decode.d3.loss_cls: 1.4677  decode.d3.loss_mask: 0.9060  decode.d3.loss_dice: 1.6904  decode.d4.loss_cls: 1.4237  decode.d4.loss_mask: 0.9137  decode.d4.loss_dice: 1.6742  decode.d5.loss_cls: 1.4588  decode.d5.loss_mask: 0.9066  decode.d5.loss_dice: 1.7213  decode.d6.loss_cls: 1.4626  decode.d6.loss_mask: 0.9164  decode.d6.loss_dice: 1.6906  decode.d7.loss_cls: 1.4879  decode.d7.loss_mask: 0.9071  decode.d7.loss_dice: 1.7007  decode.d8.loss_cls: 1.4531  decode.d8.loss_mask: 0.8927  decode.d8.loss_dice: 1.6648
2023/05/24 11:44:15 - mmengine - INFO - Iter(train) [140750/160000]  lr: 1.4869e-06  eta: 2:19:02  time: 0.4171  data_time: 0.0099  memory: 4859  grad_norm: 112.7194  loss: 42.7487  decode.loss_cls: 1.3901  decode.loss_mask: 0.8573  decode.loss_dice: 1.6822  decode.d0.loss_cls: 3.3812  decode.d0.loss_mask: 0.9278  decode.d0.loss_dice: 1.9312  decode.d1.loss_cls: 1.4561  decode.d1.loss_mask: 0.9366  decode.d1.loss_dice: 1.9009  decode.d2.loss_cls: 1.5142  decode.d2.loss_mask: 0.9270  decode.d2.loss_dice: 1.7704  decode.d3.loss_cls: 1.4164  decode.d3.loss_mask: 0.9119  decode.d3.loss_dice: 1.7133  decode.d4.loss_cls: 1.4446  decode.d4.loss_mask: 0.9006  decode.d4.loss_dice: 1.7302  decode.d5.loss_cls: 1.4188  decode.d5.loss_mask: 0.8809  decode.d5.loss_dice: 1.7046  decode.d6.loss_cls: 1.3801  decode.d6.loss_mask: 0.8778  decode.d6.loss_dice: 1.7088  decode.d7.loss_cls: 1.3996  decode.d7.loss_mask: 0.8807  decode.d7.loss_dice: 1.7180  decode.d8.loss_cls: 1.4040  decode.d8.loss_mask: 0.8665  decode.d8.loss_dice: 1.7169
2023/05/24 11:44:39 - mmengine - INFO - Iter(train) [140800/160000]  lr: 1.4834e-06  eta: 2:18:40  time: 0.4833  data_time: 0.0112  memory: 4871  grad_norm: 93.5535  loss: 42.4557  decode.loss_cls: 1.3896  decode.loss_mask: 0.8209  decode.loss_dice: 1.6928  decode.d0.loss_cls: 3.5056  decode.d0.loss_mask: 0.8482  decode.d0.loss_dice: 1.9205  decode.d1.loss_cls: 1.6041  decode.d1.loss_mask: 0.8967  decode.d1.loss_dice: 1.8420  decode.d2.loss_cls: 1.4925  decode.d2.loss_mask: 0.8534  decode.d2.loss_dice: 1.7659  decode.d3.loss_cls: 1.4705  decode.d3.loss_mask: 0.8414  decode.d3.loss_dice: 1.6965  decode.d4.loss_cls: 1.4540  decode.d4.loss_mask: 0.8217  decode.d4.loss_dice: 1.7303  decode.d5.loss_cls: 1.4339  decode.d5.loss_mask: 0.8024  decode.d5.loss_dice: 1.7326  decode.d6.loss_cls: 1.4247  decode.d6.loss_mask: 0.8055  decode.d6.loss_dice: 1.6908  decode.d7.loss_cls: 1.3960  decode.d7.loss_mask: 0.8146  decode.d7.loss_dice: 1.7266  decode.d8.loss_cls: 1.4104  decode.d8.loss_mask: 0.8410  decode.d8.loss_dice: 1.7308
2023/05/24 11:45:03 - mmengine - INFO - Iter(train) [140850/160000]  lr: 1.4799e-06  eta: 2:18:19  time: 0.4444  data_time: 0.0105  memory: 4880  grad_norm: 91.0006  loss: 36.5659  decode.loss_cls: 1.2087  decode.loss_mask: 0.7655  decode.loss_dice: 1.3323  decode.d0.loss_cls: 3.3309  decode.d0.loss_mask: 0.8911  decode.d0.loss_dice: 1.5890  decode.d1.loss_cls: 1.3473  decode.d1.loss_mask: 0.7962  decode.d1.loss_dice: 1.4706  decode.d2.loss_cls: 1.3030  decode.d2.loss_mask: 0.8225  decode.d2.loss_dice: 1.4403  decode.d3.loss_cls: 1.2197  decode.d3.loss_mask: 0.8422  decode.d3.loss_dice: 1.4227  decode.d4.loss_cls: 1.1865  decode.d4.loss_mask: 0.7821  decode.d4.loss_dice: 1.4121  decode.d5.loss_cls: 1.1691  decode.d5.loss_mask: 0.8069  decode.d5.loss_dice: 1.3850  decode.d6.loss_cls: 1.2159  decode.d6.loss_mask: 0.7828  decode.d6.loss_dice: 1.3566  decode.d7.loss_cls: 1.2437  decode.d7.loss_mask: 0.7819  decode.d7.loss_dice: 1.3624  decode.d8.loss_cls: 1.1938  decode.d8.loss_mask: 0.7688  decode.d8.loss_dice: 1.3363
2023/05/24 11:45:24 - mmengine - INFO - Iter(train) [140900/160000]  lr: 1.4765e-06  eta: 2:17:57  time: 0.4385  data_time: 0.0098  memory: 4848  grad_norm: 83.3047  loss: 30.0435  decode.loss_cls: 0.9574  decode.loss_mask: 0.7364  decode.loss_dice: 1.0255  decode.d0.loss_cls: 3.0221  decode.d0.loss_mask: 0.8067  decode.d0.loss_dice: 1.1784  decode.d1.loss_cls: 1.0997  decode.d1.loss_mask: 0.7093  decode.d1.loss_dice: 1.0837  decode.d2.loss_cls: 0.9865  decode.d2.loss_mask: 0.7254  decode.d2.loss_dice: 1.0874  decode.d3.loss_cls: 0.9706  decode.d3.loss_mask: 0.7381  decode.d3.loss_dice: 1.0752  decode.d4.loss_cls: 0.9529  decode.d4.loss_mask: 0.7419  decode.d4.loss_dice: 1.0747  decode.d5.loss_cls: 0.9477  decode.d5.loss_mask: 0.7733  decode.d5.loss_dice: 1.0822  decode.d6.loss_cls: 0.9864  decode.d6.loss_mask: 0.7416  decode.d6.loss_dice: 1.0505  decode.d7.loss_cls: 0.9751  decode.d7.loss_mask: 0.7269  decode.d7.loss_dice: 1.0371  decode.d8.loss_cls: 0.9398  decode.d8.loss_mask: 0.7396  decode.d8.loss_dice: 1.0715
2023/05/24 11:45:46 - mmengine - INFO - Iter(train) [140950/160000]  lr: 1.4730e-06  eta: 2:17:36  time: 0.4347  data_time: 0.0099  memory: 4870  grad_norm: 89.0374  loss: 41.0350  decode.loss_cls: 1.2501  decode.loss_mask: 0.9913  decode.loss_dice: 1.6229  decode.d0.loss_cls: 3.1826  decode.d0.loss_mask: 1.0581  decode.d0.loss_dice: 1.8869  decode.d1.loss_cls: 1.3769  decode.d1.loss_mask: 1.0034  decode.d1.loss_dice: 1.6557  decode.d2.loss_cls: 1.2720  decode.d2.loss_mask: 0.9823  decode.d2.loss_dice: 1.6622  decode.d3.loss_cls: 1.2400  decode.d3.loss_mask: 0.9834  decode.d3.loss_dice: 1.6286  decode.d4.loss_cls: 1.1918  decode.d4.loss_mask: 1.0074  decode.d4.loss_dice: 1.6345  decode.d5.loss_cls: 1.2554  decode.d5.loss_mask: 0.9597  decode.d5.loss_dice: 1.5979  decode.d6.loss_cls: 1.2979  decode.d6.loss_mask: 0.9663  decode.d6.loss_dice: 1.5988  decode.d7.loss_cls: 1.2686  decode.d7.loss_mask: 0.9720  decode.d7.loss_dice: 1.6185  decode.d8.loss_cls: 1.2811  decode.d8.loss_mask: 0.9754  decode.d8.loss_dice: 1.6132
2023/05/24 11:46:08 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 11:46:08 - mmengine - INFO - Iter(train) [141000/160000]  lr: 1.4695e-06  eta: 2:17:14  time: 0.4304  data_time: 0.0100  memory: 4868  grad_norm: 92.8280  loss: 22.5158  decode.loss_cls: 0.6691  decode.loss_mask: 0.5667  decode.loss_dice: 0.7700  decode.d0.loss_cls: 2.4650  decode.d0.loss_mask: 0.5872  decode.d0.loss_dice: 0.9049  decode.d1.loss_cls: 0.6945  decode.d1.loss_mask: 0.6209  decode.d1.loss_dice: 0.8453  decode.d2.loss_cls: 0.7722  decode.d2.loss_mask: 0.6027  decode.d2.loss_dice: 0.8016  decode.d3.loss_cls: 0.7427  decode.d3.loss_mask: 0.5839  decode.d3.loss_dice: 0.7797  decode.d4.loss_cls: 0.6946  decode.d4.loss_mask: 0.5780  decode.d4.loss_dice: 0.7754  decode.d5.loss_cls: 0.6878  decode.d5.loss_mask: 0.5873  decode.d5.loss_dice: 0.7575  decode.d6.loss_cls: 0.6715  decode.d6.loss_mask: 0.5866  decode.d6.loss_dice: 0.7694  decode.d7.loss_cls: 0.6541  decode.d7.loss_mask: 0.5858  decode.d7.loss_dice: 0.7657  decode.d8.loss_cls: 0.6716  decode.d8.loss_mask: 0.5764  decode.d8.loss_dice: 0.7479
2023/05/24 11:46:08 - mmengine - INFO - Saving checkpoint at 141000 iterations
2023/05/24 11:46:35 - mmengine - INFO - Iter(train) [141050/160000]  lr: 1.4660e-06  eta: 2:16:53  time: 0.4220  data_time: 0.0103  memory: 4821  grad_norm: 97.8895  loss: 33.5297  decode.loss_cls: 1.1167  decode.loss_mask: 0.7574  decode.loss_dice: 1.1967  decode.d0.loss_cls: 2.8186  decode.d0.loss_mask: 0.8385  decode.d0.loss_dice: 1.3891  decode.d1.loss_cls: 1.2983  decode.d1.loss_mask: 0.7811  decode.d1.loss_dice: 1.3014  decode.d2.loss_cls: 1.1077  decode.d2.loss_mask: 0.7990  decode.d2.loss_dice: 1.2856  decode.d3.loss_cls: 1.1323  decode.d3.loss_mask: 0.7871  decode.d3.loss_dice: 1.2382  decode.d4.loss_cls: 1.1360  decode.d4.loss_mask: 0.7864  decode.d4.loss_dice: 1.2310  decode.d5.loss_cls: 1.1713  decode.d5.loss_mask: 0.7838  decode.d5.loss_dice: 1.2293  decode.d6.loss_cls: 1.1516  decode.d6.loss_mask: 0.7546  decode.d6.loss_dice: 1.2155  decode.d7.loss_cls: 1.0912  decode.d7.loss_mask: 0.7857  decode.d7.loss_dice: 1.2405  decode.d8.loss_cls: 1.0916  decode.d8.loss_mask: 0.7786  decode.d8.loss_dice: 1.2348
2023/05/24 11:46:56 - mmengine - INFO - Iter(train) [141100/160000]  lr: 1.4625e-06  eta: 2:16:31  time: 0.4169  data_time: 0.0104  memory: 4817  grad_norm: 97.4277  loss: 36.5681  decode.loss_cls: 1.2325  decode.loss_mask: 0.7434  decode.loss_dice: 1.3443  decode.d0.loss_cls: 3.2299  decode.d0.loss_mask: 0.8542  decode.d0.loss_dice: 1.6990  decode.d1.loss_cls: 1.4391  decode.d1.loss_mask: 0.8203  decode.d1.loss_dice: 1.5157  decode.d2.loss_cls: 1.3153  decode.d2.loss_mask: 0.8389  decode.d2.loss_dice: 1.4961  decode.d3.loss_cls: 1.2844  decode.d3.loss_mask: 0.7396  decode.d3.loss_dice: 1.4087  decode.d4.loss_cls: 1.2567  decode.d4.loss_mask: 0.7151  decode.d4.loss_dice: 1.3760  decode.d5.loss_cls: 1.2344  decode.d5.loss_mask: 0.7480  decode.d5.loss_dice: 1.3807  decode.d6.loss_cls: 1.2100  decode.d6.loss_mask: 0.7288  decode.d6.loss_dice: 1.3485  decode.d7.loss_cls: 1.2035  decode.d7.loss_mask: 0.7418  decode.d7.loss_dice: 1.3528  decode.d8.loss_cls: 1.2111  decode.d8.loss_mask: 0.7360  decode.d8.loss_dice: 1.3631
2023/05/24 11:47:18 - mmengine - INFO - Iter(train) [141150/160000]  lr: 1.4591e-06  eta: 2:16:09  time: 0.4778  data_time: 0.0103  memory: 4838  grad_norm: 90.4141  loss: 36.2621  decode.loss_cls: 1.2624  decode.loss_mask: 0.7489  decode.loss_dice: 1.3112  decode.d0.loss_cls: 2.9397  decode.d0.loss_mask: 0.8660  decode.d0.loss_dice: 1.5858  decode.d1.loss_cls: 1.4066  decode.d1.loss_mask: 0.8413  decode.d1.loss_dice: 1.4540  decode.d2.loss_cls: 1.3626  decode.d2.loss_mask: 0.7861  decode.d2.loss_dice: 1.3763  decode.d3.loss_cls: 1.3072  decode.d3.loss_mask: 0.7860  decode.d3.loss_dice: 1.3500  decode.d4.loss_cls: 1.3221  decode.d4.loss_mask: 0.7730  decode.d4.loss_dice: 1.3435  decode.d5.loss_cls: 1.2897  decode.d5.loss_mask: 0.7620  decode.d5.loss_dice: 1.3342  decode.d6.loss_cls: 1.3029  decode.d6.loss_mask: 0.7389  decode.d6.loss_dice: 1.3150  decode.d7.loss_cls: 1.2937  decode.d7.loss_mask: 0.7475  decode.d7.loss_dice: 1.3073  decode.d8.loss_cls: 1.2556  decode.d8.loss_mask: 0.7570  decode.d8.loss_dice: 1.3356
2023/05/24 11:47:39 - mmengine - INFO - Iter(train) [141200/160000]  lr: 1.4556e-06  eta: 2:15:48  time: 0.4235  data_time: 0.0098  memory: 4866  grad_norm: 86.8304  loss: 32.0884  decode.loss_cls: 0.9746  decode.loss_mask: 0.7140  decode.loss_dice: 1.2410  decode.d0.loss_cls: 2.9619  decode.d0.loss_mask: 0.8046  decode.d0.loss_dice: 1.4925  decode.d1.loss_cls: 0.9835  decode.d1.loss_mask: 0.7596  decode.d1.loss_dice: 1.4009  decode.d2.loss_cls: 1.0044  decode.d2.loss_mask: 0.7106  decode.d2.loss_dice: 1.3310  decode.d3.loss_cls: 1.0544  decode.d3.loss_mask: 0.6995  decode.d3.loss_dice: 1.2650  decode.d4.loss_cls: 0.9974  decode.d4.loss_mask: 0.7038  decode.d4.loss_dice: 1.2646  decode.d5.loss_cls: 1.0283  decode.d5.loss_mask: 0.6819  decode.d5.loss_dice: 1.2719  decode.d6.loss_cls: 0.9652  decode.d6.loss_mask: 0.6877  decode.d6.loss_dice: 1.2630  decode.d7.loss_cls: 1.0049  decode.d7.loss_mask: 0.6893  decode.d7.loss_dice: 1.2163  decode.d8.loss_cls: 0.9869  decode.d8.loss_mask: 0.6947  decode.d8.loss_dice: 1.2351
2023/05/24 11:48:02 - mmengine - INFO - Iter(train) [141250/160000]  lr: 1.4521e-06  eta: 2:15:26  time: 0.4802  data_time: 0.0095  memory: 4813  grad_norm: 92.9288  loss: 36.4301  decode.loss_cls: 1.2280  decode.loss_mask: 0.7952  decode.loss_dice: 1.3430  decode.d0.loss_cls: 3.1551  decode.d0.loss_mask: 0.9255  decode.d0.loss_dice: 1.6261  decode.d1.loss_cls: 1.3369  decode.d1.loss_mask: 0.8477  decode.d1.loss_dice: 1.4932  decode.d2.loss_cls: 1.2861  decode.d2.loss_mask: 0.8270  decode.d2.loss_dice: 1.4121  decode.d3.loss_cls: 1.2022  decode.d3.loss_mask: 0.7896  decode.d3.loss_dice: 1.3737  decode.d4.loss_cls: 1.2535  decode.d4.loss_mask: 0.7901  decode.d4.loss_dice: 1.3346  decode.d5.loss_cls: 1.2230  decode.d5.loss_mask: 0.7899  decode.d5.loss_dice: 1.3558  decode.d6.loss_cls: 1.2422  decode.d6.loss_mask: 0.7910  decode.d6.loss_dice: 1.3250  decode.d7.loss_cls: 1.2210  decode.d7.loss_mask: 0.7780  decode.d7.loss_dice: 1.3187  decode.d8.loss_cls: 1.2633  decode.d8.loss_mask: 0.7851  decode.d8.loss_dice: 1.3174
2023/05/24 11:48:23 - mmengine - INFO - Iter(train) [141300/160000]  lr: 1.4486e-06  eta: 2:15:05  time: 0.4231  data_time: 0.0100  memory: 4873  grad_norm: 89.1475  loss: 38.4420  decode.loss_cls: 1.2262  decode.loss_mask: 0.8826  decode.loss_dice: 1.3107  decode.d0.loss_cls: 3.5127  decode.d0.loss_mask: 1.1086  decode.d0.loss_dice: 1.6097  decode.d1.loss_cls: 1.3785  decode.d1.loss_mask: 1.0032  decode.d1.loss_dice: 1.5385  decode.d2.loss_cls: 1.3008  decode.d2.loss_mask: 0.9290  decode.d2.loss_dice: 1.4341  decode.d3.loss_cls: 1.2237  decode.d3.loss_mask: 0.9654  decode.d3.loss_dice: 1.4478  decode.d4.loss_cls: 1.2576  decode.d4.loss_mask: 0.9056  decode.d4.loss_dice: 1.3901  decode.d5.loss_cls: 1.2725  decode.d5.loss_mask: 0.9093  decode.d5.loss_dice: 1.3834  decode.d6.loss_cls: 1.2738  decode.d6.loss_mask: 0.8928  decode.d6.loss_dice: 1.3863  decode.d7.loss_cls: 1.2193  decode.d7.loss_mask: 0.8980  decode.d7.loss_dice: 1.3463  decode.d8.loss_cls: 1.2048  decode.d8.loss_mask: 0.8912  decode.d8.loss_dice: 1.3398
2023/05/24 11:48:44 - mmengine - INFO - Iter(train) [141350/160000]  lr: 1.4451e-06  eta: 2:14:43  time: 0.4182  data_time: 0.0098  memory: 4826  grad_norm: 97.6269  loss: 25.0173  decode.loss_cls: 0.9152  decode.loss_mask: 0.5237  decode.loss_dice: 0.8168  decode.d0.loss_cls: 2.6403  decode.d0.loss_mask: 0.5787  decode.d0.loss_dice: 0.9639  decode.d1.loss_cls: 1.0040  decode.d1.loss_mask: 0.5627  decode.d1.loss_dice: 0.9118  decode.d2.loss_cls: 0.9922  decode.d2.loss_mask: 0.5682  decode.d2.loss_dice: 0.8858  decode.d3.loss_cls: 1.0080  decode.d3.loss_mask: 0.5233  decode.d3.loss_dice: 0.8094  decode.d4.loss_cls: 0.9266  decode.d4.loss_mask: 0.5167  decode.d4.loss_dice: 0.8106  decode.d5.loss_cls: 0.9490  decode.d5.loss_mask: 0.5052  decode.d5.loss_dice: 0.8205  decode.d6.loss_cls: 0.9485  decode.d6.loss_mask: 0.5065  decode.d6.loss_dice: 0.8121  decode.d7.loss_cls: 0.9302  decode.d7.loss_mask: 0.5118  decode.d7.loss_dice: 0.8267  decode.d8.loss_cls: 0.9066  decode.d8.loss_mask: 0.5186  decode.d8.loss_dice: 0.8239
2023/05/24 11:49:05 - mmengine - INFO - Iter(train) [141400/160000]  lr: 1.4416e-06  eta: 2:14:21  time: 0.4263  data_time: 0.0101  memory: 4865  grad_norm: 104.2904  loss: 38.2013  decode.loss_cls: 1.1899  decode.loss_mask: 0.7943  decode.loss_dice: 1.5076  decode.d0.loss_cls: 3.1474  decode.d0.loss_mask: 0.8869  decode.d0.loss_dice: 1.8256  decode.d1.loss_cls: 1.2985  decode.d1.loss_mask: 0.8981  decode.d1.loss_dice: 1.7131  decode.d2.loss_cls: 1.2292  decode.d2.loss_mask: 0.8693  decode.d2.loss_dice: 1.5720  decode.d3.loss_cls: 1.2387  decode.d3.loss_mask: 0.8358  decode.d3.loss_dice: 1.5306  decode.d4.loss_cls: 1.2702  decode.d4.loss_mask: 0.8234  decode.d4.loss_dice: 1.5197  decode.d5.loss_cls: 1.2084  decode.d5.loss_mask: 0.8182  decode.d5.loss_dice: 1.5079  decode.d6.loss_cls: 1.1252  decode.d6.loss_mask: 0.8337  decode.d6.loss_dice: 1.5391  decode.d7.loss_cls: 1.1639  decode.d7.loss_mask: 0.8062  decode.d7.loss_dice: 1.5213  decode.d8.loss_cls: 1.1871  decode.d8.loss_mask: 0.7947  decode.d8.loss_dice: 1.5452
2023/05/24 11:49:28 - mmengine - INFO - Iter(train) [141450/160000]  lr: 1.4381e-06  eta: 2:13:59  time: 0.4360  data_time: 0.0100  memory: 4871  grad_norm: 84.4448  loss: 25.0800  decode.loss_cls: 0.7838  decode.loss_mask: 0.5526  decode.loss_dice: 0.8955  decode.d0.loss_cls: 2.7439  decode.d0.loss_mask: 0.6313  decode.d0.loss_dice: 1.0850  decode.d1.loss_cls: 0.8340  decode.d1.loss_mask: 0.6064  decode.d1.loss_dice: 0.9983  decode.d2.loss_cls: 0.8451  decode.d2.loss_mask: 0.5579  decode.d2.loss_dice: 0.9572  decode.d3.loss_cls: 0.8424  decode.d3.loss_mask: 0.5466  decode.d3.loss_dice: 0.9357  decode.d4.loss_cls: 0.7886  decode.d4.loss_mask: 0.5750  decode.d4.loss_dice: 0.9547  decode.d5.loss_cls: 0.7737  decode.d5.loss_mask: 0.5387  decode.d5.loss_dice: 0.9361  decode.d6.loss_cls: 0.7970  decode.d6.loss_mask: 0.5381  decode.d6.loss_dice: 0.8907  decode.d7.loss_cls: 0.7907  decode.d7.loss_mask: 0.5338  decode.d7.loss_dice: 0.9143  decode.d8.loss_cls: 0.7855  decode.d8.loss_mask: 0.5453  decode.d8.loss_dice: 0.9022
2023/05/24 11:49:49 - mmengine - INFO - Iter(train) [141500/160000]  lr: 1.4347e-06  eta: 2:13:38  time: 0.4155  data_time: 0.0102  memory: 4926  grad_norm: 90.7523  loss: 32.7128  decode.loss_cls: 0.9715  decode.loss_mask: 0.6112  decode.loss_dice: 1.3186  decode.d0.loss_cls: 3.1676  decode.d0.loss_mask: 0.7186  decode.d0.loss_dice: 1.5791  decode.d1.loss_cls: 1.2224  decode.d1.loss_mask: 0.6805  decode.d1.loss_dice: 1.5567  decode.d2.loss_cls: 1.1753  decode.d2.loss_mask: 0.6420  decode.d2.loss_dice: 1.4133  decode.d3.loss_cls: 1.0646  decode.d3.loss_mask: 0.6195  decode.d3.loss_dice: 1.3233  decode.d4.loss_cls: 1.0838  decode.d4.loss_mask: 0.6295  decode.d4.loss_dice: 1.3363  decode.d5.loss_cls: 1.0233  decode.d5.loss_mask: 0.6080  decode.d5.loss_dice: 1.2872  decode.d6.loss_cls: 0.9637  decode.d6.loss_mask: 0.6160  decode.d6.loss_dice: 1.3295  decode.d7.loss_cls: 0.9636  decode.d7.loss_mask: 0.6074  decode.d7.loss_dice: 1.2995  decode.d8.loss_cls: 0.9581  decode.d8.loss_mask: 0.6153  decode.d8.loss_dice: 1.3277
2023/05/24 11:50:10 - mmengine - INFO - Iter(train) [141550/160000]  lr: 1.4312e-06  eta: 2:13:16  time: 0.4243  data_time: 0.0099  memory: 4815  grad_norm: 100.3843  loss: 26.9225  decode.loss_cls: 0.8903  decode.loss_mask: 0.6842  decode.loss_dice: 0.8310  decode.d0.loss_cls: 2.7943  decode.d0.loss_mask: 0.7524  decode.d0.loss_dice: 0.9828  decode.d1.loss_cls: 0.9726  decode.d1.loss_mask: 0.7555  decode.d1.loss_dice: 1.0018  decode.d2.loss_cls: 0.9068  decode.d2.loss_mask: 0.7172  decode.d2.loss_dice: 0.9260  decode.d3.loss_cls: 0.9414  decode.d3.loss_mask: 0.7020  decode.d3.loss_dice: 0.8777  decode.d4.loss_cls: 0.8762  decode.d4.loss_mask: 0.6835  decode.d4.loss_dice: 0.8581  decode.d5.loss_cls: 0.9093  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 0.8421  decode.d6.loss_cls: 0.9220  decode.d6.loss_mask: 0.6700  decode.d6.loss_dice: 0.8507  decode.d7.loss_cls: 0.8936  decode.d7.loss_mask: 0.6831  decode.d7.loss_dice: 0.8722  decode.d8.loss_cls: 0.8956  decode.d8.loss_mask: 0.6866  decode.d8.loss_dice: 0.8493
2023/05/24 11:50:32 - mmengine - INFO - Iter(train) [141600/160000]  lr: 1.4277e-06  eta: 2:12:54  time: 0.4333  data_time: 0.0100  memory: 4834  grad_norm: 88.8461  loss: 27.9877  decode.loss_cls: 0.9142  decode.loss_mask: 0.6349  decode.loss_dice: 0.9471  decode.d0.loss_cls: 2.5380  decode.d0.loss_mask: 0.7285  decode.d0.loss_dice: 1.1760  decode.d1.loss_cls: 0.9851  decode.d1.loss_mask: 0.7180  decode.d1.loss_dice: 1.1334  decode.d2.loss_cls: 0.9317  decode.d2.loss_mask: 0.7041  decode.d2.loss_dice: 1.1033  decode.d3.loss_cls: 0.9915  decode.d3.loss_mask: 0.6531  decode.d3.loss_dice: 0.9948  decode.d4.loss_cls: 0.8909  decode.d4.loss_mask: 0.6834  decode.d4.loss_dice: 1.0221  decode.d5.loss_cls: 0.8900  decode.d5.loss_mask: 0.6712  decode.d5.loss_dice: 1.0083  decode.d6.loss_cls: 0.9454  decode.d6.loss_mask: 0.6562  decode.d6.loss_dice: 0.9916  decode.d7.loss_cls: 0.9036  decode.d7.loss_mask: 0.6428  decode.d7.loss_dice: 0.9953  decode.d8.loss_cls: 0.9217  decode.d8.loss_mask: 0.6398  decode.d8.loss_dice: 0.9718
2023/05/24 11:50:55 - mmengine - INFO - Iter(train) [141650/160000]  lr: 1.4242e-06  eta: 2:12:33  time: 0.4827  data_time: 0.0097  memory: 4890  grad_norm: 102.8774  loss: 28.0633  decode.loss_cls: 1.0764  decode.loss_mask: 0.5780  decode.loss_dice: 0.8467  decode.d0.loss_cls: 3.3102  decode.d0.loss_mask: 0.6444  decode.d0.loss_dice: 1.1038  decode.d1.loss_cls: 1.1532  decode.d1.loss_mask: 0.6786  decode.d1.loss_dice: 1.0009  decode.d2.loss_cls: 1.1595  decode.d2.loss_mask: 0.5971  decode.d2.loss_dice: 0.8703  decode.d3.loss_cls: 1.0943  decode.d3.loss_mask: 0.6065  decode.d3.loss_dice: 0.8351  decode.d4.loss_cls: 1.0669  decode.d4.loss_mask: 0.6235  decode.d4.loss_dice: 0.8592  decode.d5.loss_cls: 1.0867  decode.d5.loss_mask: 0.5866  decode.d5.loss_dice: 0.8529  decode.d6.loss_cls: 1.0650  decode.d6.loss_mask: 0.5781  decode.d6.loss_dice: 0.8550  decode.d7.loss_cls: 1.0570  decode.d7.loss_mask: 0.5756  decode.d7.loss_dice: 0.8309  decode.d8.loss_cls: 1.0609  decode.d8.loss_mask: 0.5726  decode.d8.loss_dice: 0.8375
2023/05/24 11:51:16 - mmengine - INFO - Iter(train) [141700/160000]  lr: 1.4207e-06  eta: 2:12:11  time: 0.4181  data_time: 0.0098  memory: 4877  grad_norm: 86.8206  loss: 29.1796  decode.loss_cls: 0.9221  decode.loss_mask: 0.6618  decode.loss_dice: 1.0769  decode.d0.loss_cls: 2.7075  decode.d0.loss_mask: 0.6624  decode.d0.loss_dice: 1.2338  decode.d1.loss_cls: 1.0412  decode.d1.loss_mask: 0.6800  decode.d1.loss_dice: 1.2003  decode.d2.loss_cls: 0.9696  decode.d2.loss_mask: 0.6862  decode.d2.loss_dice: 1.1167  decode.d3.loss_cls: 0.9427  decode.d3.loss_mask: 0.6935  decode.d3.loss_dice: 1.0839  decode.d4.loss_cls: 0.9486  decode.d4.loss_mask: 0.6992  decode.d4.loss_dice: 1.0962  decode.d5.loss_cls: 0.9136  decode.d5.loss_mask: 0.6954  decode.d5.loss_dice: 1.0987  decode.d6.loss_cls: 0.9035  decode.d6.loss_mask: 0.6933  decode.d6.loss_dice: 1.0903  decode.d7.loss_cls: 0.8854  decode.d7.loss_mask: 0.6956  decode.d7.loss_dice: 1.1124  decode.d8.loss_cls: 0.8900  decode.d8.loss_mask: 0.6672  decode.d8.loss_dice: 1.1116
2023/05/24 11:51:38 - mmengine - INFO - Iter(train) [141750/160000]  lr: 1.4172e-06  eta: 2:11:49  time: 0.4264  data_time: 0.0101  memory: 4829  grad_norm: 95.5845  loss: 40.2556  decode.loss_cls: 1.4387  decode.loss_mask: 0.9477  decode.loss_dice: 1.3630  decode.d0.loss_cls: 3.3933  decode.d0.loss_mask: 1.0123  decode.d0.loss_dice: 1.6465  decode.d1.loss_cls: 1.5236  decode.d1.loss_mask: 0.9551  decode.d1.loss_dice: 1.5713  decode.d2.loss_cls: 1.4360  decode.d2.loss_mask: 0.9841  decode.d2.loss_dice: 1.4584  decode.d3.loss_cls: 1.4432  decode.d3.loss_mask: 0.9234  decode.d3.loss_dice: 1.4152  decode.d4.loss_cls: 1.4332  decode.d4.loss_mask: 0.9090  decode.d4.loss_dice: 1.4191  decode.d5.loss_cls: 1.4221  decode.d5.loss_mask: 0.9139  decode.d5.loss_dice: 1.3832  decode.d6.loss_cls: 1.4289  decode.d6.loss_mask: 0.9311  decode.d6.loss_dice: 1.3716  decode.d7.loss_cls: 1.4653  decode.d7.loss_mask: 0.9332  decode.d7.loss_dice: 1.3773  decode.d8.loss_cls: 1.4838  decode.d8.loss_mask: 0.9214  decode.d8.loss_dice: 1.3510
2023/05/24 11:51:59 - mmengine - INFO - Iter(train) [141800/160000]  lr: 1.4137e-06  eta: 2:11:28  time: 0.4255  data_time: 0.0102  memory: 4864  grad_norm: 89.1254  loss: 38.8397  decode.loss_cls: 1.2322  decode.loss_mask: 0.7957  decode.loss_dice: 1.5754  decode.d0.loss_cls: 3.0768  decode.d0.loss_mask: 0.9086  decode.d0.loss_dice: 1.8314  decode.d1.loss_cls: 1.3389  decode.d1.loss_mask: 0.8347  decode.d1.loss_dice: 1.6697  decode.d2.loss_cls: 1.3246  decode.d2.loss_mask: 0.8012  decode.d2.loss_dice: 1.6010  decode.d3.loss_cls: 1.3137  decode.d3.loss_mask: 0.7895  decode.d3.loss_dice: 1.5761  decode.d4.loss_cls: 1.2511  decode.d4.loss_mask: 0.8049  decode.d4.loss_dice: 1.5547  decode.d5.loss_cls: 1.2613  decode.d5.loss_mask: 0.8078  decode.d5.loss_dice: 1.5797  decode.d6.loss_cls: 1.2386  decode.d6.loss_mask: 0.8019  decode.d6.loss_dice: 1.5879  decode.d7.loss_cls: 1.2568  decode.d7.loss_mask: 0.8047  decode.d7.loss_dice: 1.6061  decode.d8.loss_cls: 1.2226  decode.d8.loss_mask: 0.8122  decode.d8.loss_dice: 1.5799
2023/05/24 11:52:21 - mmengine - INFO - Iter(train) [141850/160000]  lr: 1.4102e-06  eta: 2:11:06  time: 0.4184  data_time: 0.0100  memory: 4878  grad_norm: 87.0469  loss: 29.1173  decode.loss_cls: 1.0431  decode.loss_mask: 0.6861  decode.loss_dice: 0.9229  decode.d0.loss_cls: 2.9354  decode.d0.loss_mask: 0.7549  decode.d0.loss_dice: 1.0924  decode.d1.loss_cls: 1.1974  decode.d1.loss_mask: 0.7424  decode.d1.loss_dice: 1.0086  decode.d2.loss_cls: 1.0874  decode.d2.loss_mask: 0.7017  decode.d2.loss_dice: 0.9718  decode.d3.loss_cls: 1.1082  decode.d3.loss_mask: 0.7078  decode.d3.loss_dice: 0.9160  decode.d4.loss_cls: 1.0867  decode.d4.loss_mask: 0.6577  decode.d4.loss_dice: 0.8966  decode.d5.loss_cls: 1.0755  decode.d5.loss_mask: 0.6632  decode.d5.loss_dice: 0.9135  decode.d6.loss_cls: 1.1038  decode.d6.loss_mask: 0.6510  decode.d6.loss_dice: 0.9048  decode.d7.loss_cls: 1.1046  decode.d7.loss_mask: 0.6469  decode.d7.loss_dice: 0.8986  decode.d8.loss_cls: 1.0534  decode.d8.loss_mask: 0.6669  decode.d8.loss_dice: 0.9179
2023/05/24 11:52:42 - mmengine - INFO - Iter(train) [141900/160000]  lr: 1.4067e-06  eta: 2:10:44  time: 0.4168  data_time: 0.0097  memory: 4938  grad_norm: 95.2422  loss: 30.4208  decode.loss_cls: 0.9775  decode.loss_mask: 0.8110  decode.loss_dice: 0.9854  decode.d0.loss_cls: 3.0027  decode.d0.loss_mask: 0.8388  decode.d0.loss_dice: 1.1653  decode.d1.loss_cls: 1.1033  decode.d1.loss_mask: 0.8468  decode.d1.loss_dice: 1.1189  decode.d2.loss_cls: 1.0344  decode.d2.loss_mask: 0.8385  decode.d2.loss_dice: 1.0543  decode.d3.loss_cls: 1.0283  decode.d3.loss_mask: 0.8173  decode.d3.loss_dice: 0.9874  decode.d4.loss_cls: 1.0097  decode.d4.loss_mask: 0.7991  decode.d4.loss_dice: 0.9743  decode.d5.loss_cls: 0.9527  decode.d5.loss_mask: 0.8416  decode.d5.loss_dice: 0.9994  decode.d6.loss_cls: 1.0167  decode.d6.loss_mask: 0.7730  decode.d6.loss_dice: 0.9518  decode.d7.loss_cls: 0.9888  decode.d7.loss_mask: 0.7827  decode.d7.loss_dice: 0.9652  decode.d8.loss_cls: 0.9921  decode.d8.loss_mask: 0.7867  decode.d8.loss_dice: 0.9773
2023/05/24 11:53:04 - mmengine - INFO - Iter(train) [141950/160000]  lr: 1.4032e-06  eta: 2:10:23  time: 0.4181  data_time: 0.0100  memory: 4866  grad_norm: 152.2138  loss: 34.8109  decode.loss_cls: 1.2578  decode.loss_mask: 0.6448  decode.loss_dice: 1.2361  decode.d0.loss_cls: 3.2001  decode.d0.loss_mask: 0.6506  decode.d0.loss_dice: 1.5819  decode.d1.loss_cls: 1.4548  decode.d1.loss_mask: 0.6626  decode.d1.loss_dice: 1.3993  decode.d2.loss_cls: 1.3592  decode.d2.loss_mask: 0.6706  decode.d2.loss_dice: 1.3348  decode.d3.loss_cls: 1.3378  decode.d3.loss_mask: 0.6467  decode.d3.loss_dice: 1.2926  decode.d4.loss_cls: 1.3072  decode.d4.loss_mask: 0.6423  decode.d4.loss_dice: 1.2933  decode.d5.loss_cls: 1.3094  decode.d5.loss_mask: 0.6617  decode.d5.loss_dice: 1.2894  decode.d6.loss_cls: 1.2916  decode.d6.loss_mask: 0.6455  decode.d6.loss_dice: 1.2656  decode.d7.loss_cls: 1.2268  decode.d7.loss_mask: 0.6424  decode.d7.loss_dice: 1.2916  decode.d8.loss_cls: 1.2892  decode.d8.loss_mask: 0.6393  decode.d8.loss_dice: 1.2860
2023/05/24 11:53:25 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 11:53:25 - mmengine - INFO - Iter(train) [142000/160000]  lr: 1.3997e-06  eta: 2:10:01  time: 0.4223  data_time: 0.0102  memory: 4858  grad_norm: 90.6465  loss: 35.7461  decode.loss_cls: 1.1511  decode.loss_mask: 0.8093  decode.loss_dice: 1.2796  decode.d0.loss_cls: 3.0594  decode.d0.loss_mask: 0.8471  decode.d0.loss_dice: 1.5590  decode.d1.loss_cls: 1.3514  decode.d1.loss_mask: 0.8612  decode.d1.loss_dice: 1.3870  decode.d2.loss_cls: 1.1976  decode.d2.loss_mask: 0.8527  decode.d2.loss_dice: 1.3595  decode.d3.loss_cls: 1.2205  decode.d3.loss_mask: 0.8246  decode.d3.loss_dice: 1.3526  decode.d4.loss_cls: 1.2104  decode.d4.loss_mask: 0.8177  decode.d4.loss_dice: 1.3625  decode.d5.loss_cls: 1.1805  decode.d5.loss_mask: 0.8290  decode.d5.loss_dice: 1.3329  decode.d6.loss_cls: 1.1819  decode.d6.loss_mask: 0.8109  decode.d6.loss_dice: 1.3294  decode.d7.loss_cls: 1.2379  decode.d7.loss_mask: 0.8024  decode.d7.loss_dice: 1.2694  decode.d8.loss_cls: 1.1474  decode.d8.loss_mask: 0.8063  decode.d8.loss_dice: 1.3150
2023/05/24 11:53:25 - mmengine - INFO - Saving checkpoint at 142000 iterations
2023/05/24 11:53:52 - mmengine - INFO - Iter(train) [142050/160000]  lr: 1.3962e-06  eta: 2:09:40  time: 0.4253  data_time: 0.0098  memory: 4853  grad_norm: 100.1078  loss: 36.4434  decode.loss_cls: 1.4121  decode.loss_mask: 0.6486  decode.loss_dice: 1.2560  decode.d0.loss_cls: 3.4672  decode.d0.loss_mask: 0.7336  decode.d0.loss_dice: 1.4764  decode.d1.loss_cls: 1.5849  decode.d1.loss_mask: 0.7234  decode.d1.loss_dice: 1.3833  decode.d2.loss_cls: 1.4834  decode.d2.loss_mask: 0.6934  decode.d2.loss_dice: 1.3478  decode.d3.loss_cls: 1.5130  decode.d3.loss_mask: 0.6694  decode.d3.loss_dice: 1.2878  decode.d4.loss_cls: 1.4584  decode.d4.loss_mask: 0.6694  decode.d4.loss_dice: 1.2742  decode.d5.loss_cls: 1.4047  decode.d5.loss_mask: 0.6461  decode.d5.loss_dice: 1.3070  decode.d6.loss_cls: 1.4558  decode.d6.loss_mask: 0.6491  decode.d6.loss_dice: 1.2648  decode.d7.loss_cls: 1.4010  decode.d7.loss_mask: 0.6525  decode.d7.loss_dice: 1.2638  decode.d8.loss_cls: 1.4129  decode.d8.loss_mask: 0.6531  decode.d8.loss_dice: 1.2503
2023/05/24 11:54:16 - mmengine - INFO - Iter(train) [142100/160000]  lr: 1.3927e-06  eta: 2:09:19  time: 0.4780  data_time: 0.0096  memory: 4894  grad_norm: 122.5555  loss: 40.4354  decode.loss_cls: 1.3629  decode.loss_mask: 0.8080  decode.loss_dice: 1.5280  decode.d0.loss_cls: 3.3817  decode.d0.loss_mask: 0.8300  decode.d0.loss_dice: 1.7807  decode.d1.loss_cls: 1.4608  decode.d1.loss_mask: 0.8571  decode.d1.loss_dice: 1.6905  decode.d2.loss_cls: 1.4077  decode.d2.loss_mask: 0.8352  decode.d2.loss_dice: 1.6401  decode.d3.loss_cls: 1.4038  decode.d3.loss_mask: 0.8341  decode.d3.loss_dice: 1.5760  decode.d4.loss_cls: 1.4479  decode.d4.loss_mask: 0.8040  decode.d4.loss_dice: 1.5412  decode.d5.loss_cls: 1.4585  decode.d5.loss_mask: 0.8503  decode.d5.loss_dice: 1.5545  decode.d6.loss_cls: 1.4480  decode.d6.loss_mask: 0.8396  decode.d6.loss_dice: 1.5385  decode.d7.loss_cls: 1.4753  decode.d7.loss_mask: 0.8029  decode.d7.loss_dice: 1.5178  decode.d8.loss_cls: 1.4149  decode.d8.loss_mask: 0.8171  decode.d8.loss_dice: 1.5284
2023/05/24 11:54:39 - mmengine - INFO - Iter(train) [142150/160000]  lr: 1.3892e-06  eta: 2:08:57  time: 0.4733  data_time: 0.0097  memory: 4857  grad_norm: 105.9566  loss: 36.6989  decode.loss_cls: 1.3229  decode.loss_mask: 0.8657  decode.loss_dice: 1.2288  decode.d0.loss_cls: 2.9859  decode.d0.loss_mask: 0.9462  decode.d0.loss_dice: 1.4739  decode.d1.loss_cls: 1.4387  decode.d1.loss_mask: 0.9547  decode.d1.loss_dice: 1.3595  decode.d2.loss_cls: 1.3646  decode.d2.loss_mask: 0.9308  decode.d2.loss_dice: 1.2892  decode.d3.loss_cls: 1.3787  decode.d3.loss_mask: 0.8702  decode.d3.loss_dice: 1.2312  decode.d4.loss_cls: 1.3670  decode.d4.loss_mask: 0.8833  decode.d4.loss_dice: 1.2224  decode.d5.loss_cls: 1.3567  decode.d5.loss_mask: 0.8507  decode.d5.loss_dice: 1.2063  decode.d6.loss_cls: 1.3165  decode.d6.loss_mask: 0.8497  decode.d6.loss_dice: 1.2257  decode.d7.loss_cls: 1.3565  decode.d7.loss_mask: 0.8500  decode.d7.loss_dice: 1.2120  decode.d8.loss_cls: 1.2972  decode.d8.loss_mask: 0.8472  decode.d8.loss_dice: 1.2168
2023/05/24 11:55:01 - mmengine - INFO - Iter(train) [142200/160000]  lr: 1.3857e-06  eta: 2:08:35  time: 0.4304  data_time: 0.0100  memory: 4877  grad_norm: 156.5128  loss: 36.9959  decode.loss_cls: 1.2462  decode.loss_mask: 0.8413  decode.loss_dice: 1.3588  decode.d0.loss_cls: 3.2901  decode.d0.loss_mask: 0.8354  decode.d0.loss_dice: 1.4895  decode.d1.loss_cls: 1.4089  decode.d1.loss_mask: 0.9171  decode.d1.loss_dice: 1.4425  decode.d2.loss_cls: 1.3475  decode.d2.loss_mask: 0.8203  decode.d2.loss_dice: 1.3578  decode.d3.loss_cls: 1.3013  decode.d3.loss_mask: 0.8129  decode.d3.loss_dice: 1.3642  decode.d4.loss_cls: 1.2498  decode.d4.loss_mask: 0.7999  decode.d4.loss_dice: 1.3585  decode.d5.loss_cls: 1.2584  decode.d5.loss_mask: 0.8170  decode.d5.loss_dice: 1.3771  decode.d6.loss_cls: 1.2371  decode.d6.loss_mask: 0.8225  decode.d6.loss_dice: 1.3583  decode.d7.loss_cls: 1.2184  decode.d7.loss_mask: 0.8230  decode.d7.loss_dice: 1.3722  decode.d8.loss_cls: 1.2626  decode.d8.loss_mask: 0.8378  decode.d8.loss_dice: 1.3694
2023/05/24 11:55:22 - mmengine - INFO - Iter(train) [142250/160000]  lr: 1.3822e-06  eta: 2:08:14  time: 0.4234  data_time: 0.0106  memory: 4846  grad_norm: 96.4304  loss: 30.8328  decode.loss_cls: 0.8525  decode.loss_mask: 0.7071  decode.loss_dice: 1.2465  decode.d0.loss_cls: 2.8684  decode.d0.loss_mask: 0.7253  decode.d0.loss_dice: 1.3939  decode.d1.loss_cls: 0.9888  decode.d1.loss_mask: 0.6871  decode.d1.loss_dice: 1.3054  decode.d2.loss_cls: 0.9273  decode.d2.loss_mask: 0.6685  decode.d2.loss_dice: 1.2567  decode.d3.loss_cls: 0.9404  decode.d3.loss_mask: 0.6912  decode.d3.loss_dice: 1.2462  decode.d4.loss_cls: 0.9078  decode.d4.loss_mask: 0.6962  decode.d4.loss_dice: 1.2413  decode.d5.loss_cls: 0.8753  decode.d5.loss_mask: 0.7070  decode.d5.loss_dice: 1.2734  decode.d6.loss_cls: 0.9022  decode.d6.loss_mask: 0.7039  decode.d6.loss_dice: 1.2810  decode.d7.loss_cls: 0.9121  decode.d7.loss_mask: 0.7131  decode.d7.loss_dice: 1.2720  decode.d8.loss_cls: 0.8725  decode.d8.loss_mask: 0.7156  decode.d8.loss_dice: 1.2540
2023/05/24 11:55:43 - mmengine - INFO - Iter(train) [142300/160000]  lr: 1.3787e-06  eta: 2:07:52  time: 0.4218  data_time: 0.0098  memory: 4869  grad_norm: 95.2304  loss: 37.0385  decode.loss_cls: 1.2371  decode.loss_mask: 0.9288  decode.loss_dice: 1.3154  decode.d0.loss_cls: 2.9129  decode.d0.loss_mask: 0.9097  decode.d0.loss_dice: 1.5490  decode.d1.loss_cls: 1.3052  decode.d1.loss_mask: 0.8882  decode.d1.loss_dice: 1.4331  decode.d2.loss_cls: 1.2570  decode.d2.loss_mask: 0.9025  decode.d2.loss_dice: 1.3985  decode.d3.loss_cls: 1.2772  decode.d3.loss_mask: 0.8604  decode.d3.loss_dice: 1.3266  decode.d4.loss_cls: 1.2078  decode.d4.loss_mask: 0.9032  decode.d4.loss_dice: 1.3740  decode.d5.loss_cls: 1.2049  decode.d5.loss_mask: 0.9048  decode.d5.loss_dice: 1.3266  decode.d6.loss_cls: 1.2760  decode.d6.loss_mask: 0.9197  decode.d6.loss_dice: 1.3527  decode.d7.loss_cls: 1.2372  decode.d7.loss_mask: 0.9464  decode.d7.loss_dice: 1.3641  decode.d8.loss_cls: 1.2034  decode.d8.loss_mask: 0.9470  decode.d8.loss_dice: 1.3692
2023/05/24 11:56:06 - mmengine - INFO - Iter(train) [142350/160000]  lr: 1.3752e-06  eta: 2:07:30  time: 0.4802  data_time: 0.0101  memory: 4859  grad_norm: 87.1301  loss: 44.5539  decode.loss_cls: 1.4117  decode.loss_mask: 1.0318  decode.loss_dice: 1.7253  decode.d0.loss_cls: 3.2935  decode.d0.loss_mask: 1.1655  decode.d0.loss_dice: 1.9613  decode.d1.loss_cls: 1.5795  decode.d1.loss_mask: 1.1422  decode.d1.loss_dice: 1.7977  decode.d2.loss_cls: 1.5187  decode.d2.loss_mask: 1.0980  decode.d2.loss_dice: 1.7735  decode.d3.loss_cls: 1.4386  decode.d3.loss_mask: 1.0727  decode.d3.loss_dice: 1.7561  decode.d4.loss_cls: 1.4239  decode.d4.loss_mask: 1.0571  decode.d4.loss_dice: 1.7455  decode.d5.loss_cls: 1.4279  decode.d5.loss_mask: 1.0591  decode.d5.loss_dice: 1.7149  decode.d6.loss_cls: 1.4049  decode.d6.loss_mask: 1.0311  decode.d6.loss_dice: 1.7007  decode.d7.loss_cls: 1.3826  decode.d7.loss_mask: 1.0490  decode.d7.loss_dice: 1.7145  decode.d8.loss_cls: 1.3229  decode.d8.loss_mask: 1.0553  decode.d8.loss_dice: 1.6983
2023/05/24 11:56:27 - mmengine - INFO - Iter(train) [142400/160000]  lr: 1.3717e-06  eta: 2:07:09  time: 0.4221  data_time: 0.0101  memory: 4886  grad_norm: 93.5864  loss: 37.7203  decode.loss_cls: 1.1186  decode.loss_mask: 0.7887  decode.loss_dice: 1.5622  decode.d0.loss_cls: 3.2998  decode.d0.loss_mask: 0.8890  decode.d0.loss_dice: 1.8624  decode.d1.loss_cls: 1.3638  decode.d1.loss_mask: 0.8096  decode.d1.loss_dice: 1.6857  decode.d2.loss_cls: 1.2295  decode.d2.loss_mask: 0.7714  decode.d2.loss_dice: 1.6115  decode.d3.loss_cls: 1.1996  decode.d3.loss_mask: 0.7745  decode.d3.loss_dice: 1.5557  decode.d4.loss_cls: 1.1706  decode.d4.loss_mask: 0.7770  decode.d4.loss_dice: 1.5458  decode.d5.loss_cls: 1.1223  decode.d5.loss_mask: 0.7747  decode.d5.loss_dice: 1.5268  decode.d6.loss_cls: 1.1578  decode.d6.loss_mask: 0.7677  decode.d6.loss_dice: 1.4869  decode.d7.loss_cls: 1.1377  decode.d7.loss_mask: 0.7891  decode.d7.loss_dice: 1.5300  decode.d8.loss_cls: 1.1178  decode.d8.loss_mask: 0.7792  decode.d8.loss_dice: 1.5149
2023/05/24 11:56:48 - mmengine - INFO - Iter(train) [142450/160000]  lr: 1.3682e-06  eta: 2:06:47  time: 0.4245  data_time: 0.0102  memory: 4928  grad_norm: 85.6466  loss: 39.5472  decode.loss_cls: 1.2257  decode.loss_mask: 0.8302  decode.loss_dice: 1.5318  decode.d0.loss_cls: 3.4801  decode.d0.loss_mask: 0.8834  decode.d0.loss_dice: 1.7944  decode.d1.loss_cls: 1.4685  decode.d1.loss_mask: 0.8815  decode.d1.loss_dice: 1.7013  decode.d2.loss_cls: 1.2926  decode.d2.loss_mask: 0.8616  decode.d2.loss_dice: 1.6197  decode.d3.loss_cls: 1.2461  decode.d3.loss_mask: 0.8405  decode.d3.loss_dice: 1.5330  decode.d4.loss_cls: 1.2626  decode.d4.loss_mask: 0.8486  decode.d4.loss_dice: 1.5917  decode.d5.loss_cls: 1.3090  decode.d5.loss_mask: 0.8254  decode.d5.loss_dice: 1.5468  decode.d6.loss_cls: 1.2768  decode.d6.loss_mask: 0.8632  decode.d6.loss_dice: 1.5675  decode.d7.loss_cls: 1.2289  decode.d7.loss_mask: 0.8629  decode.d7.loss_dice: 1.5721  decode.d8.loss_cls: 1.2518  decode.d8.loss_mask: 0.8232  decode.d8.loss_dice: 1.5265
2023/05/24 11:57:10 - mmengine - INFO - Iter(train) [142500/160000]  lr: 1.3647e-06  eta: 2:06:25  time: 0.4316  data_time: 0.0098  memory: 4847  grad_norm: 87.6507  loss: 42.9391  decode.loss_cls: 1.2749  decode.loss_mask: 0.8553  decode.loss_dice: 1.7369  decode.d0.loss_cls: 3.5293  decode.d0.loss_mask: 0.9369  decode.d0.loss_dice: 2.1045  decode.d1.loss_cls: 1.6256  decode.d1.loss_mask: 0.9196  decode.d1.loss_dice: 1.9080  decode.d2.loss_cls: 1.4643  decode.d2.loss_mask: 0.8799  decode.d2.loss_dice: 1.8120  decode.d3.loss_cls: 1.4526  decode.d3.loss_mask: 0.8976  decode.d3.loss_dice: 1.7844  decode.d4.loss_cls: 1.3754  decode.d4.loss_mask: 0.8802  decode.d4.loss_dice: 1.7418  decode.d5.loss_cls: 1.3661  decode.d5.loss_mask: 0.8805  decode.d5.loss_dice: 1.7502  decode.d6.loss_cls: 1.3623  decode.d6.loss_mask: 0.8570  decode.d6.loss_dice: 1.6934  decode.d7.loss_cls: 1.3597  decode.d7.loss_mask: 0.8698  decode.d7.loss_dice: 1.7352  decode.d8.loss_cls: 1.2897  decode.d8.loss_mask: 0.8636  decode.d8.loss_dice: 1.7327
2023/05/24 11:57:31 - mmengine - INFO - Iter(train) [142550/160000]  lr: 1.3612e-06  eta: 2:06:03  time: 0.4306  data_time: 0.0099  memory: 4845  grad_norm: 89.8067  loss: 35.0460  decode.loss_cls: 1.1723  decode.loss_mask: 0.8060  decode.loss_dice: 1.3111  decode.d0.loss_cls: 2.8453  decode.d0.loss_mask: 0.8236  decode.d0.loss_dice: 1.5403  decode.d1.loss_cls: 1.2645  decode.d1.loss_mask: 0.7546  decode.d1.loss_dice: 1.3843  decode.d2.loss_cls: 1.2098  decode.d2.loss_mask: 0.8075  decode.d2.loss_dice: 1.3499  decode.d3.loss_cls: 1.2029  decode.d3.loss_mask: 0.7797  decode.d3.loss_dice: 1.3266  decode.d4.loss_cls: 1.2184  decode.d4.loss_mask: 0.8038  decode.d4.loss_dice: 1.3430  decode.d5.loss_cls: 1.1619  decode.d5.loss_mask: 0.7740  decode.d5.loss_dice: 1.3522  decode.d6.loss_cls: 1.2041  decode.d6.loss_mask: 0.7843  decode.d6.loss_dice: 1.2776  decode.d7.loss_cls: 1.1860  decode.d7.loss_mask: 0.7615  decode.d7.loss_dice: 1.2989  decode.d8.loss_cls: 1.1778  decode.d8.loss_mask: 0.8166  decode.d8.loss_dice: 1.3075
2023/05/24 11:57:54 - mmengine - INFO - Iter(train) [142600/160000]  lr: 1.3577e-06  eta: 2:05:42  time: 0.4298  data_time: 0.0104  memory: 4865  grad_norm: 103.6810  loss: 29.1226  decode.loss_cls: 0.8937  decode.loss_mask: 0.6196  decode.loss_dice: 1.0974  decode.d0.loss_cls: 2.9622  decode.d0.loss_mask: 0.6829  decode.d0.loss_dice: 1.2606  decode.d1.loss_cls: 1.1044  decode.d1.loss_mask: 0.6279  decode.d1.loss_dice: 1.1703  decode.d2.loss_cls: 1.0057  decode.d2.loss_mask: 0.6168  decode.d2.loss_dice: 1.1157  decode.d3.loss_cls: 0.9330  decode.d3.loss_mask: 0.6491  decode.d3.loss_dice: 1.0908  decode.d4.loss_cls: 0.8864  decode.d4.loss_mask: 0.6694  decode.d4.loss_dice: 1.0872  decode.d5.loss_cls: 0.9522  decode.d5.loss_mask: 0.6441  decode.d5.loss_dice: 1.0652  decode.d6.loss_cls: 0.9822  decode.d6.loss_mask: 0.6090  decode.d6.loss_dice: 1.0771  decode.d7.loss_cls: 0.9579  decode.d7.loss_mask: 0.6169  decode.d7.loss_dice: 1.0723  decode.d8.loss_cls: 0.9611  decode.d8.loss_mask: 0.6094  decode.d8.loss_dice: 1.1018
2023/05/24 11:58:16 - mmengine - INFO - Iter(train) [142650/160000]  lr: 1.3541e-06  eta: 2:05:20  time: 0.4351  data_time: 0.0102  memory: 4878  grad_norm: 92.8633  loss: 41.2801  decode.loss_cls: 1.4798  decode.loss_mask: 0.9223  decode.loss_dice: 1.4140  decode.d0.loss_cls: 3.6081  decode.d0.loss_mask: 1.0976  decode.d0.loss_dice: 1.7121  decode.d1.loss_cls: 1.6236  decode.d1.loss_mask: 1.0144  decode.d1.loss_dice: 1.5418  decode.d2.loss_cls: 1.6661  decode.d2.loss_mask: 0.9577  decode.d2.loss_dice: 1.4202  decode.d3.loss_cls: 1.5081  decode.d3.loss_mask: 0.8889  decode.d3.loss_dice: 1.4177  decode.d4.loss_cls: 1.5272  decode.d4.loss_mask: 0.8791  decode.d4.loss_dice: 1.4136  decode.d5.loss_cls: 1.4898  decode.d5.loss_mask: 0.8871  decode.d5.loss_dice: 1.4113  decode.d6.loss_cls: 1.4643  decode.d6.loss_mask: 0.8922  decode.d6.loss_dice: 1.3997  decode.d7.loss_cls: 1.5012  decode.d7.loss_mask: 0.9132  decode.d7.loss_dice: 1.4041  decode.d8.loss_cls: 1.4794  decode.d8.loss_mask: 0.9166  decode.d8.loss_dice: 1.4289
2023/05/24 11:58:37 - mmengine - INFO - Iter(train) [142700/160000]  lr: 1.3506e-06  eta: 2:04:59  time: 0.4214  data_time: 0.0103  memory: 4907  grad_norm: 90.7269  loss: 30.6046  decode.loss_cls: 1.1603  decode.loss_mask: 0.5715  decode.loss_dice: 1.0372  decode.d0.loss_cls: 3.0254  decode.d0.loss_mask: 0.6446  decode.d0.loss_dice: 1.2407  decode.d1.loss_cls: 1.2727  decode.d1.loss_mask: 0.6387  decode.d1.loss_dice: 1.1893  decode.d2.loss_cls: 1.2719  decode.d2.loss_mask: 0.5902  decode.d2.loss_dice: 1.0977  decode.d3.loss_cls: 1.1357  decode.d3.loss_mask: 0.6407  decode.d3.loss_dice: 1.0970  decode.d4.loss_cls: 1.1637  decode.d4.loss_mask: 0.6087  decode.d4.loss_dice: 1.0590  decode.d5.loss_cls: 1.1595  decode.d5.loss_mask: 0.5850  decode.d5.loss_dice: 1.0493  decode.d6.loss_cls: 1.2069  decode.d6.loss_mask: 0.5645  decode.d6.loss_dice: 1.0439  decode.d7.loss_cls: 1.1754  decode.d7.loss_mask: 0.5700  decode.d7.loss_dice: 1.0547  decode.d8.loss_cls: 1.1754  decode.d8.loss_mask: 0.5666  decode.d8.loss_dice: 1.0084
2023/05/24 11:58:58 - mmengine - INFO - Iter(train) [142750/160000]  lr: 1.3471e-06  eta: 2:04:37  time: 0.4249  data_time: 0.0108  memory: 4823  grad_norm: 95.5457  loss: 31.8043  decode.loss_cls: 1.0735  decode.loss_mask: 0.6616  decode.loss_dice: 1.1994  decode.d0.loss_cls: 2.9688  decode.d0.loss_mask: 0.6877  decode.d0.loss_dice: 1.4010  decode.d1.loss_cls: 1.2229  decode.d1.loss_mask: 0.7198  decode.d1.loss_dice: 1.3590  decode.d2.loss_cls: 1.1212  decode.d2.loss_mask: 0.6774  decode.d2.loss_dice: 1.2412  decode.d3.loss_cls: 1.0386  decode.d3.loss_mask: 0.6560  decode.d3.loss_dice: 1.1797  decode.d4.loss_cls: 1.0718  decode.d4.loss_mask: 0.6512  decode.d4.loss_dice: 1.1734  decode.d5.loss_cls: 1.0737  decode.d5.loss_mask: 0.6512  decode.d5.loss_dice: 1.1887  decode.d6.loss_cls: 1.1252  decode.d6.loss_mask: 0.6492  decode.d6.loss_dice: 1.1747  decode.d7.loss_cls: 1.0903  decode.d7.loss_mask: 0.6562  decode.d7.loss_dice: 1.1905  decode.d8.loss_cls: 1.0796  decode.d8.loss_mask: 0.6584  decode.d8.loss_dice: 1.1624
2023/05/24 11:59:20 - mmengine - INFO - Iter(train) [142800/160000]  lr: 1.3436e-06  eta: 2:04:15  time: 0.4164  data_time: 0.0101  memory: 4885  grad_norm: 86.3330  loss: 28.8360  decode.loss_cls: 0.8511  decode.loss_mask: 0.6065  decode.loss_dice: 1.1495  decode.d0.loss_cls: 2.8433  decode.d0.loss_mask: 0.6094  decode.d0.loss_dice: 1.3989  decode.d1.loss_cls: 1.0165  decode.d1.loss_mask: 0.6255  decode.d1.loss_dice: 1.2364  decode.d2.loss_cls: 1.0155  decode.d2.loss_mask: 0.5821  decode.d2.loss_dice: 1.1739  decode.d3.loss_cls: 0.9113  decode.d3.loss_mask: 0.5955  decode.d3.loss_dice: 1.1735  decode.d4.loss_cls: 0.8936  decode.d4.loss_mask: 0.5983  decode.d4.loss_dice: 1.1546  decode.d5.loss_cls: 0.8803  decode.d5.loss_mask: 0.5934  decode.d5.loss_dice: 1.1329  decode.d6.loss_cls: 0.8321  decode.d6.loss_mask: 0.6012  decode.d6.loss_dice: 1.1671  decode.d7.loss_cls: 0.8350  decode.d7.loss_mask: 0.6068  decode.d7.loss_dice: 1.1533  decode.d8.loss_cls: 0.8469  decode.d8.loss_mask: 0.6070  decode.d8.loss_dice: 1.1445
2023/05/24 11:59:42 - mmengine - INFO - Iter(train) [142850/160000]  lr: 1.3401e-06  eta: 2:03:53  time: 0.4781  data_time: 0.0103  memory: 4895  grad_norm: 106.7226  loss: 43.9367  decode.loss_cls: 1.4765  decode.loss_mask: 0.9987  decode.loss_dice: 1.5765  decode.d0.loss_cls: 3.5448  decode.d0.loss_mask: 1.0944  decode.d0.loss_dice: 1.8894  decode.d1.loss_cls: 1.6727  decode.d1.loss_mask: 1.0642  decode.d1.loss_dice: 1.7754  decode.d2.loss_cls: 1.5667  decode.d2.loss_mask: 0.9990  decode.d2.loss_dice: 1.6948  decode.d3.loss_cls: 1.4747  decode.d3.loss_mask: 0.9740  decode.d3.loss_dice: 1.6270  decode.d4.loss_cls: 1.4553  decode.d4.loss_mask: 0.9889  decode.d4.loss_dice: 1.6609  decode.d5.loss_cls: 1.4512  decode.d5.loss_mask: 0.9869  decode.d5.loss_dice: 1.6498  decode.d6.loss_cls: 1.4926  decode.d6.loss_mask: 0.9976  decode.d6.loss_dice: 1.5992  decode.d7.loss_cls: 1.4607  decode.d7.loss_mask: 1.0010  decode.d7.loss_dice: 1.6313  decode.d8.loss_cls: 1.5096  decode.d8.loss_mask: 1.0097  decode.d8.loss_dice: 1.6134
2023/05/24 12:00:05 - mmengine - INFO - Iter(train) [142900/160000]  lr: 1.3366e-06  eta: 2:03:32  time: 0.4799  data_time: 0.0102  memory: 4807  grad_norm: 92.8440  loss: 29.7937  decode.loss_cls: 0.9164  decode.loss_mask: 0.7366  decode.loss_dice: 1.0620  decode.d0.loss_cls: 2.7003  decode.d0.loss_mask: 0.7895  decode.d0.loss_dice: 1.2567  decode.d1.loss_cls: 1.0499  decode.d1.loss_mask: 0.7331  decode.d1.loss_dice: 1.1382  decode.d2.loss_cls: 1.0108  decode.d2.loss_mask: 0.7110  decode.d2.loss_dice: 1.1174  decode.d3.loss_cls: 0.9709  decode.d3.loss_mask: 0.7187  decode.d3.loss_dice: 1.1057  decode.d4.loss_cls: 0.9691  decode.d4.loss_mask: 0.7227  decode.d4.loss_dice: 1.0901  decode.d5.loss_cls: 0.9493  decode.d5.loss_mask: 0.7254  decode.d5.loss_dice: 1.0929  decode.d6.loss_cls: 0.9434  decode.d6.loss_mask: 0.7342  decode.d6.loss_dice: 1.0739  decode.d7.loss_cls: 0.9464  decode.d7.loss_mask: 0.7488  decode.d7.loss_dice: 1.0773  decode.d8.loss_cls: 0.9212  decode.d8.loss_mask: 0.7259  decode.d8.loss_dice: 1.0561
2023/05/24 12:00:27 - mmengine - INFO - Iter(train) [142950/160000]  lr: 1.3330e-06  eta: 2:03:10  time: 0.4545  data_time: 0.0112  memory: 4907  grad_norm: 87.6504  loss: 43.4376  decode.loss_cls: 1.4369  decode.loss_mask: 0.8209  decode.loss_dice: 1.8005  decode.d0.loss_cls: 3.1725  decode.d0.loss_mask: 0.8876  decode.d0.loss_dice: 2.0401  decode.d1.loss_cls: 1.5652  decode.d1.loss_mask: 0.8479  decode.d1.loss_dice: 1.9421  decode.d2.loss_cls: 1.5443  decode.d2.loss_mask: 0.7905  decode.d2.loss_dice: 1.8568  decode.d3.loss_cls: 1.5693  decode.d3.loss_mask: 0.8227  decode.d3.loss_dice: 1.8472  decode.d4.loss_cls: 1.3939  decode.d4.loss_mask: 0.8469  decode.d4.loss_dice: 1.8716  decode.d5.loss_cls: 1.4995  decode.d5.loss_mask: 0.8186  decode.d5.loss_dice: 1.8072  decode.d6.loss_cls: 1.4414  decode.d6.loss_mask: 0.8538  decode.d6.loss_dice: 1.8323  decode.d7.loss_cls: 1.3929  decode.d7.loss_mask: 0.8520  decode.d7.loss_dice: 1.8304  decode.d8.loss_cls: 1.4129  decode.d8.loss_mask: 0.8439  decode.d8.loss_dice: 1.7956
2023/05/24 12:00:51 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 12:00:51 - mmengine - INFO - Iter(train) [143000/160000]  lr: 1.3295e-06  eta: 2:02:49  time: 0.4812  data_time: 0.0111  memory: 4930  grad_norm: 88.3522  loss: 38.4240  decode.loss_cls: 1.2492  decode.loss_mask: 0.9008  decode.loss_dice: 1.3782  decode.d0.loss_cls: 3.4876  decode.d0.loss_mask: 1.0437  decode.d0.loss_dice: 1.6083  decode.d1.loss_cls: 1.3163  decode.d1.loss_mask: 0.9583  decode.d1.loss_dice: 1.4877  decode.d2.loss_cls: 1.2890  decode.d2.loss_mask: 0.9571  decode.d2.loss_dice: 1.4495  decode.d3.loss_cls: 1.2888  decode.d3.loss_mask: 0.9263  decode.d3.loss_dice: 1.3894  decode.d4.loss_cls: 1.2512  decode.d4.loss_mask: 0.9139  decode.d4.loss_dice: 1.3969  decode.d5.loss_cls: 1.2274  decode.d5.loss_mask: 0.9322  decode.d5.loss_dice: 1.3933  decode.d6.loss_cls: 1.2252  decode.d6.loss_mask: 0.9070  decode.d6.loss_dice: 1.3878  decode.d7.loss_cls: 1.2291  decode.d7.loss_mask: 0.9214  decode.d7.loss_dice: 1.3796  decode.d8.loss_cls: 1.2117  decode.d8.loss_mask: 0.9297  decode.d8.loss_dice: 1.3874
2023/05/24 12:00:51 - mmengine - INFO - Saving checkpoint at 143000 iterations
2023/05/24 12:01:18 - mmengine - INFO - Iter(train) [143050/160000]  lr: 1.3260e-06  eta: 2:02:28  time: 0.4190  data_time: 0.0103  memory: 4863  grad_norm: 78.7128  loss: 36.1957  decode.loss_cls: 1.1710  decode.loss_mask: 0.8142  decode.loss_dice: 1.3438  decode.d0.loss_cls: 3.0774  decode.d0.loss_mask: 0.8752  decode.d0.loss_dice: 1.5624  decode.d1.loss_cls: 1.3396  decode.d1.loss_mask: 0.8875  decode.d1.loss_dice: 1.4657  decode.d2.loss_cls: 1.2451  decode.d2.loss_mask: 0.8252  decode.d2.loss_dice: 1.4242  decode.d3.loss_cls: 1.2516  decode.d3.loss_mask: 0.8278  decode.d3.loss_dice: 1.3484  decode.d4.loss_cls: 1.2104  decode.d4.loss_mask: 0.8454  decode.d4.loss_dice: 1.3409  decode.d5.loss_cls: 1.1942  decode.d5.loss_mask: 0.7993  decode.d5.loss_dice: 1.3756  decode.d6.loss_cls: 1.1908  decode.d6.loss_mask: 0.8049  decode.d6.loss_dice: 1.3693  decode.d7.loss_cls: 1.1934  decode.d7.loss_mask: 0.7766  decode.d7.loss_dice: 1.3248  decode.d8.loss_cls: 1.1621  decode.d8.loss_mask: 0.8041  decode.d8.loss_dice: 1.3448
2023/05/24 12:01:40 - mmengine - INFO - Iter(train) [143100/160000]  lr: 1.3225e-06  eta: 2:02:06  time: 0.4263  data_time: 0.0100  memory: 4839  grad_norm: 93.8428  loss: 26.8952  decode.loss_cls: 0.9683  decode.loss_mask: 0.6386  decode.loss_dice: 0.8634  decode.d0.loss_cls: 2.9575  decode.d0.loss_mask: 0.6876  decode.d0.loss_dice: 0.9940  decode.d1.loss_cls: 1.0353  decode.d1.loss_mask: 0.7156  decode.d1.loss_dice: 0.9451  decode.d2.loss_cls: 0.9572  decode.d2.loss_mask: 0.6945  decode.d2.loss_dice: 0.8964  decode.d3.loss_cls: 0.9300  decode.d3.loss_mask: 0.6681  decode.d3.loss_dice: 0.8049  decode.d4.loss_cls: 0.9087  decode.d4.loss_mask: 0.6505  decode.d4.loss_dice: 0.8251  decode.d5.loss_cls: 0.9133  decode.d5.loss_mask: 0.6577  decode.d5.loss_dice: 0.8581  decode.d6.loss_cls: 0.9766  decode.d6.loss_mask: 0.6350  decode.d6.loss_dice: 0.8340  decode.d7.loss_cls: 0.9588  decode.d7.loss_mask: 0.6340  decode.d7.loss_dice: 0.8641  decode.d8.loss_cls: 0.9594  decode.d8.loss_mask: 0.6338  decode.d8.loss_dice: 0.8300
2023/05/24 12:02:01 - mmengine - INFO - Iter(train) [143150/160000]  lr: 1.3190e-06  eta: 2:01:45  time: 0.4295  data_time: 0.0106  memory: 4829  grad_norm: 100.1351  loss: 35.9476  decode.loss_cls: 1.0520  decode.loss_mask: 0.7954  decode.loss_dice: 1.3912  decode.d0.loss_cls: 3.3100  decode.d0.loss_mask: 0.8944  decode.d0.loss_dice: 1.6214  decode.d1.loss_cls: 1.2530  decode.d1.loss_mask: 0.8306  decode.d1.loss_dice: 1.4684  decode.d2.loss_cls: 1.2076  decode.d2.loss_mask: 0.8024  decode.d2.loss_dice: 1.3966  decode.d3.loss_cls: 1.1787  decode.d3.loss_mask: 0.8203  decode.d3.loss_dice: 1.4065  decode.d4.loss_cls: 1.1178  decode.d4.loss_mask: 0.8071  decode.d4.loss_dice: 1.4016  decode.d5.loss_cls: 1.1201  decode.d5.loss_mask: 0.8100  decode.d5.loss_dice: 1.3896  decode.d6.loss_cls: 1.1440  decode.d6.loss_mask: 0.8123  decode.d6.loss_dice: 1.4045  decode.d7.loss_cls: 1.1169  decode.d7.loss_mask: 0.7890  decode.d7.loss_dice: 1.3828  decode.d8.loss_cls: 1.0712  decode.d8.loss_mask: 0.7883  decode.d8.loss_dice: 1.3639
2023/05/24 12:02:23 - mmengine - INFO - Iter(train) [143200/160000]  lr: 1.3154e-06  eta: 2:01:23  time: 0.4134  data_time: 0.0099  memory: 4878  grad_norm: 97.2191  loss: 36.1292  decode.loss_cls: 1.1452  decode.loss_mask: 0.8371  decode.loss_dice: 1.3199  decode.d0.loss_cls: 3.0072  decode.d0.loss_mask: 0.9882  decode.d0.loss_dice: 1.5037  decode.d1.loss_cls: 1.1939  decode.d1.loss_mask: 0.9463  decode.d1.loss_dice: 1.4454  decode.d2.loss_cls: 1.1828  decode.d2.loss_mask: 0.9483  decode.d2.loss_dice: 1.4083  decode.d3.loss_cls: 1.0988  decode.d3.loss_mask: 0.9562  decode.d3.loss_dice: 1.3988  decode.d4.loss_cls: 1.0956  decode.d4.loss_mask: 0.9438  decode.d4.loss_dice: 1.3954  decode.d5.loss_cls: 1.0804  decode.d5.loss_mask: 0.9371  decode.d5.loss_dice: 1.3794  decode.d6.loss_cls: 1.0700  decode.d6.loss_mask: 0.8761  decode.d6.loss_dice: 1.3496  decode.d7.loss_cls: 1.0783  decode.d7.loss_mask: 0.8968  decode.d7.loss_dice: 1.3597  decode.d8.loss_cls: 1.1108  decode.d8.loss_mask: 0.8575  decode.d8.loss_dice: 1.3187
2023/05/24 12:02:44 - mmengine - INFO - Iter(train) [143250/160000]  lr: 1.3119e-06  eta: 2:01:01  time: 0.4217  data_time: 0.0106  memory: 4897  grad_norm: 113.6238  loss: 33.9185  decode.loss_cls: 0.9970  decode.loss_mask: 0.7721  decode.loss_dice: 1.3156  decode.d0.loss_cls: 3.1505  decode.d0.loss_mask: 0.8625  decode.d0.loss_dice: 1.5760  decode.d1.loss_cls: 1.1395  decode.d1.loss_mask: 0.8163  decode.d1.loss_dice: 1.4295  decode.d2.loss_cls: 1.0487  decode.d2.loss_mask: 0.7758  decode.d2.loss_dice: 1.3718  decode.d3.loss_cls: 1.0648  decode.d3.loss_mask: 0.7724  decode.d3.loss_dice: 1.3459  decode.d4.loss_cls: 0.9996  decode.d4.loss_mask: 0.7803  decode.d4.loss_dice: 1.3396  decode.d5.loss_cls: 0.9868  decode.d5.loss_mask: 0.7763  decode.d5.loss_dice: 1.3298  decode.d6.loss_cls: 1.0251  decode.d6.loss_mask: 0.7672  decode.d6.loss_dice: 1.3184  decode.d7.loss_cls: 0.9891  decode.d7.loss_mask: 0.7660  decode.d7.loss_dice: 1.2949  decode.d8.loss_cls: 1.0273  decode.d8.loss_mask: 0.7697  decode.d8.loss_dice: 1.3100
2023/05/24 12:03:07 - mmengine - INFO - Iter(train) [143300/160000]  lr: 1.3084e-06  eta: 2:00:40  time: 0.4814  data_time: 0.0098  memory: 4824  grad_norm: 84.5701  loss: 42.3139  decode.loss_cls: 1.5085  decode.loss_mask: 0.8757  decode.loss_dice: 1.5373  decode.d0.loss_cls: 3.4315  decode.d0.loss_mask: 0.9328  decode.d0.loss_dice: 1.7915  decode.d1.loss_cls: 1.7206  decode.d1.loss_mask: 0.8805  decode.d1.loss_dice: 1.7186  decode.d2.loss_cls: 1.6498  decode.d2.loss_mask: 0.8882  decode.d2.loss_dice: 1.6097  decode.d3.loss_cls: 1.5587  decode.d3.loss_mask: 0.8745  decode.d3.loss_dice: 1.5701  decode.d4.loss_cls: 1.5573  decode.d4.loss_mask: 0.8770  decode.d4.loss_dice: 1.5640  decode.d5.loss_cls: 1.5486  decode.d5.loss_mask: 0.8844  decode.d5.loss_dice: 1.5398  decode.d6.loss_cls: 1.5448  decode.d6.loss_mask: 0.8756  decode.d6.loss_dice: 1.5239  decode.d7.loss_cls: 1.5103  decode.d7.loss_mask: 0.8739  decode.d7.loss_dice: 1.5575  decode.d8.loss_cls: 1.4894  decode.d8.loss_mask: 0.8823  decode.d8.loss_dice: 1.5371
2023/05/24 12:03:30 - mmengine - INFO - Iter(train) [143350/160000]  lr: 1.3049e-06  eta: 2:00:18  time: 0.4281  data_time: 0.0099  memory: 4802  grad_norm: 137.0118  loss: 33.3069  decode.loss_cls: 1.0708  decode.loss_mask: 0.7126  decode.loss_dice: 1.2369  decode.d0.loss_cls: 3.1309  decode.d0.loss_mask: 0.7690  decode.d0.loss_dice: 1.4209  decode.d1.loss_cls: 1.2202  decode.d1.loss_mask: 0.7560  decode.d1.loss_dice: 1.3435  decode.d2.loss_cls: 1.2647  decode.d2.loss_mask: 0.7368  decode.d2.loss_dice: 1.2693  decode.d3.loss_cls: 1.1479  decode.d3.loss_mask: 0.7216  decode.d3.loss_dice: 1.2002  decode.d4.loss_cls: 1.1491  decode.d4.loss_mask: 0.7118  decode.d4.loss_dice: 1.2257  decode.d5.loss_cls: 1.1771  decode.d5.loss_mask: 0.7201  decode.d5.loss_dice: 1.2270  decode.d6.loss_cls: 1.0909  decode.d6.loss_mask: 0.7141  decode.d6.loss_dice: 1.2277  decode.d7.loss_cls: 1.0898  decode.d7.loss_mask: 0.7140  decode.d7.loss_dice: 1.2349  decode.d8.loss_cls: 1.0796  decode.d8.loss_mask: 0.7100  decode.d8.loss_dice: 1.2337
2023/05/24 12:03:52 - mmengine - INFO - Iter(train) [143400/160000]  lr: 1.3013e-06  eta: 1:59:56  time: 0.4271  data_time: 0.0101  memory: 4835  grad_norm: 80.6764  loss: 28.9735  decode.loss_cls: 1.1322  decode.loss_mask: 0.6080  decode.loss_dice: 0.9502  decode.d0.loss_cls: 2.8605  decode.d0.loss_mask: 0.6997  decode.d0.loss_dice: 1.1355  decode.d1.loss_cls: 1.1032  decode.d1.loss_mask: 0.6821  decode.d1.loss_dice: 1.0413  decode.d2.loss_cls: 1.1145  decode.d2.loss_mask: 0.6481  decode.d2.loss_dice: 1.0123  decode.d3.loss_cls: 1.0878  decode.d3.loss_mask: 0.6179  decode.d3.loss_dice: 0.9652  decode.d4.loss_cls: 1.0898  decode.d4.loss_mask: 0.6100  decode.d4.loss_dice: 0.9655  decode.d5.loss_cls: 1.0666  decode.d5.loss_mask: 0.6146  decode.d5.loss_dice: 0.9628  decode.d6.loss_cls: 1.0900  decode.d6.loss_mask: 0.6170  decode.d6.loss_dice: 0.9360  decode.d7.loss_cls: 1.1151  decode.d7.loss_mask: 0.6262  decode.d7.loss_dice: 0.9467  decode.d8.loss_cls: 1.1153  decode.d8.loss_mask: 0.6170  decode.d8.loss_dice: 0.9424
2023/05/24 12:04:13 - mmengine - INFO - Iter(train) [143450/160000]  lr: 1.2978e-06  eta: 1:59:35  time: 0.4275  data_time: 0.0103  memory: 4897  grad_norm: 116.4850  loss: 30.3571  decode.loss_cls: 1.0966  decode.loss_mask: 0.6684  decode.loss_dice: 1.0535  decode.d0.loss_cls: 2.8084  decode.d0.loss_mask: 0.7212  decode.d0.loss_dice: 1.2230  decode.d1.loss_cls: 1.1948  decode.d1.loss_mask: 0.6942  decode.d1.loss_dice: 1.1709  decode.d2.loss_cls: 1.0805  decode.d2.loss_mask: 0.6870  decode.d2.loss_dice: 1.0950  decode.d3.loss_cls: 1.0418  decode.d3.loss_mask: 0.7079  decode.d3.loss_dice: 1.0845  decode.d4.loss_cls: 1.0557  decode.d4.loss_mask: 0.6987  decode.d4.loss_dice: 1.0605  decode.d5.loss_cls: 1.0185  decode.d5.loss_mask: 0.7222  decode.d5.loss_dice: 1.0701  decode.d6.loss_cls: 1.1013  decode.d6.loss_mask: 0.6773  decode.d6.loss_dice: 1.0433  decode.d7.loss_cls: 1.0876  decode.d7.loss_mask: 0.6798  decode.d7.loss_dice: 1.0327  decode.d8.loss_cls: 1.0770  decode.d8.loss_mask: 0.6820  decode.d8.loss_dice: 1.0227
2023/05/24 12:04:34 - mmengine - INFO - Iter(train) [143500/160000]  lr: 1.2943e-06  eta: 1:59:13  time: 0.4209  data_time: 0.0103  memory: 4867  grad_norm: 98.4407  loss: 33.6111  decode.loss_cls: 1.0050  decode.loss_mask: 0.7303  decode.loss_dice: 1.3312  decode.d0.loss_cls: 2.9509  decode.d0.loss_mask: 0.8129  decode.d0.loss_dice: 1.5939  decode.d1.loss_cls: 1.0683  decode.d1.loss_mask: 0.8189  decode.d1.loss_dice: 1.4648  decode.d2.loss_cls: 0.9917  decode.d2.loss_mask: 0.8050  decode.d2.loss_dice: 1.4249  decode.d3.loss_cls: 0.9998  decode.d3.loss_mask: 0.7787  decode.d3.loss_dice: 1.3839  decode.d4.loss_cls: 0.9422  decode.d4.loss_mask: 0.7891  decode.d4.loss_dice: 1.4044  decode.d5.loss_cls: 0.9479  decode.d5.loss_mask: 0.7715  decode.d5.loss_dice: 1.3732  decode.d6.loss_cls: 1.0082  decode.d6.loss_mask: 0.7570  decode.d6.loss_dice: 1.3585  decode.d7.loss_cls: 0.9260  decode.d7.loss_mask: 0.7626  decode.d7.loss_dice: 1.3652  decode.d8.loss_cls: 0.9350  decode.d8.loss_mask: 0.7535  decode.d8.loss_dice: 1.3567
2023/05/24 12:04:55 - mmengine - INFO - Iter(train) [143550/160000]  lr: 1.2908e-06  eta: 1:58:51  time: 0.4279  data_time: 0.0105  memory: 4905  grad_norm: 93.2399  loss: 37.4718  decode.loss_cls: 1.3369  decode.loss_mask: 0.8246  decode.loss_dice: 1.3174  decode.d0.loss_cls: 3.1437  decode.d0.loss_mask: 0.8289  decode.d0.loss_dice: 1.5576  decode.d1.loss_cls: 1.5211  decode.d1.loss_mask: 0.8423  decode.d1.loss_dice: 1.4836  decode.d2.loss_cls: 1.3437  decode.d2.loss_mask: 0.8280  decode.d2.loss_dice: 1.4110  decode.d3.loss_cls: 1.3177  decode.d3.loss_mask: 0.8427  decode.d3.loss_dice: 1.3823  decode.d4.loss_cls: 1.2944  decode.d4.loss_mask: 0.8304  decode.d4.loss_dice: 1.3745  decode.d5.loss_cls: 1.3400  decode.d5.loss_mask: 0.8270  decode.d5.loss_dice: 1.3631  decode.d6.loss_cls: 1.3104  decode.d6.loss_mask: 0.8279  decode.d6.loss_dice: 1.3399  decode.d7.loss_cls: 1.3425  decode.d7.loss_mask: 0.8096  decode.d7.loss_dice: 1.3089  decode.d8.loss_cls: 1.3753  decode.d8.loss_mask: 0.8150  decode.d8.loss_dice: 1.3314
2023/05/24 12:05:17 - mmengine - INFO - Iter(train) [143600/160000]  lr: 1.2872e-06  eta: 1:58:29  time: 0.4214  data_time: 0.0102  memory: 4857  grad_norm: 148.1793  loss: 43.7285  decode.loss_cls: 1.3913  decode.loss_mask: 0.8387  decode.loss_dice: 1.7730  decode.d0.loss_cls: 3.4912  decode.d0.loss_mask: 0.8513  decode.d0.loss_dice: 2.1688  decode.d1.loss_cls: 1.5856  decode.d1.loss_mask: 0.9082  decode.d1.loss_dice: 2.0246  decode.d2.loss_cls: 1.4352  decode.d2.loss_mask: 0.8958  decode.d2.loss_dice: 1.9290  decode.d3.loss_cls: 1.4864  decode.d3.loss_mask: 0.8481  decode.d3.loss_dice: 1.7797  decode.d4.loss_cls: 1.4359  decode.d4.loss_mask: 0.8354  decode.d4.loss_dice: 1.8300  decode.d5.loss_cls: 1.4468  decode.d5.loss_mask: 0.8353  decode.d5.loss_dice: 1.8105  decode.d6.loss_cls: 1.4865  decode.d6.loss_mask: 0.8189  decode.d6.loss_dice: 1.7721  decode.d7.loss_cls: 1.4164  decode.d7.loss_mask: 0.8218  decode.d7.loss_dice: 1.7662  decode.d8.loss_cls: 1.4984  decode.d8.loss_mask: 0.7929  decode.d8.loss_dice: 1.7545
2023/05/24 12:05:38 - mmengine - INFO - Iter(train) [143650/160000]  lr: 1.2837e-06  eta: 1:58:08  time: 0.4212  data_time: 0.0100  memory: 4875  grad_norm: 93.8955  loss: 38.1904  decode.loss_cls: 1.3876  decode.loss_mask: 0.7751  decode.loss_dice: 1.3979  decode.d0.loss_cls: 3.1072  decode.d0.loss_mask: 0.8505  decode.d0.loss_dice: 1.6406  decode.d1.loss_cls: 1.3882  decode.d1.loss_mask: 0.8596  decode.d1.loss_dice: 1.5474  decode.d2.loss_cls: 1.4203  decode.d2.loss_mask: 0.7989  decode.d2.loss_dice: 1.4682  decode.d3.loss_cls: 1.4099  decode.d3.loss_mask: 0.7904  decode.d3.loss_dice: 1.4284  decode.d4.loss_cls: 1.3203  decode.d4.loss_mask: 0.8143  decode.d4.loss_dice: 1.4330  decode.d5.loss_cls: 1.3985  decode.d5.loss_mask: 0.7834  decode.d5.loss_dice: 1.3953  decode.d6.loss_cls: 1.4159  decode.d6.loss_mask: 0.7925  decode.d6.loss_dice: 1.4205  decode.d7.loss_cls: 1.4102  decode.d7.loss_mask: 0.7831  decode.d7.loss_dice: 1.4061  decode.d8.loss_cls: 1.3546  decode.d8.loss_mask: 0.7887  decode.d8.loss_dice: 1.4036
2023/05/24 12:06:00 - mmengine - INFO - Iter(train) [143700/160000]  lr: 1.2802e-06  eta: 1:57:46  time: 0.4352  data_time: 0.0106  memory: 4927  grad_norm: 94.7566  loss: 37.3417  decode.loss_cls: 1.1834  decode.loss_mask: 0.8594  decode.loss_dice: 1.3626  decode.d0.loss_cls: 3.3859  decode.d0.loss_mask: 0.9743  decode.d0.loss_dice: 1.6391  decode.d1.loss_cls: 1.2980  decode.d1.loss_mask: 0.8620  decode.d1.loss_dice: 1.4610  decode.d2.loss_cls: 1.2180  decode.d2.loss_mask: 0.9105  decode.d2.loss_dice: 1.4314  decode.d3.loss_cls: 1.1571  decode.d3.loss_mask: 0.8926  decode.d3.loss_dice: 1.4404  decode.d4.loss_cls: 1.2081  decode.d4.loss_mask: 0.8763  decode.d4.loss_dice: 1.3967  decode.d5.loss_cls: 1.1931  decode.d5.loss_mask: 0.8874  decode.d5.loss_dice: 1.4102  decode.d6.loss_cls: 1.2769  decode.d6.loss_mask: 0.8395  decode.d6.loss_dice: 1.3416  decode.d7.loss_cls: 1.2237  decode.d7.loss_mask: 0.8435  decode.d7.loss_dice: 1.3689  decode.d8.loss_cls: 1.2328  decode.d8.loss_mask: 0.8409  decode.d8.loss_dice: 1.3264
2023/05/24 12:06:21 - mmengine - INFO - Iter(train) [143750/160000]  lr: 1.2766e-06  eta: 1:57:24  time: 0.4284  data_time: 0.0109  memory: 4805  grad_norm: 85.0047  loss: 26.8766  decode.loss_cls: 0.8477  decode.loss_mask: 0.5412  decode.loss_dice: 1.0323  decode.d0.loss_cls: 2.6519  decode.d0.loss_mask: 0.6255  decode.d0.loss_dice: 1.1591  decode.d1.loss_cls: 0.9710  decode.d1.loss_mask: 0.6108  decode.d1.loss_dice: 1.0918  decode.d2.loss_cls: 1.0616  decode.d2.loss_mask: 0.5724  decode.d2.loss_dice: 1.0817  decode.d3.loss_cls: 0.8828  decode.d3.loss_mask: 0.5573  decode.d3.loss_dice: 1.0891  decode.d4.loss_cls: 0.8139  decode.d4.loss_mask: 0.5420  decode.d4.loss_dice: 1.0941  decode.d5.loss_cls: 0.7874  decode.d5.loss_mask: 0.5412  decode.d5.loss_dice: 1.0435  decode.d6.loss_cls: 0.8530  decode.d6.loss_mask: 0.5371  decode.d6.loss_dice: 1.0358  decode.d7.loss_cls: 0.8452  decode.d7.loss_mask: 0.5433  decode.d7.loss_dice: 1.0472  decode.d8.loss_cls: 0.8460  decode.d8.loss_mask: 0.5369  decode.d8.loss_dice: 1.0340
2023/05/24 12:06:44 - mmengine - INFO - Iter(train) [143800/160000]  lr: 1.2731e-06  eta: 1:57:03  time: 0.4216  data_time: 0.0101  memory: 4818  grad_norm: 107.6865  loss: 29.9921  decode.loss_cls: 1.0559  decode.loss_mask: 0.6709  decode.loss_dice: 0.9746  decode.d0.loss_cls: 2.9637  decode.d0.loss_mask: 0.6990  decode.d0.loss_dice: 1.3063  decode.d1.loss_cls: 1.1998  decode.d1.loss_mask: 0.6809  decode.d1.loss_dice: 1.1348  decode.d2.loss_cls: 1.0824  decode.d2.loss_mask: 0.6978  decode.d2.loss_dice: 1.0958  decode.d3.loss_cls: 1.0403  decode.d3.loss_mask: 0.6896  decode.d3.loss_dice: 1.0625  decode.d4.loss_cls: 1.0083  decode.d4.loss_mask: 0.6867  decode.d4.loss_dice: 1.0366  decode.d5.loss_cls: 1.0398  decode.d5.loss_mask: 0.6795  decode.d5.loss_dice: 1.0434  decode.d6.loss_cls: 1.0332  decode.d6.loss_mask: 0.6820  decode.d6.loss_dice: 1.0151  decode.d7.loss_cls: 1.0410  decode.d7.loss_mask: 0.6598  decode.d7.loss_dice: 0.9801  decode.d8.loss_cls: 1.0458  decode.d8.loss_mask: 0.6632  decode.d8.loss_dice: 1.0234
2023/05/24 12:07:05 - mmengine - INFO - Iter(train) [143850/160000]  lr: 1.2695e-06  eta: 1:56:41  time: 0.4206  data_time: 0.0104  memory: 4846  grad_norm: 87.1121  loss: 32.1561  decode.loss_cls: 1.1639  decode.loss_mask: 0.6232  decode.loss_dice: 1.1420  decode.d0.loss_cls: 2.9351  decode.d0.loss_mask: 0.7273  decode.d0.loss_dice: 1.3655  decode.d1.loss_cls: 1.2625  decode.d1.loss_mask: 0.6651  decode.d1.loss_dice: 1.3059  decode.d2.loss_cls: 1.1962  decode.d2.loss_mask: 0.6507  decode.d2.loss_dice: 1.2595  decode.d3.loss_cls: 1.2282  decode.d3.loss_mask: 0.6350  decode.d3.loss_dice: 1.1738  decode.d4.loss_cls: 1.2076  decode.d4.loss_mask: 0.6431  decode.d4.loss_dice: 1.1743  decode.d5.loss_cls: 1.1921  decode.d5.loss_mask: 0.6285  decode.d5.loss_dice: 1.1740  decode.d6.loss_cls: 1.1747  decode.d6.loss_mask: 0.6232  decode.d6.loss_dice: 1.1388  decode.d7.loss_cls: 1.1677  decode.d7.loss_mask: 0.6364  decode.d7.loss_dice: 1.1270  decode.d8.loss_cls: 1.1403  decode.d8.loss_mask: 0.6432  decode.d8.loss_dice: 1.1512
2023/05/24 12:07:27 - mmengine - INFO - Iter(train) [143900/160000]  lr: 1.2660e-06  eta: 1:56:19  time: 0.4207  data_time: 0.0104  memory: 4827  grad_norm: 103.1241  loss: 35.6519  decode.loss_cls: 1.0940  decode.loss_mask: 0.7705  decode.loss_dice: 1.4193  decode.d0.loss_cls: 2.6788  decode.d0.loss_mask: 0.8117  decode.d0.loss_dice: 1.6756  decode.d1.loss_cls: 1.2200  decode.d1.loss_mask: 0.8808  decode.d1.loss_dice: 1.6086  decode.d2.loss_cls: 1.1503  decode.d2.loss_mask: 0.8238  decode.d2.loss_dice: 1.5051  decode.d3.loss_cls: 1.1618  decode.d3.loss_mask: 0.8150  decode.d3.loss_dice: 1.4660  decode.d4.loss_cls: 1.1253  decode.d4.loss_mask: 0.8118  decode.d4.loss_dice: 1.4144  decode.d5.loss_cls: 1.0872  decode.d5.loss_mask: 0.7996  decode.d5.loss_dice: 1.4405  decode.d6.loss_cls: 1.0857  decode.d6.loss_mask: 0.7912  decode.d6.loss_dice: 1.4258  decode.d7.loss_cls: 1.0821  decode.d7.loss_mask: 0.7829  decode.d7.loss_dice: 1.4173  decode.d8.loss_cls: 1.0837  decode.d8.loss_mask: 0.7853  decode.d8.loss_dice: 1.4376
2023/05/24 12:07:48 - mmengine - INFO - Iter(train) [143950/160000]  lr: 1.2625e-06  eta: 1:55:58  time: 0.4293  data_time: 0.0101  memory: 4953  grad_norm: 89.6199  loss: 36.0018  decode.loss_cls: 1.0848  decode.loss_mask: 0.7530  decode.loss_dice: 1.3667  decode.d0.loss_cls: 3.2027  decode.d0.loss_mask: 0.8996  decode.d0.loss_dice: 1.6848  decode.d1.loss_cls: 1.2584  decode.d1.loss_mask: 0.8736  decode.d1.loss_dice: 1.6056  decode.d2.loss_cls: 1.2164  decode.d2.loss_mask: 0.7990  decode.d2.loss_dice: 1.4830  decode.d3.loss_cls: 1.1593  decode.d3.loss_mask: 0.7820  decode.d3.loss_dice: 1.4285  decode.d4.loss_cls: 1.1005  decode.d4.loss_mask: 0.7980  decode.d4.loss_dice: 1.4143  decode.d5.loss_cls: 1.1448  decode.d5.loss_mask: 0.7842  decode.d5.loss_dice: 1.4290  decode.d6.loss_cls: 1.0894  decode.d6.loss_mask: 0.7599  decode.d6.loss_dice: 1.3797  decode.d7.loss_cls: 1.0784  decode.d7.loss_mask: 0.7751  decode.d7.loss_dice: 1.4171  decode.d8.loss_cls: 1.0703  decode.d8.loss_mask: 0.7673  decode.d8.loss_dice: 1.3963
2023/05/24 12:08:10 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 12:08:10 - mmengine - INFO - Iter(train) [144000/160000]  lr: 1.2589e-06  eta: 1:55:36  time: 0.4313  data_time: 0.0103  memory: 4998  grad_norm: 87.9644  loss: 39.2259  decode.loss_cls: 1.3339  decode.loss_mask: 0.7198  decode.loss_dice: 1.4504  decode.d0.loss_cls: 3.4445  decode.d0.loss_mask: 0.8472  decode.d0.loss_dice: 1.8192  decode.d1.loss_cls: 1.4825  decode.d1.loss_mask: 0.8197  decode.d1.loss_dice: 1.6589  decode.d2.loss_cls: 1.4635  decode.d2.loss_mask: 0.7891  decode.d2.loss_dice: 1.5757  decode.d3.loss_cls: 1.4058  decode.d3.loss_mask: 0.7722  decode.d3.loss_dice: 1.5115  decode.d4.loss_cls: 1.4086  decode.d4.loss_mask: 0.7503  decode.d4.loss_dice: 1.5006  decode.d5.loss_cls: 1.3818  decode.d5.loss_mask: 0.7450  decode.d5.loss_dice: 1.5282  decode.d6.loss_cls: 1.3963  decode.d6.loss_mask: 0.7395  decode.d6.loss_dice: 1.4847  decode.d7.loss_cls: 1.3913  decode.d7.loss_mask: 0.7264  decode.d7.loss_dice: 1.4813  decode.d8.loss_cls: 1.3972  decode.d8.loss_mask: 0.7206  decode.d8.loss_dice: 1.4805
2023/05/24 12:08:10 - mmengine - INFO - Saving checkpoint at 144000 iterations
2023/05/24 12:08:36 - mmengine - INFO - Iter(train) [144050/160000]  lr: 1.2554e-06  eta: 1:55:15  time: 0.4256  data_time: 0.0103  memory: 4895  grad_norm: 83.1673  loss: 38.6586  decode.loss_cls: 1.3230  decode.loss_mask: 0.6756  decode.loss_dice: 1.5415  decode.d0.loss_cls: 3.3850  decode.d0.loss_mask: 0.6874  decode.d0.loss_dice: 1.7858  decode.d1.loss_cls: 1.4715  decode.d1.loss_mask: 0.7134  decode.d1.loss_dice: 1.7389  decode.d2.loss_cls: 1.4968  decode.d2.loss_mask: 0.6878  decode.d2.loss_dice: 1.6499  decode.d3.loss_cls: 1.4478  decode.d3.loss_mask: 0.6761  decode.d3.loss_dice: 1.6147  decode.d4.loss_cls: 1.3575  decode.d4.loss_mask: 0.6752  decode.d4.loss_dice: 1.5680  decode.d5.loss_cls: 1.3818  decode.d5.loss_mask: 0.6578  decode.d5.loss_dice: 1.5394  decode.d6.loss_cls: 1.3180  decode.d6.loss_mask: 0.6618  decode.d6.loss_dice: 1.5611  decode.d7.loss_cls: 1.3269  decode.d7.loss_mask: 0.6597  decode.d7.loss_dice: 1.5355  decode.d8.loss_cls: 1.2928  decode.d8.loss_mask: 0.6758  decode.d8.loss_dice: 1.5520
2023/05/24 12:08:58 - mmengine - INFO - Iter(train) [144100/160000]  lr: 1.2518e-06  eta: 1:54:53  time: 0.4300  data_time: 0.0102  memory: 4859  grad_norm: 79.0005  loss: 31.4002  decode.loss_cls: 1.2191  decode.loss_mask: 0.6661  decode.loss_dice: 0.9801  decode.d0.loss_cls: 3.0048  decode.d0.loss_mask: 0.7024  decode.d0.loss_dice: 1.1413  decode.d1.loss_cls: 1.3955  decode.d1.loss_mask: 0.6678  decode.d1.loss_dice: 1.1034  decode.d2.loss_cls: 1.3033  decode.d2.loss_mask: 0.6570  decode.d2.loss_dice: 0.9915  decode.d3.loss_cls: 1.3086  decode.d3.loss_mask: 0.6460  decode.d3.loss_dice: 1.0047  decode.d4.loss_cls: 1.3127  decode.d4.loss_mask: 0.6369  decode.d4.loss_dice: 1.0179  decode.d5.loss_cls: 1.3000  decode.d5.loss_mask: 0.6584  decode.d5.loss_dice: 0.9952  decode.d6.loss_cls: 1.2490  decode.d6.loss_mask: 0.6559  decode.d6.loss_dice: 0.9709  decode.d7.loss_cls: 1.2540  decode.d7.loss_mask: 0.6559  decode.d7.loss_dice: 0.9925  decode.d8.loss_cls: 1.2541  decode.d8.loss_mask: 0.6541  decode.d8.loss_dice: 1.0009
2023/05/24 12:09:19 - mmengine - INFO - Iter(train) [144150/160000]  lr: 1.2483e-06  eta: 1:54:31  time: 0.4286  data_time: 0.0102  memory: 4885  grad_norm: 76.9345  loss: 31.9400  decode.loss_cls: 1.0151  decode.loss_mask: 0.6529  decode.loss_dice: 1.2218  decode.d0.loss_cls: 3.0561  decode.d0.loss_mask: 0.6438  decode.d0.loss_dice: 1.3780  decode.d1.loss_cls: 1.2157  decode.d1.loss_mask: 0.7011  decode.d1.loss_dice: 1.2966  decode.d2.loss_cls: 1.1614  decode.d2.loss_mask: 0.6654  decode.d2.loss_dice: 1.2677  decode.d3.loss_cls: 1.1280  decode.d3.loss_mask: 0.6810  decode.d3.loss_dice: 1.2270  decode.d4.loss_cls: 1.0431  decode.d4.loss_mask: 0.6840  decode.d4.loss_dice: 1.2351  decode.d5.loss_cls: 1.0199  decode.d5.loss_mask: 0.6816  decode.d5.loss_dice: 1.2261  decode.d6.loss_cls: 1.0322  decode.d6.loss_mask: 0.6655  decode.d6.loss_dice: 1.2112  decode.d7.loss_cls: 0.9988  decode.d7.loss_mask: 0.6624  decode.d7.loss_dice: 1.2542  decode.d8.loss_cls: 1.0353  decode.d8.loss_mask: 0.6558  decode.d8.loss_dice: 1.2232
2023/05/24 12:09:41 - mmengine - INFO - Iter(train) [144200/160000]  lr: 1.2448e-06  eta: 1:54:10  time: 0.4285  data_time: 0.0103  memory: 4906  grad_norm: 108.1479  loss: 36.5596  decode.loss_cls: 1.2787  decode.loss_mask: 0.7651  decode.loss_dice: 1.2037  decode.d0.loss_cls: 3.3956  decode.d0.loss_mask: 0.8848  decode.d0.loss_dice: 1.5042  decode.d1.loss_cls: 1.3854  decode.d1.loss_mask: 0.8825  decode.d1.loss_dice: 1.4417  decode.d2.loss_cls: 1.3459  decode.d2.loss_mask: 0.8606  decode.d2.loss_dice: 1.3463  decode.d3.loss_cls: 1.4006  decode.d3.loss_mask: 0.8107  decode.d3.loss_dice: 1.2990  decode.d4.loss_cls: 1.3475  decode.d4.loss_mask: 0.7925  decode.d4.loss_dice: 1.2550  decode.d5.loss_cls: 1.3477  decode.d5.loss_mask: 0.7770  decode.d5.loss_dice: 1.2825  decode.d6.loss_cls: 1.3850  decode.d6.loss_mask: 0.7660  decode.d6.loss_dice: 1.2322  decode.d7.loss_cls: 1.3085  decode.d7.loss_mask: 0.7475  decode.d7.loss_dice: 1.2158  decode.d8.loss_cls: 1.3277  decode.d8.loss_mask: 0.7601  decode.d8.loss_dice: 1.2099
2023/05/24 12:10:02 - mmengine - INFO - Iter(train) [144250/160000]  lr: 1.2412e-06  eta: 1:53:48  time: 0.4178  data_time: 0.0103  memory: 4866  grad_norm: 96.0938  loss: 31.1401  decode.loss_cls: 1.1831  decode.loss_mask: 0.6063  decode.loss_dice: 1.0659  decode.d0.loss_cls: 2.8658  decode.d0.loss_mask: 0.6684  decode.d0.loss_dice: 1.2596  decode.d1.loss_cls: 1.2977  decode.d1.loss_mask: 0.6334  decode.d1.loss_dice: 1.1442  decode.d2.loss_cls: 1.2738  decode.d2.loss_mask: 0.6210  decode.d2.loss_dice: 1.1146  decode.d3.loss_cls: 1.2487  decode.d3.loss_mask: 0.6197  decode.d3.loss_dice: 1.1064  decode.d4.loss_cls: 1.2596  decode.d4.loss_mask: 0.6076  decode.d4.loss_dice: 1.0585  decode.d5.loss_cls: 1.2499  decode.d5.loss_mask: 0.6130  decode.d5.loss_dice: 1.0714  decode.d6.loss_cls: 1.1815  decode.d6.loss_mask: 0.6190  decode.d6.loss_dice: 1.0743  decode.d7.loss_cls: 1.1881  decode.d7.loss_mask: 0.5841  decode.d7.loss_dice: 1.0420  decode.d8.loss_cls: 1.1702  decode.d8.loss_mask: 0.6177  decode.d8.loss_dice: 1.0946
2023/05/24 12:10:24 - mmengine - INFO - Iter(train) [144300/160000]  lr: 1.2377e-06  eta: 1:53:26  time: 0.4217  data_time: 0.0104  memory: 4829  grad_norm: 92.8675  loss: 38.1663  decode.loss_cls: 1.2810  decode.loss_mask: 0.8604  decode.loss_dice: 1.3621  decode.d0.loss_cls: 3.2864  decode.d0.loss_mask: 0.8867  decode.d0.loss_dice: 1.6547  decode.d1.loss_cls: 1.4402  decode.d1.loss_mask: 0.8790  decode.d1.loss_dice: 1.4664  decode.d2.loss_cls: 1.3760  decode.d2.loss_mask: 0.9092  decode.d2.loss_dice: 1.4408  decode.d3.loss_cls: 1.4090  decode.d3.loss_mask: 0.8929  decode.d3.loss_dice: 1.3707  decode.d4.loss_cls: 1.2985  decode.d4.loss_mask: 0.9009  decode.d4.loss_dice: 1.3769  decode.d5.loss_cls: 1.3493  decode.d5.loss_mask: 0.8680  decode.d5.loss_dice: 1.3853  decode.d6.loss_cls: 1.2640  decode.d6.loss_mask: 0.8519  decode.d6.loss_dice: 1.3787  decode.d7.loss_cls: 1.3005  decode.d7.loss_mask: 0.8261  decode.d7.loss_dice: 1.3540  decode.d8.loss_cls: 1.2871  decode.d8.loss_mask: 0.8362  decode.d8.loss_dice: 1.3732
2023/05/24 12:10:45 - mmengine - INFO - Iter(train) [144350/160000]  lr: 1.2341e-06  eta: 1:53:05  time: 0.4121  data_time: 0.0098  memory: 4821  grad_norm: 105.7089  loss: 23.6813  decode.loss_cls: 0.7944  decode.loss_mask: 0.5919  decode.loss_dice: 0.7086  decode.d0.loss_cls: 2.6253  decode.d0.loss_mask: 0.6333  decode.d0.loss_dice: 0.8369  decode.d1.loss_cls: 1.0329  decode.d1.loss_mask: 0.6102  decode.d1.loss_dice: 0.7533  decode.d2.loss_cls: 1.0002  decode.d2.loss_mask: 0.5970  decode.d2.loss_dice: 0.7153  decode.d3.loss_cls: 0.9560  decode.d3.loss_mask: 0.5778  decode.d3.loss_dice: 0.6764  decode.d4.loss_cls: 0.8893  decode.d4.loss_mask: 0.5923  decode.d4.loss_dice: 0.6933  decode.d5.loss_cls: 0.8152  decode.d5.loss_mask: 0.6027  decode.d5.loss_dice: 0.6832  decode.d6.loss_cls: 0.8612  decode.d6.loss_mask: 0.6032  decode.d6.loss_dice: 0.6960  decode.d7.loss_cls: 0.8240  decode.d7.loss_mask: 0.5976  decode.d7.loss_dice: 0.6527  decode.d8.loss_cls: 0.7892  decode.d8.loss_mask: 0.6025  decode.d8.loss_dice: 0.6694
2023/05/24 12:11:06 - mmengine - INFO - Iter(train) [144400/160000]  lr: 1.2306e-06  eta: 1:52:43  time: 0.4213  data_time: 0.0101  memory: 4819  grad_norm: 97.6039  loss: 36.2190  decode.loss_cls: 1.3003  decode.loss_mask: 0.6311  decode.loss_dice: 1.3806  decode.d0.loss_cls: 3.3249  decode.d0.loss_mask: 0.6996  decode.d0.loss_dice: 1.6091  decode.d1.loss_cls: 1.4520  decode.d1.loss_mask: 0.7177  decode.d1.loss_dice: 1.4684  decode.d2.loss_cls: 1.3559  decode.d2.loss_mask: 0.7256  decode.d2.loss_dice: 1.4513  decode.d3.loss_cls: 1.3737  decode.d3.loss_mask: 0.6587  decode.d3.loss_dice: 1.3597  decode.d4.loss_cls: 1.3463  decode.d4.loss_mask: 0.6544  decode.d4.loss_dice: 1.3878  decode.d5.loss_cls: 1.3258  decode.d5.loss_mask: 0.6604  decode.d5.loss_dice: 1.3442  decode.d6.loss_cls: 1.3094  decode.d6.loss_mask: 0.6619  decode.d6.loss_dice: 1.3730  decode.d7.loss_cls: 1.2765  decode.d7.loss_mask: 0.6666  decode.d7.loss_dice: 1.4029  decode.d8.loss_cls: 1.2874  decode.d8.loss_mask: 0.6308  decode.d8.loss_dice: 1.3831
2023/05/24 12:11:28 - mmengine - INFO - Iter(train) [144450/160000]  lr: 1.2270e-06  eta: 1:52:21  time: 0.4254  data_time: 0.0100  memory: 4848  grad_norm: 95.6535  loss: 38.7875  decode.loss_cls: 1.3120  decode.loss_mask: 0.7632  decode.loss_dice: 1.5357  decode.d0.loss_cls: 3.2140  decode.d0.loss_mask: 0.7967  decode.d0.loss_dice: 1.7150  decode.d1.loss_cls: 1.4355  decode.d1.loss_mask: 0.7786  decode.d1.loss_dice: 1.6502  decode.d2.loss_cls: 1.3768  decode.d2.loss_mask: 0.8045  decode.d2.loss_dice: 1.6039  decode.d3.loss_cls: 1.3569  decode.d3.loss_mask: 0.7912  decode.d3.loss_dice: 1.5506  decode.d4.loss_cls: 1.3091  decode.d4.loss_mask: 0.7640  decode.d4.loss_dice: 1.5421  decode.d5.loss_cls: 1.3273  decode.d5.loss_mask: 0.7470  decode.d5.loss_dice: 1.5336  decode.d6.loss_cls: 1.3447  decode.d6.loss_mask: 0.7839  decode.d6.loss_dice: 1.5432  decode.d7.loss_cls: 1.2701  decode.d7.loss_mask: 0.7857  decode.d7.loss_dice: 1.5530  decode.d8.loss_cls: 1.3106  decode.d8.loss_mask: 0.7721  decode.d8.loss_dice: 1.5161
2023/05/24 12:11:49 - mmengine - INFO - Iter(train) [144500/160000]  lr: 1.2235e-06  eta: 1:51:59  time: 0.4216  data_time: 0.0100  memory: 4822  grad_norm: 98.9630  loss: 34.2515  decode.loss_cls: 1.0304  decode.loss_mask: 0.6365  decode.loss_dice: 1.4085  decode.d0.loss_cls: 3.3469  decode.d0.loss_mask: 0.7365  decode.d0.loss_dice: 1.5892  decode.d1.loss_cls: 1.1236  decode.d1.loss_mask: 0.6817  decode.d1.loss_dice: 1.5262  decode.d2.loss_cls: 1.1719  decode.d2.loss_mask: 0.6653  decode.d2.loss_dice: 1.4778  decode.d3.loss_cls: 1.1404  decode.d3.loss_mask: 0.6471  decode.d3.loss_dice: 1.4111  decode.d4.loss_cls: 1.0867  decode.d4.loss_mask: 0.6564  decode.d4.loss_dice: 1.4357  decode.d5.loss_cls: 1.0925  decode.d5.loss_mask: 0.6447  decode.d5.loss_dice: 1.4246  decode.d6.loss_cls: 1.0737  decode.d6.loss_mask: 0.6264  decode.d6.loss_dice: 1.4241  decode.d7.loss_cls: 1.0628  decode.d7.loss_mask: 0.6374  decode.d7.loss_dice: 1.4194  decode.d8.loss_cls: 1.0471  decode.d8.loss_mask: 0.6407  decode.d8.loss_dice: 1.3859
2023/05/24 12:12:11 - mmengine - INFO - Iter(train) [144550/160000]  lr: 1.2199e-06  eta: 1:51:38  time: 0.4224  data_time: 0.0099  memory: 4845  grad_norm: 83.7251  loss: 30.0633  decode.loss_cls: 0.8479  decode.loss_mask: 0.6164  decode.loss_dice: 1.2512  decode.d0.loss_cls: 2.9111  decode.d0.loss_mask: 0.6818  decode.d0.loss_dice: 1.4250  decode.d1.loss_cls: 1.0016  decode.d1.loss_mask: 0.6741  decode.d1.loss_dice: 1.2982  decode.d2.loss_cls: 1.0016  decode.d2.loss_mask: 0.6518  decode.d2.loss_dice: 1.2359  decode.d3.loss_cls: 0.9281  decode.d3.loss_mask: 0.6267  decode.d3.loss_dice: 1.2774  decode.d4.loss_cls: 0.9263  decode.d4.loss_mask: 0.6211  decode.d4.loss_dice: 1.2269  decode.d5.loss_cls: 0.8728  decode.d5.loss_mask: 0.6233  decode.d5.loss_dice: 1.2480  decode.d6.loss_cls: 0.8552  decode.d6.loss_mask: 0.6247  decode.d6.loss_dice: 1.2386  decode.d7.loss_cls: 0.8263  decode.d7.loss_mask: 0.6245  decode.d7.loss_dice: 1.2221  decode.d8.loss_cls: 0.8360  decode.d8.loss_mask: 0.6277  decode.d8.loss_dice: 1.2613
2023/05/24 12:12:33 - mmengine - INFO - Iter(train) [144600/160000]  lr: 1.2164e-06  eta: 1:51:16  time: 0.4204  data_time: 0.0103  memory: 4875  grad_norm: 103.9333  loss: 36.1733  decode.loss_cls: 1.2544  decode.loss_mask: 0.7025  decode.loss_dice: 1.3220  decode.d0.loss_cls: 3.1053  decode.d0.loss_mask: 0.8085  decode.d0.loss_dice: 1.6146  decode.d1.loss_cls: 1.4488  decode.d1.loss_mask: 0.7823  decode.d1.loss_dice: 1.5234  decode.d2.loss_cls: 1.3012  decode.d2.loss_mask: 0.7444  decode.d2.loss_dice: 1.4575  decode.d3.loss_cls: 1.3080  decode.d3.loss_mask: 0.7438  decode.d3.loss_dice: 1.3614  decode.d4.loss_cls: 1.2798  decode.d4.loss_mask: 0.7615  decode.d4.loss_dice: 1.3859  decode.d5.loss_cls: 1.2575  decode.d5.loss_mask: 0.7493  decode.d5.loss_dice: 1.3602  decode.d6.loss_cls: 1.2569  decode.d6.loss_mask: 0.7344  decode.d6.loss_dice: 1.3362  decode.d7.loss_cls: 1.2809  decode.d7.loss_mask: 0.7135  decode.d7.loss_dice: 1.3208  decode.d8.loss_cls: 1.2440  decode.d8.loss_mask: 0.6997  decode.d8.loss_dice: 1.3146
2023/05/24 12:12:54 - mmengine - INFO - Iter(train) [144650/160000]  lr: 1.2128e-06  eta: 1:50:54  time: 0.4182  data_time: 0.0099  memory: 4828  grad_norm: 95.7346  loss: 39.1576  decode.loss_cls: 1.1597  decode.loss_mask: 0.7103  decode.loss_dice: 1.7279  decode.d0.loss_cls: 3.1910  decode.d0.loss_mask: 0.7881  decode.d0.loss_dice: 2.0612  decode.d1.loss_cls: 1.3610  decode.d1.loss_mask: 0.7497  decode.d1.loss_dice: 1.9191  decode.d2.loss_cls: 1.2834  decode.d2.loss_mask: 0.6969  decode.d2.loss_dice: 1.8147  decode.d3.loss_cls: 1.1910  decode.d3.loss_mask: 0.6893  decode.d3.loss_dice: 1.7939  decode.d4.loss_cls: 1.2393  decode.d4.loss_mask: 0.6837  decode.d4.loss_dice: 1.7614  decode.d5.loss_cls: 1.1683  decode.d5.loss_mask: 0.6803  decode.d5.loss_dice: 1.7381  decode.d6.loss_cls: 1.1640  decode.d6.loss_mask: 0.7014  decode.d6.loss_dice: 1.7364  decode.d7.loss_cls: 1.1866  decode.d7.loss_mask: 0.6960  decode.d7.loss_dice: 1.7027  decode.d8.loss_cls: 1.1478  decode.d8.loss_mask: 0.7115  decode.d8.loss_dice: 1.7029
2023/05/24 12:13:15 - mmengine - INFO - Iter(train) [144700/160000]  lr: 1.2093e-06  eta: 1:50:33  time: 0.4199  data_time: 0.0099  memory: 4828  grad_norm: 95.7661  loss: 42.0022  decode.loss_cls: 1.6076  decode.loss_mask: 0.7618  decode.loss_dice: 1.4473  decode.d0.loss_cls: 3.7411  decode.d0.loss_mask: 0.9073  decode.d0.loss_dice: 1.8761  decode.d1.loss_cls: 1.7544  decode.d1.loss_mask: 0.8520  decode.d1.loss_dice: 1.5954  decode.d2.loss_cls: 1.7988  decode.d2.loss_mask: 0.8440  decode.d2.loss_dice: 1.5426  decode.d3.loss_cls: 1.6996  decode.d3.loss_mask: 0.7819  decode.d3.loss_dice: 1.4709  decode.d4.loss_cls: 1.6328  decode.d4.loss_mask: 0.7735  decode.d4.loss_dice: 1.4841  decode.d5.loss_cls: 1.6493  decode.d5.loss_mask: 0.7946  decode.d5.loss_dice: 1.4695  decode.d6.loss_cls: 1.6038  decode.d6.loss_mask: 0.7991  decode.d6.loss_dice: 1.4532  decode.d7.loss_cls: 1.5841  decode.d7.loss_mask: 0.7817  decode.d7.loss_dice: 1.4574  decode.d8.loss_cls: 1.6179  decode.d8.loss_mask: 0.7694  decode.d8.loss_dice: 1.4511
2023/05/24 12:13:36 - mmengine - INFO - Iter(train) [144750/160000]  lr: 1.2057e-06  eta: 1:50:11  time: 0.4206  data_time: 0.0097  memory: 4837  grad_norm: 93.8093  loss: 27.5638  decode.loss_cls: 0.9318  decode.loss_mask: 0.6182  decode.loss_dice: 0.8959  decode.d0.loss_cls: 2.7488  decode.d0.loss_mask: 0.7156  decode.d0.loss_dice: 1.1184  decode.d1.loss_cls: 1.1189  decode.d1.loss_mask: 0.6480  decode.d1.loss_dice: 0.9726  decode.d2.loss_cls: 1.1027  decode.d2.loss_mask: 0.6098  decode.d2.loss_dice: 0.9096  decode.d3.loss_cls: 1.0135  decode.d3.loss_mask: 0.6405  decode.d3.loss_dice: 0.9099  decode.d4.loss_cls: 0.9962  decode.d4.loss_mask: 0.6290  decode.d4.loss_dice: 0.9094  decode.d5.loss_cls: 1.0013  decode.d5.loss_mask: 0.6206  decode.d5.loss_dice: 0.9112  decode.d6.loss_cls: 1.0107  decode.d6.loss_mask: 0.6178  decode.d6.loss_dice: 0.8962  decode.d7.loss_cls: 1.0110  decode.d7.loss_mask: 0.6081  decode.d7.loss_dice: 0.9273  decode.d8.loss_cls: 0.9340  decode.d8.loss_mask: 0.6097  decode.d8.loss_dice: 0.9270
2023/05/24 12:13:58 - mmengine - INFO - Iter(train) [144800/160000]  lr: 1.2021e-06  eta: 1:49:49  time: 0.4278  data_time: 0.0105  memory: 4847  grad_norm: 88.5627  loss: 31.5062  decode.loss_cls: 1.0018  decode.loss_mask: 0.7604  decode.loss_dice: 1.1166  decode.d0.loss_cls: 2.9492  decode.d0.loss_mask: 0.7905  decode.d0.loss_dice: 1.2633  decode.d1.loss_cls: 1.1103  decode.d1.loss_mask: 0.8403  decode.d1.loss_dice: 1.2165  decode.d2.loss_cls: 1.1576  decode.d2.loss_mask: 0.7664  decode.d2.loss_dice: 1.1426  decode.d3.loss_cls: 1.0544  decode.d3.loss_mask: 0.7605  decode.d3.loss_dice: 1.1390  decode.d4.loss_cls: 1.0861  decode.d4.loss_mask: 0.7361  decode.d4.loss_dice: 1.0856  decode.d5.loss_cls: 1.0195  decode.d5.loss_mask: 0.7561  decode.d5.loss_dice: 1.0858  decode.d6.loss_cls: 1.0146  decode.d6.loss_mask: 0.7562  decode.d6.loss_dice: 1.0935  decode.d7.loss_cls: 1.0400  decode.d7.loss_mask: 0.7539  decode.d7.loss_dice: 1.0958  decode.d8.loss_cls: 1.0264  decode.d8.loss_mask: 0.7692  decode.d8.loss_dice: 1.1179
2023/05/24 12:14:19 - mmengine - INFO - Iter(train) [144850/160000]  lr: 1.1986e-06  eta: 1:49:28  time: 0.4238  data_time: 0.0100  memory: 4847  grad_norm: 121.0513  loss: 38.1414  decode.loss_cls: 1.3970  decode.loss_mask: 0.7003  decode.loss_dice: 1.3905  decode.d0.loss_cls: 3.3369  decode.d0.loss_mask: 0.7906  decode.d0.loss_dice: 1.6769  decode.d1.loss_cls: 1.6354  decode.d1.loss_mask: 0.7770  decode.d1.loss_dice: 1.5956  decode.d2.loss_cls: 1.4872  decode.d2.loss_mask: 0.7032  decode.d2.loss_dice: 1.5092  decode.d3.loss_cls: 1.4449  decode.d3.loss_mask: 0.6837  decode.d3.loss_dice: 1.4732  decode.d4.loss_cls: 1.4112  decode.d4.loss_mask: 0.7239  decode.d4.loss_dice: 1.4279  decode.d5.loss_cls: 1.4039  decode.d5.loss_mask: 0.7153  decode.d5.loss_dice: 1.4099  decode.d6.loss_cls: 1.3722  decode.d6.loss_mask: 0.7242  decode.d6.loss_dice: 1.3913  decode.d7.loss_cls: 1.4098  decode.d7.loss_mask: 0.7103  decode.d7.loss_dice: 1.3782  decode.d8.loss_cls: 1.3605  decode.d8.loss_mask: 0.7051  decode.d8.loss_dice: 1.3965
2023/05/24 12:14:41 - mmengine - INFO - Iter(train) [144900/160000]  lr: 1.1950e-06  eta: 1:49:06  time: 0.4719  data_time: 0.0097  memory: 4859  grad_norm: 89.7070  loss: 32.1149  decode.loss_cls: 1.0994  decode.loss_mask: 0.7284  decode.loss_dice: 1.1280  decode.d0.loss_cls: 2.9657  decode.d0.loss_mask: 0.8100  decode.d0.loss_dice: 1.3805  decode.d1.loss_cls: 1.1409  decode.d1.loss_mask: 0.8040  decode.d1.loss_dice: 1.2388  decode.d2.loss_cls: 1.1934  decode.d2.loss_mask: 0.7661  decode.d2.loss_dice: 1.1770  decode.d3.loss_cls: 1.1211  decode.d3.loss_mask: 0.7158  decode.d3.loss_dice: 1.1300  decode.d4.loss_cls: 1.1146  decode.d4.loss_mask: 0.7277  decode.d4.loss_dice: 1.1757  decode.d5.loss_cls: 1.0385  decode.d5.loss_mask: 0.7289  decode.d5.loss_dice: 1.1509  decode.d6.loss_cls: 1.0507  decode.d6.loss_mask: 0.7407  decode.d6.loss_dice: 1.1594  decode.d7.loss_cls: 1.0234  decode.d7.loss_mask: 0.7275  decode.d7.loss_dice: 1.1763  decode.d8.loss_cls: 1.0230  decode.d8.loss_mask: 0.7311  decode.d8.loss_dice: 1.1471
2023/05/24 12:15:05 - mmengine - INFO - Iter(train) [144950/160000]  lr: 1.1915e-06  eta: 1:48:44  time: 0.4795  data_time: 0.0103  memory: 4827  grad_norm: 98.0227  loss: 41.9509  decode.loss_cls: 1.2795  decode.loss_mask: 0.9328  decode.loss_dice: 1.7040  decode.d0.loss_cls: 3.3568  decode.d0.loss_mask: 1.0144  decode.d0.loss_dice: 1.9470  decode.d1.loss_cls: 1.4323  decode.d1.loss_mask: 0.9201  decode.d1.loss_dice: 1.7916  decode.d2.loss_cls: 1.3163  decode.d2.loss_mask: 0.9087  decode.d2.loss_dice: 1.7558  decode.d3.loss_cls: 1.3311  decode.d3.loss_mask: 0.9223  decode.d3.loss_dice: 1.7123  decode.d4.loss_cls: 1.2351  decode.d4.loss_mask: 0.9405  decode.d4.loss_dice: 1.7277  decode.d5.loss_cls: 1.2621  decode.d5.loss_mask: 0.9491  decode.d5.loss_dice: 1.7392  decode.d6.loss_cls: 1.2953  decode.d6.loss_mask: 0.9429  decode.d6.loss_dice: 1.7174  decode.d7.loss_cls: 1.2348  decode.d7.loss_mask: 0.9398  decode.d7.loss_dice: 1.7225  decode.d8.loss_cls: 1.2660  decode.d8.loss_mask: 0.9413  decode.d8.loss_dice: 1.7124
2023/05/24 12:15:27 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 12:15:27 - mmengine - INFO - Iter(train) [145000/160000]  lr: 1.1879e-06  eta: 1:48:23  time: 0.4816  data_time: 0.0110  memory: 4827  grad_norm: 96.6118  loss: 32.4990  decode.loss_cls: 1.2350  decode.loss_mask: 0.6087  decode.loss_dice: 1.1453  decode.d0.loss_cls: 3.0215  decode.d0.loss_mask: 0.6572  decode.d0.loss_dice: 1.3467  decode.d1.loss_cls: 1.4114  decode.d1.loss_mask: 0.6128  decode.d1.loss_dice: 1.2517  decode.d2.loss_cls: 1.3491  decode.d2.loss_mask: 0.6106  decode.d2.loss_dice: 1.1620  decode.d3.loss_cls: 1.2633  decode.d3.loss_mask: 0.6192  decode.d3.loss_dice: 1.1875  decode.d4.loss_cls: 1.2700  decode.d4.loss_mask: 0.6251  decode.d4.loss_dice: 1.1689  decode.d5.loss_cls: 1.2666  decode.d5.loss_mask: 0.6200  decode.d5.loss_dice: 1.1541  decode.d6.loss_cls: 1.2209  decode.d6.loss_mask: 0.6232  decode.d6.loss_dice: 1.1492  decode.d7.loss_cls: 1.2495  decode.d7.loss_mask: 0.6178  decode.d7.loss_dice: 1.1170  decode.d8.loss_cls: 1.1932  decode.d8.loss_mask: 0.6220  decode.d8.loss_dice: 1.1196
2023/05/24 12:15:27 - mmengine - INFO - Saving checkpoint at 145000 iterations
2023/05/24 12:15:40 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:01:11  time: 0.2364  data_time: 0.0020  memory: 2167  
2023/05/24 12:15:44 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:54  time: 0.0837  data_time: 0.0018  memory: 2216  
2023/05/24 12:15:48 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:46  time: 0.0795  data_time: 0.0019  memory: 2167  
2023/05/24 12:15:52 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:39  time: 0.0789  data_time: 0.0018  memory: 2104  
2023/05/24 12:15:56 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:34  time: 0.0923  data_time: 0.0019  memory: 2831  
2023/05/24 12:16:00 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0784  data_time: 0.0017  memory: 2167  
2023/05/24 12:16:04 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0801  data_time: 0.0018  memory: 2167  
2023/05/24 12:16:08 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:19  time: 0.0922  data_time: 0.0018  memory: 2167  
2023/05/24 12:16:12 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0795  data_time: 0.0018  memory: 2944  
2023/05/24 12:16:17 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0825  data_time: 0.0018  memory: 2356  
2023/05/24 12:16:21 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.1039  data_time: 0.0019  memory: 2217  
2023/05/24 12:16:26 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0773  data_time: 0.0017  memory: 2328  
2023/05/24 12:16:30 - mmengine - INFO - per class results:
2023/05/24 12:16:30 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.16 | 93.68 |
|     bicycle      | 70.64 | 83.34 |
|       car        | 61.61 | 84.26 |
|    motorcycle    | 82.75 | 90.21 |
|     airplane     | 85.33 | 92.71 |
|       bus        | 82.02 | 87.73 |
|      train       | 83.18 |  93.4 |
|      truck       | 56.89 | 73.58 |
|       boat       | 62.25 |  81.0 |
|  traffic light   | 69.15 | 84.32 |
|   fire hydrant   | 90.12 | 95.19 |
|    stop sign     |  91.5 | 96.88 |
|  parking meter   | 76.18 | 86.19 |
|      bench       |  50.3 | 71.38 |
|       bird       | 81.59 | 91.09 |
|       cat        | 83.12 | 88.86 |
|       dog        | 81.08 | 86.78 |
|      horse       | 78.94 | 90.81 |
|      sheep       | 85.98 | 92.28 |
|       cow        | 82.14 |  88.7 |
|     elephant     | 89.86 | 95.02 |
|       bear       | 92.67 | 95.23 |
|      zebra       | 90.38 | 93.62 |
|     giraffe      | 87.51 | 93.95 |
|     backpack     |  36.9 | 55.12 |
|     umbrella     | 79.75 | 88.38 |
|     handbag      | 35.35 | 60.53 |
|       tie        | 11.91 | 15.18 |
|     suitcase     | 78.03 | 91.56 |
|     frisbee      | 66.35 | 91.02 |
|       skis       | 47.97 | 63.61 |
|    snowboard     | 59.69 | 72.04 |
|   sports ball    | 56.72 | 73.73 |
|       kite       | 57.49 | 71.08 |
|   baseball bat   | 51.39 | 62.14 |
|  baseball glove  |  73.7 | 87.26 |
|    skateboard    | 76.64 | 84.39 |
|    surfboard     | 73.89 | 86.46 |
|  tennis racket   | 84.55 | 92.27 |
|      bottle      | 41.96 | 55.54 |
|    wine glass    | 57.11 | 79.69 |
|       cup        | 57.36 | 73.97 |
|       fork       | 38.81 | 47.92 |
|      knife       | 34.21 | 43.65 |
|      spoon       | 34.99 | 55.38 |
|       bowl       | 47.21 |  66.0 |
|      banana      |  66.8 | 87.46 |
|      apple       | 49.65 | 71.26 |
|     sandwich     | 43.69 | 59.34 |
|      orange      | 63.18 | 68.69 |
|     broccoli     | 57.77 | 69.49 |
|      carrot      | 52.36 | 57.79 |
|     hot dog      |  46.9 | 57.91 |
|      pizza       | 67.59 | 84.91 |
|      donut       | 70.57 |  87.0 |
|       cake       | 58.46 | 73.74 |
|      chair       | 46.86 | 64.51 |
|      couch       | 54.62 | 82.39 |
|   potted plant   | 31.35 | 44.14 |
|       bed        | 61.54 | 83.03 |
|   dining table   | 44.36 | 78.96 |
|      toilet      | 82.27 | 93.62 |
|        tv        | 70.39 | 84.89 |
|      laptop      | 73.51 | 91.04 |
|      mouse       | 75.62 | 89.18 |
|      remote      | 63.32 | 72.88 |
|     keyboard     | 61.49 | 70.21 |
|    cell phone    |  69.9 | 90.04 |
|    microwave     | 64.23 | 76.04 |
|       oven       | 53.43 | 83.15 |
|     toaster      | 45.41 | 53.83 |
|       sink       | 56.19 | 78.79 |
|   refrigerator   | 78.67 | 91.98 |
|       book       | 52.17 | 70.44 |
|      clock       | 71.63 | 82.28 |
|       vase       | 57.97 | 87.07 |
|     scissors     | 78.62 | 91.46 |
|    teddy bear    | 74.65 | 85.85 |
|    hair drier    | 51.73 | 54.06 |
|    toothbrush    | 43.12 | 77.84 |
|      banner      | 35.69 | 64.05 |
|     blanket      |  4.0  |  4.44 |
|      branch      | 20.62 | 37.26 |
|      bridge      | 31.71 | 42.67 |
|  building-other  | 53.03 | 75.34 |
|       bush       | 33.42 |  48.4 |
|     cabinet      | 54.33 | 73.13 |
|       cage       |  19.3 | 34.12 |
|    cardboard     |  46.9 | 56.25 |
|      carpet      | 51.86 | 73.52 |
|  ceiling-other   | 63.65 | 78.57 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 20.45 | 27.74 |
|      clouds      | 45.44 | 58.07 |
|     counter      | 26.25 | 47.51 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 65.35 |  77.5 |
|    desk-stuff    | 46.08 | 62.71 |
|       dirt       | 42.39 | 61.28 |
|    door-stuff    | 40.09 | 60.18 |
|      fence       | 28.52 | 48.31 |
|   floor-marble   |  6.19 |  6.58 |
|   floor-other    | 22.81 | 32.95 |
|   floor-stone    |  2.75 |  3.15 |
|    floor-tile    | 61.56 |  74.0 |
|    floor-wood    | 64.85 | 79.84 |
|      flower      | 43.11 | 68.61 |
|       fog        |  5.03 |  5.05 |
|    food-other    | 28.47 | 34.49 |
|      fruit       | 38.87 | 56.97 |
| furniture-other  | 17.13 | 23.72 |
|      grass       | 70.52 | 83.92 |
|      gravel      | 26.84 | 34.78 |
|   ground-other   |  0.43 |  0.52 |
|       hill       | 24.39 | 35.23 |
|      house       | 25.03 | 30.71 |
|      leaves      | 23.59 | 29.41 |
|      light       | 37.35 |  55.7 |
|       mat        |  0.0  |  0.0  |
|      metal       | 32.96 | 48.59 |
|   mirror-stuff   | 49.26 | 63.99 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 52.41 | 66.57 |
|       mud        |  8.06 | 10.08 |
|      napkin      |  6.3  |  6.37 |
|       net        | 39.23 | 67.06 |
|      paper       | 30.11 | 40.16 |
|     pavement     | 50.95 | 69.95 |
|      pillow      | 11.15 | 15.07 |
|   plant-other    | 17.64 | 27.55 |
|     plastic      | 22.27 | 30.25 |
|     platform     | 28.02 | 45.74 |
|   playingfield   | 70.37 | 92.48 |
|     railing      |  6.09 |  9.53 |
|     railroad     | 60.86 | 82.37 |
|      river       | 51.64 | 75.01 |
|       road       | 66.82 | 81.86 |
|       rock       | 42.18 |  62.4 |
|       roof       | 11.25 |  14.7 |
|       rug        | 31.87 | 46.45 |
|      salad       |  0.04 |  0.04 |
|       sand       | 62.41 | 72.42 |
|       sea        | 85.89 | 91.67 |
|      shelf       | 34.35 | 47.99 |
|    sky-other     | 70.14 | 87.93 |
|    skyscraper    | 33.91 | 45.34 |
|       snow       | 89.25 | 93.61 |
|   solid-other    |  0.0  |  0.0  |
|      stairs      | 22.58 | 36.66 |
|      stone       | 11.83 | 21.85 |
|      straw       | 29.91 | 40.82 |
| structural-other |  0.01 |  0.01 |
|      table       | 15.26 | 19.06 |
|       tent       |  7.69 | 10.22 |
|  textile-other   | 11.52 | 17.22 |
|      towel       | 33.23 | 41.96 |
|       tree       | 73.35 | 85.97 |
|    vegetable     | 33.53 | 43.07 |
|    wall-brick    | 47.84 | 64.02 |
|  wall-concrete   | 60.84 | 79.43 |
|    wall-other    | 19.77 | 32.32 |
|    wall-panel    |  2.49 |  2.65 |
|    wall-stone    | 34.28 | 39.75 |
|    wall-tile     | 66.53 | 85.28 |
|    wall-wood     | 39.91 | 56.02 |
|   water-other    | 20.95 | 31.26 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 50.25 | 58.93 |
|   window-other   | 48.52 | 72.65 |
|       wood       | 23.37 | 36.73 |
+------------------+-------+-------+
2023/05/24 12:16:30 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.4500  mIoU: 47.3100  mAcc: 59.6500  data_time: 0.0020  time: 0.0867
2023/05/24 12:16:51 - mmengine - INFO - Iter(train) [145050/160000]  lr: 1.1843e-06  eta: 1:48:01  time: 0.4307  data_time: 0.0116  memory: 4865  grad_norm: 88.8082  loss: 32.7624  decode.loss_cls: 1.0286  decode.loss_mask: 0.7900  decode.loss_dice: 1.1368  decode.d0.loss_cls: 2.9819  decode.d0.loss_mask: 0.9001  decode.d0.loss_dice: 1.3780  decode.d1.loss_cls: 1.1813  decode.d1.loss_mask: 0.8820  decode.d1.loss_dice: 1.2806  decode.d2.loss_cls: 1.1040  decode.d2.loss_mask: 0.8520  decode.d2.loss_dice: 1.1975  decode.d3.loss_cls: 1.1245  decode.d3.loss_mask: 0.7753  decode.d3.loss_dice: 1.1936  decode.d4.loss_cls: 1.0857  decode.d4.loss_mask: 0.7808  decode.d4.loss_dice: 1.1701  decode.d5.loss_cls: 1.0751  decode.d5.loss_mask: 0.7781  decode.d5.loss_dice: 1.1540  decode.d6.loss_cls: 1.0511  decode.d6.loss_mask: 0.7936  decode.d6.loss_dice: 1.1615  decode.d7.loss_cls: 1.0251  decode.d7.loss_mask: 0.7870  decode.d7.loss_dice: 1.1383  decode.d8.loss_cls: 1.0160  decode.d8.loss_mask: 0.7905  decode.d8.loss_dice: 1.1495
2023/05/24 12:17:13 - mmengine - INFO - Iter(train) [145100/160000]  lr: 1.1808e-06  eta: 1:47:40  time: 0.4325  data_time: 0.0099  memory: 4931  grad_norm: 101.2368  loss: 35.4925  decode.loss_cls: 1.1697  decode.loss_mask: 0.8897  decode.loss_dice: 1.2672  decode.d0.loss_cls: 3.0269  decode.d0.loss_mask: 0.8613  decode.d0.loss_dice: 1.5074  decode.d1.loss_cls: 1.2069  decode.d1.loss_mask: 0.8846  decode.d1.loss_dice: 1.3437  decode.d2.loss_cls: 1.1418  decode.d2.loss_mask: 0.8666  decode.d2.loss_dice: 1.3138  decode.d3.loss_cls: 1.1865  decode.d3.loss_mask: 0.8785  decode.d3.loss_dice: 1.2811  decode.d4.loss_cls: 1.1555  decode.d4.loss_mask: 0.8971  decode.d4.loss_dice: 1.2792  decode.d5.loss_cls: 1.1833  decode.d5.loss_mask: 0.9035  decode.d5.loss_dice: 1.2782  decode.d6.loss_cls: 1.2227  decode.d6.loss_mask: 0.8697  decode.d6.loss_dice: 1.2525  decode.d7.loss_cls: 1.1868  decode.d7.loss_mask: 0.8725  decode.d7.loss_dice: 1.2447  decode.d8.loss_cls: 1.1904  decode.d8.loss_mask: 0.8728  decode.d8.loss_dice: 1.2580
2023/05/24 12:17:34 - mmengine - INFO - Iter(train) [145150/160000]  lr: 1.1772e-06  eta: 1:47:18  time: 0.4249  data_time: 0.0108  memory: 4821  grad_norm: 135.7773  loss: 30.6086  decode.loss_cls: 1.2122  decode.loss_mask: 0.5349  decode.loss_dice: 1.0718  decode.d0.loss_cls: 2.8408  decode.d0.loss_mask: 0.6570  decode.d0.loss_dice: 1.2541  decode.d1.loss_cls: 1.3007  decode.d1.loss_mask: 0.6004  decode.d1.loss_dice: 1.1371  decode.d2.loss_cls: 1.2443  decode.d2.loss_mask: 0.5515  decode.d2.loss_dice: 1.1165  decode.d3.loss_cls: 1.2608  decode.d3.loss_mask: 0.5675  decode.d3.loss_dice: 1.0856  decode.d4.loss_cls: 1.2536  decode.d4.loss_mask: 0.5332  decode.d4.loss_dice: 1.0303  decode.d5.loss_cls: 1.2607  decode.d5.loss_mask: 0.5314  decode.d5.loss_dice: 1.0553  decode.d6.loss_cls: 1.2669  decode.d6.loss_mask: 0.5350  decode.d6.loss_dice: 1.0351  decode.d7.loss_cls: 1.2146  decode.d7.loss_mask: 0.5413  decode.d7.loss_dice: 1.0651  decode.d8.loss_cls: 1.2510  decode.d8.loss_mask: 0.5307  decode.d8.loss_dice: 1.0694
2023/05/24 12:17:55 - mmengine - INFO - Iter(train) [145200/160000]  lr: 1.1736e-06  eta: 1:46:56  time: 0.4332  data_time: 0.0112  memory: 4875  grad_norm: 94.2273  loss: 28.5989  decode.loss_cls: 0.9756  decode.loss_mask: 0.6254  decode.loss_dice: 1.0180  decode.d0.loss_cls: 2.7357  decode.d0.loss_mask: 0.7151  decode.d0.loss_dice: 1.1974  decode.d1.loss_cls: 1.0657  decode.d1.loss_mask: 0.6259  decode.d1.loss_dice: 1.0804  decode.d2.loss_cls: 1.0018  decode.d2.loss_mask: 0.6191  decode.d2.loss_dice: 1.0969  decode.d3.loss_cls: 1.0071  decode.d3.loss_mask: 0.6357  decode.d3.loss_dice: 1.0413  decode.d4.loss_cls: 0.9892  decode.d4.loss_mask: 0.6436  decode.d4.loss_dice: 1.0318  decode.d5.loss_cls: 0.9654  decode.d5.loss_mask: 0.6361  decode.d5.loss_dice: 1.0536  decode.d6.loss_cls: 1.0133  decode.d6.loss_mask: 0.6269  decode.d6.loss_dice: 0.9972  decode.d7.loss_cls: 0.9518  decode.d7.loss_mask: 0.6308  decode.d7.loss_dice: 1.0087  decode.d8.loss_cls: 0.9901  decode.d8.loss_mask: 0.6256  decode.d8.loss_dice: 0.9938
2023/05/24 12:18:17 - mmengine - INFO - Iter(train) [145250/160000]  lr: 1.1701e-06  eta: 1:46:35  time: 0.4356  data_time: 0.0100  memory: 4874  grad_norm: 92.2484  loss: 37.9431  decode.loss_cls: 1.4149  decode.loss_mask: 0.6996  decode.loss_dice: 1.3983  decode.d0.loss_cls: 3.2549  decode.d0.loss_mask: 0.8123  decode.d0.loss_dice: 1.7736  decode.d1.loss_cls: 1.5098  decode.d1.loss_mask: 0.7574  decode.d1.loss_dice: 1.5400  decode.d2.loss_cls: 1.4375  decode.d2.loss_mask: 0.7200  decode.d2.loss_dice: 1.4305  decode.d3.loss_cls: 1.4087  decode.d3.loss_mask: 0.7319  decode.d3.loss_dice: 1.4206  decode.d4.loss_cls: 1.4288  decode.d4.loss_mask: 0.7281  decode.d4.loss_dice: 1.4285  decode.d5.loss_cls: 1.3960  decode.d5.loss_mask: 0.7430  decode.d5.loss_dice: 1.4080  decode.d6.loss_cls: 1.4302  decode.d6.loss_mask: 0.7295  decode.d6.loss_dice: 1.3748  decode.d7.loss_cls: 1.3709  decode.d7.loss_mask: 0.7254  decode.d7.loss_dice: 1.4063  decode.d8.loss_cls: 1.3792  decode.d8.loss_mask: 0.6970  decode.d8.loss_dice: 1.3874
2023/05/24 12:18:39 - mmengine - INFO - Iter(train) [145300/160000]  lr: 1.1665e-06  eta: 1:46:13  time: 0.4285  data_time: 0.0099  memory: 4788  grad_norm: 83.8585  loss: 23.5159  decode.loss_cls: 0.8047  decode.loss_mask: 0.6113  decode.loss_dice: 0.7047  decode.d0.loss_cls: 2.4654  decode.d0.loss_mask: 0.6323  decode.d0.loss_dice: 0.8559  decode.d1.loss_cls: 0.8021  decode.d1.loss_mask: 0.6248  decode.d1.loss_dice: 0.8196  decode.d2.loss_cls: 0.7436  decode.d2.loss_mask: 0.6668  decode.d2.loss_dice: 0.8152  decode.d3.loss_cls: 0.7971  decode.d3.loss_mask: 0.6553  decode.d3.loss_dice: 0.7417  decode.d4.loss_cls: 0.7942  decode.d4.loss_mask: 0.6329  decode.d4.loss_dice: 0.7565  decode.d5.loss_cls: 0.7766  decode.d5.loss_mask: 0.6221  decode.d5.loss_dice: 0.7546  decode.d6.loss_cls: 0.8136  decode.d6.loss_mask: 0.6198  decode.d6.loss_dice: 0.7186  decode.d7.loss_cls: 0.7830  decode.d7.loss_mask: 0.6253  decode.d7.loss_dice: 0.7382  decode.d8.loss_cls: 0.7827  decode.d8.loss_mask: 0.6337  decode.d8.loss_dice: 0.7236
2023/05/24 12:19:01 - mmengine - INFO - Iter(train) [145350/160000]  lr: 1.1629e-06  eta: 1:45:51  time: 0.4334  data_time: 0.0102  memory: 4919  grad_norm: 113.0573  loss: 33.7509  decode.loss_cls: 1.1462  decode.loss_mask: 0.6812  decode.loss_dice: 1.2942  decode.d0.loss_cls: 3.0900  decode.d0.loss_mask: 0.7412  decode.d0.loss_dice: 1.4573  decode.d1.loss_cls: 1.1947  decode.d1.loss_mask: 0.6798  decode.d1.loss_dice: 1.3578  decode.d2.loss_cls: 1.2273  decode.d2.loss_mask: 0.6918  decode.d2.loss_dice: 1.3026  decode.d3.loss_cls: 1.1973  decode.d3.loss_mask: 0.6963  decode.d3.loss_dice: 1.2976  decode.d4.loss_cls: 1.1971  decode.d4.loss_mask: 0.7009  decode.d4.loss_dice: 1.2958  decode.d5.loss_cls: 1.1585  decode.d5.loss_mask: 0.6995  decode.d5.loss_dice: 1.2675  decode.d6.loss_cls: 1.1649  decode.d6.loss_mask: 0.6814  decode.d6.loss_dice: 1.2806  decode.d7.loss_cls: 1.1745  decode.d7.loss_mask: 0.6826  decode.d7.loss_dice: 1.2883  decode.d8.loss_cls: 1.1334  decode.d8.loss_mask: 0.6820  decode.d8.loss_dice: 1.2884
2023/05/24 12:19:22 - mmengine - INFO - Iter(train) [145400/160000]  lr: 1.1593e-06  eta: 1:45:29  time: 0.4236  data_time: 0.0100  memory: 4891  grad_norm: 90.9143  loss: 34.1128  decode.loss_cls: 0.9884  decode.loss_mask: 0.7663  decode.loss_dice: 1.2672  decode.d0.loss_cls: 3.4924  decode.d0.loss_mask: 0.8533  decode.d0.loss_dice: 1.4684  decode.d1.loss_cls: 1.2536  decode.d1.loss_mask: 0.8455  decode.d1.loss_dice: 1.4044  decode.d2.loss_cls: 1.1386  decode.d2.loss_mask: 0.8216  decode.d2.loss_dice: 1.3500  decode.d3.loss_cls: 1.0395  decode.d3.loss_mask: 0.7957  decode.d3.loss_dice: 1.2952  decode.d4.loss_cls: 1.0117  decode.d4.loss_mask: 0.7953  decode.d4.loss_dice: 1.3162  decode.d5.loss_cls: 0.9702  decode.d5.loss_mask: 0.7952  decode.d5.loss_dice: 1.3107  decode.d6.loss_cls: 0.9552  decode.d6.loss_mask: 0.7747  decode.d6.loss_dice: 1.2609  decode.d7.loss_cls: 0.9762  decode.d7.loss_mask: 0.7774  decode.d7.loss_dice: 1.3117  decode.d8.loss_cls: 0.9772  decode.d8.loss_mask: 0.7867  decode.d8.loss_dice: 1.3133
2023/05/24 12:19:43 - mmengine - INFO - Iter(train) [145450/160000]  lr: 1.1558e-06  eta: 1:45:08  time: 0.4165  data_time: 0.0096  memory: 4877  grad_norm: 87.4823  loss: 38.7950  decode.loss_cls: 1.2024  decode.loss_mask: 0.7660  decode.loss_dice: 1.4813  decode.d0.loss_cls: 3.4739  decode.d0.loss_mask: 0.7869  decode.d0.loss_dice: 1.7631  decode.d1.loss_cls: 1.3604  decode.d1.loss_mask: 0.8665  decode.d1.loss_dice: 1.6445  decode.d2.loss_cls: 1.3844  decode.d2.loss_mask: 0.8189  decode.d2.loss_dice: 1.5665  decode.d3.loss_cls: 1.3203  decode.d3.loss_mask: 0.8455  decode.d3.loss_dice: 1.5562  decode.d4.loss_cls: 1.2852  decode.d4.loss_mask: 0.8231  decode.d4.loss_dice: 1.5617  decode.d5.loss_cls: 1.2389  decode.d5.loss_mask: 0.8314  decode.d5.loss_dice: 1.5743  decode.d6.loss_cls: 1.2787  decode.d6.loss_mask: 0.8114  decode.d6.loss_dice: 1.5474  decode.d7.loss_cls: 1.2835  decode.d7.loss_mask: 0.8088  decode.d7.loss_dice: 1.5110  decode.d8.loss_cls: 1.1637  decode.d8.loss_mask: 0.7564  decode.d8.loss_dice: 1.4827
2023/05/24 12:20:04 - mmengine - INFO - Iter(train) [145500/160000]  lr: 1.1522e-06  eta: 1:44:46  time: 0.4225  data_time: 0.0103  memory: 4899  grad_norm: 100.4852  loss: 33.2513  decode.loss_cls: 1.1557  decode.loss_mask: 0.6949  decode.loss_dice: 1.1418  decode.d0.loss_cls: 3.2605  decode.d0.loss_mask: 0.7531  decode.d0.loss_dice: 1.4732  decode.d1.loss_cls: 1.3072  decode.d1.loss_mask: 0.7338  decode.d1.loss_dice: 1.2897  decode.d2.loss_cls: 1.2430  decode.d2.loss_mask: 0.7152  decode.d2.loss_dice: 1.2267  decode.d3.loss_cls: 1.2095  decode.d3.loss_mask: 0.7085  decode.d3.loss_dice: 1.1485  decode.d4.loss_cls: 1.1911  decode.d4.loss_mask: 0.7274  decode.d4.loss_dice: 1.1701  decode.d5.loss_cls: 1.1823  decode.d5.loss_mask: 0.7326  decode.d5.loss_dice: 1.1661  decode.d6.loss_cls: 1.1802  decode.d6.loss_mask: 0.7132  decode.d6.loss_dice: 1.1451  decode.d7.loss_cls: 1.1123  decode.d7.loss_mask: 0.7164  decode.d7.loss_dice: 1.1835  decode.d8.loss_cls: 1.1538  decode.d8.loss_mask: 0.6999  decode.d8.loss_dice: 1.1159
2023/05/24 12:20:25 - mmengine - INFO - Iter(train) [145550/160000]  lr: 1.1486e-06  eta: 1:44:24  time: 0.4276  data_time: 0.0098  memory: 4900  grad_norm: 122.4970  loss: 41.4797  decode.loss_cls: 1.5048  decode.loss_mask: 0.6965  decode.loss_dice: 1.6599  decode.d0.loss_cls: 3.5762  decode.d0.loss_mask: 0.7868  decode.d0.loss_dice: 1.9414  decode.d1.loss_cls: 1.6799  decode.d1.loss_mask: 0.7686  decode.d1.loss_dice: 1.8208  decode.d2.loss_cls: 1.5873  decode.d2.loss_mask: 0.7116  decode.d2.loss_dice: 1.6951  decode.d3.loss_cls: 1.5010  decode.d3.loss_mask: 0.6858  decode.d3.loss_dice: 1.6341  decode.d4.loss_cls: 1.4862  decode.d4.loss_mask: 0.6914  decode.d4.loss_dice: 1.6201  decode.d5.loss_cls: 1.4943  decode.d5.loss_mask: 0.6903  decode.d5.loss_dice: 1.6515  decode.d6.loss_cls: 1.5146  decode.d6.loss_mask: 0.6965  decode.d6.loss_dice: 1.6671  decode.d7.loss_cls: 1.5280  decode.d7.loss_mask: 0.6991  decode.d7.loss_dice: 1.6570  decode.d8.loss_cls: 1.4705  decode.d8.loss_mask: 0.7020  decode.d8.loss_dice: 1.6610
2023/05/24 12:20:46 - mmengine - INFO - Iter(train) [145600/160000]  lr: 1.1450e-06  eta: 1:44:03  time: 0.4236  data_time: 0.0099  memory: 4900  grad_norm: 107.5072  loss: 32.4031  decode.loss_cls: 0.9229  decode.loss_mask: 0.7109  decode.loss_dice: 1.3042  decode.d0.loss_cls: 3.2979  decode.d0.loss_mask: 0.7568  decode.d0.loss_dice: 1.4689  decode.d1.loss_cls: 1.1422  decode.d1.loss_mask: 0.6992  decode.d1.loss_dice: 1.3671  decode.d2.loss_cls: 1.0824  decode.d2.loss_mask: 0.6938  decode.d2.loss_dice: 1.3070  decode.d3.loss_cls: 0.9993  decode.d3.loss_mask: 0.7156  decode.d3.loss_dice: 1.2689  decode.d4.loss_cls: 0.9996  decode.d4.loss_mask: 0.7061  decode.d4.loss_dice: 1.2572  decode.d5.loss_cls: 0.9844  decode.d5.loss_mask: 0.7000  decode.d5.loss_dice: 1.2727  decode.d6.loss_cls: 0.9316  decode.d6.loss_mask: 0.6914  decode.d6.loss_dice: 1.2682  decode.d7.loss_cls: 0.9888  decode.d7.loss_mask: 0.6825  decode.d7.loss_dice: 1.2821  decode.d8.loss_cls: 0.9463  decode.d8.loss_mask: 0.6939  decode.d8.loss_dice: 1.2614
2023/05/24 12:21:08 - mmengine - INFO - Iter(train) [145650/160000]  lr: 1.1415e-06  eta: 1:43:41  time: 0.4403  data_time: 0.0102  memory: 4885  grad_norm: 101.0245  loss: 36.4403  decode.loss_cls: 1.1847  decode.loss_mask: 0.8341  decode.loss_dice: 1.3491  decode.d0.loss_cls: 3.1269  decode.d0.loss_mask: 0.9623  decode.d0.loss_dice: 1.6652  decode.d1.loss_cls: 1.3052  decode.d1.loss_mask: 0.8893  decode.d1.loss_dice: 1.5086  decode.d2.loss_cls: 1.2720  decode.d2.loss_mask: 0.8824  decode.d2.loss_dice: 1.4298  decode.d3.loss_cls: 1.1729  decode.d3.loss_mask: 0.8418  decode.d3.loss_dice: 1.3843  decode.d4.loss_cls: 1.1637  decode.d4.loss_mask: 0.8174  decode.d4.loss_dice: 1.3939  decode.d5.loss_cls: 1.1595  decode.d5.loss_mask: 0.8086  decode.d5.loss_dice: 1.3533  decode.d6.loss_cls: 1.1592  decode.d6.loss_mask: 0.8148  decode.d6.loss_dice: 1.3231  decode.d7.loss_cls: 1.1501  decode.d7.loss_mask: 0.8137  decode.d7.loss_dice: 1.3478  decode.d8.loss_cls: 1.1550  decode.d8.loss_mask: 0.8291  decode.d8.loss_dice: 1.3425
2023/05/24 12:21:30 - mmengine - INFO - Iter(train) [145700/160000]  lr: 1.1379e-06  eta: 1:43:19  time: 0.4186  data_time: 0.0102  memory: 4787  grad_norm: 222.4743  loss: 31.5397  decode.loss_cls: 1.0086  decode.loss_mask: 0.7306  decode.loss_dice: 1.1332  decode.d0.loss_cls: 2.9884  decode.d0.loss_mask: 0.8228  decode.d0.loss_dice: 1.3491  decode.d1.loss_cls: 1.2064  decode.d1.loss_mask: 0.7471  decode.d1.loss_dice: 1.1926  decode.d2.loss_cls: 1.1431  decode.d2.loss_mask: 0.7320  decode.d2.loss_dice: 1.1526  decode.d3.loss_cls: 1.0716  decode.d3.loss_mask: 0.7168  decode.d3.loss_dice: 1.1259  decode.d4.loss_cls: 1.0536  decode.d4.loss_mask: 0.7230  decode.d4.loss_dice: 1.1226  decode.d5.loss_cls: 1.0983  decode.d5.loss_mask: 0.7214  decode.d5.loss_dice: 1.1672  decode.d6.loss_cls: 1.0260  decode.d6.loss_mask: 0.7114  decode.d6.loss_dice: 1.1507  decode.d7.loss_cls: 1.0215  decode.d7.loss_mask: 0.7069  decode.d7.loss_dice: 1.1078  decode.d8.loss_cls: 1.0074  decode.d8.loss_mask: 0.7044  decode.d8.loss_dice: 1.0967
2023/05/24 12:21:52 - mmengine - INFO - Iter(train) [145750/160000]  lr: 1.1343e-06  eta: 1:42:58  time: 0.4799  data_time: 0.0104  memory: 4822  grad_norm: 123.5746  loss: 24.0624  decode.loss_cls: 0.7422  decode.loss_mask: 0.5189  decode.loss_dice: 0.9278  decode.d0.loss_cls: 2.6038  decode.d0.loss_mask: 0.5553  decode.d0.loss_dice: 1.0204  decode.d1.loss_cls: 0.8797  decode.d1.loss_mask: 0.5265  decode.d1.loss_dice: 0.9631  decode.d2.loss_cls: 0.8130  decode.d2.loss_mask: 0.5748  decode.d2.loss_dice: 0.9387  decode.d3.loss_cls: 0.7438  decode.d3.loss_mask: 0.5311  decode.d3.loss_dice: 0.9004  decode.d4.loss_cls: 0.7340  decode.d4.loss_mask: 0.5445  decode.d4.loss_dice: 0.8899  decode.d5.loss_cls: 0.7557  decode.d5.loss_mask: 0.5120  decode.d5.loss_dice: 0.8943  decode.d6.loss_cls: 0.7624  decode.d6.loss_mask: 0.5108  decode.d6.loss_dice: 0.8854  decode.d7.loss_cls: 0.7566  decode.d7.loss_mask: 0.5207  decode.d7.loss_dice: 0.8670  decode.d8.loss_cls: 0.7570  decode.d8.loss_mask: 0.5217  decode.d8.loss_dice: 0.9111
2023/05/24 12:22:14 - mmengine - INFO - Iter(train) [145800/160000]  lr: 1.1307e-06  eta: 1:42:36  time: 0.4332  data_time: 0.0108  memory: 4908  grad_norm: 85.3120  loss: 40.6632  decode.loss_cls: 1.3155  decode.loss_mask: 0.8410  decode.loss_dice: 1.6036  decode.d0.loss_cls: 3.3505  decode.d0.loss_mask: 0.9677  decode.d0.loss_dice: 1.9492  decode.d1.loss_cls: 1.4528  decode.d1.loss_mask: 0.9365  decode.d1.loss_dice: 1.7478  decode.d2.loss_cls: 1.4027  decode.d2.loss_mask: 0.9127  decode.d2.loss_dice: 1.6341  decode.d3.loss_cls: 1.3530  decode.d3.loss_mask: 0.8714  decode.d3.loss_dice: 1.6399  decode.d4.loss_cls: 1.3111  decode.d4.loss_mask: 0.8496  decode.d4.loss_dice: 1.6319  decode.d5.loss_cls: 1.2959  decode.d5.loss_mask: 0.8255  decode.d5.loss_dice: 1.5879  decode.d6.loss_cls: 1.3047  decode.d6.loss_mask: 0.8452  decode.d6.loss_dice: 1.5692  decode.d7.loss_cls: 1.2677  decode.d7.loss_mask: 0.8330  decode.d7.loss_dice: 1.6229  decode.d8.loss_cls: 1.2948  decode.d8.loss_mask: 0.8385  decode.d8.loss_dice: 1.6067
2023/05/24 12:22:35 - mmengine - INFO - Iter(train) [145850/160000]  lr: 1.1271e-06  eta: 1:42:14  time: 0.4272  data_time: 0.0100  memory: 4905  grad_norm: 126.3571  loss: 41.9937  decode.loss_cls: 1.3366  decode.loss_mask: 0.8864  decode.loss_dice: 1.6141  decode.d0.loss_cls: 3.2719  decode.d0.loss_mask: 1.0044  decode.d0.loss_dice: 2.0377  decode.d1.loss_cls: 1.5264  decode.d1.loss_mask: 0.9879  decode.d1.loss_dice: 1.8555  decode.d2.loss_cls: 1.4273  decode.d2.loss_mask: 0.9445  decode.d2.loss_dice: 1.7316  decode.d3.loss_cls: 1.3624  decode.d3.loss_mask: 0.9055  decode.d3.loss_dice: 1.6613  decode.d4.loss_cls: 1.3184  decode.d4.loss_mask: 0.9161  decode.d4.loss_dice: 1.6912  decode.d5.loss_cls: 1.3435  decode.d5.loss_mask: 0.8920  decode.d5.loss_dice: 1.6452  decode.d6.loss_cls: 1.3888  decode.d6.loss_mask: 0.8758  decode.d6.loss_dice: 1.6244  decode.d7.loss_cls: 1.3761  decode.d7.loss_mask: 0.8828  decode.d7.loss_dice: 1.6420  decode.d8.loss_cls: 1.3411  decode.d8.loss_mask: 0.8749  decode.d8.loss_dice: 1.6276
2023/05/24 12:22:56 - mmengine - INFO - Iter(train) [145900/160000]  lr: 1.1235e-06  eta: 1:41:52  time: 0.4171  data_time: 0.0102  memory: 4857  grad_norm: 91.4869  loss: 31.2814  decode.loss_cls: 0.9428  decode.loss_mask: 0.7127  decode.loss_dice: 1.1533  decode.d0.loss_cls: 2.9719  decode.d0.loss_mask: 0.8141  decode.d0.loss_dice: 1.4284  decode.d1.loss_cls: 1.1184  decode.d1.loss_mask: 0.7158  decode.d1.loss_dice: 1.2194  decode.d2.loss_cls: 1.0431  decode.d2.loss_mask: 0.7494  decode.d2.loss_dice: 1.2523  decode.d3.loss_cls: 1.0233  decode.d3.loss_mask: 0.7056  decode.d3.loss_dice: 1.1659  decode.d4.loss_cls: 0.9803  decode.d4.loss_mask: 0.7160  decode.d4.loss_dice: 1.1833  decode.d5.loss_cls: 0.9350  decode.d5.loss_mask: 0.7271  decode.d5.loss_dice: 1.1845  decode.d6.loss_cls: 0.9373  decode.d6.loss_mask: 0.7321  decode.d6.loss_dice: 1.1833  decode.d7.loss_cls: 0.9836  decode.d7.loss_mask: 0.7258  decode.d7.loss_dice: 1.1468  decode.d8.loss_cls: 0.9261  decode.d8.loss_mask: 0.7325  decode.d8.loss_dice: 1.1714
2023/05/24 12:23:17 - mmengine - INFO - Iter(train) [145950/160000]  lr: 1.1200e-06  eta: 1:41:31  time: 0.4334  data_time: 0.0109  memory: 4894  grad_norm: 88.3931  loss: 30.0927  decode.loss_cls: 0.9452  decode.loss_mask: 0.7137  decode.loss_dice: 1.0519  decode.d0.loss_cls: 2.9267  decode.d0.loss_mask: 0.7988  decode.d0.loss_dice: 1.2582  decode.d1.loss_cls: 1.2289  decode.d1.loss_mask: 0.7221  decode.d1.loss_dice: 1.1316  decode.d2.loss_cls: 1.1152  decode.d2.loss_mask: 0.7158  decode.d2.loss_dice: 1.0700  decode.d3.loss_cls: 0.9571  decode.d3.loss_mask: 0.7211  decode.d3.loss_dice: 1.0741  decode.d4.loss_cls: 0.9769  decode.d4.loss_mask: 0.7162  decode.d4.loss_dice: 1.0454  decode.d5.loss_cls: 0.9187  decode.d5.loss_mask: 0.7362  decode.d5.loss_dice: 1.0802  decode.d6.loss_cls: 0.9155  decode.d6.loss_mask: 0.7160  decode.d6.loss_dice: 1.0550  decode.d7.loss_cls: 0.9867  decode.d7.loss_mask: 0.7141  decode.d7.loss_dice: 1.0564  decode.d8.loss_cls: 0.9981  decode.d8.loss_mask: 0.6974  decode.d8.loss_dice: 1.0495
2023/05/24 12:23:39 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 12:23:39 - mmengine - INFO - Iter(train) [146000/160000]  lr: 1.1164e-06  eta: 1:41:09  time: 0.4259  data_time: 0.0100  memory: 4841  grad_norm: 103.4106  loss: 29.7112  decode.loss_cls: 1.0340  decode.loss_mask: 0.6429  decode.loss_dice: 1.0471  decode.d0.loss_cls: 2.8168  decode.d0.loss_mask: 0.6699  decode.d0.loss_dice: 1.2180  decode.d1.loss_cls: 1.2020  decode.d1.loss_mask: 0.6694  decode.d1.loss_dice: 1.1479  decode.d2.loss_cls: 1.1338  decode.d2.loss_mask: 0.6700  decode.d2.loss_dice: 1.1094  decode.d3.loss_cls: 1.0957  decode.d3.loss_mask: 0.6394  decode.d3.loss_dice: 1.0569  decode.d4.loss_cls: 1.0905  decode.d4.loss_mask: 0.6359  decode.d4.loss_dice: 1.0453  decode.d5.loss_cls: 1.0594  decode.d5.loss_mask: 0.6187  decode.d5.loss_dice: 1.0192  decode.d6.loss_cls: 1.0387  decode.d6.loss_mask: 0.6289  decode.d6.loss_dice: 1.0427  decode.d7.loss_cls: 1.0057  decode.d7.loss_mask: 0.6308  decode.d7.loss_dice: 1.0448  decode.d8.loss_cls: 1.0454  decode.d8.loss_mask: 0.6252  decode.d8.loss_dice: 1.0267
2023/05/24 12:23:39 - mmengine - INFO - Saving checkpoint at 146000 iterations
2023/05/24 12:24:07 - mmengine - INFO - Iter(train) [146050/160000]  lr: 1.1128e-06  eta: 1:40:48  time: 0.4408  data_time: 0.0102  memory: 4838  grad_norm: 110.6389  loss: 35.7165  decode.loss_cls: 1.1228  decode.loss_mask: 0.7667  decode.loss_dice: 1.4069  decode.d0.loss_cls: 3.0258  decode.d0.loss_mask: 0.7632  decode.d0.loss_dice: 1.6025  decode.d1.loss_cls: 1.2748  decode.d1.loss_mask: 0.7660  decode.d1.loss_dice: 1.4647  decode.d2.loss_cls: 1.1722  decode.d2.loss_mask: 0.7908  decode.d2.loss_dice: 1.4863  decode.d3.loss_cls: 1.2051  decode.d3.loss_mask: 0.7869  decode.d3.loss_dice: 1.4249  decode.d4.loss_cls: 1.2125  decode.d4.loss_mask: 0.7836  decode.d4.loss_dice: 1.4118  decode.d5.loss_cls: 1.1901  decode.d5.loss_mask: 0.7795  decode.d5.loss_dice: 1.3933  decode.d6.loss_cls: 1.0902  decode.d6.loss_mask: 0.7817  decode.d6.loss_dice: 1.4159  decode.d7.loss_cls: 1.1190  decode.d7.loss_mask: 0.7783  decode.d7.loss_dice: 1.3908  decode.d8.loss_cls: 1.1581  decode.d8.loss_mask: 0.7628  decode.d8.loss_dice: 1.3890
2023/05/24 12:24:28 - mmengine - INFO - Iter(train) [146100/160000]  lr: 1.1092e-06  eta: 1:40:26  time: 0.4443  data_time: 0.0101  memory: 4871  grad_norm: 91.6071  loss: 29.9459  decode.loss_cls: 1.0146  decode.loss_mask: 0.6884  decode.loss_dice: 1.0066  decode.d0.loss_cls: 3.1316  decode.d0.loss_mask: 0.7553  decode.d0.loss_dice: 1.1842  decode.d1.loss_cls: 1.1025  decode.d1.loss_mask: 0.7551  decode.d1.loss_dice: 1.1620  decode.d2.loss_cls: 1.0356  decode.d2.loss_mask: 0.7135  decode.d2.loss_dice: 1.0757  decode.d3.loss_cls: 0.9902  decode.d3.loss_mask: 0.7058  decode.d3.loss_dice: 1.0694  decode.d4.loss_cls: 1.0011  decode.d4.loss_mask: 0.7099  decode.d4.loss_dice: 1.0170  decode.d5.loss_cls: 0.9271  decode.d5.loss_mask: 0.7058  decode.d5.loss_dice: 1.0566  decode.d6.loss_cls: 0.9794  decode.d6.loss_mask: 0.7086  decode.d6.loss_dice: 1.0462  decode.d7.loss_cls: 0.9866  decode.d7.loss_mask: 0.7062  decode.d7.loss_dice: 1.0146  decode.d8.loss_cls: 0.9720  decode.d8.loss_mask: 0.7001  decode.d8.loss_dice: 1.0245
2023/05/24 12:24:51 - mmengine - INFO - Iter(train) [146150/160000]  lr: 1.1056e-06  eta: 1:40:05  time: 0.4837  data_time: 0.0099  memory: 4804  grad_norm: 88.0194  loss: 26.8008  decode.loss_cls: 0.8983  decode.loss_mask: 0.6204  decode.loss_dice: 0.8651  decode.d0.loss_cls: 2.7522  decode.d0.loss_mask: 0.7321  decode.d0.loss_dice: 1.0854  decode.d1.loss_cls: 1.0545  decode.d1.loss_mask: 0.6828  decode.d1.loss_dice: 0.9923  decode.d2.loss_cls: 0.9693  decode.d2.loss_mask: 0.6645  decode.d2.loss_dice: 0.9466  decode.d3.loss_cls: 0.9393  decode.d3.loss_mask: 0.6193  decode.d3.loss_dice: 0.9056  decode.d4.loss_cls: 0.8740  decode.d4.loss_mask: 0.6495  decode.d4.loss_dice: 0.9125  decode.d5.loss_cls: 0.9169  decode.d5.loss_mask: 0.6235  decode.d5.loss_dice: 0.8922  decode.d6.loss_cls: 0.9081  decode.d6.loss_mask: 0.6169  decode.d6.loss_dice: 0.8737  decode.d7.loss_cls: 0.8923  decode.d7.loss_mask: 0.6199  decode.d7.loss_dice: 0.8937  decode.d8.loss_cls: 0.8915  decode.d8.loss_mask: 0.6262  decode.d8.loss_dice: 0.8824
2023/05/24 12:25:14 - mmengine - INFO - Iter(train) [146200/160000]  lr: 1.1020e-06  eta: 1:39:43  time: 0.4796  data_time: 0.0123  memory: 4887  grad_norm: 91.5536  loss: 37.1070  decode.loss_cls: 1.3045  decode.loss_mask: 0.8487  decode.loss_dice: 1.2499  decode.d0.loss_cls: 2.9774  decode.d0.loss_mask: 0.8873  decode.d0.loss_dice: 1.4378  decode.d1.loss_cls: 1.3706  decode.d1.loss_mask: 0.8781  decode.d1.loss_dice: 1.3904  decode.d2.loss_cls: 1.4347  decode.d2.loss_mask: 0.8719  decode.d2.loss_dice: 1.3275  decode.d3.loss_cls: 1.5095  decode.d3.loss_mask: 0.8443  decode.d3.loss_dice: 1.2913  decode.d4.loss_cls: 1.4357  decode.d4.loss_mask: 0.8616  decode.d4.loss_dice: 1.2762  decode.d5.loss_cls: 1.3296  decode.d5.loss_mask: 0.8760  decode.d5.loss_dice: 1.2704  decode.d6.loss_cls: 1.3810  decode.d6.loss_mask: 0.8601  decode.d6.loss_dice: 1.2619  decode.d7.loss_cls: 1.3640  decode.d7.loss_mask: 0.8458  decode.d7.loss_dice: 1.2536  decode.d8.loss_cls: 1.3937  decode.d8.loss_mask: 0.8478  decode.d8.loss_dice: 1.2259
2023/05/24 12:25:37 - mmengine - INFO - Iter(train) [146250/160000]  lr: 1.0984e-06  eta: 1:39:22  time: 0.4215  data_time: 0.0099  memory: 5009  grad_norm: 103.4320  loss: 35.9644  decode.loss_cls: 1.0432  decode.loss_mask: 0.7483  decode.loss_dice: 1.4745  decode.d0.loss_cls: 3.2754  decode.d0.loss_mask: 0.7903  decode.d0.loss_dice: 1.6488  decode.d1.loss_cls: 1.2554  decode.d1.loss_mask: 0.7736  decode.d1.loss_dice: 1.6116  decode.d2.loss_cls: 1.2075  decode.d2.loss_mask: 0.7343  decode.d2.loss_dice: 1.5025  decode.d3.loss_cls: 1.1033  decode.d3.loss_mask: 0.7396  decode.d3.loss_dice: 1.4723  decode.d4.loss_cls: 1.0858  decode.d4.loss_mask: 0.7360  decode.d4.loss_dice: 1.5175  decode.d5.loss_cls: 1.0602  decode.d5.loss_mask: 0.7463  decode.d5.loss_dice: 1.4788  decode.d6.loss_cls: 1.0906  decode.d6.loss_mask: 0.7546  decode.d6.loss_dice: 1.5375  decode.d7.loss_cls: 1.0531  decode.d7.loss_mask: 0.7539  decode.d7.loss_dice: 1.4840  decode.d8.loss_cls: 1.0528  decode.d8.loss_mask: 0.7437  decode.d8.loss_dice: 1.4889
2023/05/24 12:25:58 - mmengine - INFO - Iter(train) [146300/160000]  lr: 1.0948e-06  eta: 1:39:00  time: 0.4229  data_time: 0.0105  memory: 4859  grad_norm: 80.2905  loss: 27.7200  decode.loss_cls: 1.0127  decode.loss_mask: 0.6299  decode.loss_dice: 0.8964  decode.d0.loss_cls: 2.7726  decode.d0.loss_mask: 0.6837  decode.d0.loss_dice: 1.0286  decode.d1.loss_cls: 1.0484  decode.d1.loss_mask: 0.6669  decode.d1.loss_dice: 1.0146  decode.d2.loss_cls: 1.0229  decode.d2.loss_mask: 0.6692  decode.d2.loss_dice: 0.9615  decode.d3.loss_cls: 0.9822  decode.d3.loss_mask: 0.6350  decode.d3.loss_dice: 0.9203  decode.d4.loss_cls: 1.0039  decode.d4.loss_mask: 0.6451  decode.d4.loss_dice: 0.9419  decode.d5.loss_cls: 1.0087  decode.d5.loss_mask: 0.6368  decode.d5.loss_dice: 0.9277  decode.d6.loss_cls: 0.9867  decode.d6.loss_mask: 0.6257  decode.d6.loss_dice: 0.9087  decode.d7.loss_cls: 0.9747  decode.d7.loss_mask: 0.6253  decode.d7.loss_dice: 0.9332  decode.d8.loss_cls: 1.0094  decode.d8.loss_mask: 0.6112  decode.d8.loss_dice: 0.9361
2023/05/24 12:26:19 - mmengine - INFO - Iter(train) [146350/160000]  lr: 1.0912e-06  eta: 1:38:38  time: 0.4246  data_time: 0.0102  memory: 4895  grad_norm: 98.8079  loss: 32.3443  decode.loss_cls: 1.2627  decode.loss_mask: 0.5554  decode.loss_dice: 1.1762  decode.d0.loss_cls: 3.2152  decode.d0.loss_mask: 0.6246  decode.d0.loss_dice: 1.3899  decode.d1.loss_cls: 1.4108  decode.d1.loss_mask: 0.5876  decode.d1.loss_dice: 1.2645  decode.d2.loss_cls: 1.2512  decode.d2.loss_mask: 0.5832  decode.d2.loss_dice: 1.2605  decode.d3.loss_cls: 1.2678  decode.d3.loss_mask: 0.5806  decode.d3.loss_dice: 1.1941  decode.d4.loss_cls: 1.2353  decode.d4.loss_mask: 0.5675  decode.d4.loss_dice: 1.1627  decode.d5.loss_cls: 1.2554  decode.d5.loss_mask: 0.5547  decode.d5.loss_dice: 1.1358  decode.d6.loss_cls: 1.2360  decode.d6.loss_mask: 0.5610  decode.d6.loss_dice: 1.1446  decode.d7.loss_cls: 1.2344  decode.d7.loss_mask: 0.5623  decode.d7.loss_dice: 1.1506  decode.d8.loss_cls: 1.2384  decode.d8.loss_mask: 0.5544  decode.d8.loss_dice: 1.1271
2023/05/24 12:26:40 - mmengine - INFO - Iter(train) [146400/160000]  lr: 1.0876e-06  eta: 1:38:16  time: 0.4244  data_time: 0.0103  memory: 4984  grad_norm: 109.6859  loss: 36.5789  decode.loss_cls: 1.2053  decode.loss_mask: 0.7557  decode.loss_dice: 1.4732  decode.d0.loss_cls: 3.0022  decode.d0.loss_mask: 0.7576  decode.d0.loss_dice: 1.6667  decode.d1.loss_cls: 1.2680  decode.d1.loss_mask: 0.7833  decode.d1.loss_dice: 1.5858  decode.d2.loss_cls: 1.2153  decode.d2.loss_mask: 0.7356  decode.d2.loss_dice: 1.5002  decode.d3.loss_cls: 1.2205  decode.d3.loss_mask: 0.7481  decode.d3.loss_dice: 1.5052  decode.d4.loss_cls: 1.2098  decode.d4.loss_mask: 0.7582  decode.d4.loss_dice: 1.4908  decode.d5.loss_cls: 1.2026  decode.d5.loss_mask: 0.7513  decode.d5.loss_dice: 1.5122  decode.d6.loss_cls: 1.1883  decode.d6.loss_mask: 0.7550  decode.d6.loss_dice: 1.4732  decode.d7.loss_cls: 1.1782  decode.d7.loss_mask: 0.7461  decode.d7.loss_dice: 1.4778  decode.d8.loss_cls: 1.1748  decode.d8.loss_mask: 0.7591  decode.d8.loss_dice: 1.4786
2023/05/24 12:27:02 - mmengine - INFO - Iter(train) [146450/160000]  lr: 1.0840e-06  eta: 1:37:55  time: 0.4223  data_time: 0.0108  memory: 4844  grad_norm: 105.5757  loss: 28.1523  decode.loss_cls: 0.8777  decode.loss_mask: 0.7210  decode.loss_dice: 0.9385  decode.d0.loss_cls: 2.7519  decode.d0.loss_mask: 0.7518  decode.d0.loss_dice: 1.0983  decode.d1.loss_cls: 1.0444  decode.d1.loss_mask: 0.7270  decode.d1.loss_dice: 0.9960  decode.d2.loss_cls: 0.9702  decode.d2.loss_mask: 0.7343  decode.d2.loss_dice: 0.9857  decode.d3.loss_cls: 0.9639  decode.d3.loss_mask: 0.7179  decode.d3.loss_dice: 0.9487  decode.d4.loss_cls: 0.9707  decode.d4.loss_mask: 0.7171  decode.d4.loss_dice: 0.9506  decode.d5.loss_cls: 0.9143  decode.d5.loss_mask: 0.7177  decode.d5.loss_dice: 0.9481  decode.d6.loss_cls: 0.9126  decode.d6.loss_mask: 0.7149  decode.d6.loss_dice: 0.9527  decode.d7.loss_cls: 0.9022  decode.d7.loss_mask: 0.7153  decode.d7.loss_dice: 0.9479  decode.d8.loss_cls: 0.8787  decode.d8.loss_mask: 0.7236  decode.d8.loss_dice: 0.9586
2023/05/24 12:27:23 - mmengine - INFO - Iter(train) [146500/160000]  lr: 1.0804e-06  eta: 1:37:33  time: 0.4210  data_time: 0.0106  memory: 4819  grad_norm: 99.5108  loss: 34.1639  decode.loss_cls: 1.0306  decode.loss_mask: 0.7653  decode.loss_dice: 1.3003  decode.d0.loss_cls: 3.1329  decode.d0.loss_mask: 0.8185  decode.d0.loss_dice: 1.5423  decode.d1.loss_cls: 1.1214  decode.d1.loss_mask: 0.8402  decode.d1.loss_dice: 1.4593  decode.d2.loss_cls: 1.0868  decode.d2.loss_mask: 0.8305  decode.d2.loss_dice: 1.3964  decode.d3.loss_cls: 1.0552  decode.d3.loss_mask: 0.8129  decode.d3.loss_dice: 1.3478  decode.d4.loss_cls: 1.0882  decode.d4.loss_mask: 0.7749  decode.d4.loss_dice: 1.3345  decode.d5.loss_cls: 1.0285  decode.d5.loss_mask: 0.7779  decode.d5.loss_dice: 1.3136  decode.d6.loss_cls: 1.0546  decode.d6.loss_mask: 0.7729  decode.d6.loss_dice: 1.2868  decode.d7.loss_cls: 1.0264  decode.d7.loss_mask: 0.7684  decode.d7.loss_dice: 1.3035  decode.d8.loss_cls: 1.0121  decode.d8.loss_mask: 0.7720  decode.d8.loss_dice: 1.3091
2023/05/24 12:27:47 - mmengine - INFO - Iter(train) [146550/160000]  lr: 1.0768e-06  eta: 1:37:11  time: 0.4768  data_time: 0.0100  memory: 4890  grad_norm: 89.5794  loss: 24.9017  decode.loss_cls: 0.8187  decode.loss_mask: 0.5733  decode.loss_dice: 0.8431  decode.d0.loss_cls: 2.6432  decode.d0.loss_mask: 0.6226  decode.d0.loss_dice: 0.9839  decode.d1.loss_cls: 0.9964  decode.d1.loss_mask: 0.6160  decode.d1.loss_dice: 0.9120  decode.d2.loss_cls: 0.8623  decode.d2.loss_mask: 0.6063  decode.d2.loss_dice: 0.9001  decode.d3.loss_cls: 0.8464  decode.d3.loss_mask: 0.6054  decode.d3.loss_dice: 0.8673  decode.d4.loss_cls: 0.8316  decode.d4.loss_mask: 0.5936  decode.d4.loss_dice: 0.8503  decode.d5.loss_cls: 0.8455  decode.d5.loss_mask: 0.5846  decode.d5.loss_dice: 0.8367  decode.d6.loss_cls: 0.8318  decode.d6.loss_mask: 0.5810  decode.d6.loss_dice: 0.8425  decode.d7.loss_cls: 0.7851  decode.d7.loss_mask: 0.5749  decode.d7.loss_dice: 0.8313  decode.d8.loss_cls: 0.7663  decode.d8.loss_mask: 0.5916  decode.d8.loss_dice: 0.8580
2023/05/24 12:28:09 - mmengine - INFO - Iter(train) [146600/160000]  lr: 1.0732e-06  eta: 1:36:50  time: 0.4329  data_time: 0.0100  memory: 4866  grad_norm: 103.7291  loss: 28.7738  decode.loss_cls: 1.0387  decode.loss_mask: 0.6086  decode.loss_dice: 0.9421  decode.d0.loss_cls: 3.0618  decode.d0.loss_mask: 0.6547  decode.d0.loss_dice: 1.1146  decode.d1.loss_cls: 1.2469  decode.d1.loss_mask: 0.6818  decode.d1.loss_dice: 0.9923  decode.d2.loss_cls: 1.1032  decode.d2.loss_mask: 0.6254  decode.d2.loss_dice: 0.9851  decode.d3.loss_cls: 1.0703  decode.d3.loss_mask: 0.6285  decode.d3.loss_dice: 0.9652  decode.d4.loss_cls: 1.0265  decode.d4.loss_mask: 0.6253  decode.d4.loss_dice: 0.9418  decode.d5.loss_cls: 1.0019  decode.d5.loss_mask: 0.6246  decode.d5.loss_dice: 0.9678  decode.d6.loss_cls: 1.1014  decode.d6.loss_mask: 0.6246  decode.d6.loss_dice: 0.9443  decode.d7.loss_cls: 1.0237  decode.d7.loss_mask: 0.6291  decode.d7.loss_dice: 0.9566  decode.d8.loss_cls: 0.9986  decode.d8.loss_mask: 0.6177  decode.d8.loss_dice: 0.9705
2023/05/24 12:28:31 - mmengine - INFO - Iter(train) [146650/160000]  lr: 1.0696e-06  eta: 1:36:28  time: 0.4211  data_time: 0.0099  memory: 4891  grad_norm: 91.0233  loss: 25.8261  decode.loss_cls: 0.8587  decode.loss_mask: 0.6214  decode.loss_dice: 0.8224  decode.d0.loss_cls: 2.7666  decode.d0.loss_mask: 0.7432  decode.d0.loss_dice: 0.9636  decode.d1.loss_cls: 1.0451  decode.d1.loss_mask: 0.6543  decode.d1.loss_dice: 0.8998  decode.d2.loss_cls: 0.9017  decode.d2.loss_mask: 0.6361  decode.d2.loss_dice: 0.8613  decode.d3.loss_cls: 0.8525  decode.d3.loss_mask: 0.6399  decode.d3.loss_dice: 0.8277  decode.d4.loss_cls: 0.8559  decode.d4.loss_mask: 0.6412  decode.d4.loss_dice: 0.8349  decode.d5.loss_cls: 0.8740  decode.d5.loss_mask: 0.6404  decode.d5.loss_dice: 0.8441  decode.d6.loss_cls: 0.8846  decode.d6.loss_mask: 0.6291  decode.d6.loss_dice: 0.8389  decode.d7.loss_cls: 0.9002  decode.d7.loss_mask: 0.6286  decode.d7.loss_dice: 0.8331  decode.d8.loss_cls: 0.8822  decode.d8.loss_mask: 0.6243  decode.d8.loss_dice: 0.8205
2023/05/24 12:28:53 - mmengine - INFO - Iter(train) [146700/160000]  lr: 1.0660e-06  eta: 1:36:06  time: 0.4352  data_time: 0.0099  memory: 4845  grad_norm: 95.9845  loss: 34.2801  decode.loss_cls: 1.2081  decode.loss_mask: 0.7266  decode.loss_dice: 1.2208  decode.d0.loss_cls: 3.1437  decode.d0.loss_mask: 0.8036  decode.d0.loss_dice: 1.4805  decode.d1.loss_cls: 1.3517  decode.d1.loss_mask: 0.7481  decode.d1.loss_dice: 1.2919  decode.d2.loss_cls: 1.2390  decode.d2.loss_mask: 0.7226  decode.d2.loss_dice: 1.2805  decode.d3.loss_cls: 1.2351  decode.d3.loss_mask: 0.7141  decode.d3.loss_dice: 1.2534  decode.d4.loss_cls: 1.2066  decode.d4.loss_mask: 0.7179  decode.d4.loss_dice: 1.2702  decode.d5.loss_cls: 1.1808  decode.d5.loss_mask: 0.7300  decode.d5.loss_dice: 1.2697  decode.d6.loss_cls: 1.2212  decode.d6.loss_mask: 0.7227  decode.d6.loss_dice: 1.2438  decode.d7.loss_cls: 1.2271  decode.d7.loss_mask: 0.7191  decode.d7.loss_dice: 1.2069  decode.d8.loss_cls: 1.1852  decode.d8.loss_mask: 0.7282  decode.d8.loss_dice: 1.2310
2023/05/24 12:29:14 - mmengine - INFO - Iter(train) [146750/160000]  lr: 1.0624e-06  eta: 1:35:45  time: 0.4273  data_time: 0.0098  memory: 4927  grad_norm: 94.7944  loss: 41.4066  decode.loss_cls: 1.2901  decode.loss_mask: 0.7829  decode.loss_dice: 1.7220  decode.d0.loss_cls: 3.1923  decode.d0.loss_mask: 0.8756  decode.d0.loss_dice: 2.0626  decode.d1.loss_cls: 1.4881  decode.d1.loss_mask: 0.8681  decode.d1.loss_dice: 1.9186  decode.d2.loss_cls: 1.3687  decode.d2.loss_mask: 0.8209  decode.d2.loss_dice: 1.8194  decode.d3.loss_cls: 1.3562  decode.d3.loss_mask: 0.7987  decode.d3.loss_dice: 1.7424  decode.d4.loss_cls: 1.4217  decode.d4.loss_mask: 0.7893  decode.d4.loss_dice: 1.7217  decode.d5.loss_cls: 1.3733  decode.d5.loss_mask: 0.7815  decode.d5.loss_dice: 1.7213  decode.d6.loss_cls: 1.3046  decode.d6.loss_mask: 0.7827  decode.d6.loss_dice: 1.7226  decode.d7.loss_cls: 1.3347  decode.d7.loss_mask: 0.7807  decode.d7.loss_dice: 1.7174  decode.d8.loss_cls: 1.3427  decode.d8.loss_mask: 0.7792  decode.d8.loss_dice: 1.7268
2023/05/24 12:29:36 - mmengine - INFO - Iter(train) [146800/160000]  lr: 1.0588e-06  eta: 1:35:23  time: 0.4306  data_time: 0.0107  memory: 4836  grad_norm: 80.5859  loss: 34.4121  decode.loss_cls: 1.1691  decode.loss_mask: 0.6962  decode.loss_dice: 1.2986  decode.d0.loss_cls: 3.1539  decode.d0.loss_mask: 0.8045  decode.d0.loss_dice: 1.5622  decode.d1.loss_cls: 1.3000  decode.d1.loss_mask: 0.7426  decode.d1.loss_dice: 1.4067  decode.d2.loss_cls: 1.1785  decode.d2.loss_mask: 0.7347  decode.d2.loss_dice: 1.3457  decode.d3.loss_cls: 1.1832  decode.d3.loss_mask: 0.6960  decode.d3.loss_dice: 1.3074  decode.d4.loss_cls: 1.1197  decode.d4.loss_mask: 0.7034  decode.d4.loss_dice: 1.3144  decode.d5.loss_cls: 1.1632  decode.d5.loss_mask: 0.7132  decode.d5.loss_dice: 1.3244  decode.d6.loss_cls: 1.1599  decode.d6.loss_mask: 0.7110  decode.d6.loss_dice: 1.2932  decode.d7.loss_cls: 1.1361  decode.d7.loss_mask: 0.7254  decode.d7.loss_dice: 1.3107  decode.d8.loss_cls: 1.1566  decode.d8.loss_mask: 0.6943  decode.d8.loss_dice: 1.3073
2023/05/24 12:29:58 - mmengine - INFO - Iter(train) [146850/160000]  lr: 1.0552e-06  eta: 1:35:01  time: 0.4321  data_time: 0.0098  memory: 4807  grad_norm: 97.1283  loss: 30.9811  decode.loss_cls: 1.0085  decode.loss_mask: 0.6193  decode.loss_dice: 1.1821  decode.d0.loss_cls: 2.7891  decode.d0.loss_mask: 0.6299  decode.d0.loss_dice: 1.4451  decode.d1.loss_cls: 1.1545  decode.d1.loss_mask: 0.6326  decode.d1.loss_dice: 1.2564  decode.d2.loss_cls: 1.1375  decode.d2.loss_mask: 0.6357  decode.d2.loss_dice: 1.2159  decode.d3.loss_cls: 1.1000  decode.d3.loss_mask: 0.6411  decode.d3.loss_dice: 1.1981  decode.d4.loss_cls: 1.0642  decode.d4.loss_mask: 0.6413  decode.d4.loss_dice: 1.2042  decode.d5.loss_cls: 1.0940  decode.d5.loss_mask: 0.6043  decode.d5.loss_dice: 1.1712  decode.d6.loss_cls: 1.0853  decode.d6.loss_mask: 0.6141  decode.d6.loss_dice: 1.1740  decode.d7.loss_cls: 1.0614  decode.d7.loss_mask: 0.6122  decode.d7.loss_dice: 1.1600  decode.d8.loss_cls: 1.0411  decode.d8.loss_mask: 0.6161  decode.d8.loss_dice: 1.1919
2023/05/24 12:30:20 - mmengine - INFO - Iter(train) [146900/160000]  lr: 1.0516e-06  eta: 1:34:40  time: 0.4783  data_time: 0.0101  memory: 4858  grad_norm: 117.0400  loss: 27.6331  decode.loss_cls: 0.9619  decode.loss_mask: 0.6758  decode.loss_dice: 0.9025  decode.d0.loss_cls: 2.7464  decode.d0.loss_mask: 0.6935  decode.d0.loss_dice: 1.0797  decode.d1.loss_cls: 1.0544  decode.d1.loss_mask: 0.6794  decode.d1.loss_dice: 0.9820  decode.d2.loss_cls: 0.9809  decode.d2.loss_mask: 0.6710  decode.d2.loss_dice: 0.9712  decode.d3.loss_cls: 0.9429  decode.d3.loss_mask: 0.6623  decode.d3.loss_dice: 0.9599  decode.d4.loss_cls: 0.9607  decode.d4.loss_mask: 0.6831  decode.d4.loss_dice: 0.9256  decode.d5.loss_cls: 0.9311  decode.d5.loss_mask: 0.6796  decode.d5.loss_dice: 0.9319  decode.d6.loss_cls: 0.9112  decode.d6.loss_mask: 0.6704  decode.d6.loss_dice: 0.9188  decode.d7.loss_cls: 0.9224  decode.d7.loss_mask: 0.6777  decode.d7.loss_dice: 0.9176  decode.d8.loss_cls: 0.9630  decode.d8.loss_mask: 0.6728  decode.d8.loss_dice: 0.9038
2023/05/24 12:30:44 - mmengine - INFO - Iter(train) [146950/160000]  lr: 1.0480e-06  eta: 1:34:18  time: 0.4735  data_time: 0.0098  memory: 4821  grad_norm: 87.1179  loss: 31.1296  decode.loss_cls: 1.0240  decode.loss_mask: 0.7970  decode.loss_dice: 1.0717  decode.d0.loss_cls: 2.6866  decode.d0.loss_mask: 0.8530  decode.d0.loss_dice: 1.2197  decode.d1.loss_cls: 1.1894  decode.d1.loss_mask: 0.8222  decode.d1.loss_dice: 1.0706  decode.d2.loss_cls: 1.1409  decode.d2.loss_mask: 0.7990  decode.d2.loss_dice: 1.0286  decode.d3.loss_cls: 1.0671  decode.d3.loss_mask: 0.8152  decode.d3.loss_dice: 1.0603  decode.d4.loss_cls: 1.0448  decode.d4.loss_mask: 0.7984  decode.d4.loss_dice: 1.0881  decode.d5.loss_cls: 1.0440  decode.d5.loss_mask: 0.8162  decode.d5.loss_dice: 1.0985  decode.d6.loss_cls: 1.0014  decode.d6.loss_mask: 0.7869  decode.d6.loss_dice: 1.0657  decode.d7.loss_cls: 0.9944  decode.d7.loss_mask: 0.7883  decode.d7.loss_dice: 1.0780  decode.d8.loss_cls: 1.0205  decode.d8.loss_mask: 0.7933  decode.d8.loss_dice: 1.0657
2023/05/24 12:31:08 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 12:31:08 - mmengine - INFO - Iter(train) [147000/160000]  lr: 1.0443e-06  eta: 1:33:57  time: 0.4758  data_time: 0.0098  memory: 4866  grad_norm: 129.8951  loss: 33.2470  decode.loss_cls: 1.0493  decode.loss_mask: 0.8665  decode.loss_dice: 1.0916  decode.d0.loss_cls: 3.0343  decode.d0.loss_mask: 0.9690  decode.d0.loss_dice: 1.3075  decode.d1.loss_cls: 1.2070  decode.d1.loss_mask: 0.9257  decode.d1.loss_dice: 1.1669  decode.d2.loss_cls: 1.0455  decode.d2.loss_mask: 0.8974  decode.d2.loss_dice: 1.1305  decode.d3.loss_cls: 1.1624  decode.d3.loss_mask: 0.8523  decode.d3.loss_dice: 1.1118  decode.d4.loss_cls: 1.1661  decode.d4.loss_mask: 0.8477  decode.d4.loss_dice: 1.0958  decode.d5.loss_cls: 1.2044  decode.d5.loss_mask: 0.8464  decode.d5.loss_dice: 1.0933  decode.d6.loss_cls: 1.1197  decode.d6.loss_mask: 0.8559  decode.d6.loss_dice: 1.1022  decode.d7.loss_cls: 1.1528  decode.d7.loss_mask: 0.8391  decode.d7.loss_dice: 1.0759  decode.d8.loss_cls: 1.1307  decode.d8.loss_mask: 0.8332  decode.d8.loss_dice: 1.0661
2023/05/24 12:31:08 - mmengine - INFO - Saving checkpoint at 147000 iterations
2023/05/24 12:31:36 - mmengine - INFO - Iter(train) [147050/160000]  lr: 1.0407e-06  eta: 1:33:36  time: 0.4232  data_time: 0.0099  memory: 4788  grad_norm: 94.4634  loss: 31.8129  decode.loss_cls: 1.0069  decode.loss_mask: 0.6929  decode.loss_dice: 1.0960  decode.d0.loss_cls: 3.2587  decode.d0.loss_mask: 0.7487  decode.d0.loss_dice: 1.3253  decode.d1.loss_cls: 1.2833  decode.d1.loss_mask: 0.7223  decode.d1.loss_dice: 1.2537  decode.d2.loss_cls: 1.1537  decode.d2.loss_mask: 0.7381  decode.d2.loss_dice: 1.2236  decode.d3.loss_cls: 1.0336  decode.d3.loss_mask: 0.7747  decode.d3.loss_dice: 1.1341  decode.d4.loss_cls: 1.0400  decode.d4.loss_mask: 0.7514  decode.d4.loss_dice: 1.1554  decode.d5.loss_cls: 1.0577  decode.d5.loss_mask: 0.7243  decode.d5.loss_dice: 1.1475  decode.d6.loss_cls: 0.9882  decode.d6.loss_mask: 0.7276  decode.d6.loss_dice: 1.1155  decode.d7.loss_cls: 1.0124  decode.d7.loss_mask: 0.7097  decode.d7.loss_dice: 1.0873  decode.d8.loss_cls: 0.9891  decode.d8.loss_mask: 0.7095  decode.d8.loss_dice: 1.1517
2023/05/24 12:31:57 - mmengine - INFO - Iter(train) [147100/160000]  lr: 1.0371e-06  eta: 1:33:14  time: 0.4278  data_time: 0.0100  memory: 4877  grad_norm: 99.9485  loss: 38.1649  decode.loss_cls: 1.1450  decode.loss_mask: 0.8148  decode.loss_dice: 1.5174  decode.d0.loss_cls: 3.0043  decode.d0.loss_mask: 0.8935  decode.d0.loss_dice: 1.7590  decode.d1.loss_cls: 1.2688  decode.d1.loss_mask: 0.9208  decode.d1.loss_dice: 1.7091  decode.d2.loss_cls: 1.2186  decode.d2.loss_mask: 0.8453  decode.d2.loss_dice: 1.6582  decode.d3.loss_cls: 1.1776  decode.d3.loss_mask: 0.8573  decode.d3.loss_dice: 1.5989  decode.d4.loss_cls: 1.1950  decode.d4.loss_mask: 0.8364  decode.d4.loss_dice: 1.6036  decode.d5.loss_cls: 1.1470  decode.d5.loss_mask: 0.8205  decode.d5.loss_dice: 1.5834  decode.d6.loss_cls: 1.1703  decode.d6.loss_mask: 0.8090  decode.d6.loss_dice: 1.5463  decode.d7.loss_cls: 1.1546  decode.d7.loss_mask: 0.8304  decode.d7.loss_dice: 1.5670  decode.d8.loss_cls: 1.1641  decode.d8.loss_mask: 0.8145  decode.d8.loss_dice: 1.5343
2023/05/24 12:32:19 - mmengine - INFO - Iter(train) [147150/160000]  lr: 1.0335e-06  eta: 1:32:52  time: 0.4281  data_time: 0.0102  memory: 4877  grad_norm: 89.6654  loss: 26.0509  decode.loss_cls: 0.9706  decode.loss_mask: 0.5774  decode.loss_dice: 0.7901  decode.d0.loss_cls: 2.7651  decode.d0.loss_mask: 0.7656  decode.d0.loss_dice: 0.9521  decode.d1.loss_cls: 1.0064  decode.d1.loss_mask: 0.6495  decode.d1.loss_dice: 0.8890  decode.d2.loss_cls: 1.0226  decode.d2.loss_mask: 0.6145  decode.d2.loss_dice: 0.8235  decode.d3.loss_cls: 0.9608  decode.d3.loss_mask: 0.6101  decode.d3.loss_dice: 0.7998  decode.d4.loss_cls: 1.0242  decode.d4.loss_mask: 0.5977  decode.d4.loss_dice: 0.7840  decode.d5.loss_cls: 1.0179  decode.d5.loss_mask: 0.5918  decode.d5.loss_dice: 0.7640  decode.d6.loss_cls: 1.0409  decode.d6.loss_mask: 0.5797  decode.d6.loss_dice: 0.7672  decode.d7.loss_cls: 0.9658  decode.d7.loss_mask: 0.5927  decode.d7.loss_dice: 0.7853  decode.d8.loss_cls: 0.9581  decode.d8.loss_mask: 0.5953  decode.d8.loss_dice: 0.7891
2023/05/24 12:32:41 - mmengine - INFO - Iter(train) [147200/160000]  lr: 1.0299e-06  eta: 1:32:31  time: 0.4317  data_time: 0.0105  memory: 4886  grad_norm: 98.0136  loss: 35.8912  decode.loss_cls: 1.1244  decode.loss_mask: 0.8506  decode.loss_dice: 1.3914  decode.d0.loss_cls: 2.7645  decode.d0.loss_mask: 0.8935  decode.d0.loss_dice: 1.6554  decode.d1.loss_cls: 1.2113  decode.d1.loss_mask: 0.8383  decode.d1.loss_dice: 1.5121  decode.d2.loss_cls: 1.1824  decode.d2.loss_mask: 0.8363  decode.d2.loss_dice: 1.4474  decode.d3.loss_cls: 1.1657  decode.d3.loss_mask: 0.8252  decode.d3.loss_dice: 1.3845  decode.d4.loss_cls: 1.1001  decode.d4.loss_mask: 0.8324  decode.d4.loss_dice: 1.4186  decode.d5.loss_cls: 1.1473  decode.d5.loss_mask: 0.8235  decode.d5.loss_dice: 1.4000  decode.d6.loss_cls: 1.1485  decode.d6.loss_mask: 0.8347  decode.d6.loss_dice: 1.4123  decode.d7.loss_cls: 1.1170  decode.d7.loss_mask: 0.8297  decode.d7.loss_dice: 1.3824  decode.d8.loss_cls: 1.1068  decode.d8.loss_mask: 0.8422  decode.d8.loss_dice: 1.4126
2023/05/24 12:33:02 - mmengine - INFO - Iter(train) [147250/160000]  lr: 1.0263e-06  eta: 1:32:09  time: 0.4312  data_time: 0.0108  memory: 4838  grad_norm: 93.1488  loss: 25.4584  decode.loss_cls: 0.8268  decode.loss_mask: 0.6912  decode.loss_dice: 0.7282  decode.d0.loss_cls: 2.8994  decode.d0.loss_mask: 0.7159  decode.d0.loss_dice: 0.8889  decode.d1.loss_cls: 1.0382  decode.d1.loss_mask: 0.7035  decode.d1.loss_dice: 0.8241  decode.d2.loss_cls: 0.9402  decode.d2.loss_mask: 0.6953  decode.d2.loss_dice: 0.7536  decode.d3.loss_cls: 0.8827  decode.d3.loss_mask: 0.6989  decode.d3.loss_dice: 0.7595  decode.d4.loss_cls: 0.8520  decode.d4.loss_mask: 0.6899  decode.d4.loss_dice: 0.7454  decode.d5.loss_cls: 0.8458  decode.d5.loss_mask: 0.6934  decode.d5.loss_dice: 0.7423  decode.d6.loss_cls: 0.8773  decode.d6.loss_mask: 0.6820  decode.d6.loss_dice: 0.7319  decode.d7.loss_cls: 0.8904  decode.d7.loss_mask: 0.6657  decode.d7.loss_dice: 0.7256  decode.d8.loss_cls: 0.8717  decode.d8.loss_mask: 0.6765  decode.d8.loss_dice: 0.7222
2023/05/24 12:33:25 - mmengine - INFO - Iter(train) [147300/160000]  lr: 1.0226e-06  eta: 1:31:47  time: 0.4572  data_time: 0.0106  memory: 4892  grad_norm: 96.4990  loss: 32.9906  decode.loss_cls: 1.0029  decode.loss_mask: 0.8857  decode.loss_dice: 1.1862  decode.d0.loss_cls: 2.8958  decode.d0.loss_mask: 0.9225  decode.d0.loss_dice: 1.4094  decode.d1.loss_cls: 1.0642  decode.d1.loss_mask: 0.9177  decode.d1.loss_dice: 1.3109  decode.d2.loss_cls: 1.0702  decode.d2.loss_mask: 0.9039  decode.d2.loss_dice: 1.2488  decode.d3.loss_cls: 0.9985  decode.d3.loss_mask: 0.8623  decode.d3.loss_dice: 1.1617  decode.d4.loss_cls: 0.9907  decode.d4.loss_mask: 0.8730  decode.d4.loss_dice: 1.1832  decode.d5.loss_cls: 1.0005  decode.d5.loss_mask: 0.8619  decode.d5.loss_dice: 1.2061  decode.d6.loss_cls: 0.9723  decode.d6.loss_mask: 0.8603  decode.d6.loss_dice: 1.1658  decode.d7.loss_cls: 0.9921  decode.d7.loss_mask: 0.8662  decode.d7.loss_dice: 1.1591  decode.d8.loss_cls: 1.0166  decode.d8.loss_mask: 0.8577  decode.d8.loss_dice: 1.1446
2023/05/24 12:33:46 - mmengine - INFO - Iter(train) [147350/160000]  lr: 1.0190e-06  eta: 1:31:26  time: 0.4476  data_time: 0.0097  memory: 4841  grad_norm: 85.0057  loss: 34.1383  decode.loss_cls: 1.1589  decode.loss_mask: 0.6425  decode.loss_dice: 1.2992  decode.d0.loss_cls: 2.9796  decode.d0.loss_mask: 0.7184  decode.d0.loss_dice: 1.5682  decode.d1.loss_cls: 1.4018  decode.d1.loss_mask: 0.6686  decode.d1.loss_dice: 1.4048  decode.d2.loss_cls: 1.3781  decode.d2.loss_mask: 0.6223  decode.d2.loss_dice: 1.3645  decode.d3.loss_cls: 1.2297  decode.d3.loss_mask: 0.6592  decode.d3.loss_dice: 1.3292  decode.d4.loss_cls: 1.2080  decode.d4.loss_mask: 0.6511  decode.d4.loss_dice: 1.3052  decode.d5.loss_cls: 1.2342  decode.d5.loss_mask: 0.6522  decode.d5.loss_dice: 1.3036  decode.d6.loss_cls: 1.1644  decode.d6.loss_mask: 0.6584  decode.d6.loss_dice: 1.3016  decode.d7.loss_cls: 1.1975  decode.d7.loss_mask: 0.6452  decode.d7.loss_dice: 1.2909  decode.d8.loss_cls: 1.1982  decode.d8.loss_mask: 0.6278  decode.d8.loss_dice: 1.2748
2023/05/24 12:34:08 - mmengine - INFO - Iter(train) [147400/160000]  lr: 1.0154e-06  eta: 1:31:04  time: 0.4235  data_time: 0.0098  memory: 4821  grad_norm: 93.0189  loss: 39.6084  decode.loss_cls: 1.2890  decode.loss_mask: 0.8681  decode.loss_dice: 1.5008  decode.d0.loss_cls: 3.2277  decode.d0.loss_mask: 1.0143  decode.d0.loss_dice: 1.7554  decode.d1.loss_cls: 1.3302  decode.d1.loss_mask: 0.9398  decode.d1.loss_dice: 1.6068  decode.d2.loss_cls: 1.3153  decode.d2.loss_mask: 0.9352  decode.d2.loss_dice: 1.5794  decode.d3.loss_cls: 1.3647  decode.d3.loss_mask: 0.8933  decode.d3.loss_dice: 1.5444  decode.d4.loss_cls: 1.2946  decode.d4.loss_mask: 0.9043  decode.d4.loss_dice: 1.5394  decode.d5.loss_cls: 1.2533  decode.d5.loss_mask: 0.9024  decode.d5.loss_dice: 1.5259  decode.d6.loss_cls: 1.2728  decode.d6.loss_mask: 0.9051  decode.d6.loss_dice: 1.5288  decode.d7.loss_cls: 1.2289  decode.d7.loss_mask: 0.9015  decode.d7.loss_dice: 1.5367  decode.d8.loss_cls: 1.2315  decode.d8.loss_mask: 0.8893  decode.d8.loss_dice: 1.5296
2023/05/24 12:34:29 - mmengine - INFO - Iter(train) [147450/160000]  lr: 1.0118e-06  eta: 1:30:42  time: 0.4252  data_time: 0.0106  memory: 4868  grad_norm: 91.8169  loss: 33.2335  decode.loss_cls: 1.0338  decode.loss_mask: 0.6958  decode.loss_dice: 1.2326  decode.d0.loss_cls: 3.2220  decode.d0.loss_mask: 0.7514  decode.d0.loss_dice: 1.5409  decode.d1.loss_cls: 1.2162  decode.d1.loss_mask: 0.7691  decode.d1.loss_dice: 1.3808  decode.d2.loss_cls: 1.1665  decode.d2.loss_mask: 0.7262  decode.d2.loss_dice: 1.3196  decode.d3.loss_cls: 1.1607  decode.d3.loss_mask: 0.6876  decode.d3.loss_dice: 1.2829  decode.d4.loss_cls: 1.1009  decode.d4.loss_mask: 0.6836  decode.d4.loss_dice: 1.2730  decode.d5.loss_cls: 1.0162  decode.d5.loss_mask: 0.6998  decode.d5.loss_dice: 1.2829  decode.d6.loss_cls: 1.0574  decode.d6.loss_mask: 0.6854  decode.d6.loss_dice: 1.2622  decode.d7.loss_cls: 1.0298  decode.d7.loss_mask: 0.7149  decode.d7.loss_dice: 1.2644  decode.d8.loss_cls: 1.0390  decode.d8.loss_mask: 0.7050  decode.d8.loss_dice: 1.2330
2023/05/24 12:34:50 - mmengine - INFO - Iter(train) [147500/160000]  lr: 1.0081e-06  eta: 1:30:20  time: 0.4194  data_time: 0.0101  memory: 4857  grad_norm: 99.9658  loss: 45.5994  decode.loss_cls: 1.6746  decode.loss_mask: 0.8747  decode.loss_dice: 1.7289  decode.d0.loss_cls: 3.4804  decode.d0.loss_mask: 0.9099  decode.d0.loss_dice: 2.1007  decode.d1.loss_cls: 1.7630  decode.d1.loss_mask: 0.9790  decode.d1.loss_dice: 1.8877  decode.d2.loss_cls: 1.7061  decode.d2.loss_mask: 0.9403  decode.d2.loss_dice: 1.8323  decode.d3.loss_cls: 1.6798  decode.d3.loss_mask: 0.9091  decode.d3.loss_dice: 1.8125  decode.d4.loss_cls: 1.6690  decode.d4.loss_mask: 0.8899  decode.d4.loss_dice: 1.7755  decode.d5.loss_cls: 1.6615  decode.d5.loss_mask: 0.8833  decode.d5.loss_dice: 1.7813  decode.d6.loss_cls: 1.6305  decode.d6.loss_mask: 0.8540  decode.d6.loss_dice: 1.7229  decode.d7.loss_cls: 1.6137  decode.d7.loss_mask: 0.8575  decode.d7.loss_dice: 1.7440  decode.d8.loss_cls: 1.6568  decode.d8.loss_mask: 0.8647  decode.d8.loss_dice: 1.7156
2023/05/24 12:35:13 - mmengine - INFO - Iter(train) [147550/160000]  lr: 1.0045e-06  eta: 1:29:59  time: 0.4626  data_time: 0.0100  memory: 4799  grad_norm: 84.2570  loss: 35.0228  decode.loss_cls: 1.2579  decode.loss_mask: 0.6333  decode.loss_dice: 1.2833  decode.d0.loss_cls: 3.2510  decode.d0.loss_mask: 0.7064  decode.d0.loss_dice: 1.5794  decode.d1.loss_cls: 1.3708  decode.d1.loss_mask: 0.7098  decode.d1.loss_dice: 1.4495  decode.d2.loss_cls: 1.1961  decode.d2.loss_mask: 0.7130  decode.d2.loss_dice: 1.4354  decode.d3.loss_cls: 1.2422  decode.d3.loss_mask: 0.6667  decode.d3.loss_dice: 1.3513  decode.d4.loss_cls: 1.2632  decode.d4.loss_mask: 0.6673  decode.d4.loss_dice: 1.3202  decode.d5.loss_cls: 1.2938  decode.d5.loss_mask: 0.6501  decode.d5.loss_dice: 1.3267  decode.d6.loss_cls: 1.3057  decode.d6.loss_mask: 0.6263  decode.d6.loss_dice: 1.2804  decode.d7.loss_cls: 1.2951  decode.d7.loss_mask: 0.6338  decode.d7.loss_dice: 1.2813  decode.d8.loss_cls: 1.3009  decode.d8.loss_mask: 0.6320  decode.d8.loss_dice: 1.3000
2023/05/24 12:35:34 - mmengine - INFO - Iter(train) [147600/160000]  lr: 1.0009e-06  eta: 1:29:37  time: 0.4269  data_time: 0.0102  memory: 4864  grad_norm: 100.2951  loss: 37.9126  decode.loss_cls: 1.2020  decode.loss_mask: 0.8187  decode.loss_dice: 1.4853  decode.d0.loss_cls: 3.2205  decode.d0.loss_mask: 0.8303  decode.d0.loss_dice: 1.6179  decode.d1.loss_cls: 1.5175  decode.d1.loss_mask: 0.8197  decode.d1.loss_dice: 1.5003  decode.d2.loss_cls: 1.3547  decode.d2.loss_mask: 0.7922  decode.d2.loss_dice: 1.4800  decode.d3.loss_cls: 1.2889  decode.d3.loss_mask: 0.8198  decode.d3.loss_dice: 1.4666  decode.d4.loss_cls: 1.3117  decode.d4.loss_mask: 0.7879  decode.d4.loss_dice: 1.4717  decode.d5.loss_cls: 1.2607  decode.d5.loss_mask: 0.8122  decode.d5.loss_dice: 1.4547  decode.d6.loss_cls: 1.2403  decode.d6.loss_mask: 0.8050  decode.d6.loss_dice: 1.4731  decode.d7.loss_cls: 1.2530  decode.d7.loss_mask: 0.8150  decode.d7.loss_dice: 1.4877  decode.d8.loss_cls: 1.2156  decode.d8.loss_mask: 0.8134  decode.d8.loss_dice: 1.4960
2023/05/24 12:35:56 - mmengine - INFO - Iter(train) [147650/160000]  lr: 9.9723e-07  eta: 1:29:15  time: 0.4751  data_time: 0.0102  memory: 4824  grad_norm: 92.5609  loss: 27.8030  decode.loss_cls: 0.8615  decode.loss_mask: 0.6075  decode.loss_dice: 0.9779  decode.d0.loss_cls: 2.9339  decode.d0.loss_mask: 0.7738  decode.d0.loss_dice: 1.1959  decode.d1.loss_cls: 1.1046  decode.d1.loss_mask: 0.6720  decode.d1.loss_dice: 1.0998  decode.d2.loss_cls: 1.0156  decode.d2.loss_mask: 0.6103  decode.d2.loss_dice: 1.0286  decode.d3.loss_cls: 0.9066  decode.d3.loss_mask: 0.6619  decode.d3.loss_dice: 0.9934  decode.d4.loss_cls: 0.8393  decode.d4.loss_mask: 0.6392  decode.d4.loss_dice: 1.0196  decode.d5.loss_cls: 0.8551  decode.d5.loss_mask: 0.6380  decode.d5.loss_dice: 0.9908  decode.d6.loss_cls: 0.8633  decode.d6.loss_mask: 0.6405  decode.d6.loss_dice: 0.9794  decode.d7.loss_cls: 0.8625  decode.d7.loss_mask: 0.6310  decode.d7.loss_dice: 0.9568  decode.d8.loss_cls: 0.8488  decode.d8.loss_mask: 0.6057  decode.d8.loss_dice: 0.9898
2023/05/24 12:36:18 - mmengine - INFO - Iter(train) [147700/160000]  lr: 9.9359e-07  eta: 1:28:54  time: 0.4236  data_time: 0.0100  memory: 4795  grad_norm: 89.6396  loss: 37.2114  decode.loss_cls: 1.2326  decode.loss_mask: 0.7738  decode.loss_dice: 1.3899  decode.d0.loss_cls: 3.3206  decode.d0.loss_mask: 0.9153  decode.d0.loss_dice: 1.6267  decode.d1.loss_cls: 1.4510  decode.d1.loss_mask: 0.8205  decode.d1.loss_dice: 1.4813  decode.d2.loss_cls: 1.3191  decode.d2.loss_mask: 0.8091  decode.d2.loss_dice: 1.4048  decode.d3.loss_cls: 1.3266  decode.d3.loss_mask: 0.7790  decode.d3.loss_dice: 1.3826  decode.d4.loss_cls: 1.2800  decode.d4.loss_mask: 0.7874  decode.d4.loss_dice: 1.4180  decode.d5.loss_cls: 1.2733  decode.d5.loss_mask: 0.7904  decode.d5.loss_dice: 1.3985  decode.d6.loss_cls: 1.3115  decode.d6.loss_mask: 0.7656  decode.d6.loss_dice: 1.3447  decode.d7.loss_cls: 1.2782  decode.d7.loss_mask: 0.7678  decode.d7.loss_dice: 1.3453  decode.d8.loss_cls: 1.2511  decode.d8.loss_mask: 0.7836  decode.d8.loss_dice: 1.3832
2023/05/24 12:36:40 - mmengine - INFO - Iter(train) [147750/160000]  lr: 9.8996e-07  eta: 1:28:32  time: 0.4216  data_time: 0.0101  memory: 4829  grad_norm: 96.9617  loss: 41.8521  decode.loss_cls: 1.3868  decode.loss_mask: 0.7935  decode.loss_dice: 1.6750  decode.d0.loss_cls: 3.4200  decode.d0.loss_mask: 0.8229  decode.d0.loss_dice: 2.0428  decode.d1.loss_cls: 1.4102  decode.d1.loss_mask: 0.9227  decode.d1.loss_dice: 1.8995  decode.d2.loss_cls: 1.4134  decode.d2.loss_mask: 0.8848  decode.d2.loss_dice: 1.8567  decode.d3.loss_cls: 1.3966  decode.d3.loss_mask: 0.8253  decode.d3.loss_dice: 1.7653  decode.d4.loss_cls: 1.3885  decode.d4.loss_mask: 0.7949  decode.d4.loss_dice: 1.7804  decode.d5.loss_cls: 1.3483  decode.d5.loss_mask: 0.7910  decode.d5.loss_dice: 1.7131  decode.d6.loss_cls: 1.3752  decode.d6.loss_mask: 0.7871  decode.d6.loss_dice: 1.6797  decode.d7.loss_cls: 1.3438  decode.d7.loss_mask: 0.8032  decode.d7.loss_dice: 1.7000  decode.d8.loss_cls: 1.3922  decode.d8.loss_mask: 0.7723  decode.d8.loss_dice: 1.6671
2023/05/24 12:37:01 - mmengine - INFO - Iter(train) [147800/160000]  lr: 9.8632e-07  eta: 1:28:10  time: 0.4196  data_time: 0.0101  memory: 4886  grad_norm: 156.6391  loss: 33.4627  decode.loss_cls: 1.0921  decode.loss_mask: 0.8169  decode.loss_dice: 1.1150  decode.d0.loss_cls: 3.2658  decode.d0.loss_mask: 0.8111  decode.d0.loss_dice: 1.2797  decode.d1.loss_cls: 1.1214  decode.d1.loss_mask: 0.9059  decode.d1.loss_dice: 1.2656  decode.d2.loss_cls: 1.1931  decode.d2.loss_mask: 0.8888  decode.d2.loss_dice: 1.2114  decode.d3.loss_cls: 1.1453  decode.d3.loss_mask: 0.8147  decode.d3.loss_dice: 1.1807  decode.d4.loss_cls: 1.1133  decode.d4.loss_mask: 0.8025  decode.d4.loss_dice: 1.1499  decode.d5.loss_cls: 1.1364  decode.d5.loss_mask: 0.8022  decode.d5.loss_dice: 1.1690  decode.d6.loss_cls: 1.1484  decode.d6.loss_mask: 0.7912  decode.d6.loss_dice: 1.1322  decode.d7.loss_cls: 1.1412  decode.d7.loss_mask: 0.7884  decode.d7.loss_dice: 1.1317  decode.d8.loss_cls: 1.1202  decode.d8.loss_mask: 0.7983  decode.d8.loss_dice: 1.1304
2023/05/24 12:37:23 - mmengine - INFO - Iter(train) [147850/160000]  lr: 9.8268e-07  eta: 1:27:49  time: 0.4296  data_time: 0.0104  memory: 4888  grad_norm: 97.0253  loss: 26.1165  decode.loss_cls: 0.9249  decode.loss_mask: 0.5621  decode.loss_dice: 0.9590  decode.d0.loss_cls: 2.7098  decode.d0.loss_mask: 0.5244  decode.d0.loss_dice: 1.0557  decode.d1.loss_cls: 1.0061  decode.d1.loss_mask: 0.5397  decode.d1.loss_dice: 0.9990  decode.d2.loss_cls: 0.9448  decode.d2.loss_mask: 0.5047  decode.d2.loss_dice: 0.9672  decode.d3.loss_cls: 0.9298  decode.d3.loss_mask: 0.4949  decode.d3.loss_dice: 0.9620  decode.d4.loss_cls: 0.9085  decode.d4.loss_mask: 0.4891  decode.d4.loss_dice: 1.0031  decode.d5.loss_cls: 0.9742  decode.d5.loss_mask: 0.4784  decode.d5.loss_dice: 0.9404  decode.d6.loss_cls: 0.9634  decode.d6.loss_mask: 0.5444  decode.d6.loss_dice: 0.9295  decode.d7.loss_cls: 0.8945  decode.d7.loss_mask: 0.5482  decode.d7.loss_dice: 0.9441  decode.d8.loss_cls: 0.9224  decode.d8.loss_mask: 0.5484  decode.d8.loss_dice: 0.9437
2023/05/24 12:37:44 - mmengine - INFO - Iter(train) [147900/160000]  lr: 9.7904e-07  eta: 1:27:27  time: 0.4249  data_time: 0.0099  memory: 4815  grad_norm: 100.7700  loss: 32.1293  decode.loss_cls: 1.1024  decode.loss_mask: 0.6972  decode.loss_dice: 1.0713  decode.d0.loss_cls: 3.2028  decode.d0.loss_mask: 0.7563  decode.d0.loss_dice: 1.3526  decode.d1.loss_cls: 1.2741  decode.d1.loss_mask: 0.7309  decode.d1.loss_dice: 1.2222  decode.d2.loss_cls: 1.1972  decode.d2.loss_mask: 0.7544  decode.d2.loss_dice: 1.1790  decode.d3.loss_cls: 1.1457  decode.d3.loss_mask: 0.7323  decode.d3.loss_dice: 1.1241  decode.d4.loss_cls: 1.1158  decode.d4.loss_mask: 0.7212  decode.d4.loss_dice: 1.1055  decode.d5.loss_cls: 1.1378  decode.d5.loss_mask: 0.7094  decode.d5.loss_dice: 1.1056  decode.d6.loss_cls: 1.1205  decode.d6.loss_mask: 0.6913  decode.d6.loss_dice: 1.0846  decode.d7.loss_cls: 1.1172  decode.d7.loss_mask: 0.6935  decode.d7.loss_dice: 1.0898  decode.d8.loss_cls: 1.0906  decode.d8.loss_mask: 0.7019  decode.d8.loss_dice: 1.1020
2023/05/24 12:38:05 - mmengine - INFO - Iter(train) [147950/160000]  lr: 9.7540e-07  eta: 1:27:05  time: 0.4283  data_time: 0.0101  memory: 4876  grad_norm: 89.2432  loss: 27.8135  decode.loss_cls: 0.8555  decode.loss_mask: 0.6147  decode.loss_dice: 1.0480  decode.d0.loss_cls: 2.8094  decode.d0.loss_mask: 0.7099  decode.d0.loss_dice: 1.2353  decode.d1.loss_cls: 0.8367  decode.d1.loss_mask: 0.6928  decode.d1.loss_dice: 1.1756  decode.d2.loss_cls: 0.7919  decode.d2.loss_mask: 0.6843  decode.d2.loss_dice: 1.1576  decode.d3.loss_cls: 0.8446  decode.d3.loss_mask: 0.6442  decode.d3.loss_dice: 1.1039  decode.d4.loss_cls: 0.8187  decode.d4.loss_mask: 0.6561  decode.d4.loss_dice: 1.1002  decode.d5.loss_cls: 0.8530  decode.d5.loss_mask: 0.6177  decode.d5.loss_dice: 1.0604  decode.d6.loss_cls: 0.8427  decode.d6.loss_mask: 0.6045  decode.d6.loss_dice: 1.0525  decode.d7.loss_cls: 0.8616  decode.d7.loss_mask: 0.6041  decode.d7.loss_dice: 1.0207  decode.d8.loss_cls: 0.8704  decode.d8.loss_mask: 0.6092  decode.d8.loss_dice: 1.0374
2023/05/24 12:38:27 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 12:38:27 - mmengine - INFO - Iter(train) [148000/160000]  lr: 9.7176e-07  eta: 1:26:44  time: 0.4199  data_time: 0.0103  memory: 4835  grad_norm: 92.3398  loss: 38.7527  decode.loss_cls: 1.3025  decode.loss_mask: 0.8468  decode.loss_dice: 1.3927  decode.d0.loss_cls: 3.2625  decode.d0.loss_mask: 0.9289  decode.d0.loss_dice: 1.6925  decode.d1.loss_cls: 1.4978  decode.d1.loss_mask: 0.9103  decode.d1.loss_dice: 1.5344  decode.d2.loss_cls: 1.4058  decode.d2.loss_mask: 0.8449  decode.d2.loss_dice: 1.4746  decode.d3.loss_cls: 1.3468  decode.d3.loss_mask: 0.8073  decode.d3.loss_dice: 1.4151  decode.d4.loss_cls: 1.3337  decode.d4.loss_mask: 0.8314  decode.d4.loss_dice: 1.4535  decode.d5.loss_cls: 1.3159  decode.d5.loss_mask: 0.8383  decode.d5.loss_dice: 1.4741  decode.d6.loss_cls: 1.3461  decode.d6.loss_mask: 0.8572  decode.d6.loss_dice: 1.4092  decode.d7.loss_cls: 1.3429  decode.d7.loss_mask: 0.8635  decode.d7.loss_dice: 1.4314  decode.d8.loss_cls: 1.3138  decode.d8.loss_mask: 0.8615  decode.d8.loss_dice: 1.4171
2023/05/24 12:38:27 - mmengine - INFO - Saving checkpoint at 148000 iterations
2023/05/24 12:38:55 - mmengine - INFO - Iter(train) [148050/160000]  lr: 9.6811e-07  eta: 1:26:22  time: 0.4224  data_time: 0.0101  memory: 4835  grad_norm: 100.8991  loss: 40.2002  decode.loss_cls: 1.4600  decode.loss_mask: 0.7431  decode.loss_dice: 1.4286  decode.d0.loss_cls: 3.5508  decode.d0.loss_mask: 0.8167  decode.d0.loss_dice: 1.7352  decode.d1.loss_cls: 1.7190  decode.d1.loss_mask: 0.7715  decode.d1.loss_dice: 1.6211  decode.d2.loss_cls: 1.6114  decode.d2.loss_mask: 0.7453  decode.d2.loss_dice: 1.5202  decode.d3.loss_cls: 1.5548  decode.d3.loss_mask: 0.7534  decode.d3.loss_dice: 1.4925  decode.d4.loss_cls: 1.5452  decode.d4.loss_mask: 0.7402  decode.d4.loss_dice: 1.4748  decode.d5.loss_cls: 1.5422  decode.d5.loss_mask: 0.7472  decode.d5.loss_dice: 1.4655  decode.d6.loss_cls: 1.5001  decode.d6.loss_mask: 0.7547  decode.d6.loss_dice: 1.4508  decode.d7.loss_cls: 1.4946  decode.d7.loss_mask: 0.7434  decode.d7.loss_dice: 1.4728  decode.d8.loss_cls: 1.5165  decode.d8.loss_mask: 0.7589  decode.d8.loss_dice: 1.4697
2023/05/24 12:39:16 - mmengine - INFO - Iter(train) [148100/160000]  lr: 9.6447e-07  eta: 1:26:01  time: 0.4233  data_time: 0.0103  memory: 4852  grad_norm: 91.2884  loss: 30.4707  decode.loss_cls: 0.9517  decode.loss_mask: 0.7580  decode.loss_dice: 1.1239  decode.d0.loss_cls: 2.6121  decode.d0.loss_mask: 0.7510  decode.d0.loss_dice: 1.2011  decode.d1.loss_cls: 1.1077  decode.d1.loss_mask: 0.7977  decode.d1.loss_dice: 1.1829  decode.d2.loss_cls: 0.9636  decode.d2.loss_mask: 0.7542  decode.d2.loss_dice: 1.1477  decode.d3.loss_cls: 0.9988  decode.d3.loss_mask: 0.7319  decode.d3.loss_dice: 1.0951  decode.d4.loss_cls: 1.0084  decode.d4.loss_mask: 0.7357  decode.d4.loss_dice: 1.1102  decode.d5.loss_cls: 1.0294  decode.d5.loss_mask: 0.7498  decode.d5.loss_dice: 1.1060  decode.d6.loss_cls: 0.9878  decode.d6.loss_mask: 0.7439  decode.d6.loss_dice: 1.1238  decode.d7.loss_cls: 1.0025  decode.d7.loss_mask: 0.7354  decode.d7.loss_dice: 1.1166  decode.d8.loss_cls: 0.9782  decode.d8.loss_mask: 0.7330  decode.d8.loss_dice: 1.1326
2023/05/24 12:39:38 - mmengine - INFO - Iter(train) [148150/160000]  lr: 9.6082e-07  eta: 1:25:39  time: 0.4221  data_time: 0.0099  memory: 4857  grad_norm: 100.9010  loss: 29.2757  decode.loss_cls: 0.9579  decode.loss_mask: 0.7439  decode.loss_dice: 0.9767  decode.d0.loss_cls: 2.7822  decode.d0.loss_mask: 0.8079  decode.d0.loss_dice: 1.1166  decode.d1.loss_cls: 1.0494  decode.d1.loss_mask: 0.8213  decode.d1.loss_dice: 1.0373  decode.d2.loss_cls: 1.0467  decode.d2.loss_mask: 0.7658  decode.d2.loss_dice: 0.9882  decode.d3.loss_cls: 0.9860  decode.d3.loss_mask: 0.7492  decode.d3.loss_dice: 0.9838  decode.d4.loss_cls: 0.9532  decode.d4.loss_mask: 0.7478  decode.d4.loss_dice: 1.0192  decode.d5.loss_cls: 0.9587  decode.d5.loss_mask: 0.7565  decode.d5.loss_dice: 1.0084  decode.d6.loss_cls: 0.9642  decode.d6.loss_mask: 0.7496  decode.d6.loss_dice: 0.9711  decode.d7.loss_cls: 0.9632  decode.d7.loss_mask: 0.7281  decode.d7.loss_dice: 0.9859  decode.d8.loss_cls: 0.9518  decode.d8.loss_mask: 0.7289  decode.d8.loss_dice: 0.9760
2023/05/24 12:40:01 - mmengine - INFO - Iter(train) [148200/160000]  lr: 9.5717e-07  eta: 1:25:17  time: 0.4243  data_time: 0.0101  memory: 4836  grad_norm: 108.7895  loss: 30.7362  decode.loss_cls: 0.9524  decode.loss_mask: 0.6281  decode.loss_dice: 1.2471  decode.d0.loss_cls: 2.7787  decode.d0.loss_mask: 0.7183  decode.d0.loss_dice: 1.4574  decode.d1.loss_cls: 1.0984  decode.d1.loss_mask: 0.6939  decode.d1.loss_dice: 1.3093  decode.d2.loss_cls: 0.9317  decode.d2.loss_mask: 0.6911  decode.d2.loss_dice: 1.2856  decode.d3.loss_cls: 0.9446  decode.d3.loss_mask: 0.6757  decode.d3.loss_dice: 1.2408  decode.d4.loss_cls: 0.9627  decode.d4.loss_mask: 0.6304  decode.d4.loss_dice: 1.2474  decode.d5.loss_cls: 0.9998  decode.d5.loss_mask: 0.6223  decode.d5.loss_dice: 1.2080  decode.d6.loss_cls: 0.9503  decode.d6.loss_mask: 0.6294  decode.d6.loss_dice: 1.2321  decode.d7.loss_cls: 0.9499  decode.d7.loss_mask: 0.6286  decode.d7.loss_dice: 1.2243  decode.d8.loss_cls: 0.9343  decode.d8.loss_mask: 0.6314  decode.d8.loss_dice: 1.2324
2023/05/24 12:40:24 - mmengine - INFO - Iter(train) [148250/160000]  lr: 9.5352e-07  eta: 1:24:56  time: 0.4240  data_time: 0.0102  memory: 4920  grad_norm: 108.3150  loss: 40.5356  decode.loss_cls: 1.1540  decode.loss_mask: 0.8877  decode.loss_dice: 1.6083  decode.d0.loss_cls: 3.2029  decode.d0.loss_mask: 0.9854  decode.d0.loss_dice: 1.9658  decode.d1.loss_cls: 1.3731  decode.d1.loss_mask: 0.9483  decode.d1.loss_dice: 1.8454  decode.d2.loss_cls: 1.3061  decode.d2.loss_mask: 0.9181  decode.d2.loss_dice: 1.7573  decode.d3.loss_cls: 1.2492  decode.d3.loss_mask: 0.9185  decode.d3.loss_dice: 1.7344  decode.d4.loss_cls: 1.2115  decode.d4.loss_mask: 0.9105  decode.d4.loss_dice: 1.7435  decode.d5.loss_cls: 1.1606  decode.d5.loss_mask: 0.8974  decode.d5.loss_dice: 1.6659  decode.d6.loss_cls: 1.1626  decode.d6.loss_mask: 0.8966  decode.d6.loss_dice: 1.6471  decode.d7.loss_cls: 1.1181  decode.d7.loss_mask: 0.9187  decode.d7.loss_dice: 1.6709  decode.d8.loss_cls: 1.1726  decode.d8.loss_mask: 0.8907  decode.d8.loss_dice: 1.6144
2023/05/24 12:40:47 - mmengine - INFO - Iter(train) [148300/160000]  lr: 9.4986e-07  eta: 1:24:34  time: 0.4753  data_time: 0.0099  memory: 4879  grad_norm: 96.2867  loss: 32.5194  decode.loss_cls: 1.1464  decode.loss_mask: 0.7176  decode.loss_dice: 1.1025  decode.d0.loss_cls: 3.1633  decode.d0.loss_mask: 0.7550  decode.d0.loss_dice: 1.2478  decode.d1.loss_cls: 1.2047  decode.d1.loss_mask: 0.7641  decode.d1.loss_dice: 1.1575  decode.d2.loss_cls: 1.2187  decode.d2.loss_mask: 0.7593  decode.d2.loss_dice: 1.1315  decode.d3.loss_cls: 1.2009  decode.d3.loss_mask: 0.7424  decode.d3.loss_dice: 1.1299  decode.d4.loss_cls: 1.1949  decode.d4.loss_mask: 0.7434  decode.d4.loss_dice: 1.1191  decode.d5.loss_cls: 1.1983  decode.d5.loss_mask: 0.7404  decode.d5.loss_dice: 1.1195  decode.d6.loss_cls: 1.1811  decode.d6.loss_mask: 0.7255  decode.d6.loss_dice: 1.1094  decode.d7.loss_cls: 1.1624  decode.d7.loss_mask: 0.7213  decode.d7.loss_dice: 1.0977  decode.d8.loss_cls: 1.1410  decode.d8.loss_mask: 0.7196  decode.d8.loss_dice: 1.1042
2023/05/24 12:41:09 - mmengine - INFO - Iter(train) [148350/160000]  lr: 9.4621e-07  eta: 1:24:13  time: 0.4264  data_time: 0.0099  memory: 4890  grad_norm: 90.6233  loss: 31.1025  decode.loss_cls: 1.1383  decode.loss_mask: 0.5994  decode.loss_dice: 1.0694  decode.d0.loss_cls: 2.9863  decode.d0.loss_mask: 0.6664  decode.d0.loss_dice: 1.3270  decode.d1.loss_cls: 1.2175  decode.d1.loss_mask: 0.6833  decode.d1.loss_dice: 1.2388  decode.d2.loss_cls: 1.1566  decode.d2.loss_mask: 0.6482  decode.d2.loss_dice: 1.1696  decode.d3.loss_cls: 1.1348  decode.d3.loss_mask: 0.6518  decode.d3.loss_dice: 1.1389  decode.d4.loss_cls: 1.1273  decode.d4.loss_mask: 0.6339  decode.d4.loss_dice: 1.1139  decode.d5.loss_cls: 1.1672  decode.d5.loss_mask: 0.6203  decode.d5.loss_dice: 1.0898  decode.d6.loss_cls: 1.1365  decode.d6.loss_mask: 0.6016  decode.d6.loss_dice: 1.0903  decode.d7.loss_cls: 1.1487  decode.d7.loss_mask: 0.5986  decode.d7.loss_dice: 1.0950  decode.d8.loss_cls: 1.1444  decode.d8.loss_mask: 0.6119  decode.d8.loss_dice: 1.0969
2023/05/24 12:41:30 - mmengine - INFO - Iter(train) [148400/160000]  lr: 9.4255e-07  eta: 1:23:51  time: 0.4267  data_time: 0.0097  memory: 4858  grad_norm: 85.7999  loss: 30.4928  decode.loss_cls: 1.1239  decode.loss_mask: 0.7065  decode.loss_dice: 0.9627  decode.d0.loss_cls: 2.9565  decode.d0.loss_mask: 0.7144  decode.d0.loss_dice: 1.1941  decode.d1.loss_cls: 1.1317  decode.d1.loss_mask: 0.7523  decode.d1.loss_dice: 1.1025  decode.d2.loss_cls: 1.1624  decode.d2.loss_mask: 0.7115  decode.d2.loss_dice: 1.0190  decode.d3.loss_cls: 1.1621  decode.d3.loss_mask: 0.6853  decode.d3.loss_dice: 0.9949  decode.d4.loss_cls: 1.1457  decode.d4.loss_mask: 0.6954  decode.d4.loss_dice: 0.9873  decode.d5.loss_cls: 1.1504  decode.d5.loss_mask: 0.7319  decode.d5.loss_dice: 0.9955  decode.d6.loss_cls: 1.1221  decode.d6.loss_mask: 0.7045  decode.d6.loss_dice: 0.9618  decode.d7.loss_cls: 1.1105  decode.d7.loss_mask: 0.7221  decode.d7.loss_dice: 0.9804  decode.d8.loss_cls: 1.1292  decode.d8.loss_mask: 0.7123  decode.d8.loss_dice: 0.9640
2023/05/24 12:41:52 - mmengine - INFO - Iter(train) [148450/160000]  lr: 9.3890e-07  eta: 1:23:29  time: 0.4269  data_time: 0.0107  memory: 4821  grad_norm: 212.9861  loss: 29.0338  decode.loss_cls: 1.1025  decode.loss_mask: 0.5967  decode.loss_dice: 0.9141  decode.d0.loss_cls: 2.9631  decode.d0.loss_mask: 0.6576  decode.d0.loss_dice: 1.1175  decode.d1.loss_cls: 1.2276  decode.d1.loss_mask: 0.7213  decode.d1.loss_dice: 1.0455  decode.d2.loss_cls: 1.1716  decode.d2.loss_mask: 0.6698  decode.d2.loss_dice: 0.9903  decode.d3.loss_cls: 1.0978  decode.d3.loss_mask: 0.6086  decode.d3.loss_dice: 0.9742  decode.d4.loss_cls: 1.0863  decode.d4.loss_mask: 0.6081  decode.d4.loss_dice: 0.9561  decode.d5.loss_cls: 1.0611  decode.d5.loss_mask: 0.6209  decode.d5.loss_dice: 0.9607  decode.d6.loss_cls: 1.0819  decode.d6.loss_mask: 0.6018  decode.d6.loss_dice: 0.9350  decode.d7.loss_cls: 1.0687  decode.d7.loss_mask: 0.6052  decode.d7.loss_dice: 0.9393  decode.d8.loss_cls: 1.1209  decode.d8.loss_mask: 0.6038  decode.d8.loss_dice: 0.9260
2023/05/24 12:42:13 - mmengine - INFO - Iter(train) [148500/160000]  lr: 9.3524e-07  eta: 1:23:07  time: 0.4239  data_time: 0.0103  memory: 4847  grad_norm: 94.2985  loss: 32.4824  decode.loss_cls: 1.0711  decode.loss_mask: 0.7811  decode.loss_dice: 1.0888  decode.d0.loss_cls: 2.8033  decode.d0.loss_mask: 0.8886  decode.d0.loss_dice: 1.3565  decode.d1.loss_cls: 1.2859  decode.d1.loss_mask: 0.8279  decode.d1.loss_dice: 1.1524  decode.d2.loss_cls: 1.2701  decode.d2.loss_mask: 0.8003  decode.d2.loss_dice: 1.1399  decode.d3.loss_cls: 1.1418  decode.d3.loss_mask: 0.8011  decode.d3.loss_dice: 1.1507  decode.d4.loss_cls: 1.1474  decode.d4.loss_mask: 0.7798  decode.d4.loss_dice: 1.1136  decode.d5.loss_cls: 1.1317  decode.d5.loss_mask: 0.7813  decode.d5.loss_dice: 1.1100  decode.d6.loss_cls: 1.1208  decode.d6.loss_mask: 0.7742  decode.d6.loss_dice: 1.0700  decode.d7.loss_cls: 1.1171  decode.d7.loss_mask: 0.7687  decode.d7.loss_dice: 1.0853  decode.d8.loss_cls: 1.0617  decode.d8.loss_mask: 0.7748  decode.d8.loss_dice: 1.0866
2023/05/24 12:42:34 - mmengine - INFO - Iter(train) [148550/160000]  lr: 9.3158e-07  eta: 1:22:46  time: 0.4224  data_time: 0.0106  memory: 4844  grad_norm: 99.7478  loss: 33.4272  decode.loss_cls: 1.1105  decode.loss_mask: 0.7124  decode.loss_dice: 1.1992  decode.d0.loss_cls: 3.0893  decode.d0.loss_mask: 0.7952  decode.d0.loss_dice: 1.4443  decode.d1.loss_cls: 1.1513  decode.d1.loss_mask: 0.7973  decode.d1.loss_dice: 1.3546  decode.d2.loss_cls: 1.2320  decode.d2.loss_mask: 0.7677  decode.d2.loss_dice: 1.2586  decode.d3.loss_cls: 1.2880  decode.d3.loss_mask: 0.6848  decode.d3.loss_dice: 1.2011  decode.d4.loss_cls: 1.1878  decode.d4.loss_mask: 0.7302  decode.d4.loss_dice: 1.2147  decode.d5.loss_cls: 1.2048  decode.d5.loss_mask: 0.6943  decode.d5.loss_dice: 1.1929  decode.d6.loss_cls: 1.1670  decode.d6.loss_mask: 0.7050  decode.d6.loss_dice: 1.1816  decode.d7.loss_cls: 1.1243  decode.d7.loss_mask: 0.6981  decode.d7.loss_dice: 1.2138  decode.d8.loss_cls: 1.1001  decode.d8.loss_mask: 0.7090  decode.d8.loss_dice: 1.2173
2023/05/24 12:42:56 - mmengine - INFO - Iter(train) [148600/160000]  lr: 9.2792e-07  eta: 1:22:24  time: 0.4270  data_time: 0.0101  memory: 4795  grad_norm: 94.0488  loss: 21.3657  decode.loss_cls: 0.6535  decode.loss_mask: 0.4798  decode.loss_dice: 0.8147  decode.d0.loss_cls: 2.3567  decode.d0.loss_mask: 0.5126  decode.d0.loss_dice: 0.9018  decode.d1.loss_cls: 0.7829  decode.d1.loss_mask: 0.4877  decode.d1.loss_dice: 0.8656  decode.d2.loss_cls: 0.6573  decode.d2.loss_mask: 0.4799  decode.d2.loss_dice: 0.8238  decode.d3.loss_cls: 0.6200  decode.d3.loss_mask: 0.4828  decode.d3.loss_dice: 0.8277  decode.d4.loss_cls: 0.6601  decode.d4.loss_mask: 0.4749  decode.d4.loss_dice: 0.8104  decode.d5.loss_cls: 0.6400  decode.d5.loss_mask: 0.4749  decode.d5.loss_dice: 0.8009  decode.d6.loss_cls: 0.6480  decode.d6.loss_mask: 0.4855  decode.d6.loss_dice: 0.7899  decode.d7.loss_cls: 0.6209  decode.d7.loss_mask: 0.4748  decode.d7.loss_dice: 0.8038  decode.d8.loss_cls: 0.6526  decode.d8.loss_mask: 0.4823  decode.d8.loss_dice: 0.8000
2023/05/24 12:43:17 - mmengine - INFO - Iter(train) [148650/160000]  lr: 9.2425e-07  eta: 1:22:02  time: 0.4169  data_time: 0.0098  memory: 4845  grad_norm: 133.5081  loss: 26.7160  decode.loss_cls: 0.8128  decode.loss_mask: 0.6474  decode.loss_dice: 0.9717  decode.d0.loss_cls: 2.7263  decode.d0.loss_mask: 0.6534  decode.d0.loss_dice: 1.0931  decode.d1.loss_cls: 0.9059  decode.d1.loss_mask: 0.6621  decode.d1.loss_dice: 1.0394  decode.d2.loss_cls: 0.8729  decode.d2.loss_mask: 0.6342  decode.d2.loss_dice: 1.0187  decode.d3.loss_cls: 0.8753  decode.d3.loss_mask: 0.6470  decode.d3.loss_dice: 0.9702  decode.d4.loss_cls: 0.8348  decode.d4.loss_mask: 0.6419  decode.d4.loss_dice: 0.9700  decode.d5.loss_cls: 0.8003  decode.d5.loss_mask: 0.6454  decode.d5.loss_dice: 0.9720  decode.d6.loss_cls: 0.8709  decode.d6.loss_mask: 0.6378  decode.d6.loss_dice: 0.9622  decode.d7.loss_cls: 0.8381  decode.d7.loss_mask: 0.6489  decode.d7.loss_dice: 0.9418  decode.d8.loss_cls: 0.8024  decode.d8.loss_mask: 0.6520  decode.d8.loss_dice: 0.9671
2023/05/24 12:43:39 - mmengine - INFO - Iter(train) [148700/160000]  lr: 9.2059e-07  eta: 1:21:41  time: 0.4779  data_time: 0.0105  memory: 4875  grad_norm: 98.5453  loss: 34.1365  decode.loss_cls: 1.1714  decode.loss_mask: 0.6761  decode.loss_dice: 1.2338  decode.d0.loss_cls: 3.0133  decode.d0.loss_mask: 0.8018  decode.d0.loss_dice: 1.5219  decode.d1.loss_cls: 1.3081  decode.d1.loss_mask: 0.7760  decode.d1.loss_dice: 1.3690  decode.d2.loss_cls: 1.2561  decode.d2.loss_mask: 0.7113  decode.d2.loss_dice: 1.3375  decode.d3.loss_cls: 1.1959  decode.d3.loss_mask: 0.7222  decode.d3.loss_dice: 1.2938  decode.d4.loss_cls: 1.1552  decode.d4.loss_mask: 0.7078  decode.d4.loss_dice: 1.2859  decode.d5.loss_cls: 1.2331  decode.d5.loss_mask: 0.6924  decode.d5.loss_dice: 1.2820  decode.d6.loss_cls: 1.2213  decode.d6.loss_mask: 0.7036  decode.d6.loss_dice: 1.2412  decode.d7.loss_cls: 1.1621  decode.d7.loss_mask: 0.6945  decode.d7.loss_dice: 1.2516  decode.d8.loss_cls: 1.1808  decode.d8.loss_mask: 0.7011  decode.d8.loss_dice: 1.2357
2023/05/24 12:44:00 - mmengine - INFO - Iter(train) [148750/160000]  lr: 9.1692e-07  eta: 1:21:19  time: 0.4225  data_time: 0.0101  memory: 4830  grad_norm: 85.2033  loss: 31.7136  decode.loss_cls: 0.9117  decode.loss_mask: 0.8246  decode.loss_dice: 1.1503  decode.d0.loss_cls: 2.8249  decode.d0.loss_mask: 0.8644  decode.d0.loss_dice: 1.3970  decode.d1.loss_cls: 1.0233  decode.d1.loss_mask: 0.8416  decode.d1.loss_dice: 1.3066  decode.d2.loss_cls: 1.0125  decode.d2.loss_mask: 0.8039  decode.d2.loss_dice: 1.2457  decode.d3.loss_cls: 0.9865  decode.d3.loss_mask: 0.8424  decode.d3.loss_dice: 1.2121  decode.d4.loss_cls: 0.9644  decode.d4.loss_mask: 0.8145  decode.d4.loss_dice: 1.2014  decode.d5.loss_cls: 0.9528  decode.d5.loss_mask: 0.8154  decode.d5.loss_dice: 1.1641  decode.d6.loss_cls: 0.8974  decode.d6.loss_mask: 0.7962  decode.d6.loss_dice: 1.1599  decode.d7.loss_cls: 0.8975  decode.d7.loss_mask: 0.8090  decode.d7.loss_dice: 1.1439  decode.d8.loss_cls: 0.8851  decode.d8.loss_mask: 0.8166  decode.d8.loss_dice: 1.1481
2023/05/24 12:44:21 - mmengine - INFO - Iter(train) [148800/160000]  lr: 9.1325e-07  eta: 1:20:57  time: 0.4188  data_time: 0.0099  memory: 4919  grad_norm: 103.1841  loss: 39.6289  decode.loss_cls: 1.3276  decode.loss_mask: 0.8240  decode.loss_dice: 1.5254  decode.d0.loss_cls: 3.3439  decode.d0.loss_mask: 0.8844  decode.d0.loss_dice: 1.8075  decode.d1.loss_cls: 1.4297  decode.d1.loss_mask: 0.8165  decode.d1.loss_dice: 1.6460  decode.d2.loss_cls: 1.4199  decode.d2.loss_mask: 0.8090  decode.d2.loss_dice: 1.6038  decode.d3.loss_cls: 1.4036  decode.d3.loss_mask: 0.8289  decode.d3.loss_dice: 1.5688  decode.d4.loss_cls: 1.3007  decode.d4.loss_mask: 0.8169  decode.d4.loss_dice: 1.5563  decode.d5.loss_cls: 1.3481  decode.d5.loss_mask: 0.8250  decode.d5.loss_dice: 1.5538  decode.d6.loss_cls: 1.3080  decode.d6.loss_mask: 0.8405  decode.d6.loss_dice: 1.5285  decode.d7.loss_cls: 1.2671  decode.d7.loss_mask: 0.8375  decode.d7.loss_dice: 1.5427  decode.d8.loss_cls: 1.3142  decode.d8.loss_mask: 0.8275  decode.d8.loss_dice: 1.5229
2023/05/24 12:44:42 - mmengine - INFO - Iter(train) [148850/160000]  lr: 9.0958e-07  eta: 1:20:35  time: 0.4274  data_time: 0.0100  memory: 4918  grad_norm: 99.2554  loss: 35.7688  decode.loss_cls: 1.1264  decode.loss_mask: 0.8689  decode.loss_dice: 1.2089  decode.d0.loss_cls: 3.1694  decode.d0.loss_mask: 0.9491  decode.d0.loss_dice: 1.4707  decode.d1.loss_cls: 1.3145  decode.d1.loss_mask: 0.9038  decode.d1.loss_dice: 1.3238  decode.d2.loss_cls: 1.2381  decode.d2.loss_mask: 0.9302  decode.d2.loss_dice: 1.3186  decode.d3.loss_cls: 1.2455  decode.d3.loss_mask: 0.9001  decode.d3.loss_dice: 1.2419  decode.d4.loss_cls: 1.2533  decode.d4.loss_mask: 0.8610  decode.d4.loss_dice: 1.2295  decode.d5.loss_cls: 1.2511  decode.d5.loss_mask: 0.8653  decode.d5.loss_dice: 1.2246  decode.d6.loss_cls: 1.2085  decode.d6.loss_mask: 0.8909  decode.d6.loss_dice: 1.2300  decode.d7.loss_cls: 1.2113  decode.d7.loss_mask: 0.8372  decode.d7.loss_dice: 1.2172  decode.d8.loss_cls: 1.2031  decode.d8.loss_mask: 0.8613  decode.d8.loss_dice: 1.2148
2023/05/24 12:45:04 - mmengine - INFO - Iter(train) [148900/160000]  lr: 9.0591e-07  eta: 1:20:14  time: 0.4352  data_time: 0.0110  memory: 4835  grad_norm: 92.9897  loss: 38.8270  decode.loss_cls: 1.2385  decode.loss_mask: 0.7710  decode.loss_dice: 1.5138  decode.d0.loss_cls: 3.3650  decode.d0.loss_mask: 0.7544  decode.d0.loss_dice: 1.8179  decode.d1.loss_cls: 1.4450  decode.d1.loss_mask: 0.8312  decode.d1.loss_dice: 1.7215  decode.d2.loss_cls: 1.3007  decode.d2.loss_mask: 0.8033  decode.d2.loss_dice: 1.6707  decode.d3.loss_cls: 1.3355  decode.d3.loss_mask: 0.7732  decode.d3.loss_dice: 1.6171  decode.d4.loss_cls: 1.2539  decode.d4.loss_mask: 0.7729  decode.d4.loss_dice: 1.6205  decode.d5.loss_cls: 1.2473  decode.d5.loss_mask: 0.7903  decode.d5.loss_dice: 1.5827  decode.d6.loss_cls: 1.2131  decode.d6.loss_mask: 0.7587  decode.d6.loss_dice: 1.5323  decode.d7.loss_cls: 1.2612  decode.d7.loss_mask: 0.7650  decode.d7.loss_dice: 1.5356  decode.d8.loss_cls: 1.1986  decode.d8.loss_mask: 0.7951  decode.d8.loss_dice: 1.5411
2023/05/24 12:45:26 - mmengine - INFO - Iter(train) [148950/160000]  lr: 9.0224e-07  eta: 1:19:52  time: 0.4317  data_time: 0.0101  memory: 4811  grad_norm: 107.8856  loss: 29.6777  decode.loss_cls: 0.8096  decode.loss_mask: 0.8003  decode.loss_dice: 1.0873  decode.d0.loss_cls: 2.6341  decode.d0.loss_mask: 0.8334  decode.d0.loss_dice: 1.2220  decode.d1.loss_cls: 0.9690  decode.d1.loss_mask: 0.8250  decode.d1.loss_dice: 1.1585  decode.d2.loss_cls: 0.9323  decode.d2.loss_mask: 0.8158  decode.d2.loss_dice: 1.1349  decode.d3.loss_cls: 0.8997  decode.d3.loss_mask: 0.7748  decode.d3.loss_dice: 1.1109  decode.d4.loss_cls: 0.8793  decode.d4.loss_mask: 0.7634  decode.d4.loss_dice: 1.0821  decode.d5.loss_cls: 0.8725  decode.d5.loss_mask: 0.7672  decode.d5.loss_dice: 1.1025  decode.d6.loss_cls: 0.8507  decode.d6.loss_mask: 0.8496  decode.d6.loss_dice: 1.0829  decode.d7.loss_cls: 0.8290  decode.d7.loss_mask: 0.8392  decode.d7.loss_dice: 1.0518  decode.d8.loss_cls: 0.8417  decode.d8.loss_mask: 0.7848  decode.d8.loss_dice: 1.0736
2023/05/24 12:45:48 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 12:45:48 - mmengine - INFO - Iter(train) [149000/160000]  lr: 8.9856e-07  eta: 1:19:30  time: 0.4280  data_time: 0.0103  memory: 4863  grad_norm: 91.3503  loss: 44.6858  decode.loss_cls: 1.4273  decode.loss_mask: 1.0096  decode.loss_dice: 1.7351  decode.d0.loss_cls: 3.4094  decode.d0.loss_mask: 1.0576  decode.d0.loss_dice: 1.9779  decode.d1.loss_cls: 1.6153  decode.d1.loss_mask: 1.0288  decode.d1.loss_dice: 1.8344  decode.d2.loss_cls: 1.5666  decode.d2.loss_mask: 1.0243  decode.d2.loss_dice: 1.7901  decode.d3.loss_cls: 1.4456  decode.d3.loss_mask: 1.0216  decode.d3.loss_dice: 1.7664  decode.d4.loss_cls: 1.4409  decode.d4.loss_mask: 1.0138  decode.d4.loss_dice: 1.7745  decode.d5.loss_cls: 1.3701  decode.d5.loss_mask: 1.0308  decode.d5.loss_dice: 1.7645  decode.d6.loss_cls: 1.4884  decode.d6.loss_mask: 1.0226  decode.d6.loss_dice: 1.7254  decode.d7.loss_cls: 1.3776  decode.d7.loss_mask: 1.0450  decode.d7.loss_dice: 1.7442  decode.d8.loss_cls: 1.4232  decode.d8.loss_mask: 1.0014  decode.d8.loss_dice: 1.7533
2023/05/24 12:45:48 - mmengine - INFO - Saving checkpoint at 149000 iterations
2023/05/24 12:46:15 - mmengine - INFO - Iter(train) [149050/160000]  lr: 8.9488e-07  eta: 1:19:09  time: 0.4248  data_time: 0.0103  memory: 4866  grad_norm: 100.4516  loss: 30.4079  decode.loss_cls: 0.8854  decode.loss_mask: 0.7387  decode.loss_dice: 1.1666  decode.d0.loss_cls: 2.9412  decode.d0.loss_mask: 0.8029  decode.d0.loss_dice: 1.3342  decode.d1.loss_cls: 1.0126  decode.d1.loss_mask: 0.7434  decode.d1.loss_dice: 1.2325  decode.d2.loss_cls: 0.9706  decode.d2.loss_mask: 0.7470  decode.d2.loss_dice: 1.2171  decode.d3.loss_cls: 0.8823  decode.d3.loss_mask: 0.7306  decode.d3.loss_dice: 1.2013  decode.d4.loss_cls: 0.8555  decode.d4.loss_mask: 0.7335  decode.d4.loss_dice: 1.1945  decode.d5.loss_cls: 0.8680  decode.d5.loss_mask: 0.7374  decode.d5.loss_dice: 1.1396  decode.d6.loss_cls: 0.8669  decode.d6.loss_mask: 0.7448  decode.d6.loss_dice: 1.1371  decode.d7.loss_cls: 0.8837  decode.d7.loss_mask: 0.7424  decode.d7.loss_dice: 1.1345  decode.d8.loss_cls: 0.8746  decode.d8.loss_mask: 0.7476  decode.d8.loss_dice: 1.1414
2023/05/24 12:46:37 - mmengine - INFO - Iter(train) [149100/160000]  lr: 8.9121e-07  eta: 1:18:47  time: 0.4590  data_time: 0.0109  memory: 4821  grad_norm: 89.3047  loss: 29.5054  decode.loss_cls: 1.0075  decode.loss_mask: 0.6526  decode.loss_dice: 1.0105  decode.d0.loss_cls: 2.8701  decode.d0.loss_mask: 0.7478  decode.d0.loss_dice: 1.1684  decode.d1.loss_cls: 1.0971  decode.d1.loss_mask: 0.7180  decode.d1.loss_dice: 1.1213  decode.d2.loss_cls: 1.0530  decode.d2.loss_mask: 0.6803  decode.d2.loss_dice: 1.0662  decode.d3.loss_cls: 1.0199  decode.d3.loss_mask: 0.7113  decode.d3.loss_dice: 1.0310  decode.d4.loss_cls: 1.0166  decode.d4.loss_mask: 0.6565  decode.d4.loss_dice: 1.0301  decode.d5.loss_cls: 1.0047  decode.d5.loss_mask: 0.7138  decode.d5.loss_dice: 1.0371  decode.d6.loss_cls: 1.0043  decode.d6.loss_mask: 0.6912  decode.d6.loss_dice: 1.0131  decode.d7.loss_cls: 0.9858  decode.d7.loss_mask: 0.6803  decode.d7.loss_dice: 1.0161  decode.d8.loss_cls: 1.0232  decode.d8.loss_mask: 0.6544  decode.d8.loss_dice: 1.0230
2023/05/24 12:46:58 - mmengine - INFO - Iter(train) [149150/160000]  lr: 8.8753e-07  eta: 1:18:26  time: 0.4294  data_time: 0.0108  memory: 4816  grad_norm: 104.5848  loss: 31.5943  decode.loss_cls: 1.0750  decode.loss_mask: 0.6801  decode.loss_dice: 1.1163  decode.d0.loss_cls: 3.0209  decode.d0.loss_mask: 0.7912  decode.d0.loss_dice: 1.3340  decode.d1.loss_cls: 1.1674  decode.d1.loss_mask: 0.7524  decode.d1.loss_dice: 1.2172  decode.d2.loss_cls: 1.1720  decode.d2.loss_mask: 0.6966  decode.d2.loss_dice: 1.1716  decode.d3.loss_cls: 1.1102  decode.d3.loss_mask: 0.6860  decode.d3.loss_dice: 1.1395  decode.d4.loss_cls: 1.0459  decode.d4.loss_mask: 0.6916  decode.d4.loss_dice: 1.1481  decode.d5.loss_cls: 1.0519  decode.d5.loss_mask: 0.7086  decode.d5.loss_dice: 1.1467  decode.d6.loss_cls: 1.1000  decode.d6.loss_mask: 0.6833  decode.d6.loss_dice: 1.1191  decode.d7.loss_cls: 1.0684  decode.d7.loss_mask: 0.6925  decode.d7.loss_dice: 1.1330  decode.d8.loss_cls: 1.1010  decode.d8.loss_mask: 0.6793  decode.d8.loss_dice: 1.0945
2023/05/24 12:47:21 - mmengine - INFO - Iter(train) [149200/160000]  lr: 8.8384e-07  eta: 1:18:04  time: 0.4239  data_time: 0.0101  memory: 4821  grad_norm: 106.5642  loss: 33.4334  decode.loss_cls: 1.1147  decode.loss_mask: 0.7026  decode.loss_dice: 1.2194  decode.d0.loss_cls: 3.1837  decode.d0.loss_mask: 0.7414  decode.d0.loss_dice: 1.4300  decode.d1.loss_cls: 1.3326  decode.d1.loss_mask: 0.6991  decode.d1.loss_dice: 1.3311  decode.d2.loss_cls: 1.1459  decode.d2.loss_mask: 0.7130  decode.d2.loss_dice: 1.2914  decode.d3.loss_cls: 1.2266  decode.d3.loss_mask: 0.7123  decode.d3.loss_dice: 1.2433  decode.d4.loss_cls: 1.1679  decode.d4.loss_mask: 0.7273  decode.d4.loss_dice: 1.2172  decode.d5.loss_cls: 1.1956  decode.d5.loss_mask: 0.6891  decode.d5.loss_dice: 1.2069  decode.d6.loss_cls: 1.1048  decode.d6.loss_mask: 0.7063  decode.d6.loss_dice: 1.2489  decode.d7.loss_cls: 1.1056  decode.d7.loss_mask: 0.7008  decode.d7.loss_dice: 1.2174  decode.d8.loss_cls: 1.1201  decode.d8.loss_mask: 0.7057  decode.d8.loss_dice: 1.2326
2023/05/24 12:47:43 - mmengine - INFO - Iter(train) [149250/160000]  lr: 8.8016e-07  eta: 1:17:42  time: 0.4275  data_time: 0.0101  memory: 4918  grad_norm: 90.8855  loss: 38.0672  decode.loss_cls: 1.2158  decode.loss_mask: 0.8427  decode.loss_dice: 1.4461  decode.d0.loss_cls: 3.1293  decode.d0.loss_mask: 0.9091  decode.d0.loss_dice: 1.7145  decode.d1.loss_cls: 1.3203  decode.d1.loss_mask: 0.8836  decode.d1.loss_dice: 1.5696  decode.d2.loss_cls: 1.2740  decode.d2.loss_mask: 0.8847  decode.d2.loss_dice: 1.5144  decode.d3.loss_cls: 1.3252  decode.d3.loss_mask: 0.8664  decode.d3.loss_dice: 1.4769  decode.d4.loss_cls: 1.2945  decode.d4.loss_mask: 0.8573  decode.d4.loss_dice: 1.4631  decode.d5.loss_cls: 1.2213  decode.d5.loss_mask: 0.8634  decode.d5.loss_dice: 1.4950  decode.d6.loss_cls: 1.2396  decode.d6.loss_mask: 0.8378  decode.d6.loss_dice: 1.4416  decode.d7.loss_cls: 1.2274  decode.d7.loss_mask: 0.8443  decode.d7.loss_dice: 1.4333  decode.d8.loss_cls: 1.1945  decode.d8.loss_mask: 0.8349  decode.d8.loss_dice: 1.4466
2023/05/24 12:48:05 - mmengine - INFO - Iter(train) [149300/160000]  lr: 8.7648e-07  eta: 1:17:21  time: 0.4540  data_time: 0.0100  memory: 4888  grad_norm: 87.5669  loss: 38.4009  decode.loss_cls: 1.4410  decode.loss_mask: 0.6994  decode.loss_dice: 1.3572  decode.d0.loss_cls: 3.3892  decode.d0.loss_mask: 0.8066  decode.d0.loss_dice: 1.7415  decode.d1.loss_cls: 1.5197  decode.d1.loss_mask: 0.8075  decode.d1.loss_dice: 1.6028  decode.d2.loss_cls: 1.4040  decode.d2.loss_mask: 0.7862  decode.d2.loss_dice: 1.4796  decode.d3.loss_cls: 1.4465  decode.d3.loss_mask: 0.7507  decode.d3.loss_dice: 1.4134  decode.d4.loss_cls: 1.3953  decode.d4.loss_mask: 0.7546  decode.d4.loss_dice: 1.4471  decode.d5.loss_cls: 1.4760  decode.d5.loss_mask: 0.7142  decode.d5.loss_dice: 1.4142  decode.d6.loss_cls: 1.3925  decode.d6.loss_mask: 0.7540  decode.d6.loss_dice: 1.3797  decode.d7.loss_cls: 1.4004  decode.d7.loss_mask: 0.7157  decode.d7.loss_dice: 1.3931  decode.d8.loss_cls: 1.4045  decode.d8.loss_mask: 0.7172  decode.d8.loss_dice: 1.3971
2023/05/24 12:48:29 - mmengine - INFO - Iter(train) [149350/160000]  lr: 8.7279e-07  eta: 1:16:59  time: 0.4803  data_time: 0.0098  memory: 4860  grad_norm: 90.2179  loss: 30.5348  decode.loss_cls: 1.2039  decode.loss_mask: 0.7539  decode.loss_dice: 0.8672  decode.d0.loss_cls: 3.0464  decode.d0.loss_mask: 0.7383  decode.d0.loss_dice: 1.0797  decode.d1.loss_cls: 1.3364  decode.d1.loss_mask: 0.7474  decode.d1.loss_dice: 0.9564  decode.d2.loss_cls: 1.2433  decode.d2.loss_mask: 0.7580  decode.d2.loss_dice: 0.9257  decode.d3.loss_cls: 1.2827  decode.d3.loss_mask: 0.6827  decode.d3.loss_dice: 0.8676  decode.d4.loss_cls: 1.2130  decode.d4.loss_mask: 0.7174  decode.d4.loss_dice: 0.8733  decode.d5.loss_cls: 1.1944  decode.d5.loss_mask: 0.7124  decode.d5.loss_dice: 0.8642  decode.d6.loss_cls: 1.2156  decode.d6.loss_mask: 0.7191  decode.d6.loss_dice: 0.8482  decode.d7.loss_cls: 1.2137  decode.d7.loss_mask: 0.7585  decode.d7.loss_dice: 0.8769  decode.d8.loss_cls: 1.2174  decode.d8.loss_mask: 0.7533  decode.d8.loss_dice: 0.8676
2023/05/24 12:48:50 - mmengine - INFO - Iter(train) [149400/160000]  lr: 8.6910e-07  eta: 1:16:38  time: 0.4196  data_time: 0.0101  memory: 4838  grad_norm: 76.3359  loss: 32.3669  decode.loss_cls: 1.1252  decode.loss_mask: 0.7892  decode.loss_dice: 1.1065  decode.d0.loss_cls: 3.2791  decode.d0.loss_mask: 0.8631  decode.d0.loss_dice: 1.3393  decode.d1.loss_cls: 1.0888  decode.d1.loss_mask: 0.8232  decode.d1.loss_dice: 1.2039  decode.d2.loss_cls: 1.0815  decode.d2.loss_mask: 0.7988  decode.d2.loss_dice: 1.1563  decode.d3.loss_cls: 1.0557  decode.d3.loss_mask: 0.7871  decode.d3.loss_dice: 1.1338  decode.d4.loss_cls: 1.0356  decode.d4.loss_mask: 0.7889  decode.d4.loss_dice: 1.1345  decode.d5.loss_cls: 1.0045  decode.d5.loss_mask: 0.8044  decode.d5.loss_dice: 1.1578  decode.d6.loss_cls: 1.0071  decode.d6.loss_mask: 0.7767  decode.d6.loss_dice: 1.1464  decode.d7.loss_cls: 1.0212  decode.d7.loss_mask: 0.7678  decode.d7.loss_dice: 1.1334  decode.d8.loss_cls: 1.0559  decode.d8.loss_mask: 0.7865  decode.d8.loss_dice: 1.1148
2023/05/24 12:49:12 - mmengine - INFO - Iter(train) [149450/160000]  lr: 8.6541e-07  eta: 1:16:16  time: 0.4211  data_time: 0.0101  memory: 4876  grad_norm: 95.5568  loss: 31.3116  decode.loss_cls: 1.1025  decode.loss_mask: 0.6285  decode.loss_dice: 1.1498  decode.d0.loss_cls: 3.0779  decode.d0.loss_mask: 0.6634  decode.d0.loss_dice: 1.3982  decode.d1.loss_cls: 1.1952  decode.d1.loss_mask: 0.6454  decode.d1.loss_dice: 1.2396  decode.d2.loss_cls: 1.0672  decode.d2.loss_mask: 0.6665  decode.d2.loss_dice: 1.2368  decode.d3.loss_cls: 1.0870  decode.d3.loss_mask: 0.6523  decode.d3.loss_dice: 1.1682  decode.d4.loss_cls: 1.0625  decode.d4.loss_mask: 0.6480  decode.d4.loss_dice: 1.1913  decode.d5.loss_cls: 1.0817  decode.d5.loss_mask: 0.6131  decode.d5.loss_dice: 1.1969  decode.d6.loss_cls: 1.1012  decode.d6.loss_mask: 0.6094  decode.d6.loss_dice: 1.1593  decode.d7.loss_cls: 1.0273  decode.d7.loss_mask: 0.6256  decode.d7.loss_dice: 1.1871  decode.d8.loss_cls: 1.0624  decode.d8.loss_mask: 0.6125  decode.d8.loss_dice: 1.1547
2023/05/24 12:49:33 - mmengine - INFO - Iter(train) [149500/160000]  lr: 8.6172e-07  eta: 1:15:54  time: 0.4272  data_time: 0.0103  memory: 4827  grad_norm: 79.7227  loss: 39.3926  decode.loss_cls: 1.2484  decode.loss_mask: 0.8580  decode.loss_dice: 1.4674  decode.d0.loss_cls: 3.3844  decode.d0.loss_mask: 0.9762  decode.d0.loss_dice: 1.7722  decode.d1.loss_cls: 1.4864  decode.d1.loss_mask: 0.8745  decode.d1.loss_dice: 1.6102  decode.d2.loss_cls: 1.4126  decode.d2.loss_mask: 0.8731  decode.d2.loss_dice: 1.5784  decode.d3.loss_cls: 1.3458  decode.d3.loss_mask: 0.8655  decode.d3.loss_dice: 1.5367  decode.d4.loss_cls: 1.3401  decode.d4.loss_mask: 0.8530  decode.d4.loss_dice: 1.5244  decode.d5.loss_cls: 1.3074  decode.d5.loss_mask: 0.8431  decode.d5.loss_dice: 1.5005  decode.d6.loss_cls: 1.2770  decode.d6.loss_mask: 0.8502  decode.d6.loss_dice: 1.4527  decode.d7.loss_cls: 1.2871  decode.d7.loss_mask: 0.8495  decode.d7.loss_dice: 1.4736  decode.d8.loss_cls: 1.2454  decode.d8.loss_mask: 0.8387  decode.d8.loss_dice: 1.4604
2023/05/24 12:49:54 - mmengine - INFO - Iter(train) [149550/160000]  lr: 8.5802e-07  eta: 1:15:32  time: 0.4286  data_time: 0.0100  memory: 4861  grad_norm: 94.6946  loss: 46.6561  decode.loss_cls: 1.3266  decode.loss_mask: 1.1361  decode.loss_dice: 1.8832  decode.d0.loss_cls: 3.5858  decode.d0.loss_mask: 1.1741  decode.d0.loss_dice: 2.1975  decode.d1.loss_cls: 1.5124  decode.d1.loss_mask: 1.1534  decode.d1.loss_dice: 2.0151  decode.d2.loss_cls: 1.4633  decode.d2.loss_mask: 1.1092  decode.d2.loss_dice: 1.9598  decode.d3.loss_cls: 1.3603  decode.d3.loss_mask: 1.0870  decode.d3.loss_dice: 1.8902  decode.d4.loss_cls: 1.3743  decode.d4.loss_mask: 1.0901  decode.d4.loss_dice: 1.8818  decode.d5.loss_cls: 1.3268  decode.d5.loss_mask: 1.1147  decode.d5.loss_dice: 1.9183  decode.d6.loss_cls: 1.3971  decode.d6.loss_mask: 1.1185  decode.d6.loss_dice: 1.8812  decode.d7.loss_cls: 1.3156  decode.d7.loss_mask: 1.1264  decode.d7.loss_dice: 1.8840  decode.d8.loss_cls: 1.3365  decode.d8.loss_mask: 1.1382  decode.d8.loss_dice: 1.8983
2023/05/24 12:50:16 - mmengine - INFO - Iter(train) [149600/160000]  lr: 8.5433e-07  eta: 1:15:11  time: 0.4369  data_time: 0.0101  memory: 4850  grad_norm: 93.9210  loss: 29.0046  decode.loss_cls: 0.9491  decode.loss_mask: 0.6239  decode.loss_dice: 1.0947  decode.d0.loss_cls: 2.8498  decode.d0.loss_mask: 0.6783  decode.d0.loss_dice: 1.2986  decode.d1.loss_cls: 0.9928  decode.d1.loss_mask: 0.6957  decode.d1.loss_dice: 1.2585  decode.d2.loss_cls: 0.9624  decode.d2.loss_mask: 0.6824  decode.d2.loss_dice: 1.1466  decode.d3.loss_cls: 0.8923  decode.d3.loss_mask: 0.6494  decode.d3.loss_dice: 1.1167  decode.d4.loss_cls: 0.9000  decode.d4.loss_mask: 0.6434  decode.d4.loss_dice: 1.1042  decode.d5.loss_cls: 0.9081  decode.d5.loss_mask: 0.6433  decode.d5.loss_dice: 1.0936  decode.d6.loss_cls: 0.8790  decode.d6.loss_mask: 0.6518  decode.d6.loss_dice: 1.0647  decode.d7.loss_cls: 0.8898  decode.d7.loss_mask: 0.6463  decode.d7.loss_dice: 1.0729  decode.d8.loss_cls: 0.8615  decode.d8.loss_mask: 0.6629  decode.d8.loss_dice: 1.0916
2023/05/24 12:50:39 - mmengine - INFO - Iter(train) [149650/160000]  lr: 8.5063e-07  eta: 1:14:49  time: 0.4825  data_time: 0.0101  memory: 4783  grad_norm: 252.6958  loss: 35.0037  decode.loss_cls: 1.2985  decode.loss_mask: 0.8530  decode.loss_dice: 1.0490  decode.d0.loss_cls: 3.2172  decode.d0.loss_mask: 0.9117  decode.d0.loss_dice: 1.2767  decode.d1.loss_cls: 1.4453  decode.d1.loss_mask: 0.8309  decode.d1.loss_dice: 1.1574  decode.d2.loss_cls: 1.3849  decode.d2.loss_mask: 0.8253  decode.d2.loss_dice: 1.1224  decode.d3.loss_cls: 1.3343  decode.d3.loss_mask: 0.8747  decode.d3.loss_dice: 1.0945  decode.d4.loss_cls: 1.3245  decode.d4.loss_mask: 0.8654  decode.d4.loss_dice: 1.1213  decode.d5.loss_cls: 1.3296  decode.d5.loss_mask: 0.8606  decode.d5.loss_dice: 1.1117  decode.d6.loss_cls: 1.3026  decode.d6.loss_mask: 0.8514  decode.d6.loss_dice: 1.0794  decode.d7.loss_cls: 1.2904  decode.d7.loss_mask: 0.8550  decode.d7.loss_dice: 1.0925  decode.d8.loss_cls: 1.2965  decode.d8.loss_mask: 0.8500  decode.d8.loss_dice: 1.0969
2023/05/24 12:51:00 - mmengine - INFO - Iter(train) [149700/160000]  lr: 8.4693e-07  eta: 1:14:27  time: 0.4260  data_time: 0.0099  memory: 4821  grad_norm: 88.0744  loss: 33.2049  decode.loss_cls: 1.2914  decode.loss_mask: 0.6371  decode.loss_dice: 1.0026  decode.d0.loss_cls: 3.3475  decode.d0.loss_mask: 0.7143  decode.d0.loss_dice: 1.2704  decode.d1.loss_cls: 1.4863  decode.d1.loss_mask: 0.7511  decode.d1.loss_dice: 1.2038  decode.d2.loss_cls: 1.4881  decode.d2.loss_mask: 0.7042  decode.d2.loss_dice: 1.1033  decode.d3.loss_cls: 1.4041  decode.d3.loss_mask: 0.6907  decode.d3.loss_dice: 1.0771  decode.d4.loss_cls: 1.3907  decode.d4.loss_mask: 0.6974  decode.d4.loss_dice: 0.9993  decode.d5.loss_cls: 1.3719  decode.d5.loss_mask: 0.6786  decode.d5.loss_dice: 1.0413  decode.d6.loss_cls: 1.2943  decode.d6.loss_mask: 0.6551  decode.d6.loss_dice: 1.0200  decode.d7.loss_cls: 1.2921  decode.d7.loss_mask: 0.6458  decode.d7.loss_dice: 0.9999  decode.d8.loss_cls: 1.2771  decode.d8.loss_mask: 0.6544  decode.d8.loss_dice: 1.0149
2023/05/24 12:51:23 - mmengine - INFO - Iter(train) [149750/160000]  lr: 8.4323e-07  eta: 1:14:06  time: 0.4835  data_time: 0.0101  memory: 4857  grad_norm: 132.2937  loss: 33.1730  decode.loss_cls: 0.9121  decode.loss_mask: 0.8092  decode.loss_dice: 1.2649  decode.d0.loss_cls: 3.1165  decode.d0.loss_mask: 0.8959  decode.d0.loss_dice: 1.4866  decode.d1.loss_cls: 1.0601  decode.d1.loss_mask: 0.8519  decode.d1.loss_dice: 1.4071  decode.d2.loss_cls: 0.9923  decode.d2.loss_mask: 0.8310  decode.d2.loss_dice: 1.3180  decode.d3.loss_cls: 0.9891  decode.d3.loss_mask: 0.8358  decode.d3.loss_dice: 1.3099  decode.d4.loss_cls: 0.9717  decode.d4.loss_mask: 0.8179  decode.d4.loss_dice: 1.3218  decode.d5.loss_cls: 0.9264  decode.d5.loss_mask: 0.8202  decode.d5.loss_dice: 1.2702  decode.d6.loss_cls: 0.9141  decode.d6.loss_mask: 0.8193  decode.d6.loss_dice: 1.2666  decode.d7.loss_cls: 0.9133  decode.d7.loss_mask: 0.8088  decode.d7.loss_dice: 1.2798  decode.d8.loss_cls: 0.9070  decode.d8.loss_mask: 0.8087  decode.d8.loss_dice: 1.2466
2023/05/24 12:51:45 - mmengine - INFO - Iter(train) [149800/160000]  lr: 8.3953e-07  eta: 1:13:44  time: 0.4259  data_time: 0.0099  memory: 4983  grad_norm: 134.4085  loss: 49.7351  decode.loss_cls: 1.5662  decode.loss_mask: 0.8489  decode.loss_dice: 2.1915  decode.d0.loss_cls: 3.7944  decode.d0.loss_mask: 0.9560  decode.d0.loss_dice: 2.6619  decode.d1.loss_cls: 1.6883  decode.d1.loss_mask: 0.8906  decode.d1.loss_dice: 2.3349  decode.d2.loss_cls: 1.5234  decode.d2.loss_mask: 0.8754  decode.d2.loss_dice: 2.3139  decode.d3.loss_cls: 1.5533  decode.d3.loss_mask: 0.8850  decode.d3.loss_dice: 2.3014  decode.d4.loss_cls: 1.6028  decode.d4.loss_mask: 0.8747  decode.d4.loss_dice: 2.3024  decode.d5.loss_cls: 1.6166  decode.d5.loss_mask: 0.8428  decode.d5.loss_dice: 2.1866  decode.d6.loss_cls: 1.6048  decode.d6.loss_mask: 0.8572  decode.d6.loss_dice: 2.2132  decode.d7.loss_cls: 1.5870  decode.d7.loss_mask: 0.8517  decode.d7.loss_dice: 2.1907  decode.d8.loss_cls: 1.5532  decode.d8.loss_mask: 0.8522  decode.d8.loss_dice: 2.2142
2023/05/24 12:52:06 - mmengine - INFO - Iter(train) [149850/160000]  lr: 8.3582e-07  eta: 1:13:22  time: 0.4232  data_time: 0.0103  memory: 4907  grad_norm: 95.7896  loss: 43.4732  decode.loss_cls: 1.4370  decode.loss_mask: 0.8536  decode.loss_dice: 1.7071  decode.d0.loss_cls: 3.7122  decode.d0.loss_mask: 0.9328  decode.d0.loss_dice: 2.0478  decode.d1.loss_cls: 1.6948  decode.d1.loss_mask: 0.8854  decode.d1.loss_dice: 1.8447  decode.d2.loss_cls: 1.5487  decode.d2.loss_mask: 0.8835  decode.d2.loss_dice: 1.7469  decode.d3.loss_cls: 1.4763  decode.d3.loss_mask: 0.8951  decode.d3.loss_dice: 1.7423  decode.d4.loss_cls: 1.4161  decode.d4.loss_mask: 0.9117  decode.d4.loss_dice: 1.7459  decode.d5.loss_cls: 1.4521  decode.d5.loss_mask: 0.8854  decode.d5.loss_dice: 1.7029  decode.d6.loss_cls: 1.4492  decode.d6.loss_mask: 0.8308  decode.d6.loss_dice: 1.7077  decode.d7.loss_cls: 1.4152  decode.d7.loss_mask: 0.8689  decode.d7.loss_dice: 1.7027  decode.d8.loss_cls: 1.4397  decode.d8.loss_mask: 0.8494  decode.d8.loss_dice: 1.6873
2023/05/24 12:52:27 - mmengine - INFO - Iter(train) [149900/160000]  lr: 8.3212e-07  eta: 1:13:01  time: 0.4229  data_time: 0.0099  memory: 4927  grad_norm: 94.4159  loss: 34.5528  decode.loss_cls: 1.2372  decode.loss_mask: 0.7883  decode.loss_dice: 1.1522  decode.d0.loss_cls: 3.1254  decode.d0.loss_mask: 0.8913  decode.d0.loss_dice: 1.4013  decode.d1.loss_cls: 1.3768  decode.d1.loss_mask: 0.8698  decode.d1.loss_dice: 1.3142  decode.d2.loss_cls: 1.2932  decode.d2.loss_mask: 0.8168  decode.d2.loss_dice: 1.1831  decode.d3.loss_cls: 1.2199  decode.d3.loss_mask: 0.7988  decode.d3.loss_dice: 1.2210  decode.d4.loss_cls: 1.2060  decode.d4.loss_mask: 0.8196  decode.d4.loss_dice: 1.1737  decode.d5.loss_cls: 1.2062  decode.d5.loss_mask: 0.7938  decode.d5.loss_dice: 1.1833  decode.d6.loss_cls: 1.2089  decode.d6.loss_mask: 0.8115  decode.d6.loss_dice: 1.1545  decode.d7.loss_cls: 1.1937  decode.d7.loss_mask: 0.8076  decode.d7.loss_dice: 1.1681  decode.d8.loss_cls: 1.1610  decode.d8.loss_mask: 0.8143  decode.d8.loss_dice: 1.1613
2023/05/24 12:52:49 - mmengine - INFO - Iter(train) [149950/160000]  lr: 8.2841e-07  eta: 1:12:39  time: 0.4297  data_time: 0.0103  memory: 4875  grad_norm: 92.7463  loss: 39.3931  decode.loss_cls: 1.3463  decode.loss_mask: 0.6713  decode.loss_dice: 1.5491  decode.d0.loss_cls: 3.3856  decode.d0.loss_mask: 0.7259  decode.d0.loss_dice: 1.7473  decode.d1.loss_cls: 1.5700  decode.d1.loss_mask: 0.7571  decode.d1.loss_dice: 1.6365  decode.d2.loss_cls: 1.4922  decode.d2.loss_mask: 0.7192  decode.d2.loss_dice: 1.5462  decode.d3.loss_cls: 1.4940  decode.d3.loss_mask: 0.7210  decode.d3.loss_dice: 1.5643  decode.d4.loss_cls: 1.3943  decode.d4.loss_mask: 0.7281  decode.d4.loss_dice: 1.5952  decode.d5.loss_cls: 1.4719  decode.d5.loss_mask: 0.7354  decode.d5.loss_dice: 1.5735  decode.d6.loss_cls: 1.4195  decode.d6.loss_mask: 0.6949  decode.d6.loss_dice: 1.5511  decode.d7.loss_cls: 1.4440  decode.d7.loss_mask: 0.6757  decode.d7.loss_dice: 1.5446  decode.d8.loss_cls: 1.4056  decode.d8.loss_mask: 0.6772  decode.d8.loss_dice: 1.5560
2023/05/24 12:53:11 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 12:53:11 - mmengine - INFO - Iter(train) [150000/160000]  lr: 8.2470e-07  eta: 1:12:17  time: 0.4322  data_time: 0.0098  memory: 4838  grad_norm: 107.0539  loss: 32.7416  decode.loss_cls: 1.0668  decode.loss_mask: 0.7180  decode.loss_dice: 1.1907  decode.d0.loss_cls: 3.0257  decode.d0.loss_mask: 0.8031  decode.d0.loss_dice: 1.4708  decode.d1.loss_cls: 1.3016  decode.d1.loss_mask: 0.7439  decode.d1.loss_dice: 1.3295  decode.d2.loss_cls: 1.1913  decode.d2.loss_mask: 0.7442  decode.d2.loss_dice: 1.2430  decode.d3.loss_cls: 1.1056  decode.d3.loss_mask: 0.7365  decode.d3.loss_dice: 1.2118  decode.d4.loss_cls: 1.0876  decode.d4.loss_mask: 0.7310  decode.d4.loss_dice: 1.2233  decode.d5.loss_cls: 1.0383  decode.d5.loss_mask: 0.7337  decode.d5.loss_dice: 1.2063  decode.d6.loss_cls: 1.0230  decode.d6.loss_mask: 0.7307  decode.d6.loss_dice: 1.2014  decode.d7.loss_cls: 1.0210  decode.d7.loss_mask: 0.7226  decode.d7.loss_dice: 1.1907  decode.d8.loss_cls: 1.0415  decode.d8.loss_mask: 0.7136  decode.d8.loss_dice: 1.1944
2023/05/24 12:53:11 - mmengine - INFO - Saving checkpoint at 150000 iterations
2023/05/24 12:53:21 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:53  time: 0.0908  data_time: 0.0019  memory: 2167  
2023/05/24 12:53:26 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:47  time: 0.0788  data_time: 0.0018  memory: 2216  
2023/05/24 12:53:30 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:40  time: 0.0789  data_time: 0.0018  memory: 2167  
2023/05/24 12:53:34 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0793  data_time: 0.0018  memory: 2104  
2023/05/24 12:53:40 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:35  time: 0.3136  data_time: 0.0021  memory: 2831  
2023/05/24 12:53:44 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:29  time: 0.0899  data_time: 0.0019  memory: 2167  
2023/05/24 12:53:49 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0886  data_time: 0.0019  memory: 2167  
2023/05/24 12:53:53 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:20  time: 0.0807  data_time: 0.0018  memory: 2167  
2023/05/24 12:53:57 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0792  data_time: 0.0021  memory: 2944  
2023/05/24 12:54:01 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0794  data_time: 0.0019  memory: 2356  
2023/05/24 12:54:05 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0772  data_time: 0.0016  memory: 2217  
2023/05/24 12:54:09 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0881  data_time: 0.0021  memory: 2328  
2023/05/24 12:54:13 - mmengine - INFO - per class results:
2023/05/24 12:54:13 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.67 | 93.69 |
|     bicycle      | 70.65 | 83.64 |
|       car        | 62.68 | 83.75 |
|    motorcycle    | 83.48 | 89.68 |
|     airplane     | 86.08 | 93.52 |
|       bus        | 81.01 | 86.86 |
|      train       | 82.02 | 94.67 |
|      truck       | 56.32 |  73.0 |
|       boat       | 61.08 | 81.21 |
|  traffic light   | 69.46 |  84.3 |
|   fire hydrant   | 89.17 | 95.29 |
|    stop sign     | 91.23 | 96.43 |
|  parking meter   | 76.26 | 86.23 |
|      bench       | 49.34 | 71.05 |
|       bird       | 80.95 | 91.44 |
|       cat        |  85.9 |  92.6 |
|       dog        | 82.38 | 88.46 |
|      horse       | 78.52 | 90.18 |
|      sheep       |  86.1 | 92.39 |
|       cow        | 82.07 | 89.03 |
|     elephant     | 89.75 | 94.98 |
|       bear       | 92.36 | 95.21 |
|      zebra       | 90.33 | 93.47 |
|     giraffe      | 87.54 | 93.41 |
|     backpack     | 36.52 | 61.93 |
|     umbrella     | 79.45 | 88.49 |
|     handbag      | 34.89 | 56.88 |
|       tie        | 11.58 |  14.0 |
|     suitcase     | 77.35 | 90.67 |
|     frisbee      | 68.66 | 91.44 |
|       skis       | 47.89 | 64.63 |
|    snowboard     | 60.93 | 72.82 |
|   sports ball    | 56.93 | 74.14 |
|       kite       | 57.61 | 70.01 |
|   baseball bat   | 54.52 | 68.65 |
|  baseball glove  | 74.04 | 87.57 |
|    skateboard    | 76.61 | 84.15 |
|    surfboard     | 73.07 | 87.32 |
|  tennis racket   | 86.36 | 92.01 |
|      bottle      | 43.83 | 56.54 |
|    wine glass    | 54.27 | 74.18 |
|       cup        | 53.17 | 74.86 |
|       fork       | 33.21 | 41.26 |
|      knife       | 30.59 | 41.68 |
|      spoon       | 36.29 | 57.48 |
|       bowl       | 45.47 | 63.44 |
|      banana      | 65.72 |  86.4 |
|      apple       | 48.67 | 70.98 |
|     sandwich     | 47.16 | 64.68 |
|      orange      | 61.19 | 66.75 |
|     broccoli     | 59.82 | 73.81 |
|      carrot      | 51.22 |  58.0 |
|     hot dog      | 50.11 | 59.07 |
|      pizza       | 68.36 | 85.86 |
|      donut       | 70.72 | 85.35 |
|       cake       | 61.58 | 74.38 |
|      chair       | 47.75 | 69.68 |
|      couch       | 57.58 | 77.65 |
|   potted plant   | 32.44 | 47.27 |
|       bed        | 62.99 |  82.2 |
|   dining table   | 44.05 | 77.25 |
|      toilet      | 82.53 | 93.64 |
|        tv        | 72.72 | 87.69 |
|      laptop      | 75.92 | 89.38 |
|      mouse       | 76.13 | 88.94 |
|      remote      |  58.5 | 72.49 |
|     keyboard     | 62.84 | 73.69 |
|    cell phone    | 72.88 | 88.81 |
|    microwave     | 63.55 | 76.07 |
|       oven       | 56.24 | 80.88 |
|     toaster      | 43.44 |  54.7 |
|       sink       | 55.89 | 79.36 |
|   refrigerator   |  78.1 | 91.82 |
|       book       | 50.41 | 70.22 |
|      clock       | 72.83 | 81.43 |
|       vase       | 58.36 | 85.39 |
|     scissors     | 78.91 | 90.41 |
|    teddy bear    |  75.3 | 87.18 |
|    hair drier    | 41.69 | 54.43 |
|    toothbrush    | 44.19 | 77.96 |
|      banner      | 35.99 | 61.83 |
|     blanket      |  6.85 |  8.07 |
|      branch      | 17.93 | 25.86 |
|      bridge      | 32.96 | 47.01 |
|  building-other  | 53.65 | 73.34 |
|       bush       | 32.78 | 44.61 |
|     cabinet      | 54.74 | 72.33 |
|       cage       | 19.27 | 25.23 |
|    cardboard     | 46.91 | 54.96 |
|      carpet      | 50.89 | 70.42 |
|  ceiling-other   | 64.85 | 79.87 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 21.14 | 29.95 |
|      clouds      | 46.08 | 60.32 |
|     counter      |  27.0 | 45.05 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 65.26 | 76.88 |
|    desk-stuff    | 44.27 | 59.55 |
|       dirt       | 41.04 | 61.54 |
|    door-stuff    | 41.03 | 59.04 |
|      fence       | 34.34 | 65.27 |
|   floor-marble   |  5.52 |  6.67 |
|   floor-other    | 22.03 | 30.49 |
|   floor-stone    |  2.53 |  3.09 |
|    floor-tile    | 59.81 | 69.23 |
|    floor-wood    | 62.27 | 75.72 |
|      flower      | 40.58 | 60.08 |
|       fog        |  7.32 |  7.77 |
|    food-other    | 28.85 | 36.22 |
|      fruit       | 39.33 | 60.13 |
| furniture-other  |  17.2 | 23.45 |
|      grass       | 70.38 | 82.86 |
|      gravel      | 27.61 | 37.78 |
|   ground-other   |  0.86 |  1.08 |
|       hill       | 22.18 | 30.81 |
|      house       | 23.45 | 28.32 |
|      leaves      | 22.63 | 28.66 |
|      light       | 38.04 | 53.09 |
|       mat        |  0.0  |  0.0  |
|      metal       | 32.95 | 48.11 |
|   mirror-stuff   | 51.62 | 73.74 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 52.63 | 66.86 |
|       mud        |  5.65 | 10.47 |
|      napkin      |  7.62 |  7.82 |
|       net        | 41.84 | 62.99 |
|      paper       | 30.43 | 41.27 |
|     pavement     | 51.23 | 72.25 |
|      pillow      |  15.3 |  20.4 |
|   plant-other    | 17.83 | 34.44 |
|     plastic      | 25.38 | 34.62 |
|     platform     | 26.68 | 43.22 |
|   playingfield   | 69.64 |  89.9 |
|     railing      |  6.02 | 10.64 |
|     railroad     | 60.37 | 78.56 |
|      river       | 49.75 | 62.82 |
|       road       | 67.05 | 80.52 |
|       rock       | 43.86 | 65.45 |
|       roof       | 12.67 | 16.72 |
|       rug        | 34.95 | 52.94 |
|      salad       |  0.01 |  0.01 |
|       sand       | 62.98 | 71.93 |
|       sea        | 85.84 | 91.56 |
|      shelf       | 33.97 | 49.38 |
|    sky-other     | 70.46 | 87.12 |
|    skyscraper    | 34.62 |  44.3 |
|       snow       | 88.91 | 92.84 |
|   solid-other    |  0.21 |  0.21 |
|      stairs      | 22.64 | 38.48 |
|      stone       | 12.75 | 22.32 |
|      straw       | 33.63 | 45.51 |
| structural-other |  0.01 |  0.01 |
|      table       | 18.28 | 24.92 |
|       tent       |  8.48 |  10.8 |
|  textile-other   | 12.19 | 19.63 |
|      towel       | 31.09 | 43.26 |
|       tree       | 73.77 | 86.23 |
|    vegetable     | 33.66 | 44.52 |
|    wall-brick    | 45.57 |  61.6 |
|  wall-concrete   | 60.09 | 77.68 |
|    wall-other    | 19.42 | 34.33 |
|    wall-panel    |  2.27 |  2.59 |
|    wall-stone    | 32.91 | 39.96 |
|    wall-tile     | 66.99 | 83.54 |
|    wall-wood     | 39.87 | 56.49 |
|   water-other    | 28.79 | 49.65 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 49.28 | 57.06 |
|   window-other   | 47.18 | 73.07 |
|       wood       | 25.37 | 39.03 |
+------------------+-------+-------+
2023/05/24 12:54:13 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.4300  mIoU: 47.4700  mAcc: 59.8300  data_time: 0.0020  time: 0.0866
2023/05/24 12:54:13 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_140000.pth is removed
2023/05/24 12:54:16 - mmengine - INFO - The best checkpoint with 47.4700 mIoU at 150000 iter is saved to best_mIoU_iter_150000.pth.
2023/05/24 12:54:38 - mmengine - INFO - Iter(train) [150050/160000]  lr: 8.2099e-07  eta: 1:11:56  time: 0.4308  data_time: 0.0102  memory: 4847  grad_norm: 90.8239  loss: 36.3587  decode.loss_cls: 1.2775  decode.loss_mask: 0.7996  decode.loss_dice: 1.2168  decode.d0.loss_cls: 3.3907  decode.d0.loss_mask: 0.9464  decode.d0.loss_dice: 1.4837  decode.d1.loss_cls: 1.4185  decode.d1.loss_mask: 0.8714  decode.d1.loss_dice: 1.3340  decode.d2.loss_cls: 1.2848  decode.d2.loss_mask: 0.8339  decode.d2.loss_dice: 1.2770  decode.d3.loss_cls: 1.3534  decode.d3.loss_mask: 0.8154  decode.d3.loss_dice: 1.2629  decode.d4.loss_cls: 1.2964  decode.d4.loss_mask: 0.8491  decode.d4.loss_dice: 1.2547  decode.d5.loss_cls: 1.3135  decode.d5.loss_mask: 0.8099  decode.d5.loss_dice: 1.2526  decode.d6.loss_cls: 1.3280  decode.d6.loss_mask: 0.8257  decode.d6.loss_dice: 1.2302  decode.d7.loss_cls: 1.2753  decode.d7.loss_mask: 0.8111  decode.d7.loss_dice: 1.2452  decode.d8.loss_cls: 1.2371  decode.d8.loss_mask: 0.8241  decode.d8.loss_dice: 1.2398
2023/05/24 12:54:59 - mmengine - INFO - Iter(train) [150100/160000]  lr: 8.1727e-07  eta: 1:11:34  time: 0.4249  data_time: 0.0102  memory: 4859  grad_norm: 96.9253  loss: 39.9741  decode.loss_cls: 1.2562  decode.loss_mask: 0.9553  decode.loss_dice: 1.4334  decode.d0.loss_cls: 3.3123  decode.d0.loss_mask: 1.0425  decode.d0.loss_dice: 1.6872  decode.d1.loss_cls: 1.3813  decode.d1.loss_mask: 1.0392  decode.d1.loss_dice: 1.6341  decode.d2.loss_cls: 1.3774  decode.d2.loss_mask: 0.9863  decode.d2.loss_dice: 1.5358  decode.d3.loss_cls: 1.3811  decode.d3.loss_mask: 0.9504  decode.d3.loss_dice: 1.4686  decode.d4.loss_cls: 1.3464  decode.d4.loss_mask: 0.9580  decode.d4.loss_dice: 1.4646  decode.d5.loss_cls: 1.3429  decode.d5.loss_mask: 0.9488  decode.d5.loss_dice: 1.4672  decode.d6.loss_cls: 1.2660  decode.d6.loss_mask: 0.9608  decode.d6.loss_dice: 1.4596  decode.d7.loss_cls: 1.2675  decode.d7.loss_mask: 0.9508  decode.d7.loss_dice: 1.4493  decode.d8.loss_cls: 1.2640  decode.d8.loss_mask: 0.9497  decode.d8.loss_dice: 1.4372
2023/05/24 12:55:21 - mmengine - INFO - Iter(train) [150150/160000]  lr: 8.1356e-07  eta: 1:11:13  time: 0.4258  data_time: 0.0102  memory: 4875  grad_norm: 122.9189  loss: 32.3407  decode.loss_cls: 1.1207  decode.loss_mask: 0.7754  decode.loss_dice: 1.0460  decode.d0.loss_cls: 2.9309  decode.d0.loss_mask: 0.7793  decode.d0.loss_dice: 1.2065  decode.d1.loss_cls: 1.2780  decode.d1.loss_mask: 0.7964  decode.d1.loss_dice: 1.1661  decode.d2.loss_cls: 1.2606  decode.d2.loss_mask: 0.8155  decode.d2.loss_dice: 1.1010  decode.d3.loss_cls: 1.1593  decode.d3.loss_mask: 0.8455  decode.d3.loss_dice: 1.0706  decode.d4.loss_cls: 1.1363  decode.d4.loss_mask: 0.8120  decode.d4.loss_dice: 1.0909  decode.d5.loss_cls: 1.1357  decode.d5.loss_mask: 0.8063  decode.d5.loss_dice: 1.0702  decode.d6.loss_cls: 1.1228  decode.d6.loss_mask: 0.7945  decode.d6.loss_dice: 1.0693  decode.d7.loss_cls: 1.1103  decode.d7.loss_mask: 0.8117  decode.d7.loss_dice: 1.0560  decode.d8.loss_cls: 1.1370  decode.d8.loss_mask: 0.7804  decode.d8.loss_dice: 1.0556
2023/05/24 12:55:45 - mmengine - INFO - Iter(train) [150200/160000]  lr: 8.0984e-07  eta: 1:10:51  time: 0.4680  data_time: 0.0097  memory: 4808  grad_norm: 88.8036  loss: 31.3262  decode.loss_cls: 1.0340  decode.loss_mask: 0.6448  decode.loss_dice: 1.1526  decode.d0.loss_cls: 3.0165  decode.d0.loss_mask: 0.7081  decode.d0.loss_dice: 1.2946  decode.d1.loss_cls: 1.2317  decode.d1.loss_mask: 0.6667  decode.d1.loss_dice: 1.2146  decode.d2.loss_cls: 1.1666  decode.d2.loss_mask: 0.6328  decode.d2.loss_dice: 1.1829  decode.d3.loss_cls: 1.1507  decode.d3.loss_mask: 0.6230  decode.d3.loss_dice: 1.1517  decode.d4.loss_cls: 1.1336  decode.d4.loss_mask: 0.6340  decode.d4.loss_dice: 1.1523  decode.d5.loss_cls: 1.1194  decode.d5.loss_mask: 0.6260  decode.d5.loss_dice: 1.1587  decode.d6.loss_cls: 1.1085  decode.d6.loss_mask: 0.6215  decode.d6.loss_dice: 1.1306  decode.d7.loss_cls: 1.1184  decode.d7.loss_mask: 0.6215  decode.d7.loss_dice: 1.1294  decode.d8.loss_cls: 1.1466  decode.d8.loss_mask: 0.6287  decode.d8.loss_dice: 1.1257
2023/05/24 12:56:06 - mmengine - INFO - Iter(train) [150250/160000]  lr: 8.0612e-07  eta: 1:10:29  time: 0.4393  data_time: 0.0103  memory: 4857  grad_norm: 102.2083  loss: 34.1600  decode.loss_cls: 1.3177  decode.loss_mask: 0.6945  decode.loss_dice: 1.1357  decode.d0.loss_cls: 3.0830  decode.d0.loss_mask: 0.7656  decode.d0.loss_dice: 1.3135  decode.d1.loss_cls: 1.3969  decode.d1.loss_mask: 0.7151  decode.d1.loss_dice: 1.2907  decode.d2.loss_cls: 1.3469  decode.d2.loss_mask: 0.7321  decode.d2.loss_dice: 1.2321  decode.d3.loss_cls: 1.2931  decode.d3.loss_mask: 0.7075  decode.d3.loss_dice: 1.1876  decode.d4.loss_cls: 1.3273  decode.d4.loss_mask: 0.6890  decode.d4.loss_dice: 1.1967  decode.d5.loss_cls: 1.2891  decode.d5.loss_mask: 0.7006  decode.d5.loss_dice: 1.1839  decode.d6.loss_cls: 1.2753  decode.d6.loss_mask: 0.7149  decode.d6.loss_dice: 1.1963  decode.d7.loss_cls: 1.2608  decode.d7.loss_mask: 0.7205  decode.d7.loss_dice: 1.1636  decode.d8.loss_cls: 1.3856  decode.d8.loss_mask: 0.6967  decode.d8.loss_dice: 1.1479
2023/05/24 12:56:27 - mmengine - INFO - Iter(train) [150300/160000]  lr: 8.0240e-07  eta: 1:10:08  time: 0.4254  data_time: 0.0103  memory: 4877  grad_norm: 94.6427  loss: 36.0587  decode.loss_cls: 1.2338  decode.loss_mask: 0.7306  decode.loss_dice: 1.3138  decode.d0.loss_cls: 3.4981  decode.d0.loss_mask: 0.8809  decode.d0.loss_dice: 1.5967  decode.d1.loss_cls: 1.3816  decode.d1.loss_mask: 0.7948  decode.d1.loss_dice: 1.4192  decode.d2.loss_cls: 1.2851  decode.d2.loss_mask: 0.7445  decode.d2.loss_dice: 1.4175  decode.d3.loss_cls: 1.2681  decode.d3.loss_mask: 0.7452  decode.d3.loss_dice: 1.3187  decode.d4.loss_cls: 1.2761  decode.d4.loss_mask: 0.7370  decode.d4.loss_dice: 1.3066  decode.d5.loss_cls: 1.2374  decode.d5.loss_mask: 0.7423  decode.d5.loss_dice: 1.3278  decode.d6.loss_cls: 1.2063  decode.d6.loss_mask: 0.7335  decode.d6.loss_dice: 1.3385  decode.d7.loss_cls: 1.1828  decode.d7.loss_mask: 0.7374  decode.d7.loss_dice: 1.3083  decode.d8.loss_cls: 1.2395  decode.d8.loss_mask: 0.7351  decode.d8.loss_dice: 1.3216
2023/05/24 12:56:49 - mmengine - INFO - Iter(train) [150350/160000]  lr: 7.9867e-07  eta: 1:09:46  time: 0.4284  data_time: 0.0105  memory: 4857  grad_norm: 90.3174  loss: 39.1756  decode.loss_cls: 1.1348  decode.loss_mask: 0.9624  decode.loss_dice: 1.5180  decode.d0.loss_cls: 3.2281  decode.d0.loss_mask: 0.9303  decode.d0.loss_dice: 1.7387  decode.d1.loss_cls: 1.2177  decode.d1.loss_mask: 1.0438  decode.d1.loss_dice: 1.6712  decode.d2.loss_cls: 1.2109  decode.d2.loss_mask: 0.9971  decode.d2.loss_dice: 1.5928  decode.d3.loss_cls: 1.1971  decode.d3.loss_mask: 0.9803  decode.d3.loss_dice: 1.5558  decode.d4.loss_cls: 1.2022  decode.d4.loss_mask: 0.9777  decode.d4.loss_dice: 1.5674  decode.d5.loss_cls: 1.1460  decode.d5.loss_mask: 0.9565  decode.d5.loss_dice: 1.5126  decode.d6.loss_cls: 1.1325  decode.d6.loss_mask: 0.9591  decode.d6.loss_dice: 1.5144  decode.d7.loss_cls: 1.1182  decode.d7.loss_mask: 0.9762  decode.d7.loss_dice: 1.5202  decode.d8.loss_cls: 1.0748  decode.d8.loss_mask: 0.9853  decode.d8.loss_dice: 1.5537
2023/05/24 12:57:10 - mmengine - INFO - Iter(train) [150400/160000]  lr: 7.9495e-07  eta: 1:09:24  time: 0.4190  data_time: 0.0098  memory: 4900  grad_norm: 87.7621  loss: 29.4018  decode.loss_cls: 0.9320  decode.loss_mask: 0.6953  decode.loss_dice: 0.9747  decode.d0.loss_cls: 2.8648  decode.d0.loss_mask: 0.8310  decode.d0.loss_dice: 1.2714  decode.d1.loss_cls: 1.0446  decode.d1.loss_mask: 0.7742  decode.d1.loss_dice: 1.1380  decode.d2.loss_cls: 1.0332  decode.d2.loss_mask: 0.7614  decode.d2.loss_dice: 1.0460  decode.d3.loss_cls: 0.9948  decode.d3.loss_mask: 0.7345  decode.d3.loss_dice: 0.9987  decode.d4.loss_cls: 0.9750  decode.d4.loss_mask: 0.7310  decode.d4.loss_dice: 1.0098  decode.d5.loss_cls: 0.9672  decode.d5.loss_mask: 0.7197  decode.d5.loss_dice: 1.0103  decode.d6.loss_cls: 0.9588  decode.d6.loss_mask: 0.7005  decode.d6.loss_dice: 0.9866  decode.d7.loss_cls: 0.9348  decode.d7.loss_mask: 0.6987  decode.d7.loss_dice: 0.9977  decode.d8.loss_cls: 0.9293  decode.d8.loss_mask: 0.6940  decode.d8.loss_dice: 0.9937
2023/05/24 12:57:32 - mmengine - INFO - Iter(train) [150450/160000]  lr: 7.9122e-07  eta: 1:09:02  time: 0.4362  data_time: 0.0101  memory: 4857  grad_norm: 90.2688  loss: 32.4717  decode.loss_cls: 0.9614  decode.loss_mask: 0.7781  decode.loss_dice: 1.2308  decode.d0.loss_cls: 2.8149  decode.d0.loss_mask: 0.7833  decode.d0.loss_dice: 1.4033  decode.d1.loss_cls: 1.0249  decode.d1.loss_mask: 0.8201  decode.d1.loss_dice: 1.3721  decode.d2.loss_cls: 1.0940  decode.d2.loss_mask: 0.7898  decode.d2.loss_dice: 1.2954  decode.d3.loss_cls: 1.0466  decode.d3.loss_mask: 0.7724  decode.d3.loss_dice: 1.2577  decode.d4.loss_cls: 0.9853  decode.d4.loss_mask: 0.7849  decode.d4.loss_dice: 1.2688  decode.d5.loss_cls: 0.9759  decode.d5.loss_mask: 0.7890  decode.d5.loss_dice: 1.2598  decode.d6.loss_cls: 1.0203  decode.d6.loss_mask: 0.7557  decode.d6.loss_dice: 1.2242  decode.d7.loss_cls: 0.9515  decode.d7.loss_mask: 0.7935  decode.d7.loss_dice: 1.2334  decode.d8.loss_cls: 1.0189  decode.d8.loss_mask: 0.7652  decode.d8.loss_dice: 1.2008
2023/05/24 12:57:53 - mmengine - INFO - Iter(train) [150500/160000]  lr: 7.8749e-07  eta: 1:08:41  time: 0.4292  data_time: 0.0103  memory: 4918  grad_norm: 125.0084  loss: 26.8617  decode.loss_cls: 0.8727  decode.loss_mask: 0.6570  decode.loss_dice: 0.8642  decode.d0.loss_cls: 2.7914  decode.d0.loss_mask: 0.6748  decode.d0.loss_dice: 1.0247  decode.d1.loss_cls: 1.0931  decode.d1.loss_mask: 0.6707  decode.d1.loss_dice: 0.9482  decode.d2.loss_cls: 0.9777  decode.d2.loss_mask: 0.6686  decode.d2.loss_dice: 0.8849  decode.d3.loss_cls: 1.0108  decode.d3.loss_mask: 0.6411  decode.d3.loss_dice: 0.8823  decode.d4.loss_cls: 0.9634  decode.d4.loss_mask: 0.6460  decode.d4.loss_dice: 0.8562  decode.d5.loss_cls: 0.9759  decode.d5.loss_mask: 0.6353  decode.d5.loss_dice: 0.8710  decode.d6.loss_cls: 0.8814  decode.d6.loss_mask: 0.6584  decode.d6.loss_dice: 0.8808  decode.d7.loss_cls: 0.8894  decode.d7.loss_mask: 0.6531  decode.d7.loss_dice: 0.8784  decode.d8.loss_cls: 0.8920  decode.d8.loss_mask: 0.6469  decode.d8.loss_dice: 0.8712
2023/05/24 12:58:15 - mmengine - INFO - Iter(train) [150550/160000]  lr: 7.8376e-07  eta: 1:08:19  time: 0.4233  data_time: 0.0098  memory: 4858  grad_norm: 73.7339  loss: 39.1450  decode.loss_cls: 1.2872  decode.loss_mask: 0.6775  decode.loss_dice: 1.5698  decode.d0.loss_cls: 3.3237  decode.d0.loss_mask: 0.7431  decode.d0.loss_dice: 1.8488  decode.d1.loss_cls: 1.4905  decode.d1.loss_mask: 0.7300  decode.d1.loss_dice: 1.6970  decode.d2.loss_cls: 1.4332  decode.d2.loss_mask: 0.7312  decode.d2.loss_dice: 1.6634  decode.d3.loss_cls: 1.3642  decode.d3.loss_mask: 0.7055  decode.d3.loss_dice: 1.6529  decode.d4.loss_cls: 1.4152  decode.d4.loss_mask: 0.6999  decode.d4.loss_dice: 1.6159  decode.d5.loss_cls: 1.3648  decode.d5.loss_mask: 0.6898  decode.d5.loss_dice: 1.6163  decode.d6.loss_cls: 1.3743  decode.d6.loss_mask: 0.6795  decode.d6.loss_dice: 1.6094  decode.d7.loss_cls: 1.3981  decode.d7.loss_mask: 0.6640  decode.d7.loss_dice: 1.5698  decode.d8.loss_cls: 1.2575  decode.d8.loss_mask: 0.6850  decode.d8.loss_dice: 1.5871
2023/05/24 12:58:37 - mmengine - INFO - Iter(train) [150600/160000]  lr: 7.8003e-07  eta: 1:07:57  time: 0.4286  data_time: 0.0102  memory: 4837  grad_norm: 116.6082  loss: 31.9000  decode.loss_cls: 1.0161  decode.loss_mask: 0.7400  decode.loss_dice: 1.1345  decode.d0.loss_cls: 3.0308  decode.d0.loss_mask: 0.8938  decode.d0.loss_dice: 1.3607  decode.d1.loss_cls: 1.1784  decode.d1.loss_mask: 0.8168  decode.d1.loss_dice: 1.2495  decode.d2.loss_cls: 1.0713  decode.d2.loss_mask: 0.7794  decode.d2.loss_dice: 1.1855  decode.d3.loss_cls: 1.1312  decode.d3.loss_mask: 0.7360  decode.d3.loss_dice: 1.1236  decode.d4.loss_cls: 1.0763  decode.d4.loss_mask: 0.7352  decode.d4.loss_dice: 1.1108  decode.d5.loss_cls: 1.0509  decode.d5.loss_mask: 0.7153  decode.d5.loss_dice: 1.1239  decode.d6.loss_cls: 1.0555  decode.d6.loss_mask: 0.7075  decode.d6.loss_dice: 1.1161  decode.d7.loss_cls: 1.0349  decode.d7.loss_mask: 0.7109  decode.d7.loss_dice: 1.1176  decode.d8.loss_cls: 1.0610  decode.d8.loss_mask: 0.7110  decode.d8.loss_dice: 1.1252
2023/05/24 12:59:00 - mmengine - INFO - Iter(train) [150650/160000]  lr: 7.7629e-07  eta: 1:07:36  time: 0.4805  data_time: 0.0102  memory: 4951  grad_norm: 89.0580  loss: 30.8697  decode.loss_cls: 1.1049  decode.loss_mask: 0.6718  decode.loss_dice: 0.9345  decode.d0.loss_cls: 3.3684  decode.d0.loss_mask: 0.7294  decode.d0.loss_dice: 1.1725  decode.d1.loss_cls: 1.2976  decode.d1.loss_mask: 0.7342  decode.d1.loss_dice: 1.0664  decode.d2.loss_cls: 1.2037  decode.d2.loss_mask: 0.8033  decode.d2.loss_dice: 1.0303  decode.d3.loss_cls: 1.1865  decode.d3.loss_mask: 0.6981  decode.d3.loss_dice: 1.0060  decode.d4.loss_cls: 1.1081  decode.d4.loss_mask: 0.7420  decode.d4.loss_dice: 0.9642  decode.d5.loss_cls: 1.0680  decode.d5.loss_mask: 0.7221  decode.d5.loss_dice: 1.0055  decode.d6.loss_cls: 1.1151  decode.d6.loss_mask: 0.6945  decode.d6.loss_dice: 0.9522  decode.d7.loss_cls: 1.0749  decode.d7.loss_mask: 0.7092  decode.d7.loss_dice: 1.0017  decode.d8.loss_cls: 1.0903  decode.d8.loss_mask: 0.6756  decode.d8.loss_dice: 0.9385
2023/05/24 12:59:24 - mmengine - INFO - Iter(train) [150700/160000]  lr: 7.7255e-07  eta: 1:07:14  time: 0.4807  data_time: 0.0107  memory: 4871  grad_norm: 98.9956  loss: 34.2547  decode.loss_cls: 0.9766  decode.loss_mask: 0.9295  decode.loss_dice: 1.2757  decode.d0.loss_cls: 2.7100  decode.d0.loss_mask: 0.9795  decode.d0.loss_dice: 1.4336  decode.d1.loss_cls: 1.0442  decode.d1.loss_mask: 1.0162  decode.d1.loss_dice: 1.4421  decode.d2.loss_cls: 1.0581  decode.d2.loss_mask: 0.9653  decode.d2.loss_dice: 1.3453  decode.d3.loss_cls: 1.0044  decode.d3.loss_mask: 0.9512  decode.d3.loss_dice: 1.2719  decode.d4.loss_cls: 0.9883  decode.d4.loss_mask: 0.9242  decode.d4.loss_dice: 1.2617  decode.d5.loss_cls: 0.9569  decode.d5.loss_mask: 0.9456  decode.d5.loss_dice: 1.2513  decode.d6.loss_cls: 1.0195  decode.d6.loss_mask: 0.8972  decode.d6.loss_dice: 1.2669  decode.d7.loss_cls: 1.0130  decode.d7.loss_mask: 0.9054  decode.d7.loss_dice: 1.2753  decode.d8.loss_cls: 0.9467  decode.d8.loss_mask: 0.9282  decode.d8.loss_dice: 1.2706
2023/05/24 12:59:46 - mmengine - INFO - Iter(train) [150750/160000]  lr: 7.6882e-07  eta: 1:06:53  time: 0.4285  data_time: 0.0097  memory: 4832  grad_norm: 95.8502  loss: 29.8058  decode.loss_cls: 0.9244  decode.loss_mask: 0.6621  decode.loss_dice: 1.1102  decode.d0.loss_cls: 2.7534  decode.d0.loss_mask: 0.7436  decode.d0.loss_dice: 1.2487  decode.d1.loss_cls: 0.9869  decode.d1.loss_mask: 0.7182  decode.d1.loss_dice: 1.2357  decode.d2.loss_cls: 0.9794  decode.d2.loss_mask: 0.7454  decode.d2.loss_dice: 1.2037  decode.d3.loss_cls: 0.8706  decode.d3.loss_mask: 0.7072  decode.d3.loss_dice: 1.1633  decode.d4.loss_cls: 0.9083  decode.d4.loss_mask: 0.6902  decode.d4.loss_dice: 1.1435  decode.d5.loss_cls: 0.9146  decode.d5.loss_mask: 0.6856  decode.d5.loss_dice: 1.1682  decode.d6.loss_cls: 0.9275  decode.d6.loss_mask: 0.6734  decode.d6.loss_dice: 1.1304  decode.d7.loss_cls: 0.9714  decode.d7.loss_mask: 0.6570  decode.d7.loss_dice: 1.1381  decode.d8.loss_cls: 0.8970  decode.d8.loss_mask: 0.6728  decode.d8.loss_dice: 1.1748
2023/05/24 13:00:07 - mmengine - INFO - Iter(train) [150800/160000]  lr: 7.6507e-07  eta: 1:06:31  time: 0.4326  data_time: 0.0099  memory: 4865  grad_norm: 100.1503  loss: 30.8181  decode.loss_cls: 0.9502  decode.loss_mask: 0.7636  decode.loss_dice: 1.0328  decode.d0.loss_cls: 3.1060  decode.d0.loss_mask: 0.8091  decode.d0.loss_dice: 1.2358  decode.d1.loss_cls: 1.0806  decode.d1.loss_mask: 0.8597  decode.d1.loss_dice: 1.1362  decode.d2.loss_cls: 1.0797  decode.d2.loss_mask: 0.8037  decode.d2.loss_dice: 1.0753  decode.d3.loss_cls: 1.0149  decode.d3.loss_mask: 0.8022  decode.d3.loss_dice: 1.0672  decode.d4.loss_cls: 1.0118  decode.d4.loss_mask: 0.7909  decode.d4.loss_dice: 1.0519  decode.d5.loss_cls: 0.9439  decode.d5.loss_mask: 0.7832  decode.d5.loss_dice: 1.0514  decode.d6.loss_cls: 1.0199  decode.d6.loss_mask: 0.7582  decode.d6.loss_dice: 1.0362  decode.d7.loss_cls: 0.9655  decode.d7.loss_mask: 0.7616  decode.d7.loss_dice: 1.0411  decode.d8.loss_cls: 0.9639  decode.d8.loss_mask: 0.7600  decode.d8.loss_dice: 1.0614
2023/05/24 13:00:29 - mmengine - INFO - Iter(train) [150850/160000]  lr: 7.6133e-07  eta: 1:06:09  time: 0.4218  data_time: 0.0105  memory: 4864  grad_norm: 100.6388  loss: 33.5208  decode.loss_cls: 1.0869  decode.loss_mask: 0.8039  decode.loss_dice: 1.1757  decode.d0.loss_cls: 3.1524  decode.d0.loss_mask: 0.7360  decode.d0.loss_dice: 1.4135  decode.d1.loss_cls: 1.2675  decode.d1.loss_mask: 0.7659  decode.d1.loss_dice: 1.2672  decode.d2.loss_cls: 1.1625  decode.d2.loss_mask: 0.7779  decode.d2.loss_dice: 1.2105  decode.d3.loss_cls: 1.1745  decode.d3.loss_mask: 0.7526  decode.d3.loss_dice: 1.1780  decode.d4.loss_cls: 1.1580  decode.d4.loss_mask: 0.7987  decode.d4.loss_dice: 1.1767  decode.d5.loss_cls: 1.1748  decode.d5.loss_mask: 0.7896  decode.d5.loss_dice: 1.1735  decode.d6.loss_cls: 1.1694  decode.d6.loss_mask: 0.7929  decode.d6.loss_dice: 1.1792  decode.d7.loss_cls: 1.1228  decode.d7.loss_mask: 0.7994  decode.d7.loss_dice: 1.1789  decode.d8.loss_cls: 1.0860  decode.d8.loss_mask: 0.7959  decode.d8.loss_dice: 1.2001
2023/05/24 13:00:50 - mmengine - INFO - Iter(train) [150900/160000]  lr: 7.5759e-07  eta: 1:05:47  time: 0.4146  data_time: 0.0102  memory: 4896  grad_norm: 103.7288  loss: 27.5138  decode.loss_cls: 0.9807  decode.loss_mask: 0.6591  decode.loss_dice: 0.8688  decode.d0.loss_cls: 2.7625  decode.d0.loss_mask: 0.7125  decode.d0.loss_dice: 1.0071  decode.d1.loss_cls: 1.0769  decode.d1.loss_mask: 0.7088  decode.d1.loss_dice: 0.9475  decode.d2.loss_cls: 0.9862  decode.d2.loss_mask: 0.6711  decode.d2.loss_dice: 0.9100  decode.d3.loss_cls: 0.9769  decode.d3.loss_mask: 0.6635  decode.d3.loss_dice: 0.9167  decode.d4.loss_cls: 0.9912  decode.d4.loss_mask: 0.6598  decode.d4.loss_dice: 0.8969  decode.d5.loss_cls: 0.9542  decode.d5.loss_mask: 0.6767  decode.d5.loss_dice: 0.9087  decode.d6.loss_cls: 0.9679  decode.d6.loss_mask: 0.6684  decode.d6.loss_dice: 0.8954  decode.d7.loss_cls: 0.9501  decode.d7.loss_mask: 0.6665  decode.d7.loss_dice: 0.8909  decode.d8.loss_cls: 0.9833  decode.d8.loss_mask: 0.6656  decode.d8.loss_dice: 0.8897
2023/05/24 13:01:12 - mmengine - INFO - Iter(train) [150950/160000]  lr: 7.5384e-07  eta: 1:05:26  time: 0.4148  data_time: 0.0097  memory: 4827  grad_norm: 83.3378  loss: 34.9731  decode.loss_cls: 1.1457  decode.loss_mask: 0.8063  decode.loss_dice: 1.3248  decode.d0.loss_cls: 2.9973  decode.d0.loss_mask: 0.8015  decode.d0.loss_dice: 1.5205  decode.d1.loss_cls: 1.2809  decode.d1.loss_mask: 0.8097  decode.d1.loss_dice: 1.4498  decode.d2.loss_cls: 1.2064  decode.d2.loss_mask: 0.7945  decode.d2.loss_dice: 1.3807  decode.d3.loss_cls: 1.1652  decode.d3.loss_mask: 0.7776  decode.d3.loss_dice: 1.3320  decode.d4.loss_cls: 1.0988  decode.d4.loss_mask: 0.7813  decode.d4.loss_dice: 1.3626  decode.d5.loss_cls: 1.1064  decode.d5.loss_mask: 0.8277  decode.d5.loss_dice: 1.3548  decode.d6.loss_cls: 1.1003  decode.d6.loss_mask: 0.7795  decode.d6.loss_dice: 1.3182  decode.d7.loss_cls: 1.1225  decode.d7.loss_mask: 0.7853  decode.d7.loss_dice: 1.3070  decode.d8.loss_cls: 1.0961  decode.d8.loss_mask: 0.8157  decode.d8.loss_dice: 1.3239
2023/05/24 13:01:34 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 13:01:34 - mmengine - INFO - Iter(train) [151000/160000]  lr: 7.5009e-07  eta: 1:05:04  time: 0.4229  data_time: 0.0104  memory: 4875  grad_norm: 97.7066  loss: 32.4877  decode.loss_cls: 1.2870  decode.loss_mask: 0.7459  decode.loss_dice: 0.9385  decode.d0.loss_cls: 2.9661  decode.d0.loss_mask: 0.8532  decode.d0.loss_dice: 1.1030  decode.d1.loss_cls: 1.3943  decode.d1.loss_mask: 0.8247  decode.d1.loss_dice: 1.0478  decode.d2.loss_cls: 1.3898  decode.d2.loss_mask: 0.8262  decode.d2.loss_dice: 1.0099  decode.d3.loss_cls: 1.3942  decode.d3.loss_mask: 0.7808  decode.d3.loss_dice: 0.9573  decode.d4.loss_cls: 1.3265  decode.d4.loss_mask: 0.7496  decode.d4.loss_dice: 0.9590  decode.d5.loss_cls: 1.3482  decode.d5.loss_mask: 0.7336  decode.d5.loss_dice: 0.9194  decode.d6.loss_cls: 1.3116  decode.d6.loss_mask: 0.7378  decode.d6.loss_dice: 0.9401  decode.d7.loss_cls: 1.3336  decode.d7.loss_mask: 0.7408  decode.d7.loss_dice: 0.9403  decode.d8.loss_cls: 1.2599  decode.d8.loss_mask: 0.7444  decode.d8.loss_dice: 0.9243
2023/05/24 13:01:34 - mmengine - INFO - Saving checkpoint at 151000 iterations
2023/05/24 13:02:01 - mmengine - INFO - Iter(train) [151050/160000]  lr: 7.4634e-07  eta: 1:04:43  time: 0.4357  data_time: 0.0104  memory: 4873  grad_norm: 88.9683  loss: 30.3183  decode.loss_cls: 1.0453  decode.loss_mask: 0.7050  decode.loss_dice: 1.0406  decode.d0.loss_cls: 2.7756  decode.d0.loss_mask: 0.7755  decode.d0.loss_dice: 1.2538  decode.d1.loss_cls: 1.0261  decode.d1.loss_mask: 0.7686  decode.d1.loss_dice: 1.1308  decode.d2.loss_cls: 1.0207  decode.d2.loss_mask: 0.7698  decode.d2.loss_dice: 1.0938  decode.d3.loss_cls: 1.0100  decode.d3.loss_mask: 0.7290  decode.d3.loss_dice: 1.0873  decode.d4.loss_cls: 0.9984  decode.d4.loss_mask: 0.7561  decode.d4.loss_dice: 1.0778  decode.d5.loss_cls: 1.0266  decode.d5.loss_mask: 0.7454  decode.d5.loss_dice: 1.0721  decode.d6.loss_cls: 1.0101  decode.d6.loss_mask: 0.7247  decode.d6.loss_dice: 1.0415  decode.d7.loss_cls: 1.0080  decode.d7.loss_mask: 0.7389  decode.d7.loss_dice: 1.0732  decode.d8.loss_cls: 1.0558  decode.d8.loss_mask: 0.7340  decode.d8.loss_dice: 1.0239
2023/05/24 13:02:22 - mmengine - INFO - Iter(train) [151100/160000]  lr: 7.4258e-07  eta: 1:04:21  time: 0.4207  data_time: 0.0099  memory: 4829  grad_norm: 79.1115  loss: 26.7140  decode.loss_cls: 0.9780  decode.loss_mask: 0.5110  decode.loss_dice: 0.9039  decode.d0.loss_cls: 2.7935  decode.d0.loss_mask: 0.5599  decode.d0.loss_dice: 1.0310  decode.d1.loss_cls: 1.0933  decode.d1.loss_mask: 0.5811  decode.d1.loss_dice: 1.0359  decode.d2.loss_cls: 1.0514  decode.d2.loss_mask: 0.5468  decode.d2.loss_dice: 0.9910  decode.d3.loss_cls: 1.0875  decode.d3.loss_mask: 0.5077  decode.d3.loss_dice: 0.9079  decode.d4.loss_cls: 1.0421  decode.d4.loss_mask: 0.5258  decode.d4.loss_dice: 0.9241  decode.d5.loss_cls: 1.0560  decode.d5.loss_mask: 0.5250  decode.d5.loss_dice: 0.8758  decode.d6.loss_cls: 1.0731  decode.d6.loss_mask: 0.4909  decode.d6.loss_dice: 0.8678  decode.d7.loss_cls: 0.9855  decode.d7.loss_mask: 0.5108  decode.d7.loss_dice: 0.8792  decode.d8.loss_cls: 0.9881  decode.d8.loss_mask: 0.5019  decode.d8.loss_dice: 0.8878
2023/05/24 13:02:44 - mmengine - INFO - Iter(train) [151150/160000]  lr: 7.3883e-07  eta: 1:03:59  time: 0.4293  data_time: 0.0104  memory: 4860  grad_norm: 91.2567  loss: 37.5167  decode.loss_cls: 1.2561  decode.loss_mask: 0.8996  decode.loss_dice: 1.3148  decode.d0.loss_cls: 3.1929  decode.d0.loss_mask: 0.9734  decode.d0.loss_dice: 1.5631  decode.d1.loss_cls: 1.3672  decode.d1.loss_mask: 0.9156  decode.d1.loss_dice: 1.4083  decode.d2.loss_cls: 1.3562  decode.d2.loss_mask: 0.9052  decode.d2.loss_dice: 1.3732  decode.d3.loss_cls: 1.2722  decode.d3.loss_mask: 0.9251  decode.d3.loss_dice: 1.3373  decode.d4.loss_cls: 1.3012  decode.d4.loss_mask: 0.8709  decode.d4.loss_dice: 1.3529  decode.d5.loss_cls: 1.3010  decode.d5.loss_mask: 0.8673  decode.d5.loss_dice: 1.3301  decode.d6.loss_cls: 1.2397  decode.d6.loss_mask: 0.9154  decode.d6.loss_dice: 1.3511  decode.d7.loss_cls: 1.2477  decode.d7.loss_mask: 0.8862  decode.d7.loss_dice: 1.3294  decode.d8.loss_cls: 1.2405  decode.d8.loss_mask: 0.8924  decode.d8.loss_dice: 1.3309
2023/05/24 13:03:06 - mmengine - INFO - Iter(train) [151200/160000]  lr: 7.3507e-07  eta: 1:03:38  time: 0.4255  data_time: 0.0099  memory: 4808  grad_norm: 88.5195  loss: 27.1556  decode.loss_cls: 0.8369  decode.loss_mask: 0.6402  decode.loss_dice: 0.9605  decode.d0.loss_cls: 2.7026  decode.d0.loss_mask: 0.6647  decode.d0.loss_dice: 1.1042  decode.d1.loss_cls: 0.9354  decode.d1.loss_mask: 0.6417  decode.d1.loss_dice: 1.0972  decode.d2.loss_cls: 0.8732  decode.d2.loss_mask: 0.6652  decode.d2.loss_dice: 1.0522  decode.d3.loss_cls: 0.8869  decode.d3.loss_mask: 0.6585  decode.d3.loss_dice: 1.0063  decode.d4.loss_cls: 0.8649  decode.d4.loss_mask: 0.6505  decode.d4.loss_dice: 1.0135  decode.d5.loss_cls: 0.8994  decode.d5.loss_mask: 0.6380  decode.d5.loss_dice: 0.9789  decode.d6.loss_cls: 0.8413  decode.d6.loss_mask: 0.6490  decode.d6.loss_dice: 0.9586  decode.d7.loss_cls: 0.8410  decode.d7.loss_mask: 0.6542  decode.d7.loss_dice: 0.9804  decode.d8.loss_cls: 0.8287  decode.d8.loss_mask: 0.6464  decode.d8.loss_dice: 0.9850
2023/05/24 13:03:28 - mmengine - INFO - Iter(train) [151250/160000]  lr: 7.3131e-07  eta: 1:03:16  time: 0.4353  data_time: 0.0100  memory: 4866  grad_norm: 95.2268  loss: 35.5612  decode.loss_cls: 1.1271  decode.loss_mask: 0.7615  decode.loss_dice: 1.3862  decode.d0.loss_cls: 3.1273  decode.d0.loss_mask: 0.8177  decode.d0.loss_dice: 1.6612  decode.d1.loss_cls: 1.2105  decode.d1.loss_mask: 0.8053  decode.d1.loss_dice: 1.4838  decode.d2.loss_cls: 1.2352  decode.d2.loss_mask: 0.7716  decode.d2.loss_dice: 1.4106  decode.d3.loss_cls: 1.1683  decode.d3.loss_mask: 0.7572  decode.d3.loss_dice: 1.3700  decode.d4.loss_cls: 1.1358  decode.d4.loss_mask: 0.7616  decode.d4.loss_dice: 1.3993  decode.d5.loss_cls: 1.1393  decode.d5.loss_mask: 0.7688  decode.d5.loss_dice: 1.3790  decode.d6.loss_cls: 1.1356  decode.d6.loss_mask: 0.7759  decode.d6.loss_dice: 1.3829  decode.d7.loss_cls: 1.1327  decode.d7.loss_mask: 0.7658  decode.d7.loss_dice: 1.4051  decode.d8.loss_cls: 1.1469  decode.d8.loss_mask: 0.7586  decode.d8.loss_dice: 1.3804
2023/05/24 13:03:49 - mmengine - INFO - Iter(train) [151300/160000]  lr: 7.2755e-07  eta: 1:02:54  time: 0.4307  data_time: 0.0102  memory: 4826  grad_norm: 99.8944  loss: 41.3338  decode.loss_cls: 1.2600  decode.loss_mask: 0.9135  decode.loss_dice: 1.5944  decode.d0.loss_cls: 3.4133  decode.d0.loss_mask: 1.0445  decode.d0.loss_dice: 1.8300  decode.d1.loss_cls: 1.5625  decode.d1.loss_mask: 1.0070  decode.d1.loss_dice: 1.7191  decode.d2.loss_cls: 1.2935  decode.d2.loss_mask: 0.9929  decode.d2.loss_dice: 1.6843  decode.d3.loss_cls: 1.3499  decode.d3.loss_mask: 0.9551  decode.d3.loss_dice: 1.6403  decode.d4.loss_cls: 1.2478  decode.d4.loss_mask: 0.9655  decode.d4.loss_dice: 1.6054  decode.d5.loss_cls: 1.3244  decode.d5.loss_mask: 0.9282  decode.d5.loss_dice: 1.6136  decode.d6.loss_cls: 1.3141  decode.d6.loss_mask: 0.9117  decode.d6.loss_dice: 1.5909  decode.d7.loss_cls: 1.2890  decode.d7.loss_mask: 0.9248  decode.d7.loss_dice: 1.5765  decode.d8.loss_cls: 1.2919  decode.d8.loss_mask: 0.9239  decode.d8.loss_dice: 1.5658
2023/05/24 13:04:12 - mmengine - INFO - Iter(train) [151350/160000]  lr: 7.2378e-07  eta: 1:02:32  time: 0.4838  data_time: 0.0098  memory: 4823  grad_norm: 84.9508  loss: 45.0053  decode.loss_cls: 1.4577  decode.loss_mask: 0.9515  decode.loss_dice: 1.7762  decode.d0.loss_cls: 3.4749  decode.d0.loss_mask: 1.0570  decode.d0.loss_dice: 2.1144  decode.d1.loss_cls: 1.6133  decode.d1.loss_mask: 0.9917  decode.d1.loss_dice: 1.9563  decode.d2.loss_cls: 1.5425  decode.d2.loss_mask: 0.9837  decode.d2.loss_dice: 1.8758  decode.d3.loss_cls: 1.5445  decode.d3.loss_mask: 0.9475  decode.d3.loss_dice: 1.7854  decode.d4.loss_cls: 1.5396  decode.d4.loss_mask: 0.9316  decode.d4.loss_dice: 1.7996  decode.d5.loss_cls: 1.4262  decode.d5.loss_mask: 0.9496  decode.d5.loss_dice: 1.7884  decode.d6.loss_cls: 1.4426  decode.d6.loss_mask: 0.9426  decode.d6.loss_dice: 1.7645  decode.d7.loss_cls: 1.4606  decode.d7.loss_mask: 0.9429  decode.d7.loss_dice: 1.7346  decode.d8.loss_cls: 1.4705  decode.d8.loss_mask: 0.9515  decode.d8.loss_dice: 1.7881
2023/05/24 13:04:34 - mmengine - INFO - Iter(train) [151400/160000]  lr: 7.2002e-07  eta: 1:02:11  time: 0.4216  data_time: 0.0102  memory: 4878  grad_norm: 114.8907  loss: 39.3045  decode.loss_cls: 1.1598  decode.loss_mask: 0.9859  decode.loss_dice: 1.5017  decode.d0.loss_cls: 3.2400  decode.d0.loss_mask: 1.0087  decode.d0.loss_dice: 1.6843  decode.d1.loss_cls: 1.2423  decode.d1.loss_mask: 0.9947  decode.d1.loss_dice: 1.6962  decode.d2.loss_cls: 1.1986  decode.d2.loss_mask: 0.9832  decode.d2.loss_dice: 1.6054  decode.d3.loss_cls: 1.2057  decode.d3.loss_mask: 0.9674  decode.d3.loss_dice: 1.5372  decode.d4.loss_cls: 1.2028  decode.d4.loss_mask: 0.9317  decode.d4.loss_dice: 1.5035  decode.d5.loss_cls: 1.1323  decode.d5.loss_mask: 0.9781  decode.d5.loss_dice: 1.5260  decode.d6.loss_cls: 1.1484  decode.d6.loss_mask: 0.9877  decode.d6.loss_dice: 1.5249  decode.d7.loss_cls: 1.1411  decode.d7.loss_mask: 1.0055  decode.d7.loss_dice: 1.5477  decode.d8.loss_cls: 1.1677  decode.d8.loss_mask: 0.9899  decode.d8.loss_dice: 1.5060
2023/05/24 13:04:55 - mmengine - INFO - Iter(train) [151450/160000]  lr: 7.1625e-07  eta: 1:01:49  time: 0.4254  data_time: 0.0100  memory: 4824  grad_norm: 104.4461  loss: 33.7580  decode.loss_cls: 1.1150  decode.loss_mask: 0.8985  decode.loss_dice: 1.1075  decode.d0.loss_cls: 2.9499  decode.d0.loss_mask: 0.9144  decode.d0.loss_dice: 1.2990  decode.d1.loss_cls: 1.1983  decode.d1.loss_mask: 0.9594  decode.d1.loss_dice: 1.2161  decode.d2.loss_cls: 1.2153  decode.d2.loss_mask: 0.9031  decode.d2.loss_dice: 1.1503  decode.d3.loss_cls: 1.1744  decode.d3.loss_mask: 0.8969  decode.d3.loss_dice: 1.0990  decode.d4.loss_cls: 1.1672  decode.d4.loss_mask: 0.8649  decode.d4.loss_dice: 1.1268  decode.d5.loss_cls: 1.1828  decode.d5.loss_mask: 0.8692  decode.d5.loss_dice: 1.1042  decode.d6.loss_cls: 1.2036  decode.d6.loss_mask: 0.8266  decode.d6.loss_dice: 1.0791  decode.d7.loss_cls: 1.1606  decode.d7.loss_mask: 0.8796  decode.d7.loss_dice: 1.0934  decode.d8.loss_cls: 1.1046  decode.d8.loss_mask: 0.8910  decode.d8.loss_dice: 1.1072
2023/05/24 13:05:17 - mmengine - INFO - Iter(train) [151500/160000]  lr: 7.1248e-07  eta: 1:01:27  time: 0.4745  data_time: 0.0101  memory: 4837  grad_norm: 107.7259  loss: 34.5223  decode.loss_cls: 1.0939  decode.loss_mask: 0.8062  decode.loss_dice: 1.2683  decode.d0.loss_cls: 2.7263  decode.d0.loss_mask: 0.9064  decode.d0.loss_dice: 1.5989  decode.d1.loss_cls: 1.1966  decode.d1.loss_mask: 0.8713  decode.d1.loss_dice: 1.4122  decode.d2.loss_cls: 1.1589  decode.d2.loss_mask: 0.8368  decode.d2.loss_dice: 1.3123  decode.d3.loss_cls: 1.1352  decode.d3.loss_mask: 0.8359  decode.d3.loss_dice: 1.3186  decode.d4.loss_cls: 1.0972  decode.d4.loss_mask: 0.8372  decode.d4.loss_dice: 1.3017  decode.d5.loss_cls: 1.0797  decode.d5.loss_mask: 0.8425  decode.d5.loss_dice: 1.3267  decode.d6.loss_cls: 1.0934  decode.d6.loss_mask: 0.7996  decode.d6.loss_dice: 1.2893  decode.d7.loss_cls: 1.1251  decode.d7.loss_mask: 0.7944  decode.d7.loss_dice: 1.2504  decode.d8.loss_cls: 1.1182  decode.d8.loss_mask: 0.7917  decode.d8.loss_dice: 1.2975
2023/05/24 13:05:39 - mmengine - INFO - Iter(train) [151550/160000]  lr: 7.0870e-07  eta: 1:01:06  time: 0.4145  data_time: 0.0100  memory: 4884  grad_norm: 100.3031  loss: 31.8165  decode.loss_cls: 1.2435  decode.loss_mask: 0.6672  decode.loss_dice: 0.9787  decode.d0.loss_cls: 3.1485  decode.d0.loss_mask: 0.7088  decode.d0.loss_dice: 1.1608  decode.d1.loss_cls: 1.3216  decode.d1.loss_mask: 0.7236  decode.d1.loss_dice: 1.0884  decode.d2.loss_cls: 1.2684  decode.d2.loss_mask: 0.7341  decode.d2.loss_dice: 1.0720  decode.d3.loss_cls: 1.2862  decode.d3.loss_mask: 0.6640  decode.d3.loss_dice: 1.0559  decode.d4.loss_cls: 1.2362  decode.d4.loss_mask: 0.7226  decode.d4.loss_dice: 1.0368  decode.d5.loss_cls: 1.2902  decode.d5.loss_mask: 0.6629  decode.d5.loss_dice: 0.9926  decode.d6.loss_cls: 1.2287  decode.d6.loss_mask: 0.7055  decode.d6.loss_dice: 1.0137  decode.d7.loss_cls: 1.1877  decode.d7.loss_mask: 0.7033  decode.d7.loss_dice: 1.0236  decode.d8.loss_cls: 1.2451  decode.d8.loss_mask: 0.6641  decode.d8.loss_dice: 0.9818
2023/05/24 13:06:01 - mmengine - INFO - Iter(train) [151600/160000]  lr: 7.0493e-07  eta: 1:00:44  time: 0.4258  data_time: 0.0101  memory: 4866  grad_norm: 107.0175  loss: 36.1604  decode.loss_cls: 1.2806  decode.loss_mask: 0.7683  decode.loss_dice: 1.2288  decode.d0.loss_cls: 3.1890  decode.d0.loss_mask: 0.8455  decode.d0.loss_dice: 1.4583  decode.d1.loss_cls: 1.4654  decode.d1.loss_mask: 0.7916  decode.d1.loss_dice: 1.3388  decode.d2.loss_cls: 1.4183  decode.d2.loss_mask: 0.7839  decode.d2.loss_dice: 1.2923  decode.d3.loss_cls: 1.3292  decode.d3.loss_mask: 0.7810  decode.d3.loss_dice: 1.2819  decode.d4.loss_cls: 1.4032  decode.d4.loss_mask: 0.7674  decode.d4.loss_dice: 1.2420  decode.d5.loss_cls: 1.3332  decode.d5.loss_mask: 0.8191  decode.d5.loss_dice: 1.2838  decode.d6.loss_cls: 1.3556  decode.d6.loss_mask: 0.7974  decode.d6.loss_dice: 1.2215  decode.d7.loss_cls: 1.3270  decode.d7.loss_mask: 0.7660  decode.d7.loss_dice: 1.2565  decode.d8.loss_cls: 1.3178  decode.d8.loss_mask: 0.7667  decode.d8.loss_dice: 1.2503
2023/05/24 13:06:24 - mmengine - INFO - Iter(train) [151650/160000]  lr: 7.0115e-07  eta: 1:00:22  time: 0.4746  data_time: 0.0109  memory: 4895  grad_norm: 133.3720  loss: 35.4220  decode.loss_cls: 1.1234  decode.loss_mask: 0.8042  decode.loss_dice: 1.2578  decode.d0.loss_cls: 3.2497  decode.d0.loss_mask: 0.8318  decode.d0.loss_dice: 1.5487  decode.d1.loss_cls: 1.3195  decode.d1.loss_mask: 0.8419  decode.d1.loss_dice: 1.4392  decode.d2.loss_cls: 1.2594  decode.d2.loss_mask: 0.7723  decode.d2.loss_dice: 1.3287  decode.d3.loss_cls: 1.2331  decode.d3.loss_mask: 0.8062  decode.d3.loss_dice: 1.3470  decode.d4.loss_cls: 1.1525  decode.d4.loss_mask: 0.8023  decode.d4.loss_dice: 1.3528  decode.d5.loss_cls: 1.1954  decode.d5.loss_mask: 0.7956  decode.d5.loss_dice: 1.3172  decode.d6.loss_cls: 1.1429  decode.d6.loss_mask: 0.8065  decode.d6.loss_dice: 1.2554  decode.d7.loss_cls: 1.1511  decode.d7.loss_mask: 0.8085  decode.d7.loss_dice: 1.2919  decode.d8.loss_cls: 1.1701  decode.d8.loss_mask: 0.7873  decode.d8.loss_dice: 1.2296
2023/05/24 13:06:45 - mmengine - INFO - Iter(train) [151700/160000]  lr: 6.9737e-07  eta: 1:00:01  time: 0.4221  data_time: 0.0100  memory: 4906  grad_norm: 112.0989  loss: 31.8199  decode.loss_cls: 1.0521  decode.loss_mask: 0.7957  decode.loss_dice: 1.0511  decode.d0.loss_cls: 3.0933  decode.d0.loss_mask: 0.7448  decode.d0.loss_dice: 1.2945  decode.d1.loss_cls: 1.2575  decode.d1.loss_mask: 0.7909  decode.d1.loss_dice: 1.1456  decode.d2.loss_cls: 1.1928  decode.d2.loss_mask: 0.8180  decode.d2.loss_dice: 1.1058  decode.d3.loss_cls: 1.1106  decode.d3.loss_mask: 0.7795  decode.d3.loss_dice: 1.0377  decode.d4.loss_cls: 1.0571  decode.d4.loss_mask: 0.7885  decode.d4.loss_dice: 1.0446  decode.d5.loss_cls: 1.1206  decode.d5.loss_mask: 0.7918  decode.d5.loss_dice: 1.0207  decode.d6.loss_cls: 1.1062  decode.d6.loss_mask: 0.8048  decode.d6.loss_dice: 1.0400  decode.d7.loss_cls: 1.0434  decode.d7.loss_mask: 0.7954  decode.d7.loss_dice: 1.0524  decode.d8.loss_cls: 1.0351  decode.d8.loss_mask: 0.8013  decode.d8.loss_dice: 1.0483
2023/05/24 13:07:06 - mmengine - INFO - Iter(train) [151750/160000]  lr: 6.9359e-07  eta: 0:59:39  time: 0.4251  data_time: 0.0100  memory: 4889  grad_norm: 79.6165  loss: 35.7789  decode.loss_cls: 1.1218  decode.loss_mask: 0.7925  decode.loss_dice: 1.3735  decode.d0.loss_cls: 3.0783  decode.d0.loss_mask: 0.8968  decode.d0.loss_dice: 1.5839  decode.d1.loss_cls: 1.2965  decode.d1.loss_mask: 0.8387  decode.d1.loss_dice: 1.4861  decode.d2.loss_cls: 1.1581  decode.d2.loss_mask: 0.8455  decode.d2.loss_dice: 1.4245  decode.d3.loss_cls: 1.0648  decode.d3.loss_mask: 0.8480  decode.d3.loss_dice: 1.4007  decode.d4.loss_cls: 1.1211  decode.d4.loss_mask: 0.8322  decode.d4.loss_dice: 1.4013  decode.d5.loss_cls: 1.0969  decode.d5.loss_mask: 0.8189  decode.d5.loss_dice: 1.4066  decode.d6.loss_cls: 1.1222  decode.d6.loss_mask: 0.8135  decode.d6.loss_dice: 1.3889  decode.d7.loss_cls: 1.0732  decode.d7.loss_mask: 0.8183  decode.d7.loss_dice: 1.3677  decode.d8.loss_cls: 1.1360  decode.d8.loss_mask: 0.8146  decode.d8.loss_dice: 1.3578
2023/05/24 13:07:28 - mmengine - INFO - Iter(train) [151800/160000]  lr: 6.8981e-07  eta: 0:59:17  time: 0.4245  data_time: 0.0107  memory: 4889  grad_norm: 93.6994  loss: 35.4754  decode.loss_cls: 1.1215  decode.loss_mask: 0.7749  decode.loss_dice: 1.3456  decode.d0.loss_cls: 3.2093  decode.d0.loss_mask: 0.7881  decode.d0.loss_dice: 1.6816  decode.d1.loss_cls: 1.2017  decode.d1.loss_mask: 0.8076  decode.d1.loss_dice: 1.4790  decode.d2.loss_cls: 1.2243  decode.d2.loss_mask: 0.7604  decode.d2.loss_dice: 1.3931  decode.d3.loss_cls: 1.1509  decode.d3.loss_mask: 0.7584  decode.d3.loss_dice: 1.3719  decode.d4.loss_cls: 1.1853  decode.d4.loss_mask: 0.7698  decode.d4.loss_dice: 1.4078  decode.d5.loss_cls: 1.1142  decode.d5.loss_mask: 0.7781  decode.d5.loss_dice: 1.3630  decode.d6.loss_cls: 1.1370  decode.d6.loss_mask: 0.7707  decode.d6.loss_dice: 1.3857  decode.d7.loss_cls: 1.1624  decode.d7.loss_mask: 0.7534  decode.d7.loss_dice: 1.3222  decode.d8.loss_cls: 1.1203  decode.d8.loss_mask: 0.7852  decode.d8.loss_dice: 1.3519
2023/05/24 13:07:51 - mmengine - INFO - Iter(train) [151850/160000]  lr: 6.8602e-07  eta: 0:58:56  time: 0.4635  data_time: 0.0100  memory: 4828  grad_norm: 81.0288  loss: 29.7740  decode.loss_cls: 0.7607  decode.loss_mask: 0.6579  decode.loss_dice: 1.2848  decode.d0.loss_cls: 2.8414  decode.d0.loss_mask: 0.6836  decode.d0.loss_dice: 1.4447  decode.d1.loss_cls: 0.9785  decode.d1.loss_mask: 0.6696  decode.d1.loss_dice: 1.3674  decode.d2.loss_cls: 0.8839  decode.d2.loss_mask: 0.6781  decode.d2.loss_dice: 1.2928  decode.d3.loss_cls: 0.7733  decode.d3.loss_mask: 0.6880  decode.d3.loss_dice: 1.2625  decode.d4.loss_cls: 0.7746  decode.d4.loss_mask: 0.6790  decode.d4.loss_dice: 1.2671  decode.d5.loss_cls: 0.7959  decode.d5.loss_mask: 0.6772  decode.d5.loss_dice: 1.2649  decode.d6.loss_cls: 0.7479  decode.d6.loss_mask: 0.6611  decode.d6.loss_dice: 1.2515  decode.d7.loss_cls: 0.7884  decode.d7.loss_mask: 0.6574  decode.d7.loss_dice: 1.2659  decode.d8.loss_cls: 0.7610  decode.d8.loss_mask: 0.6576  decode.d8.loss_dice: 1.2572
2023/05/24 13:08:13 - mmengine - INFO - Iter(train) [151900/160000]  lr: 6.8223e-07  eta: 0:58:34  time: 0.4192  data_time: 0.0109  memory: 4910  grad_norm: 88.2269  loss: 33.4739  decode.loss_cls: 1.0732  decode.loss_mask: 0.7313  decode.loss_dice: 1.2226  decode.d0.loss_cls: 3.0781  decode.d0.loss_mask: 0.7686  decode.d0.loss_dice: 1.3958  decode.d1.loss_cls: 1.2525  decode.d1.loss_mask: 0.7521  decode.d1.loss_dice: 1.3422  decode.d2.loss_cls: 1.2290  decode.d2.loss_mask: 0.7372  decode.d2.loss_dice: 1.2541  decode.d3.loss_cls: 1.1550  decode.d3.loss_mask: 0.7282  decode.d3.loss_dice: 1.2241  decode.d4.loss_cls: 1.1553  decode.d4.loss_mask: 0.7584  decode.d4.loss_dice: 1.2721  decode.d5.loss_cls: 1.1125  decode.d5.loss_mask: 0.7551  decode.d5.loss_dice: 1.2418  decode.d6.loss_cls: 1.1387  decode.d6.loss_mask: 0.7137  decode.d6.loss_dice: 1.2213  decode.d7.loss_cls: 1.1084  decode.d7.loss_mask: 0.7302  decode.d7.loss_dice: 1.2327  decode.d8.loss_cls: 1.1362  decode.d8.loss_mask: 0.7349  decode.d8.loss_dice: 1.2184
2023/05/24 13:08:34 - mmengine - INFO - Iter(train) [151950/160000]  lr: 6.7844e-07  eta: 0:58:12  time: 0.4336  data_time: 0.0104  memory: 4837  grad_norm: 109.7783  loss: 30.1513  decode.loss_cls: 0.9295  decode.loss_mask: 0.7885  decode.loss_dice: 1.0565  decode.d0.loss_cls: 2.6396  decode.d0.loss_mask: 0.8957  decode.d0.loss_dice: 1.2227  decode.d1.loss_cls: 0.9629  decode.d1.loss_mask: 0.8466  decode.d1.loss_dice: 1.1498  decode.d2.loss_cls: 0.9193  decode.d2.loss_mask: 0.8224  decode.d2.loss_dice: 1.1166  decode.d3.loss_cls: 0.9417  decode.d3.loss_mask: 0.8022  decode.d3.loss_dice: 1.0239  decode.d4.loss_cls: 0.8898  decode.d4.loss_mask: 0.8188  decode.d4.loss_dice: 1.0908  decode.d5.loss_cls: 0.9243  decode.d5.loss_mask: 0.8251  decode.d5.loss_dice: 1.0829  decode.d6.loss_cls: 0.8839  decode.d6.loss_mask: 0.8183  decode.d6.loss_dice: 1.0930  decode.d7.loss_cls: 0.9769  decode.d7.loss_mask: 0.7877  decode.d7.loss_dice: 1.0828  decode.d8.loss_cls: 0.8793  decode.d8.loss_mask: 0.7990  decode.d8.loss_dice: 1.0809
2023/05/24 13:08:55 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 13:08:55 - mmengine - INFO - Iter(train) [152000/160000]  lr: 6.7465e-07  eta: 0:57:51  time: 0.4240  data_time: 0.0099  memory: 4837  grad_norm: 101.0076  loss: 34.5982  decode.loss_cls: 1.0194  decode.loss_mask: 0.8258  decode.loss_dice: 1.2256  decode.d0.loss_cls: 3.1835  decode.d0.loss_mask: 0.9382  decode.d0.loss_dice: 1.4764  decode.d1.loss_cls: 1.2416  decode.d1.loss_mask: 0.8847  decode.d1.loss_dice: 1.3636  decode.d2.loss_cls: 1.1939  decode.d2.loss_mask: 0.8393  decode.d2.loss_dice: 1.2953  decode.d3.loss_cls: 1.0895  decode.d3.loss_mask: 0.8539  decode.d3.loss_dice: 1.2826  decode.d4.loss_cls: 1.1086  decode.d4.loss_mask: 0.8496  decode.d4.loss_dice: 1.2865  decode.d5.loss_cls: 1.1154  decode.d5.loss_mask: 0.8393  decode.d5.loss_dice: 1.2700  decode.d6.loss_cls: 1.0188  decode.d6.loss_mask: 0.8511  decode.d6.loss_dice: 1.2691  decode.d7.loss_cls: 1.0561  decode.d7.loss_mask: 0.8294  decode.d7.loss_dice: 1.2421  decode.d8.loss_cls: 1.0583  decode.d8.loss_mask: 0.8228  decode.d8.loss_dice: 1.2678
2023/05/24 13:08:55 - mmengine - INFO - Saving checkpoint at 152000 iterations
2023/05/24 13:09:22 - mmengine - INFO - Iter(train) [152050/160000]  lr: 6.7085e-07  eta: 0:57:29  time: 0.4179  data_time: 0.0102  memory: 4820  grad_norm: 96.9889  loss: 33.7557  decode.loss_cls: 0.9972  decode.loss_mask: 0.9442  decode.loss_dice: 1.1796  decode.d0.loss_cls: 2.7416  decode.d0.loss_mask: 0.9882  decode.d0.loss_dice: 1.4160  decode.d1.loss_cls: 1.0833  decode.d1.loss_mask: 0.9663  decode.d1.loss_dice: 1.3475  decode.d2.loss_cls: 0.9861  decode.d2.loss_mask: 0.9781  decode.d2.loss_dice: 1.2608  decode.d3.loss_cls: 1.0180  decode.d3.loss_mask: 0.9493  decode.d3.loss_dice: 1.2419  decode.d4.loss_cls: 0.9784  decode.d4.loss_mask: 0.9499  decode.d4.loss_dice: 1.2308  decode.d5.loss_cls: 0.9697  decode.d5.loss_mask: 0.9419  decode.d5.loss_dice: 1.2341  decode.d6.loss_cls: 1.0039  decode.d6.loss_mask: 0.9515  decode.d6.loss_dice: 1.1959  decode.d7.loss_cls: 0.9932  decode.d7.loss_mask: 0.9403  decode.d7.loss_dice: 1.1890  decode.d8.loss_cls: 0.9489  decode.d8.loss_mask: 0.9378  decode.d8.loss_dice: 1.1923
2023/05/24 13:09:44 - mmengine - INFO - Iter(train) [152100/160000]  lr: 6.6705e-07  eta: 0:57:07  time: 0.4382  data_time: 0.0100  memory: 4876  grad_norm: 78.6767  loss: 29.1954  decode.loss_cls: 1.0457  decode.loss_mask: 0.6016  decode.loss_dice: 0.9833  decode.d0.loss_cls: 2.9724  decode.d0.loss_mask: 0.6811  decode.d0.loss_dice: 1.2474  decode.d1.loss_cls: 1.0503  decode.d1.loss_mask: 0.7365  decode.d1.loss_dice: 1.1281  decode.d2.loss_cls: 1.0555  decode.d2.loss_mask: 0.7115  decode.d2.loss_dice: 1.0656  decode.d3.loss_cls: 0.9925  decode.d3.loss_mask: 0.6475  decode.d3.loss_dice: 1.0377  decode.d4.loss_cls: 0.9875  decode.d4.loss_mask: 0.6507  decode.d4.loss_dice: 1.0465  decode.d5.loss_cls: 1.0325  decode.d5.loss_mask: 0.6388  decode.d5.loss_dice: 0.9895  decode.d6.loss_cls: 1.0245  decode.d6.loss_mask: 0.6299  decode.d6.loss_dice: 0.9528  decode.d7.loss_cls: 1.0503  decode.d7.loss_mask: 0.6256  decode.d7.loss_dice: 0.9791  decode.d8.loss_cls: 1.0147  decode.d8.loss_mask: 0.6228  decode.d8.loss_dice: 0.9937
2023/05/24 13:10:05 - mmengine - INFO - Iter(train) [152150/160000]  lr: 6.6325e-07  eta: 0:56:46  time: 0.4256  data_time: 0.0104  memory: 4897  grad_norm: 94.5630  loss: 39.1366  decode.loss_cls: 1.3519  decode.loss_mask: 0.7968  decode.loss_dice: 1.4508  decode.d0.loss_cls: 3.3410  decode.d0.loss_mask: 0.8838  decode.d0.loss_dice: 1.7165  decode.d1.loss_cls: 1.4754  decode.d1.loss_mask: 0.8905  decode.d1.loss_dice: 1.5944  decode.d2.loss_cls: 1.3792  decode.d2.loss_mask: 0.8521  decode.d2.loss_dice: 1.5184  decode.d3.loss_cls: 1.3822  decode.d3.loss_mask: 0.8393  decode.d3.loss_dice: 1.4936  decode.d4.loss_cls: 1.3942  decode.d4.loss_mask: 0.8140  decode.d4.loss_dice: 1.4580  decode.d5.loss_cls: 1.3460  decode.d5.loss_mask: 0.8172  decode.d5.loss_dice: 1.4570  decode.d6.loss_cls: 1.3299  decode.d6.loss_mask: 0.8196  decode.d6.loss_dice: 1.4541  decode.d7.loss_cls: 1.3690  decode.d7.loss_mask: 0.8036  decode.d7.loss_dice: 1.4594  decode.d8.loss_cls: 1.3787  decode.d8.loss_mask: 0.8026  decode.d8.loss_dice: 1.4675
2023/05/24 13:10:27 - mmengine - INFO - Iter(train) [152200/160000]  lr: 6.5945e-07  eta: 0:56:24  time: 0.4537  data_time: 0.0099  memory: 4989  grad_norm: 83.3925  loss: 29.6412  decode.loss_cls: 0.8769  decode.loss_mask: 0.7411  decode.loss_dice: 1.0081  decode.d0.loss_cls: 2.9179  decode.d0.loss_mask: 0.9009  decode.d0.loss_dice: 1.2190  decode.d1.loss_cls: 1.0040  decode.d1.loss_mask: 0.8055  decode.d1.loss_dice: 1.1759  decode.d2.loss_cls: 0.9819  decode.d2.loss_mask: 0.7762  decode.d2.loss_dice: 1.1227  decode.d3.loss_cls: 0.9208  decode.d3.loss_mask: 0.7544  decode.d3.loss_dice: 1.0767  decode.d4.loss_cls: 0.8935  decode.d4.loss_mask: 0.7569  decode.d4.loss_dice: 1.0727  decode.d5.loss_cls: 0.8669  decode.d5.loss_mask: 0.7623  decode.d5.loss_dice: 1.0698  decode.d6.loss_cls: 0.8402  decode.d6.loss_mask: 0.7465  decode.d6.loss_dice: 1.0584  decode.d7.loss_cls: 0.8509  decode.d7.loss_mask: 0.7458  decode.d7.loss_dice: 1.0642  decode.d8.loss_cls: 0.8586  decode.d8.loss_mask: 0.7447  decode.d8.loss_dice: 1.0278
2023/05/24 13:10:49 - mmengine - INFO - Iter(train) [152250/160000]  lr: 6.5564e-07  eta: 0:56:02  time: 0.4489  data_time: 0.0100  memory: 4859  grad_norm: 97.6778  loss: 26.9025  decode.loss_cls: 0.8770  decode.loss_mask: 0.5681  decode.loss_dice: 0.9371  decode.d0.loss_cls: 3.0112  decode.d0.loss_mask: 0.5395  decode.d0.loss_dice: 1.1322  decode.d1.loss_cls: 1.0235  decode.d1.loss_mask: 0.5747  decode.d1.loss_dice: 1.0338  decode.d2.loss_cls: 0.9850  decode.d2.loss_mask: 0.5872  decode.d2.loss_dice: 1.0025  decode.d3.loss_cls: 0.9789  decode.d3.loss_mask: 0.5495  decode.d3.loss_dice: 0.9466  decode.d4.loss_cls: 0.9308  decode.d4.loss_mask: 0.5700  decode.d4.loss_dice: 0.9478  decode.d5.loss_cls: 0.9208  decode.d5.loss_mask: 0.5860  decode.d5.loss_dice: 0.9351  decode.d6.loss_cls: 0.9163  decode.d6.loss_mask: 0.5722  decode.d6.loss_dice: 0.9418  decode.d7.loss_cls: 0.9112  decode.d7.loss_mask: 0.5657  decode.d7.loss_dice: 0.9420  decode.d8.loss_cls: 0.9082  decode.d8.loss_mask: 0.5661  decode.d8.loss_dice: 0.9418
2023/05/24 13:11:11 - mmengine - INFO - Iter(train) [152300/160000]  lr: 6.5183e-07  eta: 0:55:41  time: 0.4459  data_time: 0.0101  memory: 4887  grad_norm: 97.1176  loss: 33.7020  decode.loss_cls: 1.2533  decode.loss_mask: 0.7466  decode.loss_dice: 1.0530  decode.d0.loss_cls: 3.0857  decode.d0.loss_mask: 0.8550  decode.d0.loss_dice: 1.2990  decode.d1.loss_cls: 1.2665  decode.d1.loss_mask: 0.8524  decode.d1.loss_dice: 1.2530  decode.d2.loss_cls: 1.2113  decode.d2.loss_mask: 0.8189  decode.d2.loss_dice: 1.2118  decode.d3.loss_cls: 1.2413  decode.d3.loss_mask: 0.7945  decode.d3.loss_dice: 1.1446  decode.d4.loss_cls: 1.2406  decode.d4.loss_mask: 0.7896  decode.d4.loss_dice: 1.1491  decode.d5.loss_cls: 1.2472  decode.d5.loss_mask: 0.7738  decode.d5.loss_dice: 1.1081  decode.d6.loss_cls: 1.2084  decode.d6.loss_mask: 0.7979  decode.d6.loss_dice: 1.1514  decode.d7.loss_cls: 1.2400  decode.d7.loss_mask: 0.7598  decode.d7.loss_dice: 1.0713  decode.d8.loss_cls: 1.1834  decode.d8.loss_mask: 0.7975  decode.d8.loss_dice: 1.0969
2023/05/24 13:11:33 - mmengine - INFO - Iter(train) [152350/160000]  lr: 6.4802e-07  eta: 0:55:19  time: 0.4285  data_time: 0.0103  memory: 4833  grad_norm: 112.1357  loss: 22.8423  decode.loss_cls: 0.6503  decode.loss_mask: 0.5658  decode.loss_dice: 0.7775  decode.d0.loss_cls: 2.6489  decode.d0.loss_mask: 0.6289  decode.d0.loss_dice: 0.9318  decode.d1.loss_cls: 0.8300  decode.d1.loss_mask: 0.6258  decode.d1.loss_dice: 0.8880  decode.d2.loss_cls: 0.7186  decode.d2.loss_mask: 0.6013  decode.d2.loss_dice: 0.8182  decode.d3.loss_cls: 0.6979  decode.d3.loss_mask: 0.5742  decode.d3.loss_dice: 0.7588  decode.d4.loss_cls: 0.7935  decode.d4.loss_mask: 0.5787  decode.d4.loss_dice: 0.7655  decode.d5.loss_cls: 0.7477  decode.d5.loss_mask: 0.5503  decode.d5.loss_dice: 0.7437  decode.d6.loss_cls: 0.6578  decode.d6.loss_mask: 0.5707  decode.d6.loss_dice: 0.7472  decode.d7.loss_cls: 0.6476  decode.d7.loss_mask: 0.5878  decode.d7.loss_dice: 0.7488  decode.d8.loss_cls: 0.6699  decode.d8.loss_mask: 0.5622  decode.d8.loss_dice: 0.7549
2023/05/24 13:11:56 - mmengine - INFO - Iter(train) [152400/160000]  lr: 6.4421e-07  eta: 0:54:57  time: 0.4638  data_time: 0.0100  memory: 4830  grad_norm: 97.1179  loss: 32.2592  decode.loss_cls: 1.0547  decode.loss_mask: 0.7847  decode.loss_dice: 1.2186  decode.d0.loss_cls: 2.7879  decode.d0.loss_mask: 0.7452  decode.d0.loss_dice: 1.3808  decode.d1.loss_cls: 1.1563  decode.d1.loss_mask: 0.7787  decode.d1.loss_dice: 1.2137  decode.d2.loss_cls: 1.1020  decode.d2.loss_mask: 0.7713  decode.d2.loss_dice: 1.2264  decode.d3.loss_cls: 1.0499  decode.d3.loss_mask: 0.7546  decode.d3.loss_dice: 1.1873  decode.d4.loss_cls: 1.0557  decode.d4.loss_mask: 0.7618  decode.d4.loss_dice: 1.1940  decode.d5.loss_cls: 1.0933  decode.d5.loss_mask: 0.7689  decode.d5.loss_dice: 1.1981  decode.d6.loss_cls: 1.0154  decode.d6.loss_mask: 0.7809  decode.d6.loss_dice: 1.2177  decode.d7.loss_cls: 1.0824  decode.d7.loss_mask: 0.7645  decode.d7.loss_dice: 1.1548  decode.d8.loss_cls: 1.0222  decode.d8.loss_mask: 0.7565  decode.d8.loss_dice: 1.1809
2023/05/24 13:12:20 - mmengine - INFO - Iter(train) [152450/160000]  lr: 6.4039e-07  eta: 0:54:36  time: 0.4782  data_time: 0.0100  memory: 4845  grad_norm: 89.0904  loss: 33.6772  decode.loss_cls: 1.0507  decode.loss_mask: 0.8700  decode.loss_dice: 1.2043  decode.d0.loss_cls: 2.6269  decode.d0.loss_mask: 0.9713  decode.d0.loss_dice: 1.4150  decode.d1.loss_cls: 1.1272  decode.d1.loss_mask: 0.9233  decode.d1.loss_dice: 1.3015  decode.d2.loss_cls: 1.0945  decode.d2.loss_mask: 0.8826  decode.d2.loss_dice: 1.2454  decode.d3.loss_cls: 1.0669  decode.d3.loss_mask: 0.9045  decode.d3.loss_dice: 1.2413  decode.d4.loss_cls: 1.0710  decode.d4.loss_mask: 0.9049  decode.d4.loss_dice: 1.2248  decode.d5.loss_cls: 0.9521  decode.d5.loss_mask: 0.9132  decode.d5.loss_dice: 1.2582  decode.d6.loss_cls: 1.0198  decode.d6.loss_mask: 0.8994  decode.d6.loss_dice: 1.2324  decode.d7.loss_cls: 1.0565  decode.d7.loss_mask: 0.8673  decode.d7.loss_dice: 1.2170  decode.d8.loss_cls: 1.0506  decode.d8.loss_mask: 0.8784  decode.d8.loss_dice: 1.2063
2023/05/24 13:12:42 - mmengine - INFO - Iter(train) [152500/160000]  lr: 6.3658e-07  eta: 0:54:14  time: 0.4245  data_time: 0.0100  memory: 4855  grad_norm: 81.3855  loss: 31.7516  decode.loss_cls: 1.1919  decode.loss_mask: 0.5886  decode.loss_dice: 1.0790  decode.d0.loss_cls: 3.3885  decode.d0.loss_mask: 0.6236  decode.d0.loss_dice: 1.2966  decode.d1.loss_cls: 1.4271  decode.d1.loss_mask: 0.6385  decode.d1.loss_dice: 1.1537  decode.d2.loss_cls: 1.3193  decode.d2.loss_mask: 0.5913  decode.d2.loss_dice: 1.0926  decode.d3.loss_cls: 1.2723  decode.d3.loss_mask: 0.6052  decode.d3.loss_dice: 1.0595  decode.d4.loss_cls: 1.2329  decode.d4.loss_mask: 0.5956  decode.d4.loss_dice: 1.0912  decode.d5.loss_cls: 1.2504  decode.d5.loss_mask: 0.5831  decode.d5.loss_dice: 1.0599  decode.d6.loss_cls: 1.1988  decode.d6.loss_mask: 0.5859  decode.d6.loss_dice: 1.0868  decode.d7.loss_cls: 1.2147  decode.d7.loss_mask: 0.5880  decode.d7.loss_dice: 1.0931  decode.d8.loss_cls: 1.1827  decode.d8.loss_mask: 0.5894  decode.d8.loss_dice: 1.0717
2023/05/24 13:13:05 - mmengine - INFO - Iter(train) [152550/160000]  lr: 6.3275e-07  eta: 0:53:52  time: 0.4478  data_time: 0.0100  memory: 4863  grad_norm: 87.6376  loss: 30.4309  decode.loss_cls: 0.9657  decode.loss_mask: 0.6875  decode.loss_dice: 1.0680  decode.d0.loss_cls: 2.8218  decode.d0.loss_mask: 0.7363  decode.d0.loss_dice: 1.3037  decode.d1.loss_cls: 1.1542  decode.d1.loss_mask: 0.7405  decode.d1.loss_dice: 1.2404  decode.d2.loss_cls: 1.0650  decode.d2.loss_mask: 0.7311  decode.d2.loss_dice: 1.1890  decode.d3.loss_cls: 1.0212  decode.d3.loss_mask: 0.6997  decode.d3.loss_dice: 1.0867  decode.d4.loss_cls: 1.0096  decode.d4.loss_mask: 0.6866  decode.d4.loss_dice: 1.0987  decode.d5.loss_cls: 1.0292  decode.d5.loss_mask: 0.6785  decode.d5.loss_dice: 1.0949  decode.d6.loss_cls: 1.0383  decode.d6.loss_mask: 0.6825  decode.d6.loss_dice: 1.1038  decode.d7.loss_cls: 0.9549  decode.d7.loss_mask: 0.6925  decode.d7.loss_dice: 1.1293  decode.d8.loss_cls: 0.9769  decode.d8.loss_mask: 0.6872  decode.d8.loss_dice: 1.0568
2023/05/24 13:13:27 - mmengine - INFO - Iter(train) [152600/160000]  lr: 6.2893e-07  eta: 0:53:31  time: 0.4755  data_time: 0.0098  memory: 4888  grad_norm: 93.7771  loss: 44.1146  decode.loss_cls: 1.4407  decode.loss_mask: 0.9304  decode.loss_dice: 1.7240  decode.d0.loss_cls: 3.6322  decode.d0.loss_mask: 1.0397  decode.d0.loss_dice: 1.9648  decode.d1.loss_cls: 1.5368  decode.d1.loss_mask: 0.9816  decode.d1.loss_dice: 1.8247  decode.d2.loss_cls: 1.5294  decode.d2.loss_mask: 1.0242  decode.d2.loss_dice: 1.8395  decode.d3.loss_cls: 1.5703  decode.d3.loss_mask: 0.9316  decode.d3.loss_dice: 1.6940  decode.d4.loss_cls: 1.4870  decode.d4.loss_mask: 0.9302  decode.d4.loss_dice: 1.7067  decode.d5.loss_cls: 1.4753  decode.d5.loss_mask: 0.9175  decode.d5.loss_dice: 1.6768  decode.d6.loss_cls: 1.4432  decode.d6.loss_mask: 0.9527  decode.d6.loss_dice: 1.7038  decode.d7.loss_cls: 1.3958  decode.d7.loss_mask: 0.9431  decode.d7.loss_dice: 1.7311  decode.d8.loss_cls: 1.4424  decode.d8.loss_mask: 0.9453  decode.d8.loss_dice: 1.6998
2023/05/24 13:13:49 - mmengine - INFO - Iter(train) [152650/160000]  lr: 6.2511e-07  eta: 0:53:09  time: 0.4323  data_time: 0.0100  memory: 4838  grad_norm: 92.4036  loss: 24.4560  decode.loss_cls: 0.8619  decode.loss_mask: 0.6242  decode.loss_dice: 0.6702  decode.d0.loss_cls: 2.6815  decode.d0.loss_mask: 0.7584  decode.d0.loss_dice: 0.8805  decode.d1.loss_cls: 1.0301  decode.d1.loss_mask: 0.6979  decode.d1.loss_dice: 0.7669  decode.d2.loss_cls: 0.9849  decode.d2.loss_mask: 0.6270  decode.d2.loss_dice: 0.6933  decode.d3.loss_cls: 0.9351  decode.d3.loss_mask: 0.6828  decode.d3.loss_dice: 0.6857  decode.d4.loss_cls: 0.8647  decode.d4.loss_mask: 0.6578  decode.d4.loss_dice: 0.6872  decode.d5.loss_cls: 0.8813  decode.d5.loss_mask: 0.6138  decode.d5.loss_dice: 0.6966  decode.d6.loss_cls: 0.8552  decode.d6.loss_mask: 0.6092  decode.d6.loss_dice: 0.7028  decode.d7.loss_cls: 0.8505  decode.d7.loss_mask: 0.6184  decode.d7.loss_dice: 0.6809  decode.d8.loss_cls: 0.8575  decode.d8.loss_mask: 0.6352  decode.d8.loss_dice: 0.6644
2023/05/24 13:14:11 - mmengine - INFO - Iter(train) [152700/160000]  lr: 6.2128e-07  eta: 0:52:47  time: 0.4347  data_time: 0.0098  memory: 4830  grad_norm: 105.0863  loss: 32.9493  decode.loss_cls: 1.1138  decode.loss_mask: 0.8286  decode.loss_dice: 1.0456  decode.d0.loss_cls: 3.1225  decode.d0.loss_mask: 0.8720  decode.d0.loss_dice: 1.2151  decode.d1.loss_cls: 1.2983  decode.d1.loss_mask: 0.8532  decode.d1.loss_dice: 1.1905  decode.d2.loss_cls: 1.2538  decode.d2.loss_mask: 0.8351  decode.d2.loss_dice: 1.1067  decode.d3.loss_cls: 1.2053  decode.d3.loss_mask: 0.8340  decode.d3.loss_dice: 1.0735  decode.d4.loss_cls: 1.1394  decode.d4.loss_mask: 0.8289  decode.d4.loss_dice: 1.0446  decode.d5.loss_cls: 1.0814  decode.d5.loss_mask: 0.8455  decode.d5.loss_dice: 1.0768  decode.d6.loss_cls: 1.1247  decode.d6.loss_mask: 0.8589  decode.d6.loss_dice: 1.0981  decode.d7.loss_cls: 1.0822  decode.d7.loss_mask: 0.8353  decode.d7.loss_dice: 1.0649  decode.d8.loss_cls: 1.0850  decode.d8.loss_mask: 0.8629  decode.d8.loss_dice: 1.0726
2023/05/24 13:14:32 - mmengine - INFO - Iter(train) [152750/160000]  lr: 6.1745e-07  eta: 0:52:26  time: 0.4215  data_time: 0.0099  memory: 4836  grad_norm: 94.6379  loss: 31.5012  decode.loss_cls: 1.1281  decode.loss_mask: 0.7692  decode.loss_dice: 1.0048  decode.d0.loss_cls: 3.0016  decode.d0.loss_mask: 0.8601  decode.d0.loss_dice: 1.1998  decode.d1.loss_cls: 1.2443  decode.d1.loss_mask: 0.8002  decode.d1.loss_dice: 1.1191  decode.d2.loss_cls: 1.1176  decode.d2.loss_mask: 0.7601  decode.d2.loss_dice: 1.0714  decode.d3.loss_cls: 1.1586  decode.d3.loss_mask: 0.7402  decode.d3.loss_dice: 0.9965  decode.d4.loss_cls: 1.1706  decode.d4.loss_mask: 0.7379  decode.d4.loss_dice: 1.0002  decode.d5.loss_cls: 1.1402  decode.d5.loss_mask: 0.7668  decode.d5.loss_dice: 1.0276  decode.d6.loss_cls: 1.1528  decode.d6.loss_mask: 0.7409  decode.d6.loss_dice: 0.9924  decode.d7.loss_cls: 1.1509  decode.d7.loss_mask: 0.7404  decode.d7.loss_dice: 1.0111  decode.d8.loss_cls: 1.1280  decode.d8.loss_mask: 0.7644  decode.d8.loss_dice: 1.0053
2023/05/24 13:14:54 - mmengine - INFO - Iter(train) [152800/160000]  lr: 6.1361e-07  eta: 0:52:04  time: 0.4265  data_time: 0.0107  memory: 4887  grad_norm: 77.7781  loss: 32.3899  decode.loss_cls: 1.0100  decode.loss_mask: 0.7254  decode.loss_dice: 1.2010  decode.d0.loss_cls: 2.7915  decode.d0.loss_mask: 0.8047  decode.d0.loss_dice: 1.3449  decode.d1.loss_cls: 1.1096  decode.d1.loss_mask: 0.8298  decode.d1.loss_dice: 1.3111  decode.d2.loss_cls: 1.0786  decode.d2.loss_mask: 0.8162  decode.d2.loss_dice: 1.2482  decode.d3.loss_cls: 1.0671  decode.d3.loss_mask: 0.7809  decode.d3.loss_dice: 1.2187  decode.d4.loss_cls: 0.9878  decode.d4.loss_mask: 0.7777  decode.d4.loss_dice: 1.2553  decode.d5.loss_cls: 1.0349  decode.d5.loss_mask: 0.7574  decode.d5.loss_dice: 1.2076  decode.d6.loss_cls: 1.0380  decode.d6.loss_mask: 0.7815  decode.d6.loss_dice: 1.2068  decode.d7.loss_cls: 1.0464  decode.d7.loss_mask: 0.7703  decode.d7.loss_dice: 1.1896  decode.d8.loss_cls: 1.0332  decode.d8.loss_mask: 0.7602  decode.d8.loss_dice: 1.2054
2023/05/24 13:15:16 - mmengine - INFO - Iter(train) [152850/160000]  lr: 6.0978e-07  eta: 0:51:42  time: 0.4209  data_time: 0.0101  memory: 4836  grad_norm: 95.1477  loss: 34.2534  decode.loss_cls: 1.3686  decode.loss_mask: 0.6649  decode.loss_dice: 1.1199  decode.d0.loss_cls: 3.0336  decode.d0.loss_mask: 0.7977  decode.d0.loss_dice: 1.3711  decode.d1.loss_cls: 1.3738  decode.d1.loss_mask: 0.7263  decode.d1.loss_dice: 1.2774  decode.d2.loss_cls: 1.3293  decode.d2.loss_mask: 0.7623  decode.d2.loss_dice: 1.2321  decode.d3.loss_cls: 1.3210  decode.d3.loss_mask: 0.7158  decode.d3.loss_dice: 1.1815  decode.d4.loss_cls: 1.2811  decode.d4.loss_mask: 0.7236  decode.d4.loss_dice: 1.1957  decode.d5.loss_cls: 1.3662  decode.d5.loss_mask: 0.6789  decode.d5.loss_dice: 1.1449  decode.d6.loss_cls: 1.3969  decode.d6.loss_mask: 0.6898  decode.d6.loss_dice: 1.1338  decode.d7.loss_cls: 1.3708  decode.d7.loss_mask: 0.6883  decode.d7.loss_dice: 1.1440  decode.d8.loss_cls: 1.3859  decode.d8.loss_mask: 0.6661  decode.d8.loss_dice: 1.1122
2023/05/24 13:15:39 - mmengine - INFO - Iter(train) [152900/160000]  lr: 6.0594e-07  eta: 0:51:21  time: 0.4810  data_time: 0.0102  memory: 4847  grad_norm: 133.7441  loss: 36.5457  decode.loss_cls: 1.2739  decode.loss_mask: 0.8327  decode.loss_dice: 1.2170  decode.d0.loss_cls: 3.3222  decode.d0.loss_mask: 0.9178  decode.d0.loss_dice: 1.4772  decode.d1.loss_cls: 1.3306  decode.d1.loss_mask: 0.9578  decode.d1.loss_dice: 1.4154  decode.d2.loss_cls: 1.3202  decode.d2.loss_mask: 0.9005  decode.d2.loss_dice: 1.2950  decode.d3.loss_cls: 1.2450  decode.d3.loss_mask: 0.8410  decode.d3.loss_dice: 1.2679  decode.d4.loss_cls: 1.2611  decode.d4.loss_mask: 0.8549  decode.d4.loss_dice: 1.2552  decode.d5.loss_cls: 1.2885  decode.d5.loss_mask: 0.8398  decode.d5.loss_dice: 1.2625  decode.d6.loss_cls: 1.3290  decode.d6.loss_mask: 0.8348  decode.d6.loss_dice: 1.2384  decode.d7.loss_cls: 1.2726  decode.d7.loss_mask: 0.8476  decode.d7.loss_dice: 1.2511  decode.d8.loss_cls: 1.2893  decode.d8.loss_mask: 0.8541  decode.d8.loss_dice: 1.2526
2023/05/24 13:16:02 - mmengine - INFO - Iter(train) [152950/160000]  lr: 6.0209e-07  eta: 0:50:59  time: 0.4629  data_time: 0.0099  memory: 4821  grad_norm: 93.4261  loss: 31.2593  decode.loss_cls: 1.0259  decode.loss_mask: 0.7028  decode.loss_dice: 1.1096  decode.d0.loss_cls: 3.0090  decode.d0.loss_mask: 0.7833  decode.d0.loss_dice: 1.2856  decode.d1.loss_cls: 1.2172  decode.d1.loss_mask: 0.7367  decode.d1.loss_dice: 1.1854  decode.d2.loss_cls: 1.1512  decode.d2.loss_mask: 0.6917  decode.d2.loss_dice: 1.1650  decode.d3.loss_cls: 1.0978  decode.d3.loss_mask: 0.6687  decode.d3.loss_dice: 1.1488  decode.d4.loss_cls: 1.0416  decode.d4.loss_mask: 0.6905  decode.d4.loss_dice: 1.1518  decode.d5.loss_cls: 1.0147  decode.d5.loss_mask: 0.6924  decode.d5.loss_dice: 1.1323  decode.d6.loss_cls: 1.0198  decode.d6.loss_mask: 0.6849  decode.d6.loss_dice: 1.1177  decode.d7.loss_cls: 1.0269  decode.d7.loss_mask: 0.6912  decode.d7.loss_dice: 1.1581  decode.d8.loss_cls: 1.0104  decode.d8.loss_mask: 0.6910  decode.d8.loss_dice: 1.1572
2023/05/24 13:16:24 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 13:16:24 - mmengine - INFO - Iter(train) [153000/160000]  lr: 5.9825e-07  eta: 0:50:37  time: 0.4325  data_time: 0.0106  memory: 4900  grad_norm: 91.8815  loss: 31.2938  decode.loss_cls: 0.9805  decode.loss_mask: 0.7252  decode.loss_dice: 1.1582  decode.d0.loss_cls: 3.0174  decode.d0.loss_mask: 0.7435  decode.d0.loss_dice: 1.3136  decode.d1.loss_cls: 1.0910  decode.d1.loss_mask: 0.7661  decode.d1.loss_dice: 1.2561  decode.d2.loss_cls: 1.0705  decode.d2.loss_mask: 0.7255  decode.d2.loss_dice: 1.1949  decode.d3.loss_cls: 1.0438  decode.d3.loss_mask: 0.7215  decode.d3.loss_dice: 1.1769  decode.d4.loss_cls: 0.9425  decode.d4.loss_mask: 0.7083  decode.d4.loss_dice: 1.1806  decode.d5.loss_cls: 0.9801  decode.d5.loss_mask: 0.7101  decode.d5.loss_dice: 1.1736  decode.d6.loss_cls: 0.9448  decode.d6.loss_mask: 0.7172  decode.d6.loss_dice: 1.1767  decode.d7.loss_cls: 1.0200  decode.d7.loss_mask: 0.7194  decode.d7.loss_dice: 1.1483  decode.d8.loss_cls: 1.0197  decode.d8.loss_mask: 0.7151  decode.d8.loss_dice: 1.1525
2023/05/24 13:16:24 - mmengine - INFO - Saving checkpoint at 153000 iterations
2023/05/24 13:16:52 - mmengine - INFO - Iter(train) [153050/160000]  lr: 5.9440e-07  eta: 0:50:16  time: 0.4447  data_time: 0.0099  memory: 4836  grad_norm: 93.2907  loss: 31.0397  decode.loss_cls: 1.0072  decode.loss_mask: 0.7150  decode.loss_dice: 1.0789  decode.d0.loss_cls: 3.0682  decode.d0.loss_mask: 0.6918  decode.d0.loss_dice: 1.1976  decode.d1.loss_cls: 1.1136  decode.d1.loss_mask: 0.7440  decode.d1.loss_dice: 1.1687  decode.d2.loss_cls: 1.0823  decode.d2.loss_mask: 0.7463  decode.d2.loss_dice: 1.1369  decode.d3.loss_cls: 1.1501  decode.d3.loss_mask: 0.7087  decode.d3.loss_dice: 1.0679  decode.d4.loss_cls: 1.1462  decode.d4.loss_mask: 0.6988  decode.d4.loss_dice: 1.0855  decode.d5.loss_cls: 1.0880  decode.d5.loss_mask: 0.7042  decode.d5.loss_dice: 1.0808  decode.d6.loss_cls: 1.0968  decode.d6.loss_mask: 0.6986  decode.d6.loss_dice: 1.0675  decode.d7.loss_cls: 1.0913  decode.d7.loss_mask: 0.6853  decode.d7.loss_dice: 1.0512  decode.d8.loss_cls: 1.1153  decode.d8.loss_mask: 0.6854  decode.d8.loss_dice: 1.0678
2023/05/24 13:17:13 - mmengine - INFO - Iter(train) [153100/160000]  lr: 5.9055e-07  eta: 0:49:54  time: 0.4255  data_time: 0.0100  memory: 4788  grad_norm: 90.9173  loss: 22.3873  decode.loss_cls: 0.6830  decode.loss_mask: 0.5114  decode.loss_dice: 0.7873  decode.d0.loss_cls: 2.4116  decode.d0.loss_mask: 0.5769  decode.d0.loss_dice: 0.9020  decode.d1.loss_cls: 0.7572  decode.d1.loss_mask: 0.5731  decode.d1.loss_dice: 0.8439  decode.d2.loss_cls: 0.7909  decode.d2.loss_mask: 0.5246  decode.d2.loss_dice: 0.8314  decode.d3.loss_cls: 0.7272  decode.d3.loss_mask: 0.5171  decode.d3.loss_dice: 0.8415  decode.d4.loss_cls: 0.6957  decode.d4.loss_mask: 0.5155  decode.d4.loss_dice: 0.8209  decode.d5.loss_cls: 0.6850  decode.d5.loss_mask: 0.5231  decode.d5.loss_dice: 0.8165  decode.d6.loss_cls: 0.6853  decode.d6.loss_mask: 0.5154  decode.d6.loss_dice: 0.8243  decode.d7.loss_cls: 0.6877  decode.d7.loss_mask: 0.5111  decode.d7.loss_dice: 0.8276  decode.d8.loss_cls: 0.6689  decode.d8.loss_mask: 0.5132  decode.d8.loss_dice: 0.8178
2023/05/24 13:17:36 - mmengine - INFO - Iter(train) [153150/160000]  lr: 5.8670e-07  eta: 0:49:33  time: 0.4545  data_time: 0.0100  memory: 4821  grad_norm: 79.4807  loss: 33.4418  decode.loss_cls: 1.0779  decode.loss_mask: 0.7963  decode.loss_dice: 1.2124  decode.d0.loss_cls: 2.8656  decode.d0.loss_mask: 0.8845  decode.d0.loss_dice: 1.4039  decode.d1.loss_cls: 1.2510  decode.d1.loss_mask: 0.8387  decode.d1.loss_dice: 1.3035  decode.d2.loss_cls: 1.1410  decode.d2.loss_mask: 0.7995  decode.d2.loss_dice: 1.2331  decode.d3.loss_cls: 1.1130  decode.d3.loss_mask: 0.8006  decode.d3.loss_dice: 1.2335  decode.d4.loss_cls: 1.1351  decode.d4.loss_mask: 0.8111  decode.d4.loss_dice: 1.2880  decode.d5.loss_cls: 1.1293  decode.d5.loss_mask: 0.7904  decode.d5.loss_dice: 1.1921  decode.d6.loss_cls: 1.1021  decode.d6.loss_mask: 0.7826  decode.d6.loss_dice: 1.1780  decode.d7.loss_cls: 1.0857  decode.d7.loss_mask: 0.7985  decode.d7.loss_dice: 1.1805  decode.d8.loss_cls: 1.0746  decode.d8.loss_mask: 0.7941  decode.d8.loss_dice: 1.1450
2023/05/24 13:17:57 - mmengine - INFO - Iter(train) [153200/160000]  lr: 5.8284e-07  eta: 0:49:11  time: 0.4209  data_time: 0.0101  memory: 4889  grad_norm: 95.6396  loss: 43.4365  decode.loss_cls: 1.2855  decode.loss_mask: 1.0816  decode.loss_dice: 1.6662  decode.d0.loss_cls: 3.3976  decode.d0.loss_mask: 1.1006  decode.d0.loss_dice: 1.9709  decode.d1.loss_cls: 1.5134  decode.d1.loss_mask: 1.0707  decode.d1.loss_dice: 1.8340  decode.d2.loss_cls: 1.4356  decode.d2.loss_mask: 1.0483  decode.d2.loss_dice: 1.7709  decode.d3.loss_cls: 1.3885  decode.d3.loss_mask: 1.0555  decode.d3.loss_dice: 1.6684  decode.d4.loss_cls: 1.3279  decode.d4.loss_mask: 1.0587  decode.d4.loss_dice: 1.6784  decode.d5.loss_cls: 1.3527  decode.d5.loss_mask: 1.0285  decode.d5.loss_dice: 1.6549  decode.d6.loss_cls: 1.3426  decode.d6.loss_mask: 1.0844  decode.d6.loss_dice: 1.6459  decode.d7.loss_cls: 1.3347  decode.d7.loss_mask: 1.0220  decode.d7.loss_dice: 1.6546  decode.d8.loss_cls: 1.2833  decode.d8.loss_mask: 1.0327  decode.d8.loss_dice: 1.6476
2023/05/24 13:18:19 - mmengine - INFO - Iter(train) [153250/160000]  lr: 5.7899e-07  eta: 0:48:49  time: 0.4357  data_time: 0.0101  memory: 4835  grad_norm: 81.4551  loss: 35.3677  decode.loss_cls: 1.2064  decode.loss_mask: 0.8184  decode.loss_dice: 1.1783  decode.d0.loss_cls: 2.9841  decode.d0.loss_mask: 0.9029  decode.d0.loss_dice: 1.4203  decode.d1.loss_cls: 1.3384  decode.d1.loss_mask: 0.8171  decode.d1.loss_dice: 1.3256  decode.d2.loss_cls: 1.3017  decode.d2.loss_mask: 0.8548  decode.d2.loss_dice: 1.2809  decode.d3.loss_cls: 1.2833  decode.d3.loss_mask: 0.8758  decode.d3.loss_dice: 1.2404  decode.d4.loss_cls: 1.2419  decode.d4.loss_mask: 0.8987  decode.d4.loss_dice: 1.2387  decode.d5.loss_cls: 1.2779  decode.d5.loss_mask: 0.8202  decode.d5.loss_dice: 1.2098  decode.d6.loss_cls: 1.2968  decode.d6.loss_mask: 0.8234  decode.d6.loss_dice: 1.1525  decode.d7.loss_cls: 1.2180  decode.d7.loss_mask: 0.8530  decode.d7.loss_dice: 1.1873  decode.d8.loss_cls: 1.2451  decode.d8.loss_mask: 0.8544  decode.d8.loss_dice: 1.2216
2023/05/24 13:18:40 - mmengine - INFO - Iter(train) [153300/160000]  lr: 5.7512e-07  eta: 0:48:27  time: 0.4234  data_time: 0.0105  memory: 4836  grad_norm: 83.6306  loss: 34.4472  decode.loss_cls: 1.2278  decode.loss_mask: 0.8206  decode.loss_dice: 1.1724  decode.d0.loss_cls: 3.0219  decode.d0.loss_mask: 0.8477  decode.d0.loss_dice: 1.3333  decode.d1.loss_cls: 1.3515  decode.d1.loss_mask: 0.8304  decode.d1.loss_dice: 1.2222  decode.d2.loss_cls: 1.2903  decode.d2.loss_mask: 0.8394  decode.d2.loss_dice: 1.1867  decode.d3.loss_cls: 1.2779  decode.d3.loss_mask: 0.8313  decode.d3.loss_dice: 1.1717  decode.d4.loss_cls: 1.2523  decode.d4.loss_mask: 0.8233  decode.d4.loss_dice: 1.1742  decode.d5.loss_cls: 1.2621  decode.d5.loss_mask: 0.8067  decode.d5.loss_dice: 1.1792  decode.d6.loss_cls: 1.2466  decode.d6.loss_mask: 0.8060  decode.d6.loss_dice: 1.1377  decode.d7.loss_cls: 1.1821  decode.d7.loss_mask: 0.8241  decode.d7.loss_dice: 1.1539  decode.d8.loss_cls: 1.1743  decode.d8.loss_mask: 0.8300  decode.d8.loss_dice: 1.1695
2023/05/24 13:19:03 - mmengine - INFO - Iter(train) [153350/160000]  lr: 5.7126e-07  eta: 0:48:06  time: 0.4395  data_time: 0.0102  memory: 4875  grad_norm: 99.1422  loss: 32.5694  decode.loss_cls: 1.1382  decode.loss_mask: 0.6392  decode.loss_dice: 1.2006  decode.d0.loss_cls: 3.2930  decode.d0.loss_mask: 0.6507  decode.d0.loss_dice: 1.3628  decode.d1.loss_cls: 1.3355  decode.d1.loss_mask: 0.7067  decode.d1.loss_dice: 1.2598  decode.d2.loss_cls: 1.1829  decode.d2.loss_mask: 0.6807  decode.d2.loss_dice: 1.2634  decode.d3.loss_cls: 1.1514  decode.d3.loss_mask: 0.6716  decode.d3.loss_dice: 1.1982  decode.d4.loss_cls: 1.1321  decode.d4.loss_mask: 0.6631  decode.d4.loss_dice: 1.2215  decode.d5.loss_cls: 1.1000  decode.d5.loss_mask: 0.6638  decode.d5.loss_dice: 1.1846  decode.d6.loss_cls: 1.1015  decode.d6.loss_mask: 0.6645  decode.d6.loss_dice: 1.1636  decode.d7.loss_cls: 1.1059  decode.d7.loss_mask: 0.6620  decode.d7.loss_dice: 1.1852  decode.d8.loss_cls: 1.1147  decode.d8.loss_mask: 0.6658  decode.d8.loss_dice: 1.2062
2023/05/24 13:19:25 - mmengine - INFO - Iter(train) [153400/160000]  lr: 5.6739e-07  eta: 0:47:44  time: 0.4386  data_time: 0.0104  memory: 4919  grad_norm: 80.5145  loss: 34.6290  decode.loss_cls: 1.2222  decode.loss_mask: 0.6915  decode.loss_dice: 1.2487  decode.d0.loss_cls: 3.2807  decode.d0.loss_mask: 0.7513  decode.d0.loss_dice: 1.4520  decode.d1.loss_cls: 1.3566  decode.d1.loss_mask: 0.7261  decode.d1.loss_dice: 1.3773  decode.d2.loss_cls: 1.2753  decode.d2.loss_mask: 0.7148  decode.d2.loss_dice: 1.3022  decode.d3.loss_cls: 1.2428  decode.d3.loss_mask: 0.7166  decode.d3.loss_dice: 1.2485  decode.d4.loss_cls: 1.2290  decode.d4.loss_mask: 0.7146  decode.d4.loss_dice: 1.2939  decode.d5.loss_cls: 1.2006  decode.d5.loss_mask: 0.7243  decode.d5.loss_dice: 1.2941  decode.d6.loss_cls: 1.2368  decode.d6.loss_mask: 0.7237  decode.d6.loss_dice: 1.2441  decode.d7.loss_cls: 1.1948  decode.d7.loss_mask: 0.7093  decode.d7.loss_dice: 1.2470  decode.d8.loss_cls: 1.2526  decode.d8.loss_mask: 0.7133  decode.d8.loss_dice: 1.2443
2023/05/24 13:19:46 - mmengine - INFO - Iter(train) [153450/160000]  lr: 5.6352e-07  eta: 0:47:22  time: 0.4309  data_time: 0.0099  memory: 4861  grad_norm: 98.8632  loss: 32.4884  decode.loss_cls: 1.0037  decode.loss_mask: 0.7304  decode.loss_dice: 1.2183  decode.d0.loss_cls: 3.0481  decode.d0.loss_mask: 0.8065  decode.d0.loss_dice: 1.4079  decode.d1.loss_cls: 1.0907  decode.d1.loss_mask: 0.7688  decode.d1.loss_dice: 1.3232  decode.d2.loss_cls: 1.0456  decode.d2.loss_mask: 0.7775  decode.d2.loss_dice: 1.2829  decode.d3.loss_cls: 1.0380  decode.d3.loss_mask: 0.7346  decode.d3.loss_dice: 1.2292  decode.d4.loss_cls: 1.0275  decode.d4.loss_mask: 0.7475  decode.d4.loss_dice: 1.2563  decode.d5.loss_cls: 1.0416  decode.d5.loss_mask: 0.7344  decode.d5.loss_dice: 1.2097  decode.d6.loss_cls: 1.0868  decode.d6.loss_mask: 0.7264  decode.d6.loss_dice: 1.2138  decode.d7.loss_cls: 1.0508  decode.d7.loss_mask: 0.7305  decode.d7.loss_dice: 1.2046  decode.d8.loss_cls: 1.0094  decode.d8.loss_mask: 0.7323  decode.d8.loss_dice: 1.2116
2023/05/24 13:20:08 - mmengine - INFO - Iter(train) [153500/160000]  lr: 5.5965e-07  eta: 0:47:01  time: 0.4362  data_time: 0.0105  memory: 4886  grad_norm: 102.0938  loss: 36.1693  decode.loss_cls: 1.3467  decode.loss_mask: 0.6456  decode.loss_dice: 1.3497  decode.d0.loss_cls: 3.1547  decode.d0.loss_mask: 0.7594  decode.d0.loss_dice: 1.6784  decode.d1.loss_cls: 1.3329  decode.d1.loss_mask: 0.6742  decode.d1.loss_dice: 1.4921  decode.d2.loss_cls: 1.3357  decode.d2.loss_mask: 0.6725  decode.d2.loss_dice: 1.4723  decode.d3.loss_cls: 1.3922  decode.d3.loss_mask: 0.6515  decode.d3.loss_dice: 1.3629  decode.d4.loss_cls: 1.3258  decode.d4.loss_mask: 0.6588  decode.d4.loss_dice: 1.3901  decode.d5.loss_cls: 1.3350  decode.d5.loss_mask: 0.6452  decode.d5.loss_dice: 1.3683  decode.d6.loss_cls: 1.3216  decode.d6.loss_mask: 0.6611  decode.d6.loss_dice: 1.3641  decode.d7.loss_cls: 1.3638  decode.d7.loss_mask: 0.6632  decode.d7.loss_dice: 1.3667  decode.d8.loss_cls: 1.3544  decode.d8.loss_mask: 0.6495  decode.d8.loss_dice: 1.3809
2023/05/24 13:20:29 - mmengine - INFO - Iter(train) [153550/160000]  lr: 5.5577e-07  eta: 0:46:39  time: 0.4220  data_time: 0.0101  memory: 4839  grad_norm: 98.5737  loss: 31.3279  decode.loss_cls: 1.0086  decode.loss_mask: 0.7370  decode.loss_dice: 1.1876  decode.d0.loss_cls: 2.7891  decode.d0.loss_mask: 0.7672  decode.d0.loss_dice: 1.3599  decode.d1.loss_cls: 1.1338  decode.d1.loss_mask: 0.7405  decode.d1.loss_dice: 1.2502  decode.d2.loss_cls: 1.0458  decode.d2.loss_mask: 0.7301  decode.d2.loss_dice: 1.2109  decode.d3.loss_cls: 1.0095  decode.d3.loss_mask: 0.7330  decode.d3.loss_dice: 1.1883  decode.d4.loss_cls: 0.9851  decode.d4.loss_mask: 0.7322  decode.d4.loss_dice: 1.1964  decode.d5.loss_cls: 0.9521  decode.d5.loss_mask: 0.7457  decode.d5.loss_dice: 1.1934  decode.d6.loss_cls: 0.9570  decode.d6.loss_mask: 0.7287  decode.d6.loss_dice: 1.1789  decode.d7.loss_cls: 0.9886  decode.d7.loss_mask: 0.7233  decode.d7.loss_dice: 1.1740  decode.d8.loss_cls: 0.9624  decode.d8.loss_mask: 0.7349  decode.d8.loss_dice: 1.1834
2023/05/24 13:20:50 - mmengine - INFO - Iter(train) [153600/160000]  lr: 5.5189e-07  eta: 0:46:17  time: 0.4218  data_time: 0.0101  memory: 4884  grad_norm: 89.3475  loss: 33.6362  decode.loss_cls: 1.3084  decode.loss_mask: 0.6383  decode.loss_dice: 1.1846  decode.d0.loss_cls: 3.1877  decode.d0.loss_mask: 0.7037  decode.d0.loss_dice: 1.3429  decode.d1.loss_cls: 1.3565  decode.d1.loss_mask: 0.7013  decode.d1.loss_dice: 1.3216  decode.d2.loss_cls: 1.2607  decode.d2.loss_mask: 0.6737  decode.d2.loss_dice: 1.2371  decode.d3.loss_cls: 1.2721  decode.d3.loss_mask: 0.6667  decode.d3.loss_dice: 1.2147  decode.d4.loss_cls: 1.2719  decode.d4.loss_mask: 0.6614  decode.d4.loss_dice: 1.2231  decode.d5.loss_cls: 1.2621  decode.d5.loss_mask: 0.6643  decode.d5.loss_dice: 1.2090  decode.d6.loss_cls: 1.2459  decode.d6.loss_mask: 0.6428  decode.d6.loss_dice: 1.1922  decode.d7.loss_cls: 1.2235  decode.d7.loss_mask: 0.6524  decode.d7.loss_dice: 1.2154  decode.d8.loss_cls: 1.2542  decode.d8.loss_mask: 0.6513  decode.d8.loss_dice: 1.1966
2023/05/24 13:21:11 - mmengine - INFO - Iter(train) [153650/160000]  lr: 5.4801e-07  eta: 0:45:55  time: 0.4215  data_time: 0.0099  memory: 4866  grad_norm: 83.9480  loss: 39.0259  decode.loss_cls: 1.2423  decode.loss_mask: 0.8431  decode.loss_dice: 1.5140  decode.d0.loss_cls: 3.4209  decode.d0.loss_mask: 0.9701  decode.d0.loss_dice: 1.8292  decode.d1.loss_cls: 1.3223  decode.d1.loss_mask: 0.9139  decode.d1.loss_dice: 1.6692  decode.d2.loss_cls: 1.2713  decode.d2.loss_mask: 0.8990  decode.d2.loss_dice: 1.5774  decode.d3.loss_cls: 1.2534  decode.d3.loss_mask: 0.8718  decode.d3.loss_dice: 1.5020  decode.d4.loss_cls: 1.2389  decode.d4.loss_mask: 0.8796  decode.d4.loss_dice: 1.4872  decode.d5.loss_cls: 1.2017  decode.d5.loss_mask: 0.8762  decode.d5.loss_dice: 1.5018  decode.d6.loss_cls: 1.2022  decode.d6.loss_mask: 0.8866  decode.d6.loss_dice: 1.4809  decode.d7.loss_cls: 1.1724  decode.d7.loss_mask: 0.8603  decode.d7.loss_dice: 1.5381  decode.d8.loss_cls: 1.2327  decode.d8.loss_mask: 0.8528  decode.d8.loss_dice: 1.5150
2023/05/24 13:21:33 - mmengine - INFO - Iter(train) [153700/160000]  lr: 5.4413e-07  eta: 0:45:34  time: 0.4280  data_time: 0.0099  memory: 4829  grad_norm: 102.6882  loss: 25.0825  decode.loss_cls: 0.7583  decode.loss_mask: 0.5666  decode.loss_dice: 0.9259  decode.d0.loss_cls: 2.4990  decode.d0.loss_mask: 0.6369  decode.d0.loss_dice: 1.0138  decode.d1.loss_cls: 0.9570  decode.d1.loss_mask: 0.5962  decode.d1.loss_dice: 1.0104  decode.d2.loss_cls: 0.8584  decode.d2.loss_mask: 0.5759  decode.d2.loss_dice: 0.9561  decode.d3.loss_cls: 0.8099  decode.d3.loss_mask: 0.5787  decode.d3.loss_dice: 0.9390  decode.d4.loss_cls: 0.8098  decode.d4.loss_mask: 0.5601  decode.d4.loss_dice: 0.9245  decode.d5.loss_cls: 0.7793  decode.d5.loss_mask: 0.5739  decode.d5.loss_dice: 0.9483  decode.d6.loss_cls: 0.7652  decode.d6.loss_mask: 0.5687  decode.d6.loss_dice: 0.9258  decode.d7.loss_cls: 0.7893  decode.d7.loss_mask: 0.5697  decode.d7.loss_dice: 0.9141  decode.d8.loss_cls: 0.7390  decode.d8.loss_mask: 0.5797  decode.d8.loss_dice: 0.9529
2023/05/24 13:21:54 - mmengine - INFO - Iter(train) [153750/160000]  lr: 5.4024e-07  eta: 0:45:12  time: 0.4204  data_time: 0.0100  memory: 4837  grad_norm: 101.9052  loss: 34.1972  decode.loss_cls: 1.3031  decode.loss_mask: 0.6549  decode.loss_dice: 1.2246  decode.d0.loss_cls: 3.0176  decode.d0.loss_mask: 0.7341  decode.d0.loss_dice: 1.4219  decode.d1.loss_cls: 1.4656  decode.d1.loss_mask: 0.7004  decode.d1.loss_dice: 1.3424  decode.d2.loss_cls: 1.3700  decode.d2.loss_mask: 0.7101  decode.d2.loss_dice: 1.3170  decode.d3.loss_cls: 1.3458  decode.d3.loss_mask: 0.6687  decode.d3.loss_dice: 1.2250  decode.d4.loss_cls: 1.2527  decode.d4.loss_mask: 0.6612  decode.d4.loss_dice: 1.2260  decode.d5.loss_cls: 1.2655  decode.d5.loss_mask: 0.6596  decode.d5.loss_dice: 1.2153  decode.d6.loss_cls: 1.2926  decode.d6.loss_mask: 0.6406  decode.d6.loss_dice: 1.2034  decode.d7.loss_cls: 1.3270  decode.d7.loss_mask: 0.6491  decode.d7.loss_dice: 1.1978  decode.d8.loss_cls: 1.2398  decode.d8.loss_mask: 0.6487  decode.d8.loss_dice: 1.2171
2023/05/24 13:22:15 - mmengine - INFO - Iter(train) [153800/160000]  lr: 5.3635e-07  eta: 0:44:50  time: 0.4287  data_time: 0.0100  memory: 4817  grad_norm: 100.1061  loss: 35.8604  decode.loss_cls: 1.1328  decode.loss_mask: 0.7005  decode.loss_dice: 1.3909  decode.d0.loss_cls: 2.7966  decode.d0.loss_mask: 0.8325  decode.d0.loss_dice: 1.6751  decode.d1.loss_cls: 1.2240  decode.d1.loss_mask: 0.7803  decode.d1.loss_dice: 1.6069  decode.d2.loss_cls: 1.1678  decode.d2.loss_mask: 0.8060  decode.d2.loss_dice: 1.5732  decode.d3.loss_cls: 1.1864  decode.d3.loss_mask: 0.7538  decode.d3.loss_dice: 1.5168  decode.d4.loss_cls: 1.2492  decode.d4.loss_mask: 0.7355  decode.d4.loss_dice: 1.4442  decode.d5.loss_cls: 1.1235  decode.d5.loss_mask: 0.7348  decode.d5.loss_dice: 1.4772  decode.d6.loss_cls: 1.2089  decode.d6.loss_mask: 0.7228  decode.d6.loss_dice: 1.4446  decode.d7.loss_cls: 1.1105  decode.d7.loss_mask: 0.7221  decode.d7.loss_dice: 1.4694  decode.d8.loss_cls: 1.1588  decode.d8.loss_mask: 0.7118  decode.d8.loss_dice: 1.4034
2023/05/24 13:22:37 - mmengine - INFO - Iter(train) [153850/160000]  lr: 5.3245e-07  eta: 0:44:29  time: 0.4252  data_time: 0.0102  memory: 4821  grad_norm: 84.7739  loss: 39.5135  decode.loss_cls: 1.3722  decode.loss_mask: 0.7895  decode.loss_dice: 1.4492  decode.d0.loss_cls: 3.4353  decode.d0.loss_mask: 0.8187  decode.d0.loss_dice: 1.7972  decode.d1.loss_cls: 1.6131  decode.d1.loss_mask: 0.8328  decode.d1.loss_dice: 1.6374  decode.d2.loss_cls: 1.4606  decode.d2.loss_mask: 0.8156  decode.d2.loss_dice: 1.5788  decode.d3.loss_cls: 1.4318  decode.d3.loss_mask: 0.8244  decode.d3.loss_dice: 1.4887  decode.d4.loss_cls: 1.3820  decode.d4.loss_mask: 0.8200  decode.d4.loss_dice: 1.4751  decode.d5.loss_cls: 1.3986  decode.d5.loss_mask: 0.7857  decode.d5.loss_dice: 1.4690  decode.d6.loss_cls: 1.3715  decode.d6.loss_mask: 0.7947  decode.d6.loss_dice: 1.4508  decode.d7.loss_cls: 1.3595  decode.d7.loss_mask: 0.7946  decode.d7.loss_dice: 1.4344  decode.d8.loss_cls: 1.3403  decode.d8.loss_mask: 0.8153  decode.d8.loss_dice: 1.4766
2023/05/24 13:22:59 - mmengine - INFO - Iter(train) [153900/160000]  lr: 5.2856e-07  eta: 0:44:07  time: 0.4869  data_time: 0.0104  memory: 4888  grad_norm: 163.0856  loss: 26.3289  decode.loss_cls: 0.9022  decode.loss_mask: 0.6415  decode.loss_dice: 0.8132  decode.d0.loss_cls: 2.9588  decode.d0.loss_mask: 0.6360  decode.d0.loss_dice: 0.9588  decode.d1.loss_cls: 0.9759  decode.d1.loss_mask: 0.6964  decode.d1.loss_dice: 0.9311  decode.d2.loss_cls: 0.8998  decode.d2.loss_mask: 0.6552  decode.d2.loss_dice: 0.8827  decode.d3.loss_cls: 0.8950  decode.d3.loss_mask: 0.6409  decode.d3.loss_dice: 0.8826  decode.d4.loss_cls: 0.8391  decode.d4.loss_mask: 0.6597  decode.d4.loss_dice: 0.8801  decode.d5.loss_cls: 0.8630  decode.d5.loss_mask: 0.6775  decode.d5.loss_dice: 0.8662  decode.d6.loss_cls: 0.8721  decode.d6.loss_mask: 0.6833  decode.d6.loss_dice: 0.8601  decode.d7.loss_cls: 0.8773  decode.d7.loss_mask: 0.6675  decode.d7.loss_dice: 0.8442  decode.d8.loss_cls: 0.9009  decode.d8.loss_mask: 0.6279  decode.d8.loss_dice: 0.8399
2023/05/24 13:23:22 - mmengine - INFO - Iter(train) [153950/160000]  lr: 5.2466e-07  eta: 0:43:45  time: 0.4768  data_time: 0.0100  memory: 4821  grad_norm: 110.9455  loss: 31.4798  decode.loss_cls: 0.9754  decode.loss_mask: 0.6485  decode.loss_dice: 1.1714  decode.d0.loss_cls: 3.1390  decode.d0.loss_mask: 0.7255  decode.d0.loss_dice: 1.4421  decode.d1.loss_cls: 1.1316  decode.d1.loss_mask: 0.7602  decode.d1.loss_dice: 1.3203  decode.d2.loss_cls: 1.0353  decode.d2.loss_mask: 0.7094  decode.d2.loss_dice: 1.2486  decode.d3.loss_cls: 0.9684  decode.d3.loss_mask: 0.7153  decode.d3.loss_dice: 1.2341  decode.d4.loss_cls: 0.9513  decode.d4.loss_mask: 0.7218  decode.d4.loss_dice: 1.2366  decode.d5.loss_cls: 0.9347  decode.d5.loss_mask: 0.7196  decode.d5.loss_dice: 1.2096  decode.d6.loss_cls: 0.9088  decode.d6.loss_mask: 0.7180  decode.d6.loss_dice: 1.2315  decode.d7.loss_cls: 0.9661  decode.d7.loss_mask: 0.6538  decode.d7.loss_dice: 1.1924  decode.d8.loss_cls: 0.9636  decode.d8.loss_mask: 0.6581  decode.d8.loss_dice: 1.1889
2023/05/24 13:23:46 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 13:23:46 - mmengine - INFO - Iter(train) [154000/160000]  lr: 5.2075e-07  eta: 0:43:24  time: 0.4778  data_time: 0.0098  memory: 4839  grad_norm: 132.0724  loss: 32.2292  decode.loss_cls: 0.9712  decode.loss_mask: 0.7882  decode.loss_dice: 1.2254  decode.d0.loss_cls: 3.0155  decode.d0.loss_mask: 0.7757  decode.d0.loss_dice: 1.3440  decode.d1.loss_cls: 1.1379  decode.d1.loss_mask: 0.7618  decode.d1.loss_dice: 1.2960  decode.d2.loss_cls: 1.0134  decode.d2.loss_mask: 0.7611  decode.d2.loss_dice: 1.2843  decode.d3.loss_cls: 1.0367  decode.d3.loss_mask: 0.7424  decode.d3.loss_dice: 1.2192  decode.d4.loss_cls: 1.0049  decode.d4.loss_mask: 0.7262  decode.d4.loss_dice: 1.2214  decode.d5.loss_cls: 1.0336  decode.d5.loss_mask: 0.7260  decode.d5.loss_dice: 1.2192  decode.d6.loss_cls: 1.0290  decode.d6.loss_mask: 0.7391  decode.d6.loss_dice: 1.1925  decode.d7.loss_cls: 1.0393  decode.d7.loss_mask: 0.7442  decode.d7.loss_dice: 1.1990  decode.d8.loss_cls: 0.9676  decode.d8.loss_mask: 0.7972  decode.d8.loss_dice: 1.2171
2023/05/24 13:23:46 - mmengine - INFO - Saving checkpoint at 154000 iterations
2023/05/24 13:24:14 - mmengine - INFO - Iter(train) [154050/160000]  lr: 5.1684e-07  eta: 0:43:02  time: 0.4242  data_time: 0.0101  memory: 4952  grad_norm: 100.7855  loss: 31.9066  decode.loss_cls: 1.0795  decode.loss_mask: 0.6022  decode.loss_dice: 1.1740  decode.d0.loss_cls: 3.2803  decode.d0.loss_mask: 0.6897  decode.d0.loss_dice: 1.4694  decode.d1.loss_cls: 1.2030  decode.d1.loss_mask: 0.6668  decode.d1.loss_dice: 1.3382  decode.d2.loss_cls: 1.2137  decode.d2.loss_mask: 0.6015  decode.d2.loss_dice: 1.2409  decode.d3.loss_cls: 1.1983  decode.d3.loss_mask: 0.5932  decode.d3.loss_dice: 1.1792  decode.d4.loss_cls: 1.0971  decode.d4.loss_mask: 0.6141  decode.d4.loss_dice: 1.1996  decode.d5.loss_cls: 1.1043  decode.d5.loss_mask: 0.5988  decode.d5.loss_dice: 1.2087  decode.d6.loss_cls: 1.1002  decode.d6.loss_mask: 0.5988  decode.d6.loss_dice: 1.1754  decode.d7.loss_cls: 1.0805  decode.d7.loss_mask: 0.6033  decode.d7.loss_dice: 1.1686  decode.d8.loss_cls: 1.0968  decode.d8.loss_mask: 0.5956  decode.d8.loss_dice: 1.1347
2023/05/24 13:24:36 - mmengine - INFO - Iter(train) [154100/160000]  lr: 5.1293e-07  eta: 0:42:40  time: 0.4236  data_time: 0.0102  memory: 4890  grad_norm: 86.0284  loss: 42.4403  decode.loss_cls: 1.2941  decode.loss_mask: 0.9019  decode.loss_dice: 1.7209  decode.d0.loss_cls: 3.1600  decode.d0.loss_mask: 1.0362  decode.d0.loss_dice: 2.0916  decode.d1.loss_cls: 1.4926  decode.d1.loss_mask: 0.9653  decode.d1.loss_dice: 1.8479  decode.d2.loss_cls: 1.3856  decode.d2.loss_mask: 0.9114  decode.d2.loss_dice: 1.7849  decode.d3.loss_cls: 1.3505  decode.d3.loss_mask: 0.9060  decode.d3.loss_dice: 1.7413  decode.d4.loss_cls: 1.3063  decode.d4.loss_mask: 0.9191  decode.d4.loss_dice: 1.7815  decode.d5.loss_cls: 1.3294  decode.d5.loss_mask: 0.9238  decode.d5.loss_dice: 1.7113  decode.d6.loss_cls: 1.3345  decode.d6.loss_mask: 0.8954  decode.d6.loss_dice: 1.7408  decode.d7.loss_cls: 1.3205  decode.d7.loss_mask: 0.8898  decode.d7.loss_dice: 1.7573  decode.d8.loss_cls: 1.3313  decode.d8.loss_mask: 0.8866  decode.d8.loss_dice: 1.7226
2023/05/24 13:24:58 - mmengine - INFO - Iter(train) [154150/160000]  lr: 5.0902e-07  eta: 0:42:19  time: 0.4696  data_time: 0.0098  memory: 4837  grad_norm: 91.0017  loss: 29.2531  decode.loss_cls: 0.8127  decode.loss_mask: 0.6220  decode.loss_dice: 1.1606  decode.d0.loss_cls: 3.0757  decode.d0.loss_mask: 0.7046  decode.d0.loss_dice: 1.3012  decode.d1.loss_cls: 0.9300  decode.d1.loss_mask: 0.6714  decode.d1.loss_dice: 1.2373  decode.d2.loss_cls: 0.9584  decode.d2.loss_mask: 0.6336  decode.d2.loss_dice: 1.1974  decode.d3.loss_cls: 0.9107  decode.d3.loss_mask: 0.6097  decode.d3.loss_dice: 1.1416  decode.d4.loss_cls: 0.9417  decode.d4.loss_mask: 0.5984  decode.d4.loss_dice: 1.1525  decode.d5.loss_cls: 0.9125  decode.d5.loss_mask: 0.6036  decode.d5.loss_dice: 1.1450  decode.d6.loss_cls: 0.9348  decode.d6.loss_mask: 0.6022  decode.d6.loss_dice: 1.1261  decode.d7.loss_cls: 0.8779  decode.d7.loss_mask: 0.6088  decode.d7.loss_dice: 1.1642  decode.d8.loss_cls: 0.8773  decode.d8.loss_mask: 0.6117  decode.d8.loss_dice: 1.1297
2023/05/24 13:25:19 - mmengine - INFO - Iter(train) [154200/160000]  lr: 5.0510e-07  eta: 0:41:57  time: 0.4184  data_time: 0.0097  memory: 4839  grad_norm: 90.0538  loss: 30.4078  decode.loss_cls: 1.0895  decode.loss_mask: 0.5900  decode.loss_dice: 1.0868  decode.d0.loss_cls: 2.8770  decode.d0.loss_mask: 0.6777  decode.d0.loss_dice: 1.2693  decode.d1.loss_cls: 1.1756  decode.d1.loss_mask: 0.6467  decode.d1.loss_dice: 1.2049  decode.d2.loss_cls: 1.0948  decode.d2.loss_mask: 0.6102  decode.d2.loss_dice: 1.1628  decode.d3.loss_cls: 1.1154  decode.d3.loss_mask: 0.6185  decode.d3.loss_dice: 1.1746  decode.d4.loss_cls: 1.1000  decode.d4.loss_mask: 0.5957  decode.d4.loss_dice: 1.1388  decode.d5.loss_cls: 1.0760  decode.d5.loss_mask: 0.5850  decode.d5.loss_dice: 1.1356  decode.d6.loss_cls: 1.1042  decode.d6.loss_mask: 0.5804  decode.d6.loss_dice: 1.1243  decode.d7.loss_cls: 1.0760  decode.d7.loss_mask: 0.5789  decode.d7.loss_dice: 1.1312  decode.d8.loss_cls: 1.0908  decode.d8.loss_mask: 0.5822  decode.d8.loss_dice: 1.1149
2023/05/24 13:25:41 - mmengine - INFO - Iter(train) [154250/160000]  lr: 5.0118e-07  eta: 0:41:35  time: 0.4293  data_time: 0.0100  memory: 4877  grad_norm: 95.2689  loss: 36.6052  decode.loss_cls: 1.3239  decode.loss_mask: 0.8169  decode.loss_dice: 1.2811  decode.d0.loss_cls: 3.1988  decode.d0.loss_mask: 0.8374  decode.d0.loss_dice: 1.4895  decode.d1.loss_cls: 1.2995  decode.d1.loss_mask: 0.9248  decode.d1.loss_dice: 1.4686  decode.d2.loss_cls: 1.2231  decode.d2.loss_mask: 0.8494  decode.d2.loss_dice: 1.3684  decode.d3.loss_cls: 1.2018  decode.d3.loss_mask: 0.8523  decode.d3.loss_dice: 1.3800  decode.d4.loss_cls: 1.3147  decode.d4.loss_mask: 0.8429  decode.d4.loss_dice: 1.2772  decode.d5.loss_cls: 1.3096  decode.d5.loss_mask: 0.8133  decode.d5.loss_dice: 1.3353  decode.d6.loss_cls: 1.2373  decode.d6.loss_mask: 0.8420  decode.d6.loss_dice: 1.2790  decode.d7.loss_cls: 1.3342  decode.d7.loss_mask: 0.8306  decode.d7.loss_dice: 1.2833  decode.d8.loss_cls: 1.3006  decode.d8.loss_mask: 0.8287  decode.d8.loss_dice: 1.2611
2023/05/24 13:26:02 - mmengine - INFO - Iter(train) [154300/160000]  lr: 4.9726e-07  eta: 0:41:14  time: 0.4297  data_time: 0.0109  memory: 4846  grad_norm: 108.1414  loss: 37.1836  decode.loss_cls: 1.1676  decode.loss_mask: 0.7574  decode.loss_dice: 1.4424  decode.d0.loss_cls: 3.1237  decode.d0.loss_mask: 0.8436  decode.d0.loss_dice: 1.7230  decode.d1.loss_cls: 1.2939  decode.d1.loss_mask: 0.8770  decode.d1.loss_dice: 1.5882  decode.d2.loss_cls: 1.2448  decode.d2.loss_mask: 0.8272  decode.d2.loss_dice: 1.4578  decode.d3.loss_cls: 1.2537  decode.d3.loss_mask: 0.7939  decode.d3.loss_dice: 1.4889  decode.d4.loss_cls: 1.2338  decode.d4.loss_mask: 0.8000  decode.d4.loss_dice: 1.4967  decode.d5.loss_cls: 1.1545  decode.d5.loss_mask: 0.7964  decode.d5.loss_dice: 1.4930  decode.d6.loss_cls: 1.2086  decode.d6.loss_mask: 0.7815  decode.d6.loss_dice: 1.4770  decode.d7.loss_cls: 1.1970  decode.d7.loss_mask: 0.7803  decode.d7.loss_dice: 1.4761  decode.d8.loss_cls: 1.1768  decode.d8.loss_mask: 0.7651  decode.d8.loss_dice: 1.4637
2023/05/24 13:26:23 - mmengine - INFO - Iter(train) [154350/160000]  lr: 4.9333e-07  eta: 0:40:52  time: 0.4307  data_time: 0.0100  memory: 4829  grad_norm: 99.9908  loss: 33.7341  decode.loss_cls: 1.0683  decode.loss_mask: 0.9009  decode.loss_dice: 1.2046  decode.d0.loss_cls: 2.9463  decode.d0.loss_mask: 0.9152  decode.d0.loss_dice: 1.3339  decode.d1.loss_cls: 1.1433  decode.d1.loss_mask: 0.8871  decode.d1.loss_dice: 1.2554  decode.d2.loss_cls: 1.0340  decode.d2.loss_mask: 0.9289  decode.d2.loss_dice: 1.2573  decode.d3.loss_cls: 1.0200  decode.d3.loss_mask: 0.9230  decode.d3.loss_dice: 1.2101  decode.d4.loss_cls: 1.0278  decode.d4.loss_mask: 0.9112  decode.d4.loss_dice: 1.2162  decode.d5.loss_cls: 1.0186  decode.d5.loss_mask: 0.9066  decode.d5.loss_dice: 1.2203  decode.d6.loss_cls: 0.9777  decode.d6.loss_mask: 0.9069  decode.d6.loss_dice: 1.1984  decode.d7.loss_cls: 1.0149  decode.d7.loss_mask: 0.9215  decode.d7.loss_dice: 1.2047  decode.d8.loss_cls: 1.0627  decode.d8.loss_mask: 0.9129  decode.d8.loss_dice: 1.2053
2023/05/24 13:26:46 - mmengine - INFO - Iter(train) [154400/160000]  lr: 4.8940e-07  eta: 0:40:30  time: 0.4729  data_time: 0.0098  memory: 4836  grad_norm: 97.2485  loss: 35.8694  decode.loss_cls: 1.2681  decode.loss_mask: 0.6734  decode.loss_dice: 1.3520  decode.d0.loss_cls: 3.2533  decode.d0.loss_mask: 0.7206  decode.d0.loss_dice: 1.5524  decode.d1.loss_cls: 1.3184  decode.d1.loss_mask: 0.7750  decode.d1.loss_dice: 1.4821  decode.d2.loss_cls: 1.2849  decode.d2.loss_mask: 0.7622  decode.d2.loss_dice: 1.4585  decode.d3.loss_cls: 1.2585  decode.d3.loss_mask: 0.7460  decode.d3.loss_dice: 1.4209  decode.d4.loss_cls: 1.2337  decode.d4.loss_mask: 0.7254  decode.d4.loss_dice: 1.3963  decode.d5.loss_cls: 1.2272  decode.d5.loss_mask: 0.7146  decode.d5.loss_dice: 1.3716  decode.d6.loss_cls: 1.2531  decode.d6.loss_mask: 0.6913  decode.d6.loss_dice: 1.3544  decode.d7.loss_cls: 1.2290  decode.d7.loss_mask: 0.6995  decode.d7.loss_dice: 1.3378  decode.d8.loss_cls: 1.2770  decode.d8.loss_mask: 0.6975  decode.d8.loss_dice: 1.3349
2023/05/24 13:27:08 - mmengine - INFO - Iter(train) [154450/160000]  lr: 4.8547e-07  eta: 0:40:09  time: 0.4314  data_time: 0.0105  memory: 4869  grad_norm: 91.0944  loss: 28.6438  decode.loss_cls: 0.8230  decode.loss_mask: 0.6925  decode.loss_dice: 1.0273  decode.d0.loss_cls: 2.8850  decode.d0.loss_mask: 0.7401  decode.d0.loss_dice: 1.2033  decode.d1.loss_cls: 0.9769  decode.d1.loss_mask: 0.7823  decode.d1.loss_dice: 1.1128  decode.d2.loss_cls: 0.9418  decode.d2.loss_mask: 0.7381  decode.d2.loss_dice: 1.0707  decode.d3.loss_cls: 0.9289  decode.d3.loss_mask: 0.7271  decode.d3.loss_dice: 1.0540  decode.d4.loss_cls: 0.8736  decode.d4.loss_mask: 0.7032  decode.d4.loss_dice: 1.0537  decode.d5.loss_cls: 0.8856  decode.d5.loss_mask: 0.6852  decode.d5.loss_dice: 1.0356  decode.d6.loss_cls: 0.8527  decode.d6.loss_mask: 0.6917  decode.d6.loss_dice: 1.0484  decode.d7.loss_cls: 0.8377  decode.d7.loss_mask: 0.6911  decode.d7.loss_dice: 1.0345  decode.d8.loss_cls: 0.8390  decode.d8.loss_mask: 0.6804  decode.d8.loss_dice: 1.0276
2023/05/24 13:27:30 - mmengine - INFO - Iter(train) [154500/160000]  lr: 4.8153e-07  eta: 0:39:47  time: 0.4245  data_time: 0.0102  memory: 4910  grad_norm: 93.3258  loss: 34.3152  decode.loss_cls: 1.0675  decode.loss_mask: 0.8014  decode.loss_dice: 1.2471  decode.d0.loss_cls: 3.2118  decode.d0.loss_mask: 0.7908  decode.d0.loss_dice: 1.5772  decode.d1.loss_cls: 1.1543  decode.d1.loss_mask: 0.8155  decode.d1.loss_dice: 1.4182  decode.d2.loss_cls: 1.1839  decode.d2.loss_mask: 0.7888  decode.d2.loss_dice: 1.3269  decode.d3.loss_cls: 1.1982  decode.d3.loss_mask: 0.7744  decode.d3.loss_dice: 1.2566  decode.d4.loss_cls: 1.1310  decode.d4.loss_mask: 0.7880  decode.d4.loss_dice: 1.2944  decode.d5.loss_cls: 1.0895  decode.d5.loss_mask: 0.7767  decode.d5.loss_dice: 1.2959  decode.d6.loss_cls: 1.1026  decode.d6.loss_mask: 0.7846  decode.d6.loss_dice: 1.2393  decode.d7.loss_cls: 1.0756  decode.d7.loss_mask: 0.7787  decode.d7.loss_dice: 1.2373  decode.d8.loss_cls: 1.1013  decode.d8.loss_mask: 0.7800  decode.d8.loss_dice: 1.2279
2023/05/24 13:27:53 - mmengine - INFO - Iter(train) [154550/160000]  lr: 4.7759e-07  eta: 0:39:25  time: 0.4817  data_time: 0.0098  memory: 4837  grad_norm: 93.2862  loss: 38.2526  decode.loss_cls: 1.3077  decode.loss_mask: 0.7907  decode.loss_dice: 1.4527  decode.d0.loss_cls: 3.3974  decode.d0.loss_mask: 0.8414  decode.d0.loss_dice: 1.6865  decode.d1.loss_cls: 1.5021  decode.d1.loss_mask: 0.8816  decode.d1.loss_dice: 1.6280  decode.d2.loss_cls: 1.3763  decode.d2.loss_mask: 0.8304  decode.d2.loss_dice: 1.4687  decode.d3.loss_cls: 1.3793  decode.d3.loss_mask: 0.7807  decode.d3.loss_dice: 1.4449  decode.d4.loss_cls: 1.3227  decode.d4.loss_mask: 0.7831  decode.d4.loss_dice: 1.4260  decode.d5.loss_cls: 1.2873  decode.d5.loss_mask: 0.7912  decode.d5.loss_dice: 1.4209  decode.d6.loss_cls: 1.3001  decode.d6.loss_mask: 0.7830  decode.d6.loss_dice: 1.3984  decode.d7.loss_cls: 1.2833  decode.d7.loss_mask: 0.7823  decode.d7.loss_dice: 1.4161  decode.d8.loss_cls: 1.3131  decode.d8.loss_mask: 0.7843  decode.d8.loss_dice: 1.3923
2023/05/24 13:28:15 - mmengine - INFO - Iter(train) [154600/160000]  lr: 4.7364e-07  eta: 0:39:04  time: 0.4235  data_time: 0.0098  memory: 4836  grad_norm: 91.4326  loss: 31.7221  decode.loss_cls: 1.0389  decode.loss_mask: 0.7020  decode.loss_dice: 1.0787  decode.d0.loss_cls: 3.0329  decode.d0.loss_mask: 0.7222  decode.d0.loss_dice: 1.2905  decode.d1.loss_cls: 1.2413  decode.d1.loss_mask: 0.7411  decode.d1.loss_dice: 1.2485  decode.d2.loss_cls: 1.1919  decode.d2.loss_mask: 0.7160  decode.d2.loss_dice: 1.1832  decode.d3.loss_cls: 1.1336  decode.d3.loss_mask: 0.7083  decode.d3.loss_dice: 1.1525  decode.d4.loss_cls: 1.1160  decode.d4.loss_mask: 0.7164  decode.d4.loss_dice: 1.1140  decode.d5.loss_cls: 1.0719  decode.d5.loss_mask: 0.7161  decode.d5.loss_dice: 1.1573  decode.d6.loss_cls: 1.1079  decode.d6.loss_mask: 0.6905  decode.d6.loss_dice: 1.1202  decode.d7.loss_cls: 1.0722  decode.d7.loss_mask: 0.6999  decode.d7.loss_dice: 1.1393  decode.d8.loss_cls: 1.0261  decode.d8.loss_mask: 0.6987  decode.d8.loss_dice: 1.0941
2023/05/24 13:28:36 - mmengine - INFO - Iter(train) [154650/160000]  lr: 4.6969e-07  eta: 0:38:42  time: 0.4250  data_time: 0.0102  memory: 4857  grad_norm: 89.7971  loss: 34.1187  decode.loss_cls: 1.2582  decode.loss_mask: 0.7231  decode.loss_dice: 1.1269  decode.d0.loss_cls: 3.2647  decode.d0.loss_mask: 0.8633  decode.d0.loss_dice: 1.3707  decode.d1.loss_cls: 1.4071  decode.d1.loss_mask: 0.8065  decode.d1.loss_dice: 1.2715  decode.d2.loss_cls: 1.3479  decode.d2.loss_mask: 0.7651  decode.d2.loss_dice: 1.2237  decode.d3.loss_cls: 1.2361  decode.d3.loss_mask: 0.7457  decode.d3.loss_dice: 1.1562  decode.d4.loss_cls: 1.2424  decode.d4.loss_mask: 0.7236  decode.d4.loss_dice: 1.1211  decode.d5.loss_cls: 1.2516  decode.d5.loss_mask: 0.7197  decode.d5.loss_dice: 1.1272  decode.d6.loss_cls: 1.2636  decode.d6.loss_mask: 0.7259  decode.d6.loss_dice: 1.1372  decode.d7.loss_cls: 1.2382  decode.d7.loss_mask: 0.7200  decode.d7.loss_dice: 1.1374  decode.d8.loss_cls: 1.2600  decode.d8.loss_mask: 0.7218  decode.d8.loss_dice: 1.1620
2023/05/24 13:28:58 - mmengine - INFO - Iter(train) [154700/160000]  lr: 4.6574e-07  eta: 0:38:20  time: 0.4189  data_time: 0.0101  memory: 4865  grad_norm: 89.4029  loss: 29.8044  decode.loss_cls: 0.9728  decode.loss_mask: 0.6382  decode.loss_dice: 1.0411  decode.d0.loss_cls: 2.8858  decode.d0.loss_mask: 0.6986  decode.d0.loss_dice: 1.2505  decode.d1.loss_cls: 1.1353  decode.d1.loss_mask: 0.6937  decode.d1.loss_dice: 1.1709  decode.d2.loss_cls: 1.1184  decode.d2.loss_mask: 0.6766  decode.d2.loss_dice: 1.1546  decode.d3.loss_cls: 1.1028  decode.d3.loss_mask: 0.6468  decode.d3.loss_dice: 1.0635  decode.d4.loss_cls: 1.1175  decode.d4.loss_mask: 0.6468  decode.d4.loss_dice: 1.0427  decode.d5.loss_cls: 1.0283  decode.d5.loss_mask: 0.6478  decode.d5.loss_dice: 1.0652  decode.d6.loss_cls: 1.0218  decode.d6.loss_mask: 0.6423  decode.d6.loss_dice: 1.0568  decode.d7.loss_cls: 0.9509  decode.d7.loss_mask: 0.6380  decode.d7.loss_dice: 1.0632  decode.d8.loss_cls: 0.9320  decode.d8.loss_mask: 0.6459  decode.d8.loss_dice: 1.0555
2023/05/24 13:29:19 - mmengine - INFO - Iter(train) [154750/160000]  lr: 4.6178e-07  eta: 0:37:58  time: 0.4233  data_time: 0.0101  memory: 4836  grad_norm: 84.4977  loss: 36.4488  decode.loss_cls: 1.0371  decode.loss_mask: 0.8382  decode.loss_dice: 1.4310  decode.d0.loss_cls: 3.1261  decode.d0.loss_mask: 0.8945  decode.d0.loss_dice: 1.6820  decode.d1.loss_cls: 1.1750  decode.d1.loss_mask: 0.9298  decode.d1.loss_dice: 1.6204  decode.d2.loss_cls: 1.0867  decode.d2.loss_mask: 0.8918  decode.d2.loss_dice: 1.4944  decode.d3.loss_cls: 1.0439  decode.d3.loss_mask: 0.8773  decode.d3.loss_dice: 1.4815  decode.d4.loss_cls: 1.0492  decode.d4.loss_mask: 0.8577  decode.d4.loss_dice: 1.4667  decode.d5.loss_cls: 1.0407  decode.d5.loss_mask: 0.8542  decode.d5.loss_dice: 1.5041  decode.d6.loss_cls: 1.0910  decode.d6.loss_mask: 0.8456  decode.d6.loss_dice: 1.4281  decode.d7.loss_cls: 1.0794  decode.d7.loss_mask: 0.8428  decode.d7.loss_dice: 1.4590  decode.d8.loss_cls: 1.0141  decode.d8.loss_mask: 0.8645  decode.d8.loss_dice: 1.4420
2023/05/24 13:29:40 - mmengine - INFO - Iter(train) [154800/160000]  lr: 4.5782e-07  eta: 0:37:37  time: 0.4212  data_time: 0.0099  memory: 4837  grad_norm: 102.2422  loss: 31.9387  decode.loss_cls: 1.2237  decode.loss_mask: 0.7435  decode.loss_dice: 0.9884  decode.d0.loss_cls: 2.9707  decode.d0.loss_mask: 0.8185  decode.d0.loss_dice: 1.1981  decode.d1.loss_cls: 1.3284  decode.d1.loss_mask: 0.8005  decode.d1.loss_dice: 1.1162  decode.d2.loss_cls: 1.2138  decode.d2.loss_mask: 0.7603  decode.d2.loss_dice: 1.0716  decode.d3.loss_cls: 1.2410  decode.d3.loss_mask: 0.7320  decode.d3.loss_dice: 1.0314  decode.d4.loss_cls: 1.2003  decode.d4.loss_mask: 0.7330  decode.d4.loss_dice: 1.0539  decode.d5.loss_cls: 1.2323  decode.d5.loss_mask: 0.7259  decode.d5.loss_dice: 1.0078  decode.d6.loss_cls: 1.1670  decode.d6.loss_mask: 0.7351  decode.d6.loss_dice: 0.9861  decode.d7.loss_cls: 1.1509  decode.d7.loss_mask: 0.7430  decode.d7.loss_dice: 1.0053  decode.d8.loss_cls: 1.2195  decode.d8.loss_mask: 0.7405  decode.d8.loss_dice: 1.0001
2023/05/24 13:30:01 - mmengine - INFO - Iter(train) [154850/160000]  lr: 4.5386e-07  eta: 0:37:15  time: 0.4243  data_time: 0.0098  memory: 4857  grad_norm: 96.9782  loss: 32.3348  decode.loss_cls: 1.0886  decode.loss_mask: 0.6788  decode.loss_dice: 1.1941  decode.d0.loss_cls: 3.0183  decode.d0.loss_mask: 0.7139  decode.d0.loss_dice: 1.4364  decode.d1.loss_cls: 1.1929  decode.d1.loss_mask: 0.7024  decode.d1.loss_dice: 1.2907  decode.d2.loss_cls: 1.1418  decode.d2.loss_mask: 0.6789  decode.d2.loss_dice: 1.2589  decode.d3.loss_cls: 1.0698  decode.d3.loss_mask: 0.6934  decode.d3.loss_dice: 1.2142  decode.d4.loss_cls: 1.1448  decode.d4.loss_mask: 0.6933  decode.d4.loss_dice: 1.2159  decode.d5.loss_cls: 1.0825  decode.d5.loss_mask: 0.6778  decode.d5.loss_dice: 1.1903  decode.d6.loss_cls: 1.1038  decode.d6.loss_mask: 0.6812  decode.d6.loss_dice: 1.1865  decode.d7.loss_cls: 1.1164  decode.d7.loss_mask: 0.6906  decode.d7.loss_dice: 1.2030  decode.d8.loss_cls: 1.1292  decode.d8.loss_mask: 0.6716  decode.d8.loss_dice: 1.1749
2023/05/24 13:30:23 - mmengine - INFO - Iter(train) [154900/160000]  lr: 4.4989e-07  eta: 0:36:53  time: 0.4390  data_time: 0.0101  memory: 4846  grad_norm: 96.6208  loss: 33.1563  decode.loss_cls: 1.0400  decode.loss_mask: 0.7567  decode.loss_dice: 1.1840  decode.d0.loss_cls: 3.0718  decode.d0.loss_mask: 0.8368  decode.d0.loss_dice: 1.4141  decode.d1.loss_cls: 1.3437  decode.d1.loss_mask: 0.8117  decode.d1.loss_dice: 1.3132  decode.d2.loss_cls: 1.2225  decode.d2.loss_mask: 0.7485  decode.d2.loss_dice: 1.2431  decode.d3.loss_cls: 1.1714  decode.d3.loss_mask: 0.7294  decode.d3.loss_dice: 1.2305  decode.d4.loss_cls: 1.1310  decode.d4.loss_mask: 0.7267  decode.d4.loss_dice: 1.2108  decode.d5.loss_cls: 1.1171  decode.d5.loss_mask: 0.7240  decode.d5.loss_dice: 1.1962  decode.d6.loss_cls: 1.0854  decode.d6.loss_mask: 0.7358  decode.d6.loss_dice: 1.1565  decode.d7.loss_cls: 1.0673  decode.d7.loss_mask: 0.7360  decode.d7.loss_dice: 1.1704  decode.d8.loss_cls: 1.0625  decode.d8.loss_mask: 0.7445  decode.d8.loss_dice: 1.1747
2023/05/24 13:30:45 - mmengine - INFO - Iter(train) [154950/160000]  lr: 4.4592e-07  eta: 0:36:32  time: 0.4194  data_time: 0.0107  memory: 4884  grad_norm: 93.4504  loss: 32.5495  decode.loss_cls: 1.0904  decode.loss_mask: 0.7243  decode.loss_dice: 1.1531  decode.d0.loss_cls: 3.1583  decode.d0.loss_mask: 0.7273  decode.d0.loss_dice: 1.2814  decode.d1.loss_cls: 1.2024  decode.d1.loss_mask: 0.7342  decode.d1.loss_dice: 1.2344  decode.d2.loss_cls: 1.1717  decode.d2.loss_mask: 0.7049  decode.d2.loss_dice: 1.2215  decode.d3.loss_cls: 1.1009  decode.d3.loss_mask: 0.7336  decode.d3.loss_dice: 1.2046  decode.d4.loss_cls: 1.1512  decode.d4.loss_mask: 0.7428  decode.d4.loss_dice: 1.1909  decode.d5.loss_cls: 1.1423  decode.d5.loss_mask: 0.7542  decode.d5.loss_dice: 1.1956  decode.d6.loss_cls: 1.1267  decode.d6.loss_mask: 0.7139  decode.d6.loss_dice: 1.1541  decode.d7.loss_cls: 1.0942  decode.d7.loss_mask: 0.7153  decode.d7.loss_dice: 1.1449  decode.d8.loss_cls: 1.1166  decode.d8.loss_mask: 0.7181  decode.d8.loss_dice: 1.1457
2023/05/24 13:31:06 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 13:31:06 - mmengine - INFO - Iter(train) [155000/160000]  lr: 4.4194e-07  eta: 0:36:10  time: 0.4239  data_time: 0.0101  memory: 4829  grad_norm: 75.8040  loss: 34.1585  decode.loss_cls: 1.0943  decode.loss_mask: 0.6788  decode.loss_dice: 1.3267  decode.d0.loss_cls: 3.2468  decode.d0.loss_mask: 0.7246  decode.d0.loss_dice: 1.5178  decode.d1.loss_cls: 1.2379  decode.d1.loss_mask: 0.7416  decode.d1.loss_dice: 1.4847  decode.d2.loss_cls: 1.1331  decode.d2.loss_mask: 0.7277  decode.d2.loss_dice: 1.4214  decode.d3.loss_cls: 1.0716  decode.d3.loss_mask: 0.7107  decode.d3.loss_dice: 1.3799  decode.d4.loss_cls: 1.0990  decode.d4.loss_mask: 0.7045  decode.d4.loss_dice: 1.3878  decode.d5.loss_cls: 1.0665  decode.d5.loss_mask: 0.6885  decode.d5.loss_dice: 1.3707  decode.d6.loss_cls: 1.1092  decode.d6.loss_mask: 0.6752  decode.d6.loss_dice: 1.3256  decode.d7.loss_cls: 1.1346  decode.d7.loss_mask: 0.6725  decode.d7.loss_dice: 1.3416  decode.d8.loss_cls: 1.0881  decode.d8.loss_mask: 0.6760  decode.d8.loss_dice: 1.3210
2023/05/24 13:31:06 - mmengine - INFO - Saving checkpoint at 155000 iterations
2023/05/24 13:31:15 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:46  time: 0.0793  data_time: 0.0019  memory: 2167  
2023/05/24 13:31:19 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:43  time: 0.0797  data_time: 0.0018  memory: 2216  
2023/05/24 13:31:24 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:40  time: 0.0999  data_time: 0.0020  memory: 2167  
2023/05/24 13:31:28 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0787  data_time: 0.0018  memory: 2104  
2023/05/24 13:31:32 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0792  data_time: 0.0019  memory: 2831  
2023/05/24 13:31:36 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:27  time: 0.0872  data_time: 0.0020  memory: 2167  
2023/05/24 13:31:43 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:24  time: 0.0900  data_time: 0.0018  memory: 2167  
2023/05/24 13:31:47 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:20  time: 0.0961  data_time: 0.0019  memory: 2167  
2023/05/24 13:31:51 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:15  time: 0.0788  data_time: 0.0019  memory: 2944  
2023/05/24 13:31:55 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:11  time: 0.0861  data_time: 0.0019  memory: 2356  
2023/05/24 13:32:00 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0790  data_time: 0.0018  memory: 2217  
2023/05/24 13:32:04 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0782  data_time: 0.0017  memory: 2328  
2023/05/24 13:32:07 - mmengine - INFO - per class results:
2023/05/24 13:32:07 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.47 | 93.79 |
|     bicycle      | 70.55 | 84.58 |
|       car        | 63.17 | 85.07 |
|    motorcycle    | 83.56 | 90.23 |
|     airplane     | 85.69 | 93.55 |
|       bus        | 82.65 |  88.4 |
|      train       | 82.98 | 94.74 |
|      truck       | 57.02 | 75.17 |
|       boat       | 61.37 | 78.85 |
|  traffic light   | 68.99 | 85.31 |
|   fire hydrant   |  88.7 | 95.09 |
|    stop sign     | 91.29 | 97.07 |
|  parking meter   | 76.39 | 87.58 |
|      bench       | 48.89 | 71.49 |
|       bird       | 81.75 | 91.25 |
|       cat        | 85.52 | 91.94 |
|       dog        | 82.11 | 88.13 |
|      horse       | 78.87 | 91.06 |
|      sheep       | 85.89 | 92.26 |
|       cow        | 82.33 | 88.99 |
|     elephant     | 89.59 |  95.3 |
|       bear       | 92.53 | 95.29 |
|      zebra       | 90.35 | 93.55 |
|     giraffe      | 87.51 | 93.68 |
|     backpack     | 36.69 | 62.86 |
|     umbrella     | 79.87 | 88.63 |
|     handbag      | 36.17 | 57.92 |
|       tie        | 12.75 |  16.0 |
|     suitcase     | 77.56 | 90.69 |
|     frisbee      | 69.52 | 91.53 |
|       skis       | 46.81 | 64.04 |
|    snowboard     | 59.35 | 74.61 |
|   sports ball    | 56.55 | 74.14 |
|       kite       | 57.79 | 71.61 |
|   baseball bat   | 54.27 | 69.53 |
|  baseball glove  | 73.23 | 87.13 |
|    skateboard    | 76.52 | 84.85 |
|    surfboard     | 72.83 | 87.34 |
|  tennis racket   | 85.75 | 92.45 |
|      bottle      | 41.62 | 52.61 |
|    wine glass    | 56.18 | 75.45 |
|       cup        | 50.72 | 71.57 |
|       fork       |  32.9 |  41.0 |
|      knife       | 32.21 | 41.73 |
|      spoon       | 39.21 | 56.38 |
|       bowl       | 45.64 |  65.9 |
|      banana      | 66.51 | 87.18 |
|      apple       |  49.3 | 70.99 |
|     sandwich     | 41.41 | 55.94 |
|      orange      | 59.17 | 64.26 |
|     broccoli     | 52.81 |  63.4 |
|      carrot      | 51.11 | 55.87 |
|     hot dog      | 45.67 | 55.42 |
|      pizza       |  66.3 | 81.79 |
|      donut       | 70.36 | 85.79 |
|       cake       | 59.95 | 72.28 |
|      chair       | 47.77 | 68.45 |
|      couch       | 56.02 | 80.61 |
|   potted plant   | 31.11 | 48.34 |
|       bed        | 62.19 | 81.66 |
|   dining table   | 43.14 | 79.48 |
|      toilet      | 81.79 |  93.8 |
|        tv        |  70.7 |  85.3 |
|      laptop      | 74.99 | 91.31 |
|      mouse       |  76.7 | 89.37 |
|      remote      | 56.66 | 73.23 |
|     keyboard     | 63.34 |  72.6 |
|    cell phone    | 73.33 | 89.79 |
|    microwave     | 62.92 | 76.27 |
|       oven       | 56.06 | 79.76 |
|     toaster      | 42.66 | 54.64 |
|       sink       | 57.69 |  78.6 |
|   refrigerator   | 78.11 | 92.23 |
|       book       | 49.55 | 71.12 |
|      clock       | 73.19 | 82.69 |
|       vase       | 58.18 | 82.54 |
|     scissors     | 78.86 | 90.32 |
|    teddy bear    | 75.89 | 87.07 |
|    hair drier    | 45.43 | 48.48 |
|    toothbrush    | 42.14 | 78.22 |
|      banner      | 36.05 | 64.57 |
|     blanket      |  2.23 |  2.35 |
|      branch      | 17.65 | 26.42 |
|      bridge      | 33.26 | 50.51 |
|  building-other  | 53.64 | 74.32 |
|       bush       | 32.75 | 46.07 |
|     cabinet      | 53.46 | 73.65 |
|       cage       |  21.6 | 34.28 |
|    cardboard     | 46.61 | 57.42 |
|      carpet      | 52.35 | 73.81 |
|  ceiling-other   | 64.68 | 81.91 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 21.17 | 29.38 |
|      clouds      | 47.02 | 61.92 |
|     counter      | 26.94 | 45.62 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 64.85 |  78.0 |
|    desk-stuff    | 46.04 | 61.01 |
|       dirt       | 41.83 | 59.98 |
|    door-stuff    | 40.84 | 61.88 |
|      fence       | 30.88 | 54.62 |
|   floor-marble   |  5.52 |  6.42 |
|   floor-other    | 23.48 | 30.31 |
|   floor-stone    |  3.01 |  3.58 |
|    floor-tile    | 59.64 | 69.58 |
|    floor-wood    | 60.58 | 74.85 |
|      flower      | 41.11 | 60.68 |
|       fog        |  8.68 |  9.29 |
|    food-other    | 25.42 | 30.12 |
|      fruit       | 39.67 | 59.79 |
| furniture-other  | 17.91 |  24.2 |
|      grass       | 70.08 | 83.46 |
|      gravel      | 26.62 | 38.89 |
|   ground-other   |  0.54 |  0.63 |
|       hill       | 22.29 |  31.3 |
|      house       | 25.44 | 30.61 |
|      leaves      | 24.32 | 33.37 |
|      light       |  37.6 | 53.67 |
|       mat        |  0.0  |  0.0  |
|      metal       | 32.01 | 45.95 |
|   mirror-stuff   | 52.05 | 70.89 |
|       moss       |  0.0  |  0.0  |
|     mountain     |  52.3 | 67.68 |
|       mud        |  5.35 |  7.98 |
|      napkin      |  13.4 | 13.59 |
|       net        | 42.86 | 64.24 |
|      paper       | 29.18 | 41.04 |
|     pavement     | 51.56 | 72.61 |
|      pillow      | 14.34 | 17.84 |
|   plant-other    | 18.65 | 33.46 |
|     plastic      | 23.37 | 31.66 |
|     platform     | 27.39 |  42.5 |
|   playingfield   | 70.31 | 91.72 |
|     railing      |  5.89 |  9.55 |
|     railroad     | 61.39 | 78.53 |
|      river       | 51.33 | 68.81 |
|       road       |  67.1 | 82.03 |
|       rock       |  42.5 | 62.72 |
|       roof       | 17.31 | 22.72 |
|       rug        | 36.18 | 54.18 |
|      salad       |  0.0  |  0.0  |
|       sand       | 62.86 | 70.44 |
|       sea        | 85.94 | 91.86 |
|      shelf       | 34.48 |  50.6 |
|    sky-other     | 70.86 | 86.85 |
|    skyscraper    | 33.88 | 44.21 |
|       snow       | 89.14 | 92.93 |
|   solid-other    |  0.23 |  0.24 |
|      stairs      | 23.42 | 41.03 |
|      stone       |  12.1 | 21.53 |
|      straw       | 25.13 | 31.58 |
| structural-other |  0.06 |  0.07 |
|      table       | 14.93 | 19.21 |
|       tent       |  7.17 |  9.43 |
|  textile-other   |  12.6 | 20.26 |
|      towel       | 34.54 | 42.62 |
|       tree       | 73.63 | 86.17 |
|    vegetable     | 33.54 | 44.66 |
|    wall-brick    | 49.17 | 63.84 |
|  wall-concrete   | 60.82 | 79.33 |
|    wall-other    | 19.81 | 32.05 |
|    wall-panel    |  3.01 |  3.48 |
|    wall-stone    |  34.9 | 39.98 |
|    wall-tile     | 67.01 | 82.73 |
|    wall-wood     | 41.11 | 58.06 |
|   water-other    | 24.81 | 39.73 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 51.35 | 62.03 |
|   window-other   | 48.33 | 72.32 |
|       wood       |  24.7 | 37.74 |
+------------------+-------+-------+
2023/05/24 13:32:07 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.5200  mIoU: 47.3600  mAcc: 59.7200  data_time: 0.0021  time: 0.0870
2023/05/24 13:32:29 - mmengine - INFO - Iter(train) [155050/160000]  lr: 4.3796e-07  eta: 0:35:48  time: 0.4276  data_time: 0.0108  memory: 4875  grad_norm: 87.2381  loss: 32.1408  decode.loss_cls: 1.0423  decode.loss_mask: 0.6986  decode.loss_dice: 1.1148  decode.d0.loss_cls: 3.0757  decode.d0.loss_mask: 0.8152  decode.d0.loss_dice: 1.3010  decode.d1.loss_cls: 1.1276  decode.d1.loss_mask: 0.7816  decode.d1.loss_dice: 1.2785  decode.d2.loss_cls: 1.1312  decode.d2.loss_mask: 0.7980  decode.d2.loss_dice: 1.2260  decode.d3.loss_cls: 1.1334  decode.d3.loss_mask: 0.7603  decode.d3.loss_dice: 1.1914  decode.d4.loss_cls: 1.0582  decode.d4.loss_mask: 0.7377  decode.d4.loss_dice: 1.1874  decode.d5.loss_cls: 1.0725  decode.d5.loss_mask: 0.7166  decode.d5.loss_dice: 1.1698  decode.d6.loss_cls: 1.0990  decode.d6.loss_mask: 0.6918  decode.d6.loss_dice: 1.1417  decode.d7.loss_cls: 1.0673  decode.d7.loss_mask: 0.6929  decode.d7.loss_dice: 1.1451  decode.d8.loss_cls: 1.0692  decode.d8.loss_mask: 0.6973  decode.d8.loss_dice: 1.1185
2023/05/24 13:32:51 - mmengine - INFO - Iter(train) [155100/160000]  lr: 4.3398e-07  eta: 0:35:26  time: 0.4354  data_time: 0.0110  memory: 4903  grad_norm: 97.5074  loss: 31.7458  decode.loss_cls: 1.0521  decode.loss_mask: 0.7120  decode.loss_dice: 1.1447  decode.d0.loss_cls: 2.8724  decode.d0.loss_mask: 0.7673  decode.d0.loss_dice: 1.3574  decode.d1.loss_cls: 1.2256  decode.d1.loss_mask: 0.8148  decode.d1.loss_dice: 1.2834  decode.d2.loss_cls: 1.1115  decode.d2.loss_mask: 0.7344  decode.d2.loss_dice: 1.1772  decode.d3.loss_cls: 1.0287  decode.d3.loss_mask: 0.7229  decode.d3.loss_dice: 1.1985  decode.d4.loss_cls: 1.0457  decode.d4.loss_mask: 0.7209  decode.d4.loss_dice: 1.1681  decode.d5.loss_cls: 1.0689  decode.d5.loss_mask: 0.6990  decode.d5.loss_dice: 1.1731  decode.d6.loss_cls: 1.0334  decode.d6.loss_mask: 0.7018  decode.d6.loss_dice: 1.1774  decode.d7.loss_cls: 1.0092  decode.d7.loss_mask: 0.7096  decode.d7.loss_dice: 1.1506  decode.d8.loss_cls: 1.0106  decode.d8.loss_mask: 0.7105  decode.d8.loss_dice: 1.1638
2023/05/24 13:33:12 - mmengine - INFO - Iter(train) [155150/160000]  lr: 4.2999e-07  eta: 0:35:05  time: 0.4219  data_time: 0.0101  memory: 4878  grad_norm: 139.8000  loss: 33.1928  decode.loss_cls: 1.1323  decode.loss_mask: 0.7055  decode.loss_dice: 1.1812  decode.d0.loss_cls: 3.2691  decode.d0.loss_mask: 0.6788  decode.d0.loss_dice: 1.3671  decode.d1.loss_cls: 1.2490  decode.d1.loss_mask: 0.7461  decode.d1.loss_dice: 1.2961  decode.d2.loss_cls: 1.1826  decode.d2.loss_mask: 0.7319  decode.d2.loss_dice: 1.2851  decode.d3.loss_cls: 1.1952  decode.d3.loss_mask: 0.7010  decode.d3.loss_dice: 1.2235  decode.d4.loss_cls: 1.1124  decode.d4.loss_mask: 0.6999  decode.d4.loss_dice: 1.2502  decode.d5.loss_cls: 1.1127  decode.d5.loss_mask: 0.6994  decode.d5.loss_dice: 1.2472  decode.d6.loss_cls: 1.1280  decode.d6.loss_mask: 0.6983  decode.d6.loss_dice: 1.2335  decode.d7.loss_cls: 1.1090  decode.d7.loss_mask: 0.6902  decode.d7.loss_dice: 1.2181  decode.d8.loss_cls: 1.1040  decode.d8.loss_mask: 0.7096  decode.d8.loss_dice: 1.2358
2023/05/24 13:33:33 - mmengine - INFO - Iter(train) [155200/160000]  lr: 4.2600e-07  eta: 0:34:43  time: 0.4362  data_time: 0.0101  memory: 4899  grad_norm: 91.3086  loss: 36.3816  decode.loss_cls: 1.1088  decode.loss_mask: 0.7889  decode.loss_dice: 1.4150  decode.d0.loss_cls: 2.9333  decode.d0.loss_mask: 0.8934  decode.d0.loss_dice: 1.6949  decode.d1.loss_cls: 1.4146  decode.d1.loss_mask: 0.8733  decode.d1.loss_dice: 1.5723  decode.d2.loss_cls: 1.2972  decode.d2.loss_mask: 0.8040  decode.d2.loss_dice: 1.4629  decode.d3.loss_cls: 1.2242  decode.d3.loss_mask: 0.7911  decode.d3.loss_dice: 1.4252  decode.d4.loss_cls: 1.1711  decode.d4.loss_mask: 0.7858  decode.d4.loss_dice: 1.4184  decode.d5.loss_cls: 1.1394  decode.d5.loss_mask: 0.7807  decode.d5.loss_dice: 1.4312  decode.d6.loss_cls: 1.1405  decode.d6.loss_mask: 0.7762  decode.d6.loss_dice: 1.4019  decode.d7.loss_cls: 1.1261  decode.d7.loss_mask: 0.7777  decode.d7.loss_dice: 1.4147  decode.d8.loss_cls: 1.1040  decode.d8.loss_mask: 0.7942  decode.d8.loss_dice: 1.4206
2023/05/24 13:33:55 - mmengine - INFO - Iter(train) [155250/160000]  lr: 4.2201e-07  eta: 0:34:21  time: 0.4416  data_time: 0.0109  memory: 4829  grad_norm: 97.1308  loss: 32.5175  decode.loss_cls: 0.9720  decode.loss_mask: 0.7801  decode.loss_dice: 1.2107  decode.d0.loss_cls: 2.9122  decode.d0.loss_mask: 0.8237  decode.d0.loss_dice: 1.3601  decode.d1.loss_cls: 1.1563  decode.d1.loss_mask: 0.7932  decode.d1.loss_dice: 1.2774  decode.d2.loss_cls: 1.1554  decode.d2.loss_mask: 0.7960  decode.d2.loss_dice: 1.2451  decode.d3.loss_cls: 1.0737  decode.d3.loss_mask: 0.7891  decode.d3.loss_dice: 1.2165  decode.d4.loss_cls: 1.0511  decode.d4.loss_mask: 0.7825  decode.d4.loss_dice: 1.2283  decode.d5.loss_cls: 1.0031  decode.d5.loss_mask: 0.7661  decode.d5.loss_dice: 1.1956  decode.d6.loss_cls: 0.9999  decode.d6.loss_mask: 0.7949  decode.d6.loss_dice: 1.2001  decode.d7.loss_cls: 0.9808  decode.d7.loss_mask: 0.7937  decode.d7.loss_dice: 1.2213  decode.d8.loss_cls: 0.9907  decode.d8.loss_mask: 0.7827  decode.d8.loss_dice: 1.1653
2023/05/24 13:34:17 - mmengine - INFO - Iter(train) [155300/160000]  lr: 4.1801e-07  eta: 0:34:00  time: 0.4396  data_time: 0.0099  memory: 4843  grad_norm: 79.5324  loss: 29.7059  decode.loss_cls: 0.8950  decode.loss_mask: 0.6414  decode.loss_dice: 1.1703  decode.d0.loss_cls: 2.9580  decode.d0.loss_mask: 0.6670  decode.d0.loss_dice: 1.3528  decode.d1.loss_cls: 1.0359  decode.d1.loss_mask: 0.6984  decode.d1.loss_dice: 1.2399  decode.d2.loss_cls: 0.9329  decode.d2.loss_mask: 0.6524  decode.d2.loss_dice: 1.1879  decode.d3.loss_cls: 0.9652  decode.d3.loss_mask: 0.6415  decode.d3.loss_dice: 1.1708  decode.d4.loss_cls: 0.9185  decode.d4.loss_mask: 0.6652  decode.d4.loss_dice: 1.1668  decode.d5.loss_cls: 0.8847  decode.d5.loss_mask: 0.6528  decode.d5.loss_dice: 1.1638  decode.d6.loss_cls: 0.9076  decode.d6.loss_mask: 0.6303  decode.d6.loss_dice: 1.1408  decode.d7.loss_cls: 0.8457  decode.d7.loss_mask: 0.6470  decode.d7.loss_dice: 1.1678  decode.d8.loss_cls: 0.9009  decode.d8.loss_mask: 0.6275  decode.d8.loss_dice: 1.1769
2023/05/24 13:34:39 - mmengine - INFO - Iter(train) [155350/160000]  lr: 4.1400e-07  eta: 0:33:38  time: 0.4292  data_time: 0.0099  memory: 4837  grad_norm: 124.4499  loss: 29.8356  decode.loss_cls: 0.9032  decode.loss_mask: 0.5963  decode.loss_dice: 1.1757  decode.d0.loss_cls: 2.9067  decode.d0.loss_mask: 0.6226  decode.d0.loss_dice: 1.3857  decode.d1.loss_cls: 1.0689  decode.d1.loss_mask: 0.6546  decode.d1.loss_dice: 1.3062  decode.d2.loss_cls: 0.9718  decode.d2.loss_mask: 0.5988  decode.d2.loss_dice: 1.2382  decode.d3.loss_cls: 0.9527  decode.d3.loss_mask: 0.6068  decode.d3.loss_dice: 1.2245  decode.d4.loss_cls: 0.9254  decode.d4.loss_mask: 0.6026  decode.d4.loss_dice: 1.1969  decode.d5.loss_cls: 0.9833  decode.d5.loss_mask: 0.6097  decode.d5.loss_dice: 1.1954  decode.d6.loss_cls: 0.9151  decode.d6.loss_mask: 0.5912  decode.d6.loss_dice: 1.1743  decode.d7.loss_cls: 0.9096  decode.d7.loss_mask: 0.6016  decode.d7.loss_dice: 1.1835  decode.d8.loss_cls: 0.9368  decode.d8.loss_mask: 0.5966  decode.d8.loss_dice: 1.2009
2023/05/24 13:35:01 - mmengine - INFO - Iter(train) [155400/160000]  lr: 4.0999e-07  eta: 0:33:16  time: 0.4416  data_time: 0.0103  memory: 4856  grad_norm: 118.7376  loss: 36.1081  decode.loss_cls: 1.0681  decode.loss_mask: 0.8679  decode.loss_dice: 1.3133  decode.d0.loss_cls: 3.2895  decode.d0.loss_mask: 0.9571  decode.d0.loss_dice: 1.6079  decode.d1.loss_cls: 1.2039  decode.d1.loss_mask: 0.9498  decode.d1.loss_dice: 1.4783  decode.d2.loss_cls: 1.1325  decode.d2.loss_mask: 0.9405  decode.d2.loss_dice: 1.4518  decode.d3.loss_cls: 1.0662  decode.d3.loss_mask: 0.9125  decode.d3.loss_dice: 1.3906  decode.d4.loss_cls: 1.0481  decode.d4.loss_mask: 0.8899  decode.d4.loss_dice: 1.3723  decode.d5.loss_cls: 1.1166  decode.d5.loss_mask: 0.8895  decode.d5.loss_dice: 1.3254  decode.d6.loss_cls: 1.0526  decode.d6.loss_mask: 0.9005  decode.d6.loss_dice: 1.3566  decode.d7.loss_cls: 1.0397  decode.d7.loss_mask: 0.8986  decode.d7.loss_dice: 1.3398  decode.d8.loss_cls: 1.0428  decode.d8.loss_mask: 0.8833  decode.d8.loss_dice: 1.3226
2023/05/24 13:35:22 - mmengine - INFO - Iter(train) [155450/160000]  lr: 4.0598e-07  eta: 0:32:54  time: 0.4358  data_time: 0.0109  memory: 4787  grad_norm: 83.0789  loss: 28.0232  decode.loss_cls: 0.9583  decode.loss_mask: 0.5485  decode.loss_dice: 1.0289  decode.d0.loss_cls: 2.9930  decode.d0.loss_mask: 0.6433  decode.d0.loss_dice: 1.1078  decode.d1.loss_cls: 1.1027  decode.d1.loss_mask: 0.6057  decode.d1.loss_dice: 1.0561  decode.d2.loss_cls: 1.0483  decode.d2.loss_mask: 0.5968  decode.d2.loss_dice: 1.0306  decode.d3.loss_cls: 1.0461  decode.d3.loss_mask: 0.5644  decode.d3.loss_dice: 0.9804  decode.d4.loss_cls: 1.0306  decode.d4.loss_mask: 0.5593  decode.d4.loss_dice: 1.0273  decode.d5.loss_cls: 0.9986  decode.d5.loss_mask: 0.5616  decode.d5.loss_dice: 0.9879  decode.d6.loss_cls: 1.0045  decode.d6.loss_mask: 0.5614  decode.d6.loss_dice: 0.9802  decode.d7.loss_cls: 0.9745  decode.d7.loss_mask: 0.5542  decode.d7.loss_dice: 0.9721  decode.d8.loss_cls: 0.9625  decode.d8.loss_mask: 0.5481  decode.d8.loss_dice: 0.9894
2023/05/24 13:35:44 - mmengine - INFO - Iter(train) [155500/160000]  lr: 4.0196e-07  eta: 0:32:33  time: 0.4194  data_time: 0.0100  memory: 4906  grad_norm: 91.1614  loss: 26.5296  decode.loss_cls: 0.8763  decode.loss_mask: 0.5400  decode.loss_dice: 1.0213  decode.d0.loss_cls: 2.6642  decode.d0.loss_mask: 0.5740  decode.d0.loss_dice: 1.1272  decode.d1.loss_cls: 0.9497  decode.d1.loss_mask: 0.5836  decode.d1.loss_dice: 1.0725  decode.d2.loss_cls: 0.9143  decode.d2.loss_mask: 0.5598  decode.d2.loss_dice: 1.0546  decode.d3.loss_cls: 0.9082  decode.d3.loss_mask: 0.5504  decode.d3.loss_dice: 1.0281  decode.d4.loss_cls: 0.8983  decode.d4.loss_mask: 0.5543  decode.d4.loss_dice: 1.0171  decode.d5.loss_cls: 0.8544  decode.d5.loss_mask: 0.5462  decode.d5.loss_dice: 1.0201  decode.d6.loss_cls: 0.8821  decode.d6.loss_mask: 0.5332  decode.d6.loss_dice: 1.0293  decode.d7.loss_cls: 0.8587  decode.d7.loss_mask: 0.5394  decode.d7.loss_dice: 0.9812  decode.d8.loss_cls: 0.8402  decode.d8.loss_mask: 0.5327  decode.d8.loss_dice: 1.0179
2023/05/24 13:36:05 - mmengine - INFO - Iter(train) [155550/160000]  lr: 3.9794e-07  eta: 0:32:11  time: 0.4299  data_time: 0.0100  memory: 4875  grad_norm: 123.2498  loss: 33.8195  decode.loss_cls: 1.1945  decode.loss_mask: 0.8276  decode.loss_dice: 1.0908  decode.d0.loss_cls: 3.0037  decode.d0.loss_mask: 0.9386  decode.d0.loss_dice: 1.2490  decode.d1.loss_cls: 1.1922  decode.d1.loss_mask: 0.8874  decode.d1.loss_dice: 1.2204  decode.d2.loss_cls: 1.3021  decode.d2.loss_mask: 0.8488  decode.d2.loss_dice: 1.1736  decode.d3.loss_cls: 1.2860  decode.d3.loss_mask: 0.8290  decode.d3.loss_dice: 1.0962  decode.d4.loss_cls: 1.2395  decode.d4.loss_mask: 0.8074  decode.d4.loss_dice: 1.1190  decode.d5.loss_cls: 1.2427  decode.d5.loss_mask: 0.8231  decode.d5.loss_dice: 1.0847  decode.d6.loss_cls: 1.2418  decode.d6.loss_mask: 0.8089  decode.d6.loss_dice: 1.0546  decode.d7.loss_cls: 1.2463  decode.d7.loss_mask: 0.8168  decode.d7.loss_dice: 1.0527  decode.d8.loss_cls: 1.2169  decode.d8.loss_mask: 0.8220  decode.d8.loss_dice: 1.1035
2023/05/24 13:36:26 - mmengine - INFO - Iter(train) [155600/160000]  lr: 3.9391e-07  eta: 0:31:49  time: 0.4311  data_time: 0.0102  memory: 4866  grad_norm: 91.3906  loss: 34.1702  decode.loss_cls: 1.1266  decode.loss_mask: 0.8127  decode.loss_dice: 1.2774  decode.d0.loss_cls: 2.9224  decode.d0.loss_mask: 0.8718  decode.d0.loss_dice: 1.4971  decode.d1.loss_cls: 1.2411  decode.d1.loss_mask: 0.8065  decode.d1.loss_dice: 1.3516  decode.d2.loss_cls: 1.0964  decode.d2.loss_mask: 0.8516  decode.d2.loss_dice: 1.3282  decode.d3.loss_cls: 1.0444  decode.d3.loss_mask: 0.8170  decode.d3.loss_dice: 1.2837  decode.d4.loss_cls: 1.0443  decode.d4.loss_mask: 0.8213  decode.d4.loss_dice: 1.2775  decode.d5.loss_cls: 1.0967  decode.d5.loss_mask: 0.8100  decode.d5.loss_dice: 1.2625  decode.d6.loss_cls: 1.1065  decode.d6.loss_mask: 0.7963  decode.d6.loss_dice: 1.2617  decode.d7.loss_cls: 1.1102  decode.d7.loss_mask: 0.8098  decode.d7.loss_dice: 1.2721  decode.d8.loss_cls: 1.0809  decode.d8.loss_mask: 0.8205  decode.d8.loss_dice: 1.2716
2023/05/24 13:36:49 - mmengine - INFO - Iter(train) [155650/160000]  lr: 3.8988e-07  eta: 0:31:28  time: 0.4631  data_time: 0.0108  memory: 4929  grad_norm: 99.0153  loss: 38.9337  decode.loss_cls: 1.2314  decode.loss_mask: 0.7772  decode.loss_dice: 1.4497  decode.d0.loss_cls: 3.5532  decode.d0.loss_mask: 0.8925  decode.d0.loss_dice: 1.7287  decode.d1.loss_cls: 1.4352  decode.d1.loss_mask: 0.8633  decode.d1.loss_dice: 1.6859  decode.d2.loss_cls: 1.3761  decode.d2.loss_mask: 0.8114  decode.d2.loss_dice: 1.6136  decode.d3.loss_cls: 1.3123  decode.d3.loss_mask: 0.8174  decode.d3.loss_dice: 1.5635  decode.d4.loss_cls: 1.3081  decode.d4.loss_mask: 0.8265  decode.d4.loss_dice: 1.5598  decode.d5.loss_cls: 1.2261  decode.d5.loss_mask: 0.8442  decode.d5.loss_dice: 1.5161  decode.d6.loss_cls: 1.2031  decode.d6.loss_mask: 0.8038  decode.d6.loss_dice: 1.5185  decode.d7.loss_cls: 1.2253  decode.d7.loss_mask: 0.8177  decode.d7.loss_dice: 1.4659  decode.d8.loss_cls: 1.2114  decode.d8.loss_mask: 0.8145  decode.d8.loss_dice: 1.4815
2023/05/24 13:37:11 - mmengine - INFO - Iter(train) [155700/160000]  lr: 3.8585e-07  eta: 0:31:06  time: 0.4283  data_time: 0.0103  memory: 4860  grad_norm: 84.9631  loss: 37.2221  decode.loss_cls: 1.1723  decode.loss_mask: 0.8235  decode.loss_dice: 1.4358  decode.d0.loss_cls: 3.3551  decode.d0.loss_mask: 0.8430  decode.d0.loss_dice: 1.5948  decode.d1.loss_cls: 1.3644  decode.d1.loss_mask: 0.8153  decode.d1.loss_dice: 1.5199  decode.d2.loss_cls: 1.2449  decode.d2.loss_mask: 0.8392  decode.d2.loss_dice: 1.4582  decode.d3.loss_cls: 1.1591  decode.d3.loss_mask: 0.8435  decode.d3.loss_dice: 1.4716  decode.d4.loss_cls: 1.2206  decode.d4.loss_mask: 0.8281  decode.d4.loss_dice: 1.4311  decode.d5.loss_cls: 1.1700  decode.d5.loss_mask: 0.8313  decode.d5.loss_dice: 1.4408  decode.d6.loss_cls: 1.2384  decode.d6.loss_mask: 0.8156  decode.d6.loss_dice: 1.4063  decode.d7.loss_cls: 1.2210  decode.d7.loss_mask: 0.8165  decode.d7.loss_dice: 1.4239  decode.d8.loss_cls: 1.1916  decode.d8.loss_mask: 0.8237  decode.d8.loss_dice: 1.4225
2023/05/24 13:37:33 - mmengine - INFO - Iter(train) [155750/160000]  lr: 3.8181e-07  eta: 0:30:44  time: 0.4187  data_time: 0.0100  memory: 4875  grad_norm: 120.7308  loss: 32.2168  decode.loss_cls: 1.1044  decode.loss_mask: 0.6492  decode.loss_dice: 1.1730  decode.d0.loss_cls: 2.7383  decode.d0.loss_mask: 0.6525  decode.d0.loss_dice: 1.4177  decode.d1.loss_cls: 1.1849  decode.d1.loss_mask: 0.6641  decode.d1.loss_dice: 1.3590  decode.d2.loss_cls: 1.1714  decode.d2.loss_mask: 0.6420  decode.d2.loss_dice: 1.3023  decode.d3.loss_cls: 1.2060  decode.d3.loss_mask: 0.6405  decode.d3.loss_dice: 1.2589  decode.d4.loss_cls: 1.1689  decode.d4.loss_mask: 0.6402  decode.d4.loss_dice: 1.2664  decode.d5.loss_cls: 1.1708  decode.d5.loss_mask: 0.6404  decode.d5.loss_dice: 1.2146  decode.d6.loss_cls: 1.1033  decode.d6.loss_mask: 0.6444  decode.d6.loss_dice: 1.2463  decode.d7.loss_cls: 1.1140  decode.d7.loss_mask: 0.6510  decode.d7.loss_dice: 1.2300  decode.d8.loss_cls: 1.1005  decode.d8.loss_mask: 0.6490  decode.d8.loss_dice: 1.2124
2023/05/24 13:37:54 - mmengine - INFO - Iter(train) [155800/160000]  lr: 3.7776e-07  eta: 0:30:23  time: 0.4276  data_time: 0.0099  memory: 4835  grad_norm: 95.5033  loss: 29.1223  decode.loss_cls: 0.8886  decode.loss_mask: 0.7797  decode.loss_dice: 0.9309  decode.d0.loss_cls: 2.8574  decode.d0.loss_mask: 0.8941  decode.d0.loss_dice: 1.1551  decode.d1.loss_cls: 1.0013  decode.d1.loss_mask: 0.8214  decode.d1.loss_dice: 1.0250  decode.d2.loss_cls: 0.9973  decode.d2.loss_mask: 0.7794  decode.d2.loss_dice: 1.0012  decode.d3.loss_cls: 0.9415  decode.d3.loss_mask: 0.8052  decode.d3.loss_dice: 0.9870  decode.d4.loss_cls: 0.9542  decode.d4.loss_mask: 0.7664  decode.d4.loss_dice: 0.9593  decode.d5.loss_cls: 0.9430  decode.d5.loss_mask: 0.7777  decode.d5.loss_dice: 0.9555  decode.d6.loss_cls: 0.9065  decode.d6.loss_mask: 0.7777  decode.d6.loss_dice: 0.9427  decode.d7.loss_cls: 0.9387  decode.d7.loss_mask: 0.7787  decode.d7.loss_dice: 0.9269  decode.d8.loss_cls: 0.8776  decode.d8.loss_mask: 0.7902  decode.d8.loss_dice: 0.9622
2023/05/24 13:38:16 - mmengine - INFO - Iter(train) [155850/160000]  lr: 3.7371e-07  eta: 0:30:01  time: 0.4297  data_time: 0.0098  memory: 4859  grad_norm: 92.0863  loss: 34.8461  decode.loss_cls: 1.2026  decode.loss_mask: 0.8436  decode.loss_dice: 1.1624  decode.d0.loss_cls: 3.0947  decode.d0.loss_mask: 0.8152  decode.d0.loss_dice: 1.3831  decode.d1.loss_cls: 1.2360  decode.d1.loss_mask: 0.8118  decode.d1.loss_dice: 1.2777  decode.d2.loss_cls: 1.1957  decode.d2.loss_mask: 0.8787  decode.d2.loss_dice: 1.2367  decode.d3.loss_cls: 1.2663  decode.d3.loss_mask: 0.8499  decode.d3.loss_dice: 1.1961  decode.d4.loss_cls: 1.2895  decode.d4.loss_mask: 0.8582  decode.d4.loss_dice: 1.1944  decode.d5.loss_cls: 1.2562  decode.d5.loss_mask: 0.8315  decode.d5.loss_dice: 1.1826  decode.d6.loss_cls: 1.2202  decode.d6.loss_mask: 0.8712  decode.d6.loss_dice: 1.1800  decode.d7.loss_cls: 1.2107  decode.d7.loss_mask: 0.8645  decode.d7.loss_dice: 1.1882  decode.d8.loss_cls: 1.2303  decode.d8.loss_mask: 0.8486  decode.d8.loss_dice: 1.1696
2023/05/24 13:38:38 - mmengine - INFO - Iter(train) [155900/160000]  lr: 3.6966e-07  eta: 0:29:39  time: 0.4385  data_time: 0.0100  memory: 4952  grad_norm: 94.9702  loss: 40.7607  decode.loss_cls: 1.3232  decode.loss_mask: 0.8076  decode.loss_dice: 1.5493  decode.d0.loss_cls: 3.4342  decode.d0.loss_mask: 0.9350  decode.d0.loss_dice: 1.8292  decode.d1.loss_cls: 1.4247  decode.d1.loss_mask: 0.9417  decode.d1.loss_dice: 1.7572  decode.d2.loss_cls: 1.4531  decode.d2.loss_mask: 0.8787  decode.d2.loss_dice: 1.6906  decode.d3.loss_cls: 1.4033  decode.d3.loss_mask: 0.8586  decode.d3.loss_dice: 1.6524  decode.d4.loss_cls: 1.3263  decode.d4.loss_mask: 0.8613  decode.d4.loss_dice: 1.6476  decode.d5.loss_cls: 1.3719  decode.d5.loss_mask: 0.8335  decode.d5.loss_dice: 1.6458  decode.d6.loss_cls: 1.3604  decode.d6.loss_mask: 0.7929  decode.d6.loss_dice: 1.5855  decode.d7.loss_cls: 1.3368  decode.d7.loss_mask: 0.7752  decode.d7.loss_dice: 1.5882  decode.d8.loss_cls: 1.3324  decode.d8.loss_mask: 0.7891  decode.d8.loss_dice: 1.5750
2023/05/24 13:39:02 - mmengine - INFO - Iter(train) [155950/160000]  lr: 3.6560e-07  eta: 0:29:18  time: 0.4791  data_time: 0.0110  memory: 4839  grad_norm: 163.8525  loss: 34.0993  decode.loss_cls: 1.0578  decode.loss_mask: 0.7597  decode.loss_dice: 1.2469  decode.d0.loss_cls: 3.2648  decode.d0.loss_mask: 0.9189  decode.d0.loss_dice: 1.4859  decode.d1.loss_cls: 1.2332  decode.d1.loss_mask: 0.8162  decode.d1.loss_dice: 1.3587  decode.d2.loss_cls: 1.2193  decode.d2.loss_mask: 0.8156  decode.d2.loss_dice: 1.2610  decode.d3.loss_cls: 1.1744  decode.d3.loss_mask: 0.7880  decode.d3.loss_dice: 1.2237  decode.d4.loss_cls: 1.1204  decode.d4.loss_mask: 0.8133  decode.d4.loss_dice: 1.2416  decode.d5.loss_cls: 1.1053  decode.d5.loss_mask: 0.7612  decode.d5.loss_dice: 1.2168  decode.d6.loss_cls: 1.0777  decode.d6.loss_mask: 0.7657  decode.d6.loss_dice: 1.2068  decode.d7.loss_cls: 1.0939  decode.d7.loss_mask: 0.7740  decode.d7.loss_dice: 1.2213  decode.d8.loss_cls: 1.0640  decode.d8.loss_mask: 0.7673  decode.d8.loss_dice: 1.2456
2023/05/24 13:39:25 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 13:39:25 - mmengine - INFO - Iter(train) [156000/160000]  lr: 3.6153e-07  eta: 0:28:56  time: 0.4768  data_time: 0.0098  memory: 4847  grad_norm: 89.8241  loss: 33.4678  decode.loss_cls: 1.1301  decode.loss_mask: 0.7629  decode.loss_dice: 1.1757  decode.d0.loss_cls: 2.9659  decode.d0.loss_mask: 0.8338  decode.d0.loss_dice: 1.4365  decode.d1.loss_cls: 1.1411  decode.d1.loss_mask: 0.8568  decode.d1.loss_dice: 1.3108  decode.d2.loss_cls: 1.0733  decode.d2.loss_mask: 0.8344  decode.d2.loss_dice: 1.2761  decode.d3.loss_cls: 1.1417  decode.d3.loss_mask: 0.8346  decode.d3.loss_dice: 1.2155  decode.d4.loss_cls: 1.1011  decode.d4.loss_mask: 0.8112  decode.d4.loss_dice: 1.2245  decode.d5.loss_cls: 1.1098  decode.d5.loss_mask: 0.8010  decode.d5.loss_dice: 1.1733  decode.d6.loss_cls: 1.1720  decode.d6.loss_mask: 0.7847  decode.d6.loss_dice: 1.1653  decode.d7.loss_cls: 1.0855  decode.d7.loss_mask: 0.7858  decode.d7.loss_dice: 1.1884  decode.d8.loss_cls: 1.0793  decode.d8.loss_mask: 0.8106  decode.d8.loss_dice: 1.1861
2023/05/24 13:39:25 - mmengine - INFO - Saving checkpoint at 156000 iterations
2023/05/24 13:39:54 - mmengine - INFO - Iter(train) [156050/160000]  lr: 3.5746e-07  eta: 0:28:34  time: 0.4192  data_time: 0.0099  memory: 4858  grad_norm: 89.1223  loss: 29.8920  decode.loss_cls: 0.9608  decode.loss_mask: 0.6233  decode.loss_dice: 1.0974  decode.d0.loss_cls: 2.6500  decode.d0.loss_mask: 0.6547  decode.d0.loss_dice: 1.3464  decode.d1.loss_cls: 1.0370  decode.d1.loss_mask: 0.6496  decode.d1.loss_dice: 1.3273  decode.d2.loss_cls: 1.0327  decode.d2.loss_mask: 0.6217  decode.d2.loss_dice: 1.2407  decode.d3.loss_cls: 1.0002  decode.d3.loss_mask: 0.6022  decode.d3.loss_dice: 1.1756  decode.d4.loss_cls: 1.0072  decode.d4.loss_mask: 0.6081  decode.d4.loss_dice: 1.2107  decode.d5.loss_cls: 1.0410  decode.d5.loss_mask: 0.6125  decode.d5.loss_dice: 1.1614  decode.d6.loss_cls: 1.0033  decode.d6.loss_mask: 0.6103  decode.d6.loss_dice: 1.1339  decode.d7.loss_cls: 0.9572  decode.d7.loss_mask: 0.6175  decode.d7.loss_dice: 1.1763  decode.d8.loss_cls: 0.9966  decode.d8.loss_mask: 0.6089  decode.d8.loss_dice: 1.1271
2023/05/24 13:40:15 - mmengine - INFO - Iter(train) [156100/160000]  lr: 3.5339e-07  eta: 0:28:13  time: 0.4363  data_time: 0.0102  memory: 4908  grad_norm: 88.8734  loss: 34.9530  decode.loss_cls: 1.1584  decode.loss_mask: 0.6849  decode.loss_dice: 1.3860  decode.d0.loss_cls: 2.9519  decode.d0.loss_mask: 0.7854  decode.d0.loss_dice: 1.7095  decode.d1.loss_cls: 1.1484  decode.d1.loss_mask: 0.7881  decode.d1.loss_dice: 1.5512  decode.d2.loss_cls: 1.1782  decode.d2.loss_mask: 0.7190  decode.d2.loss_dice: 1.4723  decode.d3.loss_cls: 1.0801  decode.d3.loss_mask: 0.7402  decode.d3.loss_dice: 1.4993  decode.d4.loss_cls: 1.0995  decode.d4.loss_mask: 0.7051  decode.d4.loss_dice: 1.4808  decode.d5.loss_cls: 1.0906  decode.d5.loss_mask: 0.7042  decode.d5.loss_dice: 1.4356  decode.d6.loss_cls: 1.1148  decode.d6.loss_mask: 0.6914  decode.d6.loss_dice: 1.4227  decode.d7.loss_cls: 1.0752  decode.d7.loss_mask: 0.6931  decode.d7.loss_dice: 1.4034  decode.d8.loss_cls: 1.0900  decode.d8.loss_mask: 0.6770  decode.d8.loss_dice: 1.4165
2023/05/24 13:40:37 - mmengine - INFO - Iter(train) [156150/160000]  lr: 3.4931e-07  eta: 0:27:51  time: 0.4276  data_time: 0.0104  memory: 4866  grad_norm: 90.3003  loss: 28.6923  decode.loss_cls: 1.0113  decode.loss_mask: 0.5139  decode.loss_dice: 1.0134  decode.d0.loss_cls: 2.9927  decode.d0.loss_mask: 0.6424  decode.d0.loss_dice: 1.2898  decode.d1.loss_cls: 1.1169  decode.d1.loss_mask: 0.5799  decode.d1.loss_dice: 1.2200  decode.d2.loss_cls: 1.0732  decode.d2.loss_mask: 0.5076  decode.d2.loss_dice: 1.0970  decode.d3.loss_cls: 1.0953  decode.d3.loss_mask: 0.5356  decode.d3.loss_dice: 1.0515  decode.d4.loss_cls: 1.0549  decode.d4.loss_mask: 0.5196  decode.d4.loss_dice: 1.0496  decode.d5.loss_cls: 1.0881  decode.d5.loss_mask: 0.5200  decode.d5.loss_dice: 1.0298  decode.d6.loss_cls: 1.0503  decode.d6.loss_mask: 0.5088  decode.d6.loss_dice: 1.0033  decode.d7.loss_cls: 1.0206  decode.d7.loss_mask: 0.5142  decode.d7.loss_dice: 1.0382  decode.d8.loss_cls: 1.0056  decode.d8.loss_mask: 0.5202  decode.d8.loss_dice: 1.0284
2023/05/24 13:40:58 - mmengine - INFO - Iter(train) [156200/160000]  lr: 3.4522e-07  eta: 0:27:29  time: 0.4201  data_time: 0.0101  memory: 4894  grad_norm: 94.2251  loss: 25.4758  decode.loss_cls: 0.8683  decode.loss_mask: 0.5362  decode.loss_dice: 0.8782  decode.d0.loss_cls: 2.8415  decode.d0.loss_mask: 0.5905  decode.d0.loss_dice: 1.0550  decode.d1.loss_cls: 0.9849  decode.d1.loss_mask: 0.5859  decode.d1.loss_dice: 1.0059  decode.d2.loss_cls: 0.9159  decode.d2.loss_mask: 0.5887  decode.d2.loss_dice: 0.9357  decode.d3.loss_cls: 0.8486  decode.d3.loss_mask: 0.5706  decode.d3.loss_dice: 0.9135  decode.d4.loss_cls: 0.8233  decode.d4.loss_mask: 0.5628  decode.d4.loss_dice: 0.9031  decode.d5.loss_cls: 0.8700  decode.d5.loss_mask: 0.5604  decode.d5.loss_dice: 0.8737  decode.d6.loss_cls: 0.8786  decode.d6.loss_mask: 0.5428  decode.d6.loss_dice: 0.8363  decode.d7.loss_cls: 0.8326  decode.d7.loss_mask: 0.5582  decode.d7.loss_dice: 0.8772  decode.d8.loss_cls: 0.8439  decode.d8.loss_mask: 0.5388  decode.d8.loss_dice: 0.8546
2023/05/24 13:41:19 - mmengine - INFO - Iter(train) [156250/160000]  lr: 3.4113e-07  eta: 0:27:07  time: 0.4273  data_time: 0.0102  memory: 4847  grad_norm: 88.4137  loss: 33.2279  decode.loss_cls: 1.1218  decode.loss_mask: 0.6575  decode.loss_dice: 1.1818  decode.d0.loss_cls: 3.0924  decode.d0.loss_mask: 0.7825  decode.d0.loss_dice: 1.4383  decode.d1.loss_cls: 1.3935  decode.d1.loss_mask: 0.8273  decode.d1.loss_dice: 1.3101  decode.d2.loss_cls: 1.2288  decode.d2.loss_mask: 0.7602  decode.d2.loss_dice: 1.2336  decode.d3.loss_cls: 1.1999  decode.d3.loss_mask: 0.6900  decode.d3.loss_dice: 1.2037  decode.d4.loss_cls: 1.1446  decode.d4.loss_mask: 0.6936  decode.d4.loss_dice: 1.2328  decode.d5.loss_cls: 1.1188  decode.d5.loss_mask: 0.6871  decode.d5.loss_dice: 1.2259  decode.d6.loss_cls: 1.1232  decode.d6.loss_mask: 0.6847  decode.d6.loss_dice: 1.1855  decode.d7.loss_cls: 1.1367  decode.d7.loss_mask: 0.6652  decode.d7.loss_dice: 1.1938  decode.d8.loss_cls: 1.1840  decode.d8.loss_mask: 0.6604  decode.d8.loss_dice: 1.1701
2023/05/24 13:41:41 - mmengine - INFO - Iter(train) [156300/160000]  lr: 3.3704e-07  eta: 0:26:46  time: 0.4270  data_time: 0.0106  memory: 4904  grad_norm: 89.5567  loss: 35.0339  decode.loss_cls: 1.1279  decode.loss_mask: 0.8123  decode.loss_dice: 1.2120  decode.d0.loss_cls: 3.2174  decode.d0.loss_mask: 0.8897  decode.d0.loss_dice: 1.5180  decode.d1.loss_cls: 1.3361  decode.d1.loss_mask: 0.8782  decode.d1.loss_dice: 1.3553  decode.d2.loss_cls: 1.1292  decode.d2.loss_mask: 0.8910  decode.d2.loss_dice: 1.2879  decode.d3.loss_cls: 1.1351  decode.d3.loss_mask: 0.8855  decode.d3.loss_dice: 1.2350  decode.d4.loss_cls: 1.1221  decode.d4.loss_mask: 0.8653  decode.d4.loss_dice: 1.2751  decode.d5.loss_cls: 1.1334  decode.d5.loss_mask: 0.8806  decode.d5.loss_dice: 1.2866  decode.d6.loss_cls: 1.1117  decode.d6.loss_mask: 0.8778  decode.d6.loss_dice: 1.2410  decode.d7.loss_cls: 1.0967  decode.d7.loss_mask: 0.8067  decode.d7.loss_dice: 1.2329  decode.d8.loss_cls: 1.1579  decode.d8.loss_mask: 0.8000  decode.d8.loss_dice: 1.2356
2023/05/24 13:42:03 - mmengine - INFO - Iter(train) [156350/160000]  lr: 3.3293e-07  eta: 0:26:24  time: 0.4448  data_time: 0.0101  memory: 4798  grad_norm: 92.6405  loss: 26.1452  decode.loss_cls: 0.9394  decode.loss_mask: 0.5532  decode.loss_dice: 0.8492  decode.d0.loss_cls: 2.7330  decode.d0.loss_mask: 0.6383  decode.d0.loss_dice: 1.0268  decode.d1.loss_cls: 1.0403  decode.d1.loss_mask: 0.5749  decode.d1.loss_dice: 0.9798  decode.d2.loss_cls: 0.9622  decode.d2.loss_mask: 0.6067  decode.d2.loss_dice: 0.9085  decode.d3.loss_cls: 0.9296  decode.d3.loss_mask: 0.5990  decode.d3.loss_dice: 0.8688  decode.d4.loss_cls: 0.9415  decode.d4.loss_mask: 0.5868  decode.d4.loss_dice: 0.9099  decode.d5.loss_cls: 0.9212  decode.d5.loss_mask: 0.5873  decode.d5.loss_dice: 0.8857  decode.d6.loss_cls: 0.9608  decode.d6.loss_mask: 0.5658  decode.d6.loss_dice: 0.8873  decode.d7.loss_cls: 0.9046  decode.d7.loss_mask: 0.5633  decode.d7.loss_dice: 0.8588  decode.d8.loss_cls: 0.9283  decode.d8.loss_mask: 0.5648  decode.d8.loss_dice: 0.8696
2023/05/24 13:42:25 - mmengine - INFO - Iter(train) [156400/160000]  lr: 3.2883e-07  eta: 0:26:02  time: 0.4454  data_time: 0.0097  memory: 4887  grad_norm: 141.5296  loss: 37.4002  decode.loss_cls: 1.1813  decode.loss_mask: 0.7208  decode.loss_dice: 1.4211  decode.d0.loss_cls: 3.5518  decode.d0.loss_mask: 0.7847  decode.d0.loss_dice: 1.6734  decode.d1.loss_cls: 1.4145  decode.d1.loss_mask: 0.7575  decode.d1.loss_dice: 1.6050  decode.d2.loss_cls: 1.3659  decode.d2.loss_mask: 0.7440  decode.d2.loss_dice: 1.5637  decode.d3.loss_cls: 1.3621  decode.d3.loss_mask: 0.6827  decode.d3.loss_dice: 1.4286  decode.d4.loss_cls: 1.2891  decode.d4.loss_mask: 0.7570  decode.d4.loss_dice: 1.4710  decode.d5.loss_cls: 1.2530  decode.d5.loss_mask: 0.7599  decode.d5.loss_dice: 1.4492  decode.d6.loss_cls: 1.2254  decode.d6.loss_mask: 0.7239  decode.d6.loss_dice: 1.4266  decode.d7.loss_cls: 1.2671  decode.d7.loss_mask: 0.7333  decode.d7.loss_dice: 1.3998  decode.d8.loss_cls: 1.2254  decode.d8.loss_mask: 0.7526  decode.d8.loss_dice: 1.4097
2023/05/24 13:42:46 - mmengine - INFO - Iter(train) [156450/160000]  lr: 3.2471e-07  eta: 0:25:41  time: 0.4290  data_time: 0.0098  memory: 4836  grad_norm: 86.3938  loss: 32.5163  decode.loss_cls: 1.0846  decode.loss_mask: 0.6285  decode.loss_dice: 1.2524  decode.d0.loss_cls: 2.8951  decode.d0.loss_mask: 0.7325  decode.d0.loss_dice: 1.4470  decode.d1.loss_cls: 1.2421  decode.d1.loss_mask: 0.6642  decode.d1.loss_dice: 1.3475  decode.d2.loss_cls: 1.2383  decode.d2.loss_mask: 0.6508  decode.d2.loss_dice: 1.2622  decode.d3.loss_cls: 1.1275  decode.d3.loss_mask: 0.6532  decode.d3.loss_dice: 1.2668  decode.d4.loss_cls: 1.1329  decode.d4.loss_mask: 0.6367  decode.d4.loss_dice: 1.2494  decode.d5.loss_cls: 1.1148  decode.d5.loss_mask: 0.6393  decode.d5.loss_dice: 1.2644  decode.d6.loss_cls: 1.1051  decode.d6.loss_mask: 0.6352  decode.d6.loss_dice: 1.2716  decode.d7.loss_cls: 1.1388  decode.d7.loss_mask: 0.6314  decode.d7.loss_dice: 1.2160  decode.d8.loss_cls: 1.1160  decode.d8.loss_mask: 0.6269  decode.d8.loss_dice: 1.2455
2023/05/24 13:43:09 - mmengine - INFO - Iter(train) [156500/160000]  lr: 3.2059e-07  eta: 0:25:19  time: 0.4822  data_time: 0.0100  memory: 4860  grad_norm: 77.0510  loss: 24.6545  decode.loss_cls: 0.7904  decode.loss_mask: 0.6535  decode.loss_dice: 0.8374  decode.d0.loss_cls: 2.4142  decode.d0.loss_mask: 0.7140  decode.d0.loss_dice: 0.9604  decode.d1.loss_cls: 0.8744  decode.d1.loss_mask: 0.6648  decode.d1.loss_dice: 0.8921  decode.d2.loss_cls: 0.7734  decode.d2.loss_mask: 0.6544  decode.d2.loss_dice: 0.8560  decode.d3.loss_cls: 0.7863  decode.d3.loss_mask: 0.6573  decode.d3.loss_dice: 0.8570  decode.d4.loss_cls: 0.7394  decode.d4.loss_mask: 0.6584  decode.d4.loss_dice: 0.8544  decode.d5.loss_cls: 0.7523  decode.d5.loss_mask: 0.6451  decode.d5.loss_dice: 0.8363  decode.d6.loss_cls: 0.7797  decode.d6.loss_mask: 0.6472  decode.d6.loss_dice: 0.8183  decode.d7.loss_cls: 0.8101  decode.d7.loss_mask: 0.6504  decode.d7.loss_dice: 0.8160  decode.d8.loss_cls: 0.7963  decode.d8.loss_mask: 0.6458  decode.d8.loss_dice: 0.8191
2023/05/24 13:43:33 - mmengine - INFO - Iter(train) [156550/160000]  lr: 3.1647e-07  eta: 0:24:57  time: 0.4776  data_time: 0.0100  memory: 4829  grad_norm: 90.4953  loss: 29.6344  decode.loss_cls: 0.9484  decode.loss_mask: 0.6361  decode.loss_dice: 1.0997  decode.d0.loss_cls: 2.9350  decode.d0.loss_mask: 0.6975  decode.d0.loss_dice: 1.3014  decode.d1.loss_cls: 1.1404  decode.d1.loss_mask: 0.6444  decode.d1.loss_dice: 1.1853  decode.d2.loss_cls: 1.0801  decode.d2.loss_mask: 0.6174  decode.d2.loss_dice: 1.1510  decode.d3.loss_cls: 1.0022  decode.d3.loss_mask: 0.6185  decode.d3.loss_dice: 1.0946  decode.d4.loss_cls: 0.9541  decode.d4.loss_mask: 0.6275  decode.d4.loss_dice: 1.1117  decode.d5.loss_cls: 0.9513  decode.d5.loss_mask: 0.6333  decode.d5.loss_dice: 1.1246  decode.d6.loss_cls: 1.0017  decode.d6.loss_mask: 0.6414  decode.d6.loss_dice: 1.0730  decode.d7.loss_cls: 0.9409  decode.d7.loss_mask: 0.6334  decode.d7.loss_dice: 1.1061  decode.d8.loss_cls: 0.9386  decode.d8.loss_mask: 0.6339  decode.d8.loss_dice: 1.1111
2023/05/24 13:43:56 - mmengine - INFO - Iter(train) [156600/160000]  lr: 3.1234e-07  eta: 0:24:36  time: 0.4283  data_time: 0.0108  memory: 4865  grad_norm: 111.8949  loss: 32.4834  decode.loss_cls: 1.1053  decode.loss_mask: 0.7299  decode.loss_dice: 1.1141  decode.d0.loss_cls: 3.0351  decode.d0.loss_mask: 0.8214  decode.d0.loss_dice: 1.3272  decode.d1.loss_cls: 1.2693  decode.d1.loss_mask: 0.8171  decode.d1.loss_dice: 1.2369  decode.d2.loss_cls: 1.1809  decode.d2.loss_mask: 0.7323  decode.d2.loss_dice: 1.1615  decode.d3.loss_cls: 1.2130  decode.d3.loss_mask: 0.7208  decode.d3.loss_dice: 1.1338  decode.d4.loss_cls: 1.1446  decode.d4.loss_mask: 0.7280  decode.d4.loss_dice: 1.1483  decode.d5.loss_cls: 1.1286  decode.d5.loss_mask: 0.7250  decode.d5.loss_dice: 1.1578  decode.d6.loss_cls: 1.0833  decode.d6.loss_mask: 0.7273  decode.d6.loss_dice: 1.1412  decode.d7.loss_cls: 1.1205  decode.d7.loss_mask: 0.7235  decode.d7.loss_dice: 1.1128  decode.d8.loss_cls: 1.1069  decode.d8.loss_mask: 0.7096  decode.d8.loss_dice: 1.1274
2023/05/24 13:44:17 - mmengine - INFO - Iter(train) [156650/160000]  lr: 3.0820e-07  eta: 0:24:14  time: 0.4243  data_time: 0.0101  memory: 4804  grad_norm: 95.1849  loss: 42.1642  decode.loss_cls: 1.3930  decode.loss_mask: 0.8493  decode.loss_dice: 1.5711  decode.d0.loss_cls: 3.4371  decode.d0.loss_mask: 1.0330  decode.d0.loss_dice: 1.9240  decode.d1.loss_cls: 1.5699  decode.d1.loss_mask: 0.9418  decode.d1.loss_dice: 1.8048  decode.d2.loss_cls: 1.4851  decode.d2.loss_mask: 0.9503  decode.d2.loss_dice: 1.6815  decode.d3.loss_cls: 1.4675  decode.d3.loss_mask: 0.9207  decode.d3.loss_dice: 1.6674  decode.d4.loss_cls: 1.3999  decode.d4.loss_mask: 0.9207  decode.d4.loss_dice: 1.6612  decode.d5.loss_cls: 1.3842  decode.d5.loss_mask: 0.9146  decode.d5.loss_dice: 1.6490  decode.d6.loss_cls: 1.4369  decode.d6.loss_mask: 0.8526  decode.d6.loss_dice: 1.5770  decode.d7.loss_cls: 1.3933  decode.d7.loss_mask: 0.8566  decode.d7.loss_dice: 1.5697  decode.d8.loss_cls: 1.4109  decode.d8.loss_mask: 0.8630  decode.d8.loss_dice: 1.5784
2023/05/24 13:44:38 - mmengine - INFO - Iter(train) [156700/160000]  lr: 3.0406e-07  eta: 0:23:52  time: 0.4179  data_time: 0.0099  memory: 4953  grad_norm: 83.5072  loss: 30.0886  decode.loss_cls: 0.9112  decode.loss_mask: 0.6737  decode.loss_dice: 1.1526  decode.d0.loss_cls: 3.0087  decode.d0.loss_mask: 0.7187  decode.d0.loss_dice: 1.3152  decode.d1.loss_cls: 1.1097  decode.d1.loss_mask: 0.6944  decode.d1.loss_dice: 1.2092  decode.d2.loss_cls: 1.0329  decode.d2.loss_mask: 0.6666  decode.d2.loss_dice: 1.1548  decode.d3.loss_cls: 0.9976  decode.d3.loss_mask: 0.6479  decode.d3.loss_dice: 1.1427  decode.d4.loss_cls: 0.9817  decode.d4.loss_mask: 0.6627  decode.d4.loss_dice: 1.0940  decode.d5.loss_cls: 0.9693  decode.d5.loss_mask: 0.6726  decode.d5.loss_dice: 1.1327  decode.d6.loss_cls: 0.9127  decode.d6.loss_mask: 0.6829  decode.d6.loss_dice: 1.1100  decode.d7.loss_cls: 0.9162  decode.d7.loss_mask: 0.6714  decode.d7.loss_dice: 1.1309  decode.d8.loss_cls: 0.9021  decode.d8.loss_mask: 0.6784  decode.d8.loss_dice: 1.1353
2023/05/24 13:44:59 - mmengine - INFO - Iter(train) [156750/160000]  lr: 2.9991e-07  eta: 0:23:30  time: 0.4192  data_time: 0.0105  memory: 4836  grad_norm: 119.5900  loss: 35.4892  decode.loss_cls: 1.0327  decode.loss_mask: 0.8269  decode.loss_dice: 1.4139  decode.d0.loss_cls: 3.0460  decode.d0.loss_mask: 0.8402  decode.d0.loss_dice: 1.5870  decode.d1.loss_cls: 1.1577  decode.d1.loss_mask: 0.8635  decode.d1.loss_dice: 1.5057  decode.d2.loss_cls: 1.1365  decode.d2.loss_mask: 0.8627  decode.d2.loss_dice: 1.4691  decode.d3.loss_cls: 1.0980  decode.d3.loss_mask: 0.8392  decode.d3.loss_dice: 1.4353  decode.d4.loss_cls: 1.0915  decode.d4.loss_mask: 0.8274  decode.d4.loss_dice: 1.3903  decode.d5.loss_cls: 1.0437  decode.d5.loss_mask: 0.8199  decode.d5.loss_dice: 1.3917  decode.d6.loss_cls: 1.0523  decode.d6.loss_mask: 0.8269  decode.d6.loss_dice: 1.3956  decode.d7.loss_cls: 1.0558  decode.d7.loss_mask: 0.8247  decode.d7.loss_dice: 1.3792  decode.d8.loss_cls: 1.0423  decode.d8.loss_mask: 0.8217  decode.d8.loss_dice: 1.4119
2023/05/24 13:45:21 - mmengine - INFO - Iter(train) [156800/160000]  lr: 2.9575e-07  eta: 0:23:09  time: 0.4234  data_time: 0.0102  memory: 4837  grad_norm: 113.3669  loss: 31.2583  decode.loss_cls: 1.1272  decode.loss_mask: 0.7167  decode.loss_dice: 1.0110  decode.d0.loss_cls: 3.0103  decode.d0.loss_mask: 0.7795  decode.d0.loss_dice: 1.2525  decode.d1.loss_cls: 1.2856  decode.d1.loss_mask: 0.7349  decode.d1.loss_dice: 1.1348  decode.d2.loss_cls: 1.1513  decode.d2.loss_mask: 0.7217  decode.d2.loss_dice: 1.0878  decode.d3.loss_cls: 1.1122  decode.d3.loss_mask: 0.7161  decode.d3.loss_dice: 1.0316  decode.d4.loss_cls: 1.1643  decode.d4.loss_mask: 0.7056  decode.d4.loss_dice: 1.0312  decode.d5.loss_cls: 1.1303  decode.d5.loss_mask: 0.7049  decode.d5.loss_dice: 1.0146  decode.d6.loss_cls: 1.1939  decode.d6.loss_mask: 0.7171  decode.d6.loss_dice: 1.0104  decode.d7.loss_cls: 1.1476  decode.d7.loss_mask: 0.7165  decode.d7.loss_dice: 0.9934  decode.d8.loss_cls: 1.1193  decode.d8.loss_mask: 0.7157  decode.d8.loss_dice: 1.0202
2023/05/24 13:45:42 - mmengine - INFO - Iter(train) [156850/160000]  lr: 2.9159e-07  eta: 0:22:47  time: 0.4638  data_time: 0.0097  memory: 4835  grad_norm: 98.9067  loss: 23.1484  decode.loss_cls: 0.7075  decode.loss_mask: 0.5832  decode.loss_dice: 0.8228  decode.d0.loss_cls: 2.4822  decode.d0.loss_mask: 0.5799  decode.d0.loss_dice: 0.9546  decode.d1.loss_cls: 0.7012  decode.d1.loss_mask: 0.6123  decode.d1.loss_dice: 0.9079  decode.d2.loss_cls: 0.7065  decode.d2.loss_mask: 0.6090  decode.d2.loss_dice: 0.8729  decode.d3.loss_cls: 0.6551  decode.d3.loss_mask: 0.5949  decode.d3.loss_dice: 0.8453  decode.d4.loss_cls: 0.6708  decode.d4.loss_mask: 0.6017  decode.d4.loss_dice: 0.8289  decode.d5.loss_cls: 0.6888  decode.d5.loss_mask: 0.5911  decode.d5.loss_dice: 0.8307  decode.d6.loss_cls: 0.6833  decode.d6.loss_mask: 0.5845  decode.d6.loss_dice: 0.8278  decode.d7.loss_cls: 0.6956  decode.d7.loss_mask: 0.5825  decode.d7.loss_dice: 0.8248  decode.d8.loss_cls: 0.6924  decode.d8.loss_mask: 0.5916  decode.d8.loss_dice: 0.8186
2023/05/24 13:46:06 - mmengine - INFO - Iter(train) [156900/160000]  lr: 2.8742e-07  eta: 0:22:25  time: 0.4496  data_time: 0.0107  memory: 4855  grad_norm: 92.3281  loss: 29.4311  decode.loss_cls: 0.9145  decode.loss_mask: 0.6512  decode.loss_dice: 1.0731  decode.d0.loss_cls: 2.8560  decode.d0.loss_mask: 0.7435  decode.d0.loss_dice: 1.1829  decode.d1.loss_cls: 1.1448  decode.d1.loss_mask: 0.6973  decode.d1.loss_dice: 1.1462  decode.d2.loss_cls: 1.0422  decode.d2.loss_mask: 0.6973  decode.d2.loss_dice: 1.1145  decode.d3.loss_cls: 0.9841  decode.d3.loss_mask: 0.7233  decode.d3.loss_dice: 1.0849  decode.d4.loss_cls: 0.9610  decode.d4.loss_mask: 0.6878  decode.d4.loss_dice: 1.0645  decode.d5.loss_cls: 0.9370  decode.d5.loss_mask: 0.6790  decode.d5.loss_dice: 1.0769  decode.d6.loss_cls: 0.9309  decode.d6.loss_mask: 0.6703  decode.d6.loss_dice: 1.0666  decode.d7.loss_cls: 0.9078  decode.d7.loss_mask: 0.6752  decode.d7.loss_dice: 1.0673  decode.d8.loss_cls: 0.9183  decode.d8.loss_mask: 0.6661  decode.d8.loss_dice: 1.0666
2023/05/24 13:46:27 - mmengine - INFO - Iter(train) [156950/160000]  lr: 2.8325e-07  eta: 0:22:04  time: 0.4246  data_time: 0.0099  memory: 4888  grad_norm: 84.7132  loss: 33.0922  decode.loss_cls: 1.1337  decode.loss_mask: 0.7385  decode.loss_dice: 1.1916  decode.d0.loss_cls: 3.1049  decode.d0.loss_mask: 0.8021  decode.d0.loss_dice: 1.3924  decode.d1.loss_cls: 1.2510  decode.d1.loss_mask: 0.7692  decode.d1.loss_dice: 1.3064  decode.d2.loss_cls: 1.1487  decode.d2.loss_mask: 0.7462  decode.d2.loss_dice: 1.2756  decode.d3.loss_cls: 1.0812  decode.d3.loss_mask: 0.7304  decode.d3.loss_dice: 1.2182  decode.d4.loss_cls: 1.1091  decode.d4.loss_mask: 0.7377  decode.d4.loss_dice: 1.2375  decode.d5.loss_cls: 1.1343  decode.d5.loss_mask: 0.7199  decode.d5.loss_dice: 1.2197  decode.d6.loss_cls: 1.0948  decode.d6.loss_mask: 0.7416  decode.d6.loss_dice: 1.1969  decode.d7.loss_cls: 1.0934  decode.d7.loss_mask: 0.7252  decode.d7.loss_dice: 1.1861  decode.d8.loss_cls: 1.1058  decode.d8.loss_mask: 0.7260  decode.d8.loss_dice: 1.1740
2023/05/24 13:46:50 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 13:46:50 - mmengine - INFO - Iter(train) [157000/160000]  lr: 2.7906e-07  eta: 0:21:42  time: 0.4859  data_time: 0.0098  memory: 4810  grad_norm: 87.2846  loss: 36.2865  decode.loss_cls: 1.1218  decode.loss_mask: 0.7257  decode.loss_dice: 1.4387  decode.d0.loss_cls: 3.3077  decode.d0.loss_mask: 0.7559  decode.d0.loss_dice: 1.6884  decode.d1.loss_cls: 1.3009  decode.d1.loss_mask: 0.7357  decode.d1.loss_dice: 1.5595  decode.d2.loss_cls: 1.3271  decode.d2.loss_mask: 0.7095  decode.d2.loss_dice: 1.4477  decode.d3.loss_cls: 1.2759  decode.d3.loss_mask: 0.7199  decode.d3.loss_dice: 1.4722  decode.d4.loss_cls: 1.2215  decode.d4.loss_mask: 0.7179  decode.d4.loss_dice: 1.4702  decode.d5.loss_cls: 1.1598  decode.d5.loss_mask: 0.7175  decode.d5.loss_dice: 1.4314  decode.d6.loss_cls: 1.1641  decode.d6.loss_mask: 0.7263  decode.d6.loss_dice: 1.4242  decode.d7.loss_cls: 1.1594  decode.d7.loss_mask: 0.7231  decode.d7.loss_dice: 1.4716  decode.d8.loss_cls: 1.1642  decode.d8.loss_mask: 0.7165  decode.d8.loss_dice: 1.4324
2023/05/24 13:46:50 - mmengine - INFO - Saving checkpoint at 157000 iterations
2023/05/24 13:47:19 - mmengine - INFO - Iter(train) [157050/160000]  lr: 2.7487e-07  eta: 0:21:20  time: 0.4464  data_time: 0.0111  memory: 4860  grad_norm: 88.2593  loss: 35.3780  decode.loss_cls: 1.0754  decode.loss_mask: 0.9076  decode.loss_dice: 1.3132  decode.d0.loss_cls: 2.9940  decode.d0.loss_mask: 0.8577  decode.d0.loss_dice: 1.5055  decode.d1.loss_cls: 1.1828  decode.d1.loss_mask: 0.8760  decode.d1.loss_dice: 1.4115  decode.d2.loss_cls: 1.1197  decode.d2.loss_mask: 0.9222  decode.d2.loss_dice: 1.3809  decode.d3.loss_cls: 1.0786  decode.d3.loss_mask: 0.9328  decode.d3.loss_dice: 1.3352  decode.d4.loss_cls: 1.0838  decode.d4.loss_mask: 0.9053  decode.d4.loss_dice: 1.3101  decode.d5.loss_cls: 1.0702  decode.d5.loss_mask: 0.9142  decode.d5.loss_dice: 1.3394  decode.d6.loss_cls: 1.0717  decode.d6.loss_mask: 0.9031  decode.d6.loss_dice: 1.3121  decode.d7.loss_cls: 1.0412  decode.d7.loss_mask: 0.9187  decode.d7.loss_dice: 1.3051  decode.d8.loss_cls: 1.1091  decode.d8.loss_mask: 0.8988  decode.d8.loss_dice: 1.3020
2023/05/24 13:47:40 - mmengine - INFO - Iter(train) [157100/160000]  lr: 2.7068e-07  eta: 0:20:59  time: 0.4232  data_time: 0.0100  memory: 4899  grad_norm: 115.4414  loss: 29.8806  decode.loss_cls: 0.9860  decode.loss_mask: 0.6217  decode.loss_dice: 1.0475  decode.d0.loss_cls: 3.2612  decode.d0.loss_mask: 0.6875  decode.d0.loss_dice: 1.3295  decode.d1.loss_cls: 1.0928  decode.d1.loss_mask: 0.6635  decode.d1.loss_dice: 1.2156  decode.d2.loss_cls: 1.0763  decode.d2.loss_mask: 0.6545  decode.d2.loss_dice: 1.1516  decode.d3.loss_cls: 0.9460  decode.d3.loss_mask: 0.6675  decode.d3.loss_dice: 1.0998  decode.d4.loss_cls: 0.9922  decode.d4.loss_mask: 0.6340  decode.d4.loss_dice: 1.0915  decode.d5.loss_cls: 0.9505  decode.d5.loss_mask: 0.6374  decode.d5.loss_dice: 1.1038  decode.d6.loss_cls: 0.9204  decode.d6.loss_mask: 0.6542  decode.d6.loss_dice: 1.0723  decode.d7.loss_cls: 0.9217  decode.d7.loss_mask: 0.6475  decode.d7.loss_dice: 1.0853  decode.d8.loss_cls: 0.9426  decode.d8.loss_mask: 0.6340  decode.d8.loss_dice: 1.0922
2023/05/24 13:48:02 - mmengine - INFO - Iter(train) [157150/160000]  lr: 2.6647e-07  eta: 0:20:37  time: 0.4283  data_time: 0.0098  memory: 4821  grad_norm: 76.9838  loss: 28.0205  decode.loss_cls: 0.8997  decode.loss_mask: 0.6623  decode.loss_dice: 0.9242  decode.d0.loss_cls: 3.1054  decode.d0.loss_mask: 0.7662  decode.d0.loss_dice: 1.1193  decode.d1.loss_cls: 1.0469  decode.d1.loss_mask: 0.7377  decode.d1.loss_dice: 1.0216  decode.d2.loss_cls: 0.9171  decode.d2.loss_mask: 0.7127  decode.d2.loss_dice: 1.0053  decode.d3.loss_cls: 0.8983  decode.d3.loss_mask: 0.7033  decode.d3.loss_dice: 0.9584  decode.d4.loss_cls: 0.9048  decode.d4.loss_mask: 0.6950  decode.d4.loss_dice: 0.9487  decode.d5.loss_cls: 0.8644  decode.d5.loss_mask: 0.6832  decode.d5.loss_dice: 0.9507  decode.d6.loss_cls: 0.8598  decode.d6.loss_mask: 0.6896  decode.d6.loss_dice: 0.9424  decode.d7.loss_cls: 0.9240  decode.d7.loss_mask: 0.6510  decode.d7.loss_dice: 0.9214  decode.d8.loss_cls: 0.8705  decode.d8.loss_mask: 0.6930  decode.d8.loss_dice: 0.9435
2023/05/24 13:48:23 - mmengine - INFO - Iter(train) [157200/160000]  lr: 2.6226e-07  eta: 0:20:15  time: 0.4284  data_time: 0.0110  memory: 4821  grad_norm: 76.7865  loss: 37.7628  decode.loss_cls: 1.3698  decode.loss_mask: 0.7316  decode.loss_dice: 1.3728  decode.d0.loss_cls: 3.0588  decode.d0.loss_mask: 0.7498  decode.d0.loss_dice: 1.5163  decode.d1.loss_cls: 1.4222  decode.d1.loss_mask: 0.7850  decode.d1.loss_dice: 1.5462  decode.d2.loss_cls: 1.5729  decode.d2.loss_mask: 0.7244  decode.d2.loss_dice: 1.4466  decode.d3.loss_cls: 1.5435  decode.d3.loss_mask: 0.7408  decode.d3.loss_dice: 1.3835  decode.d4.loss_cls: 1.4744  decode.d4.loss_mask: 0.7617  decode.d4.loss_dice: 1.3740  decode.d5.loss_cls: 1.4628  decode.d5.loss_mask: 0.7338  decode.d5.loss_dice: 1.3419  decode.d6.loss_cls: 1.4697  decode.d6.loss_mask: 0.7306  decode.d6.loss_dice: 1.3696  decode.d7.loss_cls: 1.4469  decode.d7.loss_mask: 0.7504  decode.d7.loss_dice: 1.3647  decode.d8.loss_cls: 1.4389  decode.d8.loss_mask: 0.7192  decode.d8.loss_dice: 1.3598
2023/05/24 13:48:44 - mmengine - INFO - Iter(train) [157250/160000]  lr: 2.5804e-07  eta: 0:19:54  time: 0.4217  data_time: 0.0096  memory: 4876  grad_norm: 108.0520  loss: 37.2236  decode.loss_cls: 1.3510  decode.loss_mask: 0.6645  decode.loss_dice: 1.3711  decode.d0.loss_cls: 3.2617  decode.d0.loss_mask: 0.7118  decode.d0.loss_dice: 1.6139  decode.d1.loss_cls: 1.4256  decode.d1.loss_mask: 0.7591  decode.d1.loss_dice: 1.5639  decode.d2.loss_cls: 1.4314  decode.d2.loss_mask: 0.7071  decode.d2.loss_dice: 1.4961  decode.d3.loss_cls: 1.3897  decode.d3.loss_mask: 0.6965  decode.d3.loss_dice: 1.4493  decode.d4.loss_cls: 1.4278  decode.d4.loss_mask: 0.6763  decode.d4.loss_dice: 1.4522  decode.d5.loss_cls: 1.2950  decode.d5.loss_mask: 0.7220  decode.d5.loss_dice: 1.4665  decode.d6.loss_cls: 1.3670  decode.d6.loss_mask: 0.6894  decode.d6.loss_dice: 1.3972  decode.d7.loss_cls: 1.3532  decode.d7.loss_mask: 0.6774  decode.d7.loss_dice: 1.3812  decode.d8.loss_cls: 1.3351  decode.d8.loss_mask: 0.6867  decode.d8.loss_dice: 1.4039
2023/05/24 13:49:06 - mmengine - INFO - Iter(train) [157300/160000]  lr: 2.5382e-07  eta: 0:19:32  time: 0.4264  data_time: 0.0100  memory: 4838  grad_norm: 96.5228  loss: 41.4203  decode.loss_cls: 1.2834  decode.loss_mask: 0.9285  decode.loss_dice: 1.5751  decode.d0.loss_cls: 3.5046  decode.d0.loss_mask: 1.0413  decode.d0.loss_dice: 1.8355  decode.d1.loss_cls: 1.5816  decode.d1.loss_mask: 0.9304  decode.d1.loss_dice: 1.7310  decode.d2.loss_cls: 1.4471  decode.d2.loss_mask: 0.9304  decode.d2.loss_dice: 1.5985  decode.d3.loss_cls: 1.3927  decode.d3.loss_mask: 0.9221  decode.d3.loss_dice: 1.5920  decode.d4.loss_cls: 1.3180  decode.d4.loss_mask: 0.9438  decode.d4.loss_dice: 1.5853  decode.d5.loss_cls: 1.3555  decode.d5.loss_mask: 0.9341  decode.d5.loss_dice: 1.5644  decode.d6.loss_cls: 1.2790  decode.d6.loss_mask: 0.9471  decode.d6.loss_dice: 1.5607  decode.d7.loss_cls: 1.3063  decode.d7.loss_mask: 0.9498  decode.d7.loss_dice: 1.5991  decode.d8.loss_cls: 1.3069  decode.d8.loss_mask: 0.9218  decode.d8.loss_dice: 1.5540
2023/05/24 13:49:27 - mmengine - INFO - Iter(train) [157350/160000]  lr: 2.4958e-07  eta: 0:19:10  time: 0.4241  data_time: 0.0100  memory: 4858  grad_norm: 103.6878  loss: 36.1789  decode.loss_cls: 1.1714  decode.loss_mask: 0.7910  decode.loss_dice: 1.2664  decode.d0.loss_cls: 3.3121  decode.d0.loss_mask: 0.8452  decode.d0.loss_dice: 1.5286  decode.d1.loss_cls: 1.5259  decode.d1.loss_mask: 0.8238  decode.d1.loss_dice: 1.3864  decode.d2.loss_cls: 1.3611  decode.d2.loss_mask: 0.7943  decode.d2.loss_dice: 1.3506  decode.d3.loss_cls: 1.3289  decode.d3.loss_mask: 0.7709  decode.d3.loss_dice: 1.3289  decode.d4.loss_cls: 1.2809  decode.d4.loss_mask: 0.7807  decode.d4.loss_dice: 1.3326  decode.d5.loss_cls: 1.2048  decode.d5.loss_mask: 0.7845  decode.d5.loss_dice: 1.3546  decode.d6.loss_cls: 1.2321  decode.d6.loss_mask: 0.7823  decode.d6.loss_dice: 1.2855  decode.d7.loss_cls: 1.2097  decode.d7.loss_mask: 0.7848  decode.d7.loss_dice: 1.2558  decode.d8.loss_cls: 1.2436  decode.d8.loss_mask: 0.7801  decode.d8.loss_dice: 1.2815
2023/05/24 13:49:49 - mmengine - INFO - Iter(train) [157400/160000]  lr: 2.4534e-07  eta: 0:18:48  time: 0.4405  data_time: 0.0099  memory: 4864  grad_norm: 142.5501  loss: 32.9133  decode.loss_cls: 0.9326  decode.loss_mask: 0.7035  decode.loss_dice: 1.3547  decode.d0.loss_cls: 2.8225  decode.d0.loss_mask: 0.7237  decode.d0.loss_dice: 1.6654  decode.d1.loss_cls: 1.0032  decode.d1.loss_mask: 0.7164  decode.d1.loss_dice: 1.5055  decode.d2.loss_cls: 0.9922  decode.d2.loss_mask: 0.6897  decode.d2.loss_dice: 1.4825  decode.d3.loss_cls: 0.9736  decode.d3.loss_mask: 0.6846  decode.d3.loss_dice: 1.4294  decode.d4.loss_cls: 0.8688  decode.d4.loss_mask: 0.7085  decode.d4.loss_dice: 1.4675  decode.d5.loss_cls: 0.9281  decode.d5.loss_mask: 0.7022  decode.d5.loss_dice: 1.4336  decode.d6.loss_cls: 0.9294  decode.d6.loss_mask: 0.7203  decode.d6.loss_dice: 1.4010  decode.d7.loss_cls: 0.9509  decode.d7.loss_mask: 0.7006  decode.d7.loss_dice: 1.4039  decode.d8.loss_cls: 0.9131  decode.d8.loss_mask: 0.7126  decode.d8.loss_dice: 1.3933
2023/05/24 13:50:10 - mmengine - INFO - Iter(train) [157450/160000]  lr: 2.4109e-07  eta: 0:18:27  time: 0.4222  data_time: 0.0099  memory: 4819  grad_norm: 87.9097  loss: 35.0101  decode.loss_cls: 1.1009  decode.loss_mask: 0.7750  decode.loss_dice: 1.3529  decode.d0.loss_cls: 3.0024  decode.d0.loss_mask: 0.8205  decode.d0.loss_dice: 1.5908  decode.d1.loss_cls: 1.2398  decode.d1.loss_mask: 0.8239  decode.d1.loss_dice: 1.5143  decode.d2.loss_cls: 1.1756  decode.d2.loss_mask: 0.7993  decode.d2.loss_dice: 1.3785  decode.d3.loss_cls: 1.1852  decode.d3.loss_mask: 0.7634  decode.d3.loss_dice: 1.3454  decode.d4.loss_cls: 1.1408  decode.d4.loss_mask: 0.7817  decode.d4.loss_dice: 1.3349  decode.d5.loss_cls: 1.1108  decode.d5.loss_mask: 0.7802  decode.d5.loss_dice: 1.3287  decode.d6.loss_cls: 1.1494  decode.d6.loss_mask: 0.7821  decode.d6.loss_dice: 1.3163  decode.d7.loss_cls: 1.0860  decode.d7.loss_mask: 0.7835  decode.d7.loss_dice: 1.3491  decode.d8.loss_cls: 1.0862  decode.d8.loss_mask: 0.7813  decode.d8.loss_dice: 1.3312
2023/05/24 13:50:32 - mmengine - INFO - Iter(train) [157500/160000]  lr: 2.3683e-07  eta: 0:18:05  time: 0.4245  data_time: 0.0100  memory: 4876  grad_norm: 96.1545  loss: 33.3419  decode.loss_cls: 1.0408  decode.loss_mask: 0.8287  decode.loss_dice: 1.2282  decode.d0.loss_cls: 2.9531  decode.d0.loss_mask: 0.9109  decode.d0.loss_dice: 1.4086  decode.d1.loss_cls: 1.1693  decode.d1.loss_mask: 0.8502  decode.d1.loss_dice: 1.3371  decode.d2.loss_cls: 1.0236  decode.d2.loss_mask: 0.8476  decode.d2.loss_dice: 1.2594  decode.d3.loss_cls: 1.0314  decode.d3.loss_mask: 0.8464  decode.d3.loss_dice: 1.2682  decode.d4.loss_cls: 0.9751  decode.d4.loss_mask: 0.8641  decode.d4.loss_dice: 1.2088  decode.d5.loss_cls: 0.9862  decode.d5.loss_mask: 0.8142  decode.d5.loss_dice: 1.1971  decode.d6.loss_cls: 1.0517  decode.d6.loss_mask: 0.8281  decode.d6.loss_dice: 1.2506  decode.d7.loss_cls: 1.0160  decode.d7.loss_mask: 0.8456  decode.d7.loss_dice: 1.2175  decode.d8.loss_cls: 1.0152  decode.d8.loss_mask: 0.8345  decode.d8.loss_dice: 1.2338
2023/05/24 13:50:53 - mmengine - INFO - Iter(train) [157550/160000]  lr: 2.3256e-07  eta: 0:17:43  time: 0.4256  data_time: 0.0107  memory: 4834  grad_norm: 101.2919  loss: 29.1318  decode.loss_cls: 1.0385  decode.loss_mask: 0.6515  decode.loss_dice: 0.9897  decode.d0.loss_cls: 2.7603  decode.d0.loss_mask: 0.7001  decode.d0.loss_dice: 1.1315  decode.d1.loss_cls: 1.0645  decode.d1.loss_mask: 0.7294  decode.d1.loss_dice: 1.2431  decode.d2.loss_cls: 1.0774  decode.d2.loss_mask: 0.6706  decode.d2.loss_dice: 1.0929  decode.d3.loss_cls: 0.9774  decode.d3.loss_mask: 0.6804  decode.d3.loss_dice: 1.0382  decode.d4.loss_cls: 1.0068  decode.d4.loss_mask: 0.6476  decode.d4.loss_dice: 1.0450  decode.d5.loss_cls: 1.0155  decode.d5.loss_mask: 0.6333  decode.d5.loss_dice: 1.0396  decode.d6.loss_cls: 0.9323  decode.d6.loss_mask: 0.6718  decode.d6.loss_dice: 0.9894  decode.d7.loss_cls: 0.9567  decode.d7.loss_mask: 0.6614  decode.d7.loss_dice: 0.9884  decode.d8.loss_cls: 0.9800  decode.d8.loss_mask: 0.6662  decode.d8.loss_dice: 1.0521
2023/05/24 13:51:15 - mmengine - INFO - Iter(train) [157600/160000]  lr: 2.2829e-07  eta: 0:17:22  time: 0.4254  data_time: 0.0098  memory: 4908  grad_norm: 93.3635  loss: 39.0587  decode.loss_cls: 1.4282  decode.loss_mask: 0.7665  decode.loss_dice: 1.4136  decode.d0.loss_cls: 3.3803  decode.d0.loss_mask: 0.7583  decode.d0.loss_dice: 1.6618  decode.d1.loss_cls: 1.6154  decode.d1.loss_mask: 0.7232  decode.d1.loss_dice: 1.5402  decode.d2.loss_cls: 1.4939  decode.d2.loss_mask: 0.7551  decode.d2.loss_dice: 1.5022  decode.d3.loss_cls: 1.5431  decode.d3.loss_mask: 0.7398  decode.d3.loss_dice: 1.4313  decode.d4.loss_cls: 1.4710  decode.d4.loss_mask: 0.7452  decode.d4.loss_dice: 1.4338  decode.d5.loss_cls: 1.5542  decode.d5.loss_mask: 0.7365  decode.d5.loss_dice: 1.4256  decode.d6.loss_cls: 1.5316  decode.d6.loss_mask: 0.7546  decode.d6.loss_dice: 1.4031  decode.d7.loss_cls: 1.4561  decode.d7.loss_mask: 0.7745  decode.d7.loss_dice: 1.4228  decode.d8.loss_cls: 1.4167  decode.d8.loss_mask: 0.7505  decode.d8.loss_dice: 1.4295
2023/05/24 13:51:36 - mmengine - INFO - Iter(train) [157650/160000]  lr: 2.2400e-07  eta: 0:17:00  time: 0.4271  data_time: 0.0101  memory: 4908  grad_norm: 91.6458  loss: 30.9414  decode.loss_cls: 0.9251  decode.loss_mask: 0.6774  decode.loss_dice: 1.2289  decode.d0.loss_cls: 2.8003  decode.d0.loss_mask: 0.6985  decode.d0.loss_dice: 1.3592  decode.d1.loss_cls: 1.1539  decode.d1.loss_mask: 0.6714  decode.d1.loss_dice: 1.3125  decode.d2.loss_cls: 1.0156  decode.d2.loss_mask: 0.6735  decode.d2.loss_dice: 1.2746  decode.d3.loss_cls: 0.9996  decode.d3.loss_mask: 0.6756  decode.d3.loss_dice: 1.2454  decode.d4.loss_cls: 1.0225  decode.d4.loss_mask: 0.6813  decode.d4.loss_dice: 1.2328  decode.d5.loss_cls: 0.9971  decode.d5.loss_mask: 0.6726  decode.d5.loss_dice: 1.1798  decode.d6.loss_cls: 0.9248  decode.d6.loss_mask: 0.6785  decode.d6.loss_dice: 1.2137  decode.d7.loss_cls: 0.9287  decode.d7.loss_mask: 0.6826  decode.d7.loss_dice: 1.1857  decode.d8.loss_cls: 0.9586  decode.d8.loss_mask: 0.6763  decode.d8.loss_dice: 1.1949
2023/05/24 13:51:58 - mmengine - INFO - Iter(train) [157700/160000]  lr: 2.1971e-07  eta: 0:16:38  time: 0.4322  data_time: 0.0101  memory: 4877  grad_norm: 90.2725  loss: 35.3772  decode.loss_cls: 1.2404  decode.loss_mask: 0.6998  decode.loss_dice: 1.2823  decode.d0.loss_cls: 3.3368  decode.d0.loss_mask: 0.7895  decode.d0.loss_dice: 1.5395  decode.d1.loss_cls: 1.3640  decode.d1.loss_mask: 0.7701  decode.d1.loss_dice: 1.4007  decode.d2.loss_cls: 1.2537  decode.d2.loss_mask: 0.7342  decode.d2.loss_dice: 1.3448  decode.d3.loss_cls: 1.2440  decode.d3.loss_mask: 0.7129  decode.d3.loss_dice: 1.3522  decode.d4.loss_cls: 1.1991  decode.d4.loss_mask: 0.7276  decode.d4.loss_dice: 1.3135  decode.d5.loss_cls: 1.2954  decode.d5.loss_mask: 0.7402  decode.d5.loss_dice: 1.3020  decode.d6.loss_cls: 1.2658  decode.d6.loss_mask: 0.7119  decode.d6.loss_dice: 1.2946  decode.d7.loss_cls: 1.2164  decode.d7.loss_mask: 0.7430  decode.d7.loss_dice: 1.2538  decode.d8.loss_cls: 1.2384  decode.d8.loss_mask: 0.7060  decode.d8.loss_dice: 1.3047
2023/05/24 13:52:19 - mmengine - INFO - Iter(train) [157750/160000]  lr: 2.1541e-07  eta: 0:16:16  time: 0.4198  data_time: 0.0099  memory: 4875  grad_norm: 101.5977  loss: 36.0085  decode.loss_cls: 1.2147  decode.loss_mask: 0.8753  decode.loss_dice: 1.2192  decode.d0.loss_cls: 3.1493  decode.d0.loss_mask: 0.9292  decode.d0.loss_dice: 1.4224  decode.d1.loss_cls: 1.4200  decode.d1.loss_mask: 0.9320  decode.d1.loss_dice: 1.3504  decode.d2.loss_cls: 1.3031  decode.d2.loss_mask: 0.8944  decode.d2.loss_dice: 1.2839  decode.d3.loss_cls: 1.2368  decode.d3.loss_mask: 0.9030  decode.d3.loss_dice: 1.2509  decode.d4.loss_cls: 1.2108  decode.d4.loss_mask: 0.8877  decode.d4.loss_dice: 1.2332  decode.d5.loss_cls: 1.2843  decode.d5.loss_mask: 0.8806  decode.d5.loss_dice: 1.2066  decode.d6.loss_cls: 1.2266  decode.d6.loss_mask: 0.8739  decode.d6.loss_dice: 1.1933  decode.d7.loss_cls: 1.2744  decode.d7.loss_mask: 0.8670  decode.d7.loss_dice: 1.1788  decode.d8.loss_cls: 1.2781  decode.d8.loss_mask: 0.8568  decode.d8.loss_dice: 1.1722
2023/05/24 13:52:41 - mmengine - INFO - Iter(train) [157800/160000]  lr: 2.1109e-07  eta: 0:15:55  time: 0.4492  data_time: 0.0101  memory: 4818  grad_norm: 86.7139  loss: 24.6243  decode.loss_cls: 0.7147  decode.loss_mask: 0.6329  decode.loss_dice: 0.8615  decode.d0.loss_cls: 2.7696  decode.d0.loss_mask: 0.6525  decode.d0.loss_dice: 1.0108  decode.d1.loss_cls: 0.7063  decode.d1.loss_mask: 0.6492  decode.d1.loss_dice: 0.9550  decode.d2.loss_cls: 0.7031  decode.d2.loss_mask: 0.6448  decode.d2.loss_dice: 0.9180  decode.d3.loss_cls: 0.6986  decode.d3.loss_mask: 0.6456  decode.d3.loss_dice: 0.8914  decode.d4.loss_cls: 0.6887  decode.d4.loss_mask: 0.6367  decode.d4.loss_dice: 0.9042  decode.d5.loss_cls: 0.7811  decode.d5.loss_mask: 0.6296  decode.d5.loss_dice: 0.8902  decode.d6.loss_cls: 0.6979  decode.d6.loss_mask: 0.6366  decode.d6.loss_dice: 0.8886  decode.d7.loss_cls: 0.6789  decode.d7.loss_mask: 0.6326  decode.d7.loss_dice: 0.8986  decode.d8.loss_cls: 0.6609  decode.d8.loss_mask: 0.6351  decode.d8.loss_dice: 0.9105
2023/05/24 13:53:03 - mmengine - INFO - Iter(train) [157850/160000]  lr: 2.0677e-07  eta: 0:15:33  time: 0.4296  data_time: 0.0107  memory: 4826  grad_norm: 89.5657  loss: 25.4994  decode.loss_cls: 0.8348  decode.loss_mask: 0.5573  decode.loss_dice: 0.9081  decode.d0.loss_cls: 2.6118  decode.d0.loss_mask: 0.6458  decode.d0.loss_dice: 1.0468  decode.d1.loss_cls: 0.9259  decode.d1.loss_mask: 0.6031  decode.d1.loss_dice: 0.9682  decode.d2.loss_cls: 0.8734  decode.d2.loss_mask: 0.6082  decode.d2.loss_dice: 0.9527  decode.d3.loss_cls: 0.8462  decode.d3.loss_mask: 0.6725  decode.d3.loss_dice: 0.9450  decode.d4.loss_cls: 0.8520  decode.d4.loss_mask: 0.5842  decode.d4.loss_dice: 0.9440  decode.d5.loss_cls: 0.8167  decode.d5.loss_mask: 0.5735  decode.d5.loss_dice: 0.9218  decode.d6.loss_cls: 0.8105  decode.d6.loss_mask: 0.5623  decode.d6.loss_dice: 0.9357  decode.d7.loss_cls: 0.7763  decode.d7.loss_mask: 0.5640  decode.d7.loss_dice: 0.9124  decode.d8.loss_cls: 0.8003  decode.d8.loss_mask: 0.5585  decode.d8.loss_dice: 0.8872
2023/05/24 13:53:25 - mmengine - INFO - Iter(train) [157900/160000]  lr: 2.0244e-07  eta: 0:15:11  time: 0.4273  data_time: 0.0100  memory: 4890  grad_norm: 89.9879  loss: 30.4759  decode.loss_cls: 0.9374  decode.loss_mask: 0.7073  decode.loss_dice: 1.1597  decode.d0.loss_cls: 2.7881  decode.d0.loss_mask: 0.7384  decode.d0.loss_dice: 1.2766  decode.d1.loss_cls: 1.0023  decode.d1.loss_mask: 0.8121  decode.d1.loss_dice: 1.2379  decode.d2.loss_cls: 1.0145  decode.d2.loss_mask: 0.7714  decode.d2.loss_dice: 1.2138  decode.d3.loss_cls: 0.9448  decode.d3.loss_mask: 0.7652  decode.d3.loss_dice: 1.1540  decode.d4.loss_cls: 0.8978  decode.d4.loss_mask: 0.7369  decode.d4.loss_dice: 1.1620  decode.d5.loss_cls: 0.9176  decode.d5.loss_mask: 0.7102  decode.d5.loss_dice: 1.1480  decode.d6.loss_cls: 0.9261  decode.d6.loss_mask: 0.6983  decode.d6.loss_dice: 1.1818  decode.d7.loss_cls: 0.9050  decode.d7.loss_mask: 0.7022  decode.d7.loss_dice: 1.1766  decode.d8.loss_cls: 0.9318  decode.d8.loss_mask: 0.6955  decode.d8.loss_dice: 1.1626
2023/05/24 13:53:46 - mmengine - INFO - Iter(train) [157950/160000]  lr: 1.9809e-07  eta: 0:14:50  time: 0.4191  data_time: 0.0098  memory: 4845  grad_norm: 86.7939  loss: 33.3552  decode.loss_cls: 1.0980  decode.loss_mask: 0.6573  decode.loss_dice: 1.2725  decode.d0.loss_cls: 2.7223  decode.d0.loss_mask: 0.7784  decode.d0.loss_dice: 1.5587  decode.d1.loss_cls: 1.2248  decode.d1.loss_mask: 0.6869  decode.d1.loss_dice: 1.4664  decode.d2.loss_cls: 1.1886  decode.d2.loss_mask: 0.6453  decode.d2.loss_dice: 1.3776  decode.d3.loss_cls: 1.2158  decode.d3.loss_mask: 0.6458  decode.d3.loss_dice: 1.3260  decode.d4.loss_cls: 1.1164  decode.d4.loss_mask: 0.6376  decode.d4.loss_dice: 1.3488  decode.d5.loss_cls: 1.1053  decode.d5.loss_mask: 0.6311  decode.d5.loss_dice: 1.3226  decode.d6.loss_cls: 1.1757  decode.d6.loss_mask: 0.6524  decode.d6.loss_dice: 1.2978  decode.d7.loss_cls: 1.1310  decode.d7.loss_mask: 0.6514  decode.d7.loss_dice: 1.2984  decode.d8.loss_cls: 1.1423  decode.d8.loss_mask: 0.6377  decode.d8.loss_dice: 1.3424
2023/05/24 13:54:07 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 13:54:07 - mmengine - INFO - Iter(train) [158000/160000]  lr: 1.9374e-07  eta: 0:14:28  time: 0.4262  data_time: 0.0101  memory: 4821  grad_norm: 99.9780  loss: 30.4220  decode.loss_cls: 0.8987  decode.loss_mask: 0.7404  decode.loss_dice: 1.1639  decode.d0.loss_cls: 2.8371  decode.d0.loss_mask: 0.7677  decode.d0.loss_dice: 1.2882  decode.d1.loss_cls: 1.1046  decode.d1.loss_mask: 0.7680  decode.d1.loss_dice: 1.2196  decode.d2.loss_cls: 1.0400  decode.d2.loss_mask: 0.7347  decode.d2.loss_dice: 1.1622  decode.d3.loss_cls: 0.9657  decode.d3.loss_mask: 0.7259  decode.d3.loss_dice: 1.1309  decode.d4.loss_cls: 0.8806  decode.d4.loss_mask: 0.7442  decode.d4.loss_dice: 1.1271  decode.d5.loss_cls: 0.9139  decode.d5.loss_mask: 0.7437  decode.d5.loss_dice: 1.1324  decode.d6.loss_cls: 0.9499  decode.d6.loss_mask: 0.7332  decode.d6.loss_dice: 1.1253  decode.d7.loss_cls: 0.9174  decode.d7.loss_mask: 0.7309  decode.d7.loss_dice: 1.1153  decode.d8.loss_cls: 0.9272  decode.d8.loss_mask: 0.7250  decode.d8.loss_dice: 1.1082
2023/05/24 13:54:07 - mmengine - INFO - Saving checkpoint at 158000 iterations
2023/05/24 13:54:34 - mmengine - INFO - Iter(train) [158050/160000]  lr: 1.8938e-07  eta: 0:14:06  time: 0.4276  data_time: 0.0101  memory: 4877  grad_norm: 84.6826  loss: 39.0231  decode.loss_cls: 1.2128  decode.loss_mask: 0.7151  decode.loss_dice: 1.7202  decode.d0.loss_cls: 2.9529  decode.d0.loss_mask: 0.8250  decode.d0.loss_dice: 1.9469  decode.d1.loss_cls: 1.2628  decode.d1.loss_mask: 0.7778  decode.d1.loss_dice: 1.8743  decode.d2.loss_cls: 1.2408  decode.d2.loss_mask: 0.7764  decode.d2.loss_dice: 1.8288  decode.d3.loss_cls: 1.2044  decode.d3.loss_mask: 0.7373  decode.d3.loss_dice: 1.7692  decode.d4.loss_cls: 1.1824  decode.d4.loss_mask: 0.7604  decode.d4.loss_dice: 1.7303  decode.d5.loss_cls: 1.1359  decode.d5.loss_mask: 0.7564  decode.d5.loss_dice: 1.7644  decode.d6.loss_cls: 1.1632  decode.d6.loss_mask: 0.7411  decode.d6.loss_dice: 1.7086  decode.d7.loss_cls: 1.2038  decode.d7.loss_mask: 0.7278  decode.d7.loss_dice: 1.7147  decode.d8.loss_cls: 1.1290  decode.d8.loss_mask: 0.7277  decode.d8.loss_dice: 1.7327
2023/05/24 13:54:56 - mmengine - INFO - Iter(train) [158100/160000]  lr: 1.8500e-07  eta: 0:13:44  time: 0.4871  data_time: 0.0100  memory: 4837  grad_norm: 93.6172  loss: 23.6025  decode.loss_cls: 0.8967  decode.loss_mask: 0.5755  decode.loss_dice: 0.6374  decode.d0.loss_cls: 2.5981  decode.d0.loss_mask: 0.6672  decode.d0.loss_dice: 0.7872  decode.d1.loss_cls: 0.9909  decode.d1.loss_mask: 0.6149  decode.d1.loss_dice: 0.7607  decode.d2.loss_cls: 0.9739  decode.d2.loss_mask: 0.6077  decode.d2.loss_dice: 0.6926  decode.d3.loss_cls: 0.9339  decode.d3.loss_mask: 0.5698  decode.d3.loss_dice: 0.6458  decode.d4.loss_cls: 0.9518  decode.d4.loss_mask: 0.5643  decode.d4.loss_dice: 0.6547  decode.d5.loss_cls: 0.9410  decode.d5.loss_mask: 0.5740  decode.d5.loss_dice: 0.6501  decode.d6.loss_cls: 0.8850  decode.d6.loss_mask: 0.5749  decode.d6.loss_dice: 0.6425  decode.d7.loss_cls: 0.8765  decode.d7.loss_mask: 0.5740  decode.d7.loss_dice: 0.6267  decode.d8.loss_cls: 0.8888  decode.d8.loss_mask: 0.5853  decode.d8.loss_dice: 0.6608
2023/05/24 13:55:18 - mmengine - INFO - Iter(train) [158150/160000]  lr: 1.8061e-07  eta: 0:13:23  time: 0.4330  data_time: 0.0101  memory: 4839  grad_norm: 97.9844  loss: 33.9712  decode.loss_cls: 1.0097  decode.loss_mask: 0.7322  decode.loss_dice: 1.3166  decode.d0.loss_cls: 3.1687  decode.d0.loss_mask: 0.7092  decode.d0.loss_dice: 1.5702  decode.d1.loss_cls: 1.1807  decode.d1.loss_mask: 0.7805  decode.d1.loss_dice: 1.4785  decode.d2.loss_cls: 1.1177  decode.d2.loss_mask: 0.7064  decode.d2.loss_dice: 1.3967  decode.d3.loss_cls: 1.0636  decode.d3.loss_mask: 0.7117  decode.d3.loss_dice: 1.3924  decode.d4.loss_cls: 1.0466  decode.d4.loss_mask: 0.7380  decode.d4.loss_dice: 1.3695  decode.d5.loss_cls: 1.0505  decode.d5.loss_mask: 0.7399  decode.d5.loss_dice: 1.3356  decode.d6.loss_cls: 1.0574  decode.d6.loss_mask: 0.7362  decode.d6.loss_dice: 1.3180  decode.d7.loss_cls: 1.0667  decode.d7.loss_mask: 0.7428  decode.d7.loss_dice: 1.3160  decode.d8.loss_cls: 1.0742  decode.d8.loss_mask: 0.7284  decode.d8.loss_dice: 1.3165
2023/05/24 13:55:40 - mmengine - INFO - Iter(train) [158200/160000]  lr: 1.7621e-07  eta: 0:13:01  time: 0.4238  data_time: 0.0101  memory: 4847  grad_norm: 98.8662  loss: 37.2981  decode.loss_cls: 1.1103  decode.loss_mask: 0.8889  decode.loss_dice: 1.4441  decode.d0.loss_cls: 3.1452  decode.d0.loss_mask: 0.9291  decode.d0.loss_dice: 1.5680  decode.d1.loss_cls: 1.3054  decode.d1.loss_mask: 0.9240  decode.d1.loss_dice: 1.5313  decode.d2.loss_cls: 1.2172  decode.d2.loss_mask: 0.8793  decode.d2.loss_dice: 1.4436  decode.d3.loss_cls: 1.1927  decode.d3.loss_mask: 0.8949  decode.d3.loss_dice: 1.4145  decode.d4.loss_cls: 1.2133  decode.d4.loss_mask: 0.8863  decode.d4.loss_dice: 1.4045  decode.d5.loss_cls: 1.1771  decode.d5.loss_mask: 0.8944  decode.d5.loss_dice: 1.4270  decode.d6.loss_cls: 1.1826  decode.d6.loss_mask: 0.8767  decode.d6.loss_dice: 1.4047  decode.d7.loss_cls: 1.1822  decode.d7.loss_mask: 0.8909  decode.d7.loss_dice: 1.4325  decode.d8.loss_cls: 1.1547  decode.d8.loss_mask: 0.8818  decode.d8.loss_dice: 1.4008
2023/05/24 13:56:01 - mmengine - INFO - Iter(train) [158250/160000]  lr: 1.7180e-07  eta: 0:12:39  time: 0.4231  data_time: 0.0099  memory: 4804  grad_norm: 89.6194  loss: 29.8891  decode.loss_cls: 1.0786  decode.loss_mask: 0.6004  decode.loss_dice: 0.9802  decode.d0.loss_cls: 3.0741  decode.d0.loss_mask: 0.6494  decode.d0.loss_dice: 1.1527  decode.d1.loss_cls: 1.2913  decode.d1.loss_mask: 0.6464  decode.d1.loss_dice: 1.1242  decode.d2.loss_cls: 1.2360  decode.d2.loss_mask: 0.5970  decode.d2.loss_dice: 1.0046  decode.d3.loss_cls: 1.1846  decode.d3.loss_mask: 0.6010  decode.d3.loss_dice: 1.0028  decode.d4.loss_cls: 1.1617  decode.d4.loss_mask: 0.6186  decode.d4.loss_dice: 1.0163  decode.d5.loss_cls: 1.1087  decode.d5.loss_mask: 0.6174  decode.d5.loss_dice: 1.0361  decode.d6.loss_cls: 1.1583  decode.d6.loss_mask: 0.6050  decode.d6.loss_dice: 0.9942  decode.d7.loss_cls: 1.0866  decode.d7.loss_mask: 0.6091  decode.d7.loss_dice: 0.9887  decode.d8.loss_cls: 1.0508  decode.d8.loss_mask: 0.5992  decode.d8.loss_dice: 1.0152
2023/05/24 13:56:22 - mmengine - INFO - Iter(train) [158300/160000]  lr: 1.6738e-07  eta: 0:12:18  time: 0.4266  data_time: 0.0101  memory: 4973  grad_norm: 80.9127  loss: 35.6248  decode.loss_cls: 1.1313  decode.loss_mask: 0.7289  decode.loss_dice: 1.4365  decode.d0.loss_cls: 3.0325  decode.d0.loss_mask: 0.8335  decode.d0.loss_dice: 1.6582  decode.d1.loss_cls: 1.2183  decode.d1.loss_mask: 0.7642  decode.d1.loss_dice: 1.5223  decode.d2.loss_cls: 1.1283  decode.d2.loss_mask: 0.7673  decode.d2.loss_dice: 1.5186  decode.d3.loss_cls: 1.1183  decode.d3.loss_mask: 0.7652  decode.d3.loss_dice: 1.4827  decode.d4.loss_cls: 1.1033  decode.d4.loss_mask: 0.7426  decode.d4.loss_dice: 1.4821  decode.d5.loss_cls: 1.1194  decode.d5.loss_mask: 0.7318  decode.d5.loss_dice: 1.4360  decode.d6.loss_cls: 1.1160  decode.d6.loss_mask: 0.7323  decode.d6.loss_dice: 1.4330  decode.d7.loss_cls: 1.1088  decode.d7.loss_mask: 0.7331  decode.d7.loss_dice: 1.4481  decode.d8.loss_cls: 1.1370  decode.d8.loss_mask: 0.7318  decode.d8.loss_dice: 1.4633
2023/05/24 13:56:43 - mmengine - INFO - Iter(train) [158350/160000]  lr: 1.6294e-07  eta: 0:11:56  time: 0.4234  data_time: 0.0104  memory: 4844  grad_norm: 156.2547  loss: 30.1485  decode.loss_cls: 1.1983  decode.loss_mask: 0.5265  decode.loss_dice: 0.9935  decode.d0.loss_cls: 3.1556  decode.d0.loss_mask: 0.5942  decode.d0.loss_dice: 1.2562  decode.d1.loss_cls: 1.3463  decode.d1.loss_mask: 0.5565  decode.d1.loss_dice: 1.1287  decode.d2.loss_cls: 1.2511  decode.d2.loss_mask: 0.5351  decode.d2.loss_dice: 1.0848  decode.d3.loss_cls: 1.2532  decode.d3.loss_mask: 0.5152  decode.d3.loss_dice: 1.0583  decode.d4.loss_cls: 1.2153  decode.d4.loss_mask: 0.5188  decode.d4.loss_dice: 1.0520  decode.d5.loss_cls: 1.2141  decode.d5.loss_mask: 0.5320  decode.d5.loss_dice: 1.0345  decode.d6.loss_cls: 1.1785  decode.d6.loss_mask: 0.5206  decode.d6.loss_dice: 1.0022  decode.d7.loss_cls: 1.1871  decode.d7.loss_mask: 0.5312  decode.d7.loss_dice: 1.0205  decode.d8.loss_cls: 1.1406  decode.d8.loss_mask: 0.5238  decode.d8.loss_dice: 1.0238
2023/05/24 13:57:05 - mmengine - INFO - Iter(train) [158400/160000]  lr: 1.5849e-07  eta: 0:11:34  time: 0.4238  data_time: 0.0108  memory: 4802  grad_norm: 93.6679  loss: 25.8418  decode.loss_cls: 0.7488  decode.loss_mask: 0.6839  decode.loss_dice: 0.8925  decode.d0.loss_cls: 2.6825  decode.d0.loss_mask: 0.7660  decode.d0.loss_dice: 1.0694  decode.d1.loss_cls: 0.8523  decode.d1.loss_mask: 0.7416  decode.d1.loss_dice: 0.9815  decode.d2.loss_cls: 0.8066  decode.d2.loss_mask: 0.6980  decode.d2.loss_dice: 0.9440  decode.d3.loss_cls: 0.8160  decode.d3.loss_mask: 0.7015  decode.d3.loss_dice: 0.8873  decode.d4.loss_cls: 0.7851  decode.d4.loss_mask: 0.6736  decode.d4.loss_dice: 0.8697  decode.d5.loss_cls: 0.7601  decode.d5.loss_mask: 0.6842  decode.d5.loss_dice: 0.9070  decode.d6.loss_cls: 0.7669  decode.d6.loss_mask: 0.6696  decode.d6.loss_dice: 0.8510  decode.d7.loss_cls: 0.7456  decode.d7.loss_mask: 0.6824  decode.d7.loss_dice: 0.8842  decode.d8.loss_cls: 0.7415  decode.d8.loss_mask: 0.6802  decode.d8.loss_dice: 0.8689
2023/05/24 13:57:26 - mmengine - INFO - Iter(train) [158450/160000]  lr: 1.5403e-07  eta: 0:11:12  time: 0.4245  data_time: 0.0098  memory: 4840  grad_norm: 95.7899  loss: 29.4895  decode.loss_cls: 0.9745  decode.loss_mask: 0.6810  decode.loss_dice: 1.0002  decode.d0.loss_cls: 2.9112  decode.d0.loss_mask: 0.7300  decode.d0.loss_dice: 1.1625  decode.d1.loss_cls: 1.1532  decode.d1.loss_mask: 0.7178  decode.d1.loss_dice: 1.1060  decode.d2.loss_cls: 1.0552  decode.d2.loss_mask: 0.6974  decode.d2.loss_dice: 1.0777  decode.d3.loss_cls: 1.0697  decode.d3.loss_mask: 0.6840  decode.d3.loss_dice: 1.0555  decode.d4.loss_cls: 1.0215  decode.d4.loss_mask: 0.6729  decode.d4.loss_dice: 1.0067  decode.d5.loss_cls: 1.0253  decode.d5.loss_mask: 0.6996  decode.d5.loss_dice: 1.0175  decode.d6.loss_cls: 1.0613  decode.d6.loss_mask: 0.6459  decode.d6.loss_dice: 0.9668  decode.d7.loss_cls: 1.0428  decode.d7.loss_mask: 0.6384  decode.d7.loss_dice: 0.9893  decode.d8.loss_cls: 0.9706  decode.d8.loss_mask: 0.6493  decode.d8.loss_dice: 1.0059
2023/05/24 13:57:48 - mmengine - INFO - Iter(train) [158500/160000]  lr: 1.4955e-07  eta: 0:10:51  time: 0.4278  data_time: 0.0099  memory: 4804  grad_norm: 94.2269  loss: 31.3533  decode.loss_cls: 0.9714  decode.loss_mask: 0.6115  decode.loss_dice: 1.2195  decode.d0.loss_cls: 2.9444  decode.d0.loss_mask: 0.7496  decode.d0.loss_dice: 1.4431  decode.d1.loss_cls: 1.1849  decode.d1.loss_mask: 0.6902  decode.d1.loss_dice: 1.2709  decode.d2.loss_cls: 1.0367  decode.d2.loss_mask: 0.7180  decode.d2.loss_dice: 1.2741  decode.d3.loss_cls: 1.0643  decode.d3.loss_mask: 0.6885  decode.d3.loss_dice: 1.2394  decode.d4.loss_cls: 0.9863  decode.d4.loss_mask: 0.6678  decode.d4.loss_dice: 1.2358  decode.d5.loss_cls: 0.9703  decode.d5.loss_mask: 0.6702  decode.d5.loss_dice: 1.2500  decode.d6.loss_cls: 0.9505  decode.d6.loss_mask: 0.6363  decode.d6.loss_dice: 1.2154  decode.d7.loss_cls: 1.0561  decode.d7.loss_mask: 0.6077  decode.d7.loss_dice: 1.1892  decode.d8.loss_cls: 1.0319  decode.d8.loss_mask: 0.6018  decode.d8.loss_dice: 1.1775
2023/05/24 13:58:09 - mmengine - INFO - Iter(train) [158550/160000]  lr: 1.4505e-07  eta: 0:10:29  time: 0.4342  data_time: 0.0101  memory: 4845  grad_norm: 106.7746  loss: 33.5792  decode.loss_cls: 1.2475  decode.loss_mask: 0.6869  decode.loss_dice: 1.2110  decode.d0.loss_cls: 2.7800  decode.d0.loss_mask: 0.7541  decode.d0.loss_dice: 1.4753  decode.d1.loss_cls: 1.1328  decode.d1.loss_mask: 0.7403  decode.d1.loss_dice: 1.4360  decode.d2.loss_cls: 1.1412  decode.d2.loss_mask: 0.7362  decode.d2.loss_dice: 1.3450  decode.d3.loss_cls: 1.1433  decode.d3.loss_mask: 0.7300  decode.d3.loss_dice: 1.2893  decode.d4.loss_cls: 1.0585  decode.d4.loss_mask: 0.7252  decode.d4.loss_dice: 1.3117  decode.d5.loss_cls: 1.1865  decode.d5.loss_mask: 0.7149  decode.d5.loss_dice: 1.2860  decode.d6.loss_cls: 1.1863  decode.d6.loss_mask: 0.7000  decode.d6.loss_dice: 1.2536  decode.d7.loss_cls: 1.2253  decode.d7.loss_mask: 0.7037  decode.d7.loss_dice: 1.2317  decode.d8.loss_cls: 1.2312  decode.d8.loss_mask: 0.6900  decode.d8.loss_dice: 1.2258
2023/05/24 13:58:31 - mmengine - INFO - Iter(train) [158600/160000]  lr: 1.4054e-07  eta: 0:10:07  time: 0.4240  data_time: 0.0099  memory: 4857  grad_norm: 95.4223  loss: 30.2769  decode.loss_cls: 1.0209  decode.loss_mask: 0.6530  decode.loss_dice: 1.0044  decode.d0.loss_cls: 3.0918  decode.d0.loss_mask: 0.7474  decode.d0.loss_dice: 1.1759  decode.d1.loss_cls: 1.2253  decode.d1.loss_mask: 0.7410  decode.d1.loss_dice: 1.1299  decode.d2.loss_cls: 1.1418  decode.d2.loss_mask: 0.6969  decode.d2.loss_dice: 1.1026  decode.d3.loss_cls: 1.0898  decode.d3.loss_mask: 0.6768  decode.d3.loss_dice: 1.0487  decode.d4.loss_cls: 1.0768  decode.d4.loss_mask: 0.6827  decode.d4.loss_dice: 1.0171  decode.d5.loss_cls: 1.0900  decode.d5.loss_mask: 0.6540  decode.d5.loss_dice: 1.0508  decode.d6.loss_cls: 1.0809  decode.d6.loss_mask: 0.6615  decode.d6.loss_dice: 0.9979  decode.d7.loss_cls: 1.0153  decode.d7.loss_mask: 0.6584  decode.d7.loss_dice: 1.0283  decode.d8.loss_cls: 1.0378  decode.d8.loss_mask: 0.6531  decode.d8.loss_dice: 1.0258
2023/05/24 13:58:52 - mmengine - INFO - Iter(train) [158650/160000]  lr: 1.3602e-07  eta: 0:09:46  time: 0.4208  data_time: 0.0100  memory: 4844  grad_norm: 93.2520  loss: 39.1878  decode.loss_cls: 1.2984  decode.loss_mask: 0.8505  decode.loss_dice: 1.4702  decode.d0.loss_cls: 3.2723  decode.d0.loss_mask: 0.9053  decode.d0.loss_dice: 1.7963  decode.d1.loss_cls: 1.3619  decode.d1.loss_mask: 0.8769  decode.d1.loss_dice: 1.6603  decode.d2.loss_cls: 1.3305  decode.d2.loss_mask: 0.8645  decode.d2.loss_dice: 1.6071  decode.d3.loss_cls: 1.3339  decode.d3.loss_mask: 0.8450  decode.d3.loss_dice: 1.5580  decode.d4.loss_cls: 1.3125  decode.d4.loss_mask: 0.8457  decode.d4.loss_dice: 1.5095  decode.d5.loss_cls: 1.2991  decode.d5.loss_mask: 0.8242  decode.d5.loss_dice: 1.4923  decode.d6.loss_cls: 1.2974  decode.d6.loss_mask: 0.8364  decode.d6.loss_dice: 1.4987  decode.d7.loss_cls: 1.2696  decode.d7.loss_mask: 0.8337  decode.d7.loss_dice: 1.5235  decode.d8.loss_cls: 1.2843  decode.d8.loss_mask: 0.8315  decode.d8.loss_dice: 1.4982
2023/05/24 13:59:14 - mmengine - INFO - Iter(train) [158700/160000]  lr: 1.3148e-07  eta: 0:09:24  time: 0.4227  data_time: 0.0101  memory: 4888  grad_norm: 91.3869  loss: 33.7781  decode.loss_cls: 0.9431  decode.loss_mask: 0.9133  decode.loss_dice: 1.1969  decode.d0.loss_cls: 3.0364  decode.d0.loss_mask: 0.9877  decode.d0.loss_dice: 1.3557  decode.d1.loss_cls: 1.0320  decode.d1.loss_mask: 0.9205  decode.d1.loss_dice: 1.3463  decode.d2.loss_cls: 1.0393  decode.d2.loss_mask: 0.9668  decode.d2.loss_dice: 1.3141  decode.d3.loss_cls: 0.9726  decode.d3.loss_mask: 0.9527  decode.d3.loss_dice: 1.2723  decode.d4.loss_cls: 1.0101  decode.d4.loss_mask: 0.9483  decode.d4.loss_dice: 1.2582  decode.d5.loss_cls: 0.9422  decode.d5.loss_mask: 0.9473  decode.d5.loss_dice: 1.2377  decode.d6.loss_cls: 0.9773  decode.d6.loss_mask: 0.9121  decode.d6.loss_dice: 1.2063  decode.d7.loss_cls: 0.9412  decode.d7.loss_mask: 0.9127  decode.d7.loss_dice: 1.2167  decode.d8.loss_cls: 0.9501  decode.d8.loss_mask: 0.8817  decode.d8.loss_dice: 1.1862
2023/05/24 13:59:37 - mmengine - INFO - Iter(train) [158750/160000]  lr: 1.2692e-07  eta: 0:09:02  time: 0.4256  data_time: 0.0098  memory: 4857  grad_norm: 83.1309  loss: 31.5821  decode.loss_cls: 1.1180  decode.loss_mask: 0.6271  decode.loss_dice: 1.0603  decode.d0.loss_cls: 2.9876  decode.d0.loss_mask: 0.6738  decode.d0.loss_dice: 1.3780  decode.d1.loss_cls: 1.2877  decode.d1.loss_mask: 0.7067  decode.d1.loss_dice: 1.2629  decode.d2.loss_cls: 1.2189  decode.d2.loss_mask: 0.6867  decode.d2.loss_dice: 1.1719  decode.d3.loss_cls: 1.2681  decode.d3.loss_mask: 0.6146  decode.d3.loss_dice: 1.1341  decode.d4.loss_cls: 1.1800  decode.d4.loss_mask: 0.6267  decode.d4.loss_dice: 1.1331  decode.d5.loss_cls: 1.1716  decode.d5.loss_mask: 0.6225  decode.d5.loss_dice: 1.0931  decode.d6.loss_cls: 1.1811  decode.d6.loss_mask: 0.6079  decode.d6.loss_dice: 1.0599  decode.d7.loss_cls: 1.1860  decode.d7.loss_mask: 0.5976  decode.d7.loss_dice: 1.0593  decode.d8.loss_cls: 1.2263  decode.d8.loss_mask: 0.5987  decode.d8.loss_dice: 1.0420
2023/05/24 13:59:59 - mmengine - INFO - Iter(train) [158800/160000]  lr: 1.2234e-07  eta: 0:08:41  time: 0.4828  data_time: 0.0112  memory: 4847  grad_norm: 93.8771  loss: 31.5917  decode.loss_cls: 1.1631  decode.loss_mask: 0.6792  decode.loss_dice: 1.0981  decode.d0.loss_cls: 2.7568  decode.d0.loss_mask: 0.7866  decode.d0.loss_dice: 1.2247  decode.d1.loss_cls: 1.2183  decode.d1.loss_mask: 0.8299  decode.d1.loss_dice: 1.2048  decode.d2.loss_cls: 1.2491  decode.d2.loss_mask: 0.7625  decode.d2.loss_dice: 1.1201  decode.d3.loss_cls: 1.2143  decode.d3.loss_mask: 0.6817  decode.d3.loss_dice: 1.0688  decode.d4.loss_cls: 1.1684  decode.d4.loss_mask: 0.6863  decode.d4.loss_dice: 1.0437  decode.d5.loss_cls: 1.1529  decode.d5.loss_mask: 0.6775  decode.d5.loss_dice: 1.0798  decode.d6.loss_cls: 1.1490  decode.d6.loss_mask: 0.6817  decode.d6.loss_dice: 1.0532  decode.d7.loss_cls: 1.1382  decode.d7.loss_mask: 0.6856  decode.d7.loss_dice: 1.0828  decode.d8.loss_cls: 1.1594  decode.d8.loss_mask: 0.6878  decode.d8.loss_dice: 1.0873
2023/05/24 14:00:21 - mmengine - INFO - Iter(train) [158850/160000]  lr: 1.1774e-07  eta: 0:08:19  time: 0.4365  data_time: 0.0102  memory: 4819  grad_norm: 83.6947  loss: 29.4152  decode.loss_cls: 0.9952  decode.loss_mask: 0.6358  decode.loss_dice: 0.9909  decode.d0.loss_cls: 2.7022  decode.d0.loss_mask: 0.7104  decode.d0.loss_dice: 1.1890  decode.d1.loss_cls: 1.0500  decode.d1.loss_mask: 0.7168  decode.d1.loss_dice: 1.1273  decode.d2.loss_cls: 1.1299  decode.d2.loss_mask: 0.6867  decode.d2.loss_dice: 1.0610  decode.d3.loss_cls: 1.1353  decode.d3.loss_mask: 0.6475  decode.d3.loss_dice: 1.0336  decode.d4.loss_cls: 1.1547  decode.d4.loss_mask: 0.6342  decode.d4.loss_dice: 0.9974  decode.d5.loss_cls: 1.1165  decode.d5.loss_mask: 0.6340  decode.d5.loss_dice: 1.0105  decode.d6.loss_cls: 1.1020  decode.d6.loss_mask: 0.6121  decode.d6.loss_dice: 1.0076  decode.d7.loss_cls: 1.0606  decode.d7.loss_mask: 0.6072  decode.d7.loss_dice: 0.9956  decode.d8.loss_cls: 1.0150  decode.d8.loss_mask: 0.6322  decode.d8.loss_dice: 1.0240
2023/05/24 14:00:43 - mmengine - INFO - Iter(train) [158900/160000]  lr: 1.1312e-07  eta: 0:07:57  time: 0.4172  data_time: 0.0101  memory: 4919  grad_norm: 98.9823  loss: 35.9353  decode.loss_cls: 1.1064  decode.loss_mask: 0.7730  decode.loss_dice: 1.3619  decode.d0.loss_cls: 3.2239  decode.d0.loss_mask: 0.9040  decode.d0.loss_dice: 1.6872  decode.d1.loss_cls: 1.2107  decode.d1.loss_mask: 0.8442  decode.d1.loss_dice: 1.5091  decode.d2.loss_cls: 1.1520  decode.d2.loss_mask: 0.8061  decode.d2.loss_dice: 1.4585  decode.d3.loss_cls: 1.1386  decode.d3.loss_mask: 0.8053  decode.d3.loss_dice: 1.4189  decode.d4.loss_cls: 1.1218  decode.d4.loss_mask: 0.7896  decode.d4.loss_dice: 1.4324  decode.d5.loss_cls: 1.1560  decode.d5.loss_mask: 0.7743  decode.d5.loss_dice: 1.4024  decode.d6.loss_cls: 1.1087  decode.d6.loss_mask: 0.7940  decode.d6.loss_dice: 1.3711  decode.d7.loss_cls: 1.1515  decode.d7.loss_mask: 0.7840  decode.d7.loss_dice: 1.3754  decode.d8.loss_cls: 1.1112  decode.d8.loss_mask: 0.7773  decode.d8.loss_dice: 1.3858
2023/05/24 14:01:04 - mmengine - INFO - Iter(train) [158950/160000]  lr: 1.0848e-07  eta: 0:07:35  time: 0.4229  data_time: 0.0100  memory: 4846  grad_norm: 82.6115  loss: 27.5481  decode.loss_cls: 0.9614  decode.loss_mask: 0.5953  decode.loss_dice: 0.8915  decode.d0.loss_cls: 2.8153  decode.d0.loss_mask: 0.6661  decode.d0.loss_dice: 1.0485  decode.d1.loss_cls: 1.0603  decode.d1.loss_mask: 0.7054  decode.d1.loss_dice: 1.0222  decode.d2.loss_cls: 1.0292  decode.d2.loss_mask: 0.6440  decode.d2.loss_dice: 0.9358  decode.d3.loss_cls: 1.0110  decode.d3.loss_mask: 0.6575  decode.d3.loss_dice: 0.9166  decode.d4.loss_cls: 0.9541  decode.d4.loss_mask: 0.6555  decode.d4.loss_dice: 0.9337  decode.d5.loss_cls: 0.9954  decode.d5.loss_mask: 0.6232  decode.d5.loss_dice: 0.9041  decode.d6.loss_cls: 0.9978  decode.d6.loss_mask: 0.6238  decode.d6.loss_dice: 0.9182  decode.d7.loss_cls: 0.9659  decode.d7.loss_mask: 0.6134  decode.d7.loss_dice: 0.9069  decode.d8.loss_cls: 0.9603  decode.d8.loss_mask: 0.6225  decode.d8.loss_dice: 0.9130
2023/05/24 14:01:25 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 14:01:25 - mmengine - INFO - Iter(train) [159000/160000]  lr: 1.0382e-07  eta: 0:07:14  time: 0.4256  data_time: 0.0102  memory: 4815  grad_norm: 109.3088  loss: 31.4752  decode.loss_cls: 1.1345  decode.loss_mask: 0.6639  decode.loss_dice: 1.0574  decode.d0.loss_cls: 3.0748  decode.d0.loss_mask: 0.6830  decode.d0.loss_dice: 1.3223  decode.d1.loss_cls: 1.3393  decode.d1.loss_mask: 0.7068  decode.d1.loss_dice: 1.2258  decode.d2.loss_cls: 1.2536  decode.d2.loss_mask: 0.6840  decode.d2.loss_dice: 1.0754  decode.d3.loss_cls: 1.1729  decode.d3.loss_mask: 0.6426  decode.d3.loss_dice: 1.0771  decode.d4.loss_cls: 1.1531  decode.d4.loss_mask: 0.6570  decode.d4.loss_dice: 1.0892  decode.d5.loss_cls: 1.1372  decode.d5.loss_mask: 0.6531  decode.d5.loss_dice: 1.0621  decode.d6.loss_cls: 1.1318  decode.d6.loss_mask: 0.6892  decode.d6.loss_dice: 1.0646  decode.d7.loss_cls: 1.1240  decode.d7.loss_mask: 0.6688  decode.d7.loss_dice: 1.1046  decode.d8.loss_cls: 1.1183  decode.d8.loss_mask: 0.6597  decode.d8.loss_dice: 1.0492
2023/05/24 14:01:25 - mmengine - INFO - Saving checkpoint at 159000 iterations
2023/05/24 14:01:52 - mmengine - INFO - Iter(train) [159050/160000]  lr: 9.9139e-08  eta: 0:06:52  time: 0.4257  data_time: 0.0099  memory: 4951  grad_norm: 104.9352  loss: 39.2313  decode.loss_cls: 1.3143  decode.loss_mask: 0.8085  decode.loss_dice: 1.4091  decode.d0.loss_cls: 3.1909  decode.d0.loss_mask: 0.8911  decode.d0.loss_dice: 1.7618  decode.d1.loss_cls: 1.6077  decode.d1.loss_mask: 0.8236  decode.d1.loss_dice: 1.5824  decode.d2.loss_cls: 1.4981  decode.d2.loss_mask: 0.8593  decode.d2.loss_dice: 1.5381  decode.d3.loss_cls: 1.3933  decode.d3.loss_mask: 0.8711  decode.d3.loss_dice: 1.5399  decode.d4.loss_cls: 1.3850  decode.d4.loss_mask: 0.8673  decode.d4.loss_dice: 1.4301  decode.d5.loss_cls: 1.3597  decode.d5.loss_mask: 0.8470  decode.d5.loss_dice: 1.4777  decode.d6.loss_cls: 1.3239  decode.d6.loss_mask: 0.8468  decode.d6.loss_dice: 1.4384  decode.d7.loss_cls: 1.3565  decode.d7.loss_mask: 0.8399  decode.d7.loss_dice: 1.4346  decode.d8.loss_cls: 1.2713  decode.d8.loss_mask: 0.8367  decode.d8.loss_dice: 1.4268
2023/05/24 14:02:13 - mmengine - INFO - Iter(train) [159100/160000]  lr: 9.4431e-08  eta: 0:06:30  time: 0.4208  data_time: 0.0097  memory: 4859  grad_norm: 93.6078  loss: 36.2465  decode.loss_cls: 1.2580  decode.loss_mask: 0.7931  decode.loss_dice: 1.2241  decode.d0.loss_cls: 3.0869  decode.d0.loss_mask: 0.9943  decode.d0.loss_dice: 1.4323  decode.d1.loss_cls: 1.4293  decode.d1.loss_mask: 0.9275  decode.d1.loss_dice: 1.3668  decode.d2.loss_cls: 1.4246  decode.d2.loss_mask: 0.8752  decode.d2.loss_dice: 1.2972  decode.d3.loss_cls: 1.3465  decode.d3.loss_mask: 0.8558  decode.d3.loss_dice: 1.2128  decode.d4.loss_cls: 1.2775  decode.d4.loss_mask: 0.8283  decode.d4.loss_dice: 1.2442  decode.d5.loss_cls: 1.3068  decode.d5.loss_mask: 0.8187  decode.d5.loss_dice: 1.2251  decode.d6.loss_cls: 1.3321  decode.d6.loss_mask: 0.8229  decode.d6.loss_dice: 1.2115  decode.d7.loss_cls: 1.2884  decode.d7.loss_mask: 0.7987  decode.d7.loss_dice: 1.2088  decode.d8.loss_cls: 1.3517  decode.d8.loss_mask: 0.7906  decode.d8.loss_dice: 1.2168
2023/05/24 14:02:34 - mmengine - INFO - Iter(train) [159150/160000]  lr: 8.9696e-08  eta: 0:06:09  time: 0.4195  data_time: 0.0101  memory: 4900  grad_norm: 99.9767  loss: 36.3917  decode.loss_cls: 1.2671  decode.loss_mask: 0.7949  decode.loss_dice: 1.3017  decode.d0.loss_cls: 3.1752  decode.d0.loss_mask: 0.8586  decode.d0.loss_dice: 1.5519  decode.d1.loss_cls: 1.4130  decode.d1.loss_mask: 0.8283  decode.d1.loss_dice: 1.4644  decode.d2.loss_cls: 1.3347  decode.d2.loss_mask: 0.8251  decode.d2.loss_dice: 1.3456  decode.d3.loss_cls: 1.2825  decode.d3.loss_mask: 0.8037  decode.d3.loss_dice: 1.3655  decode.d4.loss_cls: 1.2674  decode.d4.loss_mask: 0.8215  decode.d4.loss_dice: 1.3369  decode.d5.loss_cls: 1.3154  decode.d5.loss_mask: 0.7876  decode.d5.loss_dice: 1.2779  decode.d6.loss_cls: 1.2123  decode.d6.loss_mask: 0.7930  decode.d6.loss_dice: 1.3042  decode.d7.loss_cls: 1.2360  decode.d7.loss_mask: 0.7870  decode.d7.loss_dice: 1.3258  decode.d8.loss_cls: 1.2399  decode.d8.loss_mask: 0.7777  decode.d8.loss_dice: 1.2970
2023/05/24 14:02:56 - mmengine - INFO - Iter(train) [159200/160000]  lr: 8.4933e-08  eta: 0:05:47  time: 0.4842  data_time: 0.0100  memory: 4838  grad_norm: 96.0429  loss: 42.3917  decode.loss_cls: 1.5017  decode.loss_mask: 0.8658  decode.loss_dice: 1.5846  decode.d0.loss_cls: 3.3443  decode.d0.loss_mask: 0.8790  decode.d0.loss_dice: 1.8781  decode.d1.loss_cls: 1.6718  decode.d1.loss_mask: 0.8806  decode.d1.loss_dice: 1.7427  decode.d2.loss_cls: 1.6136  decode.d2.loss_mask: 0.8586  decode.d2.loss_dice: 1.6620  decode.d3.loss_cls: 1.5764  decode.d3.loss_mask: 0.8674  decode.d3.loss_dice: 1.6367  decode.d4.loss_cls: 1.4790  decode.d4.loss_mask: 0.8870  decode.d4.loss_dice: 1.6556  decode.d5.loss_cls: 1.4894  decode.d5.loss_mask: 0.8590  decode.d5.loss_dice: 1.6177  decode.d6.loss_cls: 1.4898  decode.d6.loss_mask: 0.8647  decode.d6.loss_dice: 1.5859  decode.d7.loss_cls: 1.4965  decode.d7.loss_mask: 0.8497  decode.d7.loss_dice: 1.6060  decode.d8.loss_cls: 1.5138  decode.d8.loss_mask: 0.8680  decode.d8.loss_dice: 1.5660
2023/05/24 14:03:20 - mmengine - INFO - Iter(train) [159250/160000]  lr: 8.0140e-08  eta: 0:05:25  time: 0.4768  data_time: 0.0098  memory: 4838  grad_norm: 102.8086  loss: 37.5974  decode.loss_cls: 1.2671  decode.loss_mask: 0.7663  decode.loss_dice: 1.4714  decode.d0.loss_cls: 3.0843  decode.d0.loss_mask: 0.7906  decode.d0.loss_dice: 1.7163  decode.d1.loss_cls: 1.3354  decode.d1.loss_mask: 0.7796  decode.d1.loss_dice: 1.5730  decode.d2.loss_cls: 1.3391  decode.d2.loss_mask: 0.7568  decode.d2.loss_dice: 1.5364  decode.d3.loss_cls: 1.3761  decode.d3.loss_mask: 0.7223  decode.d3.loss_dice: 1.5129  decode.d4.loss_cls: 1.2429  decode.d4.loss_mask: 0.7589  decode.d4.loss_dice: 1.5179  decode.d5.loss_cls: 1.2370  decode.d5.loss_mask: 0.7528  decode.d5.loss_dice: 1.5303  decode.d6.loss_cls: 1.2451  decode.d6.loss_mask: 0.7682  decode.d6.loss_dice: 1.5087  decode.d7.loss_cls: 1.2124  decode.d7.loss_mask: 0.7638  decode.d7.loss_dice: 1.4972  decode.d8.loss_cls: 1.2702  decode.d8.loss_mask: 0.7689  decode.d8.loss_dice: 1.4955
2023/05/24 14:03:44 - mmengine - INFO - Iter(train) [159300/160000]  lr: 7.5315e-08  eta: 0:05:03  time: 0.4830  data_time: 0.0097  memory: 4855  grad_norm: 135.3763  loss: 29.1420  decode.loss_cls: 0.8294  decode.loss_mask: 0.7001  decode.loss_dice: 1.1190  decode.d0.loss_cls: 2.8862  decode.d0.loss_mask: 0.7548  decode.d0.loss_dice: 1.2699  decode.d1.loss_cls: 0.9679  decode.d1.loss_mask: 0.7047  decode.d1.loss_dice: 1.2199  decode.d2.loss_cls: 0.9078  decode.d2.loss_mask: 0.7039  decode.d2.loss_dice: 1.1485  decode.d3.loss_cls: 0.8699  decode.d3.loss_mask: 0.6954  decode.d3.loss_dice: 1.1125  decode.d4.loss_cls: 0.8318  decode.d4.loss_mask: 0.7051  decode.d4.loss_dice: 1.1150  decode.d5.loss_cls: 0.8639  decode.d5.loss_mask: 0.7040  decode.d5.loss_dice: 1.1057  decode.d6.loss_cls: 0.8610  decode.d6.loss_mask: 0.6803  decode.d6.loss_dice: 1.0978  decode.d7.loss_cls: 0.8661  decode.d7.loss_mask: 0.6866  decode.d7.loss_dice: 1.1069  decode.d8.loss_cls: 0.8498  decode.d8.loss_mask: 0.6769  decode.d8.loss_dice: 1.1013
2023/05/24 14:04:07 - mmengine - INFO - Iter(train) [159350/160000]  lr: 7.0456e-08  eta: 0:04:42  time: 0.4260  data_time: 0.0099  memory: 4994  grad_norm: 93.2689  loss: 35.3263  decode.loss_cls: 1.0681  decode.loss_mask: 0.7083  decode.loss_dice: 1.4371  decode.d0.loss_cls: 3.2498  decode.d0.loss_mask: 0.7487  decode.d0.loss_dice: 1.6633  decode.d1.loss_cls: 1.2007  decode.d1.loss_mask: 0.7672  decode.d1.loss_dice: 1.5426  decode.d2.loss_cls: 1.1415  decode.d2.loss_mask: 0.7235  decode.d2.loss_dice: 1.4819  decode.d3.loss_cls: 1.1137  decode.d3.loss_mask: 0.7074  decode.d3.loss_dice: 1.4842  decode.d4.loss_cls: 1.0861  decode.d4.loss_mask: 0.7131  decode.d4.loss_dice: 1.4996  decode.d5.loss_cls: 1.0595  decode.d5.loss_mask: 0.7052  decode.d5.loss_dice: 1.4604  decode.d6.loss_cls: 1.1355  decode.d6.loss_mask: 0.6993  decode.d6.loss_dice: 1.4757  decode.d7.loss_cls: 1.0431  decode.d7.loss_mask: 0.7054  decode.d7.loss_dice: 1.4728  decode.d8.loss_cls: 1.0499  decode.d8.loss_mask: 0.7158  decode.d8.loss_dice: 1.4670
2023/05/24 14:04:29 - mmengine - INFO - Iter(train) [159400/160000]  lr: 6.5559e-08  eta: 0:04:20  time: 0.4240  data_time: 0.0097  memory: 4835  grad_norm: 90.9730  loss: 31.2384  decode.loss_cls: 1.3416  decode.loss_mask: 0.5565  decode.loss_dice: 0.9152  decode.d0.loss_cls: 3.2660  decode.d0.loss_mask: 0.6277  decode.d0.loss_dice: 1.1266  decode.d1.loss_cls: 1.5548  decode.d1.loss_mask: 0.5921  decode.d1.loss_dice: 1.0341  decode.d2.loss_cls: 1.3876  decode.d2.loss_mask: 0.5802  decode.d2.loss_dice: 0.9808  decode.d3.loss_cls: 1.4243  decode.d3.loss_mask: 0.5651  decode.d3.loss_dice: 0.9265  decode.d4.loss_cls: 1.4127  decode.d4.loss_mask: 0.5677  decode.d4.loss_dice: 0.9531  decode.d5.loss_cls: 1.3659  decode.d5.loss_mask: 0.5744  decode.d5.loss_dice: 0.9554  decode.d6.loss_cls: 1.3741  decode.d6.loss_mask: 0.5742  decode.d6.loss_dice: 0.9280  decode.d7.loss_cls: 1.3490  decode.d7.loss_mask: 0.5665  decode.d7.loss_dice: 0.9355  decode.d8.loss_cls: 1.3223  decode.d8.loss_mask: 0.5601  decode.d8.loss_dice: 0.9204
2023/05/24 14:04:50 - mmengine - INFO - Iter(train) [159450/160000]  lr: 6.0621e-08  eta: 0:03:58  time: 0.4244  data_time: 0.0107  memory: 4821  grad_norm: 94.3998  loss: 25.6167  decode.loss_cls: 0.6716  decode.loss_mask: 0.7698  decode.loss_dice: 0.8936  decode.d0.loss_cls: 2.5775  decode.d0.loss_mask: 0.7449  decode.d0.loss_dice: 0.9852  decode.d1.loss_cls: 0.7699  decode.d1.loss_mask: 0.7544  decode.d1.loss_dice: 0.9650  decode.d2.loss_cls: 0.7108  decode.d2.loss_mask: 0.7551  decode.d2.loss_dice: 0.9212  decode.d3.loss_cls: 0.6899  decode.d3.loss_mask: 0.7779  decode.d3.loss_dice: 0.9344  decode.d4.loss_cls: 0.6576  decode.d4.loss_mask: 0.7845  decode.d4.loss_dice: 0.9226  decode.d5.loss_cls: 0.6695  decode.d5.loss_mask: 0.7585  decode.d5.loss_dice: 0.9067  decode.d6.loss_cls: 0.7000  decode.d6.loss_mask: 0.7428  decode.d6.loss_dice: 0.9007  decode.d7.loss_cls: 0.6935  decode.d7.loss_mask: 0.7404  decode.d7.loss_dice: 0.8909  decode.d8.loss_cls: 0.6776  decode.d8.loss_mask: 0.7611  decode.d8.loss_dice: 0.8893
2023/05/24 14:05:11 - mmengine - INFO - Iter(train) [159500/160000]  lr: 5.5637e-08  eta: 0:03:37  time: 0.4228  data_time: 0.0099  memory: 4835  grad_norm: 82.4873  loss: 33.9004  decode.loss_cls: 0.9894  decode.loss_mask: 0.6505  decode.loss_dice: 1.4122  decode.d0.loss_cls: 3.1000  decode.d0.loss_mask: 0.7553  decode.d0.loss_dice: 1.6228  decode.d1.loss_cls: 1.0601  decode.d1.loss_mask: 0.7505  decode.d1.loss_dice: 1.5840  decode.d2.loss_cls: 1.1254  decode.d2.loss_mask: 0.6684  decode.d2.loss_dice: 1.4509  decode.d3.loss_cls: 1.0426  decode.d3.loss_mask: 0.6670  decode.d3.loss_dice: 1.4221  decode.d4.loss_cls: 1.0325  decode.d4.loss_mask: 0.6638  decode.d4.loss_dice: 1.4587  decode.d5.loss_cls: 1.0601  decode.d5.loss_mask: 0.6589  decode.d5.loss_dice: 1.4378  decode.d6.loss_cls: 1.0323  decode.d6.loss_mask: 0.6591  decode.d6.loss_dice: 1.4070  decode.d7.loss_cls: 0.9841  decode.d7.loss_mask: 0.6611  decode.d7.loss_dice: 1.4477  decode.d8.loss_cls: 1.0099  decode.d8.loss_mask: 0.6570  decode.d8.loss_dice: 1.4291
2023/05/24 14:05:33 - mmengine - INFO - Iter(train) [159550/160000]  lr: 5.0604e-08  eta: 0:03:15  time: 0.4325  data_time: 0.0104  memory: 4885  grad_norm: 88.5341  loss: 29.6978  decode.loss_cls: 0.8770  decode.loss_mask: 0.7071  decode.loss_dice: 1.0772  decode.d0.loss_cls: 2.8948  decode.d0.loss_mask: 0.8234  decode.d0.loss_dice: 1.2509  decode.d1.loss_cls: 1.0441  decode.d1.loss_mask: 0.7602  decode.d1.loss_dice: 1.1912  decode.d2.loss_cls: 1.0612  decode.d2.loss_mask: 0.7151  decode.d2.loss_dice: 1.0814  decode.d3.loss_cls: 0.9138  decode.d3.loss_mask: 0.7216  decode.d3.loss_dice: 1.0936  decode.d4.loss_cls: 0.8782  decode.d4.loss_mask: 0.7195  decode.d4.loss_dice: 1.1076  decode.d5.loss_cls: 0.8860  decode.d5.loss_mask: 0.7156  decode.d5.loss_dice: 1.0905  decode.d6.loss_cls: 0.9133  decode.d6.loss_mask: 0.7157  decode.d6.loss_dice: 1.0865  decode.d7.loss_cls: 0.8984  decode.d7.loss_mask: 0.7043  decode.d7.loss_dice: 1.0774  decode.d8.loss_cls: 0.8891  decode.d8.loss_mask: 0.6980  decode.d8.loss_dice: 1.1051
2023/05/24 14:05:55 - mmengine - INFO - Iter(train) [159600/160000]  lr: 4.5514e-08  eta: 0:02:53  time: 0.4265  data_time: 0.0100  memory: 4865  grad_norm: 84.3971  loss: 24.8926  decode.loss_cls: 0.7610  decode.loss_mask: 0.6684  decode.loss_dice: 0.8045  decode.d0.loss_cls: 2.5838  decode.d0.loss_mask: 0.7020  decode.d0.loss_dice: 0.8942  decode.d1.loss_cls: 0.8925  decode.d1.loss_mask: 0.7392  decode.d1.loss_dice: 0.8814  decode.d2.loss_cls: 0.8350  decode.d2.loss_mask: 0.7007  decode.d2.loss_dice: 0.8452  decode.d3.loss_cls: 0.7777  decode.d3.loss_mask: 0.7050  decode.d3.loss_dice: 0.8221  decode.d4.loss_cls: 0.7944  decode.d4.loss_mask: 0.6791  decode.d4.loss_dice: 0.8294  decode.d5.loss_cls: 0.7802  decode.d5.loss_mask: 0.6883  decode.d5.loss_dice: 0.8167  decode.d6.loss_cls: 0.7324  decode.d6.loss_mask: 0.7003  decode.d6.loss_dice: 0.8124  decode.d7.loss_cls: 0.7507  decode.d7.loss_mask: 0.6731  decode.d7.loss_dice: 0.8185  decode.d8.loss_cls: 0.7486  decode.d8.loss_mask: 0.6485  decode.d8.loss_dice: 0.8071
2023/05/24 14:06:18 - mmengine - INFO - Iter(train) [159650/160000]  lr: 4.0360e-08  eta: 0:02:31  time: 0.4725  data_time: 0.0108  memory: 4829  grad_norm: 100.2554  loss: 30.6884  decode.loss_cls: 0.9859  decode.loss_mask: 0.8177  decode.loss_dice: 1.0379  decode.d0.loss_cls: 2.7982  decode.d0.loss_mask: 0.8385  decode.d0.loss_dice: 1.1800  decode.d1.loss_cls: 1.0589  decode.d1.loss_mask: 0.8217  decode.d1.loss_dice: 1.1267  decode.d2.loss_cls: 1.0134  decode.d2.loss_mask: 0.8397  decode.d2.loss_dice: 1.1106  decode.d3.loss_cls: 0.9931  decode.d3.loss_mask: 0.8001  decode.d3.loss_dice: 1.0295  decode.d4.loss_cls: 1.0109  decode.d4.loss_mask: 0.8077  decode.d4.loss_dice: 1.0453  decode.d5.loss_cls: 0.9713  decode.d5.loss_mask: 0.8235  decode.d5.loss_dice: 1.0475  decode.d6.loss_cls: 1.0024  decode.d6.loss_mask: 0.8188  decode.d6.loss_dice: 1.0203  decode.d7.loss_cls: 0.9877  decode.d7.loss_mask: 0.8178  decode.d7.loss_dice: 1.0516  decode.d8.loss_cls: 0.9709  decode.d8.loss_mask: 0.8153  decode.d8.loss_dice: 1.0454
2023/05/24 14:06:41 - mmengine - INFO - Iter(train) [159700/160000]  lr: 3.5132e-08  eta: 0:02:10  time: 0.4773  data_time: 0.0097  memory: 4909  grad_norm: 91.0459  loss: 27.4206  decode.loss_cls: 0.8465  decode.loss_mask: 0.7059  decode.loss_dice: 0.9318  decode.d0.loss_cls: 2.8968  decode.d0.loss_mask: 0.7564  decode.d0.loss_dice: 1.0680  decode.d1.loss_cls: 0.8773  decode.d1.loss_mask: 0.7177  decode.d1.loss_dice: 1.0516  decode.d2.loss_cls: 0.8692  decode.d2.loss_mask: 0.7093  decode.d2.loss_dice: 1.0013  decode.d3.loss_cls: 0.8652  decode.d3.loss_mask: 0.6928  decode.d3.loss_dice: 0.9513  decode.d4.loss_cls: 0.8198  decode.d4.loss_mask: 0.6981  decode.d4.loss_dice: 0.9693  decode.d5.loss_cls: 0.8613  decode.d5.loss_mask: 0.6918  decode.d5.loss_dice: 0.9571  decode.d6.loss_cls: 0.8015  decode.d6.loss_mask: 0.7093  decode.d6.loss_dice: 0.9446  decode.d7.loss_cls: 0.8581  decode.d7.loss_mask: 0.7018  decode.d7.loss_dice: 0.9571  decode.d8.loss_cls: 0.8704  decode.d8.loss_mask: 0.7063  decode.d8.loss_dice: 0.9330
2023/05/24 14:07:03 - mmengine - INFO - Iter(train) [159750/160000]  lr: 2.9815e-08  eta: 0:01:48  time: 0.4296  data_time: 0.0099  memory: 4869  grad_norm: 88.5768  loss: 38.9019  decode.loss_cls: 1.3616  decode.loss_mask: 0.8084  decode.loss_dice: 1.4047  decode.d0.loss_cls: 3.4416  decode.d0.loss_mask: 0.8712  decode.d0.loss_dice: 1.6318  decode.d1.loss_cls: 1.4787  decode.d1.loss_mask: 0.8947  decode.d1.loss_dice: 1.5433  decode.d2.loss_cls: 1.4206  decode.d2.loss_mask: 0.8245  decode.d2.loss_dice: 1.4730  decode.d3.loss_cls: 1.3604  decode.d3.loss_mask: 0.8164  decode.d3.loss_dice: 1.4578  decode.d4.loss_cls: 1.3495  decode.d4.loss_mask: 0.8091  decode.d4.loss_dice: 1.4610  decode.d5.loss_cls: 1.4343  decode.d5.loss_mask: 0.8067  decode.d5.loss_dice: 1.4343  decode.d6.loss_cls: 1.4206  decode.d6.loss_mask: 0.7933  decode.d6.loss_dice: 1.3953  decode.d7.loss_cls: 1.4019  decode.d7.loss_mask: 0.8043  decode.d7.loss_dice: 1.3922  decode.d8.loss_cls: 1.3989  decode.d8.loss_mask: 0.8046  decode.d8.loss_dice: 1.4071
2023/05/24 14:07:24 - mmengine - INFO - Iter(train) [159800/160000]  lr: 2.4391e-08  eta: 0:01:26  time: 0.4819  data_time: 0.0099  memory: 4829  grad_norm: 91.9551  loss: 30.5399  decode.loss_cls: 0.8464  decode.loss_mask: 0.7409  decode.loss_dice: 1.1899  decode.d0.loss_cls: 2.6761  decode.d0.loss_mask: 0.7479  decode.d0.loss_dice: 1.3934  decode.d1.loss_cls: 0.9295  decode.d1.loss_mask: 0.7828  decode.d1.loss_dice: 1.3638  decode.d2.loss_cls: 0.8712  decode.d2.loss_mask: 0.7518  decode.d2.loss_dice: 1.3242  decode.d3.loss_cls: 0.8979  decode.d3.loss_mask: 0.7087  decode.d3.loss_dice: 1.2258  decode.d4.loss_cls: 0.8500  decode.d4.loss_mask: 0.7489  decode.d4.loss_dice: 1.2661  decode.d5.loss_cls: 0.8184  decode.d5.loss_mask: 0.7372  decode.d5.loss_dice: 1.2607  decode.d6.loss_cls: 0.8481  decode.d6.loss_mask: 0.7270  decode.d6.loss_dice: 1.2251  decode.d7.loss_cls: 0.8670  decode.d7.loss_mask: 0.7294  decode.d7.loss_dice: 1.2125  decode.d8.loss_cls: 0.8650  decode.d8.loss_mask: 0.7115  decode.d8.loss_dice: 1.2229
2023/05/24 14:07:46 - mmengine - INFO - Iter(train) [159850/160000]  lr: 1.8827e-08  eta: 0:01:05  time: 0.4304  data_time: 0.0098  memory: 4866  grad_norm: 81.2452  loss: 34.5879  decode.loss_cls: 1.3200  decode.loss_mask: 0.7410  decode.loss_dice: 1.0487  decode.d0.loss_cls: 3.2465  decode.d0.loss_mask: 0.9462  decode.d0.loss_dice: 1.3212  decode.d1.loss_cls: 1.5070  decode.d1.loss_mask: 0.8753  decode.d1.loss_dice: 1.2350  decode.d2.loss_cls: 1.4460  decode.d2.loss_mask: 0.7712  decode.d2.loss_dice: 1.1255  decode.d3.loss_cls: 1.3898  decode.d3.loss_mask: 0.7488  decode.d3.loss_dice: 1.0733  decode.d4.loss_cls: 1.3727  decode.d4.loss_mask: 0.7775  decode.d4.loss_dice: 1.0818  decode.d5.loss_cls: 1.3626  decode.d5.loss_mask: 0.7709  decode.d5.loss_dice: 1.0729  decode.d6.loss_cls: 1.3364  decode.d6.loss_mask: 0.7390  decode.d6.loss_dice: 1.0442  decode.d7.loss_cls: 1.3388  decode.d7.loss_mask: 0.7429  decode.d7.loss_dice: 1.0367  decode.d8.loss_cls: 1.3252  decode.d8.loss_mask: 0.7395  decode.d8.loss_dice: 1.0516
2023/05/24 14:08:08 - mmengine - INFO - Iter(train) [159900/160000]  lr: 1.3071e-08  eta: 0:00:43  time: 0.4234  data_time: 0.0103  memory: 4885  grad_norm: 81.1525  loss: 40.6808  decode.loss_cls: 1.4344  decode.loss_mask: 0.8654  decode.loss_dice: 1.4607  decode.d0.loss_cls: 3.6633  decode.d0.loss_mask: 0.9255  decode.d0.loss_dice: 1.6987  decode.d1.loss_cls: 1.4812  decode.d1.loss_mask: 0.9299  decode.d1.loss_dice: 1.6516  decode.d2.loss_cls: 1.4728  decode.d2.loss_mask: 0.8989  decode.d2.loss_dice: 1.5540  decode.d3.loss_cls: 1.4784  decode.d3.loss_mask: 0.8732  decode.d3.loss_dice: 1.4455  decode.d4.loss_cls: 1.4918  decode.d4.loss_mask: 0.8760  decode.d4.loss_dice: 1.4293  decode.d5.loss_cls: 1.4261  decode.d5.loss_mask: 0.8684  decode.d5.loss_dice: 1.4814  decode.d6.loss_cls: 1.4024  decode.d6.loss_mask: 0.8655  decode.d6.loss_dice: 1.4563  decode.d7.loss_cls: 1.4605  decode.d7.loss_mask: 0.8682  decode.d7.loss_dice: 1.4408  decode.d8.loss_cls: 1.4214  decode.d8.loss_mask: 0.8656  decode.d8.loss_dice: 1.4937
2023/05/24 14:08:29 - mmengine - INFO - Iter(train) [159950/160000]  lr: 7.0043e-09  eta: 0:00:21  time: 0.4265  data_time: 0.0100  memory: 4822  grad_norm: 84.5537  loss: 31.3242  decode.loss_cls: 1.2107  decode.loss_mask: 0.5883  decode.loss_dice: 1.0594  decode.d0.loss_cls: 3.0601  decode.d0.loss_mask: 0.6516  decode.d0.loss_dice: 1.2240  decode.d1.loss_cls: 1.3511  decode.d1.loss_mask: 0.6348  decode.d1.loss_dice: 1.1329  decode.d2.loss_cls: 1.2974  decode.d2.loss_mask: 0.6330  decode.d2.loss_dice: 1.1061  decode.d3.loss_cls: 1.2592  decode.d3.loss_mask: 0.6266  decode.d3.loss_dice: 1.0800  decode.d4.loss_cls: 1.2382  decode.d4.loss_mask: 0.5978  decode.d4.loss_dice: 1.0563  decode.d5.loss_cls: 1.2240  decode.d5.loss_mask: 0.6058  decode.d5.loss_dice: 1.0580  decode.d6.loss_cls: 1.2513  decode.d6.loss_mask: 0.5821  decode.d6.loss_dice: 1.0631  decode.d7.loss_cls: 1.2308  decode.d7.loss_mask: 0.5895  decode.d7.loss_dice: 1.0415  decode.d8.loss_cls: 1.2205  decode.d8.loss_mask: 0.5888  decode.d8.loss_dice: 1.0613
2023/05/24 14:08:51 - mmengine - INFO - Exp name: mask2former_swin-s_8xb2-160k_cocostuff164k-512x512-joint-train_20230523_181754
2023/05/24 14:08:51 - mmengine - INFO - Iter(train) [160000/160000]  lr: 0.0000e+00  eta: 0:00:00  time: 0.4341  data_time: 0.0103  memory: 4843  grad_norm: 90.6507  loss: 41.2215  decode.loss_cls: 1.4385  decode.loss_mask: 0.8469  decode.loss_dice: 1.4934  decode.d0.loss_cls: 3.4327  decode.d0.loss_mask: 0.9197  decode.d0.loss_dice: 1.8324  decode.d1.loss_cls: 1.5618  decode.d1.loss_mask: 0.9355  decode.d1.loss_dice: 1.7083  decode.d2.loss_cls: 1.5208  decode.d2.loss_mask: 0.8740  decode.d2.loss_dice: 1.6299  decode.d3.loss_cls: 1.4189  decode.d3.loss_mask: 0.9080  decode.d3.loss_dice: 1.5849  decode.d4.loss_cls: 1.4118  decode.d4.loss_mask: 0.8568  decode.d4.loss_dice: 1.5604  decode.d5.loss_cls: 1.4444  decode.d5.loss_mask: 0.8729  decode.d5.loss_dice: 1.5666  decode.d6.loss_cls: 1.4675  decode.d6.loss_mask: 0.8513  decode.d6.loss_dice: 1.4975  decode.d7.loss_cls: 1.4229  decode.d7.loss_mask: 0.8478  decode.d7.loss_dice: 1.5191  decode.d8.loss_cls: 1.4536  decode.d8.loss_mask: 0.8463  decode.d8.loss_dice: 1.4967
2023/05/24 14:08:51 - mmengine - INFO - Saving checkpoint at 160000 iterations
2023/05/24 14:09:01 - mmengine - INFO - Iter(val) [ 50/625]    eta: 0:00:47  time: 0.0779  data_time: 0.0018  memory: 2167  
2023/05/24 14:09:05 - mmengine - INFO - Iter(val) [100/625]    eta: 0:00:42  time: 0.0781  data_time: 0.0017  memory: 2216  
2023/05/24 14:09:09 - mmengine - INFO - Iter(val) [150/625]    eta: 0:00:39  time: 0.0802  data_time: 0.0017  memory: 2167  
2023/05/24 14:09:13 - mmengine - INFO - Iter(val) [200/625]    eta: 0:00:35  time: 0.0797  data_time: 0.0020  memory: 2104  
2023/05/24 14:09:18 - mmengine - INFO - Iter(val) [250/625]    eta: 0:00:31  time: 0.0913  data_time: 0.0019  memory: 2831  
2023/05/24 14:09:22 - mmengine - INFO - Iter(val) [300/625]    eta: 0:00:26  time: 0.0907  data_time: 0.0018  memory: 2167  
2023/05/24 14:09:26 - mmengine - INFO - Iter(val) [350/625]    eta: 0:00:22  time: 0.0799  data_time: 0.0018  memory: 2167  
2023/05/24 14:09:30 - mmengine - INFO - Iter(val) [400/625]    eta: 0:00:18  time: 0.0823  data_time: 0.0018  memory: 2167  
2023/05/24 14:09:34 - mmengine - INFO - Iter(val) [450/625]    eta: 0:00:14  time: 0.0800  data_time: 0.0018  memory: 2944  
2023/05/24 14:09:41 - mmengine - INFO - Iter(val) [500/625]    eta: 0:00:10  time: 0.0832  data_time: 0.0018  memory: 2356  
2023/05/24 14:09:45 - mmengine - INFO - Iter(val) [550/625]    eta: 0:00:06  time: 0.0891  data_time: 0.0019  memory: 2217  
2023/05/24 14:09:49 - mmengine - INFO - Iter(val) [600/625]    eta: 0:00:02  time: 0.0791  data_time: 0.0018  memory: 2328  
2023/05/24 14:09:53 - mmengine - INFO - per class results:
2023/05/24 14:09:53 - mmengine - INFO - 
+------------------+-------+-------+
|      Class       |  IoU  |  Acc  |
+------------------+-------+-------+
|      person      | 86.54 |  93.6 |
|     bicycle      | 70.56 | 84.19 |
|       car        | 62.47 | 85.35 |
|    motorcycle    | 83.28 | 90.24 |
|     airplane     | 86.26 | 93.66 |
|       bus        |  82.5 | 88.32 |
|      train       | 83.08 | 94.74 |
|      truck       | 57.62 | 75.02 |
|       boat       | 61.58 | 80.08 |
|  traffic light   | 69.33 | 84.71 |
|   fire hydrant   | 89.18 |  95.2 |
|    stop sign     | 91.85 | 96.77 |
|  parking meter   | 76.42 | 87.64 |
|      bench       | 48.87 | 71.95 |
|       bird       | 81.96 | 91.28 |
|       cat        | 85.63 | 91.78 |
|       dog        | 81.87 | 87.91 |
|      horse       | 79.04 | 91.05 |
|      sheep       | 86.21 | 93.41 |
|       cow        | 82.65 | 88.38 |
|     elephant     | 89.69 | 95.33 |
|       bear       | 92.56 | 95.31 |
|      zebra       | 90.37 | 93.62 |
|     giraffe      | 87.54 | 93.57 |
|     backpack     | 34.96 | 63.28 |
|     umbrella     |  79.9 | 88.74 |
|     handbag      | 33.44 | 54.69 |
|       tie        | 11.73 | 15.18 |
|     suitcase     | 77.97 | 90.73 |
|     frisbee      | 69.19 | 90.79 |
|       skis       | 45.07 | 60.47 |
|    snowboard     | 58.16 | 75.19 |
|   sports ball    | 56.57 | 74.34 |
|       kite       | 58.15 | 71.67 |
|   baseball bat   | 54.34 | 68.66 |
|  baseball glove  | 72.88 | 86.07 |
|    skateboard    | 76.54 | 84.74 |
|    surfboard     | 72.91 | 87.37 |
|  tennis racket   | 86.04 | 92.63 |
|      bottle      | 42.07 | 54.17 |
|    wine glass    | 56.94 |  79.2 |
|       cup        |  53.6 | 76.71 |
|       fork       | 39.52 | 49.46 |
|      knife       | 33.17 | 45.18 |
|      spoon       | 38.22 | 58.23 |
|       bowl       | 45.43 | 64.74 |
|      banana      |  66.7 | 87.48 |
|      apple       | 48.79 | 71.19 |
|     sandwich     |  46.2 | 64.59 |
|      orange      | 60.59 | 66.44 |
|     broccoli     | 57.25 | 69.98 |
|      carrot      | 52.02 | 56.72 |
|     hot dog      | 49.32 | 60.54 |
|      pizza       | 68.69 | 85.82 |
|      donut       | 70.86 | 87.12 |
|       cake       | 61.67 | 74.33 |
|      chair       | 47.77 | 66.69 |
|      couch       | 57.37 | 80.67 |
|   potted plant   | 31.08 | 47.42 |
|       bed        | 63.69 | 83.15 |
|   dining table   |  44.6 | 78.64 |
|      toilet      | 82.45 | 93.85 |
|        tv        | 71.53 | 85.01 |
|      laptop      |  74.8 | 91.43 |
|      mouse       | 75.59 | 89.64 |
|      remote      | 57.06 | 73.04 |
|     keyboard     | 62.78 |  72.0 |
|    cell phone    | 73.11 | 89.76 |
|    microwave     |  63.3 | 76.22 |
|       oven       | 56.19 | 80.72 |
|     toaster      | 42.52 | 54.79 |
|       sink       | 55.65 | 79.42 |
|   refrigerator   | 78.06 | 92.19 |
|       book       | 49.77 |  69.9 |
|      clock       | 75.27 | 84.89 |
|       vase       | 57.15 | 83.31 |
|     scissors     | 78.86 | 90.58 |
|    teddy bear    | 75.96 | 87.61 |
|    hair drier    | 45.25 | 55.19 |
|    toothbrush    | 44.12 | 77.54 |
|      banner      | 35.25 | 61.35 |
|     blanket      |  4.8  |  5.4  |
|      branch      | 18.68 | 28.95 |
|      bridge      |  33.0 | 48.36 |
|  building-other  | 54.05 | 73.42 |
|       bush       | 32.74 | 45.76 |
|     cabinet      | 54.99 |  72.0 |
|       cage       | 18.76 | 24.62 |
|    cardboard     | 46.12 | 55.79 |
|      carpet      | 51.48 | 71.45 |
|  ceiling-other   | 64.74 | 81.55 |
|   ceiling-tile   |  0.0  |  0.0  |
|      cloth       |  0.0  |  0.0  |
|     clothes      | 21.55 | 31.58 |
|      clouds      | 46.21 | 59.87 |
|     counter      | 27.54 | 47.47 |
|     cupboard     |  0.0  |  0.0  |
|     curtain      | 65.62 | 79.05 |
|    desk-stuff    | 45.63 | 60.82 |
|       dirt       | 40.53 | 58.12 |
|    door-stuff    | 39.35 | 61.82 |
|      fence       | 34.18 | 62.67 |
|   floor-marble   |  5.76 |  6.71 |
|   floor-other    | 22.93 | 31.89 |
|   floor-stone    |  3.84 |  4.46 |
|    floor-tile    | 60.23 | 69.96 |
|    floor-wood    | 62.79 | 77.72 |
|      flower      |  40.9 | 60.16 |
|       fog        |  7.55 |  7.95 |
|    food-other    | 26.71 | 31.77 |
|      fruit       | 39.44 | 59.83 |
| furniture-other  | 17.55 | 24.42 |
|      grass       | 70.45 | 83.94 |
|      gravel      | 25.98 | 37.76 |
|   ground-other   |  1.23 |  1.56 |
|       hill       | 21.77 | 29.55 |
|      house       | 25.58 | 30.58 |
|      leaves      | 24.75 | 32.84 |
|      light       | 37.93 | 54.43 |
|       mat        |  0.0  |  0.0  |
|      metal       | 32.13 | 46.62 |
|   mirror-stuff   | 51.11 | 71.01 |
|       moss       |  0.0  |  0.0  |
|     mountain     | 52.83 | 67.03 |
|       mud        |  5.31 |  8.08 |
|      napkin      | 13.03 | 13.63 |
|       net        | 41.54 | 64.14 |
|      paper       | 29.29 | 41.67 |
|     pavement     | 52.04 | 71.41 |
|      pillow      | 14.73 | 19.19 |
|   plant-other    |  17.9 | 31.45 |
|     plastic      | 23.43 | 31.99 |
|     platform     | 27.84 | 46.42 |
|   playingfield   | 70.22 | 91.27 |
|     railing      |  6.58 |  9.76 |
|     railroad     | 61.76 | 79.77 |
|      river       | 53.21 | 68.55 |
|       road       |  67.3 |  82.8 |
|       rock       | 44.85 | 67.67 |
|       roof       | 15.98 | 21.13 |
|       rug        | 34.75 | 51.53 |
|      salad       |  0.0  |  0.0  |
|       sand       | 62.38 | 70.95 |
|       sea        | 86.05 | 91.85 |
|      shelf       | 35.45 | 48.35 |
|    sky-other     | 70.66 | 87.48 |
|    skyscraper    | 34.82 | 43.92 |
|       snow       | 89.14 | 93.26 |
|   solid-other    |  0.23 |  0.23 |
|      stairs      | 23.68 | 40.32 |
|      stone       | 11.23 |  18.0 |
|      straw       | 30.83 | 41.58 |
| structural-other |  0.08 |  0.08 |
|      table       | 18.05 | 23.66 |
|       tent       |  7.07 |  9.32 |
|  textile-other   | 12.48 | 19.53 |
|      towel       | 33.74 | 42.58 |
|       tree       | 73.75 | 86.25 |
|    vegetable     | 33.58 | 44.28 |
|    wall-brick    | 47.07 | 63.89 |
|  wall-concrete   | 60.61 | 80.34 |
|    wall-other    | 20.32 | 32.53 |
|    wall-panel    |  1.92 |  2.14 |
|    wall-stone    | 32.88 | 39.93 |
|    wall-tile     | 67.98 | 83.28 |
|    wall-wood     | 41.16 | 57.47 |
|   water-other    | 28.43 | 45.85 |
|    waterdrops    |  0.0  |  0.0  |
|   window-blind   | 51.02 |  59.9 |
|   window-other   | 47.35 | 72.52 |
|       wood       | 25.02 |  37.7 |
+------------------+-------+-------+
2023/05/24 14:09:53 - mmengine - INFO - Iter(val) [625/625]    aAcc: 71.7400  mIoU: 47.6200  mAcc: 60.1200  data_time: 0.0020  time: 0.0866
2023/05/24 14:09:53 - mmengine - INFO - The previous best checkpoint /mnt/bn/liheyang/mmsegmentation/work_dirs/mask2former_swin-s_8xb2-cocostuff164k-512x512-joint-train-bs16-lr1x-iter160k-6x-filter1.25-resampled/best_mIoU_iter_150000.pth is removed
2023/05/24 14:09:57 - mmengine - INFO - The best checkpoint with 47.6200 mIoU at 160000 iter is saved to best_mIoU_iter_160000.pth.
